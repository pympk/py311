{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set pandas display options to show more columns and rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "# pd.set_option('display.max_rows', 10)       # Limit to 10 rows for readability\n",
    "pd.set_option('display.width', None)        # Let the display adjust to the window\n",
    "\n",
    "# 2. Set the display width (optional but often helpful)\n",
    "#    'None' tries to detect terminal width. \n",
    "#    A large number (e.g., 1000) ensures no wrapping unless absolutely necessary.\n",
    "pd.set_option('display.width', 1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_path: C:\\Users\\ping\\Downloads\\df_finviz_2025-04-24_stocks_etfs.parquet\n",
      "dest_path: ..\\data\\2025-04-24_df_finviz.parquet\n"
     ]
    }
   ],
   "source": [
    "# process_files.py\n",
    "from config import date_str, DOWNLOAD_DIR, DEST_DIR\n",
    "from pathlib import Path  # Better path handling\n",
    "\n",
    "# Build paths\n",
    "# source_path = Path(DOWNLOAD_DIR) / f'df_finviz_{date_str}.pkl'\n",
    "# dest_path = Path(DEST_DIR) / 'df_finviz.pkl'\n",
    "source_path = Path(DOWNLOAD_DIR) / f'df_finviz_{date_str}_stocks_etfs.parquet'\n",
    "dest_path = Path(DEST_DIR) / f'{date_str}_df_finviz.parquet'\n",
    "\n",
    "print(f\"source_path: {source_path}\")\n",
    "print(f\"dest_path: {dest_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set pandas display options to show more columns and rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "# pd.set_option('display.max_rows', 10)       # Limit to 10 rows for readability\n",
    "# pd.set_option('display.width', None)        # Let the display adjust to the window\n",
    "# pd.set_option('display.max_colwidth', None) # Show full content of each cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\ping\\\\Downloads\\\\df_finviz_2025-04-24_stocks_etfs.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpyarrow\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# df = pd.read_pickle(source_path)\u001b[39;00m\n\u001b[32m      3\u001b[39m display(df.info(), df.head())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Lib\\site-packages\\pandas\\io\\parquet.py:667\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[39m\n\u001b[32m    664\u001b[39m     use_nullable_dtypes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    665\u001b[39m check_dtype_backend(dtype_backend)\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Lib\\site-packages\\pandas\\io\\parquet.py:267\u001b[39m, in \u001b[36mPyArrowImpl.read\u001b[39m\u001b[34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m manager == \u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    265\u001b[39m     to_pandas_kwargs[\u001b[33m\"\u001b[39m\u001b[33msplit_blocks\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m path_or_handle, handles, filesystem = \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    274\u001b[39m     pa_table = \u001b[38;5;28mself\u001b[39m.api.parquet.read_table(\n\u001b[32m    275\u001b[39m         path_or_handle,\n\u001b[32m    276\u001b[39m         columns=columns,\n\u001b[32m   (...)\u001b[39m\u001b[32m    279\u001b[39m         **kwargs,\n\u001b[32m    280\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Lib\\site-packages\\pandas\\io\\parquet.py:140\u001b[39m, in \u001b[36m_get_path_or_handle\u001b[39m\u001b[34m(path, fs, storage_options, mode, is_dir)\u001b[39m\n\u001b[32m    130\u001b[39m handles = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    132\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[32m    133\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[32m   (...)\u001b[39m\u001b[32m    138\u001b[39m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[32m    139\u001b[39m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m     handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m     fs = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    144\u001b[39m     path_or_handle = handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\ping\\\\Downloads\\\\df_finviz_2025-04-24_stocks_etfs.parquet'"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(source_path, engine='pyarrow')\n",
    "# df = pd.read_pickle(source_path)\n",
    "display(df.info(), df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convert_B_M_K_to_million(value_str):\n",
    "  \"\"\"\n",
    "  Convert financial string values with suffixes to numeric values in billions\n",
    "  Examples:\n",
    "  '104.27B' -> 104,270\n",
    "  '104.27M' -> 104.27\n",
    "  '104.27K' -> 0.10427\n",
    "  '-' -> np.nan\n",
    "  \"\"\"\n",
    "  \n",
    "  if not isinstance(value_str, str):\n",
    "    return value_str  # Return the original value if not a string\n",
    "    \n",
    "  if value_str == '-':\n",
    "    return np.nan\n",
    "    \n",
    "  # Remove any whitespace\n",
    "  value_str = value_str.strip()\n",
    "  \n",
    "  # Handle suffixes\n",
    "  multipliers = {\n",
    "    'B': 1000,  \n",
    "    'M': 1,\n",
    "    'K': 0.001\n",
    "  }\n",
    "  \n",
    "  try:\n",
    "    # Extract the numeric part and suffix\n",
    "    if value_str[-1] in multipliers:\n",
    "      number = float(value_str[:-1])\n",
    "      multiplier = multipliers[value_str[-1]]\n",
    "      return number * multiplier\n",
    "    else:\n",
    "      # If no suffix, try to convert directly to float\n",
    "      return float(value_str)\n",
    "  except (ValueError, IndexError):\n",
    "    return np.nan\n",
    "\n",
    "# Example usage:\n",
    "# df['Market Cap Numeric'] = df['Market Cap'].apply(convert_B_M_K_to_million)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def process_percentage_columns(df):\n",
    "    \"\"\"\n",
    "    Identifies and processes columns in a DataFrame where values end with '%'.\n",
    "    The function cleans, converts to numeric, renames, and prints which columns were modified.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The modified DataFrame with processed percentage columns.\n",
    "                      Returns the original DataFrame if no percentage columns are found.\n",
    "    \"\"\"\n",
    "\n",
    "    # Identify columns where values END WITH '%'\n",
    "    percent_cols = [\n",
    "        col for col in df.columns\n",
    "        if df[col].dtype == 'object'\n",
    "        and df[col].str.strip().str.endswith('%', na=False).any()\n",
    "    ]\n",
    "\n",
    "    # If no percentage columns are found, return the original DataFrame\n",
    "    if not percent_cols:\n",
    "        print(\"No percentage columns found to modify.\")  # Print message\n",
    "        return df\n",
    "\n",
    "    print(\"The following columns ending with % were modified:\") #Print message before the loop\n",
    "\n",
    "    # Process identified percentage columns\n",
    "    for col in percent_cols:\n",
    "        # Clean data: (1) Strip whitespace, (2) Handle '-', (3) Remove trailing %\n",
    "        cleaned_series = (\n",
    "            df[col].str.strip()\n",
    "            .replace('-', np.nan)  # Convert '-' to NaN\n",
    "            .str.replace(r'%$', '', regex=True)  # Remove only ENDING %\n",
    "        )\n",
    "        \n",
    "        # Convert to numeric (coerce invalid values to NaN)\n",
    "        df[col] = pd.to_numeric(cleaned_series, errors='coerce')\n",
    "        \n",
    "        # Rename column\n",
    "        df.rename(columns={col: f\"{col} %\"}, inplace=True)\n",
    "        print(f\"- {col}\")  # Print the column name\n",
    "        \n",
    "    return df\n",
    "\n",
    "# Example Usage:\n",
    "# Assuming you have a DataFrame called 'df'\n",
    "# df = process_percentage_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = process_percentage_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to concatenate\n",
    "columns_to_concat = [\"Sector\", \"Industry\", \"Single Category\", \"Asset Type\"]\n",
    "\n",
    "# Replace '-' with empty string in specified columns\n",
    "for col in columns_to_concat:\n",
    "    df[col] = df[col].replace('-', '')\n",
    "\n",
    "# Concatenate the columns, handling empty strings, and remove extra spaces\n",
    "df['Info'] = df[columns_to_concat].apply(lambda row: ', '.join(filter(None, row.astype(str))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the columns 'Market Cap' and 'AUM'\n",
    "# Replace '-' with empty string in both columns\n",
    "\n",
    "df['MktCap AUM'] = df['Market Cap'].replace('-', '') + df['AUM'].replace('-', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column by converting to numeric values in millions\n",
    "df['MktCap AUM, M'] = df['MktCap AUM'].apply(convert_B_M_K_to_million)\n",
    "df['Avg Volume, M'] = df['Avg Volume'].apply(convert_B_M_K_to_million)\n",
    "df['Volume, M'] = (pd.to_numeric(df['Volume'].str.replace(',', ''), errors='coerce') / 1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Beta', 'ATR', 'Rel Volume', and 'Price' to float\n",
    "for col in ['Beta', 'ATR', 'RSI', 'Rel Volume', 'Price']:\n",
    "  # Clean and convert to numeric\n",
    "  df[col] = pd.to_numeric(\n",
    "    df[col].str.replace('$', '').str.replace(',', ''),\n",
    "    errors='coerce'  # Convert invalid values to NaN\n",
    "  )\n",
    "\n",
    "# Verify the conversion\n",
    "for col in ['Beta', 'ATR', 'Rel Volume', 'Price']:\n",
    "  print(f\"{col}: {df[col].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cols = ['Ticker', 'Company', 'Info', 'MktCap AUM, M', 'Beta',\n",
    "          'RSI', 'Perf YTD %', 'Perf Week %', 'Perf Month %', 'Perf Quart %', 'Perf Half %', 'Perf Year %',\n",
    "          'SMA20 %', 'SMA50 %', 'SMA200 %',   \n",
    "          '50D High %', '50D Low %', '52W High %', '52W Low %', 'All-Time High %', 'All-Time Low %',\n",
    "          'ATR', 'Volatility W %', 'Volatility M %',  \n",
    "          'Volume, M', 'Avg Volume, M','Rel Volume',\n",
    "          'Price', 'Change %', 'Dividend %', \n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new df with my_cols and set Ticker as index\n",
    "new_df = df[my_cols].set_index('Ticker')\n",
    "\n",
    "# Sort by 'MktCap AUM, M' in descending order, with NaN values last\n",
    "new_df = new_df.sort_values(by='MktCap AUM, M', ascending=False, na_position='last')\n",
    "\n",
    "# Display info and first few rows to verify\n",
    "display(new_df.info(), new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to pickle file\n",
    "# new_df.to_pickle(dest_path)\n",
    "\n",
    "# Using PyArrow (default, recommended for most cases)\n",
    "new_df.to_parquet(dest_path, engine='pyarrow')\n",
    "print(f'save new_df to {dest_path}')\n",
    "\n",
    "# # To load it later:\n",
    "# loaded_df = pd.read_pickle('df_finviz.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
