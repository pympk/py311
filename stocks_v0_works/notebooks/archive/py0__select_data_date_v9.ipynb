{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Orchestrator\n",
    "\n",
    "This notebook finds available Finviz data, allows the user to select which date(s) to process, and then executes the main processing pipeline (`run_sequence.py`) for each selected date.\n",
    "\n",
    "**Workflow:**\n",
    "1.  **Setup:** Configure paths and define the default date selection rule.\n",
    "2.  **Get Valid Trading days:** Retrieve OHLCV data. Use the date index as valid trading days.\n",
    "3.  **Find Data Files:** Scan the `Downloads` directory for recent Finviz data files.\n",
    "4.  **Select Dates:** Extract available dates and apply the default selection rule.\n",
    "5.  **(Optional) Refine Selection:** Interactively prompt the user to override the default date selection.\n",
    "6.  **Execute Pipeline:** For each selected date, generate a `config.py` file and run the external processing script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Root Directory: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\n",
      "Scanning for data files in: C:\\Users\\ping\\Downloads\n",
      "OHLCV Parquet Path: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# --- Project Path Setup ---\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "ROOT_DIR = NOTEBOOK_DIR.parent if NOTEBOOK_DIR.name == 'notebooks' else NOTEBOOK_DIR\n",
    "SRC_DIR = ROOT_DIR / 'src'\n",
    "if str(ROOT_DIR) not in sys.path: sys.path.append(str(ROOT_DIR))\n",
    "if str(SRC_DIR) not in sys.path: sys.path.append(str(SRC_DIR))\n",
    "import utils\n",
    "\n",
    "# --- Data File Configuration ---\n",
    "DOWNLOADS_DIR = Path.home() / \"Downloads\"\n",
    "DATA_FILE_PREFIX = 'df_finviz'\n",
    "DATA_FILE_EXTENSION = 'parquet'\n",
    "DATA_FILES_TO_SCAN = 100\n",
    "OHLCV_PARQUET_PATH = ROOT_DIR / \"data\" / \"df_OHLCV_stocks_etfs.parquet\"\n",
    "\n",
    "# --- Analysis Run Configuration ---\n",
    "# Default rule for selecting which dates to process.\n",
    "# slice(-1, None, None) -> Processes only the most recent date.\n",
    "DATE_SLICE = slice(-1, None, None)\n",
    "\n",
    "# --- config.py Generation Parameters ---\n",
    "DEST_DIR = ROOT_DIR / 'data'\n",
    "ANNUAL_RISK_FREE_RATE = 0.04\n",
    "TRADING_DAYS_PER_YEAR = 252\n",
    "\n",
    "# --- Notebook Setup ---\n",
    "pd.set_option('display.max_columns', None); pd.set_option('display.width', 1000)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# --- Verification ---\n",
    "print(f\"Project Root Directory: {ROOT_DIR}\")\n",
    "print(f\"Scanning for data files in: {DOWNLOADS_DIR}\")\n",
    "print(f'OHLCV Parquet Path: {OHLCV_PARQUET_PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Get Valid Trading Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trading_days (total 351):\n",
      "type(trading_days): <class 'pandas.core.indexes.datetimes.DatetimeIndex'>\n",
      "trading_days:\n",
      "DatetimeIndex(['2024-02-01', '2024-02-02', '2024-02-05', '2024-02-06', '2024-02-07', '2024-02-08', '2024-02-09', '2024-02-12', '2024-02-13', '2024-02-14',\n",
      "               ...\n",
      "               '2025-06-12', '2025-06-13', '2025-06-16', '2025-06-17', '2025-06-18', '2025-06-20', '2025-06-23', '2025-06-24', '2025-06-25', '2025-06-26'], dtype='datetime64[ns]', name='Date', length=351, freq=None)\n"
     ]
    }
   ],
   "source": [
    "df_prices = pd.read_parquet(OHLCV_PARQUET_PATH)\n",
    "\n",
    "# The date is the second level of the index (level 1, since it's 0-indexed)\n",
    "trading_days = df_prices.index \\\n",
    "    .get_level_values('Date') \\\n",
    "    .unique() \\\n",
    "    .sort_values()\n",
    "\n",
    "# trading_days is now a sorted DatetimeIndex\n",
    "print(f'trading_days (total {len(trading_days)}):')\n",
    "print(f'type(trading_days): {type(trading_days)}')\n",
    "print(f'trading_days:\\n{trading_days}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Find and Display Available Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Finding recent data files ---\n",
      "\n",
      "Filtering available dates against actual trading days...\n",
      "\n",
      "Found 43 valid trading dates to process:\n",
      "  0    2025-04-25    1    2025-04-28    2    2025-04-29    3    2025-04-30    4    2025-05-01\n",
      "  5    2025-05-02    6    2025-05-05    7    2025-05-06    8    2025-05-07    9    2025-05-08\n",
      "  10   2025-05-09    11   2025-05-12    12   2025-05-13    13   2025-05-14    14   2025-05-15\n",
      "  15   2025-05-16    16   2025-05-19    17   2025-05-20    18   2025-05-21    19   2025-05-22\n",
      "  20   2025-05-23    21   2025-05-27    22   2025-05-28    23   2025-05-29    24   2025-05-30\n",
      "  25   2025-06-02    26   2025-06-03    27   2025-06-04    28   2025-06-05    29   2025-06-06\n",
      "  30   2025-06-09    31   2025-06-10    32   2025-06-11    33   2025-06-12    34   2025-06-13\n",
      "  35   2025-06-16    36   2025-06-17    37   2025-06-18    38   2025-06-20    39   2025-06-23\n",
      "  40   2025-06-24    41   2025-06-25    42   2025-06-26\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Step 1: Finding recent data files ---\")\n",
    "\n",
    "found_files = utils.get_recent_files_in_directory(\n",
    "    directory_path=DOWNLOADS_DIR,\n",
    "    prefix=DATA_FILE_PREFIX,\n",
    "    extension=DATA_FILE_EXTENSION,\n",
    "    count=DATA_FILES_TO_SCAN\n",
    ")\n",
    "\n",
    "if not found_files:\n",
    "    print(f\"No files matching '{DATA_FILE_PREFIX}*.{DATA_FILE_EXTENSION}' found.\")\n",
    "    available_dates = []\n",
    "else:\n",
    "    # Extract dates from filenames\n",
    "    available_dates = utils.extract_and_sort_dates_from_filenames(found_files)\n",
    "    \n",
    "    # --- START OF NEW CODE ---\n",
    "    print(\"\\nFiltering available dates against actual trading days...\")\n",
    "    \n",
    "    # Convert list of strings to a pandas DatetimeIndex for comparison\n",
    "    available_dt_index = pd.to_datetime(available_dates)\n",
    "    \n",
    "    # Create a boolean mask indicating which dates are valid trading days\n",
    "    is_trading_day_mask = available_dt_index.isin(trading_days)\n",
    "    \n",
    "    # Apply the mask to keep only the valid dates\n",
    "    filtered_dates = [date for date, is_valid in zip(available_dates, is_trading_day_mask) if is_valid]\n",
    "    \n",
    "    # Overwrite the variable with the cleaned list\n",
    "    available_dates = filtered_dates\n",
    "    # --- END OF NEW CODE ---\n",
    "\n",
    "    print(f\"\\nFound {len(available_dates)} valid trading dates to process:\")\n",
    "    utils.print_list_in_columns(available_dates, num_columns=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Select Dates for Processing (Default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 2: Applying default selection rule ---\n",
      "Default rule 'slice(-1, None, None)' selected 1 date(s):\n",
      "['2025-06-26']\n"
     ]
    }
   ],
   "source": [
    "if available_dates:\n",
    "    # Apply the default slice defined in the setup cell\n",
    "    dates_to_process = available_dates[DATE_SLICE]\n",
    "    print(f\"\\n--- Step 2: Applying default selection rule ---\")\n",
    "    print(f\"Default rule '{DATE_SLICE}' selected {len(dates_to_process)} date(s):\")\n",
    "    print(dates_to_process)\n",
    "else:\n",
    "    dates_to_process = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: (OPTIONAL) Interactively Refine Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Continuing with the current value.\n"
     ]
    }
   ],
   "source": [
    "if available_dates:\n",
    "    # Call the interactive utility function\n",
    "    NEW_DATE_SLICE = utils.prompt_for_slice_update(\"DATE_SLICE\", DATE_SLICE)\n",
    "    \n",
    "    # If the slice was changed, update the list of dates to process\n",
    "    if NEW_DATE_SLICE != DATE_SLICE:\n",
    "        DATE_SLICE = NEW_DATE_SLICE\n",
    "        dates_to_process = available_dates[DATE_SLICE]\n",
    "        print(f\"\\nUpdated selection. Now processing {len(dates_to_process)} date(s):\")\n",
    "        print(dates_to_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Execute Pipeline\n",
    "\n",
    "This cell iterates through the final list of selected dates, generates the `config.py` file for each, and executes the `run_sequence.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 4: Starting processing sequence ---\n",
      "\n",
      "==================== PROCESSING DATE: 2025-06-26 ====================\n",
      "Successfully created config file: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\config.py\n",
      "Executing run_sequence_v2.py for 2025-06-26...\n",
      "Starting notebook execution sequence...\n",
      "\n",
      "--- Running py1_clean_df_finviz_v14.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\executed\\executed_py1_clean_df_finviz_v14.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\py1_clean_df_finviz_v14.ipynb\n",
      "Successfully executed py1_clean_df_finviz_v14.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\executed\\executed_py1_clean_df_finviz_v14.ipynb\n",
      "\n",
      "--- Running py2_clean_df_OHLCV_v10.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\executed\\executed_py2_clean_df_OHLCV_v10.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\py2_clean_df_OHLCV_v10.ipynb\n",
      "Successfully executed py2_clean_df_OHLCV_v10.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\executed\\executed_py2_clean_df_OHLCV_v10.ipynb\n",
      "\n",
      "--- Running py2_save_df_adj_close_v1.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\executed\\executed_py2_save_df_adj_close_v1.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\py2_save_df_adj_close_v1.ipynb\n",
      "Successfully executed py2_save_df_adj_close_v1.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\executed\\executed_py2_save_df_adj_close_v1.ipynb\n",
      "\n",
      "--- Running py3_calc_perf_ratios_v16.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\executed\\executed_py3_calc_perf_ratios_v16.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\py3_calc_perf_ratios_v16.ipynb\n",
      "Successfully executed py3_calc_perf_ratios_v16.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\executed\\executed_py3_calc_perf_ratios_v16.ipynb\n",
      "\n",
      "--- Running py4_append_ratios_v9.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\executed\\executed_py4_append_ratios_v9.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\py4_append_ratios_v9.ipynb\n",
      "Successfully executed py4_append_ratios_v9.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\executed\\executed_py4_append_ratios_v9.ipynb\n",
      "\n",
      "--- Running py5_append_columns_v8.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\executed\\executed_py5_append_columns_v8.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\py5_append_columns_v8.ipynb\n",
      "Successfully executed py5_append_columns_v8.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\executed\\executed_py5_append_columns_v8.ipynb\n",
      "\n",
      "--- Running py6_append_stats_history_v4.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\executed\\executed_py6_append_stats_history_v4.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\py6_append_stats_history_v4.ipynb\n",
      "Successfully executed py6_append_stats_history_v4.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\executed\\executed_py6_append_stats_history_v4.ipynb\n",
      "\n",
      "--- Running py6_view_market_sentiment_history.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\executed\\executed_py6_view_market_sentiment_history.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\py6_view_market_sentiment_history.ipynb\n",
      "Successfully executed py6_view_market_sentiment_history.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\executed\\executed_py6_view_market_sentiment_history.ipynb\n",
      "\n",
      "--- Running py7_view_daily_market_snapshot.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\executed\\executed_py7_view_daily_market_snapshot.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\py7_view_daily_market_snapshot.ipynb\n",
      "Successfully executed py7_view_daily_market_snapshot.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\executed\\executed_py7_view_daily_market_snapshot.ipynb\n",
      "\n",
      "--- Running py8_portf_picks_short_term_v6.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\executed\\executed_py8_portf_picks_short_term_v6.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\py8_portf_picks_short_term_v6.ipynb\n",
      "Successfully executed py8_portf_picks_short_term_v6.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\executed\\executed_py8_portf_picks_short_term_v6.ipynb\n",
      "\n",
      "--- Running py9_backtest_v3.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\executed\\executed_py9_backtest_v3.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\py9_backtest_v3.ipynb\n",
      "Successfully executed py9_backtest_v3.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\executed\\executed_py9_backtest_v3.ipynb\n",
      "\n",
      "--- Running py10_backtest_verification_v1.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\executed\\executed_py10_backtest_verification_v1.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\py10_backtest_verification_v1.ipynb\n",
      "Successfully executed py10_backtest_verification_v1.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\executed\\executed_py10_backtest_verification_v1.ipynb\n",
      "\n",
      "--- All notebooks executed successfully! ---\n",
      "--- Finished processing for 2025-06-26 ---\n",
      "\n",
      "========================= ALL PROCESSING COMPLETE =========================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Step 4: Starting processing sequence ---\")\n",
    "\n",
    "if not dates_to_process:\n",
    "    print(\"No dates to process. Halting execution.\")\n",
    "else:\n",
    "    for date_str in dates_to_process:\n",
    "        print(f\"\\n{'='*20} PROCESSING DATE: {date_str} {'='*20}\")\n",
    "        \n",
    "        # 1. Create the config.py file for the current date\n",
    "        utils.create_pipeline_config_file(\n",
    "            config_path=ROOT_DIR / 'config.py',\n",
    "            date_str=date_str,\n",
    "            downloads_dir=DOWNLOADS_DIR,\n",
    "            dest_dir=DEST_DIR,\n",
    "            annual_risk_free_rate=ANNUAL_RISK_FREE_RATE,\n",
    "            trading_days_per_year=TRADING_DAYS_PER_YEAR\n",
    "        )\n",
    "\n",
    "        # 2. Run the external processing script\n",
    "        print(f\"Executing run_sequence_v2.py for {date_str}...\")\n",
    "        %run -i {ROOT_DIR / 'run_sequence_v2.py'}        \n",
    "        \n",
    "        \n",
    "        print(f\"--- Finished processing for {date_str} ---\")\n",
    "\n",
    "    print(f\"\\n{'='*25} ALL PROCESSING COMPLETE {'='*25}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
