{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python will look in these locations:\n",
      "['C:\\\\Users\\\\ping\\\\.pyenv\\\\pyenv-win\\\\versions\\\\3.11.9\\\\python311.zip', 'C:\\\\Users\\\\ping\\\\.pyenv\\\\pyenv-win\\\\versions\\\\3.11.9\\\\DLLs', 'C:\\\\Users\\\\ping\\\\.pyenv\\\\pyenv-win\\\\versions\\\\3.11.9\\\\Lib', 'C:\\\\Users\\\\ping\\\\.pyenv\\\\pyenv-win\\\\versions\\\\3.11.9', 'c:\\\\Users\\\\ping\\\\Files_win10\\\\python\\\\py311\\\\.venv', '', 'c:\\\\Users\\\\ping\\\\Files_win10\\\\python\\\\py311\\\\.venv\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\ping\\\\Files_win10\\\\python\\\\py311\\\\.venv\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\ping\\\\Files_win10\\\\python\\\\py311\\\\.venv\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\ping\\\\Files_win10\\\\python\\\\py311\\\\.venv\\\\Lib\\\\site-packages\\\\Pythonwin', 'c:\\\\Users\\\\ping\\\\Files_win10\\\\python\\\\py311\\\\stocks\\\\src']\n",
      "c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\src\\utils.py\n",
      "path_data: ..\\data\\2025-04-28_df_finviz_merged_stocks_etfs.parquet\n",
      "date_str: 2025-04-28\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Notebook cell\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Get root directory (assuming notebook is in root/notebooks/)\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "ROOT_DIR = NOTEBOOK_DIR.parent if NOTEBOOK_DIR.name == 'notebooks' else NOTEBOOK_DIR\n",
    "\n",
    "# Add src directory to Python path\n",
    "sys.path.append(str(ROOT_DIR / 'src'))\n",
    "\n",
    "# Verify path\n",
    "print(f\"Python will look in these locations:\\n{sys.path}\")\n",
    "\n",
    "\n",
    "# --- Execute the processor ---\n",
    "import utils\n",
    "from config import date_str, DOWNLOAD_DIR, DEST_DIR\n",
    "\n",
    "path_data = f'..\\data\\{date_str}_df_finviz_merged_stocks_etfs.parquet'\n",
    "\n",
    "# path_corr = f'..\\data\\{date_str}_df_corr_matrix.parquet'\n",
    "# path_cov = f'..\\data\\{date_str}_df_cov_matrix.parquet'\n",
    "# path_output = f'..\\picks\\{date_str}_portf.txt'\n",
    "\n",
    "# path_corr_emv = f'..\\data\\{date_str}_df_corr_emv_matrix.parquet'\n",
    "# path_cov_emv = f'..\\data\\{date_str}_df_cov_emv_matrix.parquet'\n",
    "# path_output_emv = f'..\\picks\\{date_str}_portf_emv.txt'\n",
    "\n",
    "print(utils.__file__)  # Should point to your src/utils.py\n",
    "print(f'path_data: {path_data}')\n",
    "# print(f'path_corr: {path_corr}')\n",
    "# print(f'path_cov: {path_cov}')  \n",
    "# print(f'path_output: {path_output}')\n",
    "# print(f'path_corr_emv: {path_corr_emv}')\n",
    "# print(f'path_cov_emv: {path_cov_emv}')\n",
    "# print(f'path_output_emv: {path_output_emv}')\n",
    "print((f'date_str: {date_str}'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Set pandas display options to show more columns and rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.width', 2000)        # Let the display adjust to the window\n",
    "pd.set_option('display.max_colwidth', None) # Show full content of each cell\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# def get_column_values_above_threshold(df, column_name='Avg Volume, M', threshold=1):\n",
    "#   \"\"\"\n",
    "#   Analyzes the number and percentage of values in a DataFrame column that are above a specified threshold,\n",
    "#   and returns the filtered DataFrame.\n",
    "\n",
    "#   Args:\n",
    "#     df (pd.DataFrame): The input DataFrame.\n",
    "#     column_name (str): The name of the column to analyze. Defaults to 'Avg Volume, M'.\n",
    "#     threshold (float): The threshold value to compare against. Defaults to 1.00.\n",
    "\n",
    "#   Returns:\n",
    "#     pd.DataFrame: A DataFrame containing only the rows where the specified column's value is above the threshold.\n",
    "#   \"\"\"\n",
    "  \n",
    "#   count_before = len(df)\n",
    "#   above_threshold_df = df[df[column_name] > threshold]\n",
    "#   count_after = len(above_threshold_df)\n",
    "#   percentage = (count_after / len(df)) * 100\n",
    "\n",
    "#   print(f\"count_before: {count_before}\")\n",
    "#   print(f\"count_after above threshold ({threshold}): {count_after}\")\n",
    "#   print(f\"Percentage above threshold ({threshold}): {percentage:.2f}%\")\n",
    "\n",
    "#   return above_threshold_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "df_data.shape: (1539, 136)\n",
      "        No.                Company               Index                  Sector                        Industry Country Exchange  Market Cap, M     P/E  Fwd P/E    PEG     P/S     P/B     P/C   P/FCF  Book/sh  Cash/sh  Dividend %  Dividend TTM Dividend Ex Date  Payout Ratio %     EPS  EPS next Q  EPS this Y %  EPS next Y %  EPS past 5Y %  EPS next 5Y %  Sales past 5Y %  Sales Q/Q %  EPS Q/Q %  EPS YoY TTM %  Sales YoY TTM %    Sales, M   Income, M  EPS Surprise %  Revenue Surprise %  Outstanding, M   Float, M  Float %  Insider Own %  Insider Trans %  Inst Own %  Inst Trans %  Short Float %  Short Ratio  Short Interest, M   ROA %    ROE %   ROI %  Curr R  Quick R  LTDebt/Eq  Debt/Eq  Gross M %  Oper M %  Profit M %  Perf 3D %  Perf Week %  Perf Month %  Perf Quart %  Perf Half %  Perf Year %  Perf YTD %   Beta     ATR  ATR/Price %  Volatility W %  Volatility M %  SMA20 %  SMA50 %  SMA200 %  50D High %  50D Low %  52W High %  52W Low %        52W Range  All-Time High %  All-Time Low %     RSI  Earnings    IPO Date Optionable Shortable    Employees  Change from Open %   Gap %  Recom  Avg Volume, M  Rel Volume     Volume  Target Price  Prev Close     Open     High      Low    Price  Change % Single Category Asset Type  Expense %  Holdings  AUM, M  Flows 1M, M  Flows% 1M  Flows 3M, M  Flows% 3M  Flows YTD, M  Flows% YTD  Return% 1Y  Return% 3Y  Return% 5Y Tags  Sharpe 3d  Sortino 3d  Omega 3d  Sharpe 5d  Sortino 5d  Omega 5d  Sharpe 10d  Sortino 10d  Omega 10d  Sharpe 15d  Sortino 15d  Omega 15d  Sharpe 30d  Sortino 30d  Omega 30d  Sharpe 60d  Sortino 60d  Omega 60d  Sharpe 120d  Sortino 120d  Omega 120d  Sharpe 250d  Sortino 250d  Omega 250d\n",
      "Ticker                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
      "AAPL      1              Apple Inc  DJIA, NDX, S&P 500              Technology            Consumer Electronics     USA     NASD   3156740.0000 33.4100  26.4400 3.7700  7.9800 47.3500 58.7000 32.1100   4.4400   3.5800      0.4900        1.0000        2/10/2025         16.1100  6.2900      1.6200        7.5700        9.4800        15.4100         8.8700           9.1800       3.9500    10.1300        -2.1400           2.6100 395760.0000  96150.0000          2.2300              0.0300      15040.0000 15010.0000  99.7800         0.0900          -3.5200     63.8600        1.4500         0.7500       1.8600           113.1300 27.5700 136.5200 63.8000  0.9200   0.8800     1.2600   1.4500    46.5200   31.7600     24.3000     2.7077       8.7900       -6.1200       -8.5800      -8.9400      24.3300    -16.0800 1.2800  8.8900       4.2305          2.4300          4.9300   4.4600  -3.7500   -7.6400    -15.9400    24.1900    -19.2100    24.2600  169.11 - 260.10         -19.2100     330225.6600 52.5200  May 01/a  12/12/1980        Yes       Yes  164000.0000              0.0700  0.3400 2.0800        60.7900      0.6200   37649330      238.6400    209.2800 210.0000 211.5000 207.4600 210.1400    0.4100               -          -        NaN       NaN     NaN          NaN        NaN          NaN        NaN           NaN         NaN         NaN         NaN         NaN    -   355.1151   3633.5485  324.7022    19.7141   6902.5956  870.6453      2.9495       4.5492     1.6200      3.6558       8.6346     2.0479      0.0304       0.0469     1.0059     -0.7733      -1.1189     0.8586      -0.2126       -0.3054      0.9576       0.6461        0.9590      1.1356\n",
      "MSFT      2  Microsoft Corporation  DJIA, NDX, S&P 500              Technology       Software - Infrastructure     USA     NASD   2907880.0000 31.5100  26.3200 2.2200 11.1100  9.6100 40.6400 41.5200  40.7100   9.6300      0.8300        3.1600        5/15/2025         25.4200 12.4200      3.2200       11.4500       12.9900        18.4500        14.2100          14.4000      12.2700    10.2300        12.3800          15.0400 261800.0000  92750.0000          3.5400              1.1100       7430.0000  7320.0000  98.5200         1.4700          -0.0400     73.3000        1.1600         0.7000       2.0300            51.2500 18.4700  34.2900 23.6000  1.3500   1.3400     0.3000   0.3400    69.4100   44.9600     35.4300     4.4793       8.9200        0.1500       -9.9900      -7.8800      -4.3800     -7.2000 0.9800 12.1100       3.0959          2.4300          3.5200   3.9100   1.1100   -5.7400     -6.7100    13.4500    -16.4800    13.4500  344.79 - 468.35         -16.4800     490822.0400 55.5500  Apr 30/a   3/13/1986        Yes       Yes  228000.0000             -0.1600 -0.0100 1.3400        25.2500      0.6500   16507890      482.9800    391.8500 391.8000 392.7400 386.6400 391.1600   -0.1800               -          -        NaN       NaN     NaN          NaN        NaN          NaN        NaN           NaN         NaN         NaN         NaN         NaN    -     8.0348     56.5437    6.0373    16.7943    266.5799   34.5859      0.7129       1.0846     1.1186      3.1616       7.6845     1.8325      0.2309       0.4236     1.0448     -0.7098      -1.1685     0.8748      -0.3194       -0.4797      0.9421      -0.1204       -0.1685      0.9783\n",
      "NVDA      3            NVIDIA Corp  DJIA, NDX, S&P 500              Technology                  Semiconductors     USA     NASD   2653010.0000 36.9900  19.2800 1.2500 20.3300 33.5500 61.4000 43.6000   3.2400   1.7700      0.0400        0.0400        3/12/2025          1.1600  2.9400      0.8900       48.0600       27.3900        91.8300        29.6400          70.8800      77.9400    81.2300       146.2600         114.2000 130500.0000  72880.0000          4.9700              3.2300      24480.0000 23420.0000  95.7000         4.0000          -0.1300     66.4500        1.8000         1.1200       0.8400           262.9600 82.2000 119.1800 81.6000  4.4400   3.8800     0.1300   0.1300    74.9900   62.4200     55.8500     5.8612      12.2000       -2.4200       -8.1800     -22.0900      36.4600    -19.0300 2.1100  6.6900       6.1529          3.8300          6.4600   3.2900  -5.2200  -13.3200    -24.2000    25.5300    -28.9900    33.8100   81.25 - 153.13         -28.9900     326089.9900 50.2400  Feb 26/a   1/22/1999        Yes       Yes   36000.0000             -0.8800 -1.1800 1.4000       314.0200      0.6600  206168440      161.5900    111.0100 109.7000 110.3700 106.0200 108.7300   -2.0500               -          -        NaN       NaN     NaN          NaN        NaN          NaN        NaN           NaN         NaN         NaN         NaN         NaN    -     3.9158     12.0273    2.0715    12.7723     37.0860    5.6724     -0.5528      -0.7518     0.9221      2.3383       5.0874     1.5442     -0.6912      -1.1184     0.8819     -0.3119      -0.4594     0.9479      -0.4721       -0.6493      0.9206       0.5947        0.8586      1.1063\n",
      "AMZN      4         Amazon.com Inc  DJIA, NDX, S&P 500       Consumer Cyclical                 Internet Retail     USA     NASD   1991940.0000 33.9900  25.2400 1.8200  3.1200  6.9500 19.0200 60.5900  27.0000   9.8700         NaN           NaN                -          0.0000  5.5200      1.3700       12.3200       19.7500        36.8900        18.7200          18.3100      10.4900    85.4800        91.6100          10.9900 637960.0000  59250.0000         25.1400              0.2400      10590.0000  9490.0000  89.5900        10.5800          -1.4600     64.4700        2.7700         0.7500       1.4400            71.1900 10.2800  24.2900 14.2100  1.0600   0.8700     0.4600   0.5200    48.8500   10.8700      9.2900     3.9313      12.1800       -6.7800      -20.2700       1.6200       6.2900    -14.4400 1.3000  8.8500       4.7150          3.4100          5.2200   3.5900  -4.0800   -5.7500    -18.5400    16.3100    -22.6000    23.8000  151.61 - 242.52         -22.6000     285919.0600 51.1600  May 01/a   5/15/1997        Yes       Yes 1556000.0000             -1.2100  0.5300 1.2900        49.5100      0.6700   33072995      248.0800    188.9900 190.0000 190.2200 184.8800 187.7000   -0.6800               -          -        NaN       NaN     NaN          NaN        NaN          NaN        NaN           NaN         NaN         NaN         NaN         NaN    -     3.3691      9.6278    1.8577    14.6765     92.5144   12.6557      2.0035       3.6346     1.3498      2.0510       4.3678     1.4238     -0.3864      -0.5809     0.9353     -2.0088      -2.7614     0.7063      -0.2085       -0.2980      0.9650       0.1592        0.2247      1.0282\n",
      "GOOGL     5           Alphabet Inc        NDX, S&P 500  Communication Services  Internet Content & Information     USA     NASD   1967500.0000 17.9100  15.7800 1.3300  5.4800  5.6500 20.6400 26.2700  28.4100   7.7800      0.3100        0.8000         6/9/2025          7.4600  8.9700      2.1600       17.9700        7.3200        26.7600        13.4600          17.3000      11.8100    48.7700        37.7300          13.0200 359310.0000 111000.0000         38.8100              1.1500       5830.0000  5820.0000  99.8400        52.2800          -0.0100     38.3800        1.0800         1.1800       1.9200            68.6700 25.1500  34.7900 30.0200  1.7700   1.7700     0.0700   0.0800    58.5400   32.6000     30.8900     3.3859       8.7600       -1.0000      -16.2700      -1.3300       0.9300    -15.1600 1.0000  5.8300       3.6299          2.4800          3.8500   4.2400  -1.8800   -6.7000    -13.8400    14.2900    -22.4300    14.2900  140.53 - 207.05         -22.4300       6588.3900 52.7700  Apr 24/a   8/19/2004        Yes       Yes  183323.0000             -1.1600  0.3300 1.4500        35.7700      0.8300   29613315      202.2700    161.9600 162.5000 163.1500 158.6000 160.6100   -0.8300               -          -        NaN       NaN     NaN          NaN        NaN          NaN        NaN           NaN         NaN         NaN         NaN         NaN    -     3.6461     10.8004    1.9622    14.5910     54.9159    7.9188      0.8251       1.3764     1.1214      3.1978       7.3018     1.7121     -0.2861      -0.4493     0.9544     -2.4017      -3.1564     0.6709      -0.2875       -0.4121      0.9533      -0.0816       -0.1123      0.9862\n",
      "\n",
      "\n",
      "            No.  Market Cap, M        P/E   Fwd P/E      PEG       P/S       P/B        P/C     P/FCF     Book/sh     Cash/sh  Dividend %  Dividend TTM  Payout Ratio %        EPS  EPS next Q  EPS this Y %  EPS next Y %  EPS past 5Y %  EPS next 5Y %  Sales past 5Y %  Sales Q/Q %   EPS Q/Q %  EPS YoY TTM %  Sales YoY TTM %    Sales, M   Income, M  EPS Surprise %  Revenue Surprise %  Outstanding, M   Float, M   Float %  Insider Own %  Insider Trans %  Inst Own %  Inst Trans %  Short Float %  Short Ratio  Short Interest, M     ROA %      ROE %     ROI %    Curr R  Quick R  LTDebt/Eq   Debt/Eq  Gross M %   Oper M %  Profit M %  Perf 3D %  Perf Week %  Perf Month %  Perf Quart %  Perf Half %  Perf Year %  Perf YTD %      Beta        ATR  ATR/Price %  Volatility W %  Volatility M %   SMA20 %   SMA50 %  SMA200 %  50D High %  50D Low %  52W High %  52W Low %  All-Time High %  All-Time Low %       RSI    Employees  Change from Open %     Gap %     Recom  Avg Volume, M  Rel Volume         Volume  Target Price  Prev Close        Open        High         Low       Price  Change %  Expense %   Holdings      AUM, M  Flows 1M, M  Flows% 1M  Flows 3M, M  Flows% 3M  Flows YTD, M  Flows% YTD  Return% 1Y  Return% 3Y  Return% 5Y   Sharpe 3d  Sortino 3d  Omega 3d  Sharpe 5d  Sortino 5d  Omega 5d  Sharpe 10d  Sortino 10d  Omega 10d  Sharpe 15d  Sortino 15d  Omega 15d  Sharpe 30d  Sortino 30d  Omega 30d  Sharpe 60d  Sortino 60d  Omega 60d  Sharpe 120d  Sortino 120d  Omega 120d  Sharpe 250d  Sortino 250d  Omega 250d\n",
      "count 1539.0000      1142.0000  1018.0000 1102.0000 921.0000 1132.0000 1087.0000  1015.0000  979.0000   1138.0000   1017.0000   1209.0000     1186.0000       1006.0000  1135.0000   1115.0000     1128.0000     1127.0000       963.0000      1066.0000        1132.0000    1125.0000   1129.0000      1131.0000        1129.0000   1137.0000   1134.0000       1128.0000           1121.0000       1142.0000  1135.0000 1135.0000      1132.0000        1076.0000   1139.0000     1122.0000      1135.0000    1539.0000          1539.0000 1131.0000  1087.0000 1132.0000 1012.0000 900.0000  1084.0000 1084.0000  1004.0000  1129.0000   1129.0000  1539.0000    1539.0000     1539.0000     1539.0000    1539.0000    1537.0000   1539.0000 1538.0000  1539.0000    1539.0000       1539.0000       1539.0000 1539.0000 1539.0000 1539.0000   1539.0000  1539.0000   1539.0000  1539.0000        1538.0000       1537.0000 1539.0000    1092.0000           1539.0000 1539.0000 1131.0000      1539.0000   1539.0000      1539.0000     1134.0000   1539.0000   1539.0000   1539.0000   1539.0000   1539.0000 1539.0000   397.0000   396.0000    397.0000     388.0000   397.0000     394.0000   397.0000      394.0000    397.0000    397.0000    372.0000    340.0000   1539.0000   1539.0000 1539.0000  1539.0000   1539.0000 1539.0000   1539.0000    1539.0000  1539.0000   1539.0000    1539.0000  1539.0000   1539.0000    1539.0000  1539.0000   1539.0000    1539.0000  1539.0000    1539.0000     1539.0000   1539.0000    1539.0000     1539.0000   1539.0000\n",
      "mean   479.2534     60429.6410    63.2796   20.8425   4.7401    8.0262    7.7486    92.1813   37.3053    432.7292    237.9938      2.9523        2.1452         68.7427    60.6074      7.9926      113.4357       22.9723        10.5166        14.1347          22.3468      10.3231     91.6864       147.9313          11.2814  24309.9331   2612.7165          8.3692              2.9412        707.6636   651.5881   92.9160         9.3620          -3.5895     72.0414        2.9686         3.6457       2.5716            10.9926    5.6404    31.4218   10.4141    2.3093   1.8511     1.3300    1.5941    42.1199     5.2886     -6.7657     2.2999       6.0463       -2.2514       -5.2990      -1.5468      12.5838     -1.4770    0.9854    18.5574       3.5829          2.8503          4.0288    3.2974   -0.8872   -2.1475    -11.9802    16.8713    -18.1372    31.5727         -29.2402      10864.6022   53.5197   42400.2656              0.2364    0.1537    2.0005         5.3477      0.8477   4351741.7258      866.7066    650.1619    653.6790    657.7712    645.2044    651.7900    0.3888     0.2553  1162.5051  23255.5164     113.9623     0.2810     554.0710     4.3547      702.0608      5.9648      8.4004      5.1972     10.7824    106.4054   1327.2235  119.2700    11.3660   1993.0031  251.9173      3.7341      19.1182     3.6970      3.5261       9.0712     2.2001     -0.2056      -0.1201     0.9917     -0.3388      -0.3553     0.9659       0.0375        0.1311      1.0192       0.3685        0.6021      1.0803\n",
      "std    337.2517    204776.8027   442.9199   19.4728  17.5575   70.4440   25.3745   578.7207   94.6280  13383.4093   7282.4355      4.2552        2.2760        504.2616  1837.6763    211.9247     1903.0640       98.5964        30.3855        18.1961          94.2807      67.2377   1440.7495      2531.9977          77.9207  54590.2247   8735.5136        201.6576             28.6865       1621.4405  1516.5784   14.1670        17.6224          18.7488     28.9828       25.1279         3.7424       2.3121            21.8103   10.6074   340.4926   40.9074    7.5282   4.6115     4.2152    4.9984    49.4256   229.3889    388.7085     3.5307       5.8067        7.0634       13.5805      19.3305      49.3897     15.5404    0.5473   535.3265       1.6687          1.4856          1.9189    4.3299    6.1482   13.0955      9.4926    10.4141     13.7467    53.3478          22.4643      44915.7261    6.8625  104967.5696              0.9812    0.6966    0.5298        14.3070      0.9035  13401603.8635    23370.0176  20283.0736  20411.5347  20517.9997  20139.3154  20333.7886    1.0627     0.2350  2233.7031  59182.7422    1307.7773     5.8266    2481.9097    17.7139     3428.2309     22.1632     11.3872      5.6926      8.4272   2205.4553   1735.7627  154.6097    13.9263   3046.5514  383.9229      4.5038     135.5256    18.4436      2.3306       8.8349     1.3174      1.4078       2.1266     0.2719      1.3785       1.9952     0.2591       0.9401        1.3815      0.1792       0.7746        1.2033      0.1574\n",
      "min      1.0000      5550.0000     2.8700    1.6300   0.1200    0.0600    0.3200     0.4900    0.3900   -266.1800      0.0000      0.0200        0.0000          0.0000   -65.0400     -3.7500     -687.4800     -114.7100      -415.2800       -28.8200         -39.7700    -125.4100 -29750.0000     -3144.6300        -100.0000      0.0000 -19196.0000      -3215.1000           -100.0000          0.5500     0.5400    2.1700         0.0000         -95.1300      0.2100      -42.6800         0.0100       0.0100             0.0000 -100.5700 -4584.4700 -152.6500    0.0500   0.0900     0.0000    0.0000 -1333.6800 -5494.8600 -11077.2900   -30.5640     -27.4100      -36.9400      -59.1800     -63.6400     -84.4100    -61.7100   -0.9500     0.0200       0.0272          0.0100          0.0100  -27.9600  -35.3800  -58.6800    -62.3500    -0.6900    -95.3700    -0.0300         -99.9900          0.5500   28.2500      19.0000             -5.6600   -6.2900    1.0000         0.0015      0.1700       518.0000        2.8900      2.3800      2.3900      2.4300      2.3700      2.3900   -8.8300     0.0200     1.0000   3050.0000  -11430.0000   -27.8400   -5540.0000   -38.5300   -16650.0000    -37.2900    -63.5500    -34.0600    -37.5100 -46669.8866    -15.8745    0.0000   -58.9577    -15.4598    0.0000    -14.3083     -10.9984     0.0357     -6.4071      -6.4655     0.3260     -5.6052      -6.0488     0.2934     -4.4114      -5.2046     0.4592      -2.9989       -3.6136      0.5857      -2.1592       -2.6484      0.6887\n",
      "25%    193.0000      9302.5000    14.1000   10.7975   1.4400    1.3475    1.7600     8.9250   12.4150     10.0150      1.6500      1.2300        0.8425          3.6925     1.2000      0.4300       -0.0800        8.1600         0.3750         6.4550           4.9050      -0.8700    -20.0300       -12.7200           0.1600   3240.0000    322.3200         -0.3575             -0.7000        109.6600   100.1750   94.0500         0.3200          -4.1875     60.8550       -0.8975         1.5500       1.3600             1.3850    1.7800     7.8200    3.7875    0.9200   0.7500     0.2700    0.3300    26.1100     9.3600      4.9300     0.7045       2.6650       -5.9450      -13.7500     -11.5250      -5.4600    -10.1950    0.6700     1.0850       2.6611          1.9900          3.0050    0.8100   -4.0850   -9.3700    -16.7150    10.6600    -26.2700    13.4400         -41.9075        203.5400   49.5500    5100.0000             -0.1800   -0.0700    1.6100         0.8559      0.5900    638600.0000       46.5075     39.0400     39.1350     39.5100     38.7700     39.2300   -0.0500     0.0700   101.0000   4940.0000    -122.7425    -1.3500    -233.0150    -2.0400     -199.7975     -2.3000      4.6300      2.0375      3.5575     -3.0607     -4.8098    0.5715     4.1785      9.6221    2.0260      1.2221       1.8442     1.2259      2.3163       4.2086     1.5196     -1.0156      -1.3973     0.8245     -1.2645      -1.7130     0.7895      -0.5702       -0.7799      0.9000      -0.1089       -0.1549      0.9803\n",
      "50%    387.0000     17435.0000    22.3750   16.3200   2.4200    2.7500    3.1400    19.2200   21.2800     22.2900      4.2500      2.3500        1.6300         29.0500     3.3500      0.9500        7.5400       12.0700         8.2700        10.2000           9.4200       4.8900      9.3900        11.5100           5.8400   7990.0000    764.9950          4.6400              0.9700        240.9050   218.1400   98.6600         1.1800          -0.6950     81.4700        0.6350         2.6500       2.2200             4.4900    5.0000    13.7000    7.9700    1.3700   1.1000     0.6250    0.7200    39.6150    16.7600     10.7800     2.0529       5.6100       -2.3900       -5.7600      -3.6600       5.9600     -2.2000    0.9700     2.5200       3.3758          2.6600          3.7900    2.8800   -1.0300   -2.8700    -10.4000    15.0600    -15.0800    19.6200         -22.7700        909.5000   53.2200   14332.0000              0.2000    0.1200    1.9200         1.9800      0.7300   1503302.0000       99.1900     74.5400     74.6100     75.0300     73.8300     74.8000    0.3300     0.1800   358.5000   8560.0000      46.4050     0.4500     202.0750     1.9900      243.2050      2.2900      7.2700      4.5550     12.7350      5.3636     20.5433    2.8301    11.4145     68.2666    8.9215      3.5677       6.2207     1.7815      3.3946       7.2925     1.9002     -0.3177      -0.4633     0.9403     -0.5419      -0.7338     0.9059      -0.0733       -0.0953      0.9867       0.3713        0.5278      1.0713\n",
      "75%    763.5000     46107.5000    33.9775   23.9000   3.7100    5.4800    6.4000    45.9500   32.7300     44.5925      9.7400      3.8800        2.7800         56.1225     7.0350      2.0000       17.0150       19.5150        17.8450        15.9350          17.6600      14.4000     52.9500        47.0100          13.6700  20500.0000   2220.0000         14.0600              2.9900        598.1650   556.7950   99.6300         9.3125           0.0000     93.3300        2.6300         4.3950       3.2900            11.4500    9.6400    25.1250   14.3875    2.2125   1.7000     1.2275    1.4700    59.4025    25.0000     17.4600     3.6758       8.7000        1.2650        2.0850       5.9100      20.6500      6.2750    1.2075     5.4200       4.4469          3.6100          4.9500    5.3000    2.1650    4.2550     -4.5800    20.8150     -8.1550    33.7700         -12.0200       4398.8800   57.5800   41400.0000              0.6800    0.3500    2.3300         4.6300      0.9200   3510597.0000      191.1475    140.3500    140.6450    142.2400    138.7350    140.6150    0.8200     0.3800  1194.7500  19080.0000     240.4325     1.9500     770.9875     6.9400      991.3225      9.2100     10.4800      8.1250     16.2825     17.6160   3633.5485  324.7022    17.4680   6902.5956  870.6453      6.2063      13.4151     2.8285      4.7218      11.1205     2.4369      0.5135       0.7537     1.0948      0.5827       0.8652     1.1087       0.6355        0.9488      1.1255       0.8056        1.1775      1.1570\n",
      "max   1160.0000   3156740.0000 11176.1200  335.5500 343.6600 1736.4100  491.1500 15257.3700 1401.7200 451507.0400 232247.4400    128.2500       35.8500      15000.0000 61913.6400   7076.9000    61103.0500     3079.2000       315.1000       186.5100        2514.6200    2110.3000  24561.9500     75461.5400        2285.2700 680990.0000 111000.0000       3400.0000            570.7600      24480.0000 23420.0000  100.0000        97.8600         441.7800    128.3900      660.0100        40.6900      33.9100           350.7000   82.2000  7616.6700 1288.1100  196.3500 112.8500    94.0000   99.6300   100.0000   123.2800    112.2400    28.5366      55.4600       41.1300       51.9800     169.1900    1033.1800     90.3800    5.2100 21001.7700      15.2970         21.3500         18.5000   25.7700   30.6700   83.0700      7.8300    81.5600      3.6800  1048.1000           3.6800     688044.8900   85.8300 2100000.0000              6.4400    9.7900    4.5000       314.0200     21.4000 267386839.0000   787061.4700 795760.0000 800799.7500 804977.1200 790120.0000 797750.0000   12.1200     1.5000 17725.0000 599550.0000   14370.0000    59.4400   34430.0000   199.8000    53290.0000    298.3800     99.9200     40.1800     50.0000  34103.4538   3633.5485  324.7022   157.5126   6902.5956  870.6453     31.0363    2599.7589   348.4074     12.0430      85.4246    14.6858      5.2937       9.4761     2.3586      4.6322       9.9421     2.3977       3.6440        6.5663      1.9546       3.5084        6.9645      1.8146\n"
     ]
    }
   ],
   "source": [
    "df_data = pd.read_parquet(path_data)\n",
    "\n",
    "# # liquidity filter, Avg Volume, M > 0.75M\n",
    "# df_data = get_column_values_above_threshold(df_data, column_name='Avg Volume, M', threshold=0.75)\n",
    "\n",
    "# Drop specified columns with NaNs in df_data\n",
    "# df_data = df_data.drop(['All-Time High %', 'All-Time Low %', 'Dividend %'], axis=1)\n",
    "\n",
    "# df_corr = pd.read_parquet(path_corr)\n",
    "# df_cov = pd.read_parquet(path_cov)\n",
    "# df_corr_emv = pd.read_parquet(path_corr_emv)\n",
    "# df_cov_emv = pd.read_parquet(path_cov_emv)\n",
    "\n",
    "# print(f'\\ndf_cov.shape: {df_cov.shape}')\n",
    "# print(df_cov.head())\n",
    "\n",
    "# print(f'\\ndf_corr.shape: {df_corr.shape}')\n",
    "# print(df_corr.head())\n",
    "\n",
    "# print(f'\\ndf_cov_emv.shape: {df_cov_emv.shape}')\n",
    "# print(df_cov_emv.head())\n",
    "\n",
    "# print(f'\\ndf_corr_emv.shape: {df_corr_emv.shape}')\n",
    "# print(df_corr_emv.head())\n",
    "\n",
    "print(f'\\ndf_data.shape: {df_data.shape}')\n",
    "print(df_data.head())\n",
    "print('\\n')\n",
    "print((df_data.describe()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check df_corr\n",
    "# has_nan_corr = df_corr.isnull().any().any()\n",
    "# print(f\"Are there any NaNs in df_corr? {has_nan_corr}\")\n",
    "\n",
    "# # Check df_cov\n",
    "# has_nan_cov = df_cov.isnull().any().any()\n",
    "# print(f\"Are there any NaNs in df_cov? {has_nan_cov}\")\n",
    "\n",
    "# # Check df_corr\n",
    "# has_nan_corr_emv = df_corr_emv.isnull().any().any()\n",
    "# print(f\"Are there any NaNs in df_corr_emv? {has_nan_corr_emv}\")\n",
    "\n",
    "# # Check df_cov\n",
    "# has_nan_cov_emv = df_cov_emv.isnull().any().any()\n",
    "# print(f\"Are there any NaNs in df_cov_emv? {has_nan_cov_emv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_data.columns:\n",
      "Index(['No.', 'Company', 'Index', 'Sector', 'Industry', 'Country', 'Exchange', 'Market Cap, M', 'P/E', 'Fwd P/E',\n",
      "       ...\n",
      "       'Omega 30d', 'Sharpe 60d', 'Sortino 60d', 'Omega 60d', 'Sharpe 120d', 'Sortino 120d', 'Omega 120d', 'Sharpe 250d', 'Sortino 250d', 'Omega 250d'], dtype='object', length=136)\n",
      "\n",
      "df_data.describe():\n",
      "            No.  Market Cap, M        P/E   Fwd P/E      PEG       P/S       P/B        P/C     P/FCF     Book/sh     Cash/sh  Dividend %  Dividend TTM  Payout Ratio %        EPS  EPS next Q  EPS this Y %  EPS next Y %  EPS past 5Y %  EPS next 5Y %  Sales past 5Y %  Sales Q/Q %   EPS Q/Q %  EPS YoY TTM %  Sales YoY TTM %    Sales, M   Income, M  EPS Surprise %  Revenue Surprise %  Outstanding, M   Float, M   Float %  Insider Own %  Insider Trans %  Inst Own %  Inst Trans %  Short Float %  Short Ratio  Short Interest, M     ROA %      ROE %     ROI %    Curr R  Quick R  LTDebt/Eq   Debt/Eq  Gross M %   Oper M %  Profit M %  Perf 3D %  Perf Week %  Perf Month %  Perf Quart %  Perf Half %  Perf Year %  Perf YTD %      Beta        ATR  ATR/Price %  Volatility W %  Volatility M %   SMA20 %   SMA50 %  SMA200 %  50D High %  50D Low %  52W High %  52W Low %  All-Time High %  All-Time Low %       RSI    Employees  Change from Open %     Gap %     Recom  Avg Volume, M  Rel Volume         Volume  Target Price  Prev Close        Open        High         Low       Price  Change %  Expense %   Holdings      AUM, M  Flows 1M, M  Flows% 1M  Flows 3M, M  Flows% 3M  Flows YTD, M  Flows% YTD  Return% 1Y  Return% 3Y  Return% 5Y   Sharpe 3d  Sortino 3d  Omega 3d  Sharpe 5d  Sortino 5d  Omega 5d  Sharpe 10d  Sortino 10d  Omega 10d  Sharpe 15d  Sortino 15d  Omega 15d  Sharpe 30d  Sortino 30d  Omega 30d  Sharpe 60d  Sortino 60d  Omega 60d  Sharpe 120d  Sortino 120d  Omega 120d  Sharpe 250d  Sortino 250d  Omega 250d\n",
      "count 1539.0000      1142.0000  1018.0000 1102.0000 921.0000 1132.0000 1087.0000  1015.0000  979.0000   1138.0000   1017.0000   1209.0000     1186.0000       1006.0000  1135.0000   1115.0000     1128.0000     1127.0000       963.0000      1066.0000        1132.0000    1125.0000   1129.0000      1131.0000        1129.0000   1137.0000   1134.0000       1128.0000           1121.0000       1142.0000  1135.0000 1135.0000      1132.0000        1076.0000   1139.0000     1122.0000      1135.0000    1539.0000          1539.0000 1131.0000  1087.0000 1132.0000 1012.0000 900.0000  1084.0000 1084.0000  1004.0000  1129.0000   1129.0000  1539.0000    1539.0000     1539.0000     1539.0000    1539.0000    1537.0000   1539.0000 1538.0000  1539.0000    1539.0000       1539.0000       1539.0000 1539.0000 1539.0000 1539.0000   1539.0000  1539.0000   1539.0000  1539.0000        1538.0000       1537.0000 1539.0000    1092.0000           1539.0000 1539.0000 1131.0000      1539.0000   1539.0000      1539.0000     1134.0000   1539.0000   1539.0000   1539.0000   1539.0000   1539.0000 1539.0000   397.0000   396.0000    397.0000     388.0000   397.0000     394.0000   397.0000      394.0000    397.0000    397.0000    372.0000    340.0000   1539.0000   1539.0000 1539.0000  1539.0000   1539.0000 1539.0000   1539.0000    1539.0000  1539.0000   1539.0000    1539.0000  1539.0000   1539.0000    1539.0000  1539.0000   1539.0000    1539.0000  1539.0000    1539.0000     1539.0000   1539.0000    1539.0000     1539.0000   1539.0000\n",
      "mean   479.2534     60429.6410    63.2796   20.8425   4.7401    8.0262    7.7486    92.1813   37.3053    432.7292    237.9938      2.9523        2.1452         68.7427    60.6074      7.9926      113.4357       22.9723        10.5166        14.1347          22.3468      10.3231     91.6864       147.9313          11.2814  24309.9331   2612.7165          8.3692              2.9412        707.6636   651.5881   92.9160         9.3620          -3.5895     72.0414        2.9686         3.6457       2.5716            10.9926    5.6404    31.4218   10.4141    2.3093   1.8511     1.3300    1.5941    42.1199     5.2886     -6.7657     2.2999       6.0463       -2.2514       -5.2990      -1.5468      12.5838     -1.4770    0.9854    18.5574       3.5829          2.8503          4.0288    3.2974   -0.8872   -2.1475    -11.9802    16.8713    -18.1372    31.5727         -29.2402      10864.6022   53.5197   42400.2656              0.2364    0.1537    2.0005         5.3477      0.8477   4351741.7258      866.7066    650.1619    653.6790    657.7712    645.2044    651.7900    0.3888     0.2553  1162.5051  23255.5164     113.9623     0.2810     554.0710     4.3547      702.0608      5.9648      8.4004      5.1972     10.7824    106.4054   1327.2235  119.2700    11.3660   1993.0031  251.9173      3.7341      19.1182     3.6970      3.5261       9.0712     2.2001     -0.2056      -0.1201     0.9917     -0.3388      -0.3553     0.9659       0.0375        0.1311      1.0192       0.3685        0.6021      1.0803\n",
      "std    337.2517    204776.8027   442.9199   19.4728  17.5575   70.4440   25.3745   578.7207   94.6280  13383.4093   7282.4355      4.2552        2.2760        504.2616  1837.6763    211.9247     1903.0640       98.5964        30.3855        18.1961          94.2807      67.2377   1440.7495      2531.9977          77.9207  54590.2247   8735.5136        201.6576             28.6865       1621.4405  1516.5784   14.1670        17.6224          18.7488     28.9828       25.1279         3.7424       2.3121            21.8103   10.6074   340.4926   40.9074    7.5282   4.6115     4.2152    4.9984    49.4256   229.3889    388.7085     3.5307       5.8067        7.0634       13.5805      19.3305      49.3897     15.5404    0.5473   535.3265       1.6687          1.4856          1.9189    4.3299    6.1482   13.0955      9.4926    10.4141     13.7467    53.3478          22.4643      44915.7261    6.8625  104967.5696              0.9812    0.6966    0.5298        14.3070      0.9035  13401603.8635    23370.0176  20283.0736  20411.5347  20517.9997  20139.3154  20333.7886    1.0627     0.2350  2233.7031  59182.7422    1307.7773     5.8266    2481.9097    17.7139     3428.2309     22.1632     11.3872      5.6926      8.4272   2205.4553   1735.7627  154.6097    13.9263   3046.5514  383.9229      4.5038     135.5256    18.4436      2.3306       8.8349     1.3174      1.4078       2.1266     0.2719      1.3785       1.9952     0.2591       0.9401        1.3815      0.1792       0.7746        1.2033      0.1574\n",
      "min      1.0000      5550.0000     2.8700    1.6300   0.1200    0.0600    0.3200     0.4900    0.3900   -266.1800      0.0000      0.0200        0.0000          0.0000   -65.0400     -3.7500     -687.4800     -114.7100      -415.2800       -28.8200         -39.7700    -125.4100 -29750.0000     -3144.6300        -100.0000      0.0000 -19196.0000      -3215.1000           -100.0000          0.5500     0.5400    2.1700         0.0000         -95.1300      0.2100      -42.6800         0.0100       0.0100             0.0000 -100.5700 -4584.4700 -152.6500    0.0500   0.0900     0.0000    0.0000 -1333.6800 -5494.8600 -11077.2900   -30.5640     -27.4100      -36.9400      -59.1800     -63.6400     -84.4100    -61.7100   -0.9500     0.0200       0.0272          0.0100          0.0100  -27.9600  -35.3800  -58.6800    -62.3500    -0.6900    -95.3700    -0.0300         -99.9900          0.5500   28.2500      19.0000             -5.6600   -6.2900    1.0000         0.0015      0.1700       518.0000        2.8900      2.3800      2.3900      2.4300      2.3700      2.3900   -8.8300     0.0200     1.0000   3050.0000  -11430.0000   -27.8400   -5540.0000   -38.5300   -16650.0000    -37.2900    -63.5500    -34.0600    -37.5100 -46669.8866    -15.8745    0.0000   -58.9577    -15.4598    0.0000    -14.3083     -10.9984     0.0357     -6.4071      -6.4655     0.3260     -5.6052      -6.0488     0.2934     -4.4114      -5.2046     0.4592      -2.9989       -3.6136      0.5857      -2.1592       -2.6484      0.6887\n",
      "25%    193.0000      9302.5000    14.1000   10.7975   1.4400    1.3475    1.7600     8.9250   12.4150     10.0150      1.6500      1.2300        0.8425          3.6925     1.2000      0.4300       -0.0800        8.1600         0.3750         6.4550           4.9050      -0.8700    -20.0300       -12.7200           0.1600   3240.0000    322.3200         -0.3575             -0.7000        109.6600   100.1750   94.0500         0.3200          -4.1875     60.8550       -0.8975         1.5500       1.3600             1.3850    1.7800     7.8200    3.7875    0.9200   0.7500     0.2700    0.3300    26.1100     9.3600      4.9300     0.7045       2.6650       -5.9450      -13.7500     -11.5250      -5.4600    -10.1950    0.6700     1.0850       2.6611          1.9900          3.0050    0.8100   -4.0850   -9.3700    -16.7150    10.6600    -26.2700    13.4400         -41.9075        203.5400   49.5500    5100.0000             -0.1800   -0.0700    1.6100         0.8559      0.5900    638600.0000       46.5075     39.0400     39.1350     39.5100     38.7700     39.2300   -0.0500     0.0700   101.0000   4940.0000    -122.7425    -1.3500    -233.0150    -2.0400     -199.7975     -2.3000      4.6300      2.0375      3.5575     -3.0607     -4.8098    0.5715     4.1785      9.6221    2.0260      1.2221       1.8442     1.2259      2.3163       4.2086     1.5196     -1.0156      -1.3973     0.8245     -1.2645      -1.7130     0.7895      -0.5702       -0.7799      0.9000      -0.1089       -0.1549      0.9803\n",
      "50%    387.0000     17435.0000    22.3750   16.3200   2.4200    2.7500    3.1400    19.2200   21.2800     22.2900      4.2500      2.3500        1.6300         29.0500     3.3500      0.9500        7.5400       12.0700         8.2700        10.2000           9.4200       4.8900      9.3900        11.5100           5.8400   7990.0000    764.9950          4.6400              0.9700        240.9050   218.1400   98.6600         1.1800          -0.6950     81.4700        0.6350         2.6500       2.2200             4.4900    5.0000    13.7000    7.9700    1.3700   1.1000     0.6250    0.7200    39.6150    16.7600     10.7800     2.0529       5.6100       -2.3900       -5.7600      -3.6600       5.9600     -2.2000    0.9700     2.5200       3.3758          2.6600          3.7900    2.8800   -1.0300   -2.8700    -10.4000    15.0600    -15.0800    19.6200         -22.7700        909.5000   53.2200   14332.0000              0.2000    0.1200    1.9200         1.9800      0.7300   1503302.0000       99.1900     74.5400     74.6100     75.0300     73.8300     74.8000    0.3300     0.1800   358.5000   8560.0000      46.4050     0.4500     202.0750     1.9900      243.2050      2.2900      7.2700      4.5550     12.7350      5.3636     20.5433    2.8301    11.4145     68.2666    8.9215      3.5677       6.2207     1.7815      3.3946       7.2925     1.9002     -0.3177      -0.4633     0.9403     -0.5419      -0.7338     0.9059      -0.0733       -0.0953      0.9867       0.3713        0.5278      1.0713\n",
      "75%    763.5000     46107.5000    33.9775   23.9000   3.7100    5.4800    6.4000    45.9500   32.7300     44.5925      9.7400      3.8800        2.7800         56.1225     7.0350      2.0000       17.0150       19.5150        17.8450        15.9350          17.6600      14.4000     52.9500        47.0100          13.6700  20500.0000   2220.0000         14.0600              2.9900        598.1650   556.7950   99.6300         9.3125           0.0000     93.3300        2.6300         4.3950       3.2900            11.4500    9.6400    25.1250   14.3875    2.2125   1.7000     1.2275    1.4700    59.4025    25.0000     17.4600     3.6758       8.7000        1.2650        2.0850       5.9100      20.6500      6.2750    1.2075     5.4200       4.4469          3.6100          4.9500    5.3000    2.1650    4.2550     -4.5800    20.8150     -8.1550    33.7700         -12.0200       4398.8800   57.5800   41400.0000              0.6800    0.3500    2.3300         4.6300      0.9200   3510597.0000      191.1475    140.3500    140.6450    142.2400    138.7350    140.6150    0.8200     0.3800  1194.7500  19080.0000     240.4325     1.9500     770.9875     6.9400      991.3225      9.2100     10.4800      8.1250     16.2825     17.6160   3633.5485  324.7022    17.4680   6902.5956  870.6453      6.2063      13.4151     2.8285      4.7218      11.1205     2.4369      0.5135       0.7537     1.0948      0.5827       0.8652     1.1087       0.6355        0.9488      1.1255       0.8056        1.1775      1.1570\n",
      "max   1160.0000   3156740.0000 11176.1200  335.5500 343.6600 1736.4100  491.1500 15257.3700 1401.7200 451507.0400 232247.4400    128.2500       35.8500      15000.0000 61913.6400   7076.9000    61103.0500     3079.2000       315.1000       186.5100        2514.6200    2110.3000  24561.9500     75461.5400        2285.2700 680990.0000 111000.0000       3400.0000            570.7600      24480.0000 23420.0000  100.0000        97.8600         441.7800    128.3900      660.0100        40.6900      33.9100           350.7000   82.2000  7616.6700 1288.1100  196.3500 112.8500    94.0000   99.6300   100.0000   123.2800    112.2400    28.5366      55.4600       41.1300       51.9800     169.1900    1033.1800     90.3800    5.2100 21001.7700      15.2970         21.3500         18.5000   25.7700   30.6700   83.0700      7.8300    81.5600      3.6800  1048.1000           3.6800     688044.8900   85.8300 2100000.0000              6.4400    9.7900    4.5000       314.0200     21.4000 267386839.0000   787061.4700 795760.0000 800799.7500 804977.1200 790120.0000 797750.0000   12.1200     1.5000 17725.0000 599550.0000   14370.0000    59.4400   34430.0000   199.8000    53290.0000    298.3800     99.9200     40.1800     50.0000  34103.4538   3633.5485  324.7022   157.5126   6902.5956  870.6453     31.0363    2599.7589   348.4074     12.0430      85.4246    14.6858      5.2937       9.4761     2.3586      4.6322       9.9421     2.3977       3.6440        6.5663      1.9546       3.5084        6.9645      1.8146\n",
      "\n",
      "df_data.info():\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1539 entries, AAPL to FELG\n",
      "Columns: 136 entries, No. to Omega 250d\n",
      "dtypes: float64(119), int64(2), object(15)\n",
      "memory usage: 1.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(f'df_data.columns:\\n{df_data.columns}')\n",
    "print(f'\\ndf_data.describe():\\n{df_data.describe()}')\n",
    "# print(f'\\ndf_data.head():\\n{df_data.head()}')\n",
    "print(f'\\ndf_data.info():')\n",
    "print(f'{df_data.info()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import logging\n",
    "# import os # Added for path manipulation\n",
    "\n",
    "# # --- Configuration ---\n",
    "# # Define weights for scoring components (adjust based on testing)\n",
    "# # Focus on mean reversion and volume confirmation\n",
    "# SCORING_WEIGHTS = {\n",
    "#     'rsi': 0.40,        # Weight for RSI (lower is better -> Z * -1)\n",
    "#     'change': 0.30,     # Weight for previous day change (more negative is better -> Z * -1)\n",
    "#     'rel_volume': 0.20, # Weight for relative volume (higher is better -> Z * 1)\n",
    "#     'volatility': 0.10  # Weight for ATR/Price % (lower is better -> Z * -1)\n",
    "# }\n",
    "\n",
    "# # Define Filters (adjust thresholds based on testing/preference)\n",
    "# FILTERS = {\n",
    "#     'min_price': 5.0,            # Minimum stock price\n",
    "#     'min_avg_volume_m': 0.8,     # Minimum average daily volume in Millions\n",
    "#     'min_roe_pct': 0.0,          # Minimum Return on Equity % (e.g., > 0)\n",
    "#     'max_debt_eq': 2.0           # Maximum Debt/Equity ratio\n",
    "# }\n",
    "\n",
    "# # Column to use for Inverse Volatility weighting (MAKE SURE THIS EXISTS IN df_data)\n",
    "# # Common choices: 'Volatility M %', 'Volatility W %', 'ATR/Price %'\n",
    "# INV_VOL_COL = 'ATR/Price %'\n",
    "\n",
    "# # Define a small epsilon for safe division\n",
    "# EPSILON = 1e-9\n",
    "\n",
    "# # --- Helper Functions ---\n",
    "\n",
    "# def setup_logging(log_filepath=\"short_term_selector_debug.log\"):\n",
    "#     \"\"\"Configures basic logging.\"\"\"\n",
    "#     log_dir = os.path.dirname(log_filepath)\n",
    "#     if log_dir and not os.path.exists(log_dir):\n",
    "#         try: # Add try-except for directory creation\n",
    "#             os.makedirs(log_dir)\n",
    "#         except OSError as e:\n",
    "#             print(f\"Warning: Could not create log directory {log_dir}: {e}\")\n",
    "#             # Continue without file logging if dir creation fails\n",
    "#             logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', handlers=[logging.StreamHandler()])\n",
    "#             logging.warning(\"Logging to console only.\")\n",
    "#             return\n",
    "#     # Remove existing handlers to avoid duplicates\n",
    "#     for handler in logging.root.handlers[:]:\n",
    "#         logging.root.removeHandler(handler)\n",
    "#     logging.basicConfig(\n",
    "#         level=logging.INFO,\n",
    "#         format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "#         handlers=[\n",
    "#             logging.FileHandler(log_filepath, mode='w'),\n",
    "#             logging.StreamHandler()\n",
    "#         ]\n",
    "#     )\n",
    "#     logging.info(f\"Logging configured. Output file: {log_filepath}\")\n",
    "\n",
    "# def z_score_series(series):\n",
    "#     \"\"\"Calculates Z-score for a pandas Series, handling NaNs and zero std dev.\"\"\"\n",
    "#     mean = series.mean()\n",
    "#     std = series.std()\n",
    "#     if pd.isna(std) or std < EPSILON: # Handle cases with NaNs or zero standard deviation\n",
    "#         logging.debug(f\"Std dev near zero or NaN for series '{series.name}'. Returning 0 Z-scores.\")\n",
    "#         return pd.Series(0.0, index=series.index, name=f\"z_{series.name}\")\n",
    "#     else:\n",
    "#         return ((series - mean) / std).rename(f\"z_{series.name}\")\n",
    "\n",
    "# # --- Main Selection Function ---\n",
    "\n",
    "# def select_short_term_stocks_debug(\n",
    "#     df_data,\n",
    "#     df_cov, # Required if using df_cov diagonal for InverseVolatility weighting\n",
    "#     n_select=20,\n",
    "#     filters=FILTERS,\n",
    "#     scoring_weights=SCORING_WEIGHTS,\n",
    "#     inv_vol_col_name=INV_VOL_COL): # Pass the volatility column name\n",
    "#     \"\"\"\n",
    "#     Selects stocks with potential for positive returns over the next 1-2 days,\n",
    "#     focusing on mean reversion and volume confirmation. Provides detailed output\n",
    "#     including scores and weights for both Equal and Inverse Volatility schemes.\n",
    "\n",
    "#     Args:\n",
    "#         df_data (pd.DataFrame): DataFrame with stock metrics (must include columns\n",
    "#                                 used in filters and scoring). Index should be Ticker.\n",
    "#         df_cov (pd.DataFrame): Covariance matrix (Index=Ticker, Columns=Ticker).\n",
    "#                               Needed only if using its diagonal for InverseVolatility weighting.\n",
    "#         n_select (int): Number of top stocks to select.\n",
    "#         filters (dict): Dictionary defining filter thresholds.\n",
    "#         scoring_weights (dict): Dictionary defining weights for scoring components.\n",
    "#         inv_vol_col_name (str): Column name in df_data to use for Inverse Volatility calculation.\n",
    "\n",
    "#     Returns:\n",
    "#         pd.DataFrame: DataFrame with selected tickers as index, including filter/score details\n",
    "#                       and 'Weight_EW', 'Weight_IV' columns.\n",
    "#                       Returns empty DataFrame on failure or if no stocks pass filters.\n",
    "#     \"\"\"\n",
    "#     logging.info(\"--- Starting Short-Term Stock Selection (Debug Mode) ---\")\n",
    "#     logging.info(f\"Parameters: n_select={n_select}\")\n",
    "#     logging.info(f\"Filters: {filters}\")\n",
    "#     logging.info(f\"Scoring Weights: {scoring_weights}\")\n",
    "#     logging.info(f\"Inverse Volatility Column: '{inv_vol_col_name}'\")\n",
    "\n",
    "#     if not isinstance(df_data, pd.DataFrame) or df_data.empty:\n",
    "#         logging.error(\"Input df_data is not a valid DataFrame or is empty.\")\n",
    "#         return pd.DataFrame() # Return empty df\n",
    "\n",
    "#     df = df_data.copy()\n",
    "\n",
    "#     # --- 1. Data Preparation and Cleaning ---\n",
    "#     base_required_cols = [\n",
    "#         'Price', 'Avg Volume, M', 'ROE %', 'Debt/Eq', # Filters\n",
    "#         'RSI', 'Change %', 'Rel Volume', 'ATR/Price %' # Scoring\n",
    "#     ]\n",
    "#     # Add the column needed for Inverse Volatility weighting\n",
    "#     if inv_vol_col_name and inv_vol_col_name not in base_required_cols:\n",
    "#         required_cols = base_required_cols + [inv_vol_col_name]\n",
    "#     else:\n",
    "#         required_cols = base_required_cols\n",
    "\n",
    "#     missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "#     if missing_cols:\n",
    "#         logging.error(f\"Missing required columns in df_data: {missing_cols}\")\n",
    "#         return pd.DataFrame()\n",
    "\n",
    "#     # Convert relevant columns to numeric just in case, coercing errors\n",
    "#     logging.debug(\"Converting required columns to numeric...\")\n",
    "#     for col in required_cols:\n",
    "#         if not pd.api.types.is_numeric_dtype(df[col]):\n",
    "#             df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "#     # Drop rows with NaNs in essential columns used for filtering/scoring\n",
    "#     initial_count = len(df)\n",
    "#     df.dropna(subset=required_cols, inplace=True)\n",
    "#     cleaned_count = len(df)\n",
    "#     logging.info(f\"Cleaned data: Removed {initial_count - cleaned_count} rows with NaNs in required columns ({required_cols}). {cleaned_count} remaining.\")\n",
    "\n",
    "#     if cleaned_count == 0:\n",
    "#         logging.warning(\"No stocks remaining after NaN cleaning.\")\n",
    "#         return pd.DataFrame()\n",
    "\n",
    "#     # --- 2. Filtering ---\n",
    "#     logging.info(\"Applying filters...\")\n",
    "#     filter_mask = (\n",
    "#         (df['Price'] >= filters['min_price']) &\n",
    "#         (df['Avg Volume, M'] >= filters['min_avg_volume_m']) &\n",
    "#         (df['ROE %'] >= filters['min_roe_pct']) &\n",
    "#         (df['Debt/Eq'] <= filters['max_debt_eq'])\n",
    "#     )\n",
    "#     df_filtered = df[filter_mask].copy()\n",
    "#     filtered_count = len(df_filtered)\n",
    "#     logging.info(f\"Filtering complete: {filtered_count} stocks passed filters.\")\n",
    "\n",
    "#     if filtered_count == 0:\n",
    "#         logging.warning(\"No stocks passed the filtering criteria.\")\n",
    "#         return pd.DataFrame()\n",
    "#     elif filtered_count < n_select:\n",
    "#         logging.warning(f\"Only {filtered_count} stocks passed filters, which is less than n_select ({n_select}). Selecting all {filtered_count}.\")\n",
    "#         n_select = filtered_count # Adjust n_select\n",
    "\n",
    "#     # --- 3. Scoring ---\n",
    "#     logging.info(\"Calculating component scores (Z-scores)...\")\n",
    "#     scores_df = pd.DataFrame(index=df_filtered.index)\n",
    "\n",
    "#     # Calculate Z-scores for each component and store them for debugging\n",
    "#     z_rsi = z_score_series(df_filtered['RSI'])\n",
    "#     z_change = z_score_series(df_filtered['Change %'])\n",
    "#     z_rel_volume = z_score_series(df_filtered['Rel Volume'])\n",
    "#     z_volatility = z_score_series(df_filtered['ATR/Price %']) # Using ATR/Price% for vol component score\n",
    "\n",
    "#     # Combine scores based on weights and desired directionality\n",
    "#     # We want LOW RSI, LOW Change% (more negative), HIGH Rel Volume, LOW Volatility (ATR/Price%)\n",
    "#     # Multiply Z-scores by -1 for factors where lower is better before applying positive weight\n",
    "#     logging.info(\"Calculating final composite score...\")\n",
    "#     final_score = (\n",
    "#         z_rsi * scoring_weights['rsi'] * (-1) +              # Lower RSI -> Higher Score\n",
    "#         z_change * scoring_weights['change'] * (-1) +        # Lower Change% -> Higher Score\n",
    "#         z_rel_volume * scoring_weights['rel_volume'] * (1) + # Higher RelVol -> Higher Score\n",
    "#         z_volatility * scoring_weights['volatility'] * (-1)  # Lower ATR/Price% -> Higher Score\n",
    "#     ).rename('final_score')\n",
    "\n",
    "#     # --- 4. Combine Data for Debug Output ---\n",
    "#     # Concatenate original filtered data, z-scores, and final score\n",
    "#     df_debug = pd.concat([\n",
    "#         df_filtered[required_cols], # Show cols used in filtering/scoring\n",
    "#         z_rsi,\n",
    "#         z_change,\n",
    "#         z_rel_volume,\n",
    "#         z_volatility,\n",
    "#         final_score\n",
    "#     ], axis=1)\n",
    "\n",
    "#     logging.info(f\"Top 5 Stocks based on Intermediate Scores:\\n{df_debug.sort_values('final_score', ascending=False).head(5)}\")\n",
    "\n",
    "\n",
    "#     # --- 5. Ranking & Selection ---\n",
    "#     logging.info(f\"Ranking stocks by final_score and selecting top {n_select}...\")\n",
    "#     df_ranked = df_debug.sort_values('final_score', ascending=False)\n",
    "#     df_selected = df_ranked.head(n_select).copy() # This now contains score details\n",
    "\n",
    "\n",
    "#     # --- 6. Weighting (Calculate BOTH Schemes) ---\n",
    "#     logging.info(f\"Applying BOTH 'EqualWeight' and 'InverseVolatility' weighting schemes...\")\n",
    "\n",
    "#     # -- Equal Weight --\n",
    "#     df_selected['Weight_EW'] = 1.0 / n_select\n",
    "#     logging.debug(f\"Equal Weight calculated: {1.0 / n_select:.4f}\")\n",
    "\n",
    "#     # -- Inverse Volatility Weight --\n",
    "#     if inv_vol_col_name not in df_selected.columns:\n",
    "#         logging.error(f\"Required column '{inv_vol_col_name}' for InverseVolatility weighting not found \"\n",
    "#                       f\"in selected stocks DataFrame. Weight_IV will be NaN.\")\n",
    "#         df_selected['Weight_IV'] = np.nan\n",
    "#     else:\n",
    "#         volatility = df_selected[inv_vol_col_name].copy()\n",
    "#         valid_vol_mask = volatility.notna() & (volatility > 0)\n",
    "#         num_invalid_vol = n_select - valid_vol_mask.sum()\n",
    "#         if num_invalid_vol > 0:\n",
    "#             logging.warning(f\"Found {num_invalid_vol} selected stocks with missing or non-positive \"\n",
    "#                             f\"'{inv_vol_col_name}'. They will receive zero weight in InverseVolatility scheme.\")\n",
    "#             volatility.loc[~valid_vol_mask] = np.inf # Set vol to inf -> inv_vol becomes 0\n",
    "\n",
    "#         inv_vol = 1.0 / volatility\n",
    "#         inv_vol = inv_vol.replace([np.inf, -np.inf], 0) # Handle division by zero/inf\n",
    "\n",
    "#         total_inv_vol = inv_vol.sum()\n",
    "#         if total_inv_vol > EPSILON:\n",
    "#             df_selected['Weight_IV'] = inv_vol / total_inv_vol\n",
    "#             logging.debug(\"Inverse Volatility weights calculated.\")\n",
    "#         else:\n",
    "#             logging.warning(\"Sum of inverse volatilities is near zero. Setting Weight_IV to Equal Weight.\")\n",
    "#             df_selected['Weight_IV'] = 1.0 / n_select # Fallback to equal weight\n",
    "\n",
    "#     # --- 7. Final Checks and Output ---\n",
    "#     # Check sums\n",
    "#     for w_col in ['Weight_EW', 'Weight_IV']:\n",
    "#         if w_col in df_selected.columns:\n",
    "#             weight_sum = df_selected[w_col].sum()\n",
    "#             if not pd.isna(weight_sum) and not np.isclose(weight_sum, 1.0):\n",
    "#                 logging.warning(f\"Final weights for '{w_col}' do not sum close to 1.0 (Sum = {weight_sum:.6f}).\")\n",
    "\n",
    "#     logging.info(f\"Selected Stocks with Scores and Weights (Top 5):\\n{df_selected.head(5)}\")\n",
    "#     logging.info(\"--- Short-Term Stock Selection Finished ---\")\n",
    "\n",
    "#     # Return the detailed DataFrame including scores and both weights\n",
    "#     return df_selected, df_filtered\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import logging\n",
    "# from scipy.stats import zscore # Assuming z_score_series uses this or similar\n",
    "\n",
    "# # --- Placeholder Constants and Functions (replace with your actual implementations) ---\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# # --- Expert Recommended Starting Parameters ---\n",
    "# FILTERS = {\n",
    "#     'min_price': 10.0,            # Minimum share price\n",
    "#     'min_avg_volume_m': 2.0,      # Minimum average daily volume in Millions\n",
    "#     'min_roe_pct': 5.0,           # Minimum Return on Equity percentage\n",
    "#     'max_debt_eq': 1.5            # Maximum Debt-to-Equity ratio\n",
    "# }\n",
    "\n",
    "# SCORING_WEIGHTS = {\n",
    "#     'rsi': 0.35,         # Weight for RSI (lower is better)\n",
    "#     'change': 0.35,      # Weight for Change % (lower is better - mean reversion)\n",
    "#     'rel_volume': 0.20,  # Weight for Relative Volume (higher is better - confirmation)\n",
    "#     'volatility': 0.10   # Weight for ATR/Price % (lower is better - risk dampener)\n",
    "# }\n",
    "# # Check that weights sum to 1 (or close enough)\n",
    "# assert abs(sum(SCORING_WEIGHTS.values()) - 1.0) < 1e-9, \"Scoring weights must sum to 1.0\"\n",
    "\n",
    "\n",
    "# INV_VOL_COL = 'ATR/Price %' # Recommended column for Inverse Volatility Weighting\n",
    "# EPSILON = 1e-9 # Small number to avoid division by zero\n",
    "\n",
    "# # Placeholder Z-score function (adjust if yours is different)\n",
    "# def z_score_series(series: pd.Series) -> pd.Series:\n",
    "#     \"\"\"Calculates Z-score for a pandas Series, handling NaNs.\"\"\"\n",
    "#     # Ensure input is numeric before zscoring\n",
    "#     numeric_series = pd.to_numeric(series, errors='coerce')\n",
    "#     if numeric_series.isnull().all(): # Handle case where all values are NaN after coercion\n",
    "#         return pd.Series(np.nan, index=series.index).rename(f\"z_{series.name}\")\n",
    "#     return pd.Series(zscore(numeric_series, nan_policy='omit'), index=series.index).rename(f\"z_{series.name}\")\n",
    "\n",
    "# # --- Modified Function ---\n",
    "\n",
    "# def select_short_term_stocks_debug(\n",
    "#     df_data,\n",
    "#     df_cov, # Kept for signature compatibility, but not used in provided logic\n",
    "#     n_select=20,\n",
    "#     filters=FILTERS, # Use recommended defaults\n",
    "#     scoring_weights=SCORING_WEIGHTS, # Use recommended defaults\n",
    "#     inv_vol_col_name=INV_VOL_COL): # Use recommended default\n",
    "#     \"\"\"\n",
    "#     Selects stocks with potential for positive returns over the next 1-2 days,\n",
    "#     focusing on mean reversion and volume confirmation. Provides detailed output\n",
    "#     including scores and weights for Equal, Inverse Volatility, and Score-Weighted schemes.\n",
    "\n",
    "#     Uses recommended baseline parameters, but they should be validated via backtesting.\n",
    "\n",
    "#     Args:\n",
    "#         df_data (pd.DataFrame): DataFrame with stock metrics (must include columns\n",
    "#                                 used in filters and scoring). Index should be Ticker.\n",
    "#         df_cov (pd.DataFrame): Covariance matrix (Index=Ticker, Columns=Ticker).\n",
    "#                                Currently unused in the provided logic but kept for signature.\n",
    "#         n_select (int): Number of top stocks to select.\n",
    "#         filters (dict): Dictionary defining filter thresholds. Uses recommended defaults if not provided.\n",
    "#         scoring_weights (dict): Dictionary defining weights for scoring components. Uses recommended defaults if not provided.\n",
    "#         inv_vol_col_name (str): Column name in df_data to use for Inverse Volatility calculation. Uses recommended default if not provided.\n",
    "\n",
    "#     Returns:\n",
    "#         Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "#             - pd.DataFrame: DataFrame with selected tickers as index, including filter/score details\n",
    "#                             and 'Weight_EW', 'Weight_IV', 'Weight_SW' columns.\n",
    "#                             Returns empty DataFrame on failure or if no stocks pass filters.\n",
    "#             - pd.DataFrame: The DataFrame *after* filtering but *before* scoring/selection.\n",
    "#                             Returns empty DataFrame on failure.\n",
    "#     \"\"\"\n",
    "#     logging.info(\"--- Starting Short-Term Stock Selection (Debug Mode) ---\")\n",
    "#     logging.info(f\"Parameters: n_select={n_select}\")\n",
    "#     # Log the actual filters/weights being used (could be defaults or overridden)\n",
    "#     logging.info(f\"Filters Used: {filters}\")\n",
    "#     logging.info(f\"Scoring Weights Used: {scoring_weights}\")\n",
    "#     logging.info(f\"Inverse Volatility Column Used: '{inv_vol_col_name}'\")\n",
    "\n",
    "#     # --- Basic Input Validation ---\n",
    "#     if not isinstance(df_data, pd.DataFrame) or df_data.empty:\n",
    "#         logging.error(\"Input df_data is not a valid DataFrame or is empty.\")\n",
    "#         return pd.DataFrame(), pd.DataFrame() # Return empty dfs\n",
    "\n",
    "#     if not isinstance(filters, dict) or not isinstance(scoring_weights, dict):\n",
    "#         logging.error(\"Filters and scoring_weights must be dictionaries.\")\n",
    "#         return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "#     if abs(sum(scoring_weights.values()) - 1.0) > EPSILON:\n",
    "#          logging.warning(f\"Scoring weights provided do not sum to 1.0 (Sum={sum(scoring_weights.values())}). Proceeding, but normalization might be affected.\")\n",
    "#          # Consider adding normalization logic here if desired, or raising an error\n",
    "\n",
    "#     df = df_data.copy()\n",
    "#     df_after_filter = pd.DataFrame() # Initialize for return\n",
    "\n",
    "#     # --- 1. Define Required Columns based on Inputs ---\n",
    "#     # Start with columns needed for filters\n",
    "#     filter_cols = ['Price', 'Avg Volume, M', 'ROE %', 'Debt/Eq']\n",
    "#     # Add columns needed for scoring (extract keys from weights dict)\n",
    "#     score_input_cols = ['RSI', 'Change %', 'Rel Volume', 'ATR/Price %'] # Base names corresponding to weights keys\n",
    "#     # Add the column needed for Inverse Volatility weighting\n",
    "#     inv_vol_req_col = [inv_vol_col_name] if inv_vol_col_name else []\n",
    "\n",
    "#     required_cols = list(set(filter_cols + score_input_cols + inv_vol_req_col))\n",
    "\n",
    "#     missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "#     if missing_cols:\n",
    "#         logging.error(f\"Missing required columns in df_data: {missing_cols}. Required based on filters/weights/inv_vol_col: {required_cols}\")\n",
    "#         return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "#     # --- 2. Data Preparation and Cleaning ---\n",
    "#     logging.debug(\"Converting required columns to numeric...\")\n",
    "#     for col in required_cols:\n",
    "#         if col in df.columns and not pd.api.types.is_numeric_dtype(df[col]):\n",
    "#             df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "#             logging.debug(f\"  Converted '{col}' to numeric.\")\n",
    "\n",
    "#     initial_count = len(df)\n",
    "#     df.dropna(subset=required_cols, inplace=True)\n",
    "#     cleaned_count = len(df)\n",
    "#     logging.info(f\"Cleaned data: Removed {initial_count - cleaned_count} rows with NaNs in essential columns ({required_cols}). {cleaned_count} remaining.\")\n",
    "\n",
    "#     if cleaned_count == 0:\n",
    "#         logging.warning(\"No stocks remaining after NaN cleaning.\")\n",
    "#         return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "#     # --- 3. Filtering ---\n",
    "#     logging.info(\"Applying filters...\")\n",
    "#     try:\n",
    "#         # Build filter mask dynamically from the filters dictionary\n",
    "#         filter_mask = pd.Series(True, index=df.index) # Start with all True\n",
    "#         if 'min_price' in filters:\n",
    "#             filter_mask &= (df['Price'] >= filters['min_price'])\n",
    "#         if 'min_avg_volume_m' in filters:\n",
    "#              # Ensure column name matches exactly (e.g., 'Avg Volume, M')\n",
    "#              filter_mask &= (df['Avg Volume, M'] >= filters['min_avg_volume_m'])\n",
    "#         if 'min_roe_pct' in filters:\n",
    "#              # Ensure column name matches exactly (e.g., 'ROE %')\n",
    "#              filter_mask &= (df['ROE %'] >= filters['min_roe_pct'])\n",
    "#         if 'max_debt_eq' in filters:\n",
    "#              # Ensure column name matches exactly (e.g., 'Debt/Eq')\n",
    "#              filter_mask &= (df['Debt/Eq'] <= filters['max_debt_eq'])\n",
    "#         # Add more filters here if needed by extending the FILTERS dict and checks\n",
    "\n",
    "#         df_filtered = df[filter_mask].copy()\n",
    "#         df_after_filter = df_filtered.copy() # Store the state after filtering\n",
    "#         filtered_count = len(df_filtered)\n",
    "#         logging.info(f\"Filtering complete: {filtered_count} stocks passed filters.\")\n",
    "\n",
    "#     except KeyError as e:\n",
    "#         logging.error(f\"Filtering failed. Check if filter keys match DataFrame columns exactly. Missing column/key: {e}. Available columns: {df.columns.tolist()}. Filters provided: {filters}\")\n",
    "#         return pd.DataFrame(), pd.DataFrame() # Return empty selection, but potentially the partially filtered df if needed\n",
    "#     except Exception as e:\n",
    "#          logging.error(f\"An unexpected error occurred during filtering: {e}\")\n",
    "#          return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "#     if filtered_count == 0:\n",
    "#         logging.warning(\"No stocks passed the filtering criteria.\")\n",
    "#         return pd.DataFrame(), df_after_filter\n",
    "#     elif filtered_count < n_select:\n",
    "#         logging.warning(f\"Only {filtered_count} stocks passed filters, which is less than n_select ({n_select}). Selecting all {filtered_count}.\")\n",
    "#         n_select = filtered_count # Adjust n_select if fewer stocks passed filters than requested\n",
    "\n",
    "#     # --- 4. Scoring ---\n",
    "#     logging.info(\"Calculating component scores (Z-scores)...\")\n",
    "#     try:\n",
    "#         # Calculate Z-scores for each component defined in scoring_weights\n",
    "#         z_rsi = z_score_series(df_filtered['RSI']).rename('z_RSI')\n",
    "#         z_change = z_score_series(df_filtered['Change %']).rename('z_Change%')\n",
    "#         z_rel_volume = z_score_series(df_filtered['Rel Volume']).rename('z_RelVolume')\n",
    "#         # Use the specific column name for volatility component score\n",
    "#         z_volatility = z_score_series(df_filtered['ATR/Price %']).rename('z_ATR/Price%')\n",
    "\n",
    "#         # Combine scores based on weights and desired directionality\n",
    "#         logging.info(\"Calculating final composite score...\")\n",
    "#         final_score = (\n",
    "#             z_rsi * scoring_weights.get('rsi', 0) * (-1) +            # Lower RSI -> Higher Score\n",
    "#             z_change * scoring_weights.get('change', 0) * (-1) +      # Lower Change% -> Higher Score\n",
    "#             z_rel_volume * scoring_weights.get('rel_volume', 0) * (1) + # Higher RelVol -> Higher Score\n",
    "#             z_volatility * scoring_weights.get('volatility', 0) * (-1) # Lower ATR/Price% -> Higher Score\n",
    "#         ).rename('final_score')\n",
    "\n",
    "#         # Handle potential NaNs in final_score if any z-score component was all NaN\n",
    "#         final_score = final_score.fillna(0) # Or consider dropping rows with NaN scores\n",
    "\n",
    "#     except KeyError as e:\n",
    "#         logging.error(f\"Scoring failed. Check if scoring_weights keys match score_input_cols/DataFrame columns. Missing column/key: {e}. Columns in df_filtered: {df_filtered.columns.tolist()}. Scoring weights: {scoring_weights}\")\n",
    "#         return pd.DataFrame(), df_after_filter\n",
    "#     except Exception as e:\n",
    "#          logging.error(f\"An unexpected error occurred during scoring: {e}\")\n",
    "#          return pd.DataFrame(), df_after_filter\n",
    "\n",
    "\n",
    "#     # --- 5. Combine Data & Rank ---\n",
    "#     # Concatenate original filtered data subset, z-scores, and final score\n",
    "#     df_debug = pd.concat([\n",
    "#         df_filtered[required_cols], # Show only essential columns for brevity\n",
    "#         z_rsi,\n",
    "#         z_change,\n",
    "#         z_rel_volume,\n",
    "#         z_volatility,\n",
    "#         final_score\n",
    "#     ], axis=1)\n",
    "\n",
    "#     # Drop rows where final_score might be NaN if z-scoring failed and fillna(0) wasn't used above\n",
    "#     # df_debug.dropna(subset=['final_score'], inplace=True) # Optional: uncomment if you prefer dropping over fillna(0)\n",
    "#     # Re-adjust n_select if rows were dropped here\n",
    "\n",
    "#     logging.info(f\"Top 5 Stocks based on Intermediate Scores:\\n{df_debug.sort_values('final_score', ascending=False).head(5)}\")\n",
    "\n",
    "#     # --- 6. Selection ---\n",
    "#     logging.info(f\"Ranking stocks by final_score and selecting top {n_select}...\")\n",
    "#     # Ensure n_select is not greater than the number of available stocks after scoring\n",
    "#     n_select = min(n_select, len(df_debug))\n",
    "#     if n_select == 0:\n",
    "#         logging.warning(\"No stocks available for selection after scoring/ranking.\")\n",
    "#         return pd.DataFrame(), df_after_filter\n",
    "\n",
    "#     df_ranked = df_debug.sort_values('final_score', ascending=False)\n",
    "#     df_selected = df_ranked.head(n_select).copy()\n",
    "\n",
    "\n",
    "#     # --- 7. Weighting ---\n",
    "#     logging.info(f\"Applying 'EqualWeight', 'InverseVolatility', and 'ScoreWeighted' schemes...\")\n",
    "\n",
    "#     # -- Equal Weight (EW) --\n",
    "#     df_selected['Weight_EW'] = 1.0 / n_select if n_select > 0 else 0\n",
    "#     logging.debug(f\"Equal Weight calculated: {df_selected['Weight_EW'].iloc[0]:.4f}\" if n_select > 0 else \"N/A\")\n",
    "\n",
    "#     # -- Inverse Volatility Weight (IV) --\n",
    "#     if not inv_vol_col_name or inv_vol_col_name not in df_selected.columns:\n",
    "#         logging.error(f\"Required column '{inv_vol_col_name}' for InverseVolatility not found in selected stocks. Weight_IV will be NaN.\")\n",
    "#         df_selected['Weight_IV'] = np.nan\n",
    "#     else:\n",
    "#         volatility = df_selected[inv_vol_col_name].copy()\n",
    "#         volatility = pd.to_numeric(volatility, errors='coerce') # Ensure numeric\n",
    "#         valid_vol_mask = volatility.notna() & (volatility > EPSILON)\n",
    "#         num_invalid_vol = len(volatility) - valid_vol_mask.sum() # Use len(volatility) which is n_select\n",
    "\n",
    "#         if num_invalid_vol > 0:\n",
    "#             logging.warning(f\"Found {num_invalid_vol}/{n_select} selected stocks with missing, zero or negative '{inv_vol_col_name}'. They get zero weight in IV scheme.\")\n",
    "#             volatility.loc[~valid_vol_mask] = np.inf # Set invalid vol to infinity -> inverse is 0\n",
    "\n",
    "#         inv_vol = 1.0 / volatility\n",
    "#         inv_vol = inv_vol.replace([np.inf, -np.inf], 0).fillna(0)\n",
    "\n",
    "#         total_inv_vol = inv_vol.sum()\n",
    "#         if total_inv_vol > EPSILON:\n",
    "#             df_selected['Weight_IV'] = inv_vol / total_inv_vol\n",
    "#             logging.debug(\"Inverse Volatility weights calculated.\")\n",
    "#         else:\n",
    "#             logging.warning(f\"Sum of inverse volatilities ('{inv_vol_col_name}') is near zero. Setting Weight_IV to Equal Weight fallback.\")\n",
    "#             df_selected['Weight_IV'] = df_selected['Weight_EW'] # Fallback to EW\n",
    "\n",
    "#     # -- Score Weighted (SW) --\n",
    "#     scores = df_selected['final_score'].copy()\n",
    "#     scores = pd.to_numeric(scores, errors='coerce').fillna(0)\n",
    "\n",
    "#     # Shift scores so the minimum score is zero - prevents negative weights if desired\n",
    "#     # If you WANT negative weights for negative scores, comment out the next two lines\n",
    "#     min_score = scores.min()\n",
    "#     if min_score < 0:\n",
    "#         logging.info(f\"Shifting scores by {-min_score:.4f} to make minimum score zero for ScoreWeighted scheme.\")\n",
    "#         scores = scores - min_score # Ensures all weights are >= 0\n",
    "\n",
    "#     total_score = scores.sum()\n",
    "\n",
    "#     if abs(total_score) > EPSILON:\n",
    "#         df_selected['Weight_SW'] = scores / total_score\n",
    "#         logging.debug(\"Score Weighted weights calculated (non-negative scores used for weighting).\")\n",
    "#     else:\n",
    "#         logging.warning(\"Sum of adjusted 'final_score' is near zero. Setting Weight_SW to Equal Weight fallback.\")\n",
    "#         df_selected['Weight_SW'] = df_selected['Weight_EW'] # Fallback to EW\n",
    "\n",
    "\n",
    "#     # --- 8. Final Checks and Output ---\n",
    "#     weight_cols = ['Weight_EW', 'Weight_IV', 'Weight_SW']\n",
    "#     for w_col in weight_cols:\n",
    "#         if w_col in df_selected.columns and pd.api.types.is_numeric_dtype(df_selected[w_col]):\n",
    "#              weight_sum = df_selected[w_col].sum()\n",
    "#              if pd.isna(weight_sum):\n",
    "#                  logging.warning(f\"Weight sum for '{w_col}' resulted in NaN.\")\n",
    "#              elif not np.isclose(weight_sum, 1.0, atol=EPSILON):\n",
    "#                  logging.warning(f\"Final weights for '{w_col}' do not sum close to 1.0 (Sum = {weight_sum:.6f}). Check calculations.\")\n",
    "#         elif w_col in df_selected.columns:\n",
    "#              logging.warning(f\"Weight column '{w_col}' exists but is not numeric.\")\n",
    "\n",
    "#     logging.info(f\"Selected Stocks ({n_select} stocks) with Scores and Weights (Top {min(5, n_select)} shown):\\n{df_selected.head(5)}\")\n",
    "#     logging.info(\"--- Short-Term Stock Selection Finished ---\")\n",
    "\n",
    "#     return df_selected, df_after_filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from scipy.stats import zscore # Assuming z_score_series uses this or similar\n",
    "from typing import Tuple, Dict, Any # Import necessary types\n",
    "\n",
    "# --- Placeholder Constants and Functions (replace with your actual implementations) ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# --- Expert Recommended Starting Parameters ---\n",
    "FILTERS = {\n",
    "    'min_price': 10.0,            # Minimum share price\n",
    "    'min_avg_volume_m': 2.0,      # Minimum average daily volume in Millions\n",
    "    'min_roe_pct': 5.0,           # Minimum Return on Equity percentage\n",
    "    'max_debt_eq': 1.5            # Maximum Debt-to-Equity ratio\n",
    "}\n",
    "\n",
    "SCORING_WEIGHTS = {\n",
    "    'rsi': 0.35,         # Weight for RSI (lower is better)\n",
    "    'change': 0.35,      # Weight for Change % (lower is better - mean reversion)\n",
    "    'rel_volume': 0.20,  # Weight for Relative Volume (higher is better - confirmation)\n",
    "    'volatility': 0.10   # Weight for ATR/Price % (lower is better - risk dampener)\n",
    "}\n",
    "# Check that weights sum to 1 (or close enough)\n",
    "assert abs(sum(SCORING_WEIGHTS.values()) - 1.0) < 1e-9, \"Scoring weights must sum to 1.0\"\n",
    "\n",
    "\n",
    "INV_VOL_COL = 'ATR/Price %' # Recommended column for Inverse Volatility Weighting\n",
    "EPSILON = 1e-9 # Small number to avoid division by zero\n",
    "\n",
    "# Placeholder Z-score function (adjust if yours is different)\n",
    "def z_score_series(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Calculates Z-score for a pandas Series, handling NaNs.\"\"\"\n",
    "    # Ensure input is numeric before zscoring\n",
    "    numeric_series = pd.to_numeric(series, errors='coerce')\n",
    "    if numeric_series.isnull().all(): # Handle case where all values are NaN after coercion\n",
    "        return pd.Series(np.nan, index=series.index).rename(f\"z_{series.name}\")\n",
    "    return pd.Series(zscore(numeric_series, nan_policy='omit'), index=series.index).rename(f\"z_{series.name}\")\n",
    "\n",
    "# --- Modified Function ---\n",
    "\n",
    "def select_short_term_stocks_debug(\n",
    "    df_data,\n",
    "    # df_cov, # Kept for signature compatibility, but not used in provided logic\n",
    "    n_select=20,\n",
    "    filters=FILTERS, # Use recommended defaults\n",
    "    scoring_weights=SCORING_WEIGHTS, # Use recommended defaults\n",
    "    inv_vol_col_name=INV_VOL_COL) -> Tuple[pd.DataFrame, pd.DataFrame, Dict[str, Any]]: # Updated return type hint\n",
    "    \"\"\"\n",
    "    Selects stocks with potential for positive returns over the next 1-2 days,\n",
    "    focusing on mean reversion and volume confirmation. Provides detailed output\n",
    "    including scores and weights for Equal, Inverse Volatility, and Score-Weighted schemes.\n",
    "\n",
    "    Uses recommended baseline parameters, but they should be validated via backtesting.\n",
    "\n",
    "    Args:\n",
    "        df_data (pd.DataFrame): DataFrame with stock metrics (must include columns\n",
    "                                used in filters and scoring). Index should be Ticker.\n",
    "        df_cov (pd.DataFrame): Covariance matrix (Index=Ticker, Columns=Ticker).\n",
    "                               Currently unused in the provided logic but kept for signature.\n",
    "        n_select (int): Number of top stocks to select *initially*. The actual number\n",
    "                        selected might be lower if fewer stocks pass filters/scoring.\n",
    "        filters (dict): Dictionary defining filter thresholds. Uses recommended defaults if not provided.\n",
    "        scoring_weights (dict): Dictionary defining weights for scoring components. Uses recommended defaults if not provided.\n",
    "        inv_vol_col_name (str): Column name in df_data to use for Inverse Volatility calculation. Uses recommended default if not provided.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, pd.DataFrame, Dict[str, Any]]:\n",
    "            - pd.DataFrame: DataFrame with selected tickers as index, including filter/score details\n",
    "                            and 'Weight_EW', 'Weight_IV', 'Weight_SW' columns.\n",
    "                            Returns empty DataFrame on failure or if no stocks pass filters/scoring.\n",
    "            - pd.DataFrame: The DataFrame *after* filtering but *before* scoring/selection.\n",
    "                            Returns empty DataFrame on failure.\n",
    "            - Dict[str, Any]: A flat dictionary containing the parameters used for the selection\n",
    "                              (e.g., {'n_select': 20, 'filter_min_price': 10.0,\n",
    "                               'score_weight_rsi': 0.35, 'inv_vol_col_name': 'ATR/Price %'}).\n",
    "    \"\"\"\n",
    "    # Store initial n_select value for parameters output\n",
    "    initial_n_select = n_select\n",
    "\n",
    "    # --- Log Parameters ---\n",
    "    logging.info(\"--- Starting Short-Term Stock Selection (Debug Mode) ---\")\n",
    "    logging.info(f\"Initial Parameters: n_select={initial_n_select}\")\n",
    "    logging.info(f\"Filters Used: {filters}\")\n",
    "    logging.info(f\"Scoring Weights Used: {scoring_weights}\")\n",
    "    logging.info(f\"Inverse Volatility Column Used: '{inv_vol_col_name}'\")\n",
    "\n",
    "    # --- Basic Input Validation ---\n",
    "    if not isinstance(df_data, pd.DataFrame) or df_data.empty:\n",
    "        logging.error(\"Input df_data is not a valid DataFrame or is empty.\")\n",
    "        # Create the parameters dict even on failure for consistent return signature\n",
    "        parameters_used = {\n",
    "            'n_select_requested': initial_n_select,\n",
    "            'inv_vol_col_name': inv_vol_col_name\n",
    "        }\n",
    "        if isinstance(filters, dict):\n",
    "            for k, v in filters.items(): parameters_used[f'filter_{k}'] = v\n",
    "        if isinstance(scoring_weights, dict):\n",
    "            for k, v in scoring_weights.items(): parameters_used[f'score_weight_{k}'] = v\n",
    "        return pd.DataFrame(), pd.DataFrame(), parameters_used\n",
    "\n",
    "    if not isinstance(filters, dict) or not isinstance(scoring_weights, dict):\n",
    "        logging.error(\"Filters and scoring_weights must be dictionaries.\")\n",
    "        parameters_used = {\n",
    "            'n_select_requested': initial_n_select,\n",
    "            'inv_vol_col_name': inv_vol_col_name\n",
    "        }\n",
    "        # Attempt to add parameters even if types are wrong, might fail if not iterable\n",
    "        try:\n",
    "            if isinstance(filters, dict):\n",
    "                 for k, v in filters.items(): parameters_used[f'filter_{k}'] = v\n",
    "            if isinstance(scoring_weights, dict):\n",
    "                 for k, v in scoring_weights.items(): parameters_used[f'score_weight_{k}'] = v\n",
    "        except: pass # Ignore errors during parameter gathering on failure\n",
    "        return pd.DataFrame(), pd.DataFrame(), parameters_used\n",
    "\n",
    "\n",
    "    if abs(sum(scoring_weights.values()) - 1.0) > EPSILON:\n",
    "         logging.warning(f\"Scoring weights provided do not sum to 1.0 (Sum={sum(scoring_weights.values())}). Proceeding, but normalization might be affected.\")\n",
    "\n",
    "    df = df_data.copy()\n",
    "    df_after_filter = pd.DataFrame() # Initialize for return\n",
    "\n",
    "    # --- [Existing code sections 1 through 6 remain unchanged] ---\n",
    "    # 1. Define Required Columns based on Inputs\n",
    "    filter_cols = ['Price', 'Avg Volume, M', 'ROE %', 'Debt/Eq']\n",
    "    score_input_cols = ['RSI', 'Change %', 'Rel Volume', 'ATR/Price %']\n",
    "    inv_vol_req_col = [inv_vol_col_name] if inv_vol_col_name else []\n",
    "    required_cols = list(set(filter_cols + score_input_cols + inv_vol_req_col))\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        logging.error(f\"Missing required columns in df_data: {missing_cols}. Required based on filters/weights/inv_vol_col: {required_cols}\")\n",
    "        parameters_used = {\n",
    "            'n_select_requested': initial_n_select, 'inv_vol_col_name': inv_vol_col_name\n",
    "        }\n",
    "        if isinstance(filters, dict):\n",
    "            for k, v in filters.items(): parameters_used[f'filter_{k}'] = v\n",
    "        if isinstance(scoring_weights, dict):\n",
    "            for k, v in scoring_weights.items(): parameters_used[f'score_weight_{k}'] = v\n",
    "        return pd.DataFrame(), pd.DataFrame(), parameters_used\n",
    "\n",
    "    # 2. Data Preparation and Cleaning\n",
    "    logging.debug(\"Converting required columns to numeric...\")\n",
    "    for col in required_cols:\n",
    "        if col in df.columns and not pd.api.types.is_numeric_dtype(df[col]):\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    initial_count = len(df)\n",
    "    df.dropna(subset=required_cols, inplace=True)\n",
    "    cleaned_count = len(df)\n",
    "    logging.info(f\"Cleaned data: Removed {initial_count - cleaned_count} rows with NaNs in essential columns ({required_cols}). {cleaned_count} remaining.\")\n",
    "    if cleaned_count == 0:\n",
    "        logging.warning(\"No stocks remaining after NaN cleaning.\")\n",
    "        parameters_used = {\n",
    "            'n_select_requested': initial_n_select, 'inv_vol_col_name': inv_vol_col_name\n",
    "        }\n",
    "        if isinstance(filters, dict):\n",
    "            for k, v in filters.items(): parameters_used[f'filter_{k}'] = v\n",
    "        if isinstance(scoring_weights, dict):\n",
    "            for k, v in scoring_weights.items(): parameters_used[f'score_weight_{k}'] = v\n",
    "        return pd.DataFrame(), pd.DataFrame(), parameters_used\n",
    "\n",
    "    # 3. Filtering\n",
    "    logging.info(\"Applying filters...\")\n",
    "    try:\n",
    "        filter_mask = pd.Series(True, index=df.index)\n",
    "        if 'min_price' in filters: filter_mask &= (df['Price'] >= filters['min_price'])\n",
    "        if 'min_avg_volume_m' in filters: filter_mask &= (df['Avg Volume, M'] >= filters['min_avg_volume_m'])\n",
    "        if 'min_roe_pct' in filters: filter_mask &= (df['ROE %'] >= filters['min_roe_pct'])\n",
    "        if 'max_debt_eq' in filters: filter_mask &= (df['Debt/Eq'] <= filters['max_debt_eq'])\n",
    "        df_filtered = df[filter_mask].copy()\n",
    "        df_after_filter = df_filtered.copy()\n",
    "        filtered_count = len(df_filtered)\n",
    "        logging.info(f\"Filtering complete: {filtered_count} stocks passed filters.\")\n",
    "    except KeyError as e:\n",
    "        logging.error(f\"Filtering failed. Check keys. Missing column/key: {e}. Filters: {filters}\")\n",
    "        parameters_used = {\n",
    "            'n_select_requested': initial_n_select, 'inv_vol_col_name': inv_vol_col_name\n",
    "        }\n",
    "        if isinstance(filters, dict):\n",
    "            for k, v in filters.items(): parameters_used[f'filter_{k}'] = v\n",
    "        if isinstance(scoring_weights, dict):\n",
    "            for k, v in scoring_weights.items(): parameters_used[f'score_weight_{k}'] = v\n",
    "        return pd.DataFrame(), pd.DataFrame(), parameters_used # Return empty dfs, params\n",
    "    except Exception as e:\n",
    "         logging.error(f\"An unexpected error occurred during filtering: {e}\")\n",
    "         parameters_used = {\n",
    "             'n_select_requested': initial_n_select, 'inv_vol_col_name': inv_vol_col_name\n",
    "         }\n",
    "         if isinstance(filters, dict):\n",
    "             for k, v in filters.items(): parameters_used[f'filter_{k}'] = v\n",
    "         if isinstance(scoring_weights, dict):\n",
    "             for k, v in scoring_weights.items(): parameters_used[f'score_weight_{k}'] = v\n",
    "         return pd.DataFrame(), pd.DataFrame(), parameters_used\n",
    "\n",
    "    if filtered_count == 0:\n",
    "        logging.warning(\"No stocks passed the filtering criteria.\")\n",
    "        parameters_used = {\n",
    "            'n_select_requested': initial_n_select, 'inv_vol_col_name': inv_vol_col_name\n",
    "        }\n",
    "        if isinstance(filters, dict):\n",
    "            for k, v in filters.items(): parameters_used[f'filter_{k}'] = v\n",
    "        if isinstance(scoring_weights, dict):\n",
    "            for k, v in scoring_weights.items(): parameters_used[f'score_weight_{k}'] = v\n",
    "        return pd.DataFrame(), df_after_filter, parameters_used # Return empty selection, filtered df, params\n",
    "    elif filtered_count < n_select:\n",
    "        logging.warning(f\"Only {filtered_count} stocks passed filters, less than n_select ({n_select}). Selecting all {filtered_count}.\")\n",
    "        n_select = filtered_count # Adjust n_select\n",
    "\n",
    "    # 4. Scoring\n",
    "    logging.info(\"Calculating component scores (Z-scores)...\")\n",
    "    try:\n",
    "        z_rsi = z_score_series(df_filtered['RSI']).rename('z_RSI')\n",
    "        z_change = z_score_series(df_filtered['Change %']).rename('z_Change%')\n",
    "        z_rel_volume = z_score_series(df_filtered['Rel Volume']).rename('z_RelVolume')\n",
    "        z_volatility = z_score_series(df_filtered['ATR/Price %']).rename('z_ATR/Price%')\n",
    "        final_score = (\n",
    "            z_rsi * scoring_weights.get('rsi', 0) * (-1) +\n",
    "            z_change * scoring_weights.get('change', 0) * (-1) +\n",
    "            z_rel_volume * scoring_weights.get('rel_volume', 0) * (1) +\n",
    "            z_volatility * scoring_weights.get('volatility', 0) * (-1)\n",
    "        ).rename('final_score').fillna(0)\n",
    "    except KeyError as e:\n",
    "        logging.error(f\"Scoring failed. Missing column/key: {e}. Weights: {scoring_weights}\")\n",
    "        parameters_used = {\n",
    "            'n_select_requested': initial_n_select, 'inv_vol_col_name': inv_vol_col_name\n",
    "        }\n",
    "        if isinstance(filters, dict):\n",
    "            for k, v in filters.items(): parameters_used[f'filter_{k}'] = v\n",
    "        if isinstance(scoring_weights, dict):\n",
    "            for k, v in scoring_weights.items(): parameters_used[f'score_weight_{k}'] = v\n",
    "        return pd.DataFrame(), df_after_filter, parameters_used\n",
    "    except Exception as e:\n",
    "         logging.error(f\"An unexpected error occurred during scoring: {e}\")\n",
    "         parameters_used = {\n",
    "             'n_select_requested': initial_n_select, 'inv_vol_col_name': inv_vol_col_name\n",
    "         }\n",
    "         if isinstance(filters, dict):\n",
    "             for k, v in filters.items(): parameters_used[f'filter_{k}'] = v\n",
    "         if isinstance(scoring_weights, dict):\n",
    "             for k, v in scoring_weights.items(): parameters_used[f'score_weight_{k}'] = v\n",
    "         return pd.DataFrame(), df_after_filter, parameters_used\n",
    "\n",
    "    # 5. Combine Data & Rank\n",
    "    df_debug = pd.concat([\n",
    "        df_filtered[required_cols], z_rsi, z_change, z_rel_volume, z_volatility, final_score\n",
    "    ], axis=1)\n",
    "    logging.info(f\"Top 5 Stocks based on Intermediate Scores:\\n{df_debug.sort_values('final_score', ascending=False).head(5)}\")\n",
    "\n",
    "    # 6. Selection\n",
    "    logging.info(f\"Ranking stocks by final_score and selecting top {n_select}...\")\n",
    "    n_select = min(n_select, len(df_debug)) # Ensure n_select is not > available\n",
    "    if n_select == 0:\n",
    "        logging.warning(\"No stocks available for selection after scoring/ranking.\")\n",
    "        parameters_used = {\n",
    "            'n_select_requested': initial_n_select, 'n_select_actual': 0, 'inv_vol_col_name': inv_vol_col_name\n",
    "        }\n",
    "        if isinstance(filters, dict):\n",
    "            for k, v in filters.items(): parameters_used[f'filter_{k}'] = v\n",
    "        if isinstance(scoring_weights, dict):\n",
    "            for k, v in scoring_weights.items(): parameters_used[f'score_weight_{k}'] = v\n",
    "        return pd.DataFrame(), df_after_filter, parameters_used\n",
    "\n",
    "    df_ranked = df_debug.sort_values('final_score', ascending=False)\n",
    "    df_selected = df_ranked.head(n_select).copy()\n",
    "    actual_n_select = len(df_selected) # Store the actual number selected\n",
    "\n",
    "    # --- 7. Weighting (Unchanged Logic) ---\n",
    "    logging.info(f\"Applying 'EqualWeight', 'InverseVolatility', and 'ScoreWeighted' schemes...\")\n",
    "    # -- Equal Weight (EW) --\n",
    "    df_selected['Weight_EW'] = 1.0 / actual_n_select if actual_n_select > 0 else 0\n",
    "    # -- Inverse Volatility Weight (IV) --\n",
    "    if not inv_vol_col_name or inv_vol_col_name not in df_selected.columns:\n",
    "        df_selected['Weight_IV'] = np.nan\n",
    "    else:\n",
    "        volatility = pd.to_numeric(df_selected[inv_vol_col_name], errors='coerce')\n",
    "        valid_vol_mask = volatility.notna() & (volatility > EPSILON)\n",
    "        volatility.loc[~valid_vol_mask] = np.inf\n",
    "        inv_vol = (1.0 / volatility).replace([np.inf, -np.inf], 0).fillna(0)\n",
    "        total_inv_vol = inv_vol.sum()\n",
    "        if total_inv_vol > EPSILON: df_selected['Weight_IV'] = inv_vol / total_inv_vol\n",
    "        else: df_selected['Weight_IV'] = df_selected['Weight_EW'] # Fallback\n",
    "    # -- Score Weighted (SW) --\n",
    "    scores = pd.to_numeric(df_selected['final_score'], errors='coerce').fillna(0)\n",
    "    min_score = scores.min()\n",
    "    if min_score < 0: scores = scores - min_score # Shift to non-negative\n",
    "    total_score = scores.sum()\n",
    "    if abs(total_score) > EPSILON: df_selected['Weight_SW'] = scores / total_score\n",
    "    else: df_selected['Weight_SW'] = df_selected['Weight_EW'] # Fallback\n",
    "\n",
    "    # --- 8. Final Checks (Unchanged Logic) ---\n",
    "    weight_cols = ['Weight_EW', 'Weight_IV', 'Weight_SW']\n",
    "    for w_col in weight_cols:\n",
    "        # ... (sum checks remain the same) ...\n",
    "        if w_col in df_selected.columns and pd.api.types.is_numeric_dtype(df_selected[w_col]):\n",
    "             weight_sum = df_selected[w_col].sum()\n",
    "             if pd.isna(weight_sum): logging.warning(f\"Weight sum for '{w_col}' resulted in NaN.\")\n",
    "             elif not np.isclose(weight_sum, 1.0, atol=EPSILON): logging.warning(f\"Final weights for '{w_col}' do not sum close to 1.0 (Sum = {weight_sum:.6f}). Check calculations.\")\n",
    "        elif w_col in df_selected.columns: logging.warning(f\"Weight column '{w_col}' exists but is not numeric.\")\n",
    "\n",
    "\n",
    "    logging.info(f\"Selected Stocks ({actual_n_select} stocks) with Scores and Weights (Top {min(5, actual_n_select)} shown):\\n{df_selected.head(min(5, actual_n_select))}\")\n",
    "\n",
    "\n",
    "    # --- 9. Prepare Parameters Dictionary for Output ---\n",
    "    parameters_used = {\n",
    "        'n_select_requested': initial_n_select, # The n_select passed into the function\n",
    "        'n_select_actual': actual_n_select,     # The number actually selected (might be lower)\n",
    "        'inv_vol_col_name': inv_vol_col_name\n",
    "    }\n",
    "    # Flatten filters into the dictionary\n",
    "    if isinstance(filters, dict):\n",
    "        for k, v in filters.items():\n",
    "            parameters_used[f'filter_{k}'] = v\n",
    "    # Flatten scoring_weights into the dictionary\n",
    "    if isinstance(scoring_weights, dict):\n",
    "        for k, v in scoring_weights.items():\n",
    "            parameters_used[f'score_weight_{k}'] = v\n",
    "\n",
    "    logging.info(\"--- Short-Term Stock Selection Finished ---\")\n",
    "\n",
    "\n",
    "    # --- 10. Return Results ---\n",
    "    return df_selected, df_after_filter, parameters_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 18:19:12,617 - INFO - --- Starting Short-Term Stock Selection (Debug Mode) ---\n",
      "2025-05-01 18:19:12,619 - INFO - Initial Parameters: n_select=10\n",
      "2025-05-01 18:19:12,620 - INFO - Filters Used: {'min_price': 10.0, 'min_avg_volume_m': 2.0, 'min_roe_pct': 5.0, 'max_debt_eq': 1.5}\n",
      "2025-05-01 18:19:12,621 - INFO - Scoring Weights Used: {'rsi': 0.35, 'change': 0.35, 'rel_volume': 0.2, 'volatility': 0.1}\n",
      "2025-05-01 18:19:12,622 - INFO - Inverse Volatility Column Used: 'ATR/Price %'\n",
      "2025-05-01 18:19:12,629 - INFO - Cleaned data: Removed 458 rows with NaNs in essential columns (['Change %', 'ROE %', 'Debt/Eq', 'Rel Volume', 'Avg Volume, M', 'ATR/Price %', 'Price', 'RSI']). 1081 remaining.\n",
      "2025-05-01 18:19:12,631 - INFO - Applying filters...\n",
      "2025-05-01 18:19:12,637 - INFO - Filtering complete: 292 stocks passed filters.\n",
      "2025-05-01 18:19:12,638 - INFO - Calculating component scores (Z-scores)...\n",
      "2025-05-01 18:19:12,655 - INFO - Top 5 Stocks based on Intermediate Scores:\n",
      "        Change %   ROE %  Debt/Eq  Rel Volume  Avg Volume, M  ATR/Price %    Price     RSI   z_RSI  z_Change%  z_RelVolume  z_ATR/Price%  final_score\n",
      "Ticker                                                                                                                                               \n",
      "AVTR     -3.4000 12.5200   0.6700      2.9000         8.9900       7.3659  12.4900 28.7500 -3.3756    -2.8988       6.3431        2.2806       3.2366\n",
      "CART     -4.7500 12.6800   0.0100      1.1800         4.1700       4.6092  39.9200 45.1100 -0.9746    -3.9292       1.2042        0.2665       1.9305\n",
      "KHC      -2.3100  5.5600   0.4200      1.7300        11.1400       2.7074  28.8100 43.1700 -1.2593    -2.0668       2.8474       -1.1231       1.8459\n",
      "TMO      -0.6800 13.7500   0.6900      1.1200         2.2500       4.2199 421.3400 34.3300 -2.5567    -0.8227       1.0249       -0.0180       1.3896\n",
      "UNH       0.3200 15.8800   0.8800      1.1100         5.9200       5.2262 420.0000 28.2500 -3.4490    -0.0594       0.9951        0.7173       1.3552\n",
      "2025-05-01 18:19:12,656 - INFO - Ranking stocks by final_score and selecting top 10...\n",
      "2025-05-01 18:19:12,660 - INFO - Applying 'EqualWeight', 'InverseVolatility', and 'ScoreWeighted' schemes...\n",
      "2025-05-01 18:19:12,671 - INFO - Selected Stocks (10 stocks) with Scores and Weights (Top 5 shown):\n",
      "        Change %   ROE %  Debt/Eq  Rel Volume  Avg Volume, M  ATR/Price %    Price     RSI   z_RSI  z_Change%  z_RelVolume  z_ATR/Price%  final_score  Weight_EW  Weight_IV  Weight_SW\n",
      "Ticker                                                                                                                                                                                \n",
      "AVTR     -3.4000 12.5200   0.6700      2.9000         8.9900       7.3659  12.4900 28.7500 -3.3756    -2.8988       6.3431        2.2806       3.2366     0.1000     0.0615     0.2004\n",
      "CART     -4.7500 12.6800   0.0100      1.1800         4.1700       4.6092  39.9200 45.1100 -0.9746    -3.9292       1.2042        0.2665       1.9305     0.1000     0.0983     0.1195\n",
      "KHC      -2.3100  5.5600   0.4200      1.7300        11.1400       2.7074  28.8100 43.1700 -1.2593    -2.0668       2.8474       -1.1231       1.8459     0.1000     0.1674     0.1143\n",
      "TMO      -0.6800 13.7500   0.6900      1.1200         2.2500       4.2199 421.3400 34.3300 -2.5567    -0.8227       1.0249       -0.0180       1.3896     0.1000     0.1074     0.0860\n",
      "UNH       0.3200 15.8800   0.8800      1.1100         5.9200       5.2262 420.0000 28.2500 -3.4490    -0.0594       0.9951        0.7173       1.3552     0.1000     0.0867     0.0839\n",
      "2025-05-01 18:19:12,672 - INFO - --- Short-Term Stock Selection Finished ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected Stocks (Detailed Output with Scores & Weights):\n",
      "        final_score  Weight_EW  Weight_IV  Weight_SW     RSI  Change %  Rel Volume  ATR/Price %\n",
      "Ticker                                                                                         \n",
      "AVTR         3.2366     0.1000     0.0615     0.2004 28.7500   -3.4000      2.9000       7.3659\n",
      "CART         1.9305     0.1000     0.0983     0.1195 45.1100   -4.7500      1.1800       4.6092\n",
      "KHC          1.8459     0.1000     0.1674     0.1143 43.1700   -2.3100      1.7300       2.7074\n",
      "TMO          1.3896     0.1000     0.1074     0.0860 34.3300   -0.6800      1.1200       4.2199\n",
      "UNH          1.3552     0.1000     0.0867     0.0839 28.2500    0.3200      1.1100       5.2262\n",
      "FI           1.3545     0.1000     0.0838     0.0839 31.1200    0.2800      1.3600       5.4092\n",
      "IR           1.3487     0.1000     0.1097     0.0835 48.3200   -0.2400      2.4400       4.1310\n",
      "LKQ          1.2667     0.1000     0.1109     0.0784 34.9700   -0.5300      1.0200       4.0849\n",
      "SPOT         1.2619     0.1000     0.0847     0.0781 55.6800   -3.7000      1.5300       5.3519\n",
      "LYB          1.1629     0.1000     0.0896     0.0720 41.8200   -1.2100      1.2500       5.0579\n",
      "\n",
      "Parameters Used for Selection:\n",
      "n_select_requested: 10\n",
      "n_select_actual: 10\n",
      "inv_vol_col_name: ATR/Price %\n",
      "filter_min_price: 10.0\n",
      "filter_min_avg_volume_m: 2.0\n",
      "filter_min_roe_pct: 5.0\n",
      "filter_max_debt_eq: 1.5\n",
      "score_weight_rsi: 0.35\n",
      "score_weight_change: 0.35\n",
      "score_weight_rel_volume: 0.2\n",
      "score_weight_volatility: 0.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os # Assume df_data, df_cov are loaded pandas DataFrames\n",
    "\n",
    "# Set up logging\n",
    "# setup_logging(\"my_short_term_run_debug.log\")\n",
    "\n",
    "# --- RUN SELECTION ---\n",
    "# Note: No 'weighting_scheme' argument needed here as both are calculated\n",
    "df_selected_stocks, df_filtered, parameters_used = select_short_term_stocks_debug(\n",
    "    df_data=df_data,   # Your DataFrame with metrics\n",
    "    # df_cov=df_cov,     # Pass covariance matrix (might be used later for MinVar etc.)\n",
    "    n_select=10,\n",
    "    # Optional: Specify which column to use for IV weighting if not default 'Volatility M %'\n",
    "    # inv_vol_col_name='ATR/Price %',\n",
    "    # Optionally pass custom filters or scoring_weights dictionaries\n",
    "    # filters = {...},\n",
    "    # scoring_weights = {...}\n",
    ")\n",
    "\n",
    "# --- Display Results ---\n",
    "if not df_selected_stocks.empty:\n",
    "    print(\"\\nSelected Stocks (Detailed Output with Scores & Weights):\")\n",
    "    # Display more columns for context\n",
    "    display_cols = ['final_score', 'Weight_EW', 'Weight_IV', 'Weight_SW','RSI', 'Change %', 'Rel Volume', INV_VOL_COL]\n",
    "    # Ensure display_cols exist before trying to display them\n",
    "    display_cols = [col for col in display_cols if col in df_selected_stocks.columns]\n",
    "    print(df_selected_stocks[display_cols])\n",
    "\n",
    "    # You can now easily extract the weights for backtesting:\n",
    "    # weights_ew = df_selected_stocks[['Weight_EW']].rename(columns={'Weight_EW':'Weight'})\n",
    "    # weights_iv = df_selected_stocks[['Weight_IV']].rename(columns={'Weight_IV':'Weight'})\n",
    "else:\n",
    "    print(\"\\nNo stocks were selected.\")\n",
    "\n",
    "# --- Display Parameters Used ---\n",
    "print(\"\\nParameters Used for Selection:\")\n",
    "for k, v in parameters_used.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 18:19:12,997 - INFO - \n",
      "--- Attempting to Save Results ---\n",
      "2025-05-01 18:19:13,007 - INFO - Successfully saved selected stocks DataFrame to Parquet: output/selection_results/2025-04-28_my_selection_run_1.parquet\n",
      "2025-05-01 18:19:13,013 - INFO - Successfully saved selected stocks DataFrame to CSV: output/selection_results/2025-04-28_my_selection_run_1.csv\n",
      "2025-05-01 18:19:13,016 - INFO - Successfully saved parameters to JSON: output/selection_results/2025-04-28_my_selection_run_1_params.json\n",
      "2025-05-01 18:19:13,019 - INFO - \n",
      "--- Attempting to Load Results ---\n",
      "2025-05-01 18:19:13,041 - INFO - Successfully loaded DataFrame from Parquet: output/selection_results/2025-04-28_my_selection_run_1.parquet\n",
      "2025-05-01 18:19:13,044 - INFO - Successfully loaded parameters from JSON: output/selection_results/2025-04-28_my_selection_run_1_params.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved successfully for base path: output/selection_results/2025-04-28_my_selection_run_1\n",
      "\n",
      "Loaded DataFrame:\n",
      "        Change %   ROE %  Debt/Eq  Rel Volume  Avg Volume, M  ATR/Price %    Price     RSI   z_RSI  z_Change%  z_RelVolume  z_ATR/Price%  final_score  Weight_EW  Weight_IV  Weight_SW\n",
      "Ticker                                                                                                                                                                                \n",
      "AVTR     -3.4000 12.5200   0.6700      2.9000         8.9900       7.3659  12.4900 28.7500 -3.3756    -2.8988       6.3431        2.2806       3.2366     0.1000     0.0615     0.2004\n",
      "CART     -4.7500 12.6800   0.0100      1.1800         4.1700       4.6092  39.9200 45.1100 -0.9746    -3.9292       1.2042        0.2665       1.9305     0.1000     0.0983     0.1195\n",
      "KHC      -2.3100  5.5600   0.4200      1.7300        11.1400       2.7074  28.8100 43.1700 -1.2593    -2.0668       2.8474       -1.1231       1.8459     0.1000     0.1674     0.1143\n",
      "TMO      -0.6800 13.7500   0.6900      1.1200         2.2500       4.2199 421.3400 34.3300 -2.5567    -0.8227       1.0249       -0.0180       1.3896     0.1000     0.1074     0.0860\n",
      "UNH       0.3200 15.8800   0.8800      1.1100         5.9200       5.2262 420.0000 28.2500 -3.4490    -0.0594       0.9951        0.7173       1.3552     0.1000     0.0867     0.0839\n",
      "FI        0.2800 11.8800   1.1000      1.3600         3.6200       5.4092 178.0300 31.1200 -3.0278    -0.0899       1.7420        0.8510       1.3545     0.1000     0.0838     0.0839\n",
      "IR       -0.2400  8.4000   0.4900      2.4400         2.8900       4.1310  74.8000 48.3200 -0.5035    -0.4868       4.9687       -0.0829       1.3487     0.1000     0.1097     0.0835\n",
      "LKQ      -0.5300 11.3700   0.9500      1.0200         2.7600       4.0849  37.2100 34.9700 -2.4627    -0.7082       0.7262       -0.1166       1.2667     0.1000     0.1109     0.0784\n",
      "SPOT     -3.7000 28.9100   0.3600      1.5300         2.5600       5.3519 597.7300 55.6800  0.5767    -3.1278       2.2499        0.8091       1.2619     0.1000     0.0847     0.0781\n",
      "LYB      -1.2100  7.1900   1.0400      1.2500         3.6500       5.0579  58.7200 41.8200 -1.4574    -1.2272       1.4133        0.5943       1.1629     0.1000     0.0896     0.0720\n",
      "\n",
      "Loaded Parameters:\n",
      "{\n",
      "  \"n_select_requested\": 10,\n",
      "  \"n_select_actual\": 10,\n",
      "  \"inv_vol_col_name\": \"ATR/Price %\",\n",
      "  \"filter_min_price\": 10.0,\n",
      "  \"filter_min_avg_volume_m\": 2.0,\n",
      "  \"filter_min_roe_pct\": 5.0,\n",
      "  \"filter_max_debt_eq\": 1.5,\n",
      "  \"score_weight_rsi\": 0.35,\n",
      "  \"score_weight_change\": 0.35,\n",
      "  \"score_weight_rel_volume\": 0.2,\n",
      "  \"score_weight_volatility\": 0.1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import logging\n",
    "from typing import Tuple, Dict, Any, Optional\n",
    "\n",
    "# Assume logger is configured elsewhere, or configure basic here\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def save_selection_results(\n",
    "    df_selected: pd.DataFrame,\n",
    "    parameters_used: Dict[str, Any],\n",
    "    base_filepath: str,\n",
    "    save_csv: bool = False # Option to also save as CSV for inspection\n",
    "    ) -> bool:\n",
    "    \"\"\"\n",
    "    Saves the selected stocks DataFrame and parameters dictionary to files.\n",
    "\n",
    "    Saves DataFrame primarily as Parquet and parameters as JSON.\n",
    "    Optionally saves DataFrame as CSV as well.\n",
    "\n",
    "    Args:\n",
    "        df_selected (pd.DataFrame): The DataFrame containing selected stocks and details.\n",
    "        parameters_used (Dict[str, Any]): The flat dictionary of parameters used.\n",
    "        base_filepath (str): The base path and filename *without* extension.\n",
    "                            Example: 'results/selection_run_20231027'\n",
    "        save_csv (bool, optional): If True, also saves the DataFrame as a CSV file.\n",
    "                                  Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if all intended save operations were successful, False otherwise.\n",
    "    \"\"\"\n",
    "    success = True\n",
    "    parquet_file = f\"{base_filepath}.parquet\"\n",
    "    json_file = f\"{base_filepath}_params.json\"\n",
    "    csv_file = f\"{base_filepath}.csv\"\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    try:\n",
    "        output_dir = os.path.dirname(base_filepath)\n",
    "        if output_dir and not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "            logging.info(f\"Created output directory: {output_dir}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to create directory for {base_filepath}: {e}\")\n",
    "        return False # Cannot proceed if directory creation fails\n",
    "\n",
    "    # --- Save DataFrame as Parquet ---\n",
    "    try:\n",
    "        if not df_selected.empty:\n",
    "            df_selected.to_parquet(parquet_file, engine='pyarrow', compression='zstd', index=True)\n",
    "            logging.info(f\"Successfully saved selected stocks DataFrame to Parquet: {parquet_file}\")\n",
    "        else:\n",
    "            logging.warning(f\"Selected stocks DataFrame is empty. Parquet file not saved: {parquet_file}\")\n",
    "            # We might consider this a partial success depending on requirements\n",
    "            # Set success = False if saving an empty df isn't acceptable\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to save DataFrame to Parquet ({parquet_file}): {e}\")\n",
    "        success = False\n",
    "\n",
    "    # --- Optionally save DataFrame as CSV ---\n",
    "    if save_csv:\n",
    "        try:\n",
    "            if not df_selected.empty:\n",
    "                df_selected.to_csv(csv_file, index=True) # IMPORTANT: Save the index (Tickers)\n",
    "                logging.info(f\"Successfully saved selected stocks DataFrame to CSV: {csv_file}\")\n",
    "            else:\n",
    "                logging.warning(f\"Selected stocks DataFrame is empty. CSV file not saved: {csv_file}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to save DataFrame to CSV ({csv_file}): {e}\")\n",
    "            success = False # Treat failure to save optional CSV as overall failure if desired\n",
    "\n",
    "    # --- Save Parameters as JSON ---\n",
    "    try:\n",
    "        with open(json_file, 'w') as f:\n",
    "            json.dump(parameters_used, f, indent=4) # Use indent for readability\n",
    "        logging.info(f\"Successfully saved parameters to JSON: {json_file}\")\n",
    "    except TypeError as e:\n",
    "         logging.error(f\"Failed to serialize parameters to JSON ({json_file}). Check for non-serializable types: {e}\")\n",
    "         success = False\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to save parameters to JSON ({json_file}): {e}\")\n",
    "        success = False\n",
    "\n",
    "    return success\n",
    "\n",
    "\n",
    "def load_selection_results(\n",
    "    base_filepath: str\n",
    "    ) -> Tuple[Optional[pd.DataFrame], Optional[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Loads the selected stocks DataFrame and parameters dictionary from files.\n",
    "\n",
    "    Attempts to load DataFrame from Parquet first, then falls back to CSV if specified.\n",
    "    Loads parameters from JSON.\n",
    "\n",
    "    Args:\n",
    "        base_filepath (str): The base path and filename *without* extension,\n",
    "                            matching the one used in save_selection_results.\n",
    "                            Example: 'results/selection_run_20231027'\n",
    "\n",
    "    Returns:\n",
    "        Tuple[Optional[pd.DataFrame], Optional[Dict[str, Any]]]:\n",
    "            A tuple containing:\n",
    "            - The loaded DataFrame (or None if loading failed or file not found).\n",
    "            - The loaded parameters dictionary (or None if loading failed or file not found).\n",
    "    \"\"\"\n",
    "    df_selected = None\n",
    "    parameters_used = None\n",
    "\n",
    "    parquet_file = f\"{base_filepath}.parquet\"\n",
    "    json_file = f\"{base_filepath}_params.json\"\n",
    "    csv_file = f\"{base_filepath}.csv\" # For fallback\n",
    "\n",
    "    # --- Load DataFrame ---\n",
    "    # Prioritize Parquet\n",
    "    if os.path.exists(parquet_file):\n",
    "        try:\n",
    "            df_selected = pd.read_parquet(parquet_file, engine='pyarrow')\n",
    "            logging.info(f\"Successfully loaded DataFrame from Parquet: {parquet_file}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to load DataFrame from Parquet ({parquet_file}): {e}\")\n",
    "            # Optionally, try CSV here if Parquet fails to load but exists\n",
    "            # For now, we just log error and proceed to check CSV explicitly below\n",
    "\n",
    "    # Fallback to CSV if Parquet doesn't exist (or failed loading - though we don't explicitly retry here)\n",
    "    if df_selected is None and os.path.exists(csv_file):\n",
    "        logging.info(f\"Parquet file ({parquet_file}) not found or failed to load. Attempting to load from CSV: {csv_file}\")\n",
    "        try:\n",
    "            # IMPORTANT: Use index_col=0 to read the first column as the index\n",
    "            df_selected = pd.read_csv(csv_file, index_col=0)\n",
    "            logging.info(f\"Successfully loaded DataFrame from CSV: {csv_file}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to load DataFrame from CSV ({csv_file}): {e}\")\n",
    "    elif df_selected is None:\n",
    "        logging.warning(f\"Could not find Parquet ({parquet_file}) or CSV ({csv_file}) for DataFrame.\")\n",
    "\n",
    "\n",
    "    # --- Load Parameters from JSON ---\n",
    "    if os.path.exists(json_file):\n",
    "        try:\n",
    "            with open(json_file, 'r') as f:\n",
    "                parameters_used = json.load(f)\n",
    "            logging.info(f\"Successfully loaded parameters from JSON: {json_file}\")\n",
    "        except json.JSONDecodeError as e:\n",
    "            logging.error(f\"Failed to decode JSON from file ({json_file}): {e}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to load parameters from JSON ({json_file}): {e}\")\n",
    "    else:\n",
    "        logging.warning(f\"Parameters JSON file not found: {json_file}\")\n",
    "\n",
    "\n",
    "    # --- Final Check ---\n",
    "    if df_selected is None and parameters_used is None:\n",
    "        logging.error(f\"Failed to load both DataFrame and Parameters for base path: {base_filepath}\")\n",
    "\n",
    "    return df_selected, parameters_used\n",
    "\n",
    "\n",
    "\n",
    "# 1. Saving the results\n",
    "base_filename = f\"output/selection_results/{date_str}_my_selection_run_1\" # Example path/filename\n",
    "logging.info(f\"\\n--- Attempting to Save Results ---\")\n",
    "save_successful = save_selection_results(\n",
    "    df_selected=df_selected_stocks,\n",
    "    parameters_used=parameters_used,\n",
    "    base_filepath=base_filename,\n",
    "    save_csv=True # Also save CSV for checking\n",
    ")\n",
    "\n",
    "if save_successful:\n",
    "    print(f\"\\nResults saved successfully for base path: {base_filename}\")\n",
    "else:\n",
    "    print(f\"\\nSaving results failed for base path: {base_filename}\")\n",
    "\n",
    "\n",
    "# 2. Loading the results later\n",
    "logging.info(f\"\\n--- Attempting to Load Results ---\")\n",
    "loaded_df, loaded_params = load_selection_results(base_filename)\n",
    "\n",
    "if loaded_df is not None:\n",
    "    print(\"\\nLoaded DataFrame:\")\n",
    "    print(loaded_df)\n",
    "else:\n",
    "    print(\"\\nFailed to load DataFrame.\")\n",
    "\n",
    "if loaded_params is not None:\n",
    "    print(\"\\nLoaded Parameters:\")\n",
    "    print(json.dumps(loaded_params, indent=2)) # Pretty print loaded JSON\n",
    "else:\n",
    "    print(\"\\nFailed to load parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List, Optional\n",
    "\n",
    "def add_columns_from_source(\n",
    "    base_df: pd.DataFrame,\n",
    "    source_df: pd.DataFrame,\n",
    "    cols_to_add: List[str],\n",
    "    match_col_base: Optional[str] = None, # Default to None now\n",
    "    match_on_base_index: bool = False   # New flag to match on base index\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds specified columns from a source DataFrame to a base DataFrame,\n",
    "    placing the added columns to the left of the original base columns.\n",
    "\n",
    "    Rows are matched based on either a specified column in the base DataFrame\n",
    "    OR the index of the base DataFrame, against the *index* of the source\n",
    "    DataFrame.\n",
    "\n",
    "    Args:\n",
    "        base_df (pd.DataFrame):\n",
    "            The DataFrame to which the columns will be added.\n",
    "        source_df (pd.DataFrame):\n",
    "            The DataFrame containing the column data to add. Its index MUST\n",
    "            contain the keys for matching (e.g., Tickers).\n",
    "        cols_to_add (List[str]):\n",
    "            A list of string names of the columns in `source_df` to retrieve data from.\n",
    "        match_col_base (Optional[str], optional):\n",
    "            The string name of the column in `base_df` containing the keys\n",
    "            (e.g., Tickers) used for matching against the `source_df` index.\n",
    "            Required if `match_on_base_index` is False. Defaults to None.\n",
    "        match_on_base_index (bool, optional):\n",
    "            If True, use the index of `base_df` for matching against the\n",
    "            `source_df` index. If False (default), use the column specified\n",
    "            by `match_col_base`. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A new DataFrame, with the specified `cols_to_add` from\n",
    "                      `source_df` appearing first (on the left), followed by\n",
    "                      all columns from the original `base_df`.\n",
    "                      Values are mapped based on the specified matching criteria.\n",
    "                      Returns NaN for the added columns where no match is found.\n",
    "\n",
    "    Raises:\n",
    "        KeyError: If `match_on_base_index` is False and `match_col_base` is None\n",
    "                  or not in `base_df.columns`.\n",
    "                  If any column in `cols_to_add` is not in `source_df.columns`.\n",
    "        ValueError: If `cols_to_add` is empty, or if both `match_col_base`\n",
    "                    is provided and `match_on_base_index` is True (ambiguous).\n",
    "    \"\"\"\n",
    "    # --- Input validation ---\n",
    "    if not cols_to_add:\n",
    "        raise ValueError(\"The 'cols_to_add' list cannot be empty.\")\n",
    "\n",
    "    if match_on_base_index and match_col_base is not None:\n",
    "        raise ValueError(\"Cannot specify both 'match_col_base' and 'match_on_base_index=True'. Choose one matching method.\")\n",
    "    if not match_on_base_index and match_col_base is None:\n",
    "         raise ValueError(\"Must specify 'match_col_base' if 'match_on_base_index' is False.\")\n",
    "\n",
    "    if not match_on_base_index:\n",
    "        if match_col_base not in base_df.columns:\n",
    "            raise KeyError(f\"Matching column '{match_col_base}' not found in base_df columns: {base_df.columns.tolist()}\")\n",
    "        match_key_description = f\"column '{match_col_base}'\"\n",
    "    else:\n",
    "        match_key_description = \"index\" # For warning messages\n",
    "\n",
    "\n",
    "    missing_source_cols = [col for col in cols_to_add if col not in source_df.columns]\n",
    "    if missing_source_cols:\n",
    "        raise KeyError(f\"Columns to add {missing_source_cols} not found in source_df columns: {source_df.columns.tolist()}\")\n",
    "\n",
    "    # --- Perform the merge ---\n",
    "    # Select only the columns needed from the source to avoid unnecessary merging\n",
    "    source_subset = source_df[cols_to_add]\n",
    "\n",
    "    # Store original base columns for later reordering\n",
    "    original_base_columns = base_df.columns.tolist()\n",
    "\n",
    "    # Build arguments for pd.merge dynamically\n",
    "    merge_kwargs = {\n",
    "        'right': source_subset,\n",
    "        'right_index': True,      # Always merge on the source's index\n",
    "        'how': 'left',            # Keep all rows from base_df\n",
    "        'suffixes': ('', '_source') # Add suffix if col name conflict occurs\n",
    "    }\n",
    "\n",
    "    if match_on_base_index:\n",
    "        merge_kwargs['left_index'] = True # Use base_df's index\n",
    "    else:\n",
    "        merge_kwargs['left_on'] = match_col_base # Use specified base_df column\n",
    "\n",
    "    # Execute the merge\n",
    "    merged_df = pd.merge(\n",
    "        base_df,\n",
    "        **merge_kwargs\n",
    "    )\n",
    "\n",
    "    # --- Reorder columns ---\n",
    "    # Identify the actual names of the columns added (handling potential suffixes)\n",
    "    all_merged_cols = merged_df.columns.tolist()\n",
    "    # Columns are considered \"added\" if they were NOT in the original base_df\n",
    "    added_cols_actual_names = [col for col in all_merged_cols if col not in original_base_columns]\n",
    "\n",
    "    # Create the desired final column order\n",
    "    new_column_order = added_cols_actual_names + original_base_columns\n",
    "\n",
    "    # Apply the new order\n",
    "    # Use reindex to ensure all expected columns are present, handling potential edge cases\n",
    "    final_df = merged_df.reindex(columns=new_column_order)\n",
    "\n",
    "\n",
    "    # --- Optional: Add warnings for NaNs in added columns ---\n",
    "    # Use the actual names of the added columns after merge for checking\n",
    "    total_rows = len(final_df)\n",
    "    for col_name in added_cols_actual_names:\n",
    "        # Check if column exists (it should, due to reindex)\n",
    "        if col_name in final_df.columns:\n",
    "            num_nas = final_df[col_name].isna().sum()\n",
    "            if num_nas > 0:\n",
    "                print(f\"Warning: {num_nas}/{total_rows} entries for added column '{col_name}' are NaN.\")\n",
    "                if num_nas == total_rows:\n",
    "                     print(f\"   -> Check if values in the base_df {match_key_description} exist in the index of the source DataFrame.\")\n",
    "        else:\n",
    "             # This case should ideally not happen with the reindex approach\n",
    "             print(f\"Warning: Expected added column '{col_name}' was not found in the final reordered DataFrame.\")\n",
    "\n",
    "\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Result DataFrame (Multiple Columns - Success) ---\n",
      "                             Company                         Industry  Market Cap, M  Change %   ROE %  Debt/Eq  Rel Volume  Avg Volume, M  ATR/Price %    Price     RSI   z_RSI  z_Change%  z_RelVolume  z_ATR/Price%  final_score  Weight_EW  Weight_IV  Weight_SW\n",
      "Ticker                                                                                                                                                                                                                                                              \n",
      "AVTR                     Avantor Inc   Medical Instruments & Supplies      8510.0000   -3.4000 12.5200   0.6700      2.9000         8.9900       7.3659  12.4900 28.7500 -3.3756    -2.8988       6.3431        2.2806       3.2366     0.1000     0.0615     0.2004\n",
      "CART                   Maplebear Inc                  Internet Retail     10480.0000   -4.7500 12.6800   0.0100      1.1800         4.1700       4.6092  39.9200 45.1100 -0.9746    -3.9292       1.2042        0.2665       1.9305     0.1000     0.0983     0.1195\n",
      "KHC                   Kraft Heinz Co                   Packaged Foods     34430.0000   -2.3100  5.5600   0.4200      1.7300        11.1400       2.7074  28.8100 43.1700 -1.2593    -2.0668       2.8474       -1.1231       1.8459     0.1000     0.1674     0.1143\n",
      "TMO     Thermo Fisher Scientific Inc           Diagnostics & Research    159050.0000   -0.6800 13.7500   0.6900      1.1200         2.2500       4.2199 421.3400 34.3300 -2.5567    -0.8227       1.0249       -0.0180       1.3896     0.1000     0.1074     0.0860\n",
      "UNH           Unitedhealth Group Inc                 Healthcare Plans    384180.0000    0.3200 15.8800   0.8800      1.1100         5.9200       5.2262 420.0000 28.2500 -3.4490    -0.0594       0.9951        0.7173       1.3552     0.1000     0.0867     0.0839\n",
      "FI                       Fiserv, Inc  Information Technology Services     99440.0000    0.2800 11.8800   1.1000      1.3600         3.6200       5.4092 178.0300 31.1200 -3.0278    -0.0899       1.7420        0.8510       1.3545     0.1000     0.0838     0.0839\n",
      "IR                Ingersoll-Rand Inc   Specialty Industrial Machinery     30150.0000   -0.2400  8.4000   0.4900      2.4400         2.8900       4.1310  74.8000 48.3200 -0.5035    -0.4868       4.9687       -0.0829       1.3487     0.1000     0.1097     0.0835\n",
      "LKQ                         LKQ Corp                       Auto Parts      9610.0000   -0.5300 11.3700   0.9500      1.0200         2.7600       4.0849  37.2100 34.9700 -2.4627    -0.7082       0.7262       -0.1166       1.2667     0.1000     0.1109     0.0784\n",
      "SPOT          Spotify Technology S.A   Internet Content & Information    120010.0000   -3.7000 28.9100   0.3600      1.5300         2.5600       5.3519 597.7300 55.6800  0.5767    -3.1278       2.2499        0.8091       1.2619     0.1000     0.0847     0.0781\n",
      "LYB     LyondellBasell Industries NV              Specialty Chemicals     18960.0000   -1.2100  7.1900   1.0400      1.2500         3.6500       5.0579  58.7200 41.8200 -1.4574    -1.2272       1.4133        0.5943       1.1629     0.1000     0.0896     0.0720\n"
     ]
    }
   ],
   "source": [
    "cols_to_add = ['Company', 'Industry', 'Market Cap, M']\n",
    "new_df_multiple_success = add_columns_from_source(\n",
    "    base_df=df_selected_stocks, # Use the DataFrame from previous selection\n",
    "    source_df=df_data,\n",
    "    cols_to_add=cols_to_add,\n",
    "    match_on_base_index=True # <-- Tell the function to use base_df's index\n",
    ")\n",
    "print(\"\\n--- Result DataFrame (Multiple Columns - Success) ---\")\n",
    "print(new_df_multiple_success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_filtered.columns:\n",
      "Index(['No.', 'Company', 'Index', 'Sector', 'Industry', 'Country', 'Exchange', 'Market Cap, M', 'P/E', 'Fwd P/E',\n",
      "       ...\n",
      "       'Omega 30d', 'Sharpe 60d', 'Sortino 60d', 'Omega 60d', 'Sharpe 120d', 'Sortino 120d', 'Omega 120d', 'Sharpe 250d', 'Sortino 250d', 'Omega 250d'], dtype='object', length=136)\n"
     ]
    }
   ],
   "source": [
    "print(f\"df_filtered.columns:\\n{df_filtered.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Ticker: CART\n"
     ]
    }
   ],
   "source": [
    "# Get a ticker from the selected stocks\n",
    "selected_ticker = df_selected_stocks.index[1]\n",
    "print(f\"Selected Ticker: {selected_ticker}\")  # This should print the ticker name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "verification_calc = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated CART RSI: 45.1100\n",
      "Calculated RSI Mean: 51.7505\n",
      "Calculated RSI Std Dev: 6.8138\n",
      "Calulated CART RSI Z-Score: -0.9746\n",
      "\n",
      "df_selected_stocks.loc[selected_ticker, 'z_RSI']: -0.9746\n"
     ]
    }
   ],
   "source": [
    "# Get selected ticker's RSI value\n",
    "selected_ticker_rsi = df_filtered.loc[selected_ticker, 'RSI']\n",
    "\n",
    "# Calculate mean and std of RSI for all stocks\n",
    "rsi_mean = df_filtered['RSI'].mean()\n",
    "# Use population standard deviation (ddof=0) to match scipy.stats.zscore default\n",
    "rsi_std = df_filtered['RSI'].std(ddof=0) # <--- CHANGE MADE HERE\n",
    "\n",
    "# Calculate z-score\n",
    "z_rsi = (selected_ticker_rsi - rsi_mean) / rsi_std\n",
    "\n",
    "# Store results in verification_calc dictionary as standard Python float\n",
    "verification_calc['rsi'] =  float(z_rsi)\n",
    "\n",
    "print(f\"Calculated {selected_ticker} RSI: {selected_ticker_rsi:.4f}\")\n",
    "print(f\"Calculated RSI Mean: {rsi_mean:.4f}\")\n",
    "print(f\"Calculated RSI Std Dev: {rsi_std:.4f}\")\n",
    "print(f\"Calulated {selected_ticker} RSI Z-Score: {z_rsi:.4f}\")\n",
    "\n",
    "print(f\"\\ndf_selected_stocks.loc[selected_ticker, 'z_RSI']: {df_selected_stocks.loc[selected_ticker, 'z_RSI']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated CART Change %: -4.7500\n",
      "Calculated Change % Mean: 0.3978\n",
      "Calculated Change % Std Dev: 1.3101\n",
      "Calulated CART Change % Z-Score: -3.9292\n",
      "\n",
      "df_selected_stocks.loc[selected_ticker, 'z_Change%']: -3.9292\n"
     ]
    }
   ],
   "source": [
    "# Get selected ticker's 'Change %' value\n",
    "selected_ticker_change = df_filtered.loc[selected_ticker, 'Change %']\n",
    "\n",
    "# Calculate mean and std of change for all stocks\n",
    "change_mean = df_filtered['Change %'].mean()\n",
    "change_std = df_filtered['Change %'].std(ddof=0)\n",
    "\n",
    "# Calculate z-score\n",
    "z_change = (selected_ticker_change - change_mean) / change_std\n",
    "\n",
    "# Store results in verification_calc dictionary as standard Python float\n",
    "verification_calc['change'] =  float(z_change) \n",
    "\n",
    "print(f\"Calculated {selected_ticker} Change %: {selected_ticker_change:.4f}\")\n",
    "print(f\"Calculated Change % Mean: {change_mean:.4f}\")\n",
    "print(f\"Calculated Change % Std Dev: {change_std:.4f}\")\n",
    "print(f\"Calulated {selected_ticker} Change % Z-Score: {z_change:.4f}\")\n",
    "\n",
    "print(f\"\\ndf_selected_stocks.loc[selected_ticker, 'z_Change%']: {df_selected_stocks.loc[selected_ticker, 'z_Change%']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated CART Rel Volume: 1.1800\n",
      "Calculated Rel Volume Mean: 0.7770\n",
      "Calculated Rel Volume Std Dev: 0.3347\n",
      "Calulated CART Rel Volume Z-Score: 1.2042\n",
      "\n",
      "df_selected_stocks.loc[selected_ticker, 'z_RelVolume']: 1.2042\n"
     ]
    }
   ],
   "source": [
    "# Get selected ticker's Rel Volume value\n",
    "selected_ticker_rsi = df_filtered.loc[selected_ticker, 'Rel Volume']\n",
    "\n",
    "# Calculate mean and std of Rel Volume for all stocks\n",
    "rel_vol_mean = df_filtered['Rel Volume'].mean()\n",
    "rel_vol_std = df_filtered['Rel Volume'].std(ddof=0)\n",
    "\n",
    "# Calculate z-score\n",
    "z_rel_vol = (selected_ticker_rsi - rel_vol_mean) / rel_vol_std\n",
    "\n",
    "# Store results in verification_calc dictionary as standard Python float\n",
    "verification_calc['rel_volume'] =  float(z_rel_vol)  \n",
    "\n",
    "print(f\"Calculated {selected_ticker} Rel Volume: {selected_ticker_rsi:.4f}\")\n",
    "print(f\"Calculated Rel Volume Mean: {rel_vol_mean:.4f}\")\n",
    "print(f\"Calculated Rel Volume Std Dev: {rel_vol_std:.4f}\")\n",
    "print(f\"Calulated {selected_ticker} Rel Volume Z-Score: {z_rel_vol:.4f}\")\n",
    "\n",
    "print(f\"\\ndf_selected_stocks.loc[selected_ticker, 'z_RelVolume']: {df_selected_stocks.loc[selected_ticker, 'z_RelVolume']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated CART ATR/Price %: 4.6092\n",
      "Calculated ATR/Price % Mean: 4.2445\n",
      "Calculated ATR/Price % Std Dev: 1.3686\n",
      "Calulated CART ATR/Price % Z-Score: 0.2665\n",
      "\n",
      "df_selected_stocks.loc[selected_ticker, 'z_ATR/Price%']: 0.2665\n"
     ]
    }
   ],
   "source": [
    "# Get selected ticker's 'ATR/Price %' value\n",
    "selected_ticker_ATR_Price = df_filtered.loc[selected_ticker, 'ATR/Price %']\n",
    "\n",
    "# Calculate mean and std of ATR_Price for all stocks\n",
    "ATR_Price_mean = df_filtered['ATR/Price %'].mean()\n",
    "ATR_Price_std = df_filtered['ATR/Price %'].std(ddof=0)\n",
    "\n",
    "# Calculate z-score\n",
    "z_atr_price = (selected_ticker_ATR_Price - ATR_Price_mean) / ATR_Price_std\n",
    "\n",
    "# Store results in verification_calc dictionary as standard Python float\n",
    "verification_calc['volatility'] =  float(z_atr_price)\n",
    "\n",
    "print(f\"Calculated {selected_ticker} ATR/Price %: {selected_ticker_ATR_Price:.4f}\")\n",
    "print(f\"Calculated ATR/Price % Mean: {ATR_Price_mean:.4f}\")\n",
    "print(f\"Calculated ATR/Price % Std Dev: {ATR_Price_std:.4f}\")\n",
    "print(f\"Calulated {selected_ticker} ATR/Price % Z-Score: {z_atr_price:.4f}\")\n",
    "\n",
    "print(f\"\\ndf_selected_stocks.loc[selected_ticker, 'z_ATR/Price%']: {df_selected_stocks.loc[selected_ticker, 'z_ATR/Price%']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORING_WEIGHTS: {'rsi': 0.35, 'change': 0.35, 'rel_volume': 0.2, 'volatility': 0.1}\n",
      "verification_calc: {'rsi': -0.9745777521443242, 'change': -3.9292181608942878, 'rel_volume': 1.2041964089109138, 'volatility': 0.26646485850838075}\n"
     ]
    }
   ],
   "source": [
    "print(f'SCORING_WEIGHTS: {SCORING_WEIGHTS}')\n",
    "print(f'verification_calc: {verification_calc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Score Verification Calculation: 1.9305\n",
      "\n",
      "df_selected_stocks.loc[selected_ticker, 'final_score']: 1.9305\n"
     ]
    }
   ],
   "source": [
    "final_score_verification_calc = (\n",
    "    verification_calc['rsi'] * SCORING_WEIGHTS['rsi'] * (-1) +              # Lower RSI -> Higher Score\n",
    "    verification_calc['change'] * SCORING_WEIGHTS['change'] * (-1) +        # Lower Change% -> Higher Score\n",
    "    verification_calc['rel_volume'] * SCORING_WEIGHTS['rel_volume'] * (1) + # Higher RelVol -> Higher Score\n",
    "    verification_calc['volatility'] * SCORING_WEIGHTS['volatility'] * (-1)  # Lower ATR/Price% -> Higher Score\n",
    ")\n",
    "\n",
    "print(f\"Final Score Verification Calculation: {final_score_verification_calc:.4f}\")\n",
    "print(f\"\\ndf_selected_stocks.loc[selected_ticker, 'final_score']: {df_selected_stocks.loc[selected_ticker, 'final_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np # Will be used if we need to handle potential infinite values if any\n",
    "\n",
    "# --- IMPORTANT ---\n",
    "# Ensure your DataFrame is named df_data and contains the columns used below.\n",
    "# Example: (replace this with your actual data loading)\n",
    "# df_data = pd.read_csv('your_market_data.csv')\n",
    "\n",
    "# --- Data Cleaning (Optional but Recommended) ---\n",
    "# Replace potential infinite values with NaN\n",
    "df_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "# Use a copy to avoid modifying original if needed later\n",
    "df_plot = df_data.copy()\n",
    "\n",
    "# --- Font Size Definitions ---\n",
    "SCALE_FONTSIZE = 1.2  # Scale factor for font sizes\n",
    "TITLE_FONTSIZE = 18 * SCALE_FONTSIZE\n",
    "AXIS_LABEL_FONTSIZE = 14 * SCALE_FONTSIZE\n",
    "TICK_LABEL_FONTSIZE = 12 * SCALE_FONTSIZE\n",
    "LEGEND_FONTSIZE = 12 * SCALE_FONTSIZE\n",
    "SUPTITLE_FONTSIZE = 22 * SCALE_FONTSIZE\n",
    "\n",
    "# --- Visualization ---\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid') # Use a visually appealing style\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 14)) # Increased figure size slightly for larger text\n",
    "fig.suptitle('Visualizing Market Bifurcation Indicators (Larger Text)', fontsize=SUPTITLE_FONTSIZE, y=1.03) # Adjusted y position slightly\n",
    "\n",
    "# 1. Histogram of Yearly Performance ('Perf Year %')\n",
    "sns.histplot(data=df_plot, x='Perf Year %', kde=True, ax=axes[0, 0], bins=50)\n",
    "axes[0, 0].set_title('Distribution of Yearly Performance (%)', fontsize=TITLE_FONTSIZE)\n",
    "axes[0, 0].set_xlabel('Perf Year %', fontsize=AXIS_LABEL_FONTSIZE)\n",
    "axes[0, 0].set_ylabel('Frequency', fontsize=AXIS_LABEL_FONTSIZE) # Added y-axis label\n",
    "axes[0, 0].tick_params(axis='both', which='major', labelsize=TICK_LABEL_FONTSIZE)\n",
    "median_val = df_plot['Perf Year %'].median()\n",
    "mean_val = df_plot['Perf Year %'].mean()\n",
    "axes[0, 0].axvline(median_val, color='red', linestyle='--', label=f'Median: {median_val:.2f}%')\n",
    "axes[0, 0].axvline(mean_val, color='orange', linestyle=':', label=f'Mean: {mean_val:.2f}%')\n",
    "axes[0, 0].legend(fontsize=LEGEND_FONTSIZE)\n",
    "\n",
    "# 2. Histogram of Normalized Volatility ('ATR/Price %')\n",
    "sns.histplot(data=df_plot, x='ATR/Price %', kde=True, ax=axes[0, 1], bins=50)\n",
    "axes[0, 1].set_title('Distribution of Normalized Daily Volatility (ATR/Price %)', fontsize=TITLE_FONTSIZE)\n",
    "axes[0, 1].set_xlabel('ATR/Price %', fontsize=AXIS_LABEL_FONTSIZE)\n",
    "axes[0, 1].set_ylabel('Frequency', fontsize=AXIS_LABEL_FONTSIZE) # Added y-axis label\n",
    "axes[0, 1].tick_params(axis='both', which='major', labelsize=TICK_LABEL_FONTSIZE)\n",
    "median_val = df_plot['ATR/Price %'].median()\n",
    "mean_val = df_plot['ATR/Price %'].mean()\n",
    "axes[0, 1].axvline(median_val, color='red', linestyle='--', label=f'Median: {median_val:.2f}%')\n",
    "axes[0, 1].axvline(mean_val, color='orange', linestyle=':', label=f'Mean: {mean_val:.2f}%')\n",
    "axes[0, 1].legend(fontsize=LEGEND_FONTSIZE)\n",
    "\n",
    "# 3. Scatter Plot: Yearly Performance vs. Normalized Volatility\n",
    "sns.scatterplot(data=df_plot, x='ATR/Price %', y='Perf Year %', ax=axes[1, 0], alpha=0.5, s=25) # Slightly larger points\n",
    "axes[1, 0].set_title('Yearly Performance vs. Daily Volatility', fontsize=TITLE_FONTSIZE)\n",
    "axes[1, 0].set_xlabel('ATR/Price % (Daily Volatility)', fontsize=AXIS_LABEL_FONTSIZE)\n",
    "axes[1, 0].set_ylabel('Perf Year %', fontsize=AXIS_LABEL_FONTSIZE)\n",
    "axes[1, 0].tick_params(axis='both', which='major', labelsize=TICK_LABEL_FONTSIZE)\n",
    "\n",
    "# 4. Scatter Plot: Yearly Performance vs. Distance from 200-Day MA\n",
    "sns.scatterplot(data=df_plot, x='SMA200 %', y='Perf Year %', ax=axes[1, 1], alpha=0.5, s=25) # Slightly larger points\n",
    "axes[1, 1].set_title('Yearly Performance vs. Position Relative to 200-Day MA', fontsize=TITLE_FONTSIZE)\n",
    "axes[1, 1].set_xlabel('Price vs SMA200 (%)', fontsize=AXIS_LABEL_FONTSIZE)\n",
    "axes[1, 1].set_ylabel('Perf Year %', fontsize=AXIS_LABEL_FONTSIZE)\n",
    "axes[1, 1].tick_params(axis='both', which='major', labelsize=TICK_LABEL_FONTSIZE)\n",
    "axes[1, 1].axvline(0, color='grey', linestyle='--') # Line at 0% (on the SMA200)\n",
    "axes[1, 1].axhline(0, color='grey', linestyle='--') # Line at 0% Perf Year\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.97]) # Adjust layout slightly for suptitle\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
