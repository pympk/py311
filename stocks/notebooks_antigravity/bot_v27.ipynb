{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9ae2708",
   "metadata": {},
   "source": [
    "# Here is the refactored solution. I have separated the concerns into three distinct layers:\n",
    "1.  **The Data Contract:** explicit `dataclasses` defining exactly what goes in and comes out.\n",
    "2.  **The Engine:** A purely mathematical class (`AlphaEngine`) containing the logic, with no widget/plotting dependencies.\n",
    "3.  **The UI:** A cleaned-up dashboard function that simply sends inputs to the Engine and visualizes the Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc79d79",
   "metadata": {},
   "source": [
    "### Following is the reverse chronological fix log (most recent entry is at the top )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68b1a41",
   "metadata": {},
   "source": [
    "```\n",
    "To see the full dataframe of all tickers (both those that passed and those that failed) for a specific date, we need to capture a snapshot of the universe inside the `_get_eligible_universe` method.\n",
    "\n",
    "I have updated the **`AlphaEngine`** class below.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30d1f60",
   "metadata": {},
   "source": [
    "```\n",
    "To verify that the relative percentile logic is working, we can modify the `AlphaEngine` to report exactly **how the cutoff was calculated** for the specific start date.\n",
    "\n",
    "We want to see evidence that:\n",
    "1.  In earlier years (e.g., 2005), the volume cutoff is lower (e.g., $200k).\n",
    "2.  In later years (e.g., 2024), the volume cutoff is higher (e.g., $5M).\n",
    "\n",
    "Here is the updated `AlphaEngine` and `UI` code. I have added a **\"Audit Log\"** feature. When you run the tool, it will now print exactly what the Dollar Volume Threshold was for that specific day.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50de4e99",
   "metadata": {},
   "source": [
    "```\n",
    "The best way to solve this is to switch from a **Fixed Dollar Threshold** (e.g., \"$1 Million\") to a **Relative Percentile Threshold** (e.g., \"Top 50% of the market\").\n",
    "\n",
    "In 2004, a stock trading $200k might have been in the top 50% of liquid stocks. In 2024, that same $200k is illiquid garbage. Using a percentile automatically adjusts for inflation and market growth over time.\n",
    "\n",
    "Here is how to modify your code to support this.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e8a3b9",
   "metadata": {},
   "source": [
    "```\n",
    "To fix this, we need to pass the **actual** calculated start date (the trading day the engine \"snapped\" to) back from the `AlphaEngine` to the UI. Then, the UI can compare the *Requested Date* vs. the *Actual Date* and display the warning message if they differ.\n",
    "\n",
    "Here is the plan:\n",
    "1.  **Update `EngineOutput`**: Add a `start_date` field to the dataclass.\n",
    "2.  **Update `AlphaEngine.run`**: Populate this new field with `safe_start_date`.\n",
    "3.  **Update `plot_walk_forward_analyzer`**: Add logic to compare the user's input date with the engine's returned date and print the \"Info\" message if they are different.\n",
    "\n",
    "Here is the updated code (Sections C, D, and E have changed):\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb918f61",
   "metadata": {},
   "source": [
    "```\n",
    "I have updated the `AlphaEngine.run` method. specifically inside the `if inputs.mode == 'Manual List':` block. It now iterates through every manual ticker and performs two checks:\n",
    "1.  **Existence**: Is the ticker in the database?\n",
    "2.  **Availability**: Does the ticker have a valid price on the specific `Start Date`?\n",
    "\n",
    "If any ticker fails, it compiles a specific error message explaining why (e.g., \"No price data on start date\") and aborts the calculation immediately.  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b728a8",
   "metadata": {},
   "source": [
    "```\n",
    "The `snapshot_df` contains **every single feature** calculated by your `generate_features` function for that specific day, plus the new audit columns we added.\n",
    "\n",
    "Here is exactly what is inside that DataFrame:\n",
    "\n",
    "### 1. The Core Features (from `generate_features`)\n",
    "*   **`TR`**: True Range\n",
    "*   **`ATR`**: Average True Range\n",
    "*   **`ATRP`**: Average True Range Percent (Volatility)\n",
    "*   **`RollingStalePct`**: How often the price didn't move or volume was 0.\n",
    "*   **`RollMedDollarVol`**: Median Daily Dollar Volume (Liquidity).\n",
    "*   **`RollingSameVolCount`**: Data quality check for repeated volume numbers.\n",
    "\n",
    "### 2. The Audit Columns (Added during filtering)\n",
    "*   **`Calculated_Cutoff`**: The specific dollar amount required to pass on that day.\n",
    "*   **`Passed_Vol_Check`**: `True` if the ticker met the liquidity requirement.\n",
    "*   **`Passed_Final`**: `True` if it passed **all** checks (Liquidity + Stale + Quality).\n",
    "\n",
    "=========================================\n",
    "\n",
    "Here are the formulas translated directly into the Python `pandas` code used in your `generate_features` function.\n",
    "\n",
    "I have simplified the code slightly to assume a single ticker context (removing the `groupby` wrapper) so you can see the raw math clearly.\n",
    "\n",
    "### 1. True Range (TR)\n",
    "Calculates the maximum of the three price differences.\n",
    "\n",
    "prev_close = df_ohlcv['Adj Close'].shift(1)\n",
    "\n",
    "# The three components\n",
    "diff1 = df_ohlcv['Adj High'] - df_ohlcv['Adj Low']\n",
    "diff2 = (df_ohlcv['Adj High'] - prev_close).abs()\n",
    "diff3 = (df_ohlcv['Adj Low'] - prev_close).abs()\n",
    "\n",
    "# Taking the max of the three\n",
    "tr = pd.concat([diff1, diff2, diff3], axis=1).max(axis=1)\n",
    "\n",
    "### 2. Average True Range (ATR)\n",
    "Uses an Exponential Weighted Mean (EWM) with a specific alpha smoothing factor.\n",
    "\n",
    "# N = atr_period (e.g., 14)\n",
    "# alpha = 1 / N\n",
    "atr = tr.ewm(alpha=1/14, adjust=False).mean()\n",
    "\n",
    "### 3. ATR Percent (ATRP)\n",
    "Simple division to normalize volatility.\n",
    "\n",
    "atrp = atr / df_ohlcv['Adj Close']\n",
    "\n",
    "### 4. Rolling Stale Percentage\n",
    "Checks if volume is 0 OR if High equals Low (price didn't move), then averages that 1 or 0 signal over the window.\n",
    "\n",
    "# 1. Define the Stale Signal (1 for stale, 0 for active)\n",
    "is_stale = np.where(\n",
    "    (df_ohlcv['Volume'] == 0) | (df_ohlcv['Adj High'] == df_ohlcv['Adj Low']), \n",
    "    1,  \n",
    "    0\n",
    ")\n",
    "\n",
    "# 2. Calculate average over window (W=252)\n",
    "rolling_stale_pct = pd.Series(is_stale).rolling(window=252).mean()\n",
    "\n",
    "### 5. Rolling Median Dollar Volume\n",
    "Calculates raw dollar volume, then finds the median over the window.\n",
    "\n",
    "# 1. Calculate Daily Dollar Volume\n",
    "dollar_volume = df_ohlcv['Adj Close'] * df_ohlcv['Volume']\n",
    "\n",
    "# 2. Get Median over window (W=252)\n",
    "roll_med_dollar_vol = dollar_volume.rolling(window=252).median()\n",
    "\n",
    "### 6. Rolling Same Volume Count\n",
    "Checks if today's volume is exactly the same as yesterday's (a sign of bad data), then sums those occurrences.\n",
    "\n",
    "# 1. Check if Volume(t) - Volume(t-1) equals 0\n",
    "# .diff() calculates current row minus previous row\n",
    "has_same_volume = (df_ohlcv['Volume'].diff() == 0).astype(int)\n",
    "\n",
    "# 2. Sum the errors over window (W=252)\n",
    "rolling_same_vol_count = has_same_volume.rolling(window=252).sum()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1110f2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Optional, Any\n",
    "from collections import Counter\n",
    "import pprint\n",
    "from datetime import datetime, date\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION A: CORE HELPER FUNCTIONS & FEATURE GENERATION\n",
    "# (Unchanged from previous version)\n",
    "# ==============================================================================\n",
    "# ... (Keep generate_features, calculate_gain, calculate_sharpe, \n",
    "#      calculate_sharpe_atr, calculate_buy_and_hold_performance as is) ...\n",
    "\n",
    "def generate_features(df_ohlcv: pd.DataFrame, atr_period: int = 14, quality_window: int = 252, quality_min_periods: int = 126) -> pd.DataFrame:\n",
    "    # (Same as before)\n",
    "    if not df_ohlcv.index.is_monotonic_increasing: df_ohlcv = df_ohlcv.sort_index()\n",
    "    grouped = df_ohlcv.groupby(level='Ticker')\n",
    "    prev_close = grouped['Adj Close'].shift(1)\n",
    "    tr = pd.concat([df_ohlcv['Adj High'] - df_ohlcv['Adj Low'], abs(df_ohlcv['Adj High'] - prev_close), abs(df_ohlcv['Adj Low'] - prev_close)], axis=1).max(axis=1, skipna=False)\n",
    "    atr = tr.groupby(level='Ticker').transform(lambda x: x.ewm(alpha=1/atr_period, adjust=False).mean())\n",
    "    atrp = (atr / df_ohlcv['Adj Close']).replace([np.inf, -np.inf], np.nan)\n",
    "    indicator_df = pd.DataFrame({'TR': tr, 'ATR': atr, 'ATRP': atrp})\n",
    "    quality_temp_df = pd.DataFrame({'IsStale': np.where((df_ohlcv['Volume'] == 0) | (df_ohlcv['Adj High'] == df_ohlcv['Adj Low']), 1, 0), 'DollarVolume': df_ohlcv['Adj Close'] * df_ohlcv['Volume'], 'HasSameVolume': (grouped['Volume'].diff() == 0).astype(int)}, index=df_ohlcv.index)\n",
    "    rolling_result = quality_temp_df.groupby(level='Ticker').rolling(window=quality_window, min_periods=quality_min_periods).agg({'IsStale': 'mean', 'DollarVolume': 'median', 'HasSameVolume': 'sum'}).rename(columns={'IsStale': 'RollingStalePct', 'DollarVolume': 'RollMedDollarVol', 'HasSameVolume': 'RollingSameVolCount'}).reset_index(level=0, drop=True)\n",
    "    return pd.concat([indicator_df, rolling_result], axis=1)\n",
    "\n",
    "def calculate_gain(price_series): \n",
    "    if price_series.dropna().shape[0] < 2: return np.nan\n",
    "    return (price_series.ffill().iloc[-1] / price_series.bfill().iloc[0]) - 1\n",
    "\n",
    "def calculate_sharpe(return_series):\n",
    "    if return_series.dropna().shape[0] < 2: return np.nan\n",
    "    std = return_series.std()\n",
    "    return (return_series.mean() / std * np.sqrt(252)) if std > 0 else 0.0\n",
    "\n",
    "def calculate_sharpe_atr(return_series, atrp_series):\n",
    "    if return_series.dropna().shape[0] < 2 or atrp_series.dropna().empty: return np.nan\n",
    "    mean_atrp = atrp_series.mean()\n",
    "    return (return_series.mean() / mean_atrp) if mean_atrp > 0 else 0.0\n",
    "\n",
    "def calculate_buy_and_hold_performance(df_close, features_df, tickers, start_date, end_date):\n",
    "    if not tickers: return pd.Series(dtype=float), pd.Series(dtype=float), pd.Series(dtype=float)\n",
    "    ticker_counts = Counter(tickers)\n",
    "    initial_weights = pd.Series({t: c / len(tickers) for t, c in ticker_counts.items()})\n",
    "    prices_raw = df_close[initial_weights.index.tolist()].loc[start_date:end_date]\n",
    "    if prices_raw.dropna(how='all').empty: return pd.Series(dtype=float), pd.Series(dtype=float), pd.Series(dtype=float)\n",
    "    prices_norm = prices_raw.div(prices_raw.bfill().iloc[0])\n",
    "    weighted_growth = prices_norm.mul(initial_weights, axis='columns')\n",
    "    value_series = weighted_growth.sum(axis=1)\n",
    "    return_series = value_series.pct_change()\n",
    "    full_idx = pd.MultiIndex.from_product([initial_weights.index.tolist(), return_series.index], names=['Ticker', 'Date'])\n",
    "    feat_subset = features_df.reindex(full_idx)['ATRP'].unstack(level='Ticker')\n",
    "    atrp_series = (weighted_growth.div(value_series, axis='index').align(feat_subset, join='inner', axis=1)[0] * weighted_growth.div(value_series, axis='index').align(feat_subset, join='inner', axis=1)[1]).sum(axis=1)\n",
    "    return value_series, return_series, atrp_series\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION B: METRIC REGISTRY\n",
    "# ==============================================================================\n",
    "\n",
    "def metric_price(d): return calculate_gain(d['calc_close'])\n",
    "def metric_sharpe(d): \n",
    "    r = d['daily_returns']\n",
    "    return (r.mean() / r.std() * np.sqrt(252)).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "def metric_sharpe_atr(d):\n",
    "    return (d['daily_returns'].mean() / d['atrp']).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "METRIC_REGISTRY = {\n",
    "    'Price': metric_price,\n",
    "    'Sharpe': metric_sharpe,\n",
    "    'Sharpe (ATR)': metric_sharpe_atr,\n",
    "}\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION C: DATA CONTRACTS (The API)\n",
    "# Updated EngineOutput to include actual start_date\n",
    "# ==============================================================================\n",
    "\n",
    "@dataclass\n",
    "class EngineInput:\n",
    "    mode: str\n",
    "    start_date: pd.Timestamp\n",
    "    calc_period: int\n",
    "    fwd_period: int\n",
    "    metric: str\n",
    "    benchmark_ticker: str\n",
    "    rank_start: int = 1\n",
    "    rank_end: int = 10\n",
    "    quality_thresholds: Dict[str, float] = field(default_factory=lambda: {'min_median_dollar_volume': 1_000_000, 'max_stale_pct': 0.05, 'max_same_vol_count': 10})\n",
    "    manual_tickers: List[str] = field(default_factory=list)\n",
    "    debug: bool = False\n",
    "\n",
    "@dataclass\n",
    "class EngineOutput:\n",
    "    portfolio_series: pd.Series\n",
    "    benchmark_series: pd.Series\n",
    "    normalized_plot_data: pd.DataFrame\n",
    "    tickers: List[str]\n",
    "    initial_weights: pd.Series\n",
    "    perf_metrics: Dict[str, float]\n",
    "    results_df: pd.DataFrame\n",
    "    start_date: pd.Timestamp # <--- NEW FIELD: The actual trading start date used\n",
    "    calc_end_date: pd.Timestamp\n",
    "    viz_end_date: pd.Timestamp\n",
    "    error_msg: Optional[str] = None\n",
    "    debug_data: Optional[Dict[str, Any]] = None\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION D: THE ALPHA ENGINE (The \"Brain\")\n",
    "# This version saves a sorted dataframe called `universe_snapshot` into the debug data. It adds columns showing exactly which tickers passed or failed the specific thresholds.\n",
    "# ==============================================================================\n",
    "\n",
    "class AlphaEngine:\n",
    "    def __init__(self, df_ohlcv: pd.DataFrame, master_ticker: str = 'SPY'):\n",
    "        print(\"--- \u2699\ufe0f Initializing AlphaEngine ---\")\n",
    "        self.features_df = generate_features(df_ohlcv)\n",
    "        print(\"Optimizing data structures...\")\n",
    "        self.df_close = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "        \n",
    "        if master_ticker not in self.df_close.columns:\n",
    "            master_ticker = self.df_close.columns[0]\n",
    "            print(f\"Warning: Master ticker not found. Using {master_ticker}\")\n",
    "            \n",
    "        self.trading_calendar = self.df_close[master_ticker].dropna().index.unique().sort_values()\n",
    "        print(\"\u2705 AlphaEngine Ready.\")\n",
    "\n",
    "    def run(self, inputs: EngineInput) -> EngineOutput:\n",
    "        # --- A. Validate Dates ---\n",
    "        try:\n",
    "            start_idx = self.trading_calendar.searchsorted(inputs.start_date)\n",
    "            if start_idx < 0: start_idx = 0\n",
    "        except Exception:\n",
    "            return self._error_result(\"Invalid Start Date\")\n",
    "\n",
    "        desired_end_idx = start_idx + inputs.calc_period + inputs.fwd_period\n",
    "        if desired_end_idx >= len(self.trading_calendar):\n",
    "            return self._error_result(f\"Date range exceeds history.\")\n",
    "\n",
    "        safe_start_date = self.trading_calendar[start_idx]\n",
    "        safe_calc_end_date = self.trading_calendar[start_idx + inputs.calc_period]\n",
    "        safe_viz_end_date = self.trading_calendar[start_idx + inputs.calc_period + inputs.fwd_period]\n",
    "\n",
    "        # --- B. Select Tickers ---\n",
    "        tickers_to_trade = []\n",
    "        results_table = pd.DataFrame()\n",
    "        debug_dict = {}\n",
    "        audit_info = {} \n",
    "\n",
    "        if inputs.mode == 'Manual List':\n",
    "            validation_errors = []\n",
    "            valid_tickers = []\n",
    "            for t in inputs.manual_tickers:\n",
    "                if t not in self.df_close.columns:\n",
    "                    validation_errors.append(f\"\u274c {t}: Ticker not found.\")\n",
    "                    continue\n",
    "                if pd.isna(self.df_close.at[safe_start_date, t]):\n",
    "                    validation_errors.append(f\"\u26a0\ufe0f {t}: No price data on start date.\")\n",
    "                    continue\n",
    "                valid_tickers.append(t)\n",
    "            \n",
    "            if validation_errors: return self._error_result(\"\\n\".join(validation_errors))\n",
    "            if not valid_tickers: return self._error_result(\"No valid tickers.\")\n",
    "            tickers_to_trade = valid_tickers\n",
    "            results_table = pd.DataFrame(index=valid_tickers)\n",
    "            \n",
    "        else: # Ranking Mode\n",
    "            eligible_tickers = self._get_eligible_universe(safe_start_date, inputs.quality_thresholds, audit_info)\n",
    "            debug_dict['audit_liquidity'] = audit_info \n",
    "            \n",
    "            if not eligible_tickers: return self._error_result(\"No tickers passed quality filters.\")\n",
    "            \n",
    "            calc_close = self.df_close.loc[safe_start_date:safe_calc_end_date, eligible_tickers]\n",
    "            idx_product = pd.MultiIndex.from_product([eligible_tickers, calc_close.index], names=['Ticker', 'Date'])\n",
    "            feat_slice = self.features_df.reindex(idx_product).dropna(how='all')\n",
    "            atrp_mean = feat_slice.groupby(level='Ticker')['ATRP'].mean()\n",
    "            \n",
    "            ingredients = { 'calc_close': calc_close, 'daily_returns': calc_close.pct_change(), 'atrp': atrp_mean }\n",
    "            if inputs.metric not in METRIC_REGISTRY: return self._error_result(f\"Metric '{inputs.metric}' not found.\")\n",
    "            metric_vals = METRIC_REGISTRY[inputs.metric](ingredients)\n",
    "            sorted_tickers = metric_vals.sort_values(ascending=False)\n",
    "            \n",
    "            start_r = max(0, inputs.rank_start - 1)\n",
    "            end_r = inputs.rank_end\n",
    "            tickers_to_trade = sorted_tickers.iloc[start_r:end_r].index.tolist()\n",
    "            if not tickers_to_trade: return self._error_result(\"No tickers generated from ranking.\")\n",
    "\n",
    "            results_table = pd.DataFrame({\n",
    "                'Rank': range(inputs.rank_start, inputs.rank_start + len(tickers_to_trade)),\n",
    "                'Ticker': tickers_to_trade,\n",
    "                'Metric Value': sorted_tickers.loc[tickers_to_trade].values\n",
    "            }).set_index('Ticker')\n",
    "\n",
    "        # --- C. Performance Calculations ---\n",
    "        p_val, p_ret, p_atrp = calculate_buy_and_hold_performance(self.df_close, self.features_df, tickers_to_trade, safe_start_date, safe_viz_end_date)\n",
    "        b_val, b_ret, b_atrp = calculate_buy_and_hold_performance(self.df_close, self.features_df, [inputs.benchmark_ticker], safe_start_date, safe_viz_end_date)\n",
    "\n",
    "        # --- D. Final Metrics ---\n",
    "        plot_data = self.df_close[list(set(tickers_to_trade))].loc[safe_start_date:safe_viz_end_date]\n",
    "        if not plot_data.empty: plot_data = plot_data / plot_data.bfill().iloc[0]\n",
    "        calc_end_ts = safe_calc_end_date\n",
    "        metrics = {}\n",
    "        get_gain = lambda s: (s.iloc[-1] / s.iloc[0]) - 1 if len(s) > 0 else 0\n",
    "\n",
    "        metrics['full_p_gain'] = get_gain(p_val)\n",
    "        metrics['calc_p_gain'] = get_gain(p_val.loc[:calc_end_ts])\n",
    "        metrics['fwd_p_gain'] = get_gain(p_val.loc[calc_end_ts:])\n",
    "        metrics['full_p_sharpe_atr'] = calculate_sharpe_atr(p_ret, p_atrp)\n",
    "        metrics['calc_p_sharpe_atr'] = calculate_sharpe_atr(p_ret.loc[:calc_end_ts], p_atrp.loc[p_ret.loc[:calc_end_ts].index])\n",
    "        metrics['fwd_p_sharpe_atr'] = calculate_sharpe_atr(p_ret.loc[calc_end_ts:].iloc[1:], p_atrp.loc[p_ret.loc[calc_end_ts:].iloc[1:].index])\n",
    "        \n",
    "        if not b_ret.empty:\n",
    "            metrics['full_b_gain'] = get_gain(b_val)\n",
    "            metrics['calc_b_gain'] = get_gain(b_val.loc[:calc_end_ts])\n",
    "            metrics['fwd_b_gain'] = get_gain(b_val.loc[calc_end_ts:])\n",
    "            metrics['full_b_sharpe_atr'] = calculate_sharpe_atr(b_ret, b_atrp)\n",
    "            metrics['calc_b_sharpe_atr'] = calculate_sharpe_atr(b_ret.loc[:calc_end_ts], b_atrp.loc[b_ret.loc[:calc_end_ts].index])\n",
    "            metrics['fwd_b_sharpe_atr'] = calculate_sharpe_atr(b_ret.loc[calc_end_ts:].iloc[1:], b_atrp.loc[b_ret.loc[calc_end_ts:].iloc[1:].index])\n",
    "\n",
    "        if not plot_data.empty: results_table['Fwd Gain'] = (plot_data.iloc[-1] / plot_data.loc[calc_end_ts]) - 1\n",
    "        ticker_counts = Counter(tickers_to_trade)\n",
    "        weights = pd.Series({t: c/len(tickers_to_trade) for t, c in ticker_counts.items()})\n",
    "\n",
    "        if inputs.debug:\n",
    "            trace_df = plot_data.copy()\n",
    "            trace_df.columns = [f'Norm_Price_{c}' for c in trace_df.columns]\n",
    "            trace_df['Norm_Price_Portfolio'] = p_val\n",
    "            if not b_val.empty: trace_df[f'Norm_Price_Benchmark_{inputs.benchmark_ticker}'] = b_val\n",
    "            debug_dict['portfolio_trace'] = trace_df\n",
    "\n",
    "        return EngineOutput(\n",
    "            portfolio_series=p_val, benchmark_series=b_val, normalized_plot_data=plot_data,\n",
    "            tickers=tickers_to_trade, initial_weights=weights, perf_metrics=metrics,\n",
    "            results_df=results_table, start_date=safe_start_date,\n",
    "            calc_end_date=safe_calc_end_date, viz_end_date=safe_viz_end_date, debug_data=debug_dict\n",
    "        )\n",
    "\n",
    "    # --- UPDATED: CAPTURE SNAPSHOT ---\n",
    "    def _get_eligible_universe(self, date_ts, thresholds, audit_container=None):\n",
    "        avail_dates = self.features_df.index.get_level_values('Date').unique().sort_values()\n",
    "        valid_dates = avail_dates[avail_dates <= date_ts]\n",
    "        if valid_dates.empty: return []\n",
    "        day_features = self.features_df.xs(valid_dates[-1], level='Date')\n",
    "\n",
    "        # 1. Determine Dynamic Cutoff\n",
    "        vol_cutoff = thresholds.get('min_median_dollar_volume', 0)\n",
    "        percentile_used = \"N/A\"\n",
    "        dynamic_val = 0\n",
    "        \n",
    "        if 'min_liquidity_percentile' in thresholds:\n",
    "            percentile_used = thresholds['min_liquidity_percentile']\n",
    "            dynamic_val = day_features['RollMedDollarVol'].quantile(percentile_used)\n",
    "            vol_cutoff = max(vol_cutoff, dynamic_val)\n",
    "\n",
    "        # 2. Logic Mask\n",
    "        mask = (\n",
    "            (day_features['RollMedDollarVol'] >= vol_cutoff) &\n",
    "            (day_features['RollingStalePct'] <= thresholds['max_stale_pct']) &\n",
    "            (day_features['RollingSameVolCount'] <= thresholds['max_same_vol_count'])\n",
    "        )\n",
    "\n",
    "        # 3. Capture Detailed Audit Snapshot\n",
    "        if audit_container is not None:\n",
    "            audit_container['date'] = valid_dates[-1]\n",
    "            audit_container['total_tickers_available'] = len(day_features)\n",
    "            audit_container['percentile_setting'] = percentile_used\n",
    "            audit_container['percentile_value_usd'] = dynamic_val\n",
    "            audit_container['final_cutoff_usd'] = vol_cutoff\n",
    "            audit_container['tickers_passed'] = mask.sum()\n",
    "            \n",
    "            # Save the DataFrame!\n",
    "            snapshot = day_features.copy()\n",
    "            snapshot['Calculated_Cutoff'] = vol_cutoff\n",
    "            snapshot['Passed_Vol_Check'] = snapshot['RollMedDollarVol'] >= vol_cutoff\n",
    "            snapshot['Passed_Final'] = mask\n",
    "            # Sort by volume so user can see the cutoff point easily\n",
    "            snapshot = snapshot.sort_values('RollMedDollarVol', ascending=False)\n",
    "            audit_container['universe_snapshot'] = snapshot\n",
    "\n",
    "        return day_features[mask].index.tolist()\n",
    "\n",
    "    def _error_result(self, msg):\n",
    "        return EngineOutput(pd.Series(dtype=float), pd.Series(dtype=float), pd.DataFrame(), [], pd.Series(dtype=float), {}, pd.DataFrame(), pd.Timestamp.min, pd.Timestamp.min, pd.Timestamp.min, msg)\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION E: THE UI (Visualization)\n",
    "# Update this function to read the audit data from the `debug_data` and print it nicely.\n",
    "# Updated print logic to detect date shift\n",
    "# Fixed EngineInput argument mapping\n",
    "# ==============================================================================\n",
    "\n",
    "def plot_walk_forward_analyzer(df_ohlcv, \n",
    "                               default_start_date='2020-01-01', \n",
    "                               default_calc_period=126, \n",
    "                               default_fwd_period=63,\n",
    "                               default_metric='Sharpe (ATR)', \n",
    "                               default_rank_start=1, \n",
    "                               default_rank_end=10,\n",
    "                               default_benchmark_ticker='SPY', \n",
    "                               master_calendar_ticker='SPY', \n",
    "                               quality_thresholds=None, \n",
    "                               debug=False):\n",
    "    \n",
    "    engine = AlphaEngine(df_ohlcv, master_ticker=master_calendar_ticker)\n",
    "    results_container = [None]\n",
    "    debug_container = [None]\n",
    "\n",
    "    # --- UPDATED DEFAULT SETTINGS WITH PERCENTILE ---\n",
    "    if quality_thresholds is None:\n",
    "        quality_thresholds = {\n",
    "            'min_median_dollar_volume': 100_000, # Hard floor\n",
    "            'min_liquidity_percentile': 0.50,    # Top 50%\n",
    "            'max_stale_pct': 0.05, \n",
    "            'max_same_vol_count': 10\n",
    "        }\n",
    "\n",
    "    # (Widget setup code remains the same...)\n",
    "    mode_selector = widgets.RadioButtons(options=['Ranking', 'Manual List'], value='Ranking', description='Portfolio Mode:', layout={'width': 'max-content'})\n",
    "    start_date_picker = widgets.DatePicker(description='Start Date:', value=pd.to_datetime(default_start_date))\n",
    "    calc_period_input = widgets.IntText(value=default_calc_period, description='Calc Period:')\n",
    "    fwd_period_input = widgets.IntText(value=default_fwd_period, description='Fwd Period:')\n",
    "    metric_dropdown = widgets.Dropdown(options=list(METRIC_REGISTRY.keys()), value=default_metric, description='Metric:')\n",
    "    rank_start_input = widgets.IntText(value=default_rank_start, description='Rank Start:')\n",
    "    rank_end_input = widgets.IntText(value=default_rank_end, description='Rank End:')\n",
    "    manual_tickers_input = widgets.Textarea(value='', placeholder='Enter tickers...', description='Manual Tickers:', layout={'width': '400px', 'height': '80px'})\n",
    "    benchmark_input = widgets.Text(value=default_benchmark_ticker, description='Benchmark:', placeholder='Enter Ticker')\n",
    "    update_button = widgets.Button(description=\"Update Chart\", button_style='primary')\n",
    "    ticker_list_output = widgets.Output()\n",
    "\n",
    "    ranking_controls = widgets.HBox([metric_dropdown, rank_start_input, rank_end_input])\n",
    "    manual_controls = widgets.HBox([manual_tickers_input])\n",
    "    date_controls = widgets.HBox([start_date_picker, calc_period_input, fwd_period_input])\n",
    "    ui = widgets.VBox([mode_selector, date_controls, ranking_controls, manual_controls, widgets.HBox([benchmark_input, update_button]), ticker_list_output], layout=widgets.Layout(margin='10px 0 20px 0'))\n",
    "    \n",
    "    def on_mode_change(c):\n",
    "        ranking_controls.layout.display = 'flex' if c['new'] == 'Ranking' else 'none'\n",
    "        manual_controls.layout.display = 'none' if c['new'] == 'Ranking' else 'flex'\n",
    "    mode_selector.observe(on_mode_change, names='value')\n",
    "    on_mode_change({'new': mode_selector.value})\n",
    "\n",
    "    fig = go.FigureWidget()\n",
    "    fig.update_layout(title='Walk-Forward Performance Analysis', height=600, width=1200, template=\"plotly_white\", hovermode='x unified', autosize=True, margin=dict(l=20, r=20, t=40, b=20))\n",
    "    for i in range(50): fig.add_trace(go.Scatter(visible=False, line=dict(width=2)))\n",
    "    fig.add_trace(go.Scatter(name='Benchmark', visible=True, line=dict(color='black', width=3, dash='dash')))\n",
    "    fig.add_trace(go.Scatter(name='Group Portfolio', visible=True, line=dict(color='green', width=3)))\n",
    "\n",
    "    def update_plot(b):\n",
    "        print('--- Plot Updated (v2) ---')\n",
    "        ticker_list_output.clear_output()\n",
    "        manual_list = [t.strip().upper() for t in manual_tickers_input.value.split(',') if t.strip()]\n",
    "        start_date_raw = pd.to_datetime(start_date_picker.value)\n",
    "        \n",
    "        if start_date_raw < (engine.trading_calendar[0] - pd.Timedelta(days=7)):\n",
    "            with ticker_list_output: print(f\"\u26a0\ufe0f DATE WARNING: Start date {start_date_raw.date()} is too early.\"); return\n",
    "\n",
    "        inputs = EngineInput(\n",
    "            mode=mode_selector.value,\n",
    "            start_date=start_date_raw,\n",
    "            calc_period=calc_period_input.value,\n",
    "            fwd_period=fwd_period_input.value,\n",
    "            metric=metric_dropdown.value,\n",
    "            benchmark_ticker=benchmark_input.value.strip().upper(),\n",
    "            rank_start=rank_start_input.value,\n",
    "            rank_end=rank_end_input.value,\n",
    "            quality_thresholds=quality_thresholds,\n",
    "            manual_tickers=manual_list,\n",
    "            debug=debug\n",
    "        )\n",
    "        \n",
    "        with ticker_list_output:\n",
    "            res = engine.run(inputs)\n",
    "            results_container[0] = res\n",
    "            debug_container[0] = res.debug_data\n",
    "            if res.error_msg: print(res.error_msg); return\n",
    "\n",
    "            with fig.batch_update():\n",
    "                cols = res.normalized_plot_data.columns.tolist()\n",
    "                for i in range(50):\n",
    "                    if i < len(cols): fig.data[i].update(x=res.normalized_plot_data.index.to_pydatetime(), y=res.normalized_plot_data[cols[i]], name=cols[i], visible=True)\n",
    "                    else: fig.data[i].visible = False\n",
    "                \n",
    "                fig.data[50].update(x=res.benchmark_series.index.to_pydatetime(), y=res.benchmark_series.values, name=f\"Benchmark ({inputs.benchmark_ticker})\", visible=not res.benchmark_series.empty)\n",
    "                fig.data[51].update(x=res.portfolio_series.index.to_pydatetime(), y=res.portfolio_series.values, visible=True)\n",
    "                fig.layout.shapes = [dict(type=\"line\", x0=res.calc_end_date.to_pydatetime(), y0=0, x1=res.calc_end_date.to_pydatetime(), y1=1, xref='x', yref='paper', line=dict(color=\"grey\", width=2, dash=\"dash\"))]\n",
    "\n",
    "            req_date = inputs.start_date.date()\n",
    "            act_date = res.start_date.date()\n",
    "            if req_date != act_date: print(f\"\u2139\ufe0f Info: Start date {req_date} is not a trading day. Snapping forward to {act_date}.\")\n",
    "            \n",
    "            # --- LIQUIDITY AUDIT PRINT ---\n",
    "            if inputs.mode == 'Ranking' and res.debug_data and 'audit_liquidity' in res.debug_data:\n",
    "                audit = res.debug_data['audit_liquidity']\n",
    "                if audit:\n",
    "                    pct_str = f\"{audit.get('percentile_setting', 0)*100:.0f}%\"\n",
    "                    cut_val = audit.get('final_cutoff_usd', 0)\n",
    "                    print(\"-\" * 60)\n",
    "                    print(f\"\ud83d\udd0d LIQUIDITY CHECK ({act_date})\")\n",
    "                    print(f\"   Universe Size: {audit.get('total_tickers_available')} tickers\")\n",
    "                    print(f\"   Filtering: Top {pct_str} of Market\")\n",
    "                    print(f\"   Calculated Cutoff: ${cut_val:,.0f} / day\")\n",
    "                    print(f\"   Tickers Remaining: {audit.get('tickers_passed')}\")\n",
    "                    print(\"-\" * 60)\n",
    "            \n",
    "            print(f\"Analysis Period: {act_date} to {res.viz_end_date.date()}.\")\n",
    "            \n",
    "            if inputs.mode == 'Ranking': print(\"Ranked Tickers:\"); pprint.pprint(res.tickers)\n",
    "            else: print(\"Manual Portfolio Tickers:\"); pprint.pprint(res.tickers)\n",
    "            \n",
    "            m = res.perf_metrics\n",
    "            rows = [\n",
    "                {'Metric': 'Group Portfolio Gain', 'Full': m.get('full_p_gain'), 'Calc': m.get('calc_p_gain'), 'Fwd': m.get('fwd_p_gain')},\n",
    "                {'Metric': f'Benchmark ({inputs.benchmark_ticker}) Gain', 'Full': m.get('full_b_gain'), 'Calc': m.get('calc_b_gain'), 'Fwd': m.get('fwd_b_gain')},\n",
    "                {'Metric': '== Gain Delta', 'Full': m.get('full_p_gain',0)-m.get('full_b_gain',0), 'Calc': m.get('calc_p_gain',0)-m.get('calc_b_gain',0), 'Fwd': m.get('fwd_p_gain',0)-m.get('fwd_b_gain',0)},\n",
    "                {'Metric': 'Group Sharpe (ATR)', 'Full': m.get('full_p_sharpe_atr'), 'Calc': m.get('calc_p_sharpe_atr'), 'Fwd': m.get('fwd_p_sharpe_atr')},\n",
    "                {'Metric': f'Benchmark Sharpe (ATR)', 'Full': m.get('full_b_sharpe_atr'), 'Calc': m.get('calc_b_sharpe_atr'), 'Fwd': m.get('fwd_b_sharpe_atr')},\n",
    "                {'Metric': '== Sharpe Delta', 'Full': m.get('full_p_sharpe_atr',0)-m.get('full_b_sharpe_atr',0), 'Calc': m.get('calc_p_sharpe_atr',0)-m.get('calc_b_sharpe_atr',0), 'Fwd': m.get('fwd_p_sharpe_atr',0)-m.get('fwd_b_sharpe_atr',0)}\n",
    "            ]\n",
    "            display(pd.DataFrame(rows).set_index('Metric').style.format(\"{:+.2%}\", na_rep=\"N/A\"))\n",
    "\n",
    "    update_button.on_click(update_plot)\n",
    "    update_plot(None)\n",
    "    display(ui, fig)\n",
    "    return results_container, debug_container\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION F: UTILITIES\n",
    "# ==============================================================================\n",
    "\n",
    "def print_nested(d, indent=0, width=4):\n",
    "    \"\"\"Pretty-print any nested dict/list/tuple combination.\"\"\"\n",
    "    spacing = ' ' * indent\n",
    "    if isinstance(d, dict):\n",
    "        for k, v in d.items():\n",
    "            print(f'{spacing}{k}:')\n",
    "            print_nested(v, indent + width, width)\n",
    "    elif isinstance(d, (list, tuple)):\n",
    "        for item in d:\n",
    "            print_nested(item, indent, width)\n",
    "    else:\n",
    "        print(f'{spacing}{d}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "232740e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 9661318 entries, ('A', Timestamp('1999-11-18 00:00:00')) to ('ZWS', Timestamp('2025-12-02 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   Adj Open   float64\n",
      " 1   Adj High   float64\n",
      " 2   Adj Low    float64\n",
      " 3   Adj Close  float64\n",
      " 4   Volume     int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 406.1+ MB\n",
      "df_ohlcv.info():\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Adj Open</th>\n",
       "      <th>Adj High</th>\n",
       "      <th>Adj Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">A</th>\n",
       "      <th>1999-11-18</th>\n",
       "      <td>27.2452</td>\n",
       "      <td>29.9398</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>26.3470</td>\n",
       "      <td>74716411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-19</th>\n",
       "      <td>25.7108</td>\n",
       "      <td>25.7482</td>\n",
       "      <td>23.8396</td>\n",
       "      <td>24.1764</td>\n",
       "      <td>18198352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-22</th>\n",
       "      <td>24.7378</td>\n",
       "      <td>26.3470</td>\n",
       "      <td>23.9893</td>\n",
       "      <td>26.3470</td>\n",
       "      <td>7857766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-23</th>\n",
       "      <td>25.4488</td>\n",
       "      <td>26.1225</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>7138321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-24</th>\n",
       "      <td>24.0267</td>\n",
       "      <td>25.1120</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>24.5881</td>\n",
       "      <td>5785609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ZWS</th>\n",
       "      <th>2025-11-25</th>\n",
       "      <td>47.2900</td>\n",
       "      <td>48.4800</td>\n",
       "      <td>47.1500</td>\n",
       "      <td>48.0200</td>\n",
       "      <td>592800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-26</th>\n",
       "      <td>47.5400</td>\n",
       "      <td>48.7000</td>\n",
       "      <td>47.3000</td>\n",
       "      <td>48.1300</td>\n",
       "      <td>1154100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-28</th>\n",
       "      <td>48.4600</td>\n",
       "      <td>48.4800</td>\n",
       "      <td>47.7000</td>\n",
       "      <td>47.7000</td>\n",
       "      <td>481400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-01</th>\n",
       "      <td>47.1700</td>\n",
       "      <td>48.1800</td>\n",
       "      <td>47.1500</td>\n",
       "      <td>47.7400</td>\n",
       "      <td>608100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-02</th>\n",
       "      <td>47.9800</td>\n",
       "      <td>48.3100</td>\n",
       "      <td>47.7050</td>\n",
       "      <td>47.8200</td>\n",
       "      <td>455240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9661318 rows \u00d7 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Adj Open  Adj High  Adj Low  Adj Close    Volume\n",
       "Ticker Date                                                        \n",
       "A      1999-11-18   27.2452   29.9398  23.9518    26.3470  74716411\n",
       "       1999-11-19   25.7108   25.7482  23.8396    24.1764  18198352\n",
       "       1999-11-22   24.7378   26.3470  23.9893    26.3470   7857766\n",
       "       1999-11-23   25.4488   26.1225  23.9518    23.9518   7138321\n",
       "       1999-11-24   24.0267   25.1120  23.9518    24.5881   5785609\n",
       "...                     ...       ...      ...        ...       ...\n",
       "ZWS    2025-11-25   47.2900   48.4800  47.1500    48.0200    592800\n",
       "       2025-11-26   47.5400   48.7000  47.3000    48.1300   1154100\n",
       "       2025-11-28   48.4600   48.4800  47.7000    47.7000    481400\n",
       "       2025-12-01   47.1700   48.1800  47.1500    47.7400    608100\n",
       "       2025-12-02   47.9800   48.3100  47.7050    47.8200    455240\n",
       "\n",
       "[9661318 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = r'c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet'\n",
    "df_ohlcv = pd.read_parquet(data_path, engine='pyarrow')\n",
    "print(f'df_ohlcv.info():\\n{df_ohlcv.info()}')\n",
    "df_ohlcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6720574b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- \u2699\ufe0f Initializing AlphaEngine ---\n",
      "Optimizing data structures...\n",
      "\u2705 AlphaEngine Ready.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77b7da8c865e48bdaa9f1f0c8c3d248e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(RadioButtons(description='Portfolio Mode:', layout=Layout(width='max-content'), options=('Ranki\u2026"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7feb63c47524440b73e4fd324fdbcc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'width': 2},\n",
       "              'name': 'JPST',\n",
       "              'type': 'scatter',\n",
       "              'uid': '3ddb194c-3f2c-4cf8-bc65-5041ecb01efc',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 0.99980155, 1.00019645, 1.00019645, 1.0007898 , 1.00098826,\n",
       "                          1.0003949 , 1.0015796 , 1.00138316, 1.00177806, 1.00197451, 1.00197451,\n",
       "                          1.00236941, 1.00254781, 1.00294472, 1.00334163])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'VLO',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd17e0f4d-e227-44c6-9f64-163d0923ccad',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 0.9975757 , 1.00477468, 1.00484859, 1.01307494, 1.03202584,\n",
       "                          1.03040718, 1.06771769, 1.08049698, 1.07932179, 1.10737858, 1.11024635,\n",
       "                          1.11648447, 1.1331589 , 1.14123743, 1.14131134])},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '872b9827-fc92-42aa-bc20-4e0e250f9679', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'd648a03d-357e-41d6-bd61-a567b663d92b', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '90a79038-7d62-4787-bde0-a50a2faf498a', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'cb316058-b48a-46a9-a351-2b4c1d436bc5', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '84fad499-9772-4249-96c1-59a45f0073dc', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'a48d4a1a-b96f-44a4-a025-b4955c0a8c7b', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '592901fa-59fc-46bd-9fa7-1e2739846b87', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '4c257f7e-d392-4e0e-85a8-4bae23be183b', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'd89f42d6-f693-4fbd-8178-1194e378beaf', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'acf1c447-b4b7-4d91-8a2e-af2f45e68c27', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'f5d07f66-7d90-4acb-92a3-5e2c03a5bf5d', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '8c06c816-3f89-44b1-8b4e-911eb3c331fd', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'e808a6a1-5750-43b2-9011-584c34c7411c', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'f6fe85f9-8748-46a7-9103-d76595b4cf54', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'aefe0f8d-6ace-471f-9ecb-2c6ce16c9fe9', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'c46415aa-8eb7-46c5-9434-773b550f9f7a', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'c916d0e1-a478-438b-9b5b-aa89286e0eb9', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '8331eb1b-764d-4a62-a5b3-36c04b2c1561', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'bcf5fb20-9303-4218-8fd2-cbeecf01c9f9', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '3034adc2-4c54-4be9-8e1b-2f950d8fbe46', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '96347142-ea13-42c9-a20a-c09a6bd99be5', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '21e61f30-0005-4a02-8409-5f2e359140fe', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '439cf2b5-0287-4d03-bc40-8d6d99471df4', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '287dcff0-e0aa-4c12-a153-b9ad4211d887', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '272cf919-f65a-4851-9b9c-77f8ea16a503', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'b32f2c0e-f2a0-48e5-82af-307165aa273c', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'cf6999de-1757-4505-99a1-7637eba4e37e', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'a00b1e4b-837c-45c1-87a4-fd1f34d1307a', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'e24081aa-002c-43ba-a087-b5a673e402bc', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'ef942aea-b3a2-4098-b494-935c4d7b22d6', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '58cb4fdd-de50-4db4-b85c-02b2c7a8f3f1', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'dc40ae89-3b03-40c6-abd3-9f1b309d2c7c', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '3b426677-f0cf-4775-a59d-10e0d0c774aa', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '33b166e8-238f-485e-879a-36b13e2caa83', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '6d0b6ad8-9a32-420a-b502-cb6f94861113', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '8559b37a-22d8-4714-b38d-51e8d286fdee', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '4dca4dff-34cb-4652-af82-7c765085e21b', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '567312a3-944c-4adb-b16d-499654fd6c50', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '923f6b77-a2de-4fca-aa04-a8d513263b4f', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'f74732da-4543-4f8e-a2af-07a21b65df99', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '9784a080-bd54-4776-8836-24186250d1e9', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '16994df9-5ad7-46b7-b883-2aaec34b6010', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '6294d246-a845-46a3-a119-fe38de8e418a', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'bd761e16-3e94-40db-9c27-2dbc0f2c579c', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'b1556a23-cd08-4231-9901-c5817b96d522', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '862fbb81-213c-4770-be6b-363b05b1d772', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'a3b42ad1-7d48-47ab-ad5a-dc9f2936176f', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'f9f8a2df-b554-4aee-a68a-b90a59e2e5b3', 'visible': False},\n",
       "             {'line': {'color': 'black', 'dash': 'dash', 'width': 3},\n",
       "              'name': 'Benchmark (VOO)',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ddb67bf8-4931-4284-aa9d-75a5f869006d',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00001692, 0.99785841, 0.99750486, 0.99205615, 0.9894409 ,\n",
       "                          0.9855451 , 1.00062421, 0.99639177, 1.00037216, 1.00266599, 1.00620825,\n",
       "                          1.00040599, 0.99303391, 0.99811215, 1.00632666])},\n",
       "             {'line': {'color': 'green', 'width': 3},\n",
       "              'name': 'Group Portfolio',\n",
       "              'type': 'scatter',\n",
       "              'uid': '4f0493c0-c379-43d2-b981-dec7b0e1540a',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 0.99868863, 1.00248556, 1.00252252, 1.00693237, 1.01650705,\n",
       "                          1.01540104, 1.03464865, 1.04094007, 1.04054992, 1.05467654, 1.05611043,\n",
       "                          1.05942694, 1.06785336, 1.07209107, 1.07232648])}],\n",
       "    'layout': {'height': 600,\n",
       "               'hovermode': 'x unified',\n",
       "               'shapes': [{'line': {'color': 'grey', 'dash': 'dash', 'width': 2},\n",
       "                           'type': 'line',\n",
       "                           'x0': Timestamp('2025-08-27 00:00:00'),\n",
       "                           'x1': Timestamp('2025-08-27 00:00:00'),\n",
       "                           'xref': 'x',\n",
       "                           'y0': 0,\n",
       "                           'y1': 1,\n",
       "                           'yref': 'paper'}],\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Walk-Forward Performance Analysis'}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_container, debug_container = plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    default_start_date='2025-08-13',\n",
    "    default_calc_period=10,\n",
    "    default_fwd_period=5,\n",
    "    default_metric='Sharpe (ATR)',\n",
    "    default_rank_start=15,\n",
    "    default_rank_end=16,\n",
    "    default_benchmark_ticker='VOO', \n",
    "    master_calendar_ticker='VOO',    \n",
    "    quality_thresholds = { \n",
    "        'min_median_dollar_volume': 100_000, # A low \"hard floor\" to filter absolute errors/garbage\n",
    "        # If min_liquidity_percentile is 0.8 (Top 20%), we want values > the 0.8 quantile.            \n",
    "        'min_liquidity_percentile': 0.50,    # Dynamic: Only keep the top 50% of stocks by volume\n",
    "        'max_stale_pct': 0.05, \n",
    "        'max_same_vol_count': 10\n",
    "    },\n",
    "    debug=True  # <-- Activate the new mode!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d7e2a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = generate_features(df_ohlcv=df_ohlcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e7267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tickers = ['SPY', 'AAPL', 'IWM', 'QQQ', 'META', 'EEM', 'BABA']\n",
    "my_tickers = ['NTES', 'LII',]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4206b269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 NTES exported to: ./export_csv/features_NTES.csv\n",
      "\u2705 LII exported to: ./export_csv/features_LII.csv\n"
     ]
    }
   ],
   "source": [
    "for ticker in my_tickers:\n",
    "  if ticker in features_df.index.get_level_values('Ticker'):\n",
    "    ticker_features = features_df.loc[ticker]\n",
    "    ticker_features.to_csv(f'./export_csv/features_{ticker}.csv')\n",
    "    print(f\"\u2705 {ticker} features exported to: ./export_csv/features_{ticker}.csv\")\n",
    "  else:\n",
    "    print(f\"\u26a0\ufe0f {ticker} not found in features_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719425da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 NTES exported to: ./export_csv/ohlcv_NTES.csv\n",
      "\u2705 LII exported to: ./export_csv/ohlcv_LII.csv\n"
     ]
    }
   ],
   "source": [
    "for ticker in my_tickers:\n",
    "  if ticker in df_ohlcv.index.get_level_values('Ticker'):\n",
    "    ticker_features = df_ohlcv.loc[ticker]\n",
    "    ticker_features.to_csv(f'./export_csv/ohlcv_{ticker}.csv')\n",
    "    print(f\"\u2705 {ticker} OHLCV exported to: ./export_csv/ohlcv_{ticker}.csv\")\n",
    "  else:\n",
    "    print(f\"\u26a0\ufe0f {ticker} not found in df_ohlcv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1e0c43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TR</th>\n",
       "      <th>ATR</th>\n",
       "      <th>ATRP</th>\n",
       "      <th>RollingStalePct</th>\n",
       "      <th>RollMedDollarVol</th>\n",
       "      <th>RollingSameVolCount</th>\n",
       "      <th>Calculated_Cutoff</th>\n",
       "      <th>Passed_Vol_Check</th>\n",
       "      <th>Passed_Final</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>1.1061</td>\n",
       "      <td>0.520297</td>\n",
       "      <td>0.017905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.348299e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.720650e+07</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            TR       ATR      ATRP  RollingStalePct  RollMedDollarVol  \\\n",
       "Ticker                                                                  \n",
       "AAPL    1.1061  0.520297  0.017905              0.0      5.348299e+09   \n",
       "\n",
       "        RollingSameVolCount  Calculated_Cutoff  Passed_Vol_Check  Passed_Final  \n",
       "Ticker                                                                          \n",
       "AAPL                    0.0       3.720650e+07              True          True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming you have run the variables setup from the previous step\n",
    "snapshot_df = debug_container[0]['audit_liquidity']['universe_snapshot']\n",
    "\n",
    "if 'AAPL' in snapshot_df.index:\n",
    "    display(snapshot_df.loc[['AAPL']])\n",
    "else:\n",
    "    print(\"AAPL was not present in the data for this date.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32da9680",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 Snapshot exported to: ./export_csv/snapshot_df.csv\n",
      "   Shape: (1226, 9)\n",
      "   Columns: ['TR', 'ATR', 'ATRP', 'RollingStalePct', 'RollMedDollarVol', 'RollingSameVolCount', 'Calculated_Cutoff', 'Passed_Vol_Check', 'Passed_Final']\n"
     ]
    }
   ],
   "source": [
    "snapshot_df.to_csv('./export_csv/snapshot_df.csv')\n",
    "print(f\"\u2705 Snapshot exported to: ./export_csv/snapshot_df.csv\")\n",
    "print(f\"   Shape: {snapshot_df.shape}\")\n",
    "print(f\"   Columns: {list(snapshot_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f5e1e53",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udcc5 Date: 2015-04-28\n",
      "\ud83d\udcb0 Calculated Cutoff: $37,206,497\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_df6b0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_df6b0_level0_col0\" class=\"col_heading level0 col0\" >TR</th>\n",
       "      <th id=\"T_df6b0_level0_col1\" class=\"col_heading level0 col1\" >ATR</th>\n",
       "      <th id=\"T_df6b0_level0_col2\" class=\"col_heading level0 col2\" >ATRP</th>\n",
       "      <th id=\"T_df6b0_level0_col3\" class=\"col_heading level0 col3\" >RollingStalePct</th>\n",
       "      <th id=\"T_df6b0_level0_col4\" class=\"col_heading level0 col4\" >RollMedDollarVol</th>\n",
       "      <th id=\"T_df6b0_level0_col5\" class=\"col_heading level0 col5\" >RollingSameVolCount</th>\n",
       "      <th id=\"T_df6b0_level0_col6\" class=\"col_heading level0 col6\" >Calculated_Cutoff</th>\n",
       "      <th id=\"T_df6b0_level0_col7\" class=\"col_heading level0 col7\" >Passed_Vol_Check</th>\n",
       "      <th id=\"T_df6b0_level0_col8\" class=\"col_heading level0 col8\" >Passed_Final</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Ticker</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_df6b0_level0_row0\" class=\"row_heading level0 row0\" >NCLH</th>\n",
       "      <td id=\"T_df6b0_row0_col0\" class=\"data row0 col0\" >1.590000</td>\n",
       "      <td id=\"T_df6b0_row0_col1\" class=\"data row0 col1\" >1.195890</td>\n",
       "      <td id=\"T_df6b0_row0_col2\" class=\"data row0 col2\" >0.023837</td>\n",
       "      <td id=\"T_df6b0_row0_col3\" class=\"data row0 col3\" >0.0%</td>\n",
       "      <td id=\"T_df6b0_row0_col4\" class=\"data row0 col4\" >$37,587,368</td>\n",
       "      <td id=\"T_df6b0_row0_col5\" class=\"data row0 col5\" >0.000000</td>\n",
       "      <td id=\"T_df6b0_row0_col6\" class=\"data row0 col6\" >$37,206,497</td>\n",
       "      <td id=\"T_df6b0_row0_col7\" class=\"data row0 col7\" >True</td>\n",
       "      <td id=\"T_df6b0_row0_col8\" class=\"data row0 col8\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df6b0_level0_row1\" class=\"row_heading level0 row1\" >TER</th>\n",
       "      <td id=\"T_df6b0_row1_col0\" class=\"data row1 col0\" >0.559200</td>\n",
       "      <td id=\"T_df6b0_row1_col1\" class=\"data row1 col1\" >0.396619</td>\n",
       "      <td id=\"T_df6b0_row1_col2\" class=\"data row1 col2\" >0.022918</td>\n",
       "      <td id=\"T_df6b0_row1_col3\" class=\"data row1 col3\" >0.0%</td>\n",
       "      <td id=\"T_df6b0_row1_col4\" class=\"data row1 col4\" >$37,569,939</td>\n",
       "      <td id=\"T_df6b0_row1_col5\" class=\"data row1 col5\" >0.000000</td>\n",
       "      <td id=\"T_df6b0_row1_col6\" class=\"data row1 col6\" >$37,206,497</td>\n",
       "      <td id=\"T_df6b0_row1_col7\" class=\"data row1 col7\" >True</td>\n",
       "      <td id=\"T_df6b0_row1_col8\" class=\"data row1 col8\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df6b0_level0_row2\" class=\"row_heading level0 row2\" >AER</th>\n",
       "      <td id=\"T_df6b0_row2_col0\" class=\"data row2 col0\" >0.787600</td>\n",
       "      <td id=\"T_df6b0_row2_col1\" class=\"data row2 col1\" >0.750605</td>\n",
       "      <td id=\"T_df6b0_row2_col2\" class=\"data row2 col2\" >0.016253</td>\n",
       "      <td id=\"T_df6b0_row2_col3\" class=\"data row2 col3\" >0.0%</td>\n",
       "      <td id=\"T_df6b0_row2_col4\" class=\"data row2 col4\" >$37,551,067</td>\n",
       "      <td id=\"T_df6b0_row2_col5\" class=\"data row2 col5\" >0.000000</td>\n",
       "      <td id=\"T_df6b0_row2_col6\" class=\"data row2 col6\" >$37,206,497</td>\n",
       "      <td id=\"T_df6b0_row2_col7\" class=\"data row2 col7\" >True</td>\n",
       "      <td id=\"T_df6b0_row2_col8\" class=\"data row2 col8\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df6b0_level0_row3\" class=\"row_heading level0 row3\" >EVRG</th>\n",
       "      <td id=\"T_df6b0_row3_col0\" class=\"data row3 col0\" >0.421200</td>\n",
       "      <td id=\"T_df6b0_row3_col1\" class=\"data row3 col1\" >0.439924</td>\n",
       "      <td id=\"T_df6b0_row3_col2\" class=\"data row3 col2\" >0.016716</td>\n",
       "      <td id=\"T_df6b0_row3_col3\" class=\"data row3 col3\" >0.0%</td>\n",
       "      <td id=\"T_df6b0_row3_col4\" class=\"data row3 col4\" >$37,542,028</td>\n",
       "      <td id=\"T_df6b0_row3_col5\" class=\"data row3 col5\" >0.000000</td>\n",
       "      <td id=\"T_df6b0_row3_col6\" class=\"data row3 col6\" >$37,206,497</td>\n",
       "      <td id=\"T_df6b0_row3_col7\" class=\"data row3 col7\" >True</td>\n",
       "      <td id=\"T_df6b0_row3_col8\" class=\"data row3 col8\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df6b0_level0_row4\" class=\"row_heading level0 row4\" >VRSK</th>\n",
       "      <td id=\"T_df6b0_row4_col0\" class=\"data row4 col0\" >0.632100</td>\n",
       "      <td id=\"T_df6b0_row4_col1\" class=\"data row4 col1\" >0.866085</td>\n",
       "      <td id=\"T_df6b0_row4_col2\" class=\"data row4 col2\" >0.012449</td>\n",
       "      <td id=\"T_df6b0_row4_col3\" class=\"data row4 col3\" >0.0%</td>\n",
       "      <td id=\"T_df6b0_row4_col4\" class=\"data row4 col4\" >$37,535,055</td>\n",
       "      <td id=\"T_df6b0_row4_col5\" class=\"data row4 col5\" >0.000000</td>\n",
       "      <td id=\"T_df6b0_row4_col6\" class=\"data row4 col6\" >$37,206,497</td>\n",
       "      <td id=\"T_df6b0_row4_col7\" class=\"data row4 col7\" >True</td>\n",
       "      <td id=\"T_df6b0_row4_col8\" class=\"data row4 col8\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df6b0_level0_row5\" class=\"row_heading level0 row5\" >NTES</th>\n",
       "      <td id=\"T_df6b0_row5_col0\" class=\"data row5 col0\" >0.475900</td>\n",
       "      <td id=\"T_df6b0_row5_col1\" class=\"data row5 col1\" >0.658619</td>\n",
       "      <td id=\"T_df6b0_row5_col2\" class=\"data row5 col2\" >0.031880</td>\n",
       "      <td id=\"T_df6b0_row5_col3\" class=\"data row5 col3\" >0.0%</td>\n",
       "      <td id=\"T_df6b0_row5_col4\" class=\"data row5 col4\" >$37,206,497</td>\n",
       "      <td id=\"T_df6b0_row5_col5\" class=\"data row5 col5\" >0.000000</td>\n",
       "      <td id=\"T_df6b0_row5_col6\" class=\"data row5 col6\" >$37,206,497</td>\n",
       "      <td id=\"T_df6b0_row5_col7\" class=\"data row5 col7\" >True</td>\n",
       "      <td id=\"T_df6b0_row5_col8\" class=\"data row5 col8\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df6b0_level0_row6\" class=\"row_heading level0 row6\" >LII</th>\n",
       "      <td id=\"T_df6b0_row6_col0\" class=\"data row6 col0\" >1.659600</td>\n",
       "      <td id=\"T_df6b0_row6_col1\" class=\"data row6 col1\" >1.712063</td>\n",
       "      <td id=\"T_df6b0_row6_col2\" class=\"data row6 col2\" >0.018024</td>\n",
       "      <td id=\"T_df6b0_row6_col3\" class=\"data row6 col3\" >0.0%</td>\n",
       "      <td id=\"T_df6b0_row6_col4\" class=\"data row6 col4\" >$37,107,899</td>\n",
       "      <td id=\"T_df6b0_row6_col5\" class=\"data row6 col5\" >0.000000</td>\n",
       "      <td id=\"T_df6b0_row6_col6\" class=\"data row6 col6\" >$37,206,497</td>\n",
       "      <td id=\"T_df6b0_row6_col7\" class=\"data row6 col7\" >False</td>\n",
       "      <td id=\"T_df6b0_row6_col8\" class=\"data row6 col8\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df6b0_level0_row7\" class=\"row_heading level0 row7\" >ATI</th>\n",
       "      <td id=\"T_df6b0_row7_col0\" class=\"data row7 col0\" >0.750900</td>\n",
       "      <td id=\"T_df6b0_row7_col1\" class=\"data row7 col1\" >1.041575</td>\n",
       "      <td id=\"T_df6b0_row7_col2\" class=\"data row7 col2\" >0.031199</td>\n",
       "      <td id=\"T_df6b0_row7_col3\" class=\"data row7 col3\" >0.0%</td>\n",
       "      <td id=\"T_df6b0_row7_col4\" class=\"data row7 col4\" >$36,741,036</td>\n",
       "      <td id=\"T_df6b0_row7_col5\" class=\"data row7 col5\" >0.000000</td>\n",
       "      <td id=\"T_df6b0_row7_col6\" class=\"data row7 col6\" >$37,206,497</td>\n",
       "      <td id=\"T_df6b0_row7_col7\" class=\"data row7 col7\" >False</td>\n",
       "      <td id=\"T_df6b0_row7_col8\" class=\"data row7 col8\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df6b0_level0_row8\" class=\"row_heading level0 row8\" >BMO</th>\n",
       "      <td id=\"T_df6b0_row8_col0\" class=\"data row8 col0\" >0.374300</td>\n",
       "      <td id=\"T_df6b0_row8_col1\" class=\"data row8 col1\" >0.620426</td>\n",
       "      <td id=\"T_df6b0_row8_col2\" class=\"data row8 col2\" >0.014351</td>\n",
       "      <td id=\"T_df6b0_row8_col3\" class=\"data row8 col3\" >0.0%</td>\n",
       "      <td id=\"T_df6b0_row8_col4\" class=\"data row8 col4\" >$36,597,179</td>\n",
       "      <td id=\"T_df6b0_row8_col5\" class=\"data row8 col5\" >0.000000</td>\n",
       "      <td id=\"T_df6b0_row8_col6\" class=\"data row8 col6\" >$37,206,497</td>\n",
       "      <td id=\"T_df6b0_row8_col7\" class=\"data row8 col7\" >False</td>\n",
       "      <td id=\"T_df6b0_row8_col8\" class=\"data row8 col8\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df6b0_level0_row9\" class=\"row_heading level0 row9\" >MKC</th>\n",
       "      <td id=\"T_df6b0_row9_col0\" class=\"data row9 col0\" >0.312700</td>\n",
       "      <td id=\"T_df6b0_row9_col1\" class=\"data row9 col1\" >0.400849</td>\n",
       "      <td id=\"T_df6b0_row9_col2\" class=\"data row9 col2\" >0.012820</td>\n",
       "      <td id=\"T_df6b0_row9_col3\" class=\"data row9 col3\" >0.0%</td>\n",
       "      <td id=\"T_df6b0_row9_col4\" class=\"data row9 col4\" >$36,228,620</td>\n",
       "      <td id=\"T_df6b0_row9_col5\" class=\"data row9 col5\" >0.000000</td>\n",
       "      <td id=\"T_df6b0_row9_col6\" class=\"data row9 col6\" >$37,206,497</td>\n",
       "      <td id=\"T_df6b0_row9_col7\" class=\"data row9 col7\" >False</td>\n",
       "      <td id=\"T_df6b0_row9_col8\" class=\"data row9 col8\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df6b0_level0_row10\" class=\"row_heading level0 row10\" >BF-B</th>\n",
       "      <td id=\"T_df6b0_row10_col0\" class=\"data row10 col0\" >0.467800</td>\n",
       "      <td id=\"T_df6b0_row10_col1\" class=\"data row10 col1\" >0.428298</td>\n",
       "      <td id=\"T_df6b0_row10_col2\" class=\"data row10 col2\" >0.013897</td>\n",
       "      <td id=\"T_df6b0_row10_col3\" class=\"data row10 col3\" >0.0%</td>\n",
       "      <td id=\"T_df6b0_row10_col4\" class=\"data row10 col4\" >$36,226,284</td>\n",
       "      <td id=\"T_df6b0_row10_col5\" class=\"data row10 col5\" >0.000000</td>\n",
       "      <td id=\"T_df6b0_row10_col6\" class=\"data row10 col6\" >$37,206,497</td>\n",
       "      <td id=\"T_df6b0_row10_col7\" class=\"data row10 col7\" >False</td>\n",
       "      <td id=\"T_df6b0_row10_col8\" class=\"data row10 col8\" >False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x20884fd5a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Access the data inside the container list\n",
    "current_debug_data = debug_container[0]\n",
    "\n",
    "# 2. Check if the audit data exists (it is created only in 'Ranking' mode)\n",
    "if current_debug_data and 'audit_liquidity' in current_debug_data:\n",
    "    audit = current_debug_data['audit_liquidity']\n",
    "    snapshot_df = audit['universe_snapshot']\n",
    "    \n",
    "    print(f\"\ud83d\udcc5 Date: {audit['date'].date()}\")\n",
    "    print(f\"\ud83d\udcb0 Calculated Cutoff: ${audit['final_cutoff_usd']:,.0f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# 3. View the tickers right around the cutoff point\n",
    "# Find the index where 'Passed_Vol_Check' switches from True to False\n",
    "    try:\n",
    "        # Get the integer location (iloc) of the last True value\n",
    "        last_pass_iloc = np.where(snapshot_df['Passed_Vol_Check'])[0][-1]\n",
    "        \n",
    "        # Show 5 rows before and 5 rows after the cutoff\n",
    "        start = max(0, last_pass_iloc - 5)\n",
    "        end = min(len(snapshot_df), last_pass_iloc + 6)\n",
    "        \n",
    "        display(snapshot_df.iloc[start:end].style.format({\n",
    "            'RollMedDollarVol': '${:,.0f}',\n",
    "            'Calculated_Cutoff': '${:,.0f}',\n",
    "            'RollingStalePct': '{:.1%}'\n",
    "        }))\n",
    "    except IndexError:\n",
    "        print(\"Could not determine cutoff boundary (maybe all passed or all failed).\")\n",
    "        display(snapshot_df.head())\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f No audit data found. Make sure you are in 'Ranking' mode and have clicked 'Update Chart'.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b6b19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(snapshot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "551b239f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EngineOutput(portfolio_series=Date\n",
      "2015-04-28    1.000000\n",
      "2015-04-29    1.015713\n",
      "2015-04-30    1.050600\n",
      "2015-05-01    1.077869\n",
      "2015-05-04    1.078302\n",
      "2015-05-05    1.063868\n",
      "2015-05-06    1.073178\n",
      "2015-05-07    1.086883\n",
      "2015-05-08    1.099645\n",
      "2015-05-11    1.099924\n",
      "2015-05-12    1.092934\n",
      "2015-05-13    1.101673\n",
      "2015-05-14    1.113253\n",
      "2015-05-15    1.117366\n",
      "2015-05-18    1.118461\n",
      "2015-05-19    1.119714\n",
      "dtype: float64, benchmark_series=Date\n",
      "2015-04-28    1.000000\n",
      "2015-04-29    0.995925\n",
      "2015-04-30    0.986015\n",
      "2015-05-01    0.996334\n",
      "2015-05-04    0.999430\n",
      "2015-05-05    0.987768\n",
      "2015-05-06    0.983798\n",
      "2015-05-07    0.987768\n",
      "2015-05-08    1.000725\n",
      "2015-05-11    0.995925\n",
      "2015-05-12    0.993032\n",
      "2015-05-13    0.993342\n",
      "2015-05-14    1.003716\n",
      "2015-05-15    1.004744\n",
      "2015-05-18    1.007841\n",
      "2015-05-19    1.007327\n",
      "dtype: float64, normalized_plot_data=Ticker           VMC       MLM      MDLZ       LKQ\n",
      "Date                                              \n",
      "2015-04-28  1.000000  1.000000  1.000000  1.000000\n",
      "2015-04-29  0.999759  1.001462  1.051630  1.009999\n",
      "2015-04-30  1.029246  1.048120  1.042661  1.082371\n",
      "2015-05-01  1.063064  1.086182  1.050272  1.111958\n",
      "2015-05-04  1.060297  1.090296  1.049457  1.113156\n",
      "2015-05-05  1.029004  1.079207  1.041302  1.105959\n",
      "2015-05-06  1.051270  1.095441  1.044837  1.101162\n",
      "2015-05-07  1.077145  1.106387  1.059238  1.104761\n",
      "2015-05-08  1.088819  1.138057  1.071739  1.099964\n",
      "2015-05-11  1.098689  1.129899  1.068748  1.102360\n",
      "2015-05-12  1.085932  1.107641  1.068204  1.109959\n",
      "2015-05-13  1.093633  1.131298  1.068204  1.113557\n",
      "2015-05-14  1.115899  1.136443  1.088313  1.112359\n",
      "2015-05-15  1.107114  1.141212  1.099185  1.121953\n",
      "2015-05-18  1.109400  1.141141  1.086954  1.136348\n",
      "2015-05-19  1.111325  1.133431  1.093751  1.140348, tickers=['LKQ', 'MLM', 'MDLZ', 'VMC'], initial_weights=LKQ     0.25\n",
      "MLM     0.25\n",
      "MDLZ    0.25\n",
      "VMC     0.25\n",
      "dtype: float64, perf_metrics={'full_p_gain': 0.11971351101912475, 'calc_p_gain': 0.09293385494501005, 'fwd_p_gain': 0.024502540526994743, 'full_p_sharpe_atr': 0.39833851694465405, 'calc_p_sharpe_atr': 0.46820493409120156, 'fwd_p_sharpe_atr': 0.2566350817884936, 'full_b_gain': 0.007326801352640411, 'calc_b_gain': -0.0069675837039056, 'fwd_b_gain': 0.014394681202716919, 'full_b_sharpe_atr': 0.05407359003487235, 'calc_b_sharpe_atr': -0.06988985031193463, 'fwd_b_sharpe_atr': 0.3127671531446315}, results_df=        Rank  Metric Value  Fwd Gain\n",
      "Ticker                              \n",
      "LKQ        1      0.524672  0.027379\n",
      "MLM        2      0.466553  0.023283\n",
      "MDLZ       3      0.456371  0.023915\n",
      "VMC        4      0.440323  0.023384, start_date=Timestamp('2015-04-28 00:00:00'), calc_end_date=Timestamp('2015-05-12 00:00:00'), viz_end_date=Timestamp('2015-05-19 00:00:00'), error_msg=None, debug_data={'audit_liquidity': {'date': Timestamp('2015-04-28 00:00:00'), 'total_tickers_available': 1226, 'percentile_setting': 0.5, 'percentile_value_usd': 37206497.0155, 'final_cutoff_usd': 37206497.0155, 'tickers_passed': 605, 'universe_snapshot':              TR       ATR      ATRP  RollingStalePct  RollMedDollarVol  \\\n",
      "Ticker                                                                   \n",
      "SPY     1.81500  1.604518  0.009071              0.0      1.886723e+10   \n",
      "AAPL    1.10610  0.520297  0.017905              0.0      5.348299e+09   \n",
      "IWM     1.84700  1.280112  0.011738              0.0      3.867770e+09   \n",
      "QQQ     1.33100  1.133654  0.011149              0.0      3.066815e+09   \n",
      "META    1.66980  1.605122  0.020018              0.0      2.275138e+09   \n",
      "...         ...       ...       ...              ...               ...   \n",
      "PDBC    0.00463  0.099226  0.010278              NaN               NaN   \n",
      "QRVO    4.86600  3.038847  0.044781              NaN               NaN   \n",
      "QSR     1.97350  1.002236  0.031966              NaN               NaN   \n",
      "SMMT    0.39000  0.684552  0.066526              NaN               NaN   \n",
      "TOTL    0.05790  0.075702  0.002268              NaN               NaN   \n",
      "\n",
      "        RollingSameVolCount  Calculated_Cutoff  Passed_Vol_Check  Passed_Final  \n",
      "Ticker                                                                          \n",
      "SPY                     0.0       3.720650e+07              True          True  \n",
      "AAPL                    0.0       3.720650e+07              True          True  \n",
      "IWM                     0.0       3.720650e+07              True          True  \n",
      "QQQ                     0.0       3.720650e+07              True          True  \n",
      "META                    0.0       3.720650e+07              True          True  \n",
      "...                     ...                ...               ...           ...  \n",
      "PDBC                    NaN       3.720650e+07             False         False  \n",
      "QRVO                    NaN       3.720650e+07             False         False  \n",
      "QSR                     NaN       3.720650e+07             False         False  \n",
      "SMMT                    NaN       3.720650e+07             False         False  \n",
      "TOTL                    NaN       3.720650e+07             False         False  \n",
      "\n",
      "[1226 rows x 9 columns]}, 'portfolio_trace':             Norm_Price_VMC  Norm_Price_MLM  Norm_Price_MDLZ  Norm_Price_LKQ  \\\n",
      "Date                                                                          \n",
      "2015-04-28        1.000000        1.000000         1.000000        1.000000   \n",
      "2015-04-29        0.999759        1.001462         1.051630        1.009999   \n",
      "2015-04-30        1.029246        1.048120         1.042661        1.082371   \n",
      "2015-05-01        1.063064        1.086182         1.050272        1.111958   \n",
      "2015-05-04        1.060297        1.090296         1.049457        1.113156   \n",
      "2015-05-05        1.029004        1.079207         1.041302        1.105959   \n",
      "2015-05-06        1.051270        1.095441         1.044837        1.101162   \n",
      "2015-05-07        1.077145        1.106387         1.059238        1.104761   \n",
      "2015-05-08        1.088819        1.138057         1.071739        1.099964   \n",
      "2015-05-11        1.098689        1.129899         1.068748        1.102360   \n",
      "2015-05-12        1.085932        1.107641         1.068204        1.109959   \n",
      "2015-05-13        1.093633        1.131298         1.068204        1.113557   \n",
      "2015-05-14        1.115899        1.136443         1.088313        1.112359   \n",
      "2015-05-15        1.107114        1.141212         1.099185        1.121953   \n",
      "2015-05-18        1.109400        1.141141         1.086954        1.136348   \n",
      "2015-05-19        1.111325        1.133431         1.093751        1.140348   \n",
      "\n",
      "            Norm_Price_Portfolio  Norm_Price_Benchmark_VOO  \n",
      "Date                                                        \n",
      "2015-04-28              1.000000                  1.000000  \n",
      "2015-04-29              1.015713                  0.995925  \n",
      "2015-04-30              1.050600                  0.986015  \n",
      "2015-05-01              1.077869                  0.996334  \n",
      "2015-05-04              1.078302                  0.999430  \n",
      "2015-05-05              1.063868                  0.987768  \n",
      "2015-05-06              1.073178                  0.983798  \n",
      "2015-05-07              1.086883                  0.987768  \n",
      "2015-05-08              1.099645                  1.000725  \n",
      "2015-05-11              1.099924                  0.995925  \n",
      "2015-05-12              1.092934                  0.993032  \n",
      "2015-05-13              1.101673                  0.993342  \n",
      "2015-05-14              1.113253                  1.003716  \n",
      "2015-05-15              1.117366                  1.004744  \n",
      "2015-05-18              1.118461                  1.007841  \n",
      "2015-05-19              1.119714                  1.007327  })\n"
     ]
    }
   ],
   "source": [
    "print_nested(results_container)\n",
    "# print('='*20)\n",
    "# print_nested(debug_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d210b89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}