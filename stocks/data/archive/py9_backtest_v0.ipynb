{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Python will look in these locations:\n",
      "['C:\\\\Users\\\\ping\\\\.pyenv\\\\pyenv-win\\\\versions\\\\3.11.9\\\\python311.zip', 'C:\\\\Users\\\\ping\\\\.pyenv\\\\pyenv-win\\\\versions\\\\3.11.9\\\\DLLs', 'C:\\\\Users\\\\ping\\\\.pyenv\\\\pyenv-win\\\\versions\\\\3.11.9\\\\Lib', 'C:\\\\Users\\\\ping\\\\.pyenv\\\\pyenv-win\\\\versions\\\\3.11.9', 'c:\\\\Users\\\\ping\\\\Files_win10\\\\python\\\\py311\\\\.venv', '', 'c:\\\\Users\\\\ping\\\\Files_win10\\\\python\\\\py311\\\\.venv\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\ping\\\\Files_win10\\\\python\\\\py311\\\\.venv\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\ping\\\\Files_win10\\\\python\\\\py311\\\\.venv\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\ping\\\\Files_win10\\\\python\\\\py311\\\\.venv\\\\Lib\\\\site-packages\\\\Pythonwin', 'c:\\\\Users\\\\ping\\\\Files_win10\\\\python\\\\py311\\\\stocks\\\\src', 'c:\\\\Users\\\\ping\\\\Files_win10\\\\python\\\\py311\\\\.venv\\\\Lib\\\\site-packages\\\\setuptools\\\\_vendor', 'c:\\\\Users\\\\ping\\\\Files_win10\\\\python\\\\py311\\\\stocks\\\\src', 'c:\\\\Users\\\\ping\\\\Files_win10\\\\python\\\\py311\\\\stocks\\\\src', 'c:\\\\Users\\\\ping\\\\Files_win10\\\\python\\\\py311\\\\stocks\\\\src', 'c:\\\\Users\\\\ping\\\\Files_win10\\\\python\\\\py311\\\\stocks\\\\src']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.display import display, Markdown  # Assuming you use these for display\n",
    "\n",
    "\n",
    "# Set pandas display options to show more columns and rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "# pd.set_option('display.max_rows', 10)       # Limit to 10 rows for readability\n",
    "pd.set_option('display.width', 1500)        # Let the display adjust to the window\n",
    "\n",
    "\n",
    "# Notebook cell\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Get root directory (assuming notebook is in root/notebooks/)\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "ROOT_DIR = NOTEBOOK_DIR.parent if NOTEBOOK_DIR.name == 'notebooks' else NOTEBOOK_DIR\n",
    "\n",
    "# Add src directory to Python path\n",
    "sys.path.append(str(ROOT_DIR / 'src'))\n",
    "\n",
    "# Verify path\n",
    "print(f\"Python will look in these locations:\\n{sys.path}\")\n",
    "\n",
    "\n",
    "# --- Execute the processor ---\n",
    "import utils\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_OHLCV: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_clean_stocks_etfs.parquet\n",
      "df_OHLCV:\n",
      "                   Adj Open  Adj High  Adj Low  Adj Close   Volume\n",
      "Symbol Date                                                       \n",
      "A      2025-05-14    114.95    115.50   111.28     111.52  2154239\n",
      "       2025-05-13    115.43    116.88   114.82     115.42  2845300\n",
      "       2025-05-12    110.81    115.71   110.45     115.55  2873100\n",
      "       2025-05-09    108.96    109.86   106.79     106.93  1369500\n",
      "       2025-05-08    108.00    110.65   106.55     108.70  2093300\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 503286 entries, ('A', Timestamp('2025-05-14 00:00:00')) to ('ZWS', Timestamp('2024-02-01 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   Adj Open   503286 non-null  float64\n",
      " 1   Adj High   503286 non-null  float64\n",
      " 2   Adj Low    503286 non-null  float64\n",
      " 3   Adj Close  503286 non-null  float64\n",
      " 4   Volume     503286 non-null  int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 21.2+ MB\n",
      "df_OHLCV.info():\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# path_OHLCV, _, _ = utils.main_processor(\n",
    "#     data_dir='..\\data',  \n",
    "#     # data_dir='output\\selection_results',  # search project ..\\data\n",
    "#     downloads_dir='',  # None searchs Downloads dir, '' omits search1\n",
    "#     downloads_limit=60,  # search the first 10 files\n",
    "#     clean_name_override=None,  # override filename\n",
    "#     start_file_pattern='df_OHLCV', # search for files starting with 'df_'\n",
    "#     contains_pattern='clean' # search for files containing 'df_'\n",
    "# )\n",
    "path_OHLCV = ROOT_DIR / 'data' / 'df_OHLCV_clean_stocks_etfs.parquet'\n",
    "\n",
    "print(f'path_OHLCV: {path_OHLCV}')\n",
    "df_OHLCV = pd.read_parquet(path_OHLCV)\n",
    "print(f'df_OHLCV:\\n{df_OHLCV.head()}\\n')\n",
    "print(f'df_OHLCV.info():\\n{df_OHLCV.info()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import pprint # For cleaner dictionary printing\n",
    "import numpy as np\n",
    "import traceback # Added for detailed error logging\n",
    "import json\n",
    "import os # For creating directories and checking file existence\n",
    "import logging # For logging instead of print\n",
    "import datetime # For timestamping runs\n",
    "import sys # Added for interpreter/path logging\n",
    "\n",
    "from typing import List, Dict, Tuple, Set, Any, Callable, Optional # Import types for hinting\n",
    "\n",
    "\n",
    "# --- Make sure 'utils' exists and has 'extract_date_from_string' ---\n",
    "try:\n",
    "    import utils # Assuming this is your utility module for date extraction\n",
    "    # Check if the function exists (optional but good practice)\n",
    "    if not hasattr(utils, 'extract_date_from_string'):\n",
    "        logging.error(\"ERROR: 'utils' module imported but 'extract_date_from_string' function not found!\")\n",
    "        sys.exit(\"Critical function missing from utils module.\")\n",
    "except ImportError:\n",
    "    # This will be caught if logging isn't set up yet, so print is a fallback here.\n",
    "    print(\"ERROR: Failed to import the 'utils' module. Make sure utils.py exists and is in the Python path.\")\n",
    "    # If logging is set up, this will also go to the log.\n",
    "    if logging.getLogger().hasHandlers():\n",
    "        logging.error(\"ERROR: Failed to import the 'utils' module.\", exc_info=True)\n",
    "    sys.exit(\"Missing required 'utils' module.\") # Exit if utils can't be imported\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: An unexpected error occurred during 'utils' import: {e}\")\n",
    "    if logging.getLogger().hasHandlers():\n",
    "        logging.error(f\"ERROR: An unexpected error occurred during 'utils' import: {e}\", exc_info=True)\n",
    "    sys.exit(\"Error during module import.\")\n",
    "\n",
    "\n",
    "# --- Constants ---\n",
    "RISK_FREE_RATE_DAILY = 0.04 / 365\n",
    "LOG_DIR = 'logs'\n",
    "RESULTS_DIR = 'output/backtest_results'\n",
    "RESULTS_CSV_PATH = os.path.join(RESULTS_DIR, 'backtest_parameter_performance.csv') # Path to the CSV file\n",
    "RESULTS_DF_PATH = os.path.join(RESULTS_DIR, 'df_backtest_parameter_performance.parquet') # Path to dataframe file\n",
    "\n",
    "# Parameters that, along with selection_date and scheme, define a unique run for overwriting purposes\n",
    "PARAMS_TO_TRACK = [\n",
    "    'n_select_requested',\n",
    "    'inv_vol_col_name',\n",
    "    'filter_min_price',\n",
    "    'filter_min_avg_volume_m',\n",
    "    'filter_min_roe_pct',\n",
    "    'filter_max_debt_eq',\n",
    "    'score_weight_rsi',\n",
    "    'score_weight_change',\n",
    "    'score_weight_rel_volume',\n",
    "    'score_weight_volatility',\n",
    "    # 'weight' (scheme) is handled separately by using 'scheme' column\n",
    "]\n",
    "\n",
    "# Define column order for the CSV file. This ensures consistency.\n",
    "# This list should include all fields from PARAMS_TO_TRACK, plus others.\n",
    "CSV_COLUMN_ORDER = [\n",
    "    'run_timestamp', 'log_file', 'selection_date', 'actual_selection_date_used', 'scheme',\n",
    "    # Parameters from PARAMS_TO_TRACK\n",
    "    'n_select_requested', 'inv_vol_col_name', 'filter_min_price',\n",
    "    'filter_min_avg_volume_m', 'filter_min_roe_pct', 'filter_max_debt_eq',\n",
    "    'score_weight_rsi', 'score_weight_change', 'score_weight_rel_volume', 'score_weight_volatility',\n",
    "    # Other parameters/results\n",
    "    'n_select_actual',\n",
    "    'portfolio_return', 'portfolio_return_normalized',\n",
    "    'num_attempted_trades',\n",
    "    'num_successful_trades', 'num_failed_or_skipped_trades',\n",
    "    'total_weight_traded',\n",
    "    'win_rate', 'average_return', 'std_dev_return', 'sharpe_ratio_period'\n",
    "]\n",
    "\n",
    "# Check at startup that all PARAMS_TO_TRACK are in CSV_COLUMN_ORDER\n",
    "if not set(PARAMS_TO_TRACK).issubset(set(CSV_COLUMN_ORDER)):\n",
    "    logging.error(\"CRITICAL: Not all PARAMS_TO_TRACK are present in CSV_COLUMN_ORDER!\")\n",
    "    sys.exit(\"Configuration error: PARAMS_TO_TRACK mismatch with CSV_COLUMN_ORDER.\")\n",
    "\n",
    "\n",
    "# Columns used to uniquely identify a row for the purpose of overwriting.\n",
    "# This combines 'selection_date', 'scheme', and all parameters defined in PARAMS_TO_TRACK.\n",
    "UNIQUE_KEY_COLUMNS_FOR_CSV = ['selection_date', 'scheme'] + PARAMS_TO_TRACK\n",
    "\n",
    "# Path to adjusted close prices\n",
    "ADJ_CLOSE_PATH = '../data/df_adj_close.parquet'\n",
    "\n",
    "# Path to selection results\n",
    "OUTPUT_DIR = 'output/selection_results/'\n",
    "\n",
    "\n",
    "\n",
    "# --- 1. Setup Logging ---\n",
    "def setup_logging(log_dir: str = LOG_DIR):\n",
    "    \"\"\"Configures logging to write to a file.\"\"\"\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    log_filename = datetime.datetime.now().strftime(\"backtest_run_%Y%m%d_%H%M%S.log\")\n",
    "    log_filepath = os.path.join(log_dir, log_filename)\n",
    "\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO) \n",
    "\n",
    "    for handler in logger.handlers[:]:\n",
    "        handler.close()\n",
    "        logger.removeHandler(handler)\n",
    "\n",
    "    file_handler_instance = logging.FileHandler(log_filepath)\n",
    "    file_handler_instance.setLevel(logging.INFO) \n",
    "\n",
    "    stream_handler = logging.StreamHandler()\n",
    "    stream_handler.setLevel(logging.INFO) \n",
    "\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    file_handler_instance.setFormatter(formatter)\n",
    "    stream_handler.setFormatter(formatter)\n",
    "\n",
    "    logger.addHandler(file_handler_instance)\n",
    "    logger.addHandler(stream_handler)\n",
    "\n",
    "    logging.info(f\"Logging initialized. Log file: {log_filepath}\")\n",
    "    return log_filepath \n",
    "\n",
    "\n",
    "def extract_backtest_setups(\n",
    "    dataframe: pd.DataFrame,\n",
    "    weight_column_names: List[str],\n",
    "    date_str: str, \n",
    "    scheme_separator: str = '_'\n",
    "    ) -> Dict[str, Dict[str, Dict[str, float]]]: \n",
    "    \"\"\"\n",
    "    Extracts Ticker-Weight pairs from specified columns in a DataFrame.\n",
    "    \"\"\"\n",
    "    if not date_str: \n",
    "        logging.error(\"The 'date_str' argument cannot be None or empty.\")\n",
    "        raise ValueError(\"The 'date_str' argument cannot be None or empty.\")\n",
    "\n",
    "    if dataframe is None or dataframe.empty:\n",
    "        logging.warning(\"Input DataFrame is None or empty. Cannot extract setups.\")\n",
    "        return {} \n",
    "\n",
    "    scheme_setups: Dict[str, Dict[str, float]] = {}\n",
    "\n",
    "    for col_name in weight_column_names:\n",
    "        if col_name in dataframe.columns:\n",
    "            try:\n",
    "                parts = col_name.split(scheme_separator)\n",
    "                scheme_name = parts[-1] if len(parts) > 1 else col_name\n",
    "                numeric_col = pd.to_numeric(dataframe[col_name], errors='coerce')\n",
    "                ticker_weights = numeric_col.dropna().astype(float).to_dict()\n",
    "\n",
    "                if ticker_weights:\n",
    "                    if scheme_name in scheme_setups:\n",
    "                        logging.warning(f\"Duplicate scheme name '{scheme_name}' derived. \"\n",
    "                                        f\"Weights from column '{col_name}' might overwrite previous ones.\")\n",
    "                    scheme_setups[scheme_name] = ticker_weights\n",
    "                    logging.info(f\"Successfully extracted weights for scheme: {scheme_name} \"\n",
    "                                f\"({len(ticker_weights)} tickers) for date {date_str}\")\n",
    "                else:\n",
    "                    logging.warning(f\"No valid (non-NaN, numeric) weights found for column '{col_name}'. \"\n",
    "                                  f\"Skipping scheme '{scheme_name}' for date '{date_str}'.\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing column '{col_name}': {e}\", exc_info=True) \n",
    "        else:\n",
    "            logging.warning(f\"Column '{col_name}' not found in the DataFrame.\")\n",
    "\n",
    "    final_output = {date_str: scheme_setups}\n",
    "\n",
    "    if not scheme_setups:\n",
    "      logging.warning(f\"No valid backtest setups generated for date {date_str}.\")\n",
    "    return final_output\n",
    "\n",
    "\n",
    "def run_single_backtest(\n",
    "    selection_date: str,\n",
    "    scheme_name: str,\n",
    "    ticker_weights: Dict[str, float],\n",
    "    df_adj_close: pd.DataFrame,\n",
    "    risk_free_rate_daily: float = RISK_FREE_RATE_DAILY,\n",
    "    ) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Runs a simple backtest for a given selection date and ticker weights.\n",
    "    \"\"\"\n",
    "    logging.info(\"-\" * 30)\n",
    "    logging.info(f\"Initiating Backtest Run...\")\n",
    "    logging.info(f\"  Date          : {selection_date}\")\n",
    "    logging.info(f\"  Scheme        : {scheme_name}\")\n",
    "    logging.info(f\"  Num Tickers   : {len(ticker_weights)}\")\n",
    "    sample_weights_str = io.StringIO()\n",
    "    pprint.pprint(dict(list(ticker_weights.items())[:3]), stream=sample_weights_str)\n",
    "    if len(ticker_weights) > 3: sample_weights_str.write(\"    ...\\n\")\n",
    "    logging.debug(f\"  Sample Weights:\\n{sample_weights_str.getvalue()}\") \n",
    "\n",
    "    try:\n",
    "        df_prices = df_adj_close.copy()\n",
    "        if not isinstance(df_prices.index, pd.DatetimeIndex):\n",
    "            try:\n",
    "                df_prices.index = pd.to_datetime(df_prices.index)\n",
    "                logging.info(\"  Info: Converted DataFrame index to DatetimeIndex.\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"  Error: Failed to convert DataFrame index to DatetimeIndex: {e}\", exc_info=True)\n",
    "                logging.info(\"-\" * 30)\n",
    "                return None\n",
    "\n",
    "        if not df_prices.index.is_monotonic_increasing:\n",
    "            logging.info(\"  Info: Sorting DataFrame index by date...\")\n",
    "            df_prices = df_prices.sort_index()\n",
    "            logging.info(\"  Info: DataFrame index sorted.\")\n",
    "\n",
    "        all_trading_dates = df_prices.index\n",
    "        selection_timestamp = pd.Timestamp(selection_date)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"  Error during initial data preparation: {e}\", exc_info=True)\n",
    "        logging.info(\"-\" * 30)\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        try:\n",
    "            selection_idx = all_trading_dates.get_loc(selection_timestamp)\n",
    "        except KeyError:\n",
    "            indexer = all_trading_dates.get_indexer([selection_timestamp], method='ffill') \n",
    "            if indexer[0] == -1: \n",
    "                 indexer_bfill = all_trading_dates.get_indexer([selection_timestamp], method='bfill')\n",
    "                 if indexer_bfill[0] == -1:\n",
    "                    logging.error(f\"  Error: Selection date {selection_date} or a nearby trading date not found in price data index.\")\n",
    "                    logging.info(\"-\" * 30)\n",
    "                    return None\n",
    "                 else:\n",
    "                     selection_idx = indexer_bfill[0]\n",
    "                     actual_selection_date_used = all_trading_dates[selection_idx]\n",
    "                     logging.warning(f\"  Warning: Exact selection date {selection_date} not found. Using next available date: {actual_selection_date_used.strftime('%Y-%m-%d')}\")\n",
    "            else:\n",
    "                selection_idx = indexer[0]\n",
    "                actual_selection_date_used = all_trading_dates[selection_idx]\n",
    "                if actual_selection_date_used != selection_timestamp:\n",
    "                     logging.warning(f\"  Warning: Exact selection date {selection_date} not found. Using previous available date: {actual_selection_date_used.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "        if selection_idx + 1 >= len(all_trading_dates):\n",
    "            logging.error(f\"  Error: No trading date found after selection date index {selection_idx} ({all_trading_dates[selection_idx].strftime('%Y-%m-%d')}).\")\n",
    "            logging.info(\"-\" * 30)\n",
    "            return None\n",
    "        buy_date = all_trading_dates[selection_idx + 1]\n",
    "\n",
    "        if selection_idx + 2 >= len(all_trading_dates):\n",
    "            logging.error(f\"  Error: No trading date found after buy date {buy_date.strftime('%Y-%m-%d')}.\")\n",
    "            logging.info(\"-\" * 30)\n",
    "            return None\n",
    "        sell_date = all_trading_dates[selection_idx + 2]\n",
    "\n",
    "        logging.info(f\"  Selection Date Used: {all_trading_dates[selection_idx].strftime('%Y-%m-%d')}\")\n",
    "        logging.info(f\"  Buy Date           : {buy_date.strftime('%Y-%m-%d')}\")\n",
    "        logging.info(f\"  Sell Date          : {sell_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "        trades = []\n",
    "        returns = []\n",
    "        portfolio_return = 0.0\n",
    "        total_weight_traded = 0.0\n",
    "        valid_tickers_count = 0\n",
    "        missing_price_count = 0\n",
    "\n",
    "        relevant_tickers = [t for t in ticker_weights.keys() if t in df_prices.columns]\n",
    "        relevant_dates = [buy_date, sell_date]\n",
    "        try:\n",
    "            price_subset = df_prices.loc[relevant_dates, relevant_tickers]\n",
    "        except KeyError as e:\n",
    "            logging.error(f\"  Error selecting price subset for dates {relevant_dates} and tickers. Missing columns?: {e}\", exc_info=True)\n",
    "            return None \n",
    "\n",
    "        for ticker in ticker_weights.keys():\n",
    "            if ticker not in price_subset.columns: \n",
    "                logging.warning(f\"    Warning: Ticker {ticker} not found in price data columns. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            valid_tickers_count += 1\n",
    "            trade_info = { \"ticker\": ticker, \"weight\": ticker_weights[ticker],\n",
    "                          \"buy_date\": buy_date.strftime('%Y-%m-%d'), \"sell_date\": sell_date.strftime('%Y-%m-%d'),\n",
    "                          \"buy_price\": None, \"sell_price\": None, \"return\": None, \"status\": \"Pending\" }\n",
    "\n",
    "            try:\n",
    "                buy_price = price_subset.at[buy_date, ticker]\n",
    "                if pd.isna(buy_price) or buy_price <= 0: raise ValueError(f\"Invalid buy price ({buy_price})\")\n",
    "                sell_price = price_subset.at[sell_date, ticker]\n",
    "                if pd.isna(sell_price): raise ValueError(f\"Invalid sell price ({sell_price})\") \n",
    "\n",
    "                trade_return = (sell_price - buy_price) / buy_price\n",
    "                trade_info.update({\"buy_price\": buy_price, \"sell_price\": sell_price, \"return\": trade_return, \"status\": \"Success\"})\n",
    "                trades.append(trade_info)\n",
    "                returns.append(trade_return)\n",
    "\n",
    "                current_weight = ticker_weights[ticker]\n",
    "                portfolio_return += trade_return * current_weight\n",
    "                total_weight_traded += current_weight\n",
    "            except KeyError as e:\n",
    "                logging.warning(f\"    Error accessing price for {ticker} on {e}. Skipping trade.\")\n",
    "                trade_info[\"status\"] = f\"Error: Price data missing ({e})\"\n",
    "                trades.append(trade_info)\n",
    "                missing_price_count += 1\n",
    "            except ValueError as e:\n",
    "                logging.warning(f\"    Warning: Invalid price data for {ticker} between {buy_date.strftime('%Y-%m-%d')} and {sell_date.strftime('%Y-%m-%d')} ({e}). Skipping trade.\")\n",
    "                trade_info[\"status\"] = f\"Skipped: Invalid price ({e})\"\n",
    "                try: trade_info[\"buy_price\"] = price_subset.at[buy_date, ticker]\n",
    "                except: pass\n",
    "                try: trade_info[\"sell_price\"] = price_subset.at[sell_date, ticker]\n",
    "                except: pass\n",
    "                trades.append(trade_info)\n",
    "                missing_price_count += 1\n",
    "            except Exception as e:\n",
    "                logging.error(f\"    Unexpected error processing trade for {ticker}: {e}\", exc_info=True)\n",
    "                trade_info[\"status\"] = f\"Error: Unexpected ({type(e).__name__})\"\n",
    "                trades.append(trade_info)\n",
    "                missing_price_count += 1\n",
    "\n",
    "        num_attempted_trades = valid_tickers_count\n",
    "        num_successful_trades = len(returns)\n",
    "        metrics = {\n",
    "            'num_selected_tickers': len(ticker_weights),\n",
    "            'num_valid_tickers_in_data': valid_tickers_count,\n",
    "            'num_attempted_trades': num_attempted_trades,\n",
    "            'num_successful_trades': num_successful_trades,\n",
    "            'num_failed_or_skipped_trades': num_attempted_trades - num_successful_trades,\n",
    "            'portfolio_return': portfolio_return if num_successful_trades > 0 and abs(total_weight_traded) > 1e-9 else 0.0,\n",
    "            'total_weight_traded': total_weight_traded,\n",
    "            'win_rate': None, 'average_return': None, 'std_dev_return': None, 'sharpe_ratio_period': None,\n",
    "        }\n",
    "\n",
    "        if num_successful_trades > 0:\n",
    "            returns_array = np.array(returns)\n",
    "            metrics['win_rate'] = np.sum(returns_array > 0) / num_successful_trades\n",
    "            metrics['average_return'] = np.mean(returns_array)\n",
    "            metrics['std_dev_return'] = np.std(returns_array, ddof=1) if num_successful_trades > 1 else 0.0\n",
    "            std_dev = metrics['std_dev_return']\n",
    "            avg_ret = metrics['average_return'] \n",
    "\n",
    "            if std_dev is not None and std_dev > 1e-9: \n",
    "                excess_return = avg_ret - risk_free_rate_daily\n",
    "                metrics['sharpe_ratio_period'] = excess_return / std_dev\n",
    "            elif avg_ret is not None: \n",
    "                excess_return = avg_ret - risk_free_rate_daily\n",
    "                if abs(excess_return) < 1e-9: \n",
    "                    metrics['sharpe_ratio_period'] = 0.0\n",
    "                else: \n",
    "                    metrics['sharpe_ratio_period'] = np.inf * np.sign(excess_return)\n",
    "            else: \n",
    "                metrics['sharpe_ratio_period'] = np.nan\n",
    "\n",
    "            logging.info(f\"  Trades Executed: {num_successful_trades}/{num_attempted_trades}\")\n",
    "            if abs(total_weight_traded - 1.0) > 1e-6 and abs(total_weight_traded) > 1e-9:\n",
    "                normalized_portfolio_return = portfolio_return / total_weight_traded\n",
    "                logging.info(f\"  Portfolio Return (Raw)    : {portfolio_return:.4f} (Based on Weight Sum: {total_weight_traded:.4f})\")\n",
    "                logging.info(f\"  Portfolio Return (Norm'd) : {normalized_portfolio_return:.4f}\")\n",
    "                metrics['portfolio_return_normalized'] = normalized_portfolio_return \n",
    "            else:\n",
    "                 logging.info(f\"  Portfolio Return          : {portfolio_return:.4f} (Based on Weight Sum: {total_weight_traded:.4f})\")\n",
    "\n",
    "            logging.info(f\"  Win Rate (Individual)   : {metrics['win_rate']:.2%}\" if metrics['win_rate'] is not None else \"N/A\")\n",
    "            logging.info(f\"  Avg Ticker Return       : {metrics['average_return']:.4f}\" if metrics['average_return'] is not None else \"N/A\")\n",
    "            logging.info(f\"  Std Dev Ticker Return   : {metrics['std_dev_return']:.4f}\" if metrics['std_dev_return'] is not None else \"N/A\")\n",
    "            logging.info(f\"  Period Sharpe (Indiv)   : {metrics['sharpe_ratio_period']:.4f}\" if metrics['sharpe_ratio_period'] is not None else \"N/A\")\n",
    "        else:\n",
    "            logging.warning(f\"  No successful trades executed out of {num_attempted_trades} attempted.\")\n",
    "            logging.info(f\"  Portfolio Return          : {metrics['portfolio_return']:.4f}\")\n",
    "\n",
    "        backtest_results = {\n",
    "            \"run_inputs\": {\n",
    "                \"selection_date\": selection_date,\n",
    "                \"actual_selection_date_used\": all_trading_dates[selection_idx].strftime('%Y-%m-%d'), \n",
    "                \"scheme_name\": scheme_name,\n",
    "                \"num_tickers_input\": len(ticker_weights),\n",
    "                \"risk_free_rate_daily\": risk_free_rate_daily,\n",
    "                \"buy_date\": buy_date.strftime('%Y-%m-%d'),\n",
    "                \"sell_date\": sell_date.strftime('%Y-%m-%d'),\n",
    "            },\n",
    "            \"metrics\": metrics,\n",
    "            \"trades\": trades \n",
    "        }\n",
    "        logging.info(f\"Backtest simulation for '{scheme_name}' on {selection_date} completed.\")\n",
    "        logging.info(\"-\" * 30)\n",
    "        return backtest_results\n",
    "    except Exception as e:\n",
    "        logging.critical(f\"  FATAL ERROR during backtest run for {selection_date}, {scheme_name}: {e}\", exc_info=True)\n",
    "        logging.info(\"-\" * 30)\n",
    "        return None\n",
    "\n",
    "\n",
    "def process_all_backtests(\n",
    "    nested_setups: Dict[str, Dict[str, Dict[str, float]]],\n",
    "    df_adj_close: pd.DataFrame \n",
    "    ) -> Dict[str, Dict[str, Optional[Dict[str, Any]]]]:\n",
    "    \"\"\"\n",
    "    Iterates through the nested setup dictionary and runs individual backtests.\n",
    "    \"\"\"  \n",
    "    all_results: Dict[str, Dict[str, Optional[Dict[str, Any]]]] = {}\n",
    "\n",
    "    if not nested_setups:\n",
    "        logging.warning(\"Received empty setup dictionary. No backtests to run.\")\n",
    "        return all_results\n",
    "\n",
    "    logging.info(\"\\n===== Starting Batch Backtest Processing =====\")\n",
    "    try:\n",
    "        df_prices_global = df_adj_close.copy()\n",
    "        if not isinstance(df_prices_global.index, pd.DatetimeIndex):\n",
    "            df_prices_global.index = pd.to_datetime(df_prices_global.index)\n",
    "        if not df_prices_global.index.is_monotonic_increasing:\n",
    "            df_prices_global = df_prices_global.sort_index()\n",
    "        logging.info(\"Prepared global price data copy for backtests.\")\n",
    "    except Exception as e:\n",
    "        logging.critical(f\"Failed to prepare global price data copy: {e}\", exc_info=True)\n",
    "        return all_results \n",
    "\n",
    "    for date_str, schemes_for_date in nested_setups.items():\n",
    "        logging.info(f\"\\nProcessing date: {date_str}\")\n",
    "        if not schemes_for_date:\n",
    "            logging.warning(f\"  No schemes found for this date. Skipping.\")\n",
    "            all_results[date_str] = {} \n",
    "            continue\n",
    "\n",
    "        results_for_date: Dict[str, Optional[Dict[str, Any]]] = {}\n",
    "        for scheme_name, ticker_weights in schemes_for_date.items():\n",
    "            if not ticker_weights:\n",
    "                logging.warning(f\"  Skipping scheme '{scheme_name}': No ticker weights provided.\")\n",
    "                results_for_date[scheme_name] = None \n",
    "                continue\n",
    "            try:\n",
    "                backtest_result = run_single_backtest(\n",
    "                    selection_date=date_str,\n",
    "                    scheme_name=scheme_name,\n",
    "                    ticker_weights=ticker_weights,\n",
    "                    df_adj_close=df_prices_global, \n",
    "                    risk_free_rate_daily = RISK_FREE_RATE_DAILY,\n",
    "                )\n",
    "                results_for_date[scheme_name] = backtest_result\n",
    "            except Exception as e:\n",
    "                logging.error(f\"!! UNEXPECTED Error running backtest for {scheme_name} on {date_str} in outer loop: {e}\", exc_info=True)\n",
    "                results_for_date[scheme_name] = None \n",
    "\n",
    "        all_results[date_str] = results_for_date\n",
    "\n",
    "    logging.info(\"\\n===== Batch Backtest Processing Finished =====\")\n",
    "    return all_results\n",
    "\n",
    "# --- 3. Function to Extract Parameters and Results for Storage ---\n",
    "def extract_params_and_results(\n",
    "    params: Dict[str, Any],\n",
    "    backtest_results_summary: Dict[str, Dict[str, Optional[Dict[str, Any]]]],\n",
    "    run_timestamp: str,\n",
    "    log_filepath: str\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Extracts relevant parameters and portfolio returns from results.\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    if not log_filepath: \n",
    "        log_filename = \"unknown_log.log\"\n",
    "        logging.error(\"Log filepath was not set correctly during parameter extraction.\")\n",
    "    else:\n",
    "        log_filename = os.path.basename(log_filepath)\n",
    "\n",
    "    for date_str, scheme_results in backtest_results_summary.items():\n",
    "        if not scheme_results: \n",
    "             logging.warning(f\"No scheme results found for date {date_str} during param extraction.\")\n",
    "             continue\n",
    "        for scheme_name, result in scheme_results.items():\n",
    "            record = {\n",
    "                'run_timestamp': run_timestamp,\n",
    "                'log_file': log_filename,\n",
    "                'selection_date': date_str,\n",
    "                'scheme': scheme_name,\n",
    "            }\n",
    "            for p_key in PARAMS_TO_TRACK:\n",
    "                record[p_key] = params.get(p_key, None) \n",
    "            record['n_select_actual'] = params.get('n_select_actual', np.nan) \n",
    "\n",
    "            if result and isinstance(result, dict) and 'metrics' in result and isinstance(result['metrics'], dict):\n",
    "                metrics = result['metrics']\n",
    "                record['portfolio_return'] = metrics.get('portfolio_return', np.nan)\n",
    "                record['portfolio_return_normalized'] = metrics.get('portfolio_return_normalized', np.nan) \n",
    "                record['num_successful_trades'] = metrics.get('num_successful_trades', 0)\n",
    "                record['total_weight_traded'] = metrics.get('total_weight_traded', 0.0)\n",
    "                record['win_rate'] = metrics.get('win_rate', np.nan)\n",
    "                record['average_return'] = metrics.get('average_return', np.nan)\n",
    "                record['std_dev_return'] = metrics.get('std_dev_return', np.nan) \n",
    "                record['sharpe_ratio_period'] = metrics.get('sharpe_ratio_period', np.nan) \n",
    "                record['num_attempted_trades'] = metrics.get('num_attempted_trades', 0)\n",
    "                record['num_failed_or_skipped_trades'] = metrics.get('num_failed_or_skipped_trades', 0)\n",
    "                record['actual_selection_date_used'] = result.get('run_inputs', {}).get('actual_selection_date_used', None)\n",
    "            else:\n",
    "                record['portfolio_return'] = np.nan\n",
    "                record['portfolio_return_normalized'] = np.nan\n",
    "                record['num_successful_trades'] = 0\n",
    "                record['total_weight_traded'] = 0.0\n",
    "                record['win_rate'] = np.nan\n",
    "                record['average_return'] = np.nan\n",
    "                record['std_dev_return'] = np.nan\n",
    "                record['sharpe_ratio_period'] = np.nan\n",
    "                record['num_attempted_trades'] = np.nan \n",
    "                record['num_failed_or_skipped_trades'] = np.nan\n",
    "                record['actual_selection_date_used'] = None\n",
    "                if result is None:\n",
    "                     logging.warning(f\"Extracting params: Backtest result was None for {date_str} / {scheme_name}.\")\n",
    "                else:\n",
    "                     logging.warning(f\"Extracting params: Unexpected result format for {date_str} / {scheme_name}: {type(result)}\")\n",
    "            records.append(record)\n",
    "    return records\n",
    "\n",
    "# --- 4. MODIFIED Function to Write Results to CSV (handles overwriting) ---\n",
    "def write_results_to_csv(records: List[Dict[str, Any]], filepath: str = RESULTS_CSV_PATH):\n",
    "    \"\"\"\n",
    "    Writes a list of result records to a CSV file.\n",
    "    If a record with the same selection_date, scheme, and all parameters\n",
    "    defined in PARAMS_TO_TRACK already exists, it's overwritten by the new record.\n",
    "    Only the latest result (from the current batch of `records`) for that specific\n",
    "    combination is kept. The file is rewritten entirely.\n",
    "    \"\"\"\n",
    "    if not records:\n",
    "        logging.info(\"No records to write to CSV.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        df_new_records = pd.DataFrame(records)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to create DataFrame from new records: {e}\", exc_info=True)\n",
    "        return\n",
    "\n",
    "    # Ensure df_new_records has all columns from CSV_COLUMN_ORDER, adding NaNs for missing ones\n",
    "    for col in CSV_COLUMN_ORDER:\n",
    "        if col not in df_new_records.columns:\n",
    "            df_new_records[col] = np.nan\n",
    "    # Select and reorder columns to match CSV_COLUMN_ORDER\n",
    "    df_new_records = df_new_records[CSV_COLUMN_ORDER]\n",
    "\n",
    "    # Ensure directory for the CSV file exists\n",
    "    os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "\n",
    "    df_existing_records = pd.DataFrame(columns=CSV_COLUMN_ORDER) # Default to empty DF with correct columns\n",
    "    if os.path.exists(filepath) and os.path.getsize(filepath) > 0:\n",
    "        try:\n",
    "            df_existing_records = pd.read_csv(filepath, na_filter=True, keep_default_na=True)\n",
    "\n",
    "            # Align columns of df_existing_records with CSV_COLUMN_ORDER\n",
    "            for col in CSV_COLUMN_ORDER:\n",
    "                if col not in df_existing_records.columns:\n",
    "                    logging.warning(f\"Column '{col}' from CSV_COLUMN_ORDER not found in existing CSV '{filepath}'. Adding it with NaNs.\")\n",
    "                    df_existing_records[col] = np.nan\n",
    "            df_existing_records = df_existing_records[CSV_COLUMN_ORDER]\n",
    "\n",
    "        except pd.errors.EmptyDataError:\n",
    "            logging.info(f\"Existing CSV file '{filepath}' is empty. Will create a new one.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error reading existing CSV file '{filepath}': {e}. \"\n",
    "                          \"Proceeding as if it were empty or to create a new file.\", exc_info=True)\n",
    "            df_existing_records = pd.DataFrame(columns=CSV_COLUMN_ORDER) # Reset to empty on error\n",
    "\n",
    "    # Combine existing data with the new records.\n",
    "    # New records are placed after existing ones.\n",
    "    df_combined = pd.concat([df_existing_records, df_new_records], ignore_index=True)\n",
    "\n",
    "    # Deduplicate based on the unique key columns. 'keep=\"last\"' ensures that\n",
    "    # if duplicates exist (i.e., an old record and a new record for the same key set),\n",
    "    # the one from df_new_records (which is last in df_combined) is kept.\n",
    "    df_final = df_combined.drop_duplicates(subset=UNIQUE_KEY_COLUMNS_FOR_CSV, keep='last').copy()\n",
    "\n",
    "    # Optional: Sort the final DataFrame for consistent ordering in the CSV.\n",
    "    if 'run_timestamp' in df_final.columns: # Should always be true\n",
    "        df_final['run_timestamp'] = pd.to_datetime(df_final['run_timestamp'], errors='coerce')\n",
    "    \n",
    "    if 'selection_date' in df_final.columns: # Should always be true\n",
    "        # Create a temporary column for sorting by datetime version of selection_date\n",
    "        # Convert selection_date to string first to handle potential mixed types before to_datetime\n",
    "        # This assumes selection_date might be like 'YYYYMMDD' or 'YYYY-MM-DD'\n",
    "        # A try-except block can make parsing more robust if formats vary\n",
    "        try:\n",
    "            # Attempt parsing with a common format like YYYYMMDD if applicable, e.g., format='%Y%m%d'\n",
    "            # For general case, let pandas infer or handle multiple formats.\n",
    "            # Convert to string first to ensure consistent input to to_datetime\n",
    "            df_final['selection_date_dt_sort'] = pd.to_datetime(df_final['selection_date'].astype(str), errors='coerce')\n",
    "        except Exception as e: # Broad exception for parsing issues\n",
    "            logging.warning(f\"Could not reliably parse 'selection_date' for sorting: {e}. Sorting may be string-based for this column.\")\n",
    "            df_final['selection_date_dt_sort'] = df_final['selection_date'] # Fallback to original for sort\n",
    "\n",
    "        df_final = df_final.sort_values(\n",
    "            by=['run_timestamp', 'selection_date_dt_sort', 'scheme'],\n",
    "            ascending=[False, False, True] # Latest runs, latest selection dates, then by scheme\n",
    "        ).drop(columns=['selection_date_dt_sort'], errors='ignore') # Drop temporary sort column\n",
    "\n",
    "    try:\n",
    "        # Write the consolidated DataFrame to the CSV file, overwriting it.\n",
    "        df_final.to_csv(filepath, mode='w', header=True, index=False, float_format='%.8f')\n",
    "\n",
    "        num_input_records = len(df_new_records)\n",
    "        num_final_records = len(df_final)\n",
    "        num_existing_before_op = len(df_existing_records) # Count before concat\n",
    "        net_change = num_final_records - num_existing_before_op\n",
    "\n",
    "        logging.info(f\"Processed {num_input_records} new records. \"\n",
    "                     f\"CSV '{filepath}' now contains {num_final_records} records (net change: {net_change:+}).\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error writing consolidated data to CSV file '{filepath}': {e}\", exc_info=True)\n",
    "\n",
    "def setup_script_logging():\n",
    "    \"\"\"\n",
    "    Sets up logging for the script and logs initial information.\n",
    "    Returns the log file path.\n",
    "    \"\"\"\n",
    "    log_filepath = setup_logging()\n",
    "    run_timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    logging.info(f\"Script execution started at: {run_timestamp}\")\n",
    "\n",
    "    logging.info(f\"Python Interpreter: {sys.executable}\")\n",
    "    logging.info(f\"Current Working Directory: {os.getcwd()}\")\n",
    "    logging.info(f\"Pandas Version: {pd.__version__}\")\n",
    "    logging.info(f\"Numpy Version: {np.__version__}\")\n",
    "\n",
    "    return log_filepath, run_timestamp # Return both log_filepath and run_timestamp\n",
    "\n",
    "# --- New Function for Loading and Preparing Price Data ---\n",
    "def load_and_prepare_price_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads price data from a parquet file, validates and prepares its index.\n",
    "\n",
    "    Args:\n",
    "        file_path: The path to the price data parquet file.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame with a DatetimeIndex, sorted chronologically.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the specified file_path does not exist.\n",
    "        Exception: For other errors during loading or processing.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Attempting to load price data from: {os.path.abspath(file_path)}\")\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Price data file not found: {os.path.abspath(file_path)}\")\n",
    "\n",
    "    try:\n",
    "        df_adj_close = pd.read_parquet(file_path)\n",
    "\n",
    "        if not isinstance(df_adj_close.index, pd.DatetimeIndex):\n",
    "            logging.info(\"Converting price data index to DatetimeIndex...\")\n",
    "            # Attempt common conversions, handle potential errors\n",
    "            try:\n",
    "                 df_adj_close.index = pd.to_datetime(df_adj_close.index)\n",
    "            except Exception as e:\n",
    "                 logging.error(f\"Error converting index to DatetimeIndex: {e}\", exc_info=True)\n",
    "                 # Decide how to handle: raise, return None, etc.\n",
    "                 # For this example, we'll let the outer exception handler catch it if it fails.\n",
    "                 raise # Re-raise the conversion error\n",
    "\n",
    "        if not df_adj_close.index.is_monotonic_increasing:\n",
    "            logging.info(\"Sorting price data index...\")\n",
    "            df_adj_close = df_adj_close.sort_index()\n",
    "\n",
    "        logging.info(f\"Successfully loaded and prepared price data from {file_path}\")\n",
    "        logging.info(f\"Price data shape: {df_adj_close.shape}, Date range: {df_adj_close.index.min()} to {df_adj_close.index.max()}\")\n",
    "        logging.info(\"Price data loading completed.\")\n",
    "\n",
    "        return df_adj_close\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred while loading/preparing price data from {file_path}: {e}\", exc_info=True)\n",
    "        raise # Re-raise the exception so the main try/except block can catch it\n",
    "\n",
    "# --- New Function for Finding and Mapping Files ---\n",
    "def find_and_map_param_files(directory_path: str) -> Tuple[List[str], List[str], Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Discovers .parquet and .json files in a directory that start with '20', and creates a map\n",
    "    of parameter files by extracted date.\n",
    "\n",
    "    Args:\n",
    "        directory_path: The path to the directory containing the files.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "        - A list of discovered selection file names (.parquet).\n",
    "        - A list of discovered parameter file names (.json).\n",
    "        - A dictionary mapping extracted date strings to parameter file names.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the specified directory_path does not exist.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Attempting to find files in: {os.path.abspath(directory_path)}\")\n",
    "\n",
    "    if not os.path.isdir(directory_path):\n",
    "        raise FileNotFoundError(f\"Data directory not found: {os.path.abspath(directory_path)}\")\n",
    "\n",
    "    all_files = os.listdir(directory_path)\n",
    "    logging.debug(f\"Files found in directory: {all_files}\")\n",
    "\n",
    "    # Assuming files starting with '20' and ending with specific extensions are relevant\n",
    "    selection_files = sorted([f for f in all_files if f.startswith('20') and f.endswith('.parquet')])\n",
    "    param_files = sorted([f for f in all_files if f.startswith('20') and f.endswith('.json')])\n",
    "    logging.info(f\"Found {len(selection_files)} potential selection files (.parquet)\")\n",
    "    logging.info(f\"Found {len(param_files)} potential parameter files (.json)\")\n",
    "\n",
    "    param_map = {}\n",
    "    # Extracted dates sets are useful for internal function validation/logging\n",
    "    # but not strictly necessary to return if only used for mismatch reporting later.\n",
    "    # We'll keep them for logging within this function.\n",
    "    extracted_dates_params = set()\n",
    "\n",
    "\n",
    "    for pf in param_files:\n",
    "        try:\n",
    "            # Assume utils.extract_date_from_string is available globally or imported\n",
    "            date_key = utils.extract_date_from_string(pf)\n",
    "            if date_key:\n",
    "                if date_key in param_map:\n",
    "                    logging.warning(f\"Duplicate date key '{date_key}' found for param file '{pf}'. Overwriting mapping with previous file '{param_map[date_key]}'.\")\n",
    "                param_map[date_key] = pf\n",
    "                extracted_dates_params.add(date_key)\n",
    "            else:\n",
    "                logging.warning(f\"Could not extract date from param file: {pf}. Skipping.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error extracting date from param file '{pf}': {e}\", exc_info=True)\n",
    "\n",
    "    logging.debug(f\"Parameter map created: {param_map}\")\n",
    "    logging.info(\"File discovery and parameter mapping completed.\")\n",
    "\n",
    "    # Return the lists of files and the parameter map\n",
    "    # return selection_files, param_files, param_map\n",
    "    return selection_files, param_files, param_map, extracted_dates_params # Return the set of extracted dates for params\n",
    "\n",
    "# --- New Function for Pairing Files ---\n",
    "def pair_data_and_param_files(\n",
    "    selection_files: List[str],\n",
    "    param_files: List[str],\n",
    "    param_map: Dict[str, str],\n",
    "    extracted_dates_params: Set[str], # Now takes this as input\n",
    "    utils_module # Pass utility module\n",
    ") -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Pairs selection files with parameter files based on date extraction.\n",
    "    Reports mismatch details.\n",
    "\n",
    "    Args:\n",
    "        selection_files: List of discovered selection file names.\n",
    "        param_files: List of discovered parameter file names (for mismatch reporting).\n",
    "        param_map: Dictionary mapping date strings to parameter file names.\n",
    "        extracted_dates_params: Set of dates extracted from parameter files.\n",
    "        utils_module: Module containing necessary utility functions.\n",
    "\n",
    "    Returns:\n",
    "        A list of successfully paired (selection_file, param_file) tuples.\n",
    "    \"\"\"\n",
    "    file_pairs = []\n",
    "    extracted_dates_select = set() # Keep this inside, only used for mismatch reporting here\n",
    "\n",
    "    logging.info(\"Attempting to pair selection files with parameter files...\")\n",
    "\n",
    "    for sf in selection_files:\n",
    "        date_str_key = None\n",
    "        try:\n",
    "            date_str_key = utils_module.extract_date_from_string(sf)\n",
    "            if date_str_key:\n",
    "                extracted_dates_select.add(date_str_key)\n",
    "                logging.debug(f\"Extracted date '{date_str_key}' from selection file: {sf}\")\n",
    "                if date_str_key in param_map:\n",
    "                    file_pairs.append((sf, param_map[date_str_key]))\n",
    "                    logging.debug(f\" Â Matched pair: ({sf}, {param_map[date_str_key]})\")\n",
    "                else:\n",
    "                    logging.warning(f\"Could not find matching param file for data file: {sf} (extracted date: {date_str_key})\")\n",
    "            else:\n",
    "                logging.warning(f\"Could not extract valid date from selection file: {sf}. Skipping.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error extracting date from selection file '{sf}': {e}\", exc_info=True)\n",
    "\n",
    "    logging.info(f\"\\n--- Found {len(file_pairs)} Paired Data and Parameter Files ---\")\n",
    "\n",
    "    # Mismatch details reporting using the sets and original file counts\n",
    "    if len(selection_files) > len(file_pairs) or len(param_files) > len(file_pairs):\n",
    "          logging.warning(f\"Mismatch details: Selection dates={extracted_dates_select}, Param dates={extracted_dates_params}\")\n",
    "\n",
    "    logging.info(\"File pairing completed.\")\n",
    "\n",
    "    # IMPORTANT: Do NOT include the 'if not file_pairs:' check here.\n",
    "    # That's logic for the caller (the main script) to decide what to do with the result.\n",
    "\n",
    "    return file_pairs\n",
    "\n",
    "# --- New Function to Process a Single Pair ---\n",
    "def process_single_pair(\n",
    "    data_file: str,\n",
    "    param_file_name: str,\n",
    "    output_dir: str, # Use output_dir consistently\n",
    "    df_adj_close: pd.DataFrame,\n",
    "    run_timestamp: str,\n",
    "    log_filepath: str,\n",
    "    utils_module: Any,\n",
    "    extract_backtest_setups_func: Callable,\n",
    "    process_all_backtests_func: Callable,\n",
    "    extract_params_and_results_func: Callable\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Processes a single data/parameter file pair, runs backtests, and extracts results.\n",
    "\n",
    "    Args:\n",
    "        data_file: Name of the selection data file (.parquet).\n",
    "        param_file_name: Name of the parameter file (.json).\n",
    "        output_dir: Directory containing the data and parameter files.\n",
    "        df_adj_close: DataFrame containing the main price data.\n",
    "        run_timestamp: Timestamp for the current run.\n",
    "        log_filepath: Path to the log file for the current run.\n",
    "        utils_module: Module containing utility functions like extract_date_from_string.\n",
    "        extract_backtest_setups_func: The function to extract backtest setups.\n",
    "        process_all_backtests_func: The function to run backtests.\n",
    "        extract_params_and_results_func: The function to extract performance records.\n",
    "\n",
    "    Returns:\n",
    "        A list of performance records (dictionaries) for this pair, or an empty list if\n",
    "        processing failed or no valid setups were found.\n",
    "    \"\"\"\n",
    "    current_date_str = None\n",
    "    try:\n",
    "        # Date re-extraction (kept here as in original logic, though could be passed in file_pairs)\n",
    "        current_date_str = utils_module.extract_date_from_string(data_file)\n",
    "        if not current_date_str:\n",
    "            logging.error(f\"Skipping pair - Failed to re-extract valid date from {data_file}\")\n",
    "            return [] # Return empty list on failure\n",
    "\n",
    "        logging.info(f\"Processing for extracted date: {current_date_str}\")\n",
    "\n",
    "        # Ensure price data is available before proceeding\n",
    "        if df_adj_close is None or df_adj_close.empty:\n",
    "             logging.critical(f\"Price data (df_adj_close) is not loaded or is empty. Skipping pair for {current_date_str}.\")\n",
    "             return [] # Return empty list if price data is missing\n",
    "\n",
    "        param_path = os.path.join(OUTPUT_DIR, param_file_name)\n",
    "        logging.debug(f\"Reading parameters from: {param_path}\")\n",
    "        with open(param_path, 'r', encoding='utf-8') as f:\n",
    "            params = json.load(f)\n",
    "            logging.info(f\"Parameters loaded from {param_file_name}:\")\n",
    "            # Log parameters neatly\n",
    "            params_str_io = io.StringIO()\n",
    "            pprint.pprint(params, stream=params_str_io, width=100)\n",
    "            logging.info(\"\\n\" + params_str_io.getvalue())\n",
    "\n",
    "        selection_path = os.path.join(OUTPUT_DIR, data_file)\n",
    "        logging.debug(f\"Reading selection data from: {selection_path}\")\n",
    "        selection_df = pd.read_parquet(selection_path)\n",
    "        logging.debug(f'Loaded selection_df. Shape: {selection_df.shape}, Index type: {type(selection_df.index)}, Columns: {selection_df.columns.tolist()[:10]}...')\n",
    "\n",
    "        logging.debug(f\"Extracting backtest setups for date: {current_date_str}\")\n",
    "        backtest_setups = extract_backtest_setups_func(\n",
    "            dataframe=selection_df,\n",
    "            weight_column_names=['Weight_EW', 'Weight_IV', 'Weight_SW'],\n",
    "            date_str=current_date_str,\n",
    "        )\n",
    "\n",
    "        if not backtest_setups or not backtest_setups.get(current_date_str):\n",
    "            logging.warning(f\"No valid backtest setups extracted for {current_date_str}. Skipping backtest run for this pair.\")\n",
    "            return [] # Return empty list if no setups\n",
    "\n",
    "        # Log extracted setups neatly\n",
    "        logging.info(f\"Successfully extracted {len(backtest_setups.get(current_date_str, {}))} setup(s) for {current_date_str}.\")\n",
    "        setups_str_io = io.StringIO()\n",
    "        pprint.pprint(backtest_setups, stream=setups_str_io, width=120, depth=3)\n",
    "        logging.debug(\"Extracted Backtest Setups (preview):\\n\" + setups_str_io.getvalue())\n",
    "\n",
    "        logging.info(f\"Running backtests for date: {current_date_str}\")\n",
    "        backtest_results_summary = process_all_backtests_func(backtest_setups, df_adj_close)\n",
    "\n",
    "        # Log backtest summary neatly\n",
    "        summary_str_io = io.StringIO()\n",
    "        for res_date, res_schemes in backtest_results_summary.items():\n",
    "            pprint.pprint({res_date: list(res_schemes.keys())}, stream=summary_str_io)\n",
    "        logging.debug(\"\\n--- Backtest Results Summary (Schemes Processed) ---\\n\" + summary_str_io.getvalue())\n",
    "\n",
    "\n",
    "        logging.debug(f\"Extracting parameters and results for date: {current_date_str}\")\n",
    "        run_records = extract_params_and_results_func(\n",
    "            params=params,\n",
    "            backtest_results_summary=backtest_results_summary,\n",
    "            run_timestamp=run_timestamp,\n",
    "            log_filepath=log_filepath\n",
    "        )\n",
    "        logging.info(f\"Extracted {len(run_records)} performance records for this pair.\")\n",
    "\n",
    "        logging.info(f\"--- Finished processing pair for {current_date_str}. ---\")\n",
    "\n",
    "        return run_records # Return the list of records on success\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        logging.error(f\"FILE NOT FOUND Error processing pair ({data_file}, {param_file_name}): {e}\", exc_info=True)\n",
    "        return [] # Return empty list on specific error\n",
    "    except KeyError as e:\n",
    "         logging.error(f\"KEY Error processing pair ({data_file}, {param_file_name}) - often related to missing columns/dates: {e}\", exc_info=True)\n",
    "         return [] # Return empty list on specific error\n",
    "    except Exception as e:\n",
    "        logging.error(f\"UNHANDLED Error processing pair ({data_file}, {param_file_name}) for date {current_date_str}: {e}\", exc_info=True)\n",
    "        logging.error(traceback.format_exc())\n",
    "        return [] # Return empty list on any other unhandled error\n",
    "\n",
    "# --- (Existing functions like write_results_to_csv) ---\n",
    "\n",
    "# --- New Function to Update or Create a DataFrame with Records ---\n",
    "def update_or_create_dataframe_with_records(\n",
    "    new_records: List[Dict[str, Any]],\n",
    "    existing_df: Optional[pd.DataFrame] = None,\n",
    "    column_order: List[str] = CSV_COLUMN_ORDER,\n",
    "    unique_key_columns: List[str] = UNIQUE_KEY_COLUMNS_FOR_CSV\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Updates an existing DataFrame with new records or creates a new DataFrame.\n",
    "\n",
    "    This function aligns columns, combines new records with an optional existing\n",
    "    DataFrame, deduplicates based on unique keys (keeping the latest), and sorts\n",
    "    the results.\n",
    "\n",
    "    Args:\n",
    "        new_records: A list of new records (dictionaries) to be added or to update\n",
    "                     existing entries.\n",
    "        existing_df: An optional existing pandas DataFrame. If None or empty,\n",
    "                     processing starts as if with a new DataFrame.\n",
    "        column_order: The definitive list and order of columns for the resulting\n",
    "                      DataFrame. Defaults to CSV_COLUMN_ORDER.\n",
    "        unique_key_columns: A list of column names that define a unique record.\n",
    "                            Used for deduplication, keeping the 'last' entry in\n",
    "                            case of duplicates. Defaults to UNIQUE_KEY_COLUMNS_FOR_CSV.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame containing the consolidated, deduplicated, and sorted records.\n",
    "        Returns an empty DataFrame (with specified columns) if both new_records\n",
    "        and existing_df are empty or None.\n",
    "    \"\"\"\n",
    "    logging.debug(f\"DataFrame Update: {len(new_records)} new records. Existing DF has \"\n",
    "                  f\"{len(existing_df) if existing_df is not None else 0} rows.\")\n",
    "\n",
    "    # 1. Prepare the existing DataFrame\n",
    "    if existing_df is not None and not existing_df.empty:\n",
    "        df_processed_existing = existing_df.copy() # Work with a copy\n",
    "        # Align columns of df_processed_existing\n",
    "        for col in column_order:\n",
    "            if col not in df_processed_existing.columns:\n",
    "                logging.debug(f\"DataFrame Update: Column '{col}' not in existing_df. Adding with NaNs.\")\n",
    "                df_processed_existing[col] = np.nan\n",
    "        df_processed_existing = df_processed_existing[column_order].copy() # Re-index and ensure copy\n",
    "    else:\n",
    "        # Start with an empty DataFrame with defined columns if no valid existing_df\n",
    "        df_processed_existing = pd.DataFrame(columns=column_order)\n",
    "\n",
    "    # 2. Prepare the new records DataFrame\n",
    "    if new_records:\n",
    "        try:\n",
    "            df_new_records = pd.DataFrame(new_records)\n",
    "            # Align columns of df_new_records\n",
    "            for col in column_order:\n",
    "                if col not in df_new_records.columns:\n",
    "                    df_new_records[col] = np.nan\n",
    "            df_new_records = df_new_records[column_order].copy() # Re-index and ensure copy\n",
    "        except Exception as e:\n",
    "            logging.error(f\"DataFrame Update: Failed to create DataFrame from new records: {e}\", exc_info=True)\n",
    "            # If new records fail, proceed with only the (processed) existing DataFrame\n",
    "            df_new_records = pd.DataFrame(columns=column_order) # Empty DF with correct columns\n",
    "    else:\n",
    "        df_new_records = pd.DataFrame(columns=column_order) # Empty DF if no new records\n",
    "\n",
    "    # 3. Combine DataFrames\n",
    "    if df_processed_existing.empty and df_new_records.empty:\n",
    "        logging.info(\"DataFrame Update: No existing data and no new records. Returning empty DataFrame.\")\n",
    "        return pd.DataFrame(columns=column_order) # Explicitly return empty DF with columns\n",
    "\n",
    "    df_combined = pd.concat([df_processed_existing, df_new_records], ignore_index=True)\n",
    "\n",
    "    # 4. Deduplicate\n",
    "    # Ensure unique_key_columns exist, otherwise, deduplication might fail or be meaningless\n",
    "    missing_keys = [key for key in unique_key_columns if key not in df_combined.columns]\n",
    "    if missing_keys:\n",
    "        logging.warning(f\"DataFrame Update: Unique key columns {missing_keys} not found in combined DataFrame. Skipping deduplication.\")\n",
    "        df_final = df_combined.copy()\n",
    "    elif df_combined.empty:\n",
    "        df_final = df_combined.copy() # Already empty, just copy\n",
    "    else:\n",
    "        df_final = df_combined.drop_duplicates(subset=unique_key_columns, keep='last').copy()\n",
    "\n",
    "    num_new_actual = len(df_new_records) # Actual count from new_records list\n",
    "    num_existing_initial = len(existing_df) if existing_df is not None else 0\n",
    "    num_final_df = len(df_final)\n",
    "    # Net change calculation is tricky if existing_df was modified before concat\n",
    "    # Let's use a simpler logging message\n",
    "    logging.info(\n",
    "        f\"DataFrame Update: Started with {num_existing_initial} existing records, processed {num_new_actual} new records. \"\n",
    "        f\"Resulting DataFrame has {num_final_df} records after consolidation and deduplication.\"\n",
    "    )\n",
    "\n",
    "\n",
    "    # 5. Sort the final DataFrame\n",
    "    if df_final.empty:\n",
    "        logging.debug(\"DataFrame Update: Final DataFrame is empty, no sorting needed.\")\n",
    "        return df_final # Already has correct columns from earlier steps\n",
    "\n",
    "    # Ensure 'run_timestamp' and 'selection_date' are present for sorting; critical for logic.\n",
    "    # These should be in 'column_order'.\n",
    "    if 'run_timestamp' in df_final.columns:\n",
    "        df_final.loc[:, 'run_timestamp'] = pd.to_datetime(df_final.loc[:, 'run_timestamp'], errors='coerce')\n",
    "\n",
    "    if 'selection_date' in df_final.columns:\n",
    "        try:\n",
    "            # Using .loc for assignment to avoid SettingWithCopyWarning\n",
    "            df_final.loc[:, 'selection_date_dt_sort'] = pd.to_datetime(df_final['selection_date'].astype(str), errors='coerce')\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"DataFrame Update: Could not parse 'selection_date' for sorting: {e}. Sorting may be string-based.\")\n",
    "            df_final.loc[:, 'selection_date_dt_sort'] = df_final['selection_date'] # Fallback\n",
    "\n",
    "        # Perform sorting\n",
    "        df_final = df_final.sort_values(\n",
    "            by=['run_timestamp', 'selection_date_dt_sort', 'scheme'],\n",
    "            ascending=[False, False, True] # Latest runs, latest selection dates, then by scheme\n",
    "        ).drop(columns=['selection_date_dt_sort'], errors='ignore')\n",
    "    elif 'run_timestamp' in df_final.columns and 'scheme' in df_final.columns:\n",
    "        logging.warning(\"DataFrame Update: 'selection_date' not found for sorting. Sorting by 'run_timestamp' and 'scheme'.\")\n",
    "        df_final = df_final.sort_values(\n",
    "            by=['run_timestamp', 'scheme'],\n",
    "            ascending=[False, True]\n",
    "        )\n",
    "    elif 'run_timestamp' in df_final.columns:\n",
    "        logging.warning(\"DataFrame Update: Only 'run_timestamp' found for sorting.\")\n",
    "        df_final = df_final.sort_values(by=['run_timestamp'], ascending=False)\n",
    "    else:\n",
    "        logging.warning(\"DataFrame Update: Key sorting columns ('run_timestamp', 'selection_date') not found. DataFrame may not be optimally sorted.\")\n",
    "\n",
    "    return df_final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 15:54:33,583 - INFO - Logging initialized. Log file: logs\\backtest_run_20250514_155433.log\n",
      "2025-05-14 15:54:33,585 - INFO - Script execution started at: 2025-05-14 15:54:33\n",
      "2025-05-14 15:54:33,585 - INFO - Python Interpreter: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe\n",
      "2025-05-14 15:54:33,585 - INFO - Current Working Directory: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\n",
      "2025-05-14 15:54:33,585 - INFO - Pandas Version: 2.2.3\n",
      "2025-05-14 15:54:33,585 - INFO - Numpy Version: 1.26.4\n",
      "2025-05-14 15:54:33,585 - INFO - Attempting to load price data from: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_adj_close.parquet\n",
      "2025-05-14 15:54:33,808 - INFO - Successfully loaded and prepared price data from ../data/df_adj_close.parquet\n",
      "2025-05-14 15:54:33,809 - INFO - Price data shape: (322, 1563), Date range: 2024-02-01 00:00:00 to 2025-05-14 00:00:00\n",
      "2025-05-14 15:54:33,811 - INFO - Price data loading completed.\n",
      "2025-05-14 15:54:33,813 - INFO - Attempting to find files in: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\output\\selection_results\n",
      "2025-05-14 15:54:33,817 - INFO - Found 14 potential selection files (.parquet)\n",
      "2025-05-14 15:54:33,817 - INFO - Found 14 potential parameter files (.json)\n",
      "2025-05-14 15:54:33,820 - INFO - File discovery and parameter mapping completed.\n",
      "2025-05-14 15:54:33,822 - INFO - Attempting to pair selection files with parameter files...\n",
      "2025-05-14 15:54:33,824 - INFO - \n",
      "--- Found 14 Paired Data and Parameter Files ---\n",
      "2025-05-14 15:54:33,826 - INFO - File pairing completed.\n",
      "2025-05-14 15:54:33,827 - INFO - Starting processing for 14 file pairs...\n",
      "2025-05-14 15:54:33,829 - INFO - \n",
      "--- Processing Pair 1/14: Data='2025-04-25_my_selection_run_1.parquet', Params='2025-04-25_my_selection_run_1_params.json' ---\n",
      "2025-05-14 15:54:33,830 - INFO - Processing for extracted date: 2025-04-25\n",
      "2025-05-14 15:54:33,838 - INFO - Parameters loaded from 2025-04-25_my_selection_run_1_params.json:\n",
      "2025-05-14 15:54:33,842 - INFO - \n",
      "{'filter_max_debt_eq': 1.5,\n",
      " 'filter_min_avg_volume_m': 2.0,\n",
      " 'filter_min_price': 10.0,\n",
      " 'filter_min_roe_pct': 5.0,\n",
      " 'inv_vol_col_name': 'ATR/Price %',\n",
      " 'n_select_actual': 10,\n",
      " 'n_select_requested': 10,\n",
      " 'score_weight_change': 0.35,\n",
      " 'score_weight_rel_volume': 0.2,\n",
      " 'score_weight_rsi': 0.35,\n",
      " 'score_weight_volatility': 0.1}\n",
      "\n",
      "2025-05-14 15:54:33,856 - INFO - Successfully extracted weights for scheme: EW (10 tickers) for date 2025-04-25\n",
      "2025-05-14 15:54:33,869 - INFO - Successfully extracted weights for scheme: IV (10 tickers) for date 2025-04-25\n",
      "2025-05-14 15:54:33,872 - INFO - Successfully extracted weights for scheme: SW (10 tickers) for date 2025-04-25\n",
      "2025-05-14 15:54:33,875 - INFO - Successfully extracted 3 setup(s) for 2025-04-25.\n",
      "2025-05-14 15:54:33,875 - INFO - Running backtests for date: 2025-04-25\n",
      "2025-05-14 15:54:33,875 - INFO - \n",
      "===== Starting Batch Backtest Processing =====\n",
      "2025-05-14 15:54:33,880 - INFO - Prepared global price data copy for backtests.\n",
      "2025-05-14 15:54:33,880 - INFO - \n",
      "Processing date: 2025-04-25\n",
      "2025-05-14 15:54:33,880 - INFO - ------------------------------\n",
      "2025-05-14 15:54:33,885 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:33,889 - INFO -   Date          : 2025-04-25\n",
      "2025-05-14 15:54:33,889 - INFO -   Scheme        : EW\n",
      "2025-05-14 15:54:33,889 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:33,889 - INFO -   Selection Date Used: 2025-04-25\n",
      "2025-05-14 15:54:33,904 - INFO -   Buy Date           : 2025-04-28\n",
      "2025-05-14 15:54:33,908 - INFO -   Sell Date          : 2025-04-29\n",
      "2025-05-14 15:54:33,921 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:33,925 - INFO -   Portfolio Return          : 0.0085 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:33,925 - INFO -   Win Rate (Individual)   : 70.00%\n",
      "2025-05-14 15:54:33,929 - INFO -   Avg Ticker Return       : 0.0085\n",
      "2025-05-14 15:54:33,929 - INFO -   Std Dev Ticker Return   : 0.0203\n",
      "2025-05-14 15:54:33,929 - INFO -   Period Sharpe (Indiv)   : 0.4154\n",
      "2025-05-14 15:54:33,929 - INFO - Backtest simulation for 'EW' on 2025-04-25 completed.\n",
      "2025-05-14 15:54:33,940 - INFO - ------------------------------\n",
      "2025-05-14 15:54:33,940 - INFO - ------------------------------\n",
      "2025-05-14 15:54:33,940 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:33,940 - INFO -   Date          : 2025-04-25\n",
      "2025-05-14 15:54:33,940 - INFO -   Scheme        : IV\n",
      "2025-05-14 15:54:33,940 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:33,955 - INFO -   Selection Date Used: 2025-04-25\n",
      "2025-05-14 15:54:33,958 - INFO -   Buy Date           : 2025-04-28\n",
      "2025-05-14 15:54:33,959 - INFO -   Sell Date          : 2025-04-29\n",
      "2025-05-14 15:54:33,960 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:33,970 - INFO -   Portfolio Return          : 0.0075 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:33,972 - INFO -   Win Rate (Individual)   : 70.00%\n",
      "2025-05-14 15:54:33,974 - INFO -   Avg Ticker Return       : 0.0085\n",
      "2025-05-14 15:54:33,977 - INFO -   Std Dev Ticker Return   : 0.0203\n",
      "2025-05-14 15:54:33,977 - INFO -   Period Sharpe (Indiv)   : 0.4154\n",
      "2025-05-14 15:54:33,977 - INFO - Backtest simulation for 'IV' on 2025-04-25 completed.\n",
      "2025-05-14 15:54:33,977 - INFO - ------------------------------\n",
      "2025-05-14 15:54:33,984 - INFO - ------------------------------\n",
      "2025-05-14 15:54:33,987 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:33,990 - INFO -   Date          : 2025-04-25\n",
      "2025-05-14 15:54:33,990 - INFO -   Scheme        : SW\n",
      "2025-05-14 15:54:33,990 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:33,990 - INFO -   Selection Date Used: 2025-04-25\n",
      "2025-05-14 15:54:33,990 - INFO -   Buy Date           : 2025-04-28\n",
      "2025-05-14 15:54:33,990 - INFO -   Sell Date          : 2025-04-29\n",
      "2025-05-14 15:54:34,008 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:34,009 - INFO -   Portfolio Return          : 0.0096 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:34,009 - INFO -   Win Rate (Individual)   : 70.00%\n",
      "2025-05-14 15:54:34,009 - INFO -   Avg Ticker Return       : 0.0085\n",
      "2025-05-14 15:54:34,009 - INFO -   Std Dev Ticker Return   : 0.0203\n",
      "2025-05-14 15:54:34,009 - INFO -   Period Sharpe (Indiv)   : 0.4154\n",
      "2025-05-14 15:54:34,009 - INFO - Backtest simulation for 'SW' on 2025-04-25 completed.\n",
      "2025-05-14 15:54:34,009 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,019 - INFO - \n",
      "===== Batch Backtest Processing Finished =====\n",
      "2025-05-14 15:54:34,021 - INFO - Extracted 3 performance records for this pair.\n",
      "2025-05-14 15:54:34,023 - INFO - --- Finished processing pair for 2025-04-25. ---\n",
      "2025-05-14 15:54:34,024 - INFO - \n",
      "--- Processing Pair 2/14: Data='2025-04-28_my_selection_run_1.parquet', Params='2025-04-28_my_selection_run_1_params.json' ---\n",
      "2025-05-14 15:54:34,026 - INFO - Processing for extracted date: 2025-04-28\n",
      "2025-05-14 15:54:34,030 - INFO - Parameters loaded from 2025-04-28_my_selection_run_1_params.json:\n",
      "2025-05-14 15:54:34,032 - INFO - \n",
      "{'filter_max_debt_eq': 1.5,\n",
      " 'filter_min_avg_volume_m': 2.0,\n",
      " 'filter_min_price': 10.0,\n",
      " 'filter_min_roe_pct': 5.0,\n",
      " 'inv_vol_col_name': 'ATR/Price %',\n",
      " 'n_select_actual': 10,\n",
      " 'n_select_requested': 10,\n",
      " 'score_weight_change': 0.35,\n",
      " 'score_weight_rel_volume': 0.2,\n",
      " 'score_weight_rsi': 0.35,\n",
      " 'score_weight_volatility': 0.1}\n",
      "\n",
      "2025-05-14 15:54:34,074 - INFO - Successfully extracted weights for scheme: EW (10 tickers) for date 2025-04-28\n",
      "2025-05-14 15:54:34,076 - INFO - Successfully extracted weights for scheme: IV (10 tickers) for date 2025-04-28\n",
      "2025-05-14 15:54:34,078 - INFO - Successfully extracted weights for scheme: SW (10 tickers) for date 2025-04-28\n",
      "2025-05-14 15:54:34,080 - INFO - Successfully extracted 3 setup(s) for 2025-04-28.\n",
      "2025-05-14 15:54:34,082 - INFO - Running backtests for date: 2025-04-28\n",
      "2025-05-14 15:54:34,083 - INFO - \n",
      "===== Starting Batch Backtest Processing =====\n",
      "2025-05-14 15:54:34,087 - INFO - Prepared global price data copy for backtests.\n",
      "2025-05-14 15:54:34,089 - INFO - \n",
      "Processing date: 2025-04-28\n",
      "2025-05-14 15:54:34,090 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,092 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:34,093 - INFO -   Date          : 2025-04-28\n",
      "2025-05-14 15:54:34,094 - INFO -   Scheme        : EW\n",
      "2025-05-14 15:54:34,096 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:34,099 - INFO -   Selection Date Used: 2025-04-28\n",
      "2025-05-14 15:54:34,100 - INFO -   Buy Date           : 2025-04-29\n",
      "2025-05-14 15:54:34,102 - INFO -   Sell Date          : 2025-04-30\n",
      "2025-05-14 15:54:34,108 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:34,109 - INFO -   Portfolio Return          : 0.0114 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:34,109 - INFO -   Win Rate (Individual)   : 80.00%\n",
      "2025-05-14 15:54:34,109 - INFO -   Avg Ticker Return       : 0.0114\n",
      "2025-05-14 15:54:34,109 - INFO -   Std Dev Ticker Return   : 0.0208\n",
      "2025-05-14 15:54:34,109 - INFO -   Period Sharpe (Indiv)   : 0.5458\n",
      "2025-05-14 15:54:34,109 - INFO - Backtest simulation for 'EW' on 2025-04-28 completed.\n",
      "2025-05-14 15:54:34,109 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,119 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,149 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:34,150 - INFO -   Date          : 2025-04-28\n",
      "2025-05-14 15:54:34,151 - INFO -   Scheme        : IV\n",
      "2025-05-14 15:54:34,152 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:34,156 - INFO -   Selection Date Used: 2025-04-28\n",
      "2025-05-14 15:54:34,157 - INFO -   Buy Date           : 2025-04-29\n",
      "2025-05-14 15:54:34,158 - INFO -   Sell Date          : 2025-04-30\n",
      "2025-05-14 15:54:34,159 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:34,159 - INFO -   Portfolio Return          : 0.0104 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:34,159 - INFO -   Win Rate (Individual)   : 80.00%\n",
      "2025-05-14 15:54:34,159 - INFO -   Avg Ticker Return       : 0.0114\n",
      "2025-05-14 15:54:34,159 - INFO -   Std Dev Ticker Return   : 0.0208\n",
      "2025-05-14 15:54:34,159 - INFO -   Period Sharpe (Indiv)   : 0.5458\n",
      "2025-05-14 15:54:34,159 - INFO - Backtest simulation for 'IV' on 2025-04-28 completed.\n",
      "2025-05-14 15:54:34,170 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,171 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,172 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:34,173 - INFO -   Date          : 2025-04-28\n",
      "2025-05-14 15:54:34,174 - INFO -   Scheme        : SW\n",
      "2025-05-14 15:54:34,175 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:34,177 - INFO -   Selection Date Used: 2025-04-28\n",
      "2025-05-14 15:54:34,178 - INFO -   Buy Date           : 2025-04-29\n",
      "2025-05-14 15:54:34,179 - INFO -   Sell Date          : 2025-04-30\n",
      "2025-05-14 15:54:34,184 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:34,187 - INFO -   Portfolio Return          : 0.0128 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:34,189 - INFO -   Win Rate (Individual)   : 80.00%\n",
      "2025-05-14 15:54:34,205 - INFO -   Avg Ticker Return       : 0.0114\n",
      "2025-05-14 15:54:34,212 - INFO -   Std Dev Ticker Return   : 0.0208\n",
      "2025-05-14 15:54:34,220 - INFO -   Period Sharpe (Indiv)   : 0.5458\n",
      "2025-05-14 15:54:34,221 - INFO - Backtest simulation for 'SW' on 2025-04-28 completed.\n",
      "2025-05-14 15:54:34,223 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,225 - INFO - \n",
      "===== Batch Backtest Processing Finished =====\n",
      "2025-05-14 15:54:34,234 - INFO - Extracted 3 performance records for this pair.\n",
      "2025-05-14 15:54:34,239 - INFO - --- Finished processing pair for 2025-04-28. ---\n",
      "2025-05-14 15:54:34,241 - INFO - \n",
      "--- Processing Pair 3/14: Data='2025-04-29_my_selection_run_1.parquet', Params='2025-04-29_my_selection_run_1_params.json' ---\n",
      "2025-05-14 15:54:34,242 - INFO - Processing for extracted date: 2025-04-29\n",
      "2025-05-14 15:54:34,245 - INFO - Parameters loaded from 2025-04-29_my_selection_run_1_params.json:\n",
      "2025-05-14 15:54:34,247 - INFO - \n",
      "{'filter_max_debt_eq': 1.5,\n",
      " 'filter_min_avg_volume_m': 2.0,\n",
      " 'filter_min_price': 10.0,\n",
      " 'filter_min_roe_pct': 5.0,\n",
      " 'inv_vol_col_name': 'ATR/Price %',\n",
      " 'n_select_actual': 10,\n",
      " 'n_select_requested': 10,\n",
      " 'score_weight_change': 0.35,\n",
      " 'score_weight_rel_volume': 0.2,\n",
      " 'score_weight_rsi': 0.35,\n",
      " 'score_weight_volatility': 0.1}\n",
      "\n",
      "2025-05-14 15:54:34,284 - INFO - Successfully extracted weights for scheme: EW (10 tickers) for date 2025-04-29\n",
      "2025-05-14 15:54:34,288 - INFO - Successfully extracted weights for scheme: IV (10 tickers) for date 2025-04-29\n",
      "2025-05-14 15:54:34,288 - INFO - Successfully extracted weights for scheme: SW (10 tickers) for date 2025-04-29\n",
      "2025-05-14 15:54:34,293 - INFO - Successfully extracted 3 setup(s) for 2025-04-29.\n",
      "2025-05-14 15:54:34,295 - INFO - Running backtests for date: 2025-04-29\n",
      "2025-05-14 15:54:34,296 - INFO - \n",
      "===== Starting Batch Backtest Processing =====\n",
      "2025-05-14 15:54:34,298 - INFO - Prepared global price data copy for backtests.\n",
      "2025-05-14 15:54:34,298 - INFO - \n",
      "Processing date: 2025-04-29\n",
      "2025-05-14 15:54:34,303 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,305 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:34,306 - INFO -   Date          : 2025-04-29\n",
      "2025-05-14 15:54:34,308 - INFO -   Scheme        : EW\n",
      "2025-05-14 15:54:34,310 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:34,312 - INFO -   Selection Date Used: 2025-04-29\n",
      "2025-05-14 15:54:34,313 - INFO -   Buy Date           : 2025-04-30\n",
      "2025-05-14 15:54:34,315 - INFO -   Sell Date          : 2025-05-01\n",
      "2025-05-14 15:54:34,322 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:34,324 - INFO -   Portfolio Return          : -0.0023 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:34,326 - INFO -   Win Rate (Individual)   : 40.00%\n",
      "2025-05-14 15:54:34,327 - INFO -   Avg Ticker Return       : -0.0023\n",
      "2025-05-14 15:54:34,328 - INFO -   Std Dev Ticker Return   : 0.0144\n",
      "2025-05-14 15:54:34,329 - INFO -   Period Sharpe (Indiv)   : -0.1687\n",
      "2025-05-14 15:54:34,330 - INFO - Backtest simulation for 'EW' on 2025-04-29 completed.\n",
      "2025-05-14 15:54:34,331 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,333 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,334 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:34,337 - INFO -   Date          : 2025-04-29\n",
      "2025-05-14 15:54:34,338 - INFO -   Scheme        : IV\n",
      "2025-05-14 15:54:34,340 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:34,347 - INFO -   Selection Date Used: 2025-04-29\n",
      "2025-05-14 15:54:34,360 - INFO -   Buy Date           : 2025-04-30\n",
      "2025-05-14 15:54:34,372 - INFO -   Sell Date          : 2025-05-01\n",
      "2025-05-14 15:54:34,414 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:34,416 - INFO -   Portfolio Return          : -0.0012 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:34,417 - INFO -   Win Rate (Individual)   : 40.00%\n",
      "2025-05-14 15:54:34,417 - INFO -   Avg Ticker Return       : -0.0023\n",
      "2025-05-14 15:54:34,419 - INFO -   Std Dev Ticker Return   : 0.0144\n",
      "2025-05-14 15:54:34,421 - INFO -   Period Sharpe (Indiv)   : -0.1687\n",
      "2025-05-14 15:54:34,422 - INFO - Backtest simulation for 'IV' on 2025-04-29 completed.\n",
      "2025-05-14 15:54:34,422 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,422 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,422 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:34,422 - INFO -   Date          : 2025-04-29\n",
      "2025-05-14 15:54:34,422 - INFO -   Scheme        : SW\n",
      "2025-05-14 15:54:34,422 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:34,422 - INFO -   Selection Date Used: 2025-04-29\n",
      "2025-05-14 15:54:34,422 - INFO -   Buy Date           : 2025-04-30\n",
      "2025-05-14 15:54:34,436 - INFO -   Sell Date          : 2025-05-01\n",
      "2025-05-14 15:54:34,443 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:34,445 - INFO -   Portfolio Return          : -0.0064 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:34,447 - INFO -   Win Rate (Individual)   : 40.00%\n",
      "2025-05-14 15:54:34,449 - INFO -   Avg Ticker Return       : -0.0023\n",
      "2025-05-14 15:54:34,450 - INFO -   Std Dev Ticker Return   : 0.0144\n",
      "2025-05-14 15:54:34,451 - INFO -   Period Sharpe (Indiv)   : -0.1687\n",
      "2025-05-14 15:54:34,455 - INFO - Backtest simulation for 'SW' on 2025-04-29 completed.\n",
      "2025-05-14 15:54:34,457 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,459 - INFO - \n",
      "===== Batch Backtest Processing Finished =====\n",
      "2025-05-14 15:54:34,461 - INFO - Extracted 3 performance records for this pair.\n",
      "2025-05-14 15:54:34,462 - INFO - --- Finished processing pair for 2025-04-29. ---\n",
      "2025-05-14 15:54:34,463 - INFO - \n",
      "--- Processing Pair 4/14: Data='2025-04-30_my_selection_run_1.parquet', Params='2025-04-30_my_selection_run_1_params.json' ---\n",
      "2025-05-14 15:54:34,464 - INFO - Processing for extracted date: 2025-04-30\n",
      "2025-05-14 15:54:34,467 - INFO - Parameters loaded from 2025-04-30_my_selection_run_1_params.json:\n",
      "2025-05-14 15:54:34,469 - INFO - \n",
      "{'filter_max_debt_eq': 1.5,\n",
      " 'filter_min_avg_volume_m': 2.0,\n",
      " 'filter_min_price': 10.0,\n",
      " 'filter_min_roe_pct': 5.0,\n",
      " 'inv_vol_col_name': 'ATR/Price %',\n",
      " 'n_select_actual': 10,\n",
      " 'n_select_requested': 10,\n",
      " 'score_weight_change': 0.35,\n",
      " 'score_weight_rel_volume': 0.2,\n",
      " 'score_weight_rsi': 0.35,\n",
      " 'score_weight_volatility': 0.1}\n",
      "\n",
      "2025-05-14 15:54:34,490 - INFO - Successfully extracted weights for scheme: EW (10 tickers) for date 2025-04-30\n",
      "2025-05-14 15:54:34,492 - INFO - Successfully extracted weights for scheme: IV (10 tickers) for date 2025-04-30\n",
      "2025-05-14 15:54:34,494 - INFO - Successfully extracted weights for scheme: SW (10 tickers) for date 2025-04-30\n",
      "2025-05-14 15:54:34,494 - INFO - Successfully extracted 3 setup(s) for 2025-04-30.\n",
      "2025-05-14 15:54:34,494 - INFO - Running backtests for date: 2025-04-30\n",
      "2025-05-14 15:54:34,494 - INFO - \n",
      "===== Starting Batch Backtest Processing =====\n",
      "2025-05-14 15:54:34,503 - INFO - Prepared global price data copy for backtests.\n",
      "2025-05-14 15:54:34,504 - INFO - \n",
      "Processing date: 2025-04-30\n",
      "2025-05-14 15:54:34,505 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,506 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:34,507 - INFO -   Date          : 2025-04-30\n",
      "2025-05-14 15:54:34,509 - INFO -   Scheme        : EW\n",
      "2025-05-14 15:54:34,510 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:34,513 - INFO -   Selection Date Used: 2025-04-30\n",
      "2025-05-14 15:54:34,514 - INFO -   Buy Date           : 2025-05-01\n",
      "2025-05-14 15:54:34,515 - INFO -   Sell Date          : 2025-05-02\n",
      "2025-05-14 15:54:34,521 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:34,522 - INFO -   Portfolio Return          : 0.0242 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:34,523 - INFO -   Win Rate (Individual)   : 90.00%\n",
      "2025-05-14 15:54:34,524 - INFO -   Avg Ticker Return       : 0.0242\n",
      "2025-05-14 15:54:34,525 - INFO -   Std Dev Ticker Return   : 0.0141\n",
      "2025-05-14 15:54:34,526 - INFO -   Period Sharpe (Indiv)   : 1.7089\n",
      "2025-05-14 15:54:34,526 - INFO - Backtest simulation for 'EW' on 2025-04-30 completed.\n",
      "2025-05-14 15:54:34,526 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,526 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,531 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:34,531 - INFO -   Date          : 2025-04-30\n",
      "2025-05-14 15:54:34,531 - INFO -   Scheme        : IV\n",
      "2025-05-14 15:54:34,536 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:34,540 - INFO -   Selection Date Used: 2025-04-30\n",
      "2025-05-14 15:54:34,541 - INFO -   Buy Date           : 2025-05-01\n",
      "2025-05-14 15:54:34,542 - INFO -   Sell Date          : 2025-05-02\n",
      "2025-05-14 15:54:34,548 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:34,549 - INFO -   Portfolio Return          : 0.0230 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:34,550 - INFO -   Win Rate (Individual)   : 90.00%\n",
      "2025-05-14 15:54:34,552 - INFO -   Avg Ticker Return       : 0.0242\n",
      "2025-05-14 15:54:34,554 - INFO -   Std Dev Ticker Return   : 0.0141\n",
      "2025-05-14 15:54:34,556 - INFO -   Period Sharpe (Indiv)   : 1.7089\n",
      "2025-05-14 15:54:34,559 - INFO - Backtest simulation for 'IV' on 2025-04-30 completed.\n",
      "2025-05-14 15:54:34,560 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,562 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,562 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:34,562 - INFO -   Date          : 2025-04-30\n",
      "2025-05-14 15:54:34,562 - INFO -   Scheme        : SW\n",
      "2025-05-14 15:54:34,562 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:34,572 - INFO -   Selection Date Used: 2025-04-30\n",
      "2025-05-14 15:54:34,573 - INFO -   Buy Date           : 2025-05-01\n",
      "2025-05-14 15:54:34,574 - INFO -   Sell Date          : 2025-05-02\n",
      "2025-05-14 15:54:34,574 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:34,574 - INFO -   Portfolio Return          : 0.0253 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:34,574 - INFO -   Win Rate (Individual)   : 90.00%\n",
      "2025-05-14 15:54:34,574 - INFO -   Avg Ticker Return       : 0.0242\n",
      "2025-05-14 15:54:34,585 - INFO -   Std Dev Ticker Return   : 0.0141\n",
      "2025-05-14 15:54:34,587 - INFO -   Period Sharpe (Indiv)   : 1.7089\n",
      "2025-05-14 15:54:34,589 - INFO - Backtest simulation for 'SW' on 2025-04-30 completed.\n",
      "2025-05-14 15:54:34,590 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,590 - INFO - \n",
      "===== Batch Backtest Processing Finished =====\n",
      "2025-05-14 15:54:34,590 - INFO - Extracted 3 performance records for this pair.\n",
      "2025-05-14 15:54:34,590 - INFO - --- Finished processing pair for 2025-04-30. ---\n",
      "2025-05-14 15:54:34,590 - INFO - \n",
      "--- Processing Pair 5/14: Data='2025-05-01_my_selection_run_1.parquet', Params='2025-05-01_my_selection_run_1_params.json' ---\n",
      "2025-05-14 15:54:34,590 - INFO - Processing for extracted date: 2025-05-01\n",
      "2025-05-14 15:54:34,590 - INFO - Parameters loaded from 2025-05-01_my_selection_run_1_params.json:\n",
      "2025-05-14 15:54:34,602 - INFO - \n",
      "{'filter_max_debt_eq': 1.5,\n",
      " 'filter_min_avg_volume_m': 2.0,\n",
      " 'filter_min_price': 10.0,\n",
      " 'filter_min_roe_pct': 5.0,\n",
      " 'inv_vol_col_name': 'ATR/Price %',\n",
      " 'n_select_actual': 10,\n",
      " 'n_select_requested': 10,\n",
      " 'score_weight_change': 0.35,\n",
      " 'score_weight_rel_volume': 0.2,\n",
      " 'score_weight_rsi': 0.35,\n",
      " 'score_weight_volatility': 0.1}\n",
      "\n",
      "2025-05-14 15:54:34,625 - INFO - Successfully extracted weights for scheme: EW (10 tickers) for date 2025-05-01\n",
      "2025-05-14 15:54:34,625 - INFO - Successfully extracted weights for scheme: IV (10 tickers) for date 2025-05-01\n",
      "2025-05-14 15:54:34,625 - INFO - Successfully extracted weights for scheme: SW (10 tickers) for date 2025-05-01\n",
      "2025-05-14 15:54:34,625 - INFO - Successfully extracted 3 setup(s) for 2025-05-01.\n",
      "2025-05-14 15:54:34,637 - INFO - Running backtests for date: 2025-05-01\n",
      "2025-05-14 15:54:34,639 - INFO - \n",
      "===== Starting Batch Backtest Processing =====\n",
      "2025-05-14 15:54:34,646 - INFO - Prepared global price data copy for backtests.\n",
      "2025-05-14 15:54:34,647 - INFO - \n",
      "Processing date: 2025-05-01\n",
      "2025-05-14 15:54:34,649 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,650 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:34,651 - INFO -   Date          : 2025-05-01\n",
      "2025-05-14 15:54:34,653 - INFO -   Scheme        : EW\n",
      "2025-05-14 15:54:34,654 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:34,663 - INFO -   Selection Date Used: 2025-05-01\n",
      "2025-05-14 15:54:34,664 - INFO -   Buy Date           : 2025-05-02\n",
      "2025-05-14 15:54:34,666 - INFO -   Sell Date          : 2025-05-05\n",
      "2025-05-14 15:54:34,672 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:34,674 - INFO -   Portfolio Return          : -0.0038 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:34,675 - INFO -   Win Rate (Individual)   : 40.00%\n",
      "2025-05-14 15:54:34,676 - INFO -   Avg Ticker Return       : -0.0038\n",
      "2025-05-14 15:54:34,677 - INFO -   Std Dev Ticker Return   : 0.0207\n",
      "2025-05-14 15:54:34,679 - INFO -   Period Sharpe (Indiv)   : -0.1880\n",
      "2025-05-14 15:54:34,680 - INFO - Backtest simulation for 'EW' on 2025-05-01 completed.\n",
      "2025-05-14 15:54:34,681 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,683 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,684 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:34,686 - INFO -   Date          : 2025-05-01\n",
      "2025-05-14 15:54:34,687 - INFO -   Scheme        : IV\n",
      "2025-05-14 15:54:34,688 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:34,691 - INFO -   Selection Date Used: 2025-05-01\n",
      "2025-05-14 15:54:34,692 - INFO -   Buy Date           : 2025-05-02\n",
      "2025-05-14 15:54:34,693 - INFO -   Sell Date          : 2025-05-05\n",
      "2025-05-14 15:54:34,698 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:34,699 - INFO -   Portfolio Return          : -0.0049 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:34,699 - INFO -   Win Rate (Individual)   : 40.00%\n",
      "2025-05-14 15:54:34,700 - INFO -   Avg Ticker Return       : -0.0038\n",
      "2025-05-14 15:54:34,701 - INFO -   Std Dev Ticker Return   : 0.0207\n",
      "2025-05-14 15:54:34,702 - INFO -   Period Sharpe (Indiv)   : -0.1880\n",
      "2025-05-14 15:54:34,702 - INFO - Backtest simulation for 'IV' on 2025-05-01 completed.\n",
      "2025-05-14 15:54:34,702 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,702 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,702 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:34,702 - INFO -   Date          : 2025-05-01\n",
      "2025-05-14 15:54:34,702 - INFO -   Scheme        : SW\n",
      "2025-05-14 15:54:34,702 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:34,702 - INFO -   Selection Date Used: 2025-05-01\n",
      "2025-05-14 15:54:34,702 - INFO -   Buy Date           : 2025-05-02\n",
      "2025-05-14 15:54:34,702 - INFO -   Sell Date          : 2025-05-05\n",
      "2025-05-14 15:54:34,723 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:34,727 - INFO -   Portfolio Return          : -0.0016 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:34,729 - INFO -   Win Rate (Individual)   : 40.00%\n",
      "2025-05-14 15:54:34,730 - INFO -   Avg Ticker Return       : -0.0038\n",
      "2025-05-14 15:54:34,731 - INFO -   Std Dev Ticker Return   : 0.0207\n",
      "2025-05-14 15:54:34,732 - INFO -   Period Sharpe (Indiv)   : -0.1880\n",
      "2025-05-14 15:54:34,734 - INFO - Backtest simulation for 'SW' on 2025-05-01 completed.\n",
      "2025-05-14 15:54:34,736 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,739 - INFO - \n",
      "===== Batch Backtest Processing Finished =====\n",
      "2025-05-14 15:54:34,742 - INFO - Extracted 3 performance records for this pair.\n",
      "2025-05-14 15:54:34,742 - INFO - --- Finished processing pair for 2025-05-01. ---\n",
      "2025-05-14 15:54:34,742 - INFO - \n",
      "--- Processing Pair 6/14: Data='2025-05-02_my_selection_run_1.parquet', Params='2025-05-02_my_selection_run_1_params.json' ---\n",
      "2025-05-14 15:54:34,742 - INFO - Processing for extracted date: 2025-05-02\n",
      "2025-05-14 15:54:34,754 - INFO - Parameters loaded from 2025-05-02_my_selection_run_1_params.json:\n",
      "2025-05-14 15:54:34,756 - INFO - \n",
      "{'filter_max_debt_eq': 1.5,\n",
      " 'filter_min_avg_volume_m': 2.0,\n",
      " 'filter_min_price': 10.0,\n",
      " 'filter_min_roe_pct': 5.0,\n",
      " 'inv_vol_col_name': 'ATR/Price %',\n",
      " 'n_select_actual': 10,\n",
      " 'n_select_requested': 10,\n",
      " 'score_weight_change': 0.35,\n",
      " 'score_weight_rel_volume': 0.2,\n",
      " 'score_weight_rsi': 0.35,\n",
      " 'score_weight_volatility': 0.1}\n",
      "\n",
      "2025-05-14 15:54:34,779 - INFO - Successfully extracted weights for scheme: EW (10 tickers) for date 2025-05-02\n",
      "2025-05-14 15:54:34,781 - INFO - Successfully extracted weights for scheme: IV (10 tickers) for date 2025-05-02\n",
      "2025-05-14 15:54:34,783 - INFO - Successfully extracted weights for scheme: SW (10 tickers) for date 2025-05-02\n",
      "2025-05-14 15:54:34,784 - INFO - Successfully extracted 3 setup(s) for 2025-05-02.\n",
      "2025-05-14 15:54:34,786 - INFO - Running backtests for date: 2025-05-02\n",
      "2025-05-14 15:54:34,787 - INFO - \n",
      "===== Starting Batch Backtest Processing =====\n",
      "2025-05-14 15:54:34,790 - INFO - Prepared global price data copy for backtests.\n",
      "2025-05-14 15:54:34,791 - INFO - \n",
      "Processing date: 2025-05-02\n",
      "2025-05-14 15:54:34,793 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,794 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:34,796 - INFO -   Date          : 2025-05-02\n",
      "2025-05-14 15:54:34,796 - INFO -   Scheme        : EW\n",
      "2025-05-14 15:54:34,796 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:34,796 - INFO -   Selection Date Used: 2025-05-02\n",
      "2025-05-14 15:54:34,803 - INFO -   Buy Date           : 2025-05-05\n",
      "2025-05-14 15:54:34,805 - INFO -   Sell Date          : 2025-05-06\n",
      "2025-05-14 15:54:34,811 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:34,812 - INFO -   Portfolio Return          : 0.0038 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:34,813 - INFO -   Win Rate (Individual)   : 50.00%\n",
      "2025-05-14 15:54:34,815 - INFO -   Avg Ticker Return       : 0.0038\n",
      "2025-05-14 15:54:34,816 - INFO -   Std Dev Ticker Return   : 0.0225\n",
      "2025-05-14 15:54:34,817 - INFO -   Period Sharpe (Indiv)   : 0.1657\n",
      "2025-05-14 15:54:34,818 - INFO - Backtest simulation for 'EW' on 2025-05-02 completed.\n",
      "2025-05-14 15:54:34,821 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,822 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,823 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:34,825 - INFO -   Date          : 2025-05-02\n",
      "2025-05-14 15:54:34,827 - INFO -   Scheme        : IV\n",
      "2025-05-14 15:54:34,828 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:34,831 - INFO -   Selection Date Used: 2025-05-02\n",
      "2025-05-14 15:54:34,833 - INFO -   Buy Date           : 2025-05-05\n",
      "2025-05-14 15:54:34,834 - INFO -   Sell Date          : 2025-05-06\n",
      "2025-05-14 15:54:34,835 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:34,835 - INFO -   Portfolio Return          : 0.0017 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:34,835 - INFO -   Win Rate (Individual)   : 50.00%\n",
      "2025-05-14 15:54:34,835 - INFO -   Avg Ticker Return       : 0.0038\n",
      "2025-05-14 15:54:34,835 - INFO -   Std Dev Ticker Return   : 0.0225\n",
      "2025-05-14 15:54:34,835 - INFO -   Period Sharpe (Indiv)   : 0.1657\n",
      "2025-05-14 15:54:34,835 - INFO - Backtest simulation for 'IV' on 2025-05-02 completed.\n",
      "2025-05-14 15:54:34,835 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,852 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,854 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:34,856 - INFO -   Date          : 2025-05-02\n",
      "2025-05-14 15:54:34,857 - INFO -   Scheme        : SW\n",
      "2025-05-14 15:54:34,858 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:34,862 - INFO -   Selection Date Used: 2025-05-02\n",
      "2025-05-14 15:54:34,864 - INFO -   Buy Date           : 2025-05-05\n",
      "2025-05-14 15:54:34,865 - INFO -   Sell Date          : 2025-05-06\n",
      "2025-05-14 15:54:34,870 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:34,872 - INFO -   Portfolio Return          : 0.0045 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:34,873 - INFO -   Win Rate (Individual)   : 50.00%\n",
      "2025-05-14 15:54:34,875 - INFO -   Avg Ticker Return       : 0.0038\n",
      "2025-05-14 15:54:34,876 - INFO -   Std Dev Ticker Return   : 0.0225\n",
      "2025-05-14 15:54:34,877 - INFO -   Period Sharpe (Indiv)   : 0.1657\n",
      "2025-05-14 15:54:34,878 - INFO - Backtest simulation for 'SW' on 2025-05-02 completed.\n",
      "2025-05-14 15:54:34,879 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,879 - INFO - \n",
      "===== Batch Backtest Processing Finished =====\n",
      "2025-05-14 15:54:34,879 - INFO - Extracted 3 performance records for this pair.\n",
      "2025-05-14 15:54:34,879 - INFO - --- Finished processing pair for 2025-05-02. ---\n",
      "2025-05-14 15:54:34,886 - INFO - \n",
      "--- Processing Pair 7/14: Data='2025-05-05_my_selection_run_1.parquet', Params='2025-05-05_my_selection_run_1_params.json' ---\n",
      "2025-05-14 15:54:34,887 - INFO - Processing for extracted date: 2025-05-05\n",
      "2025-05-14 15:54:34,892 - INFO - Parameters loaded from 2025-05-05_my_selection_run_1_params.json:\n",
      "2025-05-14 15:54:34,894 - INFO - \n",
      "{'filter_max_debt_eq': 1.5,\n",
      " 'filter_min_avg_volume_m': 2.0,\n",
      " 'filter_min_price': 10.0,\n",
      " 'filter_min_roe_pct': 5.0,\n",
      " 'inv_vol_col_name': 'ATR/Price %',\n",
      " 'n_select_actual': 10,\n",
      " 'n_select_requested': 10,\n",
      " 'score_weight_change': 0.35,\n",
      " 'score_weight_rel_volume': 0.2,\n",
      " 'score_weight_rsi': 0.35,\n",
      " 'score_weight_volatility': 0.1}\n",
      "\n",
      "2025-05-14 15:54:34,921 - INFO - Successfully extracted weights for scheme: EW (10 tickers) for date 2025-05-05\n",
      "2025-05-14 15:54:34,924 - INFO - Successfully extracted weights for scheme: IV (10 tickers) for date 2025-05-05\n",
      "2025-05-14 15:54:34,926 - INFO - Successfully extracted weights for scheme: SW (10 tickers) for date 2025-05-05\n",
      "2025-05-14 15:54:34,927 - INFO - Successfully extracted 3 setup(s) for 2025-05-05.\n",
      "2025-05-14 15:54:34,927 - INFO - Running backtests for date: 2025-05-05\n",
      "2025-05-14 15:54:34,927 - INFO - \n",
      "===== Starting Batch Backtest Processing =====\n",
      "2025-05-14 15:54:34,927 - INFO - Prepared global price data copy for backtests.\n",
      "2025-05-14 15:54:34,935 - INFO - \n",
      "Processing date: 2025-05-05\n",
      "2025-05-14 15:54:34,936 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,938 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:34,939 - INFO -   Date          : 2025-05-05\n",
      "2025-05-14 15:54:34,940 - INFO -   Scheme        : EW\n",
      "2025-05-14 15:54:34,941 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:34,944 - INFO -   Selection Date Used: 2025-05-05\n",
      "2025-05-14 15:54:34,944 - INFO -   Buy Date           : 2025-05-06\n",
      "2025-05-14 15:54:34,944 - INFO -   Sell Date          : 2025-05-07\n",
      "2025-05-14 15:54:34,953 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:34,954 - INFO -   Portfolio Return          : 0.0105 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:34,955 - INFO -   Win Rate (Individual)   : 70.00%\n",
      "2025-05-14 15:54:34,956 - INFO -   Avg Ticker Return       : 0.0105\n",
      "2025-05-14 15:54:34,957 - INFO -   Std Dev Ticker Return   : 0.0169\n",
      "2025-05-14 15:54:34,958 - INFO -   Period Sharpe (Indiv)   : 0.6157\n",
      "2025-05-14 15:54:34,961 - INFO - Backtest simulation for 'EW' on 2025-05-05 completed.\n",
      "2025-05-14 15:54:34,962 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,965 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,966 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:34,967 - INFO -   Date          : 2025-05-05\n",
      "2025-05-14 15:54:34,969 - INFO -   Scheme        : IV\n",
      "2025-05-14 15:54:34,969 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:34,969 - INFO -   Selection Date Used: 2025-05-05\n",
      "2025-05-14 15:54:34,969 - INFO -   Buy Date           : 2025-05-06\n",
      "2025-05-14 15:54:34,969 - INFO -   Sell Date          : 2025-05-07\n",
      "2025-05-14 15:54:34,981 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:34,981 - INFO -   Portfolio Return          : 0.0106 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:34,986 - INFO -   Win Rate (Individual)   : 70.00%\n",
      "2025-05-14 15:54:34,988 - INFO -   Avg Ticker Return       : 0.0105\n",
      "2025-05-14 15:54:34,990 - INFO -   Std Dev Ticker Return   : 0.0169\n",
      "2025-05-14 15:54:34,992 - INFO -   Period Sharpe (Indiv)   : 0.6157\n",
      "2025-05-14 15:54:34,993 - INFO - Backtest simulation for 'IV' on 2025-05-05 completed.\n",
      "2025-05-14 15:54:34,995 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,995 - INFO - ------------------------------\n",
      "2025-05-14 15:54:34,995 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:34,995 - INFO -   Date          : 2025-05-05\n",
      "2025-05-14 15:54:34,995 - INFO -   Scheme        : SW\n",
      "2025-05-14 15:54:35,003 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:35,007 - INFO -   Selection Date Used: 2025-05-05\n",
      "2025-05-14 15:54:35,009 - INFO -   Buy Date           : 2025-05-06\n",
      "2025-05-14 15:54:35,010 - INFO -   Sell Date          : 2025-05-07\n",
      "2025-05-14 15:54:35,015 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:35,016 - INFO -   Portfolio Return          : 0.0105 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:35,017 - INFO -   Win Rate (Individual)   : 70.00%\n",
      "2025-05-14 15:54:35,019 - INFO -   Avg Ticker Return       : 0.0105\n",
      "2025-05-14 15:54:35,020 - INFO -   Std Dev Ticker Return   : 0.0169\n",
      "2025-05-14 15:54:35,022 - INFO -   Period Sharpe (Indiv)   : 0.6157\n",
      "2025-05-14 15:54:35,023 - INFO - Backtest simulation for 'SW' on 2025-05-05 completed.\n",
      "2025-05-14 15:54:35,025 - INFO - ------------------------------\n",
      "2025-05-14 15:54:35,027 - INFO - \n",
      "===== Batch Backtest Processing Finished =====\n",
      "2025-05-14 15:54:35,029 - INFO - Extracted 3 performance records for this pair.\n",
      "2025-05-14 15:54:35,060 - INFO - --- Finished processing pair for 2025-05-05. ---\n",
      "2025-05-14 15:54:35,062 - INFO - \n",
      "--- Processing Pair 8/14: Data='2025-05-06_my_selection_run_1.parquet', Params='2025-05-06_my_selection_run_1_params.json' ---\n",
      "2025-05-14 15:54:35,063 - INFO - Processing for extracted date: 2025-05-06\n",
      "2025-05-14 15:54:35,066 - INFO - Parameters loaded from 2025-05-06_my_selection_run_1_params.json:\n",
      "2025-05-14 15:54:35,067 - INFO - \n",
      "{'filter_max_debt_eq': 1.5,\n",
      " 'filter_min_avg_volume_m': 2.0,\n",
      " 'filter_min_price': 10.0,\n",
      " 'filter_min_roe_pct': 5.0,\n",
      " 'inv_vol_col_name': 'ATR/Price %',\n",
      " 'n_select_actual': 10,\n",
      " 'n_select_requested': 10,\n",
      " 'score_weight_change': 0.35,\n",
      " 'score_weight_rel_volume': 0.2,\n",
      " 'score_weight_rsi': 0.35,\n",
      " 'score_weight_volatility': 0.1}\n",
      "\n",
      "2025-05-14 15:54:35,086 - INFO - Successfully extracted weights for scheme: EW (10 tickers) for date 2025-05-06\n",
      "2025-05-14 15:54:35,127 - INFO - Successfully extracted weights for scheme: IV (10 tickers) for date 2025-05-06\n",
      "2025-05-14 15:54:35,128 - INFO - Successfully extracted weights for scheme: SW (10 tickers) for date 2025-05-06\n",
      "2025-05-14 15:54:35,130 - INFO - Successfully extracted 3 setup(s) for 2025-05-06.\n",
      "2025-05-14 15:54:35,132 - INFO - Running backtests for date: 2025-05-06\n",
      "2025-05-14 15:54:35,134 - INFO - \n",
      "===== Starting Batch Backtest Processing =====\n",
      "2025-05-14 15:54:35,136 - INFO - Prepared global price data copy for backtests.\n",
      "2025-05-14 15:54:35,136 - INFO - \n",
      "Processing date: 2025-05-06\n",
      "2025-05-14 15:54:35,136 - INFO - ------------------------------\n",
      "2025-05-14 15:54:35,136 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:35,136 - INFO -   Date          : 2025-05-06\n",
      "2025-05-14 15:54:35,148 - INFO -   Scheme        : EW\n",
      "2025-05-14 15:54:35,149 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:35,153 - INFO -   Selection Date Used: 2025-05-06\n",
      "2025-05-14 15:54:35,154 - INFO -   Buy Date           : 2025-05-07\n",
      "2025-05-14 15:54:35,156 - INFO -   Sell Date          : 2025-05-08\n",
      "2025-05-14 15:54:35,160 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:35,160 - INFO -   Portfolio Return          : 0.0159 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:35,160 - INFO -   Win Rate (Individual)   : 70.00%\n",
      "2025-05-14 15:54:35,160 - INFO -   Avg Ticker Return       : 0.0159\n",
      "2025-05-14 15:54:35,160 - INFO -   Std Dev Ticker Return   : 0.0253\n",
      "2025-05-14 15:54:35,160 - INFO -   Period Sharpe (Indiv)   : 0.6245\n",
      "2025-05-14 15:54:35,168 - INFO - Backtest simulation for 'EW' on 2025-05-06 completed.\n",
      "2025-05-14 15:54:35,169 - INFO - ------------------------------\n",
      "2025-05-14 15:54:35,171 - INFO - ------------------------------\n",
      "2025-05-14 15:54:35,176 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:35,177 - INFO -   Date          : 2025-05-06\n",
      "2025-05-14 15:54:35,179 - INFO -   Scheme        : IV\n",
      "2025-05-14 15:54:35,179 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:35,179 - INFO -   Selection Date Used: 2025-05-06\n",
      "2025-05-14 15:54:35,185 - INFO -   Buy Date           : 2025-05-07\n",
      "2025-05-14 15:54:35,186 - INFO -   Sell Date          : 2025-05-08\n",
      "2025-05-14 15:54:35,191 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:35,193 - INFO -   Portfolio Return          : 0.0128 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:35,193 - INFO -   Win Rate (Individual)   : 70.00%\n",
      "2025-05-14 15:54:35,193 - INFO -   Avg Ticker Return       : 0.0159\n",
      "2025-05-14 15:54:35,193 - INFO -   Std Dev Ticker Return   : 0.0253\n",
      "2025-05-14 15:54:35,219 - INFO -   Period Sharpe (Indiv)   : 0.6245\n",
      "2025-05-14 15:54:35,219 - INFO - Backtest simulation for 'IV' on 2025-05-06 completed.\n",
      "2025-05-14 15:54:35,219 - INFO - ------------------------------\n",
      "2025-05-14 15:54:35,219 - INFO - ------------------------------\n",
      "2025-05-14 15:54:35,219 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:35,219 - INFO -   Date          : 2025-05-06\n",
      "2025-05-14 15:54:35,219 - INFO -   Scheme        : SW\n",
      "2025-05-14 15:54:35,219 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:35,219 - INFO -   Selection Date Used: 2025-05-06\n",
      "2025-05-14 15:54:35,219 - INFO -   Buy Date           : 2025-05-07\n",
      "2025-05-14 15:54:35,236 - INFO -   Sell Date          : 2025-05-08\n",
      "2025-05-14 15:54:35,242 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:35,243 - INFO -   Portfolio Return          : 0.0171 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:35,245 - INFO -   Win Rate (Individual)   : 70.00%\n",
      "2025-05-14 15:54:35,246 - INFO -   Avg Ticker Return       : 0.0159\n",
      "2025-05-14 15:54:35,248 - INFO -   Std Dev Ticker Return   : 0.0253\n",
      "2025-05-14 15:54:35,249 - INFO -   Period Sharpe (Indiv)   : 0.6245\n",
      "2025-05-14 15:54:35,250 - INFO - Backtest simulation for 'SW' on 2025-05-06 completed.\n",
      "2025-05-14 15:54:35,252 - INFO - ------------------------------\n",
      "2025-05-14 15:54:35,275 - INFO - \n",
      "===== Batch Backtest Processing Finished =====\n",
      "2025-05-14 15:54:35,290 - INFO - Extracted 3 performance records for this pair.\n",
      "2025-05-14 15:54:35,295 - INFO - --- Finished processing pair for 2025-05-06. ---\n",
      "2025-05-14 15:54:35,296 - INFO - \n",
      "--- Processing Pair 9/14: Data='2025-05-07_my_selection_run_1.parquet', Params='2025-05-07_my_selection_run_1_params.json' ---\n",
      "2025-05-14 15:54:35,298 - INFO - Processing for extracted date: 2025-05-07\n",
      "2025-05-14 15:54:35,300 - INFO - Parameters loaded from 2025-05-07_my_selection_run_1_params.json:\n",
      "2025-05-14 15:54:35,303 - INFO - \n",
      "{'filter_max_debt_eq': 1.5,\n",
      " 'filter_min_avg_volume_m': 2.0,\n",
      " 'filter_min_price': 10.0,\n",
      " 'filter_min_roe_pct': 5.0,\n",
      " 'inv_vol_col_name': 'ATR/Price %',\n",
      " 'n_select_actual': 10,\n",
      " 'n_select_requested': 10,\n",
      " 'score_weight_change': 0.35,\n",
      " 'score_weight_rel_volume': 0.2,\n",
      " 'score_weight_rsi': 0.35,\n",
      " 'score_weight_volatility': 0.1}\n",
      "\n",
      "2025-05-14 15:54:35,329 - INFO - Successfully extracted weights for scheme: EW (10 tickers) for date 2025-05-07\n",
      "2025-05-14 15:54:35,329 - INFO - Successfully extracted weights for scheme: IV (10 tickers) for date 2025-05-07\n",
      "2025-05-14 15:54:35,329 - INFO - Successfully extracted weights for scheme: SW (10 tickers) for date 2025-05-07\n",
      "2025-05-14 15:54:35,329 - INFO - Successfully extracted 3 setup(s) for 2025-05-07.\n",
      "2025-05-14 15:54:35,336 - INFO - Running backtests for date: 2025-05-07\n",
      "2025-05-14 15:54:35,337 - INFO - \n",
      "===== Starting Batch Backtest Processing =====\n",
      "2025-05-14 15:54:35,340 - INFO - Prepared global price data copy for backtests.\n",
      "2025-05-14 15:54:35,340 - INFO - \n",
      "Processing date: 2025-05-07\n",
      "2025-05-14 15:54:35,340 - INFO - ------------------------------\n",
      "2025-05-14 15:54:35,340 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:35,340 - INFO -   Date          : 2025-05-07\n",
      "2025-05-14 15:54:35,340 - INFO -   Scheme        : EW\n",
      "2025-05-14 15:54:35,340 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:35,340 - INFO -   Selection Date Used: 2025-05-07\n",
      "2025-05-14 15:54:35,352 - INFO -   Buy Date           : 2025-05-08\n",
      "2025-05-14 15:54:35,354 - INFO -   Sell Date          : 2025-05-09\n",
      "2025-05-14 15:54:35,359 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:35,360 - INFO -   Portfolio Return          : -0.0044 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:35,362 - INFO -   Win Rate (Individual)   : 30.00%\n",
      "2025-05-14 15:54:35,363 - INFO -   Avg Ticker Return       : -0.0044\n",
      "2025-05-14 15:54:35,363 - INFO -   Std Dev Ticker Return   : 0.0137\n",
      "2025-05-14 15:54:35,363 - INFO -   Period Sharpe (Indiv)   : -0.3270\n",
      "2025-05-14 15:54:35,369 - INFO - Backtest simulation for 'EW' on 2025-05-07 completed.\n",
      "2025-05-14 15:54:35,370 - INFO - ------------------------------\n",
      "2025-05-14 15:54:35,372 - INFO - ------------------------------\n",
      "2025-05-14 15:54:35,373 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:35,374 - INFO -   Date          : 2025-05-07\n",
      "2025-05-14 15:54:35,375 - INFO -   Scheme        : IV\n",
      "2025-05-14 15:54:35,377 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:35,378 - INFO -   Selection Date Used: 2025-05-07\n",
      "2025-05-14 15:54:35,382 - INFO -   Buy Date           : 2025-05-08\n",
      "2025-05-14 15:54:35,382 - INFO -   Sell Date          : 2025-05-09\n",
      "2025-05-14 15:54:35,389 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:35,391 - INFO -   Portfolio Return          : -0.0031 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:35,392 - INFO -   Win Rate (Individual)   : 30.00%\n",
      "2025-05-14 15:54:35,393 - INFO -   Avg Ticker Return       : -0.0044\n",
      "2025-05-14 15:54:35,394 - INFO -   Std Dev Ticker Return   : 0.0137\n",
      "2025-05-14 15:54:35,395 - INFO -   Period Sharpe (Indiv)   : -0.3270\n",
      "2025-05-14 15:54:35,397 - INFO - Backtest simulation for 'IV' on 2025-05-07 completed.\n",
      "2025-05-14 15:54:35,398 - INFO - ------------------------------\n",
      "2025-05-14 15:54:35,400 - INFO - ------------------------------\n",
      "2025-05-14 15:54:35,401 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:35,402 - INFO -   Date          : 2025-05-07\n",
      "2025-05-14 15:54:35,402 - INFO -   Scheme        : SW\n",
      "2025-05-14 15:54:35,402 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:35,402 - INFO -   Selection Date Used: 2025-05-07\n",
      "2025-05-14 15:54:35,402 - INFO -   Buy Date           : 2025-05-08\n",
      "2025-05-14 15:54:35,402 - INFO -   Sell Date          : 2025-05-09\n",
      "2025-05-14 15:54:35,418 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:35,419 - INFO -   Portfolio Return          : -0.0047 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:35,419 - INFO -   Win Rate (Individual)   : 30.00%\n",
      "2025-05-14 15:54:35,419 - INFO -   Avg Ticker Return       : -0.0044\n",
      "2025-05-14 15:54:35,419 - INFO -   Std Dev Ticker Return   : 0.0137\n",
      "2025-05-14 15:54:35,419 - INFO -   Period Sharpe (Indiv)   : -0.3270\n",
      "2025-05-14 15:54:35,419 - INFO - Backtest simulation for 'SW' on 2025-05-07 completed.\n",
      "2025-05-14 15:54:35,419 - INFO - ------------------------------\n",
      "2025-05-14 15:54:35,419 - INFO - \n",
      "===== Batch Backtest Processing Finished =====\n",
      "2025-05-14 15:54:35,419 - INFO - Extracted 3 performance records for this pair.\n",
      "2025-05-14 15:54:35,419 - INFO - --- Finished processing pair for 2025-05-07. ---\n",
      "2025-05-14 15:54:35,419 - INFO - \n",
      "--- Processing Pair 10/14: Data='2025-05-08_my_selection_run_1.parquet', Params='2025-05-08_my_selection_run_1_params.json' ---\n",
      "2025-05-14 15:54:35,419 - INFO - Processing for extracted date: 2025-05-08\n",
      "2025-05-14 15:54:35,439 - INFO - Parameters loaded from 2025-05-08_my_selection_run_1_params.json:\n",
      "2025-05-14 15:54:35,443 - INFO - \n",
      "{'filter_max_debt_eq': 1.5,\n",
      " 'filter_min_avg_volume_m': 2.0,\n",
      " 'filter_min_price': 10.0,\n",
      " 'filter_min_roe_pct': 5.0,\n",
      " 'inv_vol_col_name': 'ATR/Price %',\n",
      " 'n_select_actual': 10,\n",
      " 'n_select_requested': 10,\n",
      " 'score_weight_change': 0.35,\n",
      " 'score_weight_rel_volume': 0.2,\n",
      " 'score_weight_rsi': 0.35,\n",
      " 'score_weight_volatility': 0.1}\n",
      "\n",
      "2025-05-14 15:54:35,466 - INFO - Successfully extracted weights for scheme: EW (10 tickers) for date 2025-05-08\n",
      "2025-05-14 15:54:35,468 - INFO - Successfully extracted weights for scheme: IV (10 tickers) for date 2025-05-08\n",
      "2025-05-14 15:54:35,470 - INFO - Successfully extracted weights for scheme: SW (10 tickers) for date 2025-05-08\n",
      "2025-05-14 15:54:35,471 - INFO - Successfully extracted 3 setup(s) for 2025-05-08.\n",
      "2025-05-14 15:54:35,471 - INFO - Running backtests for date: 2025-05-08\n",
      "2025-05-14 15:54:35,471 - INFO - \n",
      "===== Starting Batch Backtest Processing =====\n",
      "2025-05-14 15:54:35,471 - INFO - Prepared global price data copy for backtests.\n",
      "2025-05-14 15:54:35,471 - INFO - \n",
      "Processing date: 2025-05-08\n",
      "2025-05-14 15:54:35,471 - INFO - ------------------------------\n",
      "2025-05-14 15:54:35,471 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:35,471 - INFO -   Date          : 2025-05-08\n",
      "2025-05-14 15:54:35,471 - INFO -   Scheme        : EW\n",
      "2025-05-14 15:54:35,485 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:35,488 - INFO -   Selection Date Used: 2025-05-08\n",
      "2025-05-14 15:54:35,490 - INFO -   Buy Date           : 2025-05-09\n",
      "2025-05-14 15:54:35,491 - INFO -   Sell Date          : 2025-05-12\n",
      "2025-05-14 15:54:35,492 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:35,492 - INFO -   Portfolio Return          : 0.0246 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:35,505 - INFO -   Win Rate (Individual)   : 80.00%\n",
      "2025-05-14 15:54:35,506 - INFO -   Avg Ticker Return       : 0.0246\n",
      "2025-05-14 15:54:35,507 - INFO -   Std Dev Ticker Return   : 0.0295\n",
      "2025-05-14 15:54:35,509 - INFO -   Period Sharpe (Indiv)   : 0.8285\n",
      "2025-05-14 15:54:35,511 - INFO - Backtest simulation for 'EW' on 2025-05-08 completed.\n",
      "2025-05-14 15:54:35,512 - INFO - ------------------------------\n",
      "2025-05-14 15:54:35,513 - INFO - ------------------------------\n",
      "2025-05-14 15:54:35,515 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:35,517 - INFO -   Date          : 2025-05-08\n",
      "2025-05-14 15:54:35,520 - INFO -   Scheme        : IV\n",
      "2025-05-14 15:54:35,521 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:35,525 - INFO -   Selection Date Used: 2025-05-08\n",
      "2025-05-14 15:54:35,528 - INFO -   Buy Date           : 2025-05-09\n",
      "2025-05-14 15:54:35,529 - INFO -   Sell Date          : 2025-05-12\n",
      "2025-05-14 15:54:35,536 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:35,538 - INFO -   Portfolio Return          : 0.0204 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:35,539 - INFO -   Win Rate (Individual)   : 80.00%\n",
      "2025-05-14 15:54:35,540 - INFO -   Avg Ticker Return       : 0.0246\n",
      "2025-05-14 15:54:35,542 - INFO -   Std Dev Ticker Return   : 0.0295\n",
      "2025-05-14 15:54:35,544 - INFO -   Period Sharpe (Indiv)   : 0.8285\n",
      "2025-05-14 15:54:35,545 - INFO - Backtest simulation for 'IV' on 2025-05-08 completed.\n",
      "2025-05-14 15:54:35,547 - INFO - ------------------------------\n",
      "2025-05-14 15:54:35,553 - INFO - ------------------------------\n",
      "2025-05-14 15:54:35,568 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:35,570 - INFO -   Date          : 2025-05-08\n",
      "2025-05-14 15:54:35,571 - INFO -   Scheme        : SW\n",
      "2025-05-14 15:54:35,579 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:35,582 - INFO -   Selection Date Used: 2025-05-08\n",
      "2025-05-14 15:54:35,583 - INFO -   Buy Date           : 2025-05-09\n",
      "2025-05-14 15:54:35,584 - INFO -   Sell Date          : 2025-05-12\n",
      "2025-05-14 15:54:35,589 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:35,591 - INFO -   Portfolio Return          : 0.0250 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:35,592 - INFO -   Win Rate (Individual)   : 80.00%\n",
      "2025-05-14 15:54:35,593 - INFO -   Avg Ticker Return       : 0.0246\n",
      "2025-05-14 15:54:35,595 - INFO -   Std Dev Ticker Return   : 0.0295\n",
      "2025-05-14 15:54:35,596 - INFO -   Period Sharpe (Indiv)   : 0.8285\n",
      "2025-05-14 15:54:35,598 - INFO - Backtest simulation for 'SW' on 2025-05-08 completed.\n",
      "2025-05-14 15:54:35,599 - INFO - ------------------------------\n",
      "2025-05-14 15:54:35,601 - INFO - \n",
      "===== Batch Backtest Processing Finished =====\n",
      "2025-05-14 15:54:35,603 - INFO - Extracted 3 performance records for this pair.\n",
      "2025-05-14 15:54:35,605 - INFO - --- Finished processing pair for 2025-05-08. ---\n",
      "2025-05-14 15:54:35,607 - INFO - \n",
      "--- Processing Pair 11/14: Data='2025-05-09_my_selection_run_1.parquet', Params='2025-05-09_my_selection_run_1_params.json' ---\n",
      "2025-05-14 15:54:35,608 - INFO - Processing for extracted date: 2025-05-09\n",
      "2025-05-14 15:54:35,612 - INFO - Parameters loaded from 2025-05-09_my_selection_run_1_params.json:\n",
      "2025-05-14 15:54:35,614 - INFO - \n",
      "{'filter_max_debt_eq': 1.5,\n",
      " 'filter_min_avg_volume_m': 2.0,\n",
      " 'filter_min_price': 10.0,\n",
      " 'filter_min_roe_pct': 5.0,\n",
      " 'inv_vol_col_name': 'ATR/Price %',\n",
      " 'n_select_actual': 10,\n",
      " 'n_select_requested': 10,\n",
      " 'score_weight_change': 0.35,\n",
      " 'score_weight_rel_volume': 0.2,\n",
      " 'score_weight_rsi': 0.35,\n",
      " 'score_weight_volatility': 0.1}\n",
      "\n",
      "2025-05-14 15:54:35,677 - INFO - Successfully extracted weights for scheme: EW (10 tickers) for date 2025-05-09\n",
      "2025-05-14 15:54:35,678 - INFO - Successfully extracted weights for scheme: IV (10 tickers) for date 2025-05-09\n",
      "2025-05-14 15:54:35,680 - INFO - Successfully extracted weights for scheme: SW (10 tickers) for date 2025-05-09\n",
      "2025-05-14 15:54:35,681 - INFO - Successfully extracted 3 setup(s) for 2025-05-09.\n",
      "2025-05-14 15:54:35,682 - INFO - Running backtests for date: 2025-05-09\n",
      "2025-05-14 15:54:35,683 - INFO - \n",
      "===== Starting Batch Backtest Processing =====\n",
      "2025-05-14 15:54:35,686 - INFO - Prepared global price data copy for backtests.\n",
      "2025-05-14 15:54:35,688 - INFO - \n",
      "Processing date: 2025-05-09\n",
      "2025-05-14 15:54:35,689 - INFO - ------------------------------\n",
      "2025-05-14 15:54:35,690 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:35,691 - INFO -   Date          : 2025-05-09\n",
      "2025-05-14 15:54:35,692 - INFO -   Scheme        : EW\n",
      "2025-05-14 15:54:35,693 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:35,696 - INFO -   Selection Date Used: 2025-05-09\n",
      "2025-05-14 15:54:35,697 - INFO -   Buy Date           : 2025-05-12\n",
      "2025-05-14 15:54:35,698 - INFO -   Sell Date          : 2025-05-13\n",
      "2025-05-14 15:54:35,703 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:35,705 - INFO -   Portfolio Return          : -0.0248 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:35,706 - INFO -   Win Rate (Individual)   : 30.00%\n",
      "2025-05-14 15:54:35,707 - INFO -   Avg Ticker Return       : -0.0248\n",
      "2025-05-14 15:54:35,708 - INFO -   Std Dev Ticker Return   : 0.0573\n",
      "2025-05-14 15:54:35,709 - INFO -   Period Sharpe (Indiv)   : -0.4348\n",
      "2025-05-14 15:54:35,710 - INFO - Backtest simulation for 'EW' on 2025-05-09 completed.\n",
      "2025-05-14 15:54:35,711 - INFO - ------------------------------\n",
      "2025-05-14 15:54:35,712 - INFO - ------------------------------\n",
      "2025-05-14 15:54:35,713 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:35,714 - INFO -   Date          : 2025-05-09\n",
      "2025-05-14 15:54:35,715 - INFO -   Scheme        : IV\n",
      "2025-05-14 15:54:35,716 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:35,719 - INFO -   Selection Date Used: 2025-05-09\n",
      "2025-05-14 15:54:35,720 - INFO -   Buy Date           : 2025-05-12\n",
      "2025-05-14 15:54:35,720 - INFO -   Sell Date          : 2025-05-13\n",
      "2025-05-14 15:54:35,720 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:35,720 - INFO -   Portfolio Return          : -0.0230 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:35,720 - INFO -   Win Rate (Individual)   : 30.00%\n",
      "2025-05-14 15:54:35,720 - INFO -   Avg Ticker Return       : -0.0248\n",
      "2025-05-14 15:54:35,720 - INFO -   Std Dev Ticker Return   : 0.0573\n",
      "2025-05-14 15:54:35,720 - INFO -   Period Sharpe (Indiv)   : -0.4348\n",
      "2025-05-14 15:54:35,732 - INFO - Backtest simulation for 'IV' on 2025-05-09 completed.\n",
      "2025-05-14 15:54:35,733 - INFO - ------------------------------\n",
      "2025-05-14 15:54:35,757 - INFO - ------------------------------\n",
      "2025-05-14 15:54:35,757 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:35,757 - INFO -   Date          : 2025-05-09\n",
      "2025-05-14 15:54:35,757 - INFO -   Scheme        : SW\n",
      "2025-05-14 15:54:35,772 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:35,772 - INFO -   Selection Date Used: 2025-05-09\n",
      "2025-05-14 15:54:35,772 - INFO -   Buy Date           : 2025-05-12\n",
      "2025-05-14 15:54:35,772 - INFO -   Sell Date          : 2025-05-13\n",
      "2025-05-14 15:54:35,772 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:35,772 - INFO -   Portfolio Return          : -0.0236 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:35,772 - INFO -   Win Rate (Individual)   : 30.00%\n",
      "2025-05-14 15:54:35,772 - INFO -   Avg Ticker Return       : -0.0248\n",
      "2025-05-14 15:54:35,772 - INFO -   Std Dev Ticker Return   : 0.0573\n",
      "2025-05-14 15:54:35,788 - INFO -   Period Sharpe (Indiv)   : -0.4348\n",
      "2025-05-14 15:54:35,789 - INFO - Backtest simulation for 'SW' on 2025-05-09 completed.\n",
      "2025-05-14 15:54:35,791 - INFO - ------------------------------\n",
      "2025-05-14 15:54:35,792 - INFO - \n",
      "===== Batch Backtest Processing Finished =====\n",
      "2025-05-14 15:54:35,795 - INFO - Extracted 3 performance records for this pair.\n",
      "2025-05-14 15:54:35,795 - INFO - --- Finished processing pair for 2025-05-09. ---\n",
      "2025-05-14 15:54:35,795 - INFO - \n",
      "--- Processing Pair 12/14: Data='2025-05-12_my_selection_run_1.parquet', Params='2025-05-12_my_selection_run_1_params.json' ---\n",
      "2025-05-14 15:54:35,795 - INFO - Processing for extracted date: 2025-05-12\n",
      "2025-05-14 15:54:35,804 - INFO - Parameters loaded from 2025-05-12_my_selection_run_1_params.json:\n",
      "2025-05-14 15:54:35,806 - INFO - \n",
      "{'filter_max_debt_eq': 1.5,\n",
      " 'filter_min_avg_volume_m': 2.0,\n",
      " 'filter_min_price': 10.0,\n",
      " 'filter_min_roe_pct': 5.0,\n",
      " 'inv_vol_col_name': 'ATR/Price %',\n",
      " 'n_select_actual': 10,\n",
      " 'n_select_requested': 10,\n",
      " 'score_weight_change': 0.35,\n",
      " 'score_weight_rel_volume': 0.2,\n",
      " 'score_weight_rsi': 0.35,\n",
      " 'score_weight_volatility': 0.1}\n",
      "\n",
      "2025-05-14 15:54:35,828 - INFO - Successfully extracted weights for scheme: EW (10 tickers) for date 2025-05-12\n",
      "2025-05-14 15:54:35,830 - INFO - Successfully extracted weights for scheme: IV (10 tickers) for date 2025-05-12\n",
      "2025-05-14 15:54:35,831 - INFO - Successfully extracted weights for scheme: SW (10 tickers) for date 2025-05-12\n",
      "2025-05-14 15:54:35,832 - INFO - Successfully extracted 3 setup(s) for 2025-05-12.\n",
      "2025-05-14 15:54:35,834 - INFO - Running backtests for date: 2025-05-12\n",
      "2025-05-14 15:54:35,836 - INFO - \n",
      "===== Starting Batch Backtest Processing =====\n",
      "2025-05-14 15:54:35,836 - INFO - Prepared global price data copy for backtests.\n",
      "2025-05-14 15:54:35,836 - INFO - \n",
      "Processing date: 2025-05-12\n",
      "2025-05-14 15:54:35,857 - INFO - ------------------------------\n",
      "2025-05-14 15:54:35,870 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:35,872 - INFO -   Date          : 2025-05-12\n",
      "2025-05-14 15:54:35,874 - INFO -   Scheme        : EW\n",
      "2025-05-14 15:54:35,876 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:35,879 - INFO -   Selection Date Used: 2025-05-12\n",
      "2025-05-14 15:54:35,880 - INFO -   Buy Date           : 2025-05-13\n",
      "2025-05-14 15:54:35,881 - INFO -   Sell Date          : 2025-05-14\n",
      "2025-05-14 15:54:35,887 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:35,889 - INFO -   Portfolio Return          : -0.0175 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:35,890 - INFO -   Win Rate (Individual)   : 10.00%\n",
      "2025-05-14 15:54:35,891 - INFO -   Avg Ticker Return       : -0.0175\n",
      "2025-05-14 15:54:35,893 - INFO -   Std Dev Ticker Return   : 0.0121\n",
      "2025-05-14 15:54:35,894 - INFO -   Period Sharpe (Indiv)   : -1.4465\n",
      "2025-05-14 15:54:35,894 - INFO - Backtest simulation for 'EW' on 2025-05-12 completed.\n",
      "2025-05-14 15:54:35,894 - INFO - ------------------------------\n",
      "2025-05-14 15:54:35,894 - INFO - ------------------------------\n",
      "2025-05-14 15:54:35,894 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:35,894 - INFO -   Date          : 2025-05-12\n",
      "2025-05-14 15:54:35,894 - INFO -   Scheme        : IV\n",
      "2025-05-14 15:54:35,903 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:35,906 - INFO -   Selection Date Used: 2025-05-12\n",
      "2025-05-14 15:54:35,908 - INFO -   Buy Date           : 2025-05-13\n",
      "2025-05-14 15:54:35,909 - INFO -   Sell Date          : 2025-05-14\n",
      "2025-05-14 15:54:35,914 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:35,916 - INFO -   Portfolio Return          : -0.0149 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:35,918 - INFO -   Win Rate (Individual)   : 10.00%\n",
      "2025-05-14 15:54:35,920 - INFO -   Avg Ticker Return       : -0.0175\n",
      "2025-05-14 15:54:35,922 - INFO -   Std Dev Ticker Return   : 0.0121\n",
      "2025-05-14 15:54:35,923 - INFO -   Period Sharpe (Indiv)   : -1.4465\n",
      "2025-05-14 15:54:35,925 - INFO - Backtest simulation for 'IV' on 2025-05-12 completed.\n",
      "2025-05-14 15:54:35,926 - INFO - ------------------------------\n",
      "2025-05-14 15:54:35,928 - INFO - ------------------------------\n",
      "2025-05-14 15:54:35,929 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:35,929 - INFO -   Date          : 2025-05-12\n",
      "2025-05-14 15:54:35,929 - INFO -   Scheme        : SW\n",
      "2025-05-14 15:54:35,929 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:35,938 - INFO -   Selection Date Used: 2025-05-12\n",
      "2025-05-14 15:54:35,939 - INFO -   Buy Date           : 2025-05-13\n",
      "2025-05-14 15:54:35,940 - INFO -   Sell Date          : 2025-05-14\n",
      "2025-05-14 15:54:35,941 - INFO -   Trades Executed: 10/10\n",
      "2025-05-14 15:54:35,941 - INFO -   Portfolio Return          : -0.0173 (Based on Weight Sum: 1.0000)\n",
      "2025-05-14 15:54:35,941 - INFO -   Win Rate (Individual)   : 10.00%\n",
      "2025-05-14 15:54:35,953 - INFO -   Avg Ticker Return       : -0.0175\n",
      "2025-05-14 15:54:35,954 - INFO -   Std Dev Ticker Return   : 0.0121\n",
      "2025-05-14 15:54:35,956 - INFO -   Period Sharpe (Indiv)   : -1.4465\n",
      "2025-05-14 15:54:35,958 - INFO - Backtest simulation for 'SW' on 2025-05-12 completed.\n",
      "2025-05-14 15:54:35,959 - INFO - ------------------------------\n",
      "2025-05-14 15:54:35,961 - INFO - \n",
      "===== Batch Backtest Processing Finished =====\n",
      "2025-05-14 15:54:35,963 - INFO - Extracted 3 performance records for this pair.\n",
      "2025-05-14 15:54:35,964 - INFO - --- Finished processing pair for 2025-05-12. ---\n",
      "2025-05-14 15:54:35,965 - INFO - \n",
      "--- Processing Pair 13/14: Data='2025-05-13_my_selection_run_1.parquet', Params='2025-05-13_my_selection_run_1_params.json' ---\n",
      "2025-05-14 15:54:35,966 - INFO - Processing for extracted date: 2025-05-13\n",
      "2025-05-14 15:54:35,969 - INFO - Parameters loaded from 2025-05-13_my_selection_run_1_params.json:\n",
      "2025-05-14 15:54:35,971 - INFO - \n",
      "{'filter_max_debt_eq': 1.5,\n",
      " 'filter_min_avg_volume_m': 2.0,\n",
      " 'filter_min_price': 10.0,\n",
      " 'filter_min_roe_pct': 5.0,\n",
      " 'inv_vol_col_name': 'ATR/Price %',\n",
      " 'n_select_actual': 10,\n",
      " 'n_select_requested': 10,\n",
      " 'score_weight_change': 0.35,\n",
      " 'score_weight_rel_volume': 0.2,\n",
      " 'score_weight_rsi': 0.35,\n",
      " 'score_weight_volatility': 0.1}\n",
      "\n",
      "2025-05-14 15:54:35,994 - INFO - Successfully extracted weights for scheme: EW (10 tickers) for date 2025-05-13\n",
      "2025-05-14 15:54:35,997 - INFO - Successfully extracted weights for scheme: IV (10 tickers) for date 2025-05-13\n",
      "2025-05-14 15:54:35,999 - INFO - Successfully extracted weights for scheme: SW (10 tickers) for date 2025-05-13\n",
      "2025-05-14 15:54:36,000 - INFO - Successfully extracted 3 setup(s) for 2025-05-13.\n",
      "2025-05-14 15:54:36,003 - INFO - Running backtests for date: 2025-05-13\n",
      "2025-05-14 15:54:36,004 - INFO - \n",
      "===== Starting Batch Backtest Processing =====\n",
      "2025-05-14 15:54:36,005 - INFO - Prepared global price data copy for backtests.\n",
      "2025-05-14 15:54:36,005 - INFO - \n",
      "Processing date: 2025-05-13\n",
      "2025-05-14 15:54:36,005 - INFO - ------------------------------\n",
      "2025-05-14 15:54:36,005 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:36,005 - INFO -   Date          : 2025-05-13\n",
      "2025-05-14 15:54:36,005 - INFO -   Scheme        : EW\n",
      "2025-05-14 15:54:36,005 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:36,019 - ERROR -   Error: No trading date found after buy date 2025-05-14.\n",
      "2025-05-14 15:54:36,020 - INFO - ------------------------------\n",
      "2025-05-14 15:54:36,022 - INFO - ------------------------------\n",
      "2025-05-14 15:54:36,024 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:36,025 - INFO -   Date          : 2025-05-13\n",
      "2025-05-14 15:54:36,026 - INFO -   Scheme        : IV\n",
      "2025-05-14 15:54:36,027 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:36,030 - ERROR -   Error: No trading date found after buy date 2025-05-14.\n",
      "2025-05-14 15:54:36,033 - INFO - ------------------------------\n",
      "2025-05-14 15:54:36,035 - INFO - ------------------------------\n",
      "2025-05-14 15:54:36,035 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:36,035 - INFO -   Date          : 2025-05-13\n",
      "2025-05-14 15:54:36,035 - INFO -   Scheme        : SW\n",
      "2025-05-14 15:54:36,035 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:36,035 - ERROR -   Error: No trading date found after buy date 2025-05-14.\n",
      "2025-05-14 15:54:36,035 - INFO - ------------------------------\n",
      "2025-05-14 15:54:36,035 - INFO - \n",
      "===== Batch Backtest Processing Finished =====\n",
      "2025-05-14 15:54:36,035 - WARNING - Extracting params: Backtest result was None for 2025-05-13 / EW.\n",
      "2025-05-14 15:54:36,035 - WARNING - Extracting params: Backtest result was None for 2025-05-13 / IV.\n",
      "2025-05-14 15:54:36,052 - WARNING - Extracting params: Backtest result was None for 2025-05-13 / SW.\n",
      "2025-05-14 15:54:36,053 - INFO - Extracted 3 performance records for this pair.\n",
      "2025-05-14 15:54:36,056 - INFO - --- Finished processing pair for 2025-05-13. ---\n",
      "2025-05-14 15:54:36,057 - INFO - \n",
      "--- Processing Pair 14/14: Data='2025-05-14_my_selection_run_1.parquet', Params='2025-05-14_my_selection_run_1_params.json' ---\n",
      "2025-05-14 15:54:36,058 - INFO - Processing for extracted date: 2025-05-14\n",
      "2025-05-14 15:54:36,059 - INFO - Parameters loaded from 2025-05-14_my_selection_run_1_params.json:\n",
      "2025-05-14 15:54:36,059 - INFO - \n",
      "{'filter_max_debt_eq': 1.5,\n",
      " 'filter_min_avg_volume_m': 2.0,\n",
      " 'filter_min_price': 10.0,\n",
      " 'filter_min_roe_pct': 5.0,\n",
      " 'inv_vol_col_name': 'ATR/Price %',\n",
      " 'n_select_actual': 10,\n",
      " 'n_select_requested': 10,\n",
      " 'score_weight_change': 0.35,\n",
      " 'score_weight_rel_volume': 0.2,\n",
      " 'score_weight_rsi': 0.35,\n",
      " 'score_weight_volatility': 0.1}\n",
      "\n",
      "2025-05-14 15:54:36,076 - INFO - Successfully extracted weights for scheme: EW (10 tickers) for date 2025-05-14\n",
      "2025-05-14 15:54:36,076 - INFO - Successfully extracted weights for scheme: IV (10 tickers) for date 2025-05-14\n",
      "2025-05-14 15:54:36,076 - INFO - Successfully extracted weights for scheme: SW (10 tickers) for date 2025-05-14\n",
      "2025-05-14 15:54:36,076 - INFO - Successfully extracted 3 setup(s) for 2025-05-14.\n",
      "2025-05-14 15:54:36,086 - INFO - Running backtests for date: 2025-05-14\n",
      "2025-05-14 15:54:36,087 - INFO - \n",
      "===== Starting Batch Backtest Processing =====\n",
      "2025-05-14 15:54:36,090 - INFO - Prepared global price data copy for backtests.\n",
      "2025-05-14 15:54:36,092 - INFO - \n",
      "Processing date: 2025-05-14\n",
      "2025-05-14 15:54:36,093 - INFO - ------------------------------\n",
      "2025-05-14 15:54:36,094 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:36,095 - INFO -   Date          : 2025-05-14\n",
      "2025-05-14 15:54:36,097 - INFO -   Scheme        : EW\n",
      "2025-05-14 15:54:36,097 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:36,100 - ERROR -   Error: No trading date found after selection date index 321 (2025-05-14).\n",
      "2025-05-14 15:54:36,102 - INFO - ------------------------------\n",
      "2025-05-14 15:54:36,105 - INFO - ------------------------------\n",
      "2025-05-14 15:54:36,105 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:36,105 - INFO -   Date          : 2025-05-14\n",
      "2025-05-14 15:54:36,105 - INFO -   Scheme        : IV\n",
      "2025-05-14 15:54:36,105 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:36,105 - ERROR -   Error: No trading date found after selection date index 321 (2025-05-14).\n",
      "2025-05-14 15:54:36,105 - INFO - ------------------------------\n",
      "2025-05-14 15:54:36,118 - INFO - ------------------------------\n",
      "2025-05-14 15:54:36,119 - INFO - Initiating Backtest Run...\n",
      "2025-05-14 15:54:36,120 - INFO -   Date          : 2025-05-14\n",
      "2025-05-14 15:54:36,121 - INFO -   Scheme        : SW\n",
      "2025-05-14 15:54:36,139 - INFO -   Num Tickers   : 10\n",
      "2025-05-14 15:54:36,144 - ERROR -   Error: No trading date found after selection date index 321 (2025-05-14).\n",
      "2025-05-14 15:54:36,156 - INFO - ------------------------------\n",
      "2025-05-14 15:54:36,158 - INFO - \n",
      "===== Batch Backtest Processing Finished =====\n",
      "2025-05-14 15:54:36,159 - WARNING - Extracting params: Backtest result was None for 2025-05-14 / EW.\n",
      "2025-05-14 15:54:36,159 - WARNING - Extracting params: Backtest result was None for 2025-05-14 / IV.\n",
      "2025-05-14 15:54:36,159 - WARNING - Extracting params: Backtest result was None for 2025-05-14 / SW.\n",
      "2025-05-14 15:54:36,159 - INFO - Extracted 3 performance records for this pair.\n",
      "2025-05-14 15:54:36,159 - INFO - --- Finished processing pair for 2025-05-14. ---\n",
      "2025-05-14 15:54:36,159 - INFO - --- File processing loop finished. ---\n",
      "2025-05-14 15:54:36,159 - INFO - \n",
      "--- Attempting to Save/Update 42 Performance Records to CSV ---\n",
      "2025-05-14 15:54:36,229 - INFO - Processed 42 new records. CSV 'output/backtest_results\\backtest_parameter_performance.csv' now contains 42 records (net change: +3).\n",
      "2025-05-14 15:54:36,230 - INFO - \n",
      "--- Processing All Performance Records for DataFrame Store (e.g., Parquet) ---\n",
      "2025-05-14 15:54:36,251 - INFO - Loaded existing results DataFrame from output/backtest_results\\df_backtest_parameter_performance.parquet (39 records).\n",
      "2025-05-14 15:54:36,251 - INFO - DataFrame Update: Started with 39 existing records, processed 42 new records. Resulting DataFrame has 42 records after consolidation and deduplication.\n",
      "2025-05-14 15:54:36,296 - INFO - Final results DataFrame successfully saved to output/backtest_results\\df_backtest_parameter_performance.parquet (42 records).\n",
      "2025-05-14 15:54:36,304 - INFO - === Script Execution Finished (with errors if reported above) ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Script Execution Finished (with errors if reported above) ===\n",
      "Logging shutdown complete.\n"
     ]
    }
   ],
   "source": [
    "# --- Main Execution Block (Updated with process_single_pair) ---\n",
    "\n",
    "log_filepath = None\n",
    "run_timestamp = None\n",
    "df_adj_close = None\n",
    "all_performance_records = []\n",
    "file_pairs = []\n",
    "\n",
    "try:\n",
    "    log_filepath, run_timestamp = setup_script_logging()\n",
    "\n",
    "    # --- Step 1: Load and Prepare Price Data ---\n",
    "    df_adj_close = load_and_prepare_price_data(ADJ_CLOSE_PATH)\n",
    "\n",
    "    # --- Step 2: Discover and Map Input Files ---\n",
    "    # Use 'output' directory for demonstration consistency\n",
    "    selection_files, param_files, param_map, extracted_dates_params = find_and_map_param_files(OUTPUT_DIR)\n",
    "\n",
    "    # --- Step 3: Pair Selection Files with Parameter Files ---\n",
    "    file_pairs = pair_data_and_param_files(\n",
    "        selection_files=selection_files,\n",
    "        param_files=param_files,\n",
    "        param_map=param_map,\n",
    "        extracted_dates_params=extracted_dates_params,\n",
    "        utils_module=utils\n",
    "    )\n",
    "\n",
    "    # --- Step 4: Check if pairs were found and log before proceeding to loop ---\n",
    "    if not file_pairs:\n",
    "        logging.warning(\"No file pairs found to process. Skipping backtest loop.\")\n",
    "    else:\n",
    "        logging.info(f\"Starting processing for {len(file_pairs)} file pairs...\")\n",
    "\n",
    "        # --- Step 5: Process Paired Files (Loop calls process_single_pair) ---\n",
    "        processed_pair_count = 0\n",
    "        for data_file, param_file_name in file_pairs:\n",
    "            processed_pair_count += 1\n",
    "\n",
    "            # Log the start of processing for this specific pair (kept in the loop for context)\n",
    "            logging.info(f\"\\n--- Processing Pair {processed_pair_count}/{len(file_pairs)}: Data='{data_file}', Params='{param_file_name}' ---\")\n",
    "\n",
    "            # Call the function to process this single pair\n",
    "            # Pass necessary data and function references\n",
    "            pair_records = process_single_pair(\n",
    "                data_file=data_file,\n",
    "                param_file_name=param_file_name,\n",
    "                output_dir=OUTPUT_DIR, # Directory where the pair files live\n",
    "                df_adj_close=df_adj_close, # Pass the main price data\n",
    "                run_timestamp=run_timestamp, # Pass run metadata\n",
    "                log_filepath=log_filepath,\n",
    "                utils_module=utils, # Pass utilities module\n",
    "                extract_backtest_setups_func=extract_backtest_setups, # Pass function references\n",
    "                process_all_backtests_func=process_all_backtests,\n",
    "                extract_params_and_results_func=extract_params_and_results\n",
    "            )\n",
    "\n",
    "            # Extend the main results list with the records returned by the function\n",
    "            # This handles cases where the function returned [] due to an error/skip\n",
    "            all_performance_records.extend(pair_records)\n",
    "\n",
    "        logging.info(\"--- File processing loop finished. ---\")\n",
    "\n",
    "    # --- Step 6: Save Accumulated Results ---\n",
    "\n",
    "    # --- CSV Handling (primarily for new records from this run) ---\n",
    "    if all_performance_records:\n",
    "        logging.info(f\"\\n--- Attempting to Save/Update {len(all_performance_records)} Performance Records to CSV ---\")\n",
    "        write_results_to_csv(all_performance_records, RESULTS_CSV_PATH) # This updates/overwrites CSV based on its own logic\n",
    "    else:\n",
    "        logging.info(\"\\n--- No new performance records from this run to add to CSV. ---\")\n",
    "\n",
    "    # --- DataFrame Store Handling (e.g., Parquet) ---\n",
    "    logging.info(f\"\\n--- Processing All Performance Records for DataFrame Store (e.g., Parquet) ---\")\n",
    "    \n",
    "    # Load existing DataFrame from Parquet, if any\n",
    "    current_results_df = None\n",
    "    if os.path.exists(RESULTS_DF_PATH):\n",
    "        try:\n",
    "            current_results_df = pd.read_parquet(RESULTS_DF_PATH)\n",
    "            logging.info(f\"Loaded existing results DataFrame from {RESULTS_DF_PATH} ({len(current_results_df)} records).\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error loading existing results DataFrame from {RESULTS_DF_PATH}: {e}. Will proceed as if creating a new DataFrame.\", exc_info=True)\n",
    "            current_results_df = None # Reset if loading fails\n",
    "\n",
    "    # Consolidate new records with the existing DataFrame content\n",
    "    # The new_records argument will be all_performance_records from the current run.\n",
    "    # The existing_df argument will be current_results_df loaded from Parquet.\n",
    "    final_results_df = update_or_create_dataframe_with_records(\n",
    "        new_records=all_performance_records, # Records from the current run\n",
    "        existing_df=current_results_df      # DataFrame loaded from storage (or None)\n",
    "        # Using default column_order=CSV_COLUMN_ORDER and unique_key_columns=UNIQUE_KEY_COLUMNS_FOR_CSV\n",
    "    )\n",
    "\n",
    "    # Save the final consolidated DataFrame to Parquet\n",
    "    # This overwrites the Parquet file with the complete, updated dataset.\n",
    "    if final_results_df is not None and not final_results_df.empty:\n",
    "        try:\n",
    "            # Ensure the directory exists (LOG_DIR should already be created by setup_logging)\n",
    "            os.makedirs(os.path.dirname(RESULTS_DF_PATH), exist_ok=True)\n",
    "            final_results_df.to_parquet(RESULTS_DF_PATH, index=False)\n",
    "            logging.info(f\"Final results DataFrame successfully saved to {RESULTS_DF_PATH} ({len(final_results_df)} records).\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error saving final results DataFrame to {RESULTS_DF_PATH}: {e}\", exc_info=True)\n",
    "    elif final_results_df is not None and final_results_df.empty:\n",
    "        logging.info(\"Final results DataFrame is empty. Not saving to Parquet. If an old Parquet file exists, it may remain or you might want to delete it.\")\n",
    "        # Optional: Delete the parquet file if the result is empty to signify no data\n",
    "        # if os.path.exists(RESULTS_DF_PATH):\n",
    "        #     os.remove(RESULTS_DF_PATH)\n",
    "        #     logging.info(f\"Removed empty Parquet file: {RESULTS_DF_PATH}\")\n",
    "    else: # Should ideally not happen if the function guarantees a DataFrame return\n",
    "        logging.error(\"The function to update/create DataFrame returned None. This is unexpected. Parquet file not saved.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"FATAL ERROR: Required file or directory not found: {e}\")\n",
    "    if log_filepath and logging.getLogger().hasHandlers():\n",
    "          logging.critical(f\"FATAL FileNotFoundError: {e}\", exc_info=True)\n",
    "    else:\n",
    "          print(f\"Logging not initialized. Error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"FATAL ERROR in main execution block: {e}\")\n",
    "    if log_filepath and logging.getLogger().hasHandlers():\n",
    "          logging.critical(f\"CRITICAL ERROR in main execution block: {e}\", exc_info=True)\n",
    "    else:\n",
    "          print(f\"Logging not initialized. Error: {e}\")\n",
    "          traceback.print_exc()\n",
    "finally:\n",
    "    final_message = \"=== Script Execution Finished (with errors if reported above) ===\"\n",
    "    print(final_message)\n",
    "    if log_filepath and logging.getLogger().hasHandlers():\n",
    "          logging.info(final_message)\n",
    "          logging.shutdown()\n",
    "          print(\"Logging shutdown complete.\")\n",
    "    else:\n",
    "          print(\"Logging was not fully initialized or already shut down.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
