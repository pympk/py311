{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidate Yloader OHLCV Data\n",
    "\n",
    "This notebook reads all individual ticker `.csv` files generated by the `Yloader` application, combines them into a single, analysis-ready DataFrame, and saves it in the efficient Parquet format.\n",
    "\n",
    "**Workflow:**\n",
    "\n",
    "1.  **Prerequisite:** Run `Yloader` to download OHLCV data. This should create multiple `.csv` files (e.g., `AAPL.csv`, `GOOG.csv`) in a dedicated directory.\n",
    "2.  **Process & Combine:** The notebook scans the source directory, reads each CSV, and consolidates them into a single pandas DataFrame with a `(Ticker, Date)` MultiIndex.\n",
    "3.  **Save:** The final DataFrame is saved as a single `.parquet` file for fast loading in subsequent analysis notebooks.\n",
    "4.  **Verify:** The saved Parquet file is read back to confirm its integrity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and Configuration\n",
    "\n",
    "**This is the only cell you need to modify.** Adjust the paths and column definitions below to match your project structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Root Directory set to: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\n",
      "Reading Yloader CSVs from: C:\\Users\\ping\\Desktop\\yloader\n",
      "Output will be saved to: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "# 1. Set the directory where your Yloader CSV files are located.\n",
    "#    This uses Path.home() to be portable across different computers and OS.\n",
    "YLOADER_DATA_DIR = Path.home() / \"Desktop\" / \"yloader\"\n",
    "\n",
    "# 2. Define the destination path for the final combined Parquet file.\n",
    "#    It's good practice to save data outputs within the project's data folder.\n",
    "#    Assuming a project structure where this notebook is in a `notebooks` subdir.\n",
    "# ROOT_DIR = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "# DESTINATION_PARQUET_PATH = ROOT_DIR / \"data\" / \"df_OHLCV_stocks_etfs.parquet\"\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "ROOT_DIR = NOTEBOOK_DIR.parent \n",
    "SRC_DIR = ROOT_DIR / 'src'\n",
    "if str(ROOT_DIR) not in sys.path: sys.path.append(str(ROOT_DIR))\n",
    "if str(SRC_DIR) not in sys.path: sys.path.append(str(SRC_DIR))\n",
    "DESTINATION_PARQUET_PATH = ROOT_DIR / \"data\" / \"df_OHLCV_stocks_etfs.parquet\"\n",
    "\n",
    "# 3. Define the column names for the CSV files.\n",
    "#    Assumes CSVs have no header and columns are in this fixed order.\n",
    "#    The first column is always assumed to be 'Date'.\n",
    "CANONICAL_COLUMN_NAMES = ['Adj Open', 'Adj High', 'Adj Low', 'Adj Close', 'Volume']\n",
    "\n",
    "# --- Verification ---\n",
    "print(f\"Project Root Directory set to: {ROOT_DIR}\")\n",
    "print(f\"Reading Yloader CSVs from: {YLOADER_DATA_DIR}\")\n",
    "print(f\"Output will be saved to: {DESTINATION_PARQUET_PATH}\")\n",
    "\n",
    "# Set pandas display options for better readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Process and Combine CSV Data\n",
    "\n",
    "This cell defines and executes the core logic to read all individual CSV files and merge them into a single, multi-indexed DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1590 CSV files to process...\n",
      "\n",
      "CSV processing complete. DataFrame created successfully.\n",
      "\n",
      "--- DataFrame Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 998303 entries, ('A', Timestamp('2025-07-25 00:00:00')) to ('ZWS', Timestamp('2023-01-03 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   Adj Open   998303 non-null  float64\n",
      " 1   Adj High   998303 non-null  float64\n",
      " 2   Adj Low    998303 non-null  float64\n",
      " 3   Adj Close  998303 non-null  float64\n",
      " 4   Volume     998303 non-null  int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 41.9+ MB\n",
      "\n",
      "--- First 5 Rows of Combined DataFrame ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Adj Open</th>\n",
       "      <th>Adj High</th>\n",
       "      <th>Adj Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">A</th>\n",
       "      <th>2025-07-25</th>\n",
       "      <td>120.50</td>\n",
       "      <td>121.01</td>\n",
       "      <td>119.02</td>\n",
       "      <td>120.18</td>\n",
       "      <td>1972700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-24</th>\n",
       "      <td>119.43</td>\n",
       "      <td>122.75</td>\n",
       "      <td>119.43</td>\n",
       "      <td>120.35</td>\n",
       "      <td>1602800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-23</th>\n",
       "      <td>119.38</td>\n",
       "      <td>120.79</td>\n",
       "      <td>117.48</td>\n",
       "      <td>119.47</td>\n",
       "      <td>1939700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-22</th>\n",
       "      <td>112.85</td>\n",
       "      <td>117.05</td>\n",
       "      <td>112.14</td>\n",
       "      <td>116.19</td>\n",
       "      <td>1692000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-21</th>\n",
       "      <td>113.23</td>\n",
       "      <td>113.66</td>\n",
       "      <td>110.75</td>\n",
       "      <td>112.04</td>\n",
       "      <td>2060800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Adj Open  Adj High  Adj Low  Adj Close   Volume\n",
       "Ticker Date                                                       \n",
       "A      2025-07-25    120.50    121.01   119.02     120.18  1972700\n",
       "       2025-07-24    119.43    122.75   119.43     120.35  1602800\n",
       "       2025-07-23    119.38    120.79   117.48     119.47  1939700\n",
       "       2025-07-22    112.85    117.05   112.14     116.19  1692000\n",
       "       2025-07-21    113.23    113.66   110.75     112.04  2060800"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def process_yloader_csvs(\n",
    "    data_dir: Path,\n",
    "    canonical_cols: List[str]\n",
    ") -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Reads and combines all CSV files from the Yloader output directory.\n",
    "\n",
    "    Args:\n",
    "        data_dir (Path): Path object pointing to the directory with CSV files.\n",
    "        canonical_cols (List[str]): Expected data column names, excluding 'Date'.\n",
    "\n",
    "    Returns:\n",
    "        Optional[pd.DataFrame]: A sorted, multi-indexed DataFrame, or None if no\n",
    "                                data could be processed.\n",
    "    \"\"\"\n",
    "    if not data_dir.is_dir():\n",
    "        print(f\"Error: Directory not found: {data_dir}\")\n",
    "        return None\n",
    "\n",
    "    csv_files = list(data_dir.glob('*.csv'))\n",
    "    if not csv_files:\n",
    "        print(f\"No CSV files found in directory: {data_dir}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Found {len(csv_files)} CSV files to process...\")\n",
    "    all_dataframes = []\n",
    "    tickers_list = []\n",
    "    \n",
    "    # The full list of column names, including the 'Date' index column\n",
    "    expected_csv_cols = ['Date'] + canonical_cols\n",
    "\n",
    "    for file_path in csv_files:\n",
    "        # Use pathlib's `.stem` to get the filename without the extension (e.g., \"AAPL.csv\" -> \"AAPL\")\n",
    "        ticker = file_path.stem\n",
    "        try:\n",
    "            df_temp = pd.read_csv(\n",
    "                file_path,\n",
    "                header=None,\n",
    "                names=expected_csv_cols,\n",
    "                parse_dates=['Date'],\n",
    "                index_col='Date'\n",
    "            )\n",
    "            \n",
    "            if df_temp.empty:\n",
    "                print(f\"Warning: File {file_path.name} is empty. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            all_dataframes.append(df_temp)\n",
    "            tickers_list.append(ticker)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing {file_path.name}: {e}. Skipping.\")\n",
    "\n",
    "    if not all_dataframes:\n",
    "        print(\"No data was successfully loaded. Aborting.\")\n",
    "        return None\n",
    "\n",
    "    # Concatenate all DataFrames with a 'Ticker' key in the new index\n",
    "    multi_index_df = pd.concat(all_dataframes, keys=tickers_list, names=['Ticker', 'Date'])\n",
    "    \n",
    "    # Sort by Ticker (A-Z), then by Date (newest first)\n",
    "    multi_index_df.sort_index(level=['Ticker', 'Date'], ascending=[True, False], inplace=True)\n",
    "    \n",
    "    print(\"\\nCSV processing complete. DataFrame created successfully.\")\n",
    "    return multi_index_df\n",
    "\n",
    "# --- Execute Step 1 ---\n",
    "final_df = process_yloader_csvs(YLOADER_DATA_DIR, CANONICAL_COLUMN_NAMES)\n",
    "\n",
    "if final_df is not None:\n",
    "    print(\"\\n--- DataFrame Info ---\")\n",
    "    final_df.info()\n",
    "    \n",
    "    print(\"\\n--- First 5 Rows of Combined DataFrame ---\")\n",
    "    display(final_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Save DataFrame to Parquet File\n",
    "\n",
    "This step saves the combined DataFrame to a Parquet file, which is highly efficient for storage and subsequent loading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved DataFrame to: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet\n"
     ]
    }
   ],
   "source": [
    "def save_dataframe_to_parquet(df: Optional[pd.DataFrame], dest_path: Path):\n",
    "    \"\"\"\n",
    "    Saves a DataFrame to a Parquet file if it's not empty.\n",
    "\n",
    "    Args:\n",
    "        df (Optional[pd.DataFrame]): The DataFrame to save.\n",
    "        dest_path (Path): The destination file path.\n",
    "    \"\"\"\n",
    "    if df is None or df.empty:\n",
    "        print(\"DataFrame is empty or None. Nothing to save.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Ensure the destination directory exists\n",
    "        dest_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Save the file using the efficient 'pyarrow' engine and 'zstd' compression\n",
    "        df.to_parquet(dest_path, engine='pyarrow', compression='zstd', index=True)\n",
    "        print(f\"\\nSuccessfully saved DataFrame to: {dest_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError: Failed to save Parquet file. Details: {e}\")\n",
    "\n",
    "# --- Execute Step 2 ---\n",
    "save_dataframe_to_parquet(final_df, DESTINATION_PARQUET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Verify the Saved File (Optional)\n",
    "\n",
    "This final step reads the Parquet file back into a new DataFrame to ensure the data was saved correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Verifying the saved file at: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet ---\n",
      "Verification successful! File read back into memory.\n",
      "\n",
      "--- First 5 Rows of Verified DataFrame ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Adj Open</th>\n",
       "      <th>Adj High</th>\n",
       "      <th>Adj Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">A</th>\n",
       "      <th>2025-07-25</th>\n",
       "      <td>120.50</td>\n",
       "      <td>121.01</td>\n",
       "      <td>119.02</td>\n",
       "      <td>120.18</td>\n",
       "      <td>1972700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-24</th>\n",
       "      <td>119.43</td>\n",
       "      <td>122.75</td>\n",
       "      <td>119.43</td>\n",
       "      <td>120.35</td>\n",
       "      <td>1602800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-23</th>\n",
       "      <td>119.38</td>\n",
       "      <td>120.79</td>\n",
       "      <td>117.48</td>\n",
       "      <td>119.47</td>\n",
       "      <td>1939700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-22</th>\n",
       "      <td>112.85</td>\n",
       "      <td>117.05</td>\n",
       "      <td>112.14</td>\n",
       "      <td>116.19</td>\n",
       "      <td>1692000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-21</th>\n",
       "      <td>113.23</td>\n",
       "      <td>113.66</td>\n",
       "      <td>110.75</td>\n",
       "      <td>112.04</td>\n",
       "      <td>2060800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Adj Open  Adj High  Adj Low  Adj Close   Volume\n",
       "Ticker Date                                                       \n",
       "A      2025-07-25    120.50    121.01   119.02     120.18  1972700\n",
       "       2025-07-24    119.43    122.75   119.43     120.35  1602800\n",
       "       2025-07-23    119.38    120.79   117.48     119.47  1939700\n",
       "       2025-07-22    112.85    117.05   112.14     116.19  1692000\n",
       "       2025-07-21    113.23    113.66   110.75     112.04  2060800"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data for first available ticker 'A' ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Open</th>\n",
       "      <th>Adj High</th>\n",
       "      <th>Adj Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-07-25</th>\n",
       "      <td>120.50</td>\n",
       "      <td>121.01</td>\n",
       "      <td>119.02</td>\n",
       "      <td>120.18</td>\n",
       "      <td>1972700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-24</th>\n",
       "      <td>119.43</td>\n",
       "      <td>122.75</td>\n",
       "      <td>119.43</td>\n",
       "      <td>120.35</td>\n",
       "      <td>1602800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-23</th>\n",
       "      <td>119.38</td>\n",
       "      <td>120.79</td>\n",
       "      <td>117.48</td>\n",
       "      <td>119.47</td>\n",
       "      <td>1939700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-22</th>\n",
       "      <td>112.85</td>\n",
       "      <td>117.05</td>\n",
       "      <td>112.14</td>\n",
       "      <td>116.19</td>\n",
       "      <td>1692000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-21</th>\n",
       "      <td>113.23</td>\n",
       "      <td>113.66</td>\n",
       "      <td>110.75</td>\n",
       "      <td>112.04</td>\n",
       "      <td>2060800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Adj Open  Adj High  Adj Low  Adj Close   Volume\n",
       "Date                                                       \n",
       "2025-07-25    120.50    121.01   119.02     120.18  1972700\n",
       "2025-07-24    119.43    122.75   119.43     120.35  1602800\n",
       "2025-07-23    119.38    120.79   117.48     119.47  1939700\n",
       "2025-07-22    112.85    117.05   112.14     116.19  1692000\n",
       "2025-07-21    113.23    113.66   110.75     112.04  2060800"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"--- Verifying the saved file at: {DESTINATION_PARQUET_PATH} ---\")\n",
    "\n",
    "try:\n",
    "    if DESTINATION_PARQUET_PATH.exists():\n",
    "        verified_df = pd.read_parquet(DESTINATION_PARQUET_PATH)\n",
    "        print(\"Verification successful! File read back into memory.\")\n",
    "        \n",
    "        print(\"\\n--- First 5 Rows of Verified DataFrame ---\")\n",
    "        display(verified_df.head())\n",
    "        \n",
    "        # Optional: Check a specific ticker\n",
    "        if not verified_df.empty:\n",
    "            example_ticker = verified_df.index.get_level_values('Ticker')[0]\n",
    "            print(f\"\\n--- Data for first available ticker '{example_ticker}' ---\")\n",
    "            display(verified_df.loc[example_ticker].head())\n",
    "\n",
    "    else:\n",
    "        print(\"Error: The output file was not found at the specified path.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during verification: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-py3.11 (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
