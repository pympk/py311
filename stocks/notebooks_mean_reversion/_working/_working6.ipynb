{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# from pathlib import Path\n",
    "# import pandas as pd\n",
    "# import os\n",
    "# from IPython.display import display, Markdown  # Assuming you use these for display\n",
    "\n",
    "# # --- 1. PANDAS OPTIONS (No change) ---\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.width', 1500)\n",
    "\n",
    "# # --- 2. IPYTHON AUTORELOAD (No change) ---\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# # --- 3. ROBUST PATH CONFIGURATION (MODIFIED) ---\n",
    "\n",
    "# # Get the current working directory of the notebook\n",
    "# NOTEBOOK_DIR = Path.cwd()\n",
    "\n",
    "# # Find the project ROOT directory by going up from the notebook's location\n",
    "# # This is robust and works even if you move the notebook deeper.\n",
    "# ROOT_DIR = NOTEBOOK_DIR.parent.parent\n",
    "\n",
    "# # You could also define an output directory here if needed\n",
    "# OUTPUT_DIR = ROOT_DIR / 'output'\n",
    "# DATA_DIR = ROOT_DIR / 'data'\n",
    "\n",
    "# # Define key project directories relative to the ROOT\n",
    "# SELECTION_RESULTS = OUTPUT_DIR  / 'selection_results'\n",
    "# BACKTEST_RESULTS = OUTPUT_DIR / 'backtest_results'\n",
    "# SRC_DIR = ROOT_DIR / 'src'\n",
    "\n",
    "\n",
    "# # Add the 'src' directory to the Python path so you can import 'utils'\n",
    "# if str(SRC_DIR) not in sys.path:\n",
    "#     sys.path.append(str(SRC_DIR))\n",
    "\n",
    "# # --- 4. VERIFICATION (IMPROVED) ---\n",
    "# print(f\"✅ Project Root Directory: {ROOT_DIR}\")\n",
    "# print(f\"✅ Source Directory (for utils): {SRC_DIR}\")\n",
    "# print(f\"✅ Selection Results Directory (for input): {SELECTION_RESULTS}\")\n",
    "\n",
    "# # Verify that the key directories exist. This helps catch path errors early.\n",
    "# assert ROOT_DIR.exists(), f\"ROOT directory not found at: {ROOT_DIR}\"\n",
    "# assert SRC_DIR.exists(), f\"Source directory not found at: {SRC_DIR}\"\n",
    "# assert SELECTION_RESULTS.exists(), f\"Data directory not found at: {SELECTION_RESULTS}\"\n",
    "\n",
    "# # --- 5. IMPORT YOUR CUSTOM MODULE ---\n",
    "# # This will now work correctly\n",
    "# import utils\n",
    "# from config import DATE_STR\n",
    "\n",
    "# print(\"\\n✅ Successfully imported 'utils' module and DATE_STR.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Current Script Directory: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\\_working\n",
      "✅ Directory containing config.py (added to path): c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks\n",
      "\n",
      "✅ Successfully imported DATE_STR from config.py.\n",
      "✅ The value of DATE_STR is: '2025-06-10'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# --- 1. PANDAS OPTIONS (No change) ---\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1500)\n",
    "\n",
    "# --- 2. IPYTHON AUTORELOAD (No change, assuming you're in a notebook) ---\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# --- 3. ROBUST PATH CONFIGURATION (FIXED FOR YOUR STRUCTURE) ---\n",
    "\n",
    "# Get the directory where your script is currently running\n",
    "CURRENT_DIR = Path.cwd()  # This will be '.../notebooks/_working'\n",
    "\n",
    "# The directory containing 'config.py' is the parent of the current directory\n",
    "CONFIG_DIR = CURRENT_DIR.parent # This will be '.../notebooks'\n",
    "\n",
    "# Add the directory containing config.py to the Python path\n",
    "# so that the import statement `from config import ...` can find it.\n",
    "if str(CONFIG_DIR) not in sys.path:\n",
    "    sys.path.append(str(CONFIG_DIR))\n",
    "\n",
    "# --- 4. VERIFICATION ---\n",
    "print(f\"✅ Current Script Directory: {CURRENT_DIR}\")\n",
    "print(f\"✅ Directory containing config.py (added to path): {CONFIG_DIR}\")\n",
    "\n",
    "# Assert that the config file we want to import actually exists in that location.\n",
    "# This gives a much clearer error if the path is wrong.\n",
    "config_file_path = CONFIG_DIR / 'config.py'\n",
    "assert config_file_path.exists(), f\"Error: config.py not found at {config_file_path}\"\n",
    "\n",
    "\n",
    "# --- 5. IMPORT YOUR CUSTOM MODULE ---\n",
    "# This will now work correctly because its parent directory ('.../notebooks/') is on the path.\n",
    "from config import DATE_STR\n",
    "# Note: The import for 'utils' is removed as its location is not specified\n",
    "# and the old SRC_DIR path is no longer valid for this structure.\n",
    "# import utils\n",
    "\n",
    "print(\"\\n✅ Successfully imported DATE_STR from config.py.\")\n",
    "print(f\"✅ The value of DATE_STR is: '{DATE_STR}'\")\n",
    "\n",
    "\n",
    "# --- The following paths are commented out as they are based on a\n",
    "# --- 'standard project structure' you plan to adopt later.\n",
    "\n",
    "ROOT_DIR = CURRENT_DIR.parent.parent # This would point to the folder containing 'notebooks'\n",
    "OUTPUT_DIR = ROOT_DIR / 'output'\n",
    "DATA_DIR = ROOT_DIR / 'data'\n",
    "SRC_DIR = ROOT_DIR / 'src'\n",
    "SELECTION_RESULTS = OUTPUT_DIR  / 'selection_results'\n",
    "BACKTEST_RESULTS = OUTPUT_DIR / 'backtest_results'\n",
    "# SRC_DIR = ROOT_DIR / 'src'\n",
    "# ... and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. 2025-06-10_short_term_mean_reversion.csv\n",
      "1. 2025-06-10_short_term_mean_reversion.parquet\n",
      "2. 2025-06-10_short_term_mean_reversion_params.json\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all .parquet files in the directory\n",
    "# Using .glob('*.parquet') is a safe way to get only the files you want\n",
    "# Gets all files ending with .parquet that also contain 'df_finviz'\n",
    "_file_list = [f.name for f in SELECTION_RESULTS.glob(f\"*{DATE_STR}*\")]\n",
    "for i, _file in enumerate(_file_list):\n",
    "    print(f\"{i}. {_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_selections:\n",
      "          RSI  Change %  ATR/Price %  Avg Volume, M  Rel Volume  Debt/Eq  ROE %   Price     z_RSI  z_Change%  z_RelVolume  z_ATR/Price%  final_score  Weight_EW  Weight_IV  Weight_SW\n",
      "Ticker                                                                                                                                                                               \n",
      "DOCU    38.68     -1.96     4.945483           2.95        1.67     0.07  70.20   77.04 -1.959106  -1.490627     3.400199      2.190313     1.668415        0.1   0.063237   0.116645\n",
      "BF-B    24.48      0.40     4.285200           3.43        1.51     0.68  23.14   27.77 -3.415263  -0.108550     2.825392      1.528253     1.645588        0.1   0.072981   0.115049\n",
      "CPRT    22.82      0.26     2.466189           5.84        1.08     0.01  18.54   50.28 -3.585489  -0.190538     1.280600     -0.295652     1.607295        0.1   0.126810   0.112372\n",
      "SE      50.45     -4.68     3.576210           5.09        1.05     0.46  11.13  156.87 -0.752137  -3.083529     1.172824      0.817355     1.495312        0.1   0.087450   0.104543\n",
      "GE      59.88     -3.74     2.293388           6.14        1.52     1.08  28.09  242.00  0.214874  -2.533041     2.861318     -0.468918     1.430514        0.1   0.136365   0.100013\n",
      "PGR     35.67     -2.15     2.467136           3.29        0.77     0.24  34.34  265.49 -2.267770  -1.601896     0.166913     -0.294702     1.417236        0.1   0.126762   0.099084\n",
      "CART    44.55     -3.79     3.282028           4.22        0.75     0.01  12.96   44.18 -1.357160  -2.562322     0.095062      0.522382     1.338593        0.1   0.095288   0.093586\n",
      "LULU    31.90     -0.21     5.059961           2.74        1.32     0.40  42.49  258.50 -2.654369  -0.465782     2.142810      2.305099     1.290105        0.1   0.061806   0.090196\n",
      "LTH     40.07     -0.93     4.067675           2.28        1.31     1.47   8.24   27.78 -1.816567  -0.887432     2.106884      1.310143     1.236762        0.1   0.076884   0.086467\n",
      "CME     36.54     -0.84     2.051860           2.67        0.79     0.14  13.40  266.10 -2.178555  -0.834726     0.238764     -0.711096     1.173511        0.1   0.152417   0.082045\n"
     ]
    }
   ],
   "source": [
    "df_selections = pd.read_parquet(SELECTION_RESULTS / _file_list[1])\n",
    "print(f'df_selections:\\n{df_selections}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10 entries, DOCU to CME\n",
      "Data columns (total 16 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   RSI            10 non-null     float64\n",
      " 1   Change %       10 non-null     float64\n",
      " 2   ATR/Price %    10 non-null     float64\n",
      " 3   Avg Volume, M  10 non-null     float64\n",
      " 4   Rel Volume     10 non-null     float64\n",
      " 5   Debt/Eq        10 non-null     float64\n",
      " 6   ROE %          10 non-null     float64\n",
      " 7   Price          10 non-null     float64\n",
      " 8   z_RSI          10 non-null     float64\n",
      " 9   z_Change%      10 non-null     float64\n",
      " 10  z_RelVolume    10 non-null     float64\n",
      " 11  z_ATR/Price%   10 non-null     float64\n",
      " 12  final_score    10 non-null     float64\n",
      " 13  Weight_EW      10 non-null     float64\n",
      " 14  Weight_IV      10 non-null     float64\n",
      " 15  Weight_SW      10 non-null     float64\n",
      "dtypes: float64(16)\n",
      "memory usage: 1.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_selections.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DOCU', 'BF-B', 'CPRT', 'SE', 'GE', 'PGR', 'CART', 'LULU', 'LTH', 'CME']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers = df_selections.index.to_list()\n",
    "tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. df_adj_close.parquet\n"
     ]
    }
   ],
   "source": [
    "_file_list = [f.name for f in DATA_DIR.glob('*adj*.parquet')]\n",
    "for i, _file in enumerate(_file_list):\n",
    "    print(f\"{i}. {_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_adj:\n",
      "Ticker       DOCU   BF-B   CPRT      SE      GE     PGR   CART    LULU    LTH     CME\n",
      "Date                                                                                 \n",
      "2025-06-10  77.04  27.77  50.28  156.87  242.00  265.49  44.18  258.50  27.78  266.10\n",
      "2025-06-11  76.24  27.50  50.50  154.44  245.52  263.22  44.17  252.28  27.49  269.65\n",
      "2025-06-12  76.01  27.29  49.99  154.63  239.99  268.42  44.08  247.03  28.15  270.96\n",
      "2025-06-13  74.06  26.44  48.59  154.38  236.60  267.85  43.37  239.11  27.14  269.50\n"
     ]
    }
   ],
   "source": [
    "df_adj = pd.read_parquet(DATA_DIR / _file_list[0])\n",
    "start_index_pos = df_adj.index.get_loc(DATE_STR)\n",
    "end_index_pos = start_index_pos + 6\n",
    "df_adj = df_adj.iloc[start_index_pos:end_index_pos]\n",
    "df_adj = df_adj.loc[:, tickers]\n",
    "print(f\"df_adj:\\n{_df_adj}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 4 entries, 2025-06-10 to 2025-06-13\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   DOCU    4 non-null      float64\n",
      " 1   BF-B    4 non-null      float64\n",
      " 2   CPRT    4 non-null      float64\n",
      " 3   SE      4 non-null      float64\n",
      " 4   GE      4 non-null      float64\n",
      " 5   PGR     4 non-null      float64\n",
      " 6   CART    4 non-null      float64\n",
      " 7   LULU    4 non-null      float64\n",
      " 8   LTH     4 non-null      float64\n",
      " 9   CME     4 non-null      float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 352.0 bytes\n"
     ]
    }
   ],
   "source": [
    "df_adj.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sample df_selections (weights normalized) ---\n",
      "      Weight_EW  Weight_IV  Weight_SW\n",
      "DOCU   0.184034   0.018893   0.135726\n",
      "BF-B   0.110222   0.137112   0.138466\n",
      "CPRT   0.023160   0.127488   0.110389\n",
      "SE     0.028547   0.061405   0.085478\n",
      "GE     0.162411   0.030382   0.114673\n",
      "\n",
      "--- Sample df_adj (prices) ---\n",
      "                 DOCU        BF-B       CPRT          SE         GE         PGR        CART        LULU         LTH         CME\n",
      "2025-06-10  99.858234  100.451057  99.993610  101.420205  98.681946  101.215458  101.701900  101.071670   99.993163  100.688834\n",
      "2025-06-11  98.715731  100.435652  99.004629  103.343145  98.242306   98.737278  101.557866  100.423784  100.971974   99.733332\n",
      "2025-06-12  97.094794   98.959976  99.134988  102.503836  98.409268   98.185965  101.680125  100.020151  101.585004  100.533251\n",
      "2025-06-13  97.495814   97.581920  99.192663  103.482191  99.470472   98.311628   99.245495  100.818473  101.371873  100.657869\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Recreate DataFrames based on your .info() ---\n",
    "\n",
    "# Tickers from df_adj columns and df_selections index\n",
    "tickers = ['DOCU', 'BF-B', 'CPRT', 'SE', 'GE', 'PGR', 'CART', 'LULU', 'LTH', 'CME']\n",
    "\n",
    "# Create df_selections\n",
    "# We'll generate random data but ensure the weights in each column sum to 1\n",
    "data_selections = np.random.rand(10, 16)\n",
    "df_selections = pd.DataFrame(data_selections, index=tickers, columns=[\n",
    "    'RSI', 'Change %', 'ATR/Price %', 'Avg Volume, M', 'Rel Volume', \n",
    "    'Debt/Eq', 'ROE %', 'Price', 'z_RSI', 'z_Change%', 'z_RelVolume', \n",
    "    'z_ATR/Price%', 'final_score', 'Weight_EW', 'Weight_IV', 'Weight_SW'\n",
    "])\n",
    "\n",
    "# Normalize weight columns to sum to 1, as portfolio weights should\n",
    "for col in ['Weight_EW', 'Weight_IV', 'Weight_SW']:\n",
    "    df_selections[col] = df_selections[col] / df_selections[col].sum()\n",
    "\n",
    "# Create df_adj\n",
    "dates = pd.to_datetime(['2025-06-10', '2025-06-11', '2025-06-12', '2025-06-13'])\n",
    "# Generate some plausible, slightly varying stock prices\n",
    "price_data = 100 + np.random.randn(4, 10).cumsum(axis=0)\n",
    "df_adj = pd.DataFrame(price_data, index=dates, columns=tickers)\n",
    "\n",
    "print(\"--- Sample df_selections (weights normalized) ---\")\n",
    "print(df_selections[['Weight_EW', 'Weight_IV', 'Weight_SW']].head())\n",
    "print(\"\\n--- Sample df_adj (prices) ---\")\n",
    "print(df_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buy Date: 2025-06-11\n",
      "Sell Date: 2025-06-12\n",
      "\n",
      "--- Individual Stock Returns ---\n",
      "DOCU    -0.53%\n",
      "BF-B     0.15%\n",
      "CPRT    -1.04%\n",
      "SE       0.07%\n",
      "GE       2.45%\n",
      "PGR      0.15%\n",
      "CART    -1.38%\n",
      "LULU     0.13%\n",
      "LTH     -0.42%\n",
      "CME      0.92%\n",
      "dtype: object\n",
      "\n",
      "--- Portfolio Performance ---\n",
      "Weight_EW    -0.5048%\n",
      "Weight_IV     0.1800%\n",
      "Weight_SW    -0.2296%\n",
      "Name: Portfolio Return, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# # --- Recreate DataFrames (assuming this setup is correct) ---\n",
    "# tickers = ['DOCU', 'BF-B', 'CPRT', 'SE', 'GE', 'PGR', 'CART', 'LULU', 'LTH', 'CME']\n",
    "# data_selections = np.random.rand(10, 16)\n",
    "# df_selections = pd.DataFrame(data_selections, index=tickers, columns=[\n",
    "#     'RSI', 'Change %', 'ATR/Price %', 'Avg Volume, M', 'Rel Volume', \n",
    "#     'Debt/Eq', 'ROE %', 'Price', 'z_RSI', 'z_Change%', 'z_RelVolume', \n",
    "#     'z_ATR/Price%', 'final_score', 'Weight_EW', 'Weight_IV', 'Weight_SW'\n",
    "# ])\n",
    "# for col in ['Weight_EW', 'Weight_IV', 'Weight_SW']:\n",
    "#     df_selections[col] = df_selections[col] / df_selections[col].sum()\n",
    "# dates = pd.to_datetime(['2025-06-10', '2025-06-11', '2025-06-12', '2025-06-13'])\n",
    "# price_data = 100 + np.random.randn(4, 10).cumsum(axis=0)\n",
    "# df_adj = pd.DataFrame(price_data, index=dates, columns=tickers)\n",
    "\n",
    "\n",
    "# --- Main Calculation Logic ---\n",
    "\n",
    "# 1. Define Dates\n",
    "DATE_STR = '2025-06-10'\n",
    "buy_date = pd.to_datetime(DATE_STR) + pd.Timedelta(days=1)\n",
    "sell_date = buy_date + pd.Timedelta(days=1)\n",
    "\n",
    "print(f\"Buy Date: {buy_date.date()}\")\n",
    "print(f\"Sell Date: {sell_date.date()}\")\n",
    "\n",
    "# 2. Extract prices for buy and sell dates\n",
    "buy_prices = df_adj.loc[buy_date]\n",
    "sell_prices = df_adj.loc[sell_date]\n",
    "\n",
    "# 3. Calculate individual stock returns\n",
    "individual_returns = (sell_prices / buy_prices) - 1\n",
    "\n",
    "# 4. Calculate portfolio performance\n",
    "weights_df = df_selections[['Weight_EW', 'Weight_IV', 'Weight_SW']]\n",
    "weighted_returns = weights_df.multiply(individual_returns, axis=0)\n",
    "portfolio_performance = weighted_returns.sum()\n",
    "\n",
    "# 5. Display the final results (CORRECTED aPPROACH)\n",
    "\n",
    "print(\"\\n--- Individual Stock Returns ---\")\n",
    "# Just print the Series directly. Pandas will format it nicely.\n",
    "# To show as percentages, we can map a formatting function.\n",
    "print((individual_returns * 100).map('{:.2f}%'.format))\n",
    "\n",
    "\n",
    "print(\"\\n--- Portfolio Performance ---\")\n",
    "# Rename for clarity and print the final Series\n",
    "portfolio_performance.name = \"Portfolio Return\"\n",
    "print((portfolio_performance * 100).map('{:.4f}%'.format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Buy Date: 2025-06-11\n",
      "Sell Date: 2025-06-12\n",
      "\n",
      "--- Individual Stock Returns ---\n",
      "<pandas.io.formats.style.Styler object at 0x0000026A64D3D4D0>\n",
      "\n",
      "--- Portfolio Performance ---\n",
      "<pandas.io.formats.style.Styler object at 0x0000026A64933D90>\n"
     ]
    }
   ],
   "source": [
    "# --- Main Calculation Logic ---\n",
    "\n",
    "# 1. Define Dates\n",
    "# DATE_STR = '2025-06-10'\n",
    "buy_date = pd.to_datetime(DATE_STR) + pd.Timedelta(days=1)\n",
    "sell_date = buy_date + pd.Timedelta(days=1)\n",
    "\n",
    "print(f\"\\nBuy Date: {buy_date.date()}\")\n",
    "print(f\"Sell Date: {sell_date.date()}\\n\")\n",
    "\n",
    "# 2. Extract prices for buy and sell dates\n",
    "# Using .loc to select rows by their index (the dates)\n",
    "buy_prices = df_adj.loc[buy_date]\n",
    "sell_prices = df_adj.loc[sell_date]\n",
    "\n",
    "# 3. Calculate individual stock returns for the holding period\n",
    "# Return = (Sell Price / Buy Price) - 1\n",
    "individual_returns = (sell_prices / buy_prices) - 1\n",
    "\n",
    "print(\"--- Individual Stock Returns ---\")\n",
    "print(individual_returns.to_frame('Return').style.format({'Return': '{:.2%}'}))\n",
    "\n",
    "# 4. Calculate the performance for each portfolio\n",
    "# Portfolio Return = sum(weight_of_stock * return_of_stock)\n",
    "\n",
    "# Get the weight columns from df_selections\n",
    "weights_df = df_selections[['Weight_EW', 'Weight_IV', 'Weight_SW']]\n",
    "\n",
    "# Multiply the individual returns by the weights for each portfolio\n",
    "# The DataFrames are aligned by their index (the stock tickers)\n",
    "weighted_returns = weights_df.multiply(individual_returns, axis=0)\n",
    "\n",
    "# Sum the weighted returns for each portfolio to get the final performance\n",
    "portfolio_performance = weighted_returns.sum()\n",
    "\n",
    "# 5. Display the final results\n",
    "print(\"\\n--- Portfolio Performance ---\")\n",
    "# Rename for clarity and format as percentage\n",
    "portfolio_performance.name = \"Portfolio Return\"\n",
    "print(portfolio_performance.to_frame().style.format({'Portfolio Return': '{:.4%}'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. backtest_master_results.csv\n",
      "1. backtest_master_results.parquet\n"
     ]
    }
   ],
   "source": [
    "_file_list = [f.name for f in BACKTEST_RESULTS.glob('*')]\n",
    "for i, _file in enumerate(_file_list):\n",
    "    print(f\"{i}. {_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_backtest:\n",
      "  actual_selection_date_used  average_return  filter_max_debt_eq  filter_min_avg_volume_m  filter_min_price  filter_min_roe_pct inv_vol_col_name                          log_file  n_select_actual  n_select_requested  num_attempted_trades  num_failed_or_skipped_trades  num_selected_tickers  num_successful_trades  portfolio_return  portfolio_return_normalized       run_timestamp scheme  score_weight_change  score_weight_rel_volume  score_weight_rsi  score_weight_volatility selection_date  sharpe_ratio_period  std_dev_return  total_weight_traded  win_rate\n",
      "0                 2025-06-11       -0.017819                 1.5                      2.0              10.0                 5.0      ATR/Price %  backtest_run_20250616_162044.log               10                  10                    10                             0                    10                     10         -0.017819                    -0.017819 2025-06-16 16:20:44     EW                 0.35                      0.2              0.35                      0.1     2025-06-11            -0.795876        0.022589                  1.0       0.2\n",
      "1                 2025-06-11       -0.017819                 1.5                      2.0              10.0                 5.0      ATR/Price %  backtest_run_20250616_162044.log               10                  10                    10                             0                    10                     10         -0.017221                    -0.017221 2025-06-16 16:20:44     IV                 0.35                      0.2              0.35                      0.1     2025-06-11            -0.795876        0.022589                  1.0       0.2\n",
      "2                 2025-06-11       -0.017819                 1.5                      2.0              10.0                 5.0      ATR/Price %  backtest_run_20250616_162044.log               10                  10                    10                             0                    10                     10         -0.018375                    -0.018375 2025-06-16 16:20:44     SW                 0.35                      0.2              0.35                      0.1     2025-06-11            -0.795876        0.022589                  1.0       0.2\n",
      "3                 2025-06-10       -0.001627                 1.5                      2.0              10.0                 5.0      ATR/Price %  backtest_run_20250616_162044.log               10                  10                    10                             0                    10                     10         -0.001627                    -0.001627 2025-06-16 16:20:44     EW                 0.35                      0.2              0.35                      0.1     2025-06-10            -0.117492        0.015200                  1.0       0.4\n",
      "4                 2025-06-10       -0.001627                 1.5                      2.0              10.0                 5.0      ATR/Price %  backtest_run_20250616_162044.log               10                  10                    10                             0                    10                     10         -0.001382                    -0.001382 2025-06-16 16:20:44     IV                 0.35                      0.2              0.35                      0.1     2025-06-10            -0.117492        0.015200                  1.0       0.4\n",
      "5                 2025-06-10       -0.001627                 1.5                      2.0              10.0                 5.0      ATR/Price %  backtest_run_20250616_162044.log               10                  10                    10                             0                    10                     10         -0.002125                    -0.002125 2025-06-16 16:20:44     SW                 0.35                      0.2              0.35                      0.1     2025-06-10            -0.117492        0.015200                  1.0       0.4\n"
     ]
    }
   ],
   "source": [
    "df_backtest = pd.read_parquet(BACKTEST_RESULTS / _file_list[1])\n",
    "print(f'df_backtest:\\n{df_backtest.head(6)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_df_backtest:\n",
      "  actual_selection_date_used  average_return  filter_max_debt_eq  filter_min_avg_volume_m  filter_min_price  filter_min_roe_pct inv_vol_col_name                          log_file  n_select_actual  n_select_requested  num_attempted_trades  num_failed_or_skipped_trades  num_selected_tickers  num_successful_trades  portfolio_return  portfolio_return_normalized       run_timestamp scheme  score_weight_change  score_weight_rel_volume  score_weight_rsi  score_weight_volatility selection_date  sharpe_ratio_period  std_dev_return  total_weight_traded  win_rate\n",
      "3                 2025-06-10       -0.001627                 1.5                      2.0              10.0                 5.0      ATR/Price %  backtest_run_20250616_162044.log               10                  10                    10                             0                    10                     10         -0.001627                    -0.001627 2025-06-16 16:20:44     EW                 0.35                      0.2              0.35                      0.1     2025-06-10            -0.117492          0.0152                  1.0       0.4\n",
      "4                 2025-06-10       -0.001627                 1.5                      2.0              10.0                 5.0      ATR/Price %  backtest_run_20250616_162044.log               10                  10                    10                             0                    10                     10         -0.001382                    -0.001382 2025-06-16 16:20:44     IV                 0.35                      0.2              0.35                      0.1     2025-06-10            -0.117492          0.0152                  1.0       0.4\n",
      "5                 2025-06-10       -0.001627                 1.5                      2.0              10.0                 5.0      ATR/Price %  backtest_run_20250616_162044.log               10                  10                    10                             0                    10                     10         -0.002125                    -0.002125 2025-06-16 16:20:44     SW                 0.35                      0.2              0.35                      0.1     2025-06-10            -0.117492          0.0152                  1.0       0.4\n"
     ]
    }
   ],
   "source": [
    "# 1. Create the boolean mask\n",
    "condition = df_backtest ['actual_selection_date_used'] == '2025-06-10'\n",
    "\n",
    "# 2. Use the mask with .loc to select the rows\n",
    "_df_backtest = df_backtest.loc[condition]\n",
    "\n",
    "print(f'_df_backtest:\\n{_df_backtest}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
