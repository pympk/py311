{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Orchestrator\n",
    "\n",
    "This notebook finds available Finviz data, allows the user to select which date(s) to process, and then executes the main processing pipeline (`run_sequence.py`) for each selected date.\n",
    "\n",
    "**Workflow:**\n",
    "1.  **Setup:** Configure paths and define the default date selection rule.\n",
    "2.  **Get Valid Trading days:** Retrieve OHLCV data. Use the date index as valid trading days.\n",
    "3.  **Find Data Files:** Scan the `Downloads` directory for recent Finviz data files.\n",
    "4.  **Select Dates:** Extract available dates and apply the default selection rule.\n",
    "5.  **(Optional) Refine Selection:** Interactively prompt the user to override the default date selection.\n",
    "6.  **Execute Pipeline:** For each selected date, generate a `config.py` file and run the external processing script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Root Directory: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\n",
      "Scanning for data files in: C:\\Users\\ping\\Downloads\n",
      "OHLCV Parquet Path: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet\n",
      "SRC Path: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\src\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# --- Project Path Setup ---\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "ROOT_DIR = NOTEBOOK_DIR.parent \n",
    "SRC_DIR = ROOT_DIR / 'src'\n",
    "if str(ROOT_DIR) not in sys.path: sys.path.append(str(ROOT_DIR))\n",
    "if str(SRC_DIR) not in sys.path: sys.path.append(str(SRC_DIR))\n",
    "\n",
    "import utils\n",
    "\n",
    "# --- Data File Configuration ---\n",
    "DOWNLOADS_DIR = Path.home() / \"Downloads\"\n",
    "DATA_FILE_PREFIX = 'df_finviz'\n",
    "DATA_FILE_EXTENSION = 'parquet'\n",
    "DATA_FILES_TO_SCAN = 100\n",
    "OHLCV_PARQUET_PATH = ROOT_DIR / \"data\" / \"df_OHLCV_stocks_etfs.parquet\"\n",
    "\n",
    "# --- Analysis Run Configuration ---\n",
    "# Default rule for selecting which dates to process.\n",
    "# slice(-1, None, None) -> Processes only the most recent date.\n",
    "DATE_SLICE = slice(-1, None, None)\n",
    "\n",
    "# --- config.py Generation Parameters ---\n",
    "DEST_DIR = ROOT_DIR / 'data'\n",
    "ANNUAL_RISK_FREE_RATE = 0.04\n",
    "TRADING_DAYS_PER_YEAR = 252\n",
    "\n",
    "# --- Notebook Setup ---\n",
    "pd.set_option('display.max_columns', None); pd.set_option('display.width', 1000)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# --- Verification ---\n",
    "print(f\"Project Root Directory: {ROOT_DIR}\")\n",
    "print(f\"Scanning for data files in: {DOWNLOADS_DIR}\")\n",
    "print(f'OHLCV Parquet Path: {OHLCV_PARQUET_PATH}')\n",
    "print(f'SRC Path: {SRC_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Get Valid Trading Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trading_days (total 16134):\n",
      "type(trading_days): <class 'pandas.core.indexes.datetimes.DatetimeIndex'>\n",
      "trading_days:\n",
      "DatetimeIndex(['1962-01-02', '1962-01-03', '1962-01-04', '1962-01-05', '1962-01-08', '1962-01-09', '1962-01-10', '1962-01-11', '1962-01-12', '1962-01-15',\n",
      "               ...\n",
      "               '2026-01-27', '2026-01-28', '2026-01-29', '2026-01-30', '2026-02-02', '2026-02-03', '2026-02-04', '2026-02-05', '2026-02-06', '2026-02-09'], dtype='datetime64[ns]', name='Date', length=16134, freq=None)\n"
     ]
    }
   ],
   "source": [
    "df_prices = pd.read_parquet(OHLCV_PARQUET_PATH)\n",
    "\n",
    "# The date is the second level of the index (level 1, since it's 0-indexed)\n",
    "trading_days = df_prices.index.get_level_values(\"Date\").unique().sort_values()\n",
    "\n",
    "# trading_days is now a sorted DatetimeIndex\n",
    "print(f\"trading_days (total {len(trading_days)}):\")\n",
    "print(f\"type(trading_days): {type(trading_days)}\")\n",
    "print(f\"trading_days:\\n{trading_days}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Find and Display Available Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Finding recent data files ---\n",
      "\n",
      "Found 99 valid trading dates to process:\n",
      "  0    2025-07-29    1    2025-07-30    2    2025-07-31    3    2025-08-01    4    2025-08-04\n",
      "  5    2025-08-05    6    2025-08-06    7    2025-08-07    8    2025-08-08    9    2025-08-11\n",
      "  10   2025-08-12    11   2025-08-13    12   2025-08-14    13   2025-08-15    14   2025-08-18\n",
      "  15   2025-08-19    16   2025-08-20    17   2025-08-21    18   2025-08-22    19   2025-08-25\n",
      "  20   2025-08-26    21   2025-08-28    22   2025-08-29    23   2025-09-02    24   2025-09-03\n",
      "  25   2025-09-04    26   2025-09-05    27   2025-09-08    28   2025-09-09    29   2025-09-10\n",
      "  30   2025-09-11    31   2025-09-12    32   2025-09-16    33   2025-09-17    34   2025-09-18\n",
      "  35   2025-09-19    36   2025-09-22    37   2025-09-23    38   2025-09-24    39   2025-09-25\n",
      "  40   2025-09-26    41   2025-09-29    42   2025-09-30    43   2025-10-02    44   2025-10-03\n",
      "  45   2025-10-06    46   2025-10-08    47   2025-10-09    48   2025-10-11    49   2025-10-14\n",
      "  50   2025-10-16    51   2025-10-17    52   2025-11-21    53   2025-11-26    54   2025-11-28\n",
      "  55   2025-12-02    56   2025-12-03    57   2025-12-05    58   2025-12-08    59   2025-12-09\n",
      "  60   2025-12-10    61   2025-12-11    62   2025-12-12    63   2025-12-15    64   2025-12-16\n",
      "  65   2025-12-17    66   2025-12-18    67   2025-12-19    68   2025-12-22    69   2025-12-23\n",
      "  70   2025-12-26    71   2025-12-29    72   2025-12-30    73   2025-12-31    74   2026-01-02\n",
      "  75   2026-01-05    76   2026-01-06    77   2026-01-07    78   2026-01-08    79   2026-01-09\n",
      "  80   2026-01-12    81   2026-01-14    82   2026-01-15    83   2026-01-16    84   2026-01-19\n",
      "  85   2026-01-20    86   2026-01-21    87   2026-01-22    88   2026-01-23    89   2026-01-26\n",
      "  90   2026-01-27    91   2026-01-29    92   2026-01-30    93   2026-02-02    94   2026-02-03\n",
      "  95   2026-02-04    96   2026-02-05    97   2026-02-06    98   2026-02-09\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Step 1: Finding recent data files ---\")\n",
    "\n",
    "found_files = utils.get_recent_files(\n",
    "    directory_path=DOWNLOADS_DIR,\n",
    "    prefix=DATA_FILE_PREFIX,\n",
    "    extension=DATA_FILE_EXTENSION,\n",
    "    count=DATA_FILES_TO_SCAN,\n",
    ")\n",
    "\n",
    "if not found_files:\n",
    "    print(f\"No files matching '{DATA_FILE_PREFIX}*.{DATA_FILE_EXTENSION}' found.\")\n",
    "    available_dates = []\n",
    "else:\n",
    "    # Extract dates from filenames\n",
    "    available_dates = utils.extract_and_sort_dates_from_filenames(found_files)\n",
    "    print(f\"\\nFound {len(available_dates)} valid trading dates to process:\")\n",
    "    utils.print_list_in_columns(available_dates, num_columns=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Select Dates for Processing (Default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 2: Applying default selection rule ---\n",
      "Default rule 'slice(-1, None, None)' selected 1 date(s):\n",
      "['2026-02-09']\n"
     ]
    }
   ],
   "source": [
    "if available_dates:\n",
    "    # Apply the default slice defined in the setup cell\n",
    "    dates_to_process = available_dates[DATE_SLICE]\n",
    "    print(f\"\\n--- Step 2: Applying default selection rule ---\")\n",
    "    print(f\"Default rule '{DATE_SLICE}' selected {len(dates_to_process)} date(s):\")\n",
    "    print(dates_to_process)\n",
    "else:\n",
    "    dates_to_process = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: (OPTIONAL) Interactively Refine Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Continuing with the current value.\n"
     ]
    }
   ],
   "source": [
    "if available_dates:\n",
    "    # Call the interactive utility function\n",
    "    NEW_DATE_SLICE = utils.prompt_for_slice_update(\"DATE_SLICE\", DATE_SLICE)\n",
    "\n",
    "    # If the slice was changed, update the list of dates to process\n",
    "    if NEW_DATE_SLICE != DATE_SLICE:\n",
    "        DATE_SLICE = NEW_DATE_SLICE\n",
    "        dates_to_process = available_dates[DATE_SLICE]\n",
    "        print(f\"\\nUpdated selection. Now processing {len(dates_to_process)} date(s):\")\n",
    "        print(dates_to_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Execute Pipeline\n",
    "\n",
    "This cell iterates through the final list of selected dates, generates the `config.py` file for each, and executes the `run_sequence.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 4: Starting processing sequence ---\n",
      "\n",
      "==================== PROCESSING DATE: 2026-02-09 ====================\n",
      "Successfully created config file: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\config.py\n",
      "Executing run_sequence_v2.py for 2026-02-09...\n",
      "Starting notebook execution sequence...\n",
      "\n",
      "--- Running py1_clean_df_finviz_v15.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py1_clean_df_finviz_v15.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\py1_clean_df_finviz_v15.ipynb\n",
      "Successfully executed py1_clean_df_finviz_v15.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py1_clean_df_finviz_v15.ipynb\n",
      "\n",
      "--- Running py2_clean_df_OHLCV_v12.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py2_clean_df_OHLCV_v12.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\py2_clean_df_OHLCV_v12.ipynb\n",
      "Successfully executed py2_clean_df_OHLCV_v12.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py2_clean_df_OHLCV_v12.ipynb\n",
      "\n",
      "--- Running py2_save_df_adj_close_v2.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py2_save_df_adj_close_v2.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\py2_save_df_adj_close_v2.ipynb\n",
      "Successfully executed py2_save_df_adj_close_v2.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py2_save_df_adj_close_v2.ipynb\n",
      "\n",
      "--- Running py3_calc_perf_ratios_v17.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py3_calc_perf_ratios_v17.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\py3_calc_perf_ratios_v17.ipynb\n",
      "Successfully executed py3_calc_perf_ratios_v17.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py3_calc_perf_ratios_v17.ipynb\n",
      "\n",
      "--- Running py4_append_ratios_v10.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py4_append_ratios_v10.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\py4_append_ratios_v10.ipynb\n",
      "Successfully executed py4_append_ratios_v10.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py4_append_ratios_v10.ipynb\n",
      "\n",
      "--- Running py5_append_columns_v8.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py5_append_columns_v8.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\py5_append_columns_v8.ipynb\n",
      "Successfully executed py5_append_columns_v8.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py5_append_columns_v8.ipynb\n",
      "\n",
      "--- Running py6_append_stats_history_v4.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py6_append_stats_history_v4.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\py6_append_stats_history_v4.ipynb\n",
      "Successfully executed py6_append_stats_history_v4.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py6_append_stats_history_v4.ipynb\n",
      "\n",
      "--- Running py6_view_market_sentiment_history_v1.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py6_view_market_sentiment_history_v1.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\py6_view_market_sentiment_history_v1.ipynb\n",
      "Successfully executed py6_view_market_sentiment_history_v1.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py6_view_market_sentiment_history_v1.ipynb\n",
      "\n",
      "--- Running py7_view_daily_market_snapshot_v0.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py7_view_daily_market_snapshot_v0.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\py7_view_daily_market_snapshot_v0.ipynb\n",
      "Successfully executed py7_view_daily_market_snapshot_v0.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py7_view_daily_market_snapshot_v0.ipynb\n",
      "\n",
      "--- Running py8_portf_picks_short_term_v6.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py8_portf_picks_short_term_v6.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\py8_portf_picks_short_term_v6.ipynb\n",
      "Successfully executed py8_portf_picks_short_term_v6.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py8_portf_picks_short_term_v6.ipynb\n",
      "\n",
      "--- Running py9_backtest_v3.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py9_backtest_v3.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\py9_backtest_v3.ipynb\n",
      "Successfully executed py9_backtest_v3.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py9_backtest_v3.ipynb\n",
      "\n",
      "--- Running py10_backtest_verification_v3.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py10_backtest_verification_v3.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\py10_backtest_verification_v3.ipynb\n",
      "Successfully executed py10_backtest_verification_v3.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py10_backtest_verification_v3.ipynb\n",
      "\n",
      "--- Running py90_interactive_backtest_v1.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py90_interactive_backtest_v1.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\py90_interactive_backtest_v1.ipynb\n",
      "Successfully executed py90_interactive_backtest_v1.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py90_interactive_backtest_v1.ipynb\n",
      "\n",
      "--- All notebooks executed successfully! ---\n",
      "--- Finished processing for 2026-02-09 ---\n",
      "\n",
      "========================= ALL PROCESSING COMPLETE =========================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Step 4: Starting processing sequence ---\")\n",
    "\n",
    "if not dates_to_process:\n",
    "    print(\"No dates to process. Halting execution.\")\n",
    "else:\n",
    "    for date_str in dates_to_process:\n",
    "        print(f\"\\n{'='*20} PROCESSING DATE: {date_str} {'='*20}\")\n",
    "\n",
    "        # 1. Create the config.py file for the current date\n",
    "        utils.create_pipeline_config_file(\n",
    "            config_path=ROOT_DIR / \"config.py\",\n",
    "            date_str=date_str,\n",
    "            downloads_dir=DOWNLOADS_DIR,\n",
    "            dest_dir=DEST_DIR,\n",
    "            annual_risk_free_rate=ANNUAL_RISK_FREE_RATE,\n",
    "            trading_days_per_year=TRADING_DAYS_PER_YEAR,\n",
    "        )\n",
    "\n",
    "        # --- 2. Run the external processing script ---\n",
    "        print(f\"Executing run_sequence_v2.py for {date_str}...\")\n",
    "\n",
    "        # First, create a clear variable for the full path\n",
    "        script_to_run = ROOT_DIR / \"run_sequence_v2.py\"\n",
    "\n",
    "        # Now, the f-string is simple and has no quote conflicts\n",
    "        get_ipython().run_line_magic(\"run\", f'-i \"{script_to_run}\"')\n",
    "\n",
    "        print(f\"--- Finished processing for {date_str} ---\")\n",
    "\n",
    "    print(f\"\\n{'='*25} ALL PROCESSING COMPLETE {'='*25}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
