{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidate Yloader OHLCV Data\n",
    "\n",
    "This notebook reads all individual ticker `.csv` files generated by the `Yloader` application, combines them into a single, analysis-ready DataFrame, and saves it in the efficient Parquet format.\n",
    "\n",
    "**Workflow:**\n",
    "\n",
    "1.  **Prerequisite:** Run `Yloader` to download OHLCV data. This should create multiple `.csv` files (e.g., `AAPL.csv`, `GOOG.csv`) in a dedicated directory.\n",
    "2.  **Process & Combine:** The notebook scans the source directory, reads each CSV, and consolidates them into a single pandas DataFrame with a `(Ticker, Date)` MultiIndex.\n",
    "3.  **Save:** The final DataFrame is saved as a single `.parquet` file for fast loading in subsequent analysis notebooks.\n",
    "4.  **Verify:** The saved Parquet file is read back to confirm its integrity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and Configuration\n",
    "\n",
    "**This is the only cell you need to modify.** Adjust the paths and column definitions below to match your project structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Root Directory set to: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\n",
      "Reading Yloader CSVs from: C:\\Users\\ping\\Desktop\\yloader\n",
      "Output will be saved to: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "# 1. Set the directory where your Yloader CSV files are located.\n",
    "#    This uses Path.home() to be portable across different computers and OS.\n",
    "YLOADER_DATA_DIR = Path.home() / \"Desktop\" / \"yloader\"\n",
    "\n",
    "# 2. Define the destination path for the final combined Parquet file.\n",
    "#    It's good practice to save data outputs within the project's data folder.\n",
    "#    Assuming a project structure where this notebook is in a `notebooks` subdir.\n",
    "# ROOT_DIR = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "# DESTINATION_PARQUET_PATH = ROOT_DIR / \"data\" / \"df_OHLCV_stocks_etfs.parquet\"\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "ROOT_DIR = NOTEBOOK_DIR.parent \n",
    "SRC_DIR = ROOT_DIR / 'src'\n",
    "if str(ROOT_DIR) not in sys.path: sys.path.append(str(ROOT_DIR))\n",
    "if str(SRC_DIR) not in sys.path: sys.path.append(str(SRC_DIR))\n",
    "DESTINATION_PARQUET_PATH = ROOT_DIR / \"data\" / \"df_OHLCV_stocks_etfs.parquet\"\n",
    "\n",
    "# 3. Define the column names for the CSV files.\n",
    "#    Assumes CSVs have no header and columns are in this fixed order.\n",
    "#    The first column is always assumed to be 'Date'.\n",
    "CANONICAL_COLUMN_NAMES = ['Adj Open', 'Adj High', 'Adj Low', 'Adj Close', 'Volume']\n",
    "\n",
    "# --- Verification ---\n",
    "print(f\"Project Root Directory set to: {ROOT_DIR}\")\n",
    "print(f\"Reading Yloader CSVs from: {YLOADER_DATA_DIR}\")\n",
    "print(f\"Output will be saved to: {DESTINATION_PARQUET_PATH}\")\n",
    "\n",
    "# Set pandas display options for better readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Process and Combine CSV Data\n",
    "\n",
    "This cell defines and executes the core logic to read all individual CSV files and merge them into a single, multi-indexed DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Optional\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def process_yloader_csvs(\n",
    "    data_dir: Path,\n",
    "    canonical_cols: List[str],\n",
    "    anchor_ticker: str = \"SPY\",\n",
    ") -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Reads and combines CSV files from the Yloader output directory whose\n",
    "    modification *date* (ignoring time-of-day) matches that of the specified\n",
    "    anchor ticker file.\n",
    "\n",
    "    Args:\n",
    "        data_dir (Path):\n",
    "            Directory containing the Yloader CSV files.\n",
    "        canonical_cols (List[str]):\n",
    "            Expected data column names, **excluding** 'Date'.\n",
    "        anchor_ticker (str, optional):\n",
    "            Ticker whose modification date is used as the reference.\n",
    "            Defaults to \"SPY\".\n",
    "\n",
    "    Returns:\n",
    "        Optional[pd.DataFrame]:\n",
    "            A sorted, multi-indexed DataFrame (Ticker, Date) or None if\n",
    "            no data could be processed.\n",
    "    \"\"\"\n",
    "    if not data_dir.is_dir():\n",
    "        print(f\"Error: Directory not found: {data_dir}\")\n",
    "        return None\n",
    "\n",
    "    # ------------------------------------------------------------------ #\n",
    "    # 1. Determine the reference date (modification date of anchor file) #\n",
    "    # ------------------------------------------------------------------ #\n",
    "    anchor_file = data_dir / f\"{anchor_ticker.upper()}.csv\"\n",
    "    if not anchor_file.exists():\n",
    "        print(f\"Anchor file not found: {anchor_file}\")\n",
    "        return None\n",
    "\n",
    "    anchor_date = datetime.fromtimestamp(anchor_file.stat().st_mtime).date()\n",
    "    print(f'\\nProcess csv files with this date: {anchor_date}')\n",
    "\n",
    "    # ---------------------------------------------------------- #\n",
    "    # 2. Collect CSV files whose modification date matches anchor #\n",
    "    # ---------------------------------------------------------- #\n",
    "    csv_files = [\n",
    "        f\n",
    "        for f in data_dir.glob(\"*.csv\")\n",
    "        if datetime.fromtimestamp(f.stat().st_mtime).date() == anchor_date\n",
    "    ]\n",
    "\n",
    "    if not csv_files:\n",
    "        print(f\"No CSV files found with the same modification date as {anchor_ticker}.\")\n",
    "        return None\n",
    "\n",
    "    print(\n",
    "        f\"Found {len(csv_files)} CSV files with modification date \"\n",
    "        f\"{anchor_date} (anchor: {anchor_ticker})...\"\n",
    "    )\n",
    "\n",
    "    # ---------------------------------------------------------- #\n",
    "    # 3. Load and combine the matching files                     #\n",
    "    # ---------------------------------------------------------- #\n",
    "    all_dataframes = []\n",
    "    tickers_list = []\n",
    "    expected_csv_cols = [\"Date\"] + canonical_cols\n",
    "\n",
    "    for file_path in csv_files:\n",
    "        ticker = file_path.stem\n",
    "        try:\n",
    "            df_temp = pd.read_csv(\n",
    "                file_path,\n",
    "                header=None,\n",
    "                names=expected_csv_cols,\n",
    "                parse_dates=[\"Date\"],\n",
    "                index_col=\"Date\",\n",
    "            )\n",
    "\n",
    "            if df_temp.empty:\n",
    "                print(f\"Warning: File {file_path.name} is empty. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            all_dataframes.append(df_temp)\n",
    "            tickers_list.append(ticker)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path.name}: {e}. Skipping.\")\n",
    "\n",
    "    if not all_dataframes:\n",
    "        print(\"No data was successfully loaded. Aborting.\")\n",
    "        return None\n",
    "\n",
    "    multi_index_df = pd.concat(\n",
    "        all_dataframes, keys=tickers_list, names=[\"Ticker\", \"Date\"]\n",
    "    )\n",
    "    multi_index_df.sort_index(level=[\"Ticker\", \"Date\"], ascending=[True, False], inplace=True)\n",
    "\n",
    "    print(\"\\nCSV processing complete. DataFrame created successfully.\")\n",
    "    return multi_index_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Process csv files with this date: 2025-10-06\n",
      "Found 885 CSV files with modification date 2025-10-06 (anchor: SPY)...\n",
      "\n",
      "CSV processing complete. DataFrame created successfully.\n",
      "\n",
      "sorting final_df chronologically ...\n",
      "\n",
      "--- DataFrame Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 4036635 entries, ('A', Timestamp('1999-11-18 00:00:00')) to ('ZWS', Timestamp('2025-10-06 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   Adj Open   float64\n",
      " 1   Adj High   float64\n",
      " 2   Adj Low    float64\n",
      " 3   Adj Close  float64\n",
      " 4   Volume     int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 170.0+ MB\n",
      "\n",
      "--- First 5 Rows of Combined DataFrame ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Adj Open</th>\n",
       "      <th>Adj High</th>\n",
       "      <th>Adj Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ZWS</th>\n",
       "      <th>2025-09-30</th>\n",
       "      <td>46.90</td>\n",
       "      <td>47.40</td>\n",
       "      <td>46.77</td>\n",
       "      <td>47.03</td>\n",
       "      <td>609500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-01</th>\n",
       "      <td>46.72</td>\n",
       "      <td>47.04</td>\n",
       "      <td>46.40</td>\n",
       "      <td>46.80</td>\n",
       "      <td>599400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-02</th>\n",
       "      <td>46.86</td>\n",
       "      <td>47.17</td>\n",
       "      <td>46.54</td>\n",
       "      <td>46.91</td>\n",
       "      <td>839900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-03</th>\n",
       "      <td>46.87</td>\n",
       "      <td>47.37</td>\n",
       "      <td>46.62</td>\n",
       "      <td>46.84</td>\n",
       "      <td>780500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-06</th>\n",
       "      <td>47.16</td>\n",
       "      <td>47.37</td>\n",
       "      <td>46.67</td>\n",
       "      <td>47.29</td>\n",
       "      <td>661018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Adj Open  Adj High  Adj Low  Adj Close  Volume\n",
       "Ticker Date                                                      \n",
       "ZWS    2025-09-30     46.90     47.40    46.77      47.03  609500\n",
       "       2025-10-01     46.72     47.04    46.40      46.80  599400\n",
       "       2025-10-02     46.86     47.17    46.54      46.91  839900\n",
       "       2025-10-03     46.87     47.37    46.62      46.84  780500\n",
       "       2025-10-06     47.16     47.37    46.67      47.29  661018"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Execute Step 1 ---\n",
    "final_df = process_yloader_csvs(YLOADER_DATA_DIR, CANONICAL_COLUMN_NAMES)\n",
    "\n",
    "if final_df is not None:\n",
    "    # chronological sort final_df\n",
    "    if not final_df.index.is_monotonic_increasing:\n",
    "        print(f'\\nsorting final_df chronologically ...')\n",
    "        final_df.sort_index(inplace=True)\n",
    "    else:\n",
    "        print(f'\\nfinal_df is sorted chronologically')  \n",
    "\n",
    "    print(\"\\n--- DataFrame Info ---\")\n",
    "    final_df.info()\n",
    "    \n",
    "    print(\"\\n--- First 5 Rows of Combined DataFrame ---\")\n",
    "    display(final_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Save DataFrame to Parquet File\n",
    "\n",
    "This step saves the combined DataFrame to a Parquet file, which is highly efficient for storage and subsequent loading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved DataFrame to: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet\n"
     ]
    }
   ],
   "source": [
    "def save_dataframe_to_parquet(df: Optional[pd.DataFrame], dest_path: Path):\n",
    "    \"\"\"\n",
    "    Saves a DataFrame to a Parquet file if it's not empty.\n",
    "\n",
    "    Args:\n",
    "        df (Optional[pd.DataFrame]): The DataFrame to save.\n",
    "        dest_path (Path): The destination file path.\n",
    "    \"\"\"\n",
    "    if df is None or df.empty:\n",
    "        print(\"DataFrame is empty or None. Nothing to save.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Ensure the destination directory exists\n",
    "        dest_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Save the file using the efficient 'pyarrow' engine and 'zstd' compression\n",
    "        df.to_parquet(dest_path, engine='pyarrow', compression='zstd', index=True)\n",
    "        print(f\"\\nSuccessfully saved DataFrame to: {dest_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError: Failed to save Parquet file. Details: {e}\")\n",
    "\n",
    "# --- Execute Step 2 ---\n",
    "save_dataframe_to_parquet(final_df, DESTINATION_PARQUET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Verify the Saved File (Optional)\n",
    "\n",
    "This final step reads the Parquet file back into a new DataFrame to ensure the data was saved correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Verifying the saved file at: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet ---\n",
      "Verification successful! File read back into memory.\n",
      "\n",
      "--- First 5 Rows of Verified DataFrame ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Adj Open</th>\n",
       "      <th>Adj High</th>\n",
       "      <th>Adj Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">A</th>\n",
       "      <th>1999-11-18</th>\n",
       "      <td>27.2452</td>\n",
       "      <td>29.9398</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>26.3470</td>\n",
       "      <td>74716422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-19</th>\n",
       "      <td>25.7108</td>\n",
       "      <td>25.7482</td>\n",
       "      <td>23.8396</td>\n",
       "      <td>24.1764</td>\n",
       "      <td>18198351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-22</th>\n",
       "      <td>24.7378</td>\n",
       "      <td>26.3470</td>\n",
       "      <td>23.9893</td>\n",
       "      <td>26.3470</td>\n",
       "      <td>7857767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-23</th>\n",
       "      <td>25.4488</td>\n",
       "      <td>26.1225</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>7138322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-24</th>\n",
       "      <td>24.0267</td>\n",
       "      <td>25.1120</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>24.5881</td>\n",
       "      <td>5785607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Adj Open  Adj High  Adj Low  Adj Close    Volume\n",
       "Ticker Date                                                        \n",
       "A      1999-11-18   27.2452   29.9398  23.9518    26.3470  74716422\n",
       "       1999-11-19   25.7108   25.7482  23.8396    24.1764  18198351\n",
       "       1999-11-22   24.7378   26.3470  23.9893    26.3470   7857767\n",
       "       1999-11-23   25.4488   26.1225  23.9518    23.9518   7138322\n",
       "       1999-11-24   24.0267   25.1120  23.9518    24.5881   5785607"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data for first available ticker 'A' ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Open</th>\n",
       "      <th>Adj High</th>\n",
       "      <th>Adj Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999-11-18</th>\n",
       "      <td>27.2452</td>\n",
       "      <td>29.9398</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>26.3470</td>\n",
       "      <td>74716422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-19</th>\n",
       "      <td>25.7108</td>\n",
       "      <td>25.7482</td>\n",
       "      <td>23.8396</td>\n",
       "      <td>24.1764</td>\n",
       "      <td>18198351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-22</th>\n",
       "      <td>24.7378</td>\n",
       "      <td>26.3470</td>\n",
       "      <td>23.9893</td>\n",
       "      <td>26.3470</td>\n",
       "      <td>7857767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-23</th>\n",
       "      <td>25.4488</td>\n",
       "      <td>26.1225</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>7138322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-24</th>\n",
       "      <td>24.0267</td>\n",
       "      <td>25.1120</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>24.5881</td>\n",
       "      <td>5785607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Adj Open  Adj High  Adj Low  Adj Close    Volume\n",
       "Date                                                        \n",
       "1999-11-18   27.2452   29.9398  23.9518    26.3470  74716422\n",
       "1999-11-19   25.7108   25.7482  23.8396    24.1764  18198351\n",
       "1999-11-22   24.7378   26.3470  23.9893    26.3470   7857767\n",
       "1999-11-23   25.4488   26.1225  23.9518    23.9518   7138322\n",
       "1999-11-24   24.0267   25.1120  23.9518    24.5881   5785607"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"--- Verifying the saved file at: {DESTINATION_PARQUET_PATH} ---\")\n",
    "\n",
    "try:\n",
    "    if DESTINATION_PARQUET_PATH.exists():\n",
    "        verified_df = pd.read_parquet(DESTINATION_PARQUET_PATH)\n",
    "        print(\"Verification successful! File read back into memory.\")\n",
    "        \n",
    "        print(\"\\n--- First 5 Rows of Verified DataFrame ---\")\n",
    "        display(verified_df.head())\n",
    "        \n",
    "        # Optional: Check a specific ticker\n",
    "        if not verified_df.empty:\n",
    "            example_ticker = verified_df.index.get_level_values('Ticker')[0]\n",
    "            print(f\"\\n--- Data for first available ticker '{example_ticker}' ---\")\n",
    "            display(verified_df.loc[example_ticker].head())\n",
    "\n",
    "    else:\n",
    "        print(\"Error: The output file was not found at the specified path.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during verification: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Adj Open</th>\n",
       "      <th>Adj High</th>\n",
       "      <th>Adj Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">A</th>\n",
       "      <th>1999-11-18</th>\n",
       "      <td>27.2452</td>\n",
       "      <td>29.9398</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>26.3470</td>\n",
       "      <td>74716422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-19</th>\n",
       "      <td>25.7108</td>\n",
       "      <td>25.7482</td>\n",
       "      <td>23.8396</td>\n",
       "      <td>24.1764</td>\n",
       "      <td>18198351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-22</th>\n",
       "      <td>24.7378</td>\n",
       "      <td>26.3470</td>\n",
       "      <td>23.9893</td>\n",
       "      <td>26.3470</td>\n",
       "      <td>7857767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-23</th>\n",
       "      <td>25.4488</td>\n",
       "      <td>26.1225</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>7138322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-24</th>\n",
       "      <td>24.0267</td>\n",
       "      <td>25.1120</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>24.5881</td>\n",
       "      <td>5785607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ZWS</th>\n",
       "      <th>2025-09-30</th>\n",
       "      <td>46.9000</td>\n",
       "      <td>47.4000</td>\n",
       "      <td>46.7700</td>\n",
       "      <td>47.0300</td>\n",
       "      <td>609500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-01</th>\n",
       "      <td>46.7200</td>\n",
       "      <td>47.0400</td>\n",
       "      <td>46.4000</td>\n",
       "      <td>46.8000</td>\n",
       "      <td>599400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-02</th>\n",
       "      <td>46.8600</td>\n",
       "      <td>47.1700</td>\n",
       "      <td>46.5400</td>\n",
       "      <td>46.9100</td>\n",
       "      <td>839900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-03</th>\n",
       "      <td>46.8700</td>\n",
       "      <td>47.3700</td>\n",
       "      <td>46.6200</td>\n",
       "      <td>46.8400</td>\n",
       "      <td>780500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-06</th>\n",
       "      <td>47.1600</td>\n",
       "      <td>47.3700</td>\n",
       "      <td>46.6700</td>\n",
       "      <td>47.2900</td>\n",
       "      <td>661018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4036635 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Adj Open  Adj High  Adj Low  Adj Close    Volume\n",
       "Ticker Date                                                        \n",
       "A      1999-11-18   27.2452   29.9398  23.9518    26.3470  74716422\n",
       "       1999-11-19   25.7108   25.7482  23.8396    24.1764  18198351\n",
       "       1999-11-22   24.7378   26.3470  23.9893    26.3470   7857767\n",
       "       1999-11-23   25.4488   26.1225  23.9518    23.9518   7138322\n",
       "       1999-11-24   24.0267   25.1120  23.9518    24.5881   5785607\n",
       "...                     ...       ...      ...        ...       ...\n",
       "ZWS    2025-09-30   46.9000   47.4000  46.7700    47.0300    609500\n",
       "       2025-10-01   46.7200   47.0400  46.4000    46.8000    599400\n",
       "       2025-10-02   46.8600   47.1700  46.5400    46.9100    839900\n",
       "       2025-10-03   46.8700   47.3700  46.6200    46.8400    780500\n",
       "       2025-10-06   47.1600   47.3700  46.6700    47.2900    661018\n",
       "\n",
       "[4036635 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verified_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
