{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Orchestrator\n",
    "\n",
    "This notebook finds available Finviz data, allows the user to select which date(s) to process, and then executes the main processing pipeline (`run_sequence.py`) for each selected date.\n",
    "\n",
    "**Workflow:**\n",
    "1.  **Setup:** Configure paths and define the default date selection rule.\n",
    "2.  **Get Valid Trading days:** Retrieve OHLCV data. Use the date index as valid trading days.\n",
    "3.  **Find Data Files:** Scan the `Downloads` directory for recent Finviz data files.\n",
    "4.  **Select Dates:** Extract available dates and apply the default selection rule.\n",
    "5.  **(Optional) Refine Selection:** Interactively prompt the user to override the default date selection.\n",
    "6.  **Execute Pipeline:** For each selected date, generate a `config.py` file and run the external processing script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Root Directory: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\n",
      "Scanning for data files in: C:\\Users\\ping\\Downloads\n",
      "OHLCV Parquet Path: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet\n",
      "SRC Path: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\src\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# --- Project Path Setup ---\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "ROOT_DIR = NOTEBOOK_DIR.parent \n",
    "SRC_DIR = ROOT_DIR / 'src'\n",
    "if str(ROOT_DIR) not in sys.path: sys.path.append(str(ROOT_DIR))\n",
    "if str(SRC_DIR) not in sys.path: sys.path.append(str(SRC_DIR))\n",
    "\n",
    "import utils\n",
    "\n",
    "# --- Data File Configuration ---\n",
    "DOWNLOADS_DIR = Path.home() / \"Downloads\"\n",
    "DATA_FILE_PREFIX = 'df_finviz'\n",
    "DATA_FILE_EXTENSION = 'parquet'\n",
    "DATA_FILES_TO_SCAN = 100\n",
    "OHLCV_PARQUET_PATH = ROOT_DIR / \"data\" / \"df_OHLCV_stocks_etfs.parquet\"\n",
    "\n",
    "# --- Analysis Run Configuration ---\n",
    "# Default rule for selecting which dates to process.\n",
    "# slice(-1, None, None) -> Processes only the most recent date.\n",
    "DATE_SLICE = slice(-1, None, None)\n",
    "\n",
    "# --- config.py Generation Parameters ---\n",
    "DEST_DIR = ROOT_DIR / 'data'\n",
    "ANNUAL_RISK_FREE_RATE = 0.04\n",
    "TRADING_DAYS_PER_YEAR = 252\n",
    "\n",
    "# --- Notebook Setup ---\n",
    "pd.set_option('display.max_columns', None); pd.set_option('display.width', 1000)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# --- Verification ---\n",
    "print(f\"Project Root Directory: {ROOT_DIR}\")\n",
    "print(f\"Scanning for data files in: {DOWNLOADS_DIR}\")\n",
    "print(f'OHLCV Parquet Path: {OHLCV_PARQUET_PATH}')\n",
    "print(f'SRC Path: {SRC_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Get Valid Trading Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trading_days (total 685):\n",
      "type(trading_days): <class 'pandas.core.indexes.datetimes.DatetimeIndex'>\n",
      "trading_days:\n",
      "DatetimeIndex(['2023-01-03', '2023-01-04', '2023-01-05', '2023-01-06', '2023-01-09', '2023-01-10', '2023-01-11', '2023-01-12', '2023-01-13', '2023-01-17',\n",
      "               ...\n",
      "               '2025-09-12', '2025-09-15', '2025-09-16', '2025-09-17', '2025-09-18', '2025-09-19', '2025-09-22', '2025-09-23', '2025-09-24', '2025-09-25'], dtype='datetime64[ns]', name='Date', length=685, freq=None)\n"
     ]
    }
   ],
   "source": [
    "df_prices = pd.read_parquet(OHLCV_PARQUET_PATH)\n",
    "\n",
    "# The date is the second level of the index (level 1, since it's 0-indexed)\n",
    "trading_days = df_prices.index \\\n",
    "    .get_level_values('Date') \\\n",
    "    .unique() \\\n",
    "    .sort_values()\n",
    "\n",
    "# trading_days is now a sorted DatetimeIndex\n",
    "print(f'trading_days (total {len(trading_days)}):')\n",
    "print(f'type(trading_days): {type(trading_days)}')\n",
    "print(f'trading_days:\\n{trading_days}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Find and Display Available Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Finding recent data files ---\n",
      "\n",
      "Filtering available dates against actual trading days...\n",
      "\n",
      "Found 98 valid trading dates to process:\n",
      "  0    2025-05-05    1    2025-05-06    2    2025-05-07    3    2025-05-08    4    2025-05-09\n",
      "  5    2025-05-12    6    2025-05-13    7    2025-05-14    8    2025-05-15    9    2025-05-16\n",
      "  10   2025-05-19    11   2025-05-20    12   2025-05-21    13   2025-05-22    14   2025-05-23\n",
      "  15   2025-05-27    16   2025-05-28    17   2025-05-29    18   2025-05-30    19   2025-06-02\n",
      "  20   2025-06-03    21   2025-06-04    22   2025-06-05    23   2025-06-06    24   2025-06-09\n",
      "  25   2025-06-10    26   2025-06-11    27   2025-06-12    28   2025-06-13    29   2025-06-16\n",
      "  30   2025-06-17    31   2025-06-18    32   2025-06-20    33   2025-06-23    34   2025-06-24\n",
      "  35   2025-06-25    36   2025-06-26    37   2025-06-27    38   2025-06-30    39   2025-07-01\n",
      "  40   2025-07-02    41   2025-07-03    42   2025-07-07    43   2025-07-08    44   2025-07-09\n",
      "  45   2025-07-10    46   2025-07-11    47   2025-07-14    48   2025-07-15    49   2025-07-16\n",
      "  50   2025-07-17    51   2025-07-18    52   2025-07-21    53   2025-07-22    54   2025-07-23\n",
      "  55   2025-07-24    56   2025-07-25    57   2025-07-28    58   2025-07-29    59   2025-07-30\n",
      "  60   2025-07-31    61   2025-08-01    62   2025-08-04    63   2025-08-05    64   2025-08-06\n",
      "  65   2025-08-07    66   2025-08-08    67   2025-08-11    68   2025-08-12    69   2025-08-13\n",
      "  70   2025-08-14    71   2025-08-15    72   2025-08-18    73   2025-08-19    74   2025-08-20\n",
      "  75   2025-08-21    76   2025-08-22    77   2025-08-25    78   2025-08-26    79   2025-08-28\n",
      "  80   2025-08-29    81   2025-09-02    82   2025-09-03    83   2025-09-04    84   2025-09-05\n",
      "  85   2025-09-08    86   2025-09-09    87   2025-09-10    88   2025-09-11    89   2025-09-12\n",
      "  90   2025-09-16    91   2025-09-17    92   2025-09-18    93   2025-09-19    94   2025-09-22\n",
      "  95   2025-09-23    96   2025-09-24    97   2025-09-25\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Step 1: Finding recent data files ---\")\n",
    "\n",
    "found_files = utils.get_recent_files(    \n",
    "    directory_path=DOWNLOADS_DIR,\n",
    "    prefix=DATA_FILE_PREFIX,\n",
    "    extension=DATA_FILE_EXTENSION,\n",
    "    count=DATA_FILES_TO_SCAN\n",
    ")\n",
    "\n",
    "if not found_files:\n",
    "    print(f\"No files matching '{DATA_FILE_PREFIX}*.{DATA_FILE_EXTENSION}' found.\")\n",
    "    available_dates = []\n",
    "else:\n",
    "    # Extract dates from filenames\n",
    "    available_dates = utils.extract_and_sort_dates_from_filenames(found_files)\n",
    "    \n",
    "    # --- START OF NEW CODE ---\n",
    "    print(\"\\nFiltering available dates against actual trading days...\")\n",
    "    \n",
    "    # Convert list of strings to a pandas DatetimeIndex for comparison\n",
    "    available_dt_index = pd.to_datetime(available_dates)\n",
    "    \n",
    "    # Create a boolean mask indicating which dates are valid trading days\n",
    "    is_trading_day_mask = available_dt_index.isin(trading_days)\n",
    "    \n",
    "    # Apply the mask to keep only the valid dates\n",
    "    filtered_dates = [date for date, is_valid in zip(available_dates, is_trading_day_mask) if is_valid]\n",
    "    \n",
    "    # Overwrite the variable with the cleaned list\n",
    "    available_dates = filtered_dates\n",
    "    # --- END OF NEW CODE ---\n",
    "\n",
    "    print(f\"\\nFound {len(available_dates)} valid trading dates to process:\")\n",
    "    utils.print_list_in_columns(available_dates, num_columns=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Select Dates for Processing (Default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 2: Applying default selection rule ---\n",
      "Default rule 'slice(-1, None, None)' selected 1 date(s):\n",
      "['2025-09-25']\n"
     ]
    }
   ],
   "source": [
    "if available_dates:\n",
    "    # Apply the default slice defined in the setup cell\n",
    "    dates_to_process = available_dates[DATE_SLICE]\n",
    "    print(f\"\\n--- Step 2: Applying default selection rule ---\")\n",
    "    print(f\"Default rule '{DATE_SLICE}' selected {len(dates_to_process)} date(s):\")\n",
    "    print(dates_to_process)\n",
    "else:\n",
    "    dates_to_process = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: (OPTIONAL) Interactively Refine Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Continuing with the current value.\n"
     ]
    }
   ],
   "source": [
    "if available_dates:\n",
    "    # Call the interactive utility function\n",
    "    NEW_DATE_SLICE = utils.prompt_for_slice_update(\"DATE_SLICE\", DATE_SLICE)\n",
    "    \n",
    "    # If the slice was changed, update the list of dates to process\n",
    "    if NEW_DATE_SLICE != DATE_SLICE:\n",
    "        DATE_SLICE = NEW_DATE_SLICE\n",
    "        dates_to_process = available_dates[DATE_SLICE]\n",
    "        print(f\"\\nUpdated selection. Now processing {len(dates_to_process)} date(s):\")\n",
    "        print(dates_to_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Execute Pipeline\n",
    "\n",
    "This cell iterates through the final list of selected dates, generates the `config.py` file for each, and executes the `run_sequence.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 4: Starting processing sequence ---\n",
      "\n",
      "==================== PROCESSING DATE: 2025-09-25 ====================\n",
      "Successfully created config file: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\config.py\n",
      "Executing run_sequence_v2.py for 2025-09-25...\n",
      "Starting notebook execution sequence...\n",
      "\n",
      "--- Running py1_clean_df_finviz_v15.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py1_clean_df_finviz_v15.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\py1_clean_df_finviz_v15.ipynb\n",
      "Successfully executed py1_clean_df_finviz_v15.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py1_clean_df_finviz_v15.ipynb\n",
      "\n",
      "--- Running py2_clean_df_OHLCV_v12.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py2_clean_df_OHLCV_v12.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\py2_clean_df_OHLCV_v12.ipynb\n",
      "Successfully executed py2_clean_df_OHLCV_v12.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py2_clean_df_OHLCV_v12.ipynb\n",
      "\n",
      "--- Running py2_save_df_adj_close_v2.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py2_save_df_adj_close_v2.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\py2_save_df_adj_close_v2.ipynb\n",
      "Successfully executed py2_save_df_adj_close_v2.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py2_save_df_adj_close_v2.ipynb\n",
      "\n",
      "--- Running py3_calc_perf_ratios_v17.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py3_calc_perf_ratios_v17.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\py3_calc_perf_ratios_v17.ipynb\n",
      "Successfully executed py3_calc_perf_ratios_v17.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py3_calc_perf_ratios_v17.ipynb\n",
      "\n",
      "--- Running py4_append_ratios_v10.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py4_append_ratios_v10.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\py4_append_ratios_v10.ipynb\n",
      "Successfully executed py4_append_ratios_v10.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py4_append_ratios_v10.ipynb\n",
      "\n",
      "--- Running py5_append_columns_v8.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py5_append_columns_v8.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\py5_append_columns_v8.ipynb\n",
      "Successfully executed py5_append_columns_v8.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py5_append_columns_v8.ipynb\n",
      "\n",
      "--- Running py6_append_stats_history_v4.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py6_append_stats_history_v4.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\py6_append_stats_history_v4.ipynb\n",
      "Successfully executed py6_append_stats_history_v4.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py6_append_stats_history_v4.ipynb\n",
      "\n",
      "--- Running py6_view_market_sentiment_history_v1.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py6_view_market_sentiment_history_v1.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\py6_view_market_sentiment_history_v1.ipynb\n",
      "Successfully executed py6_view_market_sentiment_history_v1.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py6_view_market_sentiment_history_v1.ipynb\n",
      "\n",
      "--- Running py7_view_daily_market_snapshot_v0.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py7_view_daily_market_snapshot_v0.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\py7_view_daily_market_snapshot_v0.ipynb\n",
      "Successfully executed py7_view_daily_market_snapshot_v0.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py7_view_daily_market_snapshot_v0.ipynb\n",
      "\n",
      "--- Running py8_portf_picks_short_term_v6.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py8_portf_picks_short_term_v6.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\py8_portf_picks_short_term_v6.ipynb\n",
      "Successfully executed py8_portf_picks_short_term_v6.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py8_portf_picks_short_term_v6.ipynb\n",
      "\n",
      "--- Running py9_backtest_v3.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py9_backtest_v3.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\py9_backtest_v3.ipynb\n",
      "Successfully executed py9_backtest_v3.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py9_backtest_v3.ipynb\n",
      "\n",
      "--- Running py10_backtest_verification_v2.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py10_backtest_verification_v2.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\py10_backtest_verification_v2.ipynb\n",
      "Successfully executed py10_backtest_verification_v2.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py10_backtest_verification_v2.ipynb\n",
      "\n",
      "--- Running py90_interactive_backtest_v0.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\python.exe -m jupyter nbconvert --to notebook --execute --output C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py90_interactive_backtest_v0.ipynb C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\py90_interactive_backtest_v0.ipynb\n",
      "Successfully executed py90_interactive_backtest_v0.ipynb\n",
      "Output saved to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_mean_reversion\\executed\\executed_py90_interactive_backtest_v0.ipynb\n",
      "\n",
      "--- All notebooks executed successfully! ---\n",
      "--- Finished processing for 2025-09-25 ---\n",
      "\n",
      "========================= ALL PROCESSING COMPLETE =========================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Step 4: Starting processing sequence ---\")\n",
    "\n",
    "if not dates_to_process:\n",
    "    print(\"No dates to process. Halting execution.\")\n",
    "else:\n",
    "    for date_str in dates_to_process:\n",
    "        print(f\"\\n{'='*20} PROCESSING DATE: {date_str} {'='*20}\")\n",
    "        \n",
    "        # 1. Create the config.py file for the current date\n",
    "        utils.create_pipeline_config_file(\n",
    "            config_path=ROOT_DIR / 'config.py',\n",
    "            date_str=date_str,\n",
    "            downloads_dir=DOWNLOADS_DIR,\n",
    "            dest_dir=DEST_DIR,\n",
    "            annual_risk_free_rate=ANNUAL_RISK_FREE_RATE,\n",
    "            trading_days_per_year=TRADING_DAYS_PER_YEAR\n",
    "        )\n",
    "\n",
    "        # --- 2. Run the external processing script ---\n",
    "        print(f\"Executing run_sequence_v2.py for {date_str}...\")\n",
    "\n",
    "        # First, create a clear variable for the full path\n",
    "        script_to_run = ROOT_DIR / 'run_sequence_v2.py'\n",
    "\n",
    "        # Now, the f-string is simple and has no quote conflicts\n",
    "        get_ipython().run_line_magic('run', f'-i \"{script_to_run}\"')\n",
    "\n",
    "        print(f\"--- Finished processing for {date_str} ---\")\n",
    "\n",
    "    print(f\"\\n{'='*25} ALL PROCESSING COMPLETE {'='*25}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
