{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidate Yloader OHLCV Data\n",
    "\n",
    "This notebook reads all individual ticker `.csv` files generated by the `Yloader` application, combines them into a single, analysis-ready DataFrame, and saves it in the efficient Parquet format.\n",
    "\n",
    "**Workflow:**\n",
    "\n",
    "1.  **Prerequisite:** Run `Yloader` to download OHLCV data. This should create multiple `.csv` files (e.g., `AAPL.csv`, `GOOG.csv`) in a dedicated directory.\n",
    "2.  **Process & Combine:** The notebook scans the source directory, reads each CSV, and consolidates them into a single pandas DataFrame with a `(Ticker, Date)` MultiIndex.\n",
    "3.  **Save:** The final DataFrame is saved as a single `.parquet` file for fast loading in subsequent analysis notebooks.\n",
    "4.  **Verify:** The saved Parquet file is read back to confirm its integrity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and Configuration\n",
    "\n",
    "**This is the only cell you need to modify.** Adjust the paths and column definitions below to match your project structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Root Directory set to: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\n",
      "Reading Yloader CSVs from: C:\\Users\\ping\\Desktop\\yloader\n",
      "Ticker OHLCV output will be saved to: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet\n",
      "Indices Output will be saved to: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_indices.parquet\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "# 1. Set the directory where your Yloader CSV files are located.\n",
    "#    This uses Path.home() to be portable across different computers and OS.\n",
    "YLOADER_DATA_DIR = Path.home() / \"Desktop\" / \"yloader\"\n",
    "\n",
    "# 2. Define the destination path for the final combined Parquet file.\n",
    "#    It's good practice to save data outputs within the project's data folder.\n",
    "#    Assuming a project structure where this notebook is in a `notebooks` subdir.\n",
    "# ROOT_DIR = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "# DESTINATION_PARQUET_PATH = ROOT_DIR / \"data\" / \"df_OHLCV_stocks_etfs.parquet\"\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "ROOT_DIR = NOTEBOOK_DIR.parent\n",
    "SRC_DIR = ROOT_DIR / \"src\"\n",
    "if str(ROOT_DIR) not in sys.path:\n",
    "    sys.path.append(str(ROOT_DIR))\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.append(str(SRC_DIR))\n",
    "DESTINATION_PARQUET_PATH_OHLCV = ROOT_DIR / \"data\" / \"df_OHLCV_stocks_etfs.parquet\"\n",
    "DESTINATION_PARQUET_PATH_INDICES = ROOT_DIR / \"data\" / \"df_indices.parquet\"\n",
    "\n",
    "# 3. Define the column names for the CSV files.\n",
    "#    Assumes CSVs have no header and columns are in this fixed order.\n",
    "#    The first column is always assumed to be 'Date'.\n",
    "CANONICAL_COLUMN_NAMES = [\"Adj Open\", \"Adj High\", \"Adj Low\", \"Adj Close\", \"Volume\"]\n",
    "\n",
    "# --- Verification ---\n",
    "print(f\"Project Root Directory set to: {ROOT_DIR}\")\n",
    "print(f\"Reading Yloader CSVs from: {YLOADER_DATA_DIR}\")\n",
    "print(f\"Ticker OHLCV output will be saved to: {DESTINATION_PARQUET_PATH_OHLCV}\")\n",
    "print(f\"Indices Output will be saved to: {DESTINATION_PARQUET_PATH_INDICES}\")\n",
    "\n",
    "# Set pandas display options for better readability\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Process and Combine CSV Data\n",
    "\n",
    "This cell defines and executes the core logic to read all individual CSV files and merge them into a single, multi-indexed DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Optional\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def process_yloader_csvs(\n",
    "    data_dir: Path,\n",
    "    canonical_cols: List[str],\n",
    "    anchor_ticker: str = \"SPY\",\n",
    ") -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Reads and combines CSV files from the Yloader output directory whose\n",
    "    modification *date* (ignoring time-of-day) matches that of the specified\n",
    "    anchor ticker file.\n",
    "\n",
    "    Args:\n",
    "        data_dir (Path):\n",
    "            Directory containing the Yloader CSV files.\n",
    "        canonical_cols (List[str]):\n",
    "            Expected data column names, **excluding** 'Date'.\n",
    "        anchor_ticker (str, optional):\n",
    "            Ticker whose modification date is used as the reference.\n",
    "            Defaults to \"SPY\".\n",
    "\n",
    "    Returns:\n",
    "        Optional[pd.DataFrame]:\n",
    "            A sorted, multi-indexed DataFrame (Ticker, Date) or None if\n",
    "            no data could be processed.\n",
    "    \"\"\"\n",
    "    if not data_dir.is_dir():\n",
    "        print(f\"Error: Directory not found: {data_dir}\")\n",
    "        return None\n",
    "\n",
    "    # ------------------------------------------------------------------ #\n",
    "    # 1. Determine the reference date (modification date of anchor file) #\n",
    "    # ------------------------------------------------------------------ #\n",
    "    anchor_file = data_dir / f\"{anchor_ticker.upper()}.csv\"\n",
    "    if not anchor_file.exists():\n",
    "        print(f\"Anchor file not found: {anchor_file}\")\n",
    "        return None\n",
    "\n",
    "    anchor_date = datetime.fromtimestamp(anchor_file.stat().st_mtime).date()\n",
    "    print(f\"\\nProcess csv files with this date: {anchor_date}\")\n",
    "\n",
    "    # ---------------------------------------------------------- #\n",
    "    # 2. Collect CSV files whose modification date matches anchor #\n",
    "    # ---------------------------------------------------------- #\n",
    "    csv_files = [\n",
    "        f\n",
    "        for f in data_dir.glob(\"*.csv\")\n",
    "        if datetime.fromtimestamp(f.stat().st_mtime).date() == anchor_date\n",
    "    ]\n",
    "\n",
    "    if not csv_files:\n",
    "        print(f\"No CSV files found with the same modification date as {anchor_ticker}.\")\n",
    "        return None\n",
    "\n",
    "    print(\n",
    "        f\"Found {len(csv_files)} CSV files with modification date \"\n",
    "        f\"{anchor_date} (anchor: {anchor_ticker})...\"\n",
    "    )\n",
    "\n",
    "    # ---------------------------------------------------------- #\n",
    "    # 3. Load and combine the matching files                     #\n",
    "    # ---------------------------------------------------------- #\n",
    "    all_dataframes = []\n",
    "    tickers_list = []\n",
    "    expected_csv_cols = [\"Date\"] + canonical_cols\n",
    "\n",
    "    for file_path in csv_files:\n",
    "        ticker = file_path.stem\n",
    "        try:\n",
    "            df_temp = pd.read_csv(\n",
    "                file_path,\n",
    "                header=None,\n",
    "                names=expected_csv_cols,\n",
    "                parse_dates=[\"Date\"],\n",
    "                index_col=\"Date\",\n",
    "            )\n",
    "\n",
    "            if df_temp.empty:\n",
    "                print(f\"Warning: File {file_path.name} is empty. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            all_dataframes.append(df_temp)\n",
    "            tickers_list.append(ticker)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path.name}: {e}. Skipping.\")\n",
    "\n",
    "    if not all_dataframes:\n",
    "        print(\"No data was successfully loaded. Aborting.\")\n",
    "        return None\n",
    "\n",
    "    multi_index_df = pd.concat(\n",
    "        all_dataframes, keys=tickers_list, names=[\"Ticker\", \"Date\"]\n",
    "    )\n",
    "    multi_index_df.sort_index(\n",
    "        level=[\"Ticker\", \"Date\"], ascending=[True, False], inplace=True\n",
    "    )\n",
    "\n",
    "    print(\"\\nCSV processing complete. DataFrame created successfully.\")\n",
    "    return multi_index_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Execute Step 1 ---\n",
    "# final_df = process_yloader_csvs(YLOADER_DATA_DIR, CANONICAL_COLUMN_NAMES)\n",
    "\n",
    "# if final_df is not None:\n",
    "#     # chronological sort final_df\n",
    "#     if not final_df.index.is_monotonic_increasing:\n",
    "#         print(f'\\nsorting final_df chronologically ...')\n",
    "#         final_df.sort_index(inplace=True)\n",
    "#     else:\n",
    "#         print(f'\\nfinal_df is sorted chronologically')\n",
    "\n",
    "#     print(\"\\n--- DataFrame Info ---\")\n",
    "#     final_df.info()\n",
    "\n",
    "#     print(\"\\n--- First 5 Rows of Combined DataFrame ---\")\n",
    "#     display(final_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Save DataFrame to Parquet File\n",
    "\n",
    "This step saves the combined DataFrame to a Parquet file, which is highly efficient for storage and subsequent loading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Process csv files with this date: 2025-12-29\n",
      "Found 1603 CSV files with modification date 2025-12-29 (anchor: SPY)...\n",
      "\n",
      "CSV processing complete. DataFrame created successfully.\n",
      "\n",
      "Sorting combined DataFrame chronologically...\n",
      "\n",
      "--- Combined DataFrame Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 9620322 entries, ('A', Timestamp('1999-11-18 00:00:00')) to ('^VIX3M', Timestamp('2025-12-29 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   Adj Open   float64\n",
      " 1   Adj High   float64\n",
      " 2   Adj Low    float64\n",
      " 3   Adj Close  float64\n",
      " 4   Volume     int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 404.3+ MB\n",
      "\n",
      "Separating indices from regular tickers...\n",
      "Separation complete: 9,484,759 regular rows, 135,563 index rows.\n",
      "\n",
      "Releasing memory from combined DataFrame...\n",
      "Successfully saved to: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet\n",
      "Successfully saved to: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_indices.parquet\n",
      "\n",
      "--- Preview: Regular Tickers (df_OHLCV) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Adj Open</th>\n",
       "      <th>Adj High</th>\n",
       "      <th>Adj Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ZWS</th>\n",
       "      <th>2025-12-24</th>\n",
       "      <td>47.91</td>\n",
       "      <td>48.1900</td>\n",
       "      <td>47.72</td>\n",
       "      <td>47.95</td>\n",
       "      <td>262000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-26</th>\n",
       "      <td>47.84</td>\n",
       "      <td>48.1700</td>\n",
       "      <td>47.61</td>\n",
       "      <td>47.84</td>\n",
       "      <td>351200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-29</th>\n",
       "      <td>47.94</td>\n",
       "      <td>48.1738</td>\n",
       "      <td>47.69</td>\n",
       "      <td>47.77</td>\n",
       "      <td>371555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Adj Open  Adj High  Adj Low  Adj Close  Volume\n",
       "Ticker Date                                                      \n",
       "ZWS    2025-12-24     47.91   48.1900    47.72      47.95  262000\n",
       "       2025-12-26     47.84   48.1700    47.61      47.84  351200\n",
       "       2025-12-29     47.94   48.1738    47.69      47.77  371555"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preview: Indices (df_indices) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Adj Open</th>\n",
       "      <th>Adj High</th>\n",
       "      <th>Adj Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">^VIX3M</th>\n",
       "      <th>2025-12-24</th>\n",
       "      <td>17.93</td>\n",
       "      <td>17.93</td>\n",
       "      <td>17.63</td>\n",
       "      <td>17.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-26</th>\n",
       "      <td>17.93</td>\n",
       "      <td>18.05</td>\n",
       "      <td>17.71</td>\n",
       "      <td>17.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-29</th>\n",
       "      <td>18.26</td>\n",
       "      <td>18.29</td>\n",
       "      <td>17.65</td>\n",
       "      <td>17.82</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Adj Open  Adj High  Adj Low  Adj Close  Volume\n",
       "Ticker Date                                                      \n",
       "^VIX3M 2025-12-24     17.93     17.93    17.63      17.77       0\n",
       "       2025-12-26     17.93     18.05    17.71      17.77       0\n",
       "       2025-12-29     18.26     18.29    17.65      17.82       0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "# ==========================================\n",
    "# Helper Functions\n",
    "# ==========================================\n",
    "\n",
    "\n",
    "def separate_indices_from_tickers(\n",
    "    df: pd.DataFrame,\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Efficiently splits a MultiIndex DataFrame into two:\n",
    "    1. Regular tickers\n",
    "    2. Indices (tickers starting with '^')\n",
    "\n",
    "    Uses underlying MultiIndex codes for O(N_unique) performance instead of O(N_rows).\n",
    "    \"\"\"\n",
    "    if df is None or df.empty:\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    print(\"\\nSeparating indices from regular tickers...\")\n",
    "\n",
    "    # 1. Access underlying structure\n",
    "    # levels: unique strings, codes: integer map to those strings\n",
    "    levels = df.index.levels[0]\n",
    "    codes = df.index.codes[0]\n",
    "\n",
    "    # 2. Identify unique index tickers (vectorized string op on small array)\n",
    "    is_index_ticker = levels.str.startswith(\"^\")\n",
    "\n",
    "    # 3. Create boolean mask using integer codes (fast integer comparison)\n",
    "    target_codes = np.where(is_index_ticker)[0]\n",
    "    mask = np.isin(codes, target_codes)\n",
    "\n",
    "    # 4. Split and Copy\n",
    "    # We use copy() so the new DFs own their data, allowing garbage collection of the original\n",
    "    df_indices = df.loc[mask].copy()\n",
    "    df_OHLCV = df.loc[~mask].copy()\n",
    "\n",
    "    # 5. Clean up metadata\n",
    "    # Remove unused levels so df_OHLCV doesn't carry metadata about '^VIX', etc.\n",
    "    df_indices.index = df_indices.index.remove_unused_levels()\n",
    "    df_OHLCV.index = df_OHLCV.index.remove_unused_levels()\n",
    "\n",
    "    print(\n",
    "        f\"Separation complete: {len(df_OHLCV):,} regular rows, {len(df_indices):,} index rows.\"\n",
    "    )\n",
    "    return df_OHLCV, df_indices\n",
    "\n",
    "\n",
    "def save_dataframe_to_parquet(df: Optional[pd.DataFrame], dest_path: Path):\n",
    "    \"\"\"\n",
    "    Saves a DataFrame to a Parquet file using pyarrow/zstd.\n",
    "    \"\"\"\n",
    "    if df is None or df.empty:\n",
    "        print(f\"Skipping save: DataFrame for {dest_path.name} is empty or None.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        dest_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df.to_parquet(dest_path, engine=\"pyarrow\", compression=\"zstd\", index=True)\n",
    "        print(f\"Successfully saved to: {dest_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving {dest_path}: {e}\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# Main Execution\n",
    "# ==========================================\n",
    "\n",
    "# 1. Load Data\n",
    "final_df = process_yloader_csvs(YLOADER_DATA_DIR, CANONICAL_COLUMN_NAMES)\n",
    "\n",
    "if final_df is not None and not final_df.empty:\n",
    "\n",
    "    # 2. Sort Chronologically (Optimization: Sort once before splitting)\n",
    "    if not final_df.index.is_monotonic_increasing:\n",
    "        print(f\"\\nSorting combined DataFrame chronologically...\")\n",
    "        final_df.sort_index(inplace=True)\n",
    "    else:\n",
    "        print(f\"\\nCombined DataFrame is already sorted.\")\n",
    "\n",
    "    print(\"\\n--- Combined DataFrame Info ---\")\n",
    "    final_df.info()\n",
    "\n",
    "    # 3. Split DataFrames\n",
    "    df_OHLCV, df_indices = separate_indices_from_tickers(final_df)\n",
    "\n",
    "    # 4. Memory Cleanup\n",
    "    # Critical for large datasets: delete the massive original DF and force GC\n",
    "    print(\"\\nReleasing memory from combined DataFrame...\")\n",
    "    del final_df\n",
    "    gc.collect()\n",
    "\n",
    "    # 5. Save Outputs\n",
    "    save_dataframe_to_parquet(df_OHLCV, DESTINATION_PARQUET_PATH_OHLCV)\n",
    "    save_dataframe_to_parquet(df_indices, DESTINATION_PARQUET_PATH_INDICES)\n",
    "\n",
    "    # Display preview (using display if in Jupyter, else print)\n",
    "    try:\n",
    "        print(\"\\n--- Preview: Regular Tickers (df_OHLCV) ---\")\n",
    "        display(df_OHLCV.tail(3))\n",
    "        print(\"\\n--- Preview: Indices (df_indices) ---\")\n",
    "        display(df_indices.tail(3))\n",
    "    except NameError:\n",
    "        print(df_OHLCV.tail(3))\n",
    "        print(df_indices.tail(3))\n",
    "\n",
    "else:\n",
    "    print(\"No data loaded from process_yloader_csvs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Verify the Saved File (Optional)\n",
    "\n",
    "This final step reads the Parquet file back into a new DataFrame to ensure the data was saved correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Verifying the saved file at: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet ---\n",
      "Verification successful! File read back into memory.\n",
      "\n",
      "--- First 5 Rows of Verified DataFrame ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Adj Open</th>\n",
       "      <th>Adj High</th>\n",
       "      <th>Adj Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">A</th>\n",
       "      <th>1999-11-18</th>\n",
       "      <td>27.2452</td>\n",
       "      <td>29.9398</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>26.3470</td>\n",
       "      <td>74716417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-19</th>\n",
       "      <td>25.7108</td>\n",
       "      <td>25.7482</td>\n",
       "      <td>23.8396</td>\n",
       "      <td>24.1764</td>\n",
       "      <td>18198352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-22</th>\n",
       "      <td>24.7378</td>\n",
       "      <td>26.3470</td>\n",
       "      <td>23.9893</td>\n",
       "      <td>26.3470</td>\n",
       "      <td>7857766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-23</th>\n",
       "      <td>25.4488</td>\n",
       "      <td>26.1225</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>7138321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-24</th>\n",
       "      <td>24.0267</td>\n",
       "      <td>25.1120</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>24.5881</td>\n",
       "      <td>5785608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Adj Open  Adj High  Adj Low  Adj Close    Volume\n",
       "Ticker Date                                                        \n",
       "A      1999-11-18   27.2452   29.9398  23.9518    26.3470  74716417\n",
       "       1999-11-19   25.7108   25.7482  23.8396    24.1764  18198352\n",
       "       1999-11-22   24.7378   26.3470  23.9893    26.3470   7857766\n",
       "       1999-11-23   25.4488   26.1225  23.9518    23.9518   7138321\n",
       "       1999-11-24   24.0267   25.1120  23.9518    24.5881   5785608"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data for first available ticker 'A' ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Open</th>\n",
       "      <th>Adj High</th>\n",
       "      <th>Adj Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999-11-18</th>\n",
       "      <td>27.2452</td>\n",
       "      <td>29.9398</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>26.3470</td>\n",
       "      <td>74716417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-19</th>\n",
       "      <td>25.7108</td>\n",
       "      <td>25.7482</td>\n",
       "      <td>23.8396</td>\n",
       "      <td>24.1764</td>\n",
       "      <td>18198352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-22</th>\n",
       "      <td>24.7378</td>\n",
       "      <td>26.3470</td>\n",
       "      <td>23.9893</td>\n",
       "      <td>26.3470</td>\n",
       "      <td>7857766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-23</th>\n",
       "      <td>25.4488</td>\n",
       "      <td>26.1225</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>7138321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-24</th>\n",
       "      <td>24.0267</td>\n",
       "      <td>25.1120</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>24.5881</td>\n",
       "      <td>5785608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Adj Open  Adj High  Adj Low  Adj Close    Volume\n",
       "Date                                                        \n",
       "1999-11-18   27.2452   29.9398  23.9518    26.3470  74716417\n",
       "1999-11-19   25.7108   25.7482  23.8396    24.1764  18198352\n",
       "1999-11-22   24.7378   26.3470  23.9893    26.3470   7857766\n",
       "1999-11-23   25.4488   26.1225  23.9518    23.9518   7138321\n",
       "1999-11-24   24.0267   25.1120  23.9518    24.5881   5785608"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"--- Verifying the saved file at: {DESTINATION_PARQUET_PATH_OHLCV} ---\")\n",
    "\n",
    "try:\n",
    "    if DESTINATION_PARQUET_PATH_OHLCV.exists():\n",
    "        verified_df = pd.read_parquet(DESTINATION_PARQUET_PATH_OHLCV)\n",
    "        print(\"Verification successful! File read back into memory.\")\n",
    "\n",
    "        print(\"\\n--- First 5 Rows of Verified DataFrame ---\")\n",
    "        display(verified_df.head())\n",
    "\n",
    "        # Optional: Check a specific ticker\n",
    "        if not verified_df.empty:\n",
    "            example_ticker = verified_df.index.get_level_values(\"Ticker\")[0]\n",
    "            print(f\"\\n--- Data for first available ticker '{example_ticker}' ---\")\n",
    "            display(verified_df.loc[example_ticker].head())\n",
    "\n",
    "    else:\n",
    "        print(\"Error: The output file was not found at the specified path.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during verification: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Open</th>\n",
       "      <th>Adj High</th>\n",
       "      <th>Adj Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-12-12</th>\n",
       "      <td>0.098390</td>\n",
       "      <td>0.098817</td>\n",
       "      <td>0.098390</td>\n",
       "      <td>0.098390</td>\n",
       "      <td>611849325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-15</th>\n",
       "      <td>0.093684</td>\n",
       "      <td>0.093684</td>\n",
       "      <td>0.093256</td>\n",
       "      <td>0.093256</td>\n",
       "      <td>229439776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-16</th>\n",
       "      <td>0.086839</td>\n",
       "      <td>0.086839</td>\n",
       "      <td>0.086412</td>\n",
       "      <td>0.086412</td>\n",
       "      <td>137921067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-17</th>\n",
       "      <td>0.088550</td>\n",
       "      <td>0.088978</td>\n",
       "      <td>0.088550</td>\n",
       "      <td>0.088550</td>\n",
       "      <td>112762114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-18</th>\n",
       "      <td>0.091118</td>\n",
       "      <td>0.091545</td>\n",
       "      <td>0.091118</td>\n",
       "      <td>0.091118</td>\n",
       "      <td>95814196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-22</th>\n",
       "      <td>272.860000</td>\n",
       "      <td>273.880000</td>\n",
       "      <td>270.510000</td>\n",
       "      <td>270.970000</td>\n",
       "      <td>36571800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-23</th>\n",
       "      <td>270.840000</td>\n",
       "      <td>272.500000</td>\n",
       "      <td>269.560000</td>\n",
       "      <td>272.360000</td>\n",
       "      <td>29642000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-24</th>\n",
       "      <td>272.340000</td>\n",
       "      <td>275.430000</td>\n",
       "      <td>272.200000</td>\n",
       "      <td>273.810000</td>\n",
       "      <td>17910600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-26</th>\n",
       "      <td>274.160000</td>\n",
       "      <td>275.370000</td>\n",
       "      <td>272.860000</td>\n",
       "      <td>273.400000</td>\n",
       "      <td>21455300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-29</th>\n",
       "      <td>274.230000</td>\n",
       "      <td>274.360000</td>\n",
       "      <td>272.350000</td>\n",
       "      <td>273.760000</td>\n",
       "      <td>23399554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11353 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Adj Open    Adj High     Adj Low   Adj Close     Volume\n",
       "Date                                                                 \n",
       "1980-12-12    0.098390    0.098817    0.098390    0.098390  611849325\n",
       "1980-12-15    0.093684    0.093684    0.093256    0.093256  229439776\n",
       "1980-12-16    0.086839    0.086839    0.086412    0.086412  137921067\n",
       "1980-12-17    0.088550    0.088978    0.088550    0.088550  112762114\n",
       "1980-12-18    0.091118    0.091545    0.091118    0.091118   95814196\n",
       "...                ...         ...         ...         ...        ...\n",
       "2025-12-22  272.860000  273.880000  270.510000  270.970000   36571800\n",
       "2025-12-23  270.840000  272.500000  269.560000  272.360000   29642000\n",
       "2025-12-24  272.340000  275.430000  272.200000  273.810000   17910600\n",
       "2025-12-26  274.160000  275.370000  272.860000  273.400000   21455300\n",
       "2025-12-29  274.230000  274.360000  272.350000  273.760000   23399554\n",
       "\n",
       "[11353 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verified_df.loc[\"AAPL\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#################  \n",
    "#################  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
