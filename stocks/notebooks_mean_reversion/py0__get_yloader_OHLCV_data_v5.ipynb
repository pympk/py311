{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidate Yloader OHLCV Data\n",
    "\n",
    "This notebook reads all individual ticker `.csv` files generated by the `Yloader` application, combines them into a single, analysis-ready DataFrame, and saves it in the efficient Parquet format.\n",
    "\n",
    "**Workflow:**\n",
    "\n",
    "1.  **Prerequisite:** Run `Yloader` to download OHLCV data. This should create multiple `.csv` files (e.g., `AAPL.csv`, `GOOG.csv`) in a dedicated directory.\n",
    "2.  **Process & Combine:** The notebook scans the source directory, reads each CSV, and consolidates them into a single pandas DataFrame with a `(Ticker, Date)` MultiIndex.\n",
    "3.  **Save:** The final DataFrame is saved as a single `.parquet` file for fast loading in subsequent analysis notebooks.\n",
    "4.  **Verify:** The saved Parquet file is read back to confirm its integrity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and Configuration\n",
    "\n",
    "**This is the only cell you need to modify.** Adjust the paths and column definitions below to match your project structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Root Directory set to: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\n",
      "Reading Yloader CSVs from: C:\\Users\\ping\\Desktop\\yloader\n",
      "Ticker OHLCV output will be saved to: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet\n",
      "Indices Output will be saved to: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_indices.parquet\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "# 1. Set the directory where your Yloader CSV files are located.\n",
    "#    This uses Path.home() to be portable across different computers and OS.\n",
    "YLOADER_DATA_DIR = Path.home() / \"Desktop\" / \"yloader\"\n",
    "\n",
    "# 2. Define the destination path for the final combined Parquet file.\n",
    "#    It's good practice to save data outputs within the project's data folder.\n",
    "#    Assuming a project structure where this notebook is in a `notebooks` subdir.\n",
    "# ROOT_DIR = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "# DESTINATION_PARQUET_PATH = ROOT_DIR / \"data\" / \"df_OHLCV_stocks_etfs.parquet\"\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "ROOT_DIR = NOTEBOOK_DIR.parent\n",
    "SRC_DIR = ROOT_DIR / \"src\"\n",
    "if str(ROOT_DIR) not in sys.path:\n",
    "    sys.path.append(str(ROOT_DIR))\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.append(str(SRC_DIR))\n",
    "DESTINATION_PARQUET_PATH_OHLCV = ROOT_DIR / \"data\" / \"df_OHLCV_stocks_etfs.parquet\"\n",
    "DESTINATION_PARQUET_PATH_INDICES = ROOT_DIR / \"data\" / \"df_indices.parquet\"\n",
    "\n",
    "# 3. Define the column names for the CSV files.\n",
    "#    Assumes CSVs have no header and columns are in this fixed order.\n",
    "#    The first column is always assumed to be 'Date'.\n",
    "CANONICAL_COLUMN_NAMES = [\"Adj Open\", \"Adj High\", \"Adj Low\", \"Adj Close\", \"Volume\"]\n",
    "\n",
    "# --- Verification ---\n",
    "print(f\"Project Root Directory set to: {ROOT_DIR}\")\n",
    "print(f\"Reading Yloader CSVs from: {YLOADER_DATA_DIR}\")\n",
    "print(f\"Ticker OHLCV output will be saved to: {DESTINATION_PARQUET_PATH_OHLCV}\")\n",
    "print(f\"Indices Output will be saved to: {DESTINATION_PARQUET_PATH_INDICES}\")\n",
    "\n",
    "# Set pandas display options for better readability\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Process and Combine CSV Data\n",
    "\n",
    "This cell defines and executes the core logic to read all individual CSV files and merge them into a single, multi-indexed DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Optional\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def process_yloader_csvs(\n",
    "    data_dir: Path,\n",
    "    canonical_cols: List[str],\n",
    "    anchor_ticker: str = \"SPY\",\n",
    ") -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Reads and combines CSV files from the Yloader output directory whose\n",
    "    modification *date* (ignoring time-of-day) matches that of the specified\n",
    "    anchor ticker file.\n",
    "\n",
    "    Args:\n",
    "        data_dir (Path):\n",
    "            Directory containing the Yloader CSV files.\n",
    "        canonical_cols (List[str]):\n",
    "            Expected data column names, **excluding** 'Date'.\n",
    "        anchor_ticker (str, optional):\n",
    "            Ticker whose modification date is used as the reference.\n",
    "            Defaults to \"SPY\".\n",
    "\n",
    "    Returns:\n",
    "        Optional[pd.DataFrame]:\n",
    "            A sorted, multi-indexed DataFrame (Ticker, Date) or None if\n",
    "            no data could be processed.\n",
    "    \"\"\"\n",
    "    if not data_dir.is_dir():\n",
    "        print(f\"Error: Directory not found: {data_dir}\")\n",
    "        return None\n",
    "\n",
    "    # ------------------------------------------------------------------ #\n",
    "    # 1. Determine the reference date (modification date of anchor file) #\n",
    "    # ------------------------------------------------------------------ #\n",
    "    anchor_file = data_dir / f\"{anchor_ticker.upper()}.csv\"\n",
    "    if not anchor_file.exists():\n",
    "        print(f\"Anchor file not found: {anchor_file}\")\n",
    "        return None\n",
    "\n",
    "    anchor_date = datetime.fromtimestamp(anchor_file.stat().st_mtime).date()\n",
    "    print(f\"\\nProcess csv files with this date: {anchor_date}\")\n",
    "\n",
    "    # ---------------------------------------------------------- #\n",
    "    # 2. Collect CSV files whose modification date matches anchor #\n",
    "    # ---------------------------------------------------------- #\n",
    "    csv_files = [\n",
    "        f\n",
    "        for f in data_dir.glob(\"*.csv\")\n",
    "        if datetime.fromtimestamp(f.stat().st_mtime).date() == anchor_date\n",
    "    ]\n",
    "\n",
    "    if not csv_files:\n",
    "        print(f\"No CSV files found with the same modification date as {anchor_ticker}.\")\n",
    "        return None\n",
    "\n",
    "    print(\n",
    "        f\"Found {len(csv_files)} CSV files with modification date \"\n",
    "        f\"{anchor_date} (anchor: {anchor_ticker})...\"\n",
    "    )\n",
    "\n",
    "    # ---------------------------------------------------------- #\n",
    "    # 3. Load and combine the matching files                     #\n",
    "    # ---------------------------------------------------------- #\n",
    "    all_dataframes = []\n",
    "    tickers_list = []\n",
    "    expected_csv_cols = [\"Date\"] + canonical_cols\n",
    "\n",
    "    for file_path in csv_files:\n",
    "        ticker = file_path.stem\n",
    "        try:\n",
    "            df_temp = pd.read_csv(\n",
    "                file_path,\n",
    "                header=None,\n",
    "                names=expected_csv_cols,\n",
    "                parse_dates=[\"Date\"],\n",
    "                index_col=\"Date\",\n",
    "            )\n",
    "\n",
    "            if df_temp.empty:\n",
    "                print(f\"Warning: File {file_path.name} is empty. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            all_dataframes.append(df_temp)\n",
    "            tickers_list.append(ticker)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path.name}: {e}. Skipping.\")\n",
    "\n",
    "    if not all_dataframes:\n",
    "        print(\"No data was successfully loaded. Aborting.\")\n",
    "        return None\n",
    "\n",
    "    multi_index_df = pd.concat(\n",
    "        all_dataframes, keys=tickers_list, names=[\"Ticker\", \"Date\"]\n",
    "    )\n",
    "    multi_index_df.sort_index(\n",
    "        level=[\"Ticker\", \"Date\"], ascending=[True, False], inplace=True\n",
    "    )\n",
    "\n",
    "    print(\"\\nCSV processing complete. DataFrame created successfully.\")\n",
    "    return multi_index_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Execute Step 1 ---\n",
    "# final_df = process_yloader_csvs(YLOADER_DATA_DIR, CANONICAL_COLUMN_NAMES)\n",
    "\n",
    "# if final_df is not None:\n",
    "#     # chronological sort final_df\n",
    "#     if not final_df.index.is_monotonic_increasing:\n",
    "#         print(f'\\nsorting final_df chronologically ...')\n",
    "#         final_df.sort_index(inplace=True)\n",
    "#     else:\n",
    "#         print(f'\\nfinal_df is sorted chronologically')\n",
    "\n",
    "#     print(\"\\n--- DataFrame Info ---\")\n",
    "#     final_df.info()\n",
    "\n",
    "#     print(\"\\n--- First 5 Rows of Combined DataFrame ---\")\n",
    "#     display(final_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Save DataFrame to Parquet File\n",
    "\n",
    "This step saves the combined DataFrame to a Parquet file, which is highly efficient for storage and subsequent loading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Takes about 2.5 minutes to run ====\n",
      "\n",
      "Process csv files with this date: 2026-02-13\n",
      "Found 1598 CSV files with modification date 2026-02-13 (anchor: SPY)...\n",
      "\n",
      "CSV processing complete. DataFrame created successfully.\n",
      "\n",
      "Sorting combined DataFrame chronologically...\n",
      "\n",
      "--- Combined DataFrame Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 9642919 entries, ('A', Timestamp('1999-11-18 00:00:00')) to ('^VIX3M', Timestamp('2026-02-13 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   Adj Open   float64\n",
      " 1   Adj High   float64\n",
      " 2   Adj Low    float64\n",
      " 3   Adj Close  float64\n",
      " 4   Volume     int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 405.3+ MB\n",
      "\n",
      "Separating indices from regular tickers...\n",
      "Separation complete: 9,498,767 regular rows, 144,152 index rows.\n",
      "\n",
      "Releasing memory from combined DataFrame...\n",
      "Successfully saved to: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet\n",
      "Successfully saved to: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_indices.parquet\n",
      "\n",
      "--- Preview: Regular Tickers (df_OHLCV) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Adj Open</th>\n",
       "      <th>Adj High</th>\n",
       "      <th>Adj Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ZWS</th>\n",
       "      <th>2026-02-11</th>\n",
       "      <td>52.17</td>\n",
       "      <td>52.54</td>\n",
       "      <td>51.06</td>\n",
       "      <td>51.55</td>\n",
       "      <td>863900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-02-12</th>\n",
       "      <td>52.58</td>\n",
       "      <td>53.17</td>\n",
       "      <td>51.17</td>\n",
       "      <td>51.38</td>\n",
       "      <td>956200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-02-13</th>\n",
       "      <td>51.24</td>\n",
       "      <td>51.57</td>\n",
       "      <td>50.72</td>\n",
       "      <td>51.30</td>\n",
       "      <td>568686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Adj Open  Adj High  Adj Low  Adj Close  Volume\n",
       "Ticker Date                                                      \n",
       "ZWS    2026-02-11     52.17     52.54    51.06      51.55  863900\n",
       "       2026-02-12     52.58     53.17    51.17      51.38  956200\n",
       "       2026-02-13     51.24     51.57    50.72      51.30  568686"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preview: Indices (df_indices) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Adj Open</th>\n",
       "      <th>Adj High</th>\n",
       "      <th>Adj Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">^VIX3M</th>\n",
       "      <th>2026-02-11</th>\n",
       "      <td>19.93</td>\n",
       "      <td>20.99</td>\n",
       "      <td>19.90</td>\n",
       "      <td>20.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-02-12</th>\n",
       "      <td>20.19</td>\n",
       "      <td>22.35</td>\n",
       "      <td>20.03</td>\n",
       "      <td>22.17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-02-13</th>\n",
       "      <td>22.24</td>\n",
       "      <td>23.01</td>\n",
       "      <td>21.06</td>\n",
       "      <td>22.17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Adj Open  Adj High  Adj Low  Adj Close  Volume\n",
       "Ticker Date                                                      \n",
       "^VIX3M 2026-02-11     19.93     20.99    19.90      20.37       0\n",
       "       2026-02-12     20.19     22.35    20.03      22.17       0\n",
       "       2026-02-13     22.24     23.01    21.06      22.17       0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "# ==========================================\n",
    "# Helper Functions\n",
    "# ==========================================\n",
    "\n",
    "\n",
    "def separate_indices_from_tickers(\n",
    "    df: pd.DataFrame,\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Efficiently splits a MultiIndex DataFrame into two:\n",
    "    1. Regular tickers\n",
    "    2. Indices (tickers starting with '^')\n",
    "\n",
    "    Uses underlying MultiIndex codes for O(N_unique) performance instead of O(N_rows).\n",
    "    \"\"\"\n",
    "    if df is None or df.empty:\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    print(\"\\nSeparating indices from regular tickers...\")\n",
    "\n",
    "    # 1. Access underlying structure\n",
    "    # levels: unique strings, codes: integer map to those strings\n",
    "    levels = df.index.levels[0]\n",
    "    codes = df.index.codes[0]\n",
    "\n",
    "    # 2. Identify unique index tickers (vectorized string op on small array)\n",
    "    is_index_ticker = levels.str.startswith(\"^\")\n",
    "\n",
    "    # 3. Create boolean mask using integer codes (fast integer comparison)\n",
    "    target_codes = np.where(is_index_ticker)[0]\n",
    "    mask = np.isin(codes, target_codes)\n",
    "\n",
    "    # 4. Split and Copy\n",
    "    # We use copy() so the new DFs own their data, allowing garbage collection of the original\n",
    "    df_indices = df.loc[mask].copy()\n",
    "    df_OHLCV = df.loc[~mask].copy()\n",
    "\n",
    "    # 5. Clean up metadata\n",
    "    # Remove unused levels so df_OHLCV doesn't carry metadata about '^VIX', etc.\n",
    "    df_indices.index = df_indices.index.remove_unused_levels()\n",
    "    df_OHLCV.index = df_OHLCV.index.remove_unused_levels()\n",
    "\n",
    "    print(\n",
    "        f\"Separation complete: {len(df_OHLCV):,} regular rows, {len(df_indices):,} index rows.\"\n",
    "    )\n",
    "    return df_OHLCV, df_indices\n",
    "\n",
    "\n",
    "def save_dataframe_to_parquet(df: Optional[pd.DataFrame], dest_path: Path):\n",
    "    \"\"\"\n",
    "    Saves a DataFrame to a Parquet file using pyarrow/zstd.\n",
    "    \"\"\"\n",
    "    if df is None or df.empty:\n",
    "        print(f\"Skipping save: DataFrame for {dest_path.name} is empty or None.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        dest_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df.to_parquet(dest_path, engine=\"pyarrow\", compression=\"zstd\", index=True)\n",
    "        print(f\"Successfully saved to: {dest_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving {dest_path}: {e}\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# Main Execution\n",
    "# ==========================================\n",
    "\n",
    "# 1. Load Data\n",
    "print(f\"==== Takes about 2.5 minutes to run ====\")\n",
    "final_df = process_yloader_csvs(YLOADER_DATA_DIR, CANONICAL_COLUMN_NAMES)\n",
    "\n",
    "if final_df is not None and not final_df.empty:\n",
    "\n",
    "    # 2. Sort Chronologically (Optimization: Sort once before splitting)\n",
    "    if not final_df.index.is_monotonic_increasing:\n",
    "        print(f\"\\nSorting combined DataFrame chronologically...\")\n",
    "        final_df.sort_index(inplace=True)\n",
    "    else:\n",
    "        print(f\"\\nCombined DataFrame is already sorted.\")\n",
    "\n",
    "    print(\"\\n--- Combined DataFrame Info ---\")\n",
    "    final_df.info()\n",
    "\n",
    "    # 3. Split DataFrames\n",
    "    df_OHLCV, df_indices = separate_indices_from_tickers(final_df)\n",
    "\n",
    "    # 4. Memory Cleanup\n",
    "    # Critical for large datasets: delete the massive original DF and force GC\n",
    "    print(\"\\nReleasing memory from combined DataFrame...\")\n",
    "    del final_df\n",
    "    gc.collect()\n",
    "\n",
    "    # 5. Save Outputs\n",
    "    save_dataframe_to_parquet(df_OHLCV, DESTINATION_PARQUET_PATH_OHLCV)\n",
    "    save_dataframe_to_parquet(df_indices, DESTINATION_PARQUET_PATH_INDICES)\n",
    "\n",
    "    # Display preview (using display if in Jupyter, else print)\n",
    "    try:\n",
    "        print(\"\\n--- Preview: Regular Tickers (df_OHLCV) ---\")\n",
    "        display(df_OHLCV.tail(3))\n",
    "        print(\"\\n--- Preview: Indices (df_indices) ---\")\n",
    "        display(df_indices.tail(3))\n",
    "    except NameError:\n",
    "        print(df_OHLCV.tail(3))\n",
    "        print(df_indices.tail(3))\n",
    "\n",
    "else:\n",
    "    print(\"No data loaded from process_yloader_csvs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Verify the Saved File (Optional)\n",
    "\n",
    "This final step reads the Parquet file back into a new DataFrame to ensure the data was saved correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Verifying the saved file at: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet ---\n",
      "Verification successful! File read back into memory.\n",
      "\n",
      "--- First 5 Rows of Verified DataFrame ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Adj Open</th>\n",
       "      <th>Adj High</th>\n",
       "      <th>Adj Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">A</th>\n",
       "      <th>1999-11-18</th>\n",
       "      <td>27.1966</td>\n",
       "      <td>29.8864</td>\n",
       "      <td>23.9091</td>\n",
       "      <td>26.3000</td>\n",
       "      <td>74849965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-19</th>\n",
       "      <td>25.6649</td>\n",
       "      <td>25.7023</td>\n",
       "      <td>23.7970</td>\n",
       "      <td>24.1333</td>\n",
       "      <td>18230875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-22</th>\n",
       "      <td>24.6936</td>\n",
       "      <td>26.3000</td>\n",
       "      <td>23.9465</td>\n",
       "      <td>26.3000</td>\n",
       "      <td>7871811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-23</th>\n",
       "      <td>25.4034</td>\n",
       "      <td>26.0759</td>\n",
       "      <td>23.9091</td>\n",
       "      <td>23.9091</td>\n",
       "      <td>7151081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-24</th>\n",
       "      <td>23.9838</td>\n",
       "      <td>25.0672</td>\n",
       "      <td>23.9091</td>\n",
       "      <td>24.5442</td>\n",
       "      <td>5795947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Adj Open  Adj High  Adj Low  Adj Close    Volume\n",
       "Ticker Date                                                        \n",
       "A      1999-11-18   27.1966   29.8864  23.9091    26.3000  74849965\n",
       "       1999-11-19   25.6649   25.7023  23.7970    24.1333  18230875\n",
       "       1999-11-22   24.6936   26.3000  23.9465    26.3000   7871811\n",
       "       1999-11-23   25.4034   26.0759  23.9091    23.9091   7151081\n",
       "       1999-11-24   23.9838   25.0672  23.9091    24.5442   5795947"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data for first available ticker 'A' ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Open</th>\n",
       "      <th>Adj High</th>\n",
       "      <th>Adj Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999-11-18</th>\n",
       "      <td>27.1966</td>\n",
       "      <td>29.8864</td>\n",
       "      <td>23.9091</td>\n",
       "      <td>26.3000</td>\n",
       "      <td>74849965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-19</th>\n",
       "      <td>25.6649</td>\n",
       "      <td>25.7023</td>\n",
       "      <td>23.7970</td>\n",
       "      <td>24.1333</td>\n",
       "      <td>18230875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-22</th>\n",
       "      <td>24.6936</td>\n",
       "      <td>26.3000</td>\n",
       "      <td>23.9465</td>\n",
       "      <td>26.3000</td>\n",
       "      <td>7871811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-23</th>\n",
       "      <td>25.4034</td>\n",
       "      <td>26.0759</td>\n",
       "      <td>23.9091</td>\n",
       "      <td>23.9091</td>\n",
       "      <td>7151081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-24</th>\n",
       "      <td>23.9838</td>\n",
       "      <td>25.0672</td>\n",
       "      <td>23.9091</td>\n",
       "      <td>24.5442</td>\n",
       "      <td>5795947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Adj Open  Adj High  Adj Low  Adj Close    Volume\n",
       "Date                                                        \n",
       "1999-11-18   27.1966   29.8864  23.9091    26.3000  74849965\n",
       "1999-11-19   25.6649   25.7023  23.7970    24.1333  18230875\n",
       "1999-11-22   24.6936   26.3000  23.9465    26.3000   7871811\n",
       "1999-11-23   25.4034   26.0759  23.9091    23.9091   7151081\n",
       "1999-11-24   23.9838   25.0672  23.9091    24.5442   5795947"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"--- Verifying the saved file at: {DESTINATION_PARQUET_PATH_OHLCV} ---\")\n",
    "\n",
    "try:\n",
    "    if DESTINATION_PARQUET_PATH_OHLCV.exists():\n",
    "        verified_df = pd.read_parquet(DESTINATION_PARQUET_PATH_OHLCV)\n",
    "        print(\"Verification successful! File read back into memory.\")\n",
    "\n",
    "        print(\"\\n--- First 5 Rows of Verified DataFrame ---\")\n",
    "        display(verified_df.head())\n",
    "\n",
    "        # Optional: Check a specific ticker\n",
    "        if not verified_df.empty:\n",
    "            example_ticker = verified_df.index.get_level_values(\"Ticker\")[0]\n",
    "            print(f\"\\n--- Data for first available ticker '{example_ticker}' ---\")\n",
    "            display(verified_df.loc[example_ticker].head())\n",
    "\n",
    "    else:\n",
    "        print(\"Error: The output file was not found at the specified path.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during verification: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Open</th>\n",
       "      <th>Adj High</th>\n",
       "      <th>Adj Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-12-12</th>\n",
       "      <td>0.098297</td>\n",
       "      <td>0.098725</td>\n",
       "      <td>0.098297</td>\n",
       "      <td>0.098297</td>\n",
       "      <td>612421789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-15</th>\n",
       "      <td>0.093597</td>\n",
       "      <td>0.093597</td>\n",
       "      <td>0.093169</td>\n",
       "      <td>0.093169</td>\n",
       "      <td>229654483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-16</th>\n",
       "      <td>0.086758</td>\n",
       "      <td>0.086758</td>\n",
       "      <td>0.086331</td>\n",
       "      <td>0.086331</td>\n",
       "      <td>138050083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-17</th>\n",
       "      <td>0.088468</td>\n",
       "      <td>0.088895</td>\n",
       "      <td>0.088468</td>\n",
       "      <td>0.088468</td>\n",
       "      <td>112867631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-18</th>\n",
       "      <td>0.091033</td>\n",
       "      <td>0.091460</td>\n",
       "      <td>0.091033</td>\n",
       "      <td>0.091033</td>\n",
       "      <td>95903853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-02-09</th>\n",
       "      <td>277.910000</td>\n",
       "      <td>278.200000</td>\n",
       "      <td>271.700000</td>\n",
       "      <td>274.620000</td>\n",
       "      <td>44623400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-02-10</th>\n",
       "      <td>274.890000</td>\n",
       "      <td>275.370000</td>\n",
       "      <td>272.940000</td>\n",
       "      <td>273.680000</td>\n",
       "      <td>34376900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-02-11</th>\n",
       "      <td>274.700000</td>\n",
       "      <td>280.180000</td>\n",
       "      <td>274.450000</td>\n",
       "      <td>275.500000</td>\n",
       "      <td>51931300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-02-12</th>\n",
       "      <td>275.590000</td>\n",
       "      <td>275.720000</td>\n",
       "      <td>260.180000</td>\n",
       "      <td>261.730000</td>\n",
       "      <td>81077200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-02-13</th>\n",
       "      <td>262.010000</td>\n",
       "      <td>262.230000</td>\n",
       "      <td>255.450000</td>\n",
       "      <td>255.780000</td>\n",
       "      <td>56134274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11385 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Adj Open    Adj High     Adj Low   Adj Close     Volume\n",
       "Date                                                                 \n",
       "1980-12-12    0.098297    0.098725    0.098297    0.098297  612421789\n",
       "1980-12-15    0.093597    0.093597    0.093169    0.093169  229654483\n",
       "1980-12-16    0.086758    0.086758    0.086331    0.086331  138050083\n",
       "1980-12-17    0.088468    0.088895    0.088468    0.088468  112867631\n",
       "1980-12-18    0.091033    0.091460    0.091033    0.091033   95903853\n",
       "...                ...         ...         ...         ...        ...\n",
       "2026-02-09  277.910000  278.200000  271.700000  274.620000   44623400\n",
       "2026-02-10  274.890000  275.370000  272.940000  273.680000   34376900\n",
       "2026-02-11  274.700000  280.180000  274.450000  275.500000   51931300\n",
       "2026-02-12  275.590000  275.720000  260.180000  261.730000   81077200\n",
       "2026-02-13  262.010000  262.230000  255.450000  255.780000   56134274\n",
       "\n",
       "[11385 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verified_df.loc[\"AAPL\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#################  \n",
    "#################  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
