{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75db595f",
   "metadata": {},
   "source": [
    "# Cleaning filter out 'CRM' why df_clean.loc['CRM']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cef0dc9",
   "metadata": {},
   "source": [
    "### OHLCV Data Cleaning Pipeline\n",
    "\n",
    "This notebook cleans the consolidated OHLCV data by ensuring data integrity and temporal alignment across all tickers.\n",
    "\n",
    "**Workflow:**\n",
    "\n",
    "1.  **Load Data:** The raw, consolidated OHLCV data is loaded.\n",
    "2.  **Trim Data:** The data is reduced to only include a recent time window (e.g., the last 250 trading days).\n",
    "3.  **Clean & Filter:** The data undergoes a multi-step cleaning process:\n",
    "    *   **Date Alignment:** Tickers with date ranges not matching a reference symbol (`VOO`) are removed.\n",
    "    *   **Completeness Check:** Tickers with any `NaN` values are removed.\n",
    "    *   **Spike Removal:** Tickers with extreme single-day price changes are removed.\n",
    "4.  **Save Data:** The final, clean DataFrame is saved.\n",
    "5.  **Summarize:** A report details the number of tickers removed at each stage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deda3101",
   "metadata": {},
   "source": [
    "### Setup and Configuration\n",
    "\n",
    "**This is the only cell you need to modify.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2ea01e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Source file: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet\n",
      "Destination file: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_clean_stocks_etfs.parquet\n",
      "Reference symbol: 'VOO'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# --- Project Path Setup ---\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "ROOT_DIR = NOTEBOOK_DIR.parent\n",
    "DATA_DIR = ROOT_DIR / 'data'\n",
    "SRC_DIR = ROOT_DIR / 'src'\n",
    "if str(SRC_DIR) not in sys.path: sys.path.append(str(SRC_DIR))\n",
    "import utils\n",
    "\n",
    "# --- File Configuration ---\n",
    "SOURCE_FILENAME = 'df_OHLCV_stocks_etfs.parquet'\n",
    "DEST_FILENAME = 'df_OHLCV_clean_stocks_etfs.parquet'\n",
    "SOURCE_PATH = DATA_DIR / SOURCE_FILENAME\n",
    "DEST_PATH = DATA_DIR / DEST_FILENAME\n",
    "\n",
    "# --- Cleaning Parameters ---\n",
    "DAYS_TO_KEEP = 250\n",
    "REFERENCE_SYMBOL = 'VOO'\n",
    "MAX_DAILY_CHANGE_THRESHOLD = 0.50 # 50% change\n",
    "\n",
    "# --- Notebook Setup ---\n",
    "pd.set_option('display.max_columns', None); pd.set_option('display.width', 2000)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# --- Verification ---\n",
    "print(f\"Source file: {SOURCE_PATH}\")\n",
    "print(f\"Destination file: {DEST_PATH}\")\n",
    "print(f\"Reference symbol: '{REFERENCE_SYMBOL}'\")\n",
    "assert SOURCE_PATH.exists(), f\"Source file not found at {SOURCE_PATH}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78d3958",
   "metadata": {},
   "source": [
    "### Step 1: Load Raw OHLCV Data\n",
    "Load the consolidated data and validate that the reference symbol exists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e761d4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Loading raw data from df_OHLCV_stocks_etfs.parquet ---\n",
      "Successfully loaded data with 1606 unique tickers.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 1028170 entries, ('A', Timestamp('2025-08-15 00:00:00')) to ('ZWS', Timestamp('2023-01-03 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count    Dtype  \n",
      "---  ------     --------------    -----  \n",
      " 0   Adj Open   1028170 non-null  float64\n",
      " 1   Adj High   1028170 non-null  float64\n",
      " 2   Adj Low    1028170 non-null  float64\n",
      " 3   Adj Close  1028170 non-null  float64\n",
      " 4   Volume     1028170 non-null  int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 43.2+ MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"--- Step 1: Loading raw data from {SOURCE_PATH.name} ---\")\n",
    "df_raw = pd.read_parquet(SOURCE_PATH)\n",
    "\n",
    "if REFERENCE_SYMBOL not in df_raw.index.get_level_values('Ticker'):\n",
    "    raise ValueError(f\"Reference symbol '{REFERENCE_SYMBOL}' not found. Halting.\")\n",
    "\n",
    "initial_tickers = set(df_raw.index.get_level_values('Ticker').unique())\n",
    "print(f\"Successfully loaded data with {len(initial_tickers)} unique tickers.\")\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934e1f90",
   "metadata": {},
   "source": [
    "### Step 2: Trim Data to Recent Period\n",
    "Reduce the dataset to a manageable, recent time window using our utility function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "005bd772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimming data to keep the last 250 days for each ticker...\n",
      "Trimming complete. Data shape: (397778, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Adj Open</th>\n",
       "      <th>Adj High</th>\n",
       "      <th>Adj Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALGM</th>\n",
       "      <th>2024-08-13</th>\n",
       "      <td>23.0500</td>\n",
       "      <td>23.3700</td>\n",
       "      <td>22.6200</td>\n",
       "      <td>23.2800</td>\n",
       "      <td>1723800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BRKR</th>\n",
       "      <th>2024-08-13</th>\n",
       "      <td>60.2088</td>\n",
       "      <td>61.6331</td>\n",
       "      <td>59.9698</td>\n",
       "      <td>61.1251</td>\n",
       "      <td>792762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CFLT</th>\n",
       "      <th>2024-08-13</th>\n",
       "      <td>20.3000</td>\n",
       "      <td>21.5250</td>\n",
       "      <td>20.2900</td>\n",
       "      <td>21.3100</td>\n",
       "      <td>5419100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Adj Open  Adj High  Adj Low  Adj Close   Volume\n",
       "Ticker Date                                                       \n",
       "ALGM   2024-08-13   23.0500   23.3700  22.6200    23.2800  1723800\n",
       "BRKR   2024-08-13   60.2088   61.6331  59.9698    61.1251   792762\n",
       "CFLT   2024-08-13   20.3000   21.5250  20.2900    21.3100  5419100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_trimmed = utils.trim_dataframe_to_recent_days(\n",
    "    df=df_raw,\n",
    "    days_to_keep=DAYS_TO_KEEP\n",
    ")\n",
    "trimmed_tickers = set(df_trimmed.index.get_level_values('Ticker').unique())\n",
    "display(df_trimmed.head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e189237e",
   "metadata": {},
   "source": [
    "### Step 3: Clean and Filter Data\n",
    "Apply a sequence of cleaning functions to ensure data quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b1b9d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VOO'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REFERENCE_SYMBOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0628cded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_raw VOO\n",
      "DatetimeIndex(['2025-08-15', '2025-08-14', '2025-08-13', '2025-08-12', '2025-08-11', '2025-08-08', '2025-08-07', '2025-08-06', '2025-08-05', '2025-08-04',\n",
      "               ...\n",
      "               '2023-01-17', '2023-01-13', '2023-01-12', '2023-01-11', '2023-01-10', '2023-01-09', '2023-01-06', '2023-01-05', '2023-01-04', '2023-01-03'], dtype='datetime64[ns]', name='Date', length=657, freq=None)\n",
      "====\n",
      "df_raw CF\n",
      "DatetimeIndex(['2025-08-15', '2025-08-14', '2025-08-13', '2025-08-12', '2025-08-11', '2025-08-08', '2025-08-07', '2025-08-06', '2025-08-05', '2025-08-04',\n",
      "               ...\n",
      "               '2023-01-17', '2023-01-13', '2023-01-12', '2023-01-11', '2023-01-10', '2023-01-09', '2023-01-06', '2023-01-05', '2023-01-04', '2023-01-03'], dtype='datetime64[ns]', name='Date', length=657, freq=None)\n",
      "====\n",
      "df_raw ACN\n",
      "DatetimeIndex(['2025-08-15', '2025-08-14', '2025-08-13', '2025-08-12', '2025-08-11', '2025-08-08', '2025-08-07', '2025-08-06', '2025-08-05', '2025-08-04',\n",
      "               ...\n",
      "               '2023-01-17', '2023-01-13', '2023-01-12', '2023-01-11', '2023-01-10', '2023-01-09', '2023-01-06', '2023-01-05', '2023-01-04', '2023-01-03'], dtype='datetime64[ns]', name='Date', length=657, freq=None)\n",
      "====\n"
     ]
    }
   ],
   "source": [
    "my_tickers = [REFERENCE_SYMBOL] + ['CF', 'ACN']\n",
    "for ticker in my_tickers:\n",
    "    print(f'df_raw {ticker}\\n{df_raw.loc[ticker].index}')\n",
    "    # print(f'\\ndf_trimmed {ticker}\\n{df_trimmed.loc[ticker].index}')\n",
    "    print(f'====')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeb42ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trimmed.loc[REFERENCE_SYMBOL].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f88730",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.loc['CN'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa1d2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trimmed.loc['CN'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac05f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'removed_by_date: {removed_by_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d12c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Part A: Align dates to the reference symbol ---\n",
    "print(\"\\n--- Part A: Aligning dates to reference symbol ---\")\n",
    "df_aligned, removed_by_date = utils.filter_df_dates_to_reference_symbol(\n",
    "    df=df_trimmed,\n",
    "    reference_symbol=REFERENCE_SYMBOL\n",
    ")\n",
    "df_aligned.index.names = ['Ticker', 'Date'] # Restore index names\n",
    "\n",
    "# --- Part B: Remove symbols with missing values (NaNs) or incomplete history ---\n",
    "print(\"\\n--- Part B: Removing symbols with missing values or incomplete data ---\")\n",
    "df_complete, removed_by_nan = utils.filter_symbols_with_missing_values(\n",
    "    df=df_aligned\n",
    ")\n",
    "df_complete.index.names = ['Ticker', 'Date'] # Restore index names\n",
    "\n",
    "# --- Part C: Filter out tickers with extreme single-day price changes ---\n",
    "print(\"\\n--- Part C: Removing symbols with extreme price changes ---\")\n",
    "df_clean, removed_by_spike = utils.filter_symbols_with_extreme_changes(\n",
    "    df=df_complete,\n",
    "    threshold=MAX_DAILY_CHANGE_THRESHOLD\n",
    ")\n",
    "\n",
    "final_tickers = set(df_clean.index.get_level_values('Ticker').unique())\n",
    "print(f\"\\nCleaning complete. Final ticker count: {len(final_tickers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a758935",
   "metadata": {},
   "source": [
    "### Step 4: Save Cleaned Data\n",
    "Save the fully cleaned DataFrame to a new Parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317a8fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n--- Step 4: Saving cleaned data ---\")\n",
    "if not df_clean.empty:\n",
    "    DEST_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df_clean.to_parquet(DEST_PATH, engine='pyarrow', compression='zstd')\n",
    "    print(f\"Successfully saved cleaned data with {len(final_tickers)} tickers to: {DEST_PATH}\")\n",
    "else:\n",
    "    print(\"Clean DataFrame is empty. Nothing to save.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32728485",
   "metadata": {},
   "source": [
    "### Step 5: Final Summary\n",
    "Provide a report on the number of tickers at each stage and list those that were removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43449321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [REFACTOR] The summary now uses the cleanly collected lists of removed tickers.\n",
    "print(\"\\n--- Step 5: Cleaning Process Summary ---\")\n",
    "\n",
    "# Calculate counts at each stage\n",
    "initial_count = len(initial_tickers)\n",
    "trimmed_count = len(trimmed_tickers)\n",
    "aligned_count = len(df_aligned.index.get_level_values('Ticker').unique())\n",
    "complete_count = len(df_complete.index.get_level_values('Ticker').unique())\n",
    "final_count = len(final_tickers)\n",
    "\n",
    "# Print the funnel report\n",
    "print(\"\\n--- Ticker Count Funnel ---\")\n",
    "print(f\"{'Initial raw count:':<35} {initial_count}\")\n",
    "print(f\"{'After trimming to recent days:':<35} {trimmed_count}\")\n",
    "print(f\"{'After date alignment:':<35} {aligned_count}\")\n",
    "print(f\"{'After NaN/completeness check:':<35} {complete_count}\")\n",
    "print(f\"{'After spike removal:':<35} {final_count}\")\n",
    "print(\"-\" * 45)\n",
    "print(f\"{'Total tickers removed:':<35} {initial_count - final_count}\")\n",
    "\n",
    "# Print the lists of removed tickers\n",
    "print(\"\\n--- Details of Removed Tickers ---\")\n",
    "print(f\"\\n{len(removed_by_date)} symbols removed due to non-matching date index:\")\n",
    "print(sorted(removed_by_date))\n",
    "\n",
    "print(f\"\\n{len(removed_by_nan)} symbols removed due to NaNs or incomplete history:\")\n",
    "print(sorted(removed_by_nan))\n",
    "\n",
    "print(f\"\\n{len(removed_by_spike)} symbols removed due to extreme price spikes:\")\n",
    "print(sorted(removed_by_spike))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6292a257",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"df_raw.loc['CRM']:\\n{df_raw.loc['CRM']}\")\n",
    "print(f\"df_trimmed.loc['CRM']:\\n{df_trimmed.loc['CRM']}\")\n",
    "print(f\"\\ndf_aligned['CRM']:\\n{df_aligned['CRM']}\")\n",
    "print(f\"\\ndf_complete['CRM']:\\n{df_complete['CRM']}\")\n",
    "print(f\"\\ndf_clean['CRM']:\\n{df_clean['CRM']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786d9597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_clean.loc['CRM']\n",
    "print(f\"df_clean.loc['NVDA']:\\n{df_clean.loc['NVDA']}\")\n",
    "print(f\"\\ndf_clean.loc['CRM']:\\n{df_clean.loc['CRM']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
