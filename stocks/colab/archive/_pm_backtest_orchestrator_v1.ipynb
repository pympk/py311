{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3463a186",
   "metadata": {},
   "source": [
    "## Backtest Orchestrator Workflow\n",
    "\n",
    "This notebook automates a rolling-window backtest by iteratively executing a worker notebook (`py11_worker_sharpe_strategy.ipynb`) for each time slice.\n",
    "\n",
    "**Workflow:**\n",
    "\n",
    "1.  **Setup:** Loads project configurations and strategy parameters.\n",
    "2.  **Load Data:** Reads the master adjusted close prices file.\n",
    "3.  **Prepare Data Chunks:** Creates rolling window data chunks for the entire dataset.\n",
    "4.  **Split Data:** Divides the chunks into an **In-Sample** set (for the main walk-forward backtest) and a **Holdout** set (for final, unseen data verification).\n",
    "5.  **Execute In-Sample Backtests:** Loops through the **In-Sample** chunks, running the worker notebook for each one.\n",
    "6.  **Aggregate In-Sample Results:** Collects and combines the results from the in-sample backtest into a single portfolio returns file.\n",
    "7.  **Cleanup:** Deletes temporary data files.\n",
    "8.  **Next Steps:** Outlines how to use the **Holdout** data for a final, true out-of-sample validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5f798b",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Configuration\n",
    "\n",
    "This cell contains all imports and configuration variables. It defines the project structure and parameters for the rolling backtest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ef2028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Path Configuration ---\n",
      "ROOT_DIR:                c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\n",
      "NOTEBOOK_DIR:            c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\colab\n",
      "DATA_DIR:                c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\n",
      "SRC_DIR:                 c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\src\n",
      "TEMP_DIR:                c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\colab\\temp_backtest_data\n",
      "OUTPUT_DIR:              c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\colab\\backtest_results\n",
      "WORKER_NOTEBOOK_PATH:    c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\colab\\_pm_worker_sharpe_strategy.ipynb\n",
      "\n",
      "--- Strategy Parameters ---\n",
      "Window Width:  300, Step Size: 30\n",
      "In-Sample/Holdout Split Ratio: 0.25\n",
      "Train/Test Split: 270 rows for training\n",
      "Benchmark:     VGT\n",
      "Chunk Limit:   2 (for testing)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import papermill as pm\n",
    "import shutil\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# --- Project Path Configuration ---\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "ROOT_DIR = NOTEBOOK_DIR.parent\n",
    "DATA_DIR = ROOT_DIR / 'data'\n",
    "SRC_DIR = ROOT_DIR / 'src'\n",
    "TEMP_DIR = NOTEBOOK_DIR / 'temp_backtest_data'\n",
    "OUTPUT_DIR = NOTEBOOK_DIR / 'backtest_results'\n",
    "\n",
    "# --- Add src to Python path ---\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.append(str(SRC_DIR))\n",
    "\n",
    "# --- Import Custom Modules ---\n",
    "import utils\n",
    "\n",
    "# --- Papermill Configuration ---\n",
    "WORKER_NOTEBOOK_NAME = \"_pm_worker_sharpe_strategy.ipynb\"\n",
    "WORKER_NOTEBOOK_PATH = NOTEBOOK_DIR / WORKER_NOTEBOOK_NAME\n",
    "IN_SAMPLE_RESULTS_FILENAME = \"in_sample_portfolio_returns.parquet\"\n",
    "# [NEW] A separate filename for the eventual holdout results\n",
    "HOLDOUT_RESULTS_FILENAME = \"holdout_portfolio_returns.parquet\"\n",
    "\n",
    "# --- Strategy & Backtest Parameters ---\n",
    "SLIDING_WINDOW_WIDTH = 300\n",
    "SLIDING_WINDOW_STEP = 30\n",
    "TRAIN_TEST_SPLIT_POINT = 270\n",
    "BENCHMARK_TICKER = 'VGT'\n",
    "FINVIZ_DATA_FILENAME = '2025-08-01_df_finviz_merged_stocks_etfs.parquet'\n",
    "# [NEW] Ratio of chunks to reserve for the final holdout test. 0.25 means the last 25% of chunks are held out.\n",
    "HOLDOUT_SPLIT_RATIO = 0.25\n",
    "BACKTEST_CHUNK_LIMIT = 2\n",
    "\n",
    "# --- Verification ---\n",
    "print(\"--- Path Configuration ---\")\n",
    "print(f\"ROOT_DIR:                {ROOT_DIR}\")\n",
    "print(f\"NOTEBOOK_DIR:            {NOTEBOOK_DIR}\")\n",
    "print(f\"DATA_DIR:                {DATA_DIR}\")\n",
    "print(f\"SRC_DIR:                 {SRC_DIR}\")\n",
    "print(f\"TEMP_DIR:                {TEMP_DIR}\")\n",
    "print(f\"OUTPUT_DIR:              {OUTPUT_DIR}\")\n",
    "print(f\"WORKER_NOTEBOOK_PATH:    {WORKER_NOTEBOOK_PATH}\")\n",
    "assert all([ROOT_DIR.exists(), DATA_DIR.exists(), SRC_DIR.exists(), NOTEBOOK_DIR.exists()]), \"A key directory was not found!\"\n",
    "assert (DATA_DIR / FINVIZ_DATA_FILENAME).exists(), f\"Finviz data file not found: {FINVIZ_DATA_FILENAME}\"\n",
    "assert WORKER_NOTEBOOK_PATH.exists(), f\"Worker notebook not found at: {WORKER_NOTEBOOK_PATH}\"\n",
    "\n",
    "print(\"\\n--- Strategy Parameters ---\")\n",
    "print(f\"Window Width:  {SLIDING_WINDOW_WIDTH}, Step Size: {SLIDING_WINDOW_STEP}\")\n",
    "print(f\"In-Sample/Holdout Split Ratio: {HOLDOUT_SPLIT_RATIO}\")\n",
    "print(f\"Train/Test Split: {TRAIN_TEST_SPLIT_POINT} rows for training\")\n",
    "print(f\"Benchmark:     {BENCHMARK_TICKER}\")\n",
    "if BACKTEST_CHUNK_LIMIT is None:\n",
    "    print(f\"Chunk Limit:   None (run all in-sample chunks)\")\n",
    "else:\n",
    "    print(f\"Chunk Limit:   {BACKTEST_CHUNK_LIMIT} (for testing)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65466159",
   "metadata": {},
   "source": [
    "### Step 2: Load and Prepare Data\n",
    "\n",
    "Load the adjusted close prices and convert them to percentage returns, which form the basis of our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5495b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded returns data. Shape: (2662, 1220)\n",
      "Date range: 2015-01-05 to 2025-08-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>A</th>\n",
       "      <th>AA</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAON</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABEV</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACGL</th>\n",
       "      <th>ACM</th>\n",
       "      <th>...</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YPF</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZG</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "      <th>ZWS</th>\n",
       "      <th>CASH</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>-0.018739</td>\n",
       "      <td>-0.057934</td>\n",
       "      <td>-0.000556</td>\n",
       "      <td>-0.033745</td>\n",
       "      <td>-0.028174</td>\n",
       "      <td>-0.018821</td>\n",
       "      <td>-0.018488</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>-0.005987</td>\n",
       "      <td>-0.043822</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062237</td>\n",
       "      <td>-0.051703</td>\n",
       "      <td>-0.020317</td>\n",
       "      <td>0.037311</td>\n",
       "      <td>-0.014077</td>\n",
       "      <td>-0.058835</td>\n",
       "      <td>-0.037471</td>\n",
       "      <td>-0.006004</td>\n",
       "      <td>-0.039730</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>-0.015579</td>\n",
       "      <td>0.007352</td>\n",
       "      <td>-0.015590</td>\n",
       "      <td>-0.016051</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>-0.004950</td>\n",
       "      <td>0.037673</td>\n",
       "      <td>-0.011356</td>\n",
       "      <td>0.002236</td>\n",
       "      <td>-0.009992</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005883</td>\n",
       "      <td>-0.003230</td>\n",
       "      <td>-0.012275</td>\n",
       "      <td>-0.008484</td>\n",
       "      <td>-0.007205</td>\n",
       "      <td>-0.006560</td>\n",
       "      <td>-0.038192</td>\n",
       "      <td>-0.009755</td>\n",
       "      <td>-0.016766</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-07</th>\n",
       "      <td>0.013273</td>\n",
       "      <td>0.025880</td>\n",
       "      <td>-0.000565</td>\n",
       "      <td>0.009112</td>\n",
       "      <td>0.014022</td>\n",
       "      <td>0.040417</td>\n",
       "      <td>0.016500</td>\n",
       "      <td>0.008108</td>\n",
       "      <td>0.005837</td>\n",
       "      <td>0.020536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007887</td>\n",
       "      <td>-0.013373</td>\n",
       "      <td>0.033138</td>\n",
       "      <td>0.024875</td>\n",
       "      <td>0.025465</td>\n",
       "      <td>0.049309</td>\n",
       "      <td>0.009547</td>\n",
       "      <td>0.020643</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1220 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker             A        AA       AAL      AAON      AAPL      ABBV  \\\n",
       "Date                                                                     \n",
       "2015-01-05 -0.018739 -0.057934 -0.000556 -0.033745 -0.028174 -0.018821   \n",
       "2015-01-06 -0.015579  0.007352 -0.015590 -0.016051  0.000097 -0.004950   \n",
       "2015-01-07  0.013273  0.025880 -0.000565  0.009112  0.014022  0.040417   \n",
       "\n",
       "Ticker          ABEV       ABT      ACGL       ACM  ...       XYL       YPF  \\\n",
       "Date                                                ...                       \n",
       "2015-01-05 -0.018488  0.000224 -0.005987 -0.043822  ... -0.062237 -0.051703   \n",
       "2015-01-06  0.037673 -0.011356  0.002236 -0.009992  ... -0.005883 -0.003230   \n",
       "2015-01-07  0.016500  0.008108  0.005837  0.020536  ...  0.007887 -0.013373   \n",
       "\n",
       "Ticker           YUM       ZBH      ZBRA        ZG      ZION       ZTS  \\\n",
       "Date                                                                     \n",
       "2015-01-05 -0.020317  0.037311 -0.014077 -0.058835 -0.037471 -0.006004   \n",
       "2015-01-06 -0.012275 -0.008484 -0.007205 -0.006560 -0.038192 -0.009755   \n",
       "2015-01-07  0.033138  0.024875  0.025465  0.049309  0.009547  0.020643   \n",
       "\n",
       "Ticker           ZWS  CASH  \n",
       "Date                        \n",
       "2015-01-05 -0.039730   0.0  \n",
       "2015-01-06 -0.016766   0.0  \n",
       "2015-01-07  0.001513   0.0  \n",
       "\n",
       "[3 rows x 1220 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load historical price data\n",
    "adj_close_path = DATA_DIR / 'df_adj_close.parquet'\n",
    "df_adj_close = pd.read_parquet(adj_close_path)\n",
    "\n",
    "# Calculate daily returns\n",
    "returns = df_adj_close.pct_change().dropna()\n",
    "\n",
    "# Add a risk-free 'CASH' asset with zero return\n",
    "returns['CASH'] = 0.0\n",
    "\n",
    "print(f\"Loaded returns data. Shape: {returns.shape}\")\n",
    "print(f\"Date range: {returns.index.min().strftime('%Y-%m-%d')} to {returns.index.max().strftime('%Y-%m-%d')}\")\n",
    "display(returns.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc6adac",
   "metadata": {},
   "source": [
    "## Step 3: Generate Rolling Window Chunks\n",
    "\n",
    "Using our utility function, slice the returns data into overlapping chunks that will be used for each iteration of the backtest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1576c291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully generated 79 total rolling window chunks.\n",
      "Shape of each chunk: (300, 1220)\n"
     ]
    }
   ],
   "source": [
    "# (This cell remains exactly the same as before)\n",
    "rolling_chunks = utils.create_rolling_window_chunks(\n",
    "    returns_df=returns,\n",
    "    window_width=SLIDING_WINDOW_WIDTH,\n",
    "    step_size=SLIDING_WINDOW_STEP\n",
    ")\n",
    "\n",
    "print(f\"Successfully generated {len(rolling_chunks)} total rolling window chunks.\")\n",
    "if rolling_chunks:\n",
    "    chunk = rolling_chunks[0]\n",
    "    print(f\"Shape of each chunk: {chunk.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16813ab0",
   "metadata": {},
   "source": [
    "### Step 4: Split Data into In-Sample and Holdout Sets\n",
    "\n",
    "Divide the generated chunks into a primary set for the walk-forward backtest (`in_sample_chunks`) and a final validation set (`holdout_chunks`) that will remain untouched during this run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99140f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Split Summary ---\n",
      "Total chunks:      79\n",
      "In-Sample chunks:  59 (for immediate backtesting)\n",
      "Holdout chunks:    20 (reserved for final validation)\n",
      "In-Sample Period:  2015-01-05 to 2023-02-09\n",
      "Holdout Period:    2022-01-13 to 2025-07-03\n"
     ]
    }
   ],
   "source": [
    "# [NEW] This is the new cell implementing the requested logic.\n",
    "if not rolling_chunks:\n",
    "    raise ValueError(\"No rolling chunks were generated. Cannot proceed with split.\")\n",
    "\n",
    "# Calculate the index at which to split the chunks\n",
    "split_index = int(len(rolling_chunks) * (1 - HOLDOUT_SPLIT_RATIO))\n",
    "\n",
    "# Assign chunks to their respective sets\n",
    "in_sample_chunks = rolling_chunks[:split_index]\n",
    "holdout_chunks = rolling_chunks[split_index:]\n",
    "\n",
    "print(\"--- Data Split Summary ---\")\n",
    "print(f\"Total chunks:      {len(rolling_chunks)}\")\n",
    "print(f\"In-Sample chunks:  {len(in_sample_chunks)} (for immediate backtesting)\")\n",
    "print(f\"Holdout chunks:    {len(holdout_chunks)} (reserved for final validation)\")\n",
    "\n",
    "if in_sample_chunks:\n",
    "    print(f\"In-Sample Period:  {in_sample_chunks[0].index.min().date()} to {in_sample_chunks[-1].index.max().date()}\")\n",
    "if holdout_chunks:\n",
    "    print(f\"Holdout Period:    {holdout_chunks[0].index.min().date()} to {holdout_chunks[-1].index.max().date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0963752",
   "metadata": {},
   "source": [
    "### Step 5: Select Chunks for This Run\n",
    "\n",
    "This cell applies the `BACKTEST_CHUNK_LIMIT` to select the subset of in-sample chunks that will be processed in this execution. This is useful for running quick tests without processing the entire dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9719bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BACKTEST_CHUNK_LIMIT is set to 2. Processing the first 2 of 59 available in-sample chunks.\n"
     ]
    }
   ],
   "source": [
    "# [NEW] Create the list of chunks we will actually process based on the limit.\n",
    "if BACKTEST_CHUNK_LIMIT is None:\n",
    "    chunks_to_process = in_sample_chunks\n",
    "    print(f\"BACKTEST_CHUNK_LIMIT is not set. Processing all {len(in_sample_chunks)} in-sample chunks.\")\n",
    "elif not in_sample_chunks:\n",
    "    chunks_to_process = []\n",
    "    print(\"Warning: No in-sample chunks available to process.\")\n",
    "else:\n",
    "    chunks_to_process = in_sample_chunks[:BACKTEST_CHUNK_LIMIT]\n",
    "    print(f\"BACKTEST_CHUNK_LIMIT is set to {BACKTEST_CHUNK_LIMIT}. Processing the first {len(chunks_to_process)} of {len(in_sample_chunks)} available in-sample chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6102cebe",
   "metadata": {},
   "source": [
    "### Step 6: Execute In-Sample Backtest Loop via Papermill\n",
    "\n",
    "Iterate through the **in-sample** data chunks, save the train/test splits, and execute the worker notebook. The holdout data is not used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ec8d700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Papermill Execution Loop for 59 In-Sample chunks ---\n",
      "\n",
      "Executing In-Sample chunk 1/59...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76447607299840cb8264330c60ea8bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/17 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Executing In-Sample chunk 2/59...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e61c77469bd54a8e960bdb9da10dce65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/17 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- In-Sample Papermill execution complete. ---\n"
     ]
    }
   ],
   "source": [
    "# [MODIFIED] This step now operates only on `in_sample_chunks`.\n",
    "TEMP_DIR.mkdir(exist_ok=True)\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"--- Starting Papermill Execution Loop for {len(in_sample_chunks)} In-Sample chunks ---\")\n",
    "\n",
    "# The loop now iterates over in_sample_chunks\n",
    "for i, chunk in enumerate(in_sample_chunks[:2]):\n",
    "    # The rest of the logic inside the loop is the same, but the 'i' now corresponds\n",
    "    # to the index within the in_sample_chunks list.\n",
    "    returns_train = chunk.iloc[:TRAIN_TEST_SPLIT_POINT]\n",
    "    returns_test = chunk.iloc[TRAIN_TEST_SPLIT_POINT:]\n",
    "\n",
    "    train_file = TEMP_DIR / f\"returns_train_chunk_{i}.parquet\"\n",
    "    test_file = TEMP_DIR / f\"returns_test_chunk_{i}.parquet\"\n",
    "    result_file = OUTPUT_DIR / f\"result_chunk_{i}.parquet\"\n",
    "    output_notebook_path = OUTPUT_DIR / f\"output_notebook_chunk_{i}.ipynb\"\n",
    "\n",
    "    returns_train.to_parquet(train_file)\n",
    "    returns_test.to_parquet(test_file)\n",
    "\n",
    "    print(f\"\\nExecuting In-Sample chunk {i+1}/{len(in_sample_chunks)}...\")\n",
    "    # ... (rest of the Papermill execution logic is identical)\n",
    "    pm.execute_notebook(\n",
    "       input_path=WORKER_NOTEBOOK_PATH,\n",
    "       output_path=output_notebook_path,\n",
    "       parameters={\n",
    "           \"returns_train_path\": str(train_file),\n",
    "           \"returns_test_path\": str(test_file),\n",
    "           \"finviz_data_path\": str(DATA_DIR / FINVIZ_DATA_FILENAME),\n",
    "           \"output_path\": str(result_file),\n",
    "           \"benchmark_ticker\": BENCHMARK_TICKER,\n",
    "       },\n",
    "       kernel_name=\"python3\"\n",
    "    )\n",
    "\n",
    "print(\"\\n--- In-Sample Papermill execution complete. ---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2670b8",
   "metadata": {},
   "source": [
    "### Step 7: Aggregate and Save In-Sample Results\n",
    "\n",
    "Collect the individual result files from the in-sample run and combine them into a single, continuous time series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73ead09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully aggregated 2 in-sample result chunks.\n",
      "Final in-sample portfolio returns saved to: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\colab\\backtest_results\\in_sample_portfolio_returns.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Portfolio</th>\n",
       "      <th>Benchmark</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-02-01</th>\n",
       "      <td>-0.002675</td>\n",
       "      <td>0.002453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-02</th>\n",
       "      <td>-0.031677</td>\n",
       "      <td>-0.020259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-03</th>\n",
       "      <td>0.008096</td>\n",
       "      <td>-0.002297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-04</th>\n",
       "      <td>0.015184</td>\n",
       "      <td>0.002403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-05</th>\n",
       "      <td>-0.021902</td>\n",
       "      <td>-0.037456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Portfolio  Benchmark\n",
       "Date                            \n",
       "2016-02-01  -0.002675   0.002453\n",
       "2016-02-02  -0.031677  -0.020259\n",
       "2016-02-03   0.008096  -0.002297\n",
       "2016-02-04   0.015184   0.002403\n",
       "2016-02-05  -0.021902  -0.037456"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Portfolio</th>\n",
       "      <th>Benchmark</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-04-20</th>\n",
       "      <td>0.008825</td>\n",
       "      <td>0.002465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-21</th>\n",
       "      <td>0.002819</td>\n",
       "      <td>-0.000727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-22</th>\n",
       "      <td>0.008572</td>\n",
       "      <td>-0.014961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-25</th>\n",
       "      <td>-0.007720</td>\n",
       "      <td>-0.001945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-26</th>\n",
       "      <td>0.006864</td>\n",
       "      <td>-0.001763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Portfolio  Benchmark\n",
       "Date                            \n",
       "2016-04-20   0.008825   0.002465\n",
       "2016-04-21   0.002819  -0.000727\n",
       "2016-04-22   0.008572  -0.014961\n",
       "2016-04-25  -0.007720  -0.001945\n",
       "2016-04-26   0.006864  -0.001763"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [MODIFIED] This step now correctly aggregates the results from the in-sample run.\n",
    "all_results = []\n",
    "# The loop range must match the number of chunks processed in the previous step\n",
    "for i in range(len(in_sample_chunks[:2])):\n",
    "    result_file = OUTPUT_DIR / f\"result_chunk_{i}.parquet\"\n",
    "    if result_file.exists():\n",
    "        chunk_result = pd.read_parquet(result_file)\n",
    "        all_results.append(chunk_result)\n",
    "    else:\n",
    "        print(f\"Warning: Result file not found for chunk {i}: {result_file}\")\n",
    "\n",
    "if all_results:\n",
    "    in_sample_returns = pd.concat(all_results).sort_index()\n",
    "    in_sample_returns = in_sample_returns[~in_sample_returns.index.duplicated(keep='first')]\n",
    "\n",
    "    # Save the aggregated in-sample results\n",
    "    final_output_path = OUTPUT_DIR / IN_SAMPLE_RESULTS_FILENAME\n",
    "    in_sample_returns.to_parquet(final_output_path)\n",
    "\n",
    "    print(f\"Successfully aggregated {len(all_results)} in-sample result chunks.\")\n",
    "    print(f\"Final in-sample portfolio returns saved to: {final_output_path}\")\n",
    "    display(in_sample_returns.head())\n",
    "    display(in_sample_returns.tail())\n",
    "else:\n",
    "    print(\"No result files found to aggregate.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88959cf5",
   "metadata": {},
   "source": [
    "### Step 8: Cleanup Temporary Files\n",
    "Remove the intermediate temp_backtest_data directory to keep the project folder clean. This cell includes a retry mechanism to handle potential file-locking issues, especially on Windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edd92434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to remove temporary directory: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\colab\\temp_backtest_data\n",
      "✅ Successfully removed temporary directory on attempt 1.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import gc\n",
    "import time\n",
    "\n",
    "# --- Cleanup Configuration ---\n",
    "\n",
    "CLEANUP_RETRIES = 5\n",
    "CLEANUP_DELAY_SECONDS = 3\n",
    "\n",
    "# --- Execution ---\n",
    "\n",
    "if TEMP_DIR.exists():\n",
    "  print(f\"Attempting to remove temporary directory: {TEMP_DIR}\")\n",
    "  for attempt in range(CLEANUP_RETRIES):\n",
    "      # First, run garbage collection to help release any Python-level object locks\n",
    "      gc.collect()\n",
    "      \n",
    "      try:\n",
    "          shutil.rmtree(TEMP_DIR)\n",
    "          print(f\"✅ Successfully removed temporary directory on attempt {attempt + 1}.\")\n",
    "          break # Exit the loop if successful\n",
    "      except OSError as e:\n",
    "          print(f\"Attempt {attempt + 1}/{CLEANUP_RETRIES} failed: {e}\")\n",
    "          if attempt < CLEANUP_RETRIES - 1:\n",
    "              print(f\"Waiting {CLEANUP_DELAY_SECONDS} seconds before retrying...\")\n",
    "              time.sleep(CLEANUP_DELAY_SECONDS)\n",
    "          else:\n",
    "              print(f\"❌ Error: Could not remove temporary directory after {CLEANUP_RETRIES} attempts.\")\n",
    "              print(\"A file may still be locked by another process. You may need to restart the kernel and delete the directory manually.\")\n",
    "  else:\n",
    "      print(\"Temporary directory not found, no cleanup needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d23f18e",
   "metadata": {},
   "source": [
    "### Step 9: Verifying on Holdout Data (Next Steps)\n",
    "\n",
    "The `holdout_chunks` have been preserved and were not used in the backtest above. They can now be used for a true out-of-sample test of the final strategy. This would typically be done in a separate verification notebook (`py12_holdout_verification.ipynb`) to maintain a clean workflow.\n",
    "\n",
    "A simplified version of that process would look like this:\n",
    "\n",
    "```python\n",
    "# --- PSEUDO-CODE for a future holdout test ---\n",
    "\n",
    "# # 1. Loop through the holdout_chunks\n",
    "# for i, chunk in enumerate(holdout_chunks):\n",
    "#     # The chunk index 'i' would need to be offset to avoid overwriting temp files\n",
    "#     # if run in the same script.\n",
    "#     chunk_index_offset = len(in_sample_chunks) + i\n",
    "#\n",
    "#     # 2. Run papermill exactly as before on each holdout chunk\n",
    "#     pm.execute_notebook(...)\n",
    "#\n",
    "# # 3. Aggregate the holdout results into a separate file\n",
    "# holdout_results = pd.concat(...)\n",
    "# holdout_results.to_parquet(OUTPUT_DIR / HOLDOUT_RESULTS_FILENAME)\n",
    "#\n",
    "# # 4. Compare the performance metrics (Sharpe, CAGR, Drawdown) of the\n",
    "# #    in_sample_returns vs. the holdout_returns to check for overfitting.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
