{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9ae2708",
   "metadata": {},
   "source": [
    "# Here is the refactored solution. I have separated the concerns into three distinct layers:\n",
    "1.  **The Data Contract:** explicit `dataclasses` defining exactly what goes in and comes out.\n",
    "2.  **The Engine:** A purely mathematical class (`AlphaEngine`) containing the logic, with no widget/plotting dependencies.\n",
    "3.  **The UI:** A cleaned-up dashboard function that simply sends inputs to the Engine and visualizes the Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc79d79",
   "metadata": {},
   "source": [
    "### Following is the reverse chronological fix log (most recent entry is at the top )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a74d53",
   "metadata": {},
   "source": [
    "v46  \n",
    "**Corrected the \"Weight Drift\" logic** in the Engine, ensuring it re-initializes to ticker weights at start of Holding Period, making it a true trading simulation.  \n",
    "**Verified Engine Calculation with Excel** so that \"Full\" is a drifted path and \"Holding\" is a fresh execution.  \n",
    "**Output Debug CSV files to directory**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b271d30",
   "metadata": {},
   "source": [
    "v45  \n",
    "You are very welcome! We have taken the code from a basic script and transformed it into a professional-grade **Alpha Engine** with:\n",
    "\n",
    "1.  **Centralized Control:** `GLOBAL_SETTINGS` now acts as the single \"Source of Truth\" for your entire environment.\n",
    "2.  **Mathematical Integrity:** By linking the Registry to your helper functions, you've ensured your rankings and performance reports will never disagree.\n",
    "3.  **Data Resilience:** The new \"Clean-at-Entry\" layer protects your backtests from data glitches like the `0.0` price spikes you found.\n",
    "4.  **User-Centric UX:** The improved timeline validation makes the tool much more intuitive to use.\n",
    "\n",
    "Happy backtesting! If you run into any more \"data ghosts\" or want to add more complex logic, feel free to reach out. **Good luck with the strategy!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6368ecc4",
   "metadata": {},
   "source": [
    "v44  \n",
    "I think the **\"Pinpointed Changes\"** approach is much better for learning. It allows you to see exactly how the \"plumbing\" of the code connects without getting overwhelmed by 500 lines of existing logic.\n",
    "\n",
    "The changes are simple because they follow a **\"Find and Replace\"** pattern in three specific spots. \n",
    "\n",
    "Here is how I will present them to you:\n",
    "\n",
    "### The 3 Pinpoint Locations:\n",
    "\n",
    "1.  **The \"Head\" (New Global Config):**\n",
    "    *   **Where:** Right before Section B (Metric Registry).\n",
    "    *   **What:** We will insert the \"Source of Truth\" dictionary here with all your descriptive comments.\n",
    "\n",
    "2.  **The \"Heart\" (Engine Input):**\n",
    "    *   **Where:** In Section C, inside the `@dataclass class EngineInput`.\n",
    "    *   **What:** We will change the `default_factory` to point to the Head. This ensures the engine always knows the rules.\n",
    "\n",
    "3.  **The \"Face\" (The UI Function):**\n",
    "    *   **Where:** In Section E, at the start of `def plot_walk_forward_analyzer`.\n",
    "    *   **What:** we will remove the hard-coded dictionary and tell it to use the Head as the default.\n",
    "\n",
    "---\n",
    "\n",
    "### Why this is better than a full code dump:\n",
    "*   **You learn \"DRY\" Principles:** You'll see how to avoid \"Repeating Yourself\" (DRY) by using a single variable in multiple places.\n",
    "*   **You see the \"Mapping\":** You will understand how a variable defined at the top of a script flows down into a class, and finally into a visual widget.\n",
    "*   **Easier Debugging:** If you want to change the liquidity to \"Top 20%\" tomorrow, you will know exactly which single line to touch.\n",
    "\n",
    "**Are you ready for me to provide these three specific code blocks for you to swap in?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f18a51d",
   "metadata": {},
   "source": [
    "v43  \n",
    "**1. The Logic Core (AlphaEngine v2.4) -> üü¢ CLEAN**\n",
    "*   **Verdict:** This is robust.\n",
    "*   **Why:** We stripped out the hidden index math and replaced it with **Explicit Dates** (`decision_date` vs `buy_date`).\n",
    "*   **Big Win:** The separation of `_validate_timeline`, `_select_tickers`, and `_calculate_period_metrics` means you can debug one part without breaking the others.\n",
    "*   **The Verification Suite:** The fact that we have 3 independent auditors (`verify_engine_integrity`, `verify_portfolio_construction`, `verify_ticker_ranking_logic`) means we are no longer \"guessing\" if the math is right. We *know* it is right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e7f873",
   "metadata": {},
   "source": [
    "v38  \n",
    "Added Momentum and Pullback strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1ecc32",
   "metadata": {},
   "source": [
    "v37  \n",
    "For an automated bot (and for rigorous scientific testing), **Silent Auto-Correction (Clamping)** is dangerous. If the bot asks for \"2080\" and receives data for \"2025\", it creates \"Data Hallucinations.\"\n",
    "\n",
    "We need to replace the \"Clamping\" logic with **\"Strict Validation\" logic**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d784b62",
   "metadata": {},
   "source": [
    "v36  \n",
    "The step `self.df_close = df_ohlcv['Adj Close'].unstack(level=0)` is an expensive \"Pivot\" operation. It takes a \"Tall and Skinny\" table (1 million rows) and reshapes it into a \"Short and Wide\" matrix (Dates x Tickers). Pandas hates doing this repeatedly.\n",
    "\n",
    "Yes, we can pre-compute this matrix and pass it in, just like we did with the featur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92185d85",
   "metadata": {},
   "source": [
    "v35  \n",
    "This is a great optimization step. In data science, this is called **\"Memoization\"** or **\"Caching\"**‚Äîdo the heavy math once, save it, and reuse it.\n",
    "\n",
    "To achieve this, we need to modify the **`AlphaEngine` constructor** to accept pre-calculated features, and update the **`plot_walk_forward_analyzer`** to pass them down.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7578ec93",
   "metadata": {},
   "source": [
    "v34  \n",
    "I have refactored **SECTION D (`AlphaEngine.run`)** to implement the \"Decision Anchor\" logic, and **SECTION E (`plot_walk_forward_analyzer`)** to implement the new \"Timeline\" UI layout and renaming.\n",
    "\n",
    "### Key Changes:\n",
    "1.  **Engine Logic:** The `start_date` input is now treated as the **Decision Date (T0)**. The engine calculates backward for the Lookback period and forward for the Holding period.\n",
    "2.  **Universe Selection:** Tickers are now filtered based on liquidity **on the Decision Date**, not the start of history.\n",
    "3.  **UI Layout:** Inputs are arranged horizontally: `[Lookback] <-> [Decision Date] <-> [Holding]`.\n",
    "4.  **Renaming:** \"Metric\" is now **\"Strategy\"**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17abb82d",
   "metadata": {},
   "source": [
    "v33  \n",
    "**Action Item to make it perfect:**\n",
    "Change the \"Fwd Gain\" calculation in `AlphaEngine.run` to skip one day, or accept that your results are slightly optimistic due to the \"Overnight Gap\" bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68b1a41",
   "metadata": {},
   "source": [
    "```\n",
    "To see the full dataframe of all tickers (both those that passed and those that failed) for a specific date, we need to capture a snapshot of the universe inside the `_get_eligible_universe` method.\n",
    "\n",
    "I have updated the **`AlphaEngine`** class below.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30d1f60",
   "metadata": {},
   "source": [
    "```\n",
    "To verify that the relative percentile logic is working, we can modify the `AlphaEngine` to report exactly **how the cutoff was calculated** for the specific start date.\n",
    "\n",
    "We want to see evidence that:\n",
    "1.  In earlier years (e.g., 2005), the volume cutoff is lower (e.g., $200k).\n",
    "2.  In later years (e.g., 2024), the volume cutoff is higher (e.g., $5M).\n",
    "\n",
    "Here is the updated `AlphaEngine` and `UI` code. I have added a **\"Audit Log\"** feature. When you run the tool, it will now print exactly what the Dollar Volume Threshold was for that specific day.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50de4e99",
   "metadata": {},
   "source": [
    "```\n",
    "The best way to solve this is to switch from a **Fixed Dollar Threshold** (e.g., \"$1 Million\") to a **Relative Percentile Threshold** (e.g., \"Top 50% of the market\").\n",
    "\n",
    "In 2004, a stock trading $200k might have been in the top 50% of liquid stocks. In 2024, that same $200k is illiquid garbage. Using a percentile automatically adjusts for inflation and market growth over time.\n",
    "\n",
    "Here is how to modify your code to support this.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e8a3b9",
   "metadata": {},
   "source": [
    "```\n",
    "To fix this, we need to pass the **actual** calculated start date (the trading day the engine \"snapped\" to) back from the `AlphaEngine` to the UI. Then, the UI can compare the *Requested Date* vs. the *Actual Date* and display the warning message if they differ.\n",
    "\n",
    "Here is the plan:\n",
    "1.  **Update `EngineOutput`**: Add a `start_date` field to the dataclass.\n",
    "2.  **Update `AlphaEngine.run`**: Populate this new field with `safe_start_date`.\n",
    "3.  **Update `plot_walk_forward_analyzer`**: Add logic to compare the user's input date with the engine's returned date and print the \"Info\" message if they are different.\n",
    "\n",
    "Here is the updated code (Sections C, D, and E have changed):\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb918f61",
   "metadata": {},
   "source": [
    "```\n",
    "I have updated the `AlphaEngine.run` method. specifically inside the `if inputs.mode == 'Manual List':` block. It now iterates through every manual ticker and performs two checks:\n",
    "1.  **Existence**: Is the ticker in the database?\n",
    "2.  **Availability**: Does the ticker have a valid price on the specific `Start Date`?\n",
    "\n",
    "If any ticker fails, it compiles a specific error message explaining why (e.g., \"No price data on start date\") and aborts the calculation immediately.  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b728a8",
   "metadata": {},
   "source": [
    "```\n",
    "The `snapshot_df` contains **every single feature** calculated by your `generate_features` function for that specific day, plus the new audit columns we added.\n",
    "\n",
    "Here is exactly what is inside that DataFrame:\n",
    "\n",
    "### 1. The Core Features (from `generate_features`)\n",
    "*   **`TR`**: True Range\n",
    "*   **`ATR`**: Average True Range\n",
    "*   **`ATRP`**: Average True Range Percent (Volatility)\n",
    "*   **`RollingStalePct`**: How often the price didn't move or volume was 0.\n",
    "*   **`RollMedDollarVol`**: Median Daily Dollar Volume (Liquidity).\n",
    "*   **`RollingSameVolCount`**: Data quality check for repeated volume numbers.\n",
    "\n",
    "### 2. The Audit Columns (Added during filtering)\n",
    "*   **`Calculated_Cutoff`**: The specific dollar amount required to pass on that day.\n",
    "*   **`Passed_Vol_Check`**: `True` if the ticker met the liquidity requirement.\n",
    "*   **`Passed_Final`**: `True` if it passed **all** checks (Liquidity + Stale + Quality).\n",
    "\n",
    "=========================================\n",
    "\n",
    "Here are the formulas translated directly into the Python `pandas` code used in your `generate_features` function.\n",
    "\n",
    "I have simplified the code slightly to assume a single ticker context (removing the `groupby` wrapper) so you can see the raw math clearly.\n",
    "\n",
    "### 1. True Range (TR)\n",
    "Calculates the maximum of the three price differences.\n",
    "\n",
    "prev_close = df_ohlcv['Adj Close'].shift(1)\n",
    "\n",
    "# The three components\n",
    "diff1 = df_ohlcv['Adj High'] - df_ohlcv['Adj Low']\n",
    "diff2 = (df_ohlcv['Adj High'] - prev_close).abs()\n",
    "diff3 = (df_ohlcv['Adj Low'] - prev_close).abs()\n",
    "\n",
    "# Taking the max of the three\n",
    "tr = pd.concat([diff1, diff2, diff3], axis=1).max(axis=1)\n",
    "\n",
    "### 2. Average True Range (ATR)\n",
    "Uses an Exponential Weighted Mean (EWM) with a specific alpha smoothing factor.\n",
    "\n",
    "# N = atr_period (e.g., 14)\n",
    "# alpha = 1 / N\n",
    "atr = tr.ewm(alpha=1/14, adjust=False).mean()\n",
    "\n",
    "### 3. ATR Percent (ATRP)\n",
    "Simple division to normalize volatility.\n",
    "\n",
    "atrp = atr / df_ohlcv['Adj Close']\n",
    "\n",
    "### 4. Rolling Stale Percentage\n",
    "Checks if volume is 0 OR if High equals Low (price didn't move), then averages that 1 or 0 signal over the window.\n",
    "\n",
    "# 1. Define the Stale Signal (1 for stale, 0 for active)\n",
    "is_stale = np.where(\n",
    "    (df_ohlcv['Volume'] == 0) | (df_ohlcv['Adj High'] == df_ohlcv['Adj Low']), \n",
    "    1,  \n",
    "    0\n",
    ")\n",
    "\n",
    "# 2. Calculate average over window (W=252)\n",
    "rolling_stale_pct = pd.Series(is_stale).rolling(window=252).mean()\n",
    "\n",
    "### 5. Rolling Median Dollar Volume\n",
    "Calculates raw dollar volume, then finds the median over the window.\n",
    "\n",
    "# 1. Calculate Daily Dollar Volume\n",
    "dollar_volume = df_ohlcv['Adj Close'] * df_ohlcv['Volume']\n",
    "\n",
    "# 2. Get Median over window (W=252)\n",
    "roll_med_dollar_vol = dollar_volume.rolling(window=252).median()\n",
    "\n",
    "### 6. Rolling Same Volume Count\n",
    "Checks if today's volume is exactly the same as yesterday's (a sign of bad data), then sums those occurrences.\n",
    "\n",
    "# 1. Check if Volume(t) - Volume(t-1) equals 0\n",
    "# .diff() calculates current row minus previous row\n",
    "has_same_volume = (df_ohlcv['Volume'].diff() == 0).astype(int)\n",
    "\n",
    "# 2. Sum the errors over window (W=252)\n",
    "rolling_same_vol_count = has_same_volume.rolling(window=252).sum()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb417c7",
   "metadata": {},
   "source": [
    "================================  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1110f2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from dataclasses import dataclass, field, asdict, is_dataclass\n",
    "from typing import List, Dict, Optional, Any, Union, TypedDict\n",
    "from collections import Counter\n",
    "from datetime import datetime, date\n",
    "from pandas.testing import assert_series_equal\n",
    "\n",
    "\n",
    "# pd.set_option('display.max_rows', None)  display all rows\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"display.max_colwidth\", 50)\n",
    "pd.set_option(\"display.precision\", 4)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# GLOBAL SETTINGS: The \"Control Panel\" for the Strategy\n",
    "# ==============================================================================\n",
    "\n",
    "GLOBAL_SETTINGS = {\n",
    "    # ENVIRONMENT (The \"Where\")\n",
    "    \"benchmark_ticker\": \"SPY\",\n",
    "    \"calendar_ticker\": \"SPY\",  # Used as the \"Master Clock\" for trading days\n",
    "    # DATA SANITIZER (The \"Glitches & Gaps\" Protector)\n",
    "    \"handle_zeros_as_nan\": True,  # Convert 0.0 prices to NaN to prevent math errors\n",
    "    \"max_data_gap_ffill\": 1,  # Max consecutive days to \"Forward Fill\" missing data\n",
    "    # IMPLICATION OF nan_price_replacement:\n",
    "    # - This defines what happens if the \"Forward Fill\" limit is exceeded.\n",
    "    # - If set to 0.0: A permanent data gap will look like a \"total loss\" (-100%).\n",
    "    #   The equity curve will plummet. Good for \"disaster detection.\"\n",
    "    #   Sharpe and Sharpe(ATR) drop because: return (gets smaller) / std (gets larger)\n",
    "    # - If set to np.nan: A permanent gap will cause portfolio calculations to return NaN.\n",
    "    #   The chart may break or show gaps. Good for \"math integrity.\"\n",
    "    \"nan_price_replacement\": 0.0,\n",
    "    # STRATEGY PARAMETERS (The \"How\")\n",
    "    \"atr_period\": 14,  # Used for volatility normalization\n",
    "    \"quality_window\": 252,  # 1 year lookback for liquidity/quality stats\n",
    "    \"quality_min_periods\": 126,  # Min history required to judge a stock\n",
    "    # QUALITY THRESHOLDS (The \"Rules\")\n",
    "    \"thresholds\": {\n",
    "        # HARD LIQUIDITY FLOOR\n",
    "        # Logic: Calculates (Adj Close * Volume) daily, then takes the ROLLING MEDIAN\n",
    "        # over the quality_window (252 days). Filters out stocks where the\n",
    "        # typical daily dollar turnover is below this absolute value.\n",
    "        \"min_median_dollar_volume\": 1_000_000,\n",
    "        # DYNAMIC LIQUIDITY CUTOFF (Relative to Universe)\n",
    "        # Logic: On the decision date, the engine calculates the X-quantile\n",
    "        # of 'RollMedDollarVol' across ALL available stocks.\n",
    "        # Setting this to 0.40 calculates the 60th percentile and requires\n",
    "        # stocks to be above it‚Äîeffectively keeping only the TOP 60% of the market.\n",
    "        \"min_liquidity_percentile\": 0.40,\n",
    "        # PRICE/VOLUME STALENESS\n",
    "        # Logic: Creates a binary flag (1 if Volume is 0 OR High equals Low).\n",
    "        # It then calculates the ROLLING MEAN of this flag.\n",
    "        # A value of 0.05 means the stock is rejected if it was \"stale\"\n",
    "        # for more than 5% of the trading days in the rolling window.\n",
    "        \"max_stale_pct\": 0.05,\n",
    "        # DATA INTEGRITY (FROZEN VOLUME)\n",
    "        # Logic: Checks if Volume is identical to the previous day (Volume.diff() == 0).\n",
    "        # It calculates the ROLLING SUM of these occurrences over the window.\n",
    "        # If the exact same volume is reported more than 10 times, the stock\n",
    "        # is rejected as having \"frozen\" or low-quality data.\n",
    "        \"max_same_vol_count\": 10,\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION A: CORE HELPER FUNCTIONS & FEATURE GENERATION\n",
    "# (Unchanged from previous version)\n",
    "# ==============================================================================\n",
    "# ... (Keep generate_features, calculate_gain, calculate_sharpe,\n",
    "#      calculate_sharpe_atr, calculate_buy_and_hold_performance as is) ...\n",
    "\n",
    "\n",
    "def generate_features(\n",
    "    df_ohlcv: pd.DataFrame,\n",
    "    atr_period: int = 14,\n",
    "    quality_window: int = 252,\n",
    "    quality_min_periods: int = 126,\n",
    ") -> pd.DataFrame:\n",
    "    # 1. Sort and Group\n",
    "    if not df_ohlcv.index.is_monotonic_increasing:\n",
    "        df_ohlcv = df_ohlcv.sort_index()\n",
    "    grouped = df_ohlcv.groupby(level=\"Ticker\")\n",
    "\n",
    "    # 2. ATR Calculation (Existing)\n",
    "    prev_close = grouped[\"Adj Close\"].shift(1)\n",
    "    tr = pd.concat(\n",
    "        [\n",
    "            df_ohlcv[\"Adj High\"] - df_ohlcv[\"Adj Low\"],\n",
    "            abs(df_ohlcv[\"Adj High\"] - prev_close),\n",
    "            abs(df_ohlcv[\"Adj Low\"] - prev_close),\n",
    "        ],\n",
    "        axis=1,\n",
    "    ).max(axis=1, skipna=False)\n",
    "\n",
    "    atr = tr.groupby(level=\"Ticker\").transform(\n",
    "        lambda x: x.ewm(alpha=1 / atr_period, adjust=False).mean()\n",
    "    )\n",
    "    atrp = (atr / df_ohlcv[\"Adj Close\"]).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # 3. --- NEW: MOMENTUM / RETURN FEATURES ---\n",
    "    # We calculate percentage change for specific windows useful for Pullbacks (3D, 5D) and Trends (21D)\n",
    "    # Note: We use grouped.pct_change to respect Ticker boundaries\n",
    "    roc_1 = grouped[\"Adj Close\"].pct_change(1)\n",
    "    roc_3 = grouped[\"Adj Close\"].pct_change(3)\n",
    "    roc_5 = grouped[\"Adj Close\"].pct_change(5)\n",
    "    roc_10 = grouped[\"Adj Close\"].pct_change(10)\n",
    "    roc_21 = grouped[\"Adj Close\"].pct_change(21)\n",
    "\n",
    "    indicator_df = pd.DataFrame(\n",
    "        {\n",
    "            \"ATR\": atr,\n",
    "            \"ATRP\": atrp,\n",
    "            \"ROC_1\": roc_1,\n",
    "            \"ROC_3\": roc_3,\n",
    "            \"ROC_5\": roc_5,\n",
    "            \"ROC_10\": roc_10,\n",
    "            \"ROC_21\": roc_21,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # 4. Quality/Liquidity Features (Existing)\n",
    "    quality_temp_df = pd.DataFrame(\n",
    "        {\n",
    "            \"IsStale\": np.where(\n",
    "                (df_ohlcv[\"Volume\"] == 0)\n",
    "                | (df_ohlcv[\"Adj High\"] == df_ohlcv[\"Adj Low\"]),\n",
    "                1,\n",
    "                0,\n",
    "            ),\n",
    "            \"DollarVolume\": df_ohlcv[\"Adj Close\"] * df_ohlcv[\"Volume\"],\n",
    "            \"HasSameVolume\": (grouped[\"Volume\"].diff() == 0).astype(int),\n",
    "        },\n",
    "        index=df_ohlcv.index,\n",
    "    )\n",
    "\n",
    "    rolling_result = (\n",
    "        quality_temp_df.groupby(level=\"Ticker\")\n",
    "        .rolling(window=quality_window, min_periods=quality_min_periods)\n",
    "        .agg({\"IsStale\": \"mean\", \"DollarVolume\": \"median\", \"HasSameVolume\": \"sum\"})\n",
    "        .rename(\n",
    "            columns={\n",
    "                \"IsStale\": \"RollingStalePct\",\n",
    "                \"DollarVolume\": \"RollMedDollarVol\",\n",
    "                \"HasSameVolume\": \"RollingSameVolCount\",\n",
    "            }\n",
    "        )\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    # 5. Merge\n",
    "    return pd.concat([indicator_df, rolling_result], axis=1)\n",
    "\n",
    "\n",
    "def calculate_buy_and_hold_performance(\n",
    "    df_close, features_df, tickers, start_date, end_date\n",
    "):\n",
    "    if not tickers:\n",
    "        return pd.Series(dtype=float), pd.Series(dtype=float), pd.Series(dtype=float)\n",
    "    ticker_counts = Counter(tickers)\n",
    "    initial_weights = pd.Series({t: c / len(tickers) for t, c in ticker_counts.items()})\n",
    "    prices_raw = df_close[initial_weights.index.tolist()].loc[start_date:end_date]\n",
    "    if prices_raw.dropna(how=\"all\").empty:\n",
    "        return pd.Series(dtype=float), pd.Series(dtype=float), pd.Series(dtype=float)\n",
    "    prices_norm = prices_raw.div(prices_raw.bfill().iloc[0])\n",
    "    weighted_growth = prices_norm.mul(initial_weights, axis=\"columns\")\n",
    "    value_series = weighted_growth.sum(axis=1)\n",
    "    return_series = value_series.ffill().pct_change()\n",
    "    full_idx = pd.MultiIndex.from_product(\n",
    "        [initial_weights.index.tolist(), return_series.index], names=[\"Ticker\", \"Date\"]\n",
    "    )\n",
    "    feat_subset = features_df.reindex(full_idx)[\"ATRP\"].unstack(level=\"Ticker\")\n",
    "    atrp_series = (\n",
    "        weighted_growth.div(value_series, axis=\"index\").align(\n",
    "            feat_subset, join=\"inner\", axis=1\n",
    "        )[0]\n",
    "        * weighted_growth.div(value_series, axis=\"index\").align(\n",
    "            feat_subset, join=\"inner\", axis=1\n",
    "        )[1]\n",
    "    ).sum(axis=1)\n",
    "    return value_series, return_series, atrp_series\n",
    "\n",
    "\n",
    "def calculate_summary_gain(price_series: pd.Series) -> float:\n",
    "    \"\"\"REPORTING: Returns the total return of a single series.\"\"\"\n",
    "    if price_series.dropna().shape[0] < 2:\n",
    "        return 0.0\n",
    "    # (Final Price / Starting Price) - 1\n",
    "    res = (price_series.ffill().iloc[-1] / price_series.bfill().iloc[0]) - 1\n",
    "    return float(res) if np.isfinite(res) else 0.0\n",
    "\n",
    "\n",
    "def calculate_cross_sectional_gain(price_df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"RANKING: Returns the total return for every ticker in the universe.\"\"\"\n",
    "    if price_df.empty:\n",
    "        return pd.Series(dtype=float)\n",
    "    # Vectorized calculation across all columns (tickers)\n",
    "    res = (price_df.ffill().iloc[-1] / price_df.bfill().iloc[0]) - 1\n",
    "    return res.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "\n",
    "def calculate_summary_sharpe(return_series: pd.Series) -> float:\n",
    "    \"\"\"REPORTING: Returns a single Reward value.\"\"\"\n",
    "    if return_series.dropna().shape[0] < 2:\n",
    "        return 0.0\n",
    "    mu, std = return_series.mean(), return_series.std()\n",
    "\n",
    "    # SENIOR FIX: Volatility floor to prevent 'Infinity' or 'Exploding' rewards\n",
    "    if std < 1e-6:\n",
    "        return 0.0\n",
    "\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        res = (mu / std) * np.sqrt(252)\n",
    "    return float(res) if np.isfinite(res) else 0.0\n",
    "\n",
    "\n",
    "def calculate_cross_sectional_sharpe(return_df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"RANKING: Returns a Series of values for the whole universe.\"\"\"\n",
    "    if return_df.empty:\n",
    "        return pd.Series(dtype=float)\n",
    "    mu, std = return_df.mean(), return_df.std()\n",
    "\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        res = (mu / std) * np.sqrt(252)\n",
    "\n",
    "    # SENIOR FIX: Convert 'Broken' data (std=0) into 0.0 reward\n",
    "    return res.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "\n",
    "def calculate_summary_sharpe_atr(\n",
    "    return_series: pd.Series, atrp_input: Union[pd.Series, float]\n",
    ") -> float:\n",
    "    \"\"\"REPORTING: Returns a single Reward value normalized by Volatility.\"\"\"\n",
    "    if return_series.dropna().shape[0] < 2:\n",
    "        return 0.0\n",
    "    avg_atrp = atrp_input.mean() if hasattr(atrp_input, \"mean\") else atrp_input\n",
    "\n",
    "    if avg_atrp < 1e-6:\n",
    "        return 0.0  # Safety floor\n",
    "\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        res = return_series.mean() / avg_atrp\n",
    "    return float(res) if np.isfinite(res) else 0.0\n",
    "\n",
    "\n",
    "def calculate_cross_sectional_sharpe_atr(\n",
    "    return_df: pd.DataFrame, atrp_series: pd.Series\n",
    ") -> pd.Series:\n",
    "    \"\"\"RANKING: Returns a Series of Volatility-normalized values.\"\"\"\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        res = return_df.mean() / atrp_series\n",
    "    return res.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION B: METRIC REGISTRY (UPDATED VARIABLES)\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "class MarketObservation(TypedDict):\n",
    "    \"\"\"\n",
    "    The 'STATE' (Observation) in Reinforcement Learning.\n",
    "    This defines the context given to the agent to make a decision.\n",
    "    \"\"\"\n",
    "\n",
    "    lookback_returns: pd.DataFrame  # (Time x Tickers)\n",
    "    lookback_close: pd.DataFrame  # (Time x Tickers)\n",
    "    atrp: pd.Series  # (Tickers,) - The mean ATR% over lookback\n",
    "    roc_1: pd.Series  # (Tickers,) - Current 1D Momentum\n",
    "    roc_3: pd.Series  # ... etc\n",
    "    roc_5: pd.Series\n",
    "    roc_10: pd.Series\n",
    "    roc_21: pd.Series\n",
    "\n",
    "\n",
    "# Use the centralized helper functions for calculations\n",
    "\n",
    "\n",
    "def metric_price(obs: MarketObservation) -> pd.Series:\n",
    "    return calculate_cross_sectional_gain(obs[\"lookback_close\"])\n",
    "\n",
    "\n",
    "def metric_sharpe(obs: MarketObservation) -> pd.Series:\n",
    "    return calculate_cross_sectional_sharpe(obs[\"lookback_returns\"])\n",
    "\n",
    "\n",
    "def metric_sharpe_atr(obs: MarketObservation) -> pd.Series:\n",
    "    return calculate_cross_sectional_sharpe_atr(obs[\"lookback_returns\"], obs[\"atrp\"])\n",
    "\n",
    "\n",
    "METRIC_REGISTRY = {\n",
    "    \"Price\": metric_price,\n",
    "    \"Sharpe\": metric_sharpe,\n",
    "    \"Sharpe (ATR)\": metric_sharpe_atr,\n",
    "    \"Momentum 1D\": lambda obs: obs[\"roc_1\"],\n",
    "    \"Momentum 3D\": lambda obs: obs[\"roc_3\"],\n",
    "    \"Momentum 5D\": lambda obs: obs[\"roc_5\"],\n",
    "    \"Momentum 10D\": lambda obs: obs[\"roc_10\"],\n",
    "    \"Momentum 1M\": lambda obs: obs[\"roc_21\"],\n",
    "    \"Pullback 1D\": lambda obs: -obs[\"roc_1\"],\n",
    "    \"Pullback 3D\": lambda obs: -obs[\"roc_3\"],\n",
    "    \"Pullback 5D\": lambda obs: -obs[\"roc_5\"],\n",
    "    \"Pullback 10D\": lambda obs: -obs[\"roc_10\"],\n",
    "    \"Pullback 1M\": lambda obs: -obs[\"roc_21\"],\n",
    "}\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION C: DATA CONTRACTS (UPDATED v2.2 - Verification Ready)\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EngineInput:\n",
    "    mode: str\n",
    "    start_date: pd.Timestamp\n",
    "    lookback_period: int\n",
    "    holding_period: int\n",
    "    metric: str\n",
    "    benchmark_ticker: str\n",
    "    rank_start: int = 1\n",
    "    rank_end: int = 10\n",
    "    # Default factory pulls from Global thresholds\n",
    "    quality_thresholds: Dict[str, float] = field(\n",
    "        default_factory=lambda: GLOBAL_SETTINGS[\"thresholds\"].copy()\n",
    "    )\n",
    "    manual_tickers: List[str] = field(default_factory=list)\n",
    "    debug: bool = False\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EngineOutput:\n",
    "    portfolio_series: pd.Series\n",
    "    benchmark_series: pd.Series\n",
    "    normalized_plot_data: pd.DataFrame\n",
    "    tickers: List[str]\n",
    "    initial_weights: pd.Series\n",
    "    perf_metrics: Dict[str, float]\n",
    "    results_df: pd.DataFrame\n",
    "\n",
    "    # Dates\n",
    "    start_date: pd.Timestamp\n",
    "    decision_date: pd.Timestamp\n",
    "    buy_date: pd.Timestamp\n",
    "    holding_end_date: pd.Timestamp\n",
    "\n",
    "    error_msg: Optional[str] = None\n",
    "    debug_data: Optional[Dict[str, Any]] = None\n",
    "\n",
    "\n",
    "class AlphaEngine:\n",
    "    def __init__(\n",
    "        self,\n",
    "        df_ohlcv: pd.DataFrame,\n",
    "        features_df: pd.DataFrame = None,\n",
    "        df_close_wide: pd.DataFrame = None,\n",
    "        master_ticker: str = GLOBAL_SETTINGS[\"calendar_ticker\"],\n",
    "    ):\n",
    "        print(\"--- ‚öôÔ∏è Initializing AlphaEngine v2.2 (Sanitized) ---\")\n",
    "\n",
    "        # 1. SETUP PRICES (CLEAN-AT-ENTRY)\n",
    "        if df_close_wide is not None:\n",
    "            self.df_close = df_close_wide\n",
    "        else:\n",
    "            print(\"üê¢ Pivoting and Sanitizing Price Data...\")\n",
    "            self.df_close = df_ohlcv[\"Adj Close\"].unstack(level=0)\n",
    "\n",
    "        # APPLY DATA SANITIZER LOGIC\n",
    "        if GLOBAL_SETTINGS[\"handle_zeros_as_nan\"]:\n",
    "            # Replace 0.0 with NaN so math functions (mean/std) ignore them\n",
    "            self.df_close = self.df_close.replace(0, np.nan)\n",
    "\n",
    "        # Smooth over 1-2 day glitches (The \"FNV\" Fix)\n",
    "        self.df_close = self.df_close.ffill(limit=GLOBAL_SETTINGS[\"max_data_gap_ffill\"])\n",
    "\n",
    "        # Handle the remaining \"unfillable\" gaps\n",
    "        self.df_close = self.df_close.fillna(GLOBAL_SETTINGS[\"nan_price_replacement\"])\n",
    "\n",
    "        # 2. SETUP FEATURES\n",
    "        if features_df is not None:\n",
    "            self.features_df = features_df\n",
    "        else:\n",
    "            # We pass the cleaned price data if needed, or calculate from raw\n",
    "            self.features_df = generate_features(\n",
    "                df_ohlcv,\n",
    "                atr_period=GLOBAL_SETTINGS[\"atr_period\"],\n",
    "                quality_window=GLOBAL_SETTINGS[\"quality_window\"],\n",
    "                quality_min_periods=GLOBAL_SETTINGS[\"quality_min_periods\"],\n",
    "            )\n",
    "\n",
    "        # 3. Setup Calendar\n",
    "        if master_ticker not in self.df_close.columns:\n",
    "            master_ticker = self.df_close.columns[0]\n",
    "        self.trading_calendar = (\n",
    "            self.df_close[master_ticker].dropna().index.unique().sort_values()\n",
    "        )\n",
    "\n",
    "    # def run(self, inputs: EngineInput) -> EngineOutput:\n",
    "    #     # ... (Step 1 & 2 are unchanged) ...\n",
    "    #     dates, error = self._validate_timeline(inputs)\n",
    "    #     if error: return self._error_result(error)\n",
    "    #     (safe_start, safe_decision, safe_buy, safe_end) = dates\n",
    "\n",
    "    #     tickers_to_trade, results_table, debug_dict, error = self._select_tickers(\n",
    "    #         inputs, safe_start, safe_decision\n",
    "    #     )\n",
    "    #     if error: return self._error_result(error)\n",
    "\n",
    "    #     # --- Step 3: Generate Two Independent Performance Tracks ---\n",
    "\n",
    "    #     # TRACK A: Continuous Drift (For 'Full' and 'Lookback' metrics)\n",
    "    #     p_full_val, p_full_ret, p_full_atrp = calculate_buy_and_hold_performance(\n",
    "    #         self.df_close, self.features_df, tickers_to_trade, safe_start, safe_end\n",
    "    #     )\n",
    "    #     b_full_val, b_full_ret, b_full_atrp = calculate_buy_and_hold_performance(\n",
    "    #         self.df_close, self.features_df, [inputs.benchmark_ticker], safe_start, safe_end\n",
    "    #     )\n",
    "\n",
    "    #     # TRACK B: Independent Holding (RE-INITIALIZED Weights for 'Holding' metrics)\n",
    "    #     p_hd_val, p_hd_ret, p_hd_atrp = calculate_buy_and_hold_performance(\n",
    "    #         self.df_close, self.features_df, tickers_to_trade, safe_buy, safe_end\n",
    "    #     )\n",
    "    #     b_hd_val, b_hd_ret, b_hd_atrp = calculate_buy_and_hold_performance(\n",
    "    #         self.df_close, self.features_df, [inputs.benchmark_ticker], safe_buy, safe_end\n",
    "    #     )\n",
    "\n",
    "    #     # --- Step 4: Calculate Metrics (Directly from streams, no linking) ---\n",
    "    #     metrics = {}\n",
    "\n",
    "    #     p_metrics, p_slices = self._calculate_period_metrics(\n",
    "    #         p_full_val, p_full_ret, p_full_atrp, safe_decision,\n",
    "    #         p_hd_val, p_hd_ret, p_hd_atrp, prefix=\"p\"\n",
    "    #     )\n",
    "    #     metrics.update(p_metrics)\n",
    "\n",
    "    #     b_metrics, b_slices = self._calculate_period_metrics(\n",
    "    #         b_full_val, b_full_ret, b_full_atrp, safe_decision,\n",
    "    #         b_hd_val, b_hd_ret, b_hd_atrp, prefix=\"b\"\n",
    "    #     )\n",
    "    #     metrics.update(b_metrics)\n",
    "\n",
    "    #     # --- Step 5: Final Packaging ---\n",
    "    #     # The Plotly chart will show the continuous drifted path (Track A)\n",
    "    #     debug_dict[\"verification\"] = {\"portfolio\": p_slices, \"benchmark\": b_slices}\n",
    "\n",
    "    #     # For the Results Table, we show the re-initialized trade gain\n",
    "    #     results_table[\"Holding Gain\"] = (p_hd_val.iloc[-1] / p_hd_val.iloc[0]) - 1\n",
    "\n",
    "    #     return EngineOutput(\n",
    "    #         portfolio_series=p_full_val,\n",
    "    #         benchmark_series=b_full_val,\n",
    "    #         normalized_plot_data=self._get_normalized_plot_data(tickers_to_trade, safe_start, safe_end),\n",
    "    #         tickers=tickers_to_trade,\n",
    "    #         initial_weights=pd.Series({t: 1/len(tickers_to_trade) for t in tickers_to_trade}),\n",
    "    #         perf_metrics=metrics,\n",
    "    #         results_df=results_table,\n",
    "    #         start_date=safe_start,\n",
    "    #         decision_date=safe_decision,\n",
    "    #         buy_date=safe_buy,\n",
    "    #         holding_end_date=safe_end,\n",
    "    #         error_msg=None,\n",
    "    #         debug_data=debug_dict,\n",
    "    #     )\n",
    "\n",
    "    def run(self, inputs: EngineInput) -> EngineOutput:\n",
    "        dates, error = self._validate_timeline(inputs)\n",
    "        if error:\n",
    "            return self._error_result(error)\n",
    "        (safe_start, safe_decision, safe_buy, safe_end) = dates\n",
    "\n",
    "        tickers_to_trade, results_table, debug_dict, error = self._select_tickers(\n",
    "            inputs, safe_start, safe_decision\n",
    "        )\n",
    "        if error:\n",
    "            return self._error_result(error)\n",
    "\n",
    "        # GENERATE TRACKS\n",
    "        p_f_val, p_f_ret, p_f_atrp = calculate_buy_and_hold_performance(\n",
    "            self.df_close, self.features_df, tickers_to_trade, safe_start, safe_end\n",
    "        )\n",
    "        b_f_val, b_f_ret, b_f_atrp = calculate_buy_and_hold_performance(\n",
    "            self.df_close,\n",
    "            self.features_df,\n",
    "            [inputs.benchmark_ticker],\n",
    "            safe_start,\n",
    "            safe_end,\n",
    "        )\n",
    "\n",
    "        p_h_val, p_h_ret, p_h_atrp = calculate_buy_and_hold_performance(\n",
    "            self.df_close, self.features_df, tickers_to_trade, safe_buy, safe_end\n",
    "        )\n",
    "        b_h_val, b_h_ret, b_h_atrp = calculate_buy_and_hold_performance(\n",
    "            self.df_close,\n",
    "            self.features_df,\n",
    "            [inputs.benchmark_ticker],\n",
    "            safe_buy,\n",
    "            safe_end,\n",
    "        )\n",
    "\n",
    "        # CALCULATE METRICS\n",
    "        p_metrics, p_slices = self._calculate_period_metrics(\n",
    "            p_f_val,\n",
    "            p_f_ret,\n",
    "            p_f_atrp,\n",
    "            safe_decision,\n",
    "            p_h_val,\n",
    "            p_h_ret,\n",
    "            p_h_atrp,\n",
    "            prefix=\"p\",\n",
    "        )\n",
    "        b_metrics, b_slices = self._calculate_period_metrics(\n",
    "            b_f_val,\n",
    "            b_f_ret,\n",
    "            b_f_atrp,\n",
    "            safe_decision,\n",
    "            b_h_val,\n",
    "            b_h_ret,\n",
    "            b_h_atrp,\n",
    "            prefix=\"b\",\n",
    "        )\n",
    "\n",
    "        # CONSOLIDATE DEBUG DATA\n",
    "        debug_dict[\"verification\"] = {\"portfolio\": p_slices, \"benchmark\": b_slices}\n",
    "\n",
    "        # ADD RAW COMPONENT EXPORTS\n",
    "        debug_dict[\"portfolio_raw_components\"] = {\n",
    "            \"prices\": self.df_close[tickers_to_trade].loc[safe_start:safe_end],\n",
    "            \"atrp\": self.features_df.loc[\n",
    "                (tickers_to_trade, slice(safe_start, safe_end)), \"ATRP\"\n",
    "            ].unstack(level=0),\n",
    "        }\n",
    "        debug_dict[\"benchmark_raw_components\"] = {\n",
    "            \"prices\": self.df_close[[inputs.benchmark_ticker]].loc[safe_start:safe_end],\n",
    "            \"atrp\": self.features_df.loc[\n",
    "                ([inputs.benchmark_ticker], slice(safe_start, safe_end)), \"ATRP\"\n",
    "            ].unstack(level=0),\n",
    "        }\n",
    "\n",
    "        # FINAL OUTPUT\n",
    "        results_table[\"Holding Gain\"] = (p_h_val.iloc[-1] / p_h_val.iloc[0]) - 1\n",
    "        return EngineOutput(\n",
    "            portfolio_series=p_f_val,\n",
    "            benchmark_series=b_f_val,\n",
    "            normalized_plot_data=self._get_normalized_plot_data(\n",
    "                tickers_to_trade, safe_start, safe_end\n",
    "            ),\n",
    "            tickers=tickers_to_trade,\n",
    "            initial_weights=pd.Series(\n",
    "                {t: 1 / len(tickers_to_trade) for t in tickers_to_trade}\n",
    "            ),\n",
    "            perf_metrics={**p_metrics, **b_metrics},\n",
    "            results_df=results_table,\n",
    "            start_date=safe_start,\n",
    "            decision_date=safe_decision,\n",
    "            buy_date=safe_buy,\n",
    "            holding_end_date=safe_end,\n",
    "            debug_data=debug_dict,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    # ==============================================================================\n",
    "    # INTERNAL LOGIC MODULES\n",
    "    # ==============================================================================\n",
    "\n",
    "    def _validate_timeline(self, inputs: EngineInput):\n",
    "        cal = self.trading_calendar\n",
    "        last_idx = len(cal) - 1\n",
    "\n",
    "        if len(cal) <= inputs.lookback_period:\n",
    "            return (\n",
    "                None,\n",
    "                f\"‚ùå Dataset too small.\\nNeed > {inputs.lookback_period} days of history.\",\n",
    "            )\n",
    "\n",
    "        # 2. Check \"Past\" Constraints (Lookback)\n",
    "        min_decision_date = cal[inputs.lookback_period]\n",
    "        if inputs.start_date < min_decision_date:\n",
    "            # Added \\n here\n",
    "            return None, (\n",
    "                f\"‚ùå Not enough history for a {inputs.lookback_period}-day lookback.\\n\"\n",
    "                f\"Earliest valid Decision Date: {min_decision_date.date()}\"\n",
    "            )\n",
    "\n",
    "        # 3. Check \"Future\" Constraints (Entry T+1 and Holding Period)\n",
    "        required_future_days = 1 + inputs.holding_period\n",
    "        latest_valid_idx = last_idx - required_future_days\n",
    "\n",
    "        if latest_valid_idx < 0:\n",
    "            return (\n",
    "                None,\n",
    "                f\"‚ùå Holding period too long.\\n{inputs.holding_period} days exceeds available data.\",\n",
    "            )\n",
    "\n",
    "        # If user picked a date beyond the available \"future\" runway\n",
    "        if inputs.start_date > cal[latest_valid_idx]:\n",
    "            latest_date = cal[latest_valid_idx].date()\n",
    "            # Added \\n here and shortened the text slightly to fit better\n",
    "            return None, (\n",
    "                f\"‚ùå Decision Date too late for a {inputs.holding_period}-day hold.\\n\"\n",
    "                f\"Latest valid date: {latest_date}. Please move picker back.\"\n",
    "            )\n",
    "\n",
    "        # 4. Map the safe indices\n",
    "        decision_idx = cal.searchsorted(inputs.start_date)\n",
    "        if decision_idx > latest_valid_idx:\n",
    "            decision_idx = latest_valid_idx\n",
    "\n",
    "        start_idx = decision_idx - inputs.lookback_period\n",
    "        entry_idx = decision_idx + 1\n",
    "        end_idx = entry_idx + inputs.holding_period\n",
    "\n",
    "        return (cal[start_idx], cal[decision_idx], cal[entry_idx], cal[end_idx]), None\n",
    "\n",
    "    def _select_tickers(self, inputs: EngineInput, start_date, decision_date):\n",
    "        debug_dict = {}\n",
    "        if inputs.mode == \"Manual List\":\n",
    "            validation_errors = []\n",
    "            valid_tickers = []\n",
    "            for t in inputs.manual_tickers:\n",
    "                if t not in self.df_close.columns:\n",
    "                    validation_errors.append(f\"‚ùå {t}: Not found.\")\n",
    "                    continue\n",
    "                if pd.isna(self.df_close.at[start_date, t]):\n",
    "                    validation_errors.append(f\"‚ö†Ô∏è {t}: No data on start date.\")\n",
    "                    continue\n",
    "                valid_tickers.append(t)\n",
    "\n",
    "            if validation_errors:\n",
    "                return [], pd.DataFrame(), {}, \"\\n\".join(validation_errors)\n",
    "            if not valid_tickers:\n",
    "                return [], pd.DataFrame(), {}, \"No valid tickers found.\"\n",
    "            return valid_tickers, pd.DataFrame(index=valid_tickers), {}, None\n",
    "\n",
    "        else:  # Ranking\n",
    "            audit_info = {}\n",
    "            eligible_tickers = self._filter_universe(\n",
    "                decision_date, inputs.quality_thresholds, audit_info\n",
    "            )\n",
    "            debug_dict[\"audit_liquidity\"] = audit_info\n",
    "\n",
    "            if not eligible_tickers:\n",
    "                return (\n",
    "                    [],\n",
    "                    pd.DataFrame(),\n",
    "                    debug_dict,\n",
    "                    \"No tickers passed quality filters.\",\n",
    "                )\n",
    "\n",
    "            lookback_close = self.df_close.loc[\n",
    "                start_date:decision_date, eligible_tickers\n",
    "            ]\n",
    "            idx_product = pd.MultiIndex.from_product(\n",
    "                [eligible_tickers, lookback_close.index], names=[\"Ticker\", \"Date\"]\n",
    "            )\n",
    "\n",
    "            feat_slice_current = self.features_df.xs(\n",
    "                decision_date, level=\"Date\"\n",
    "            ).reindex(eligible_tickers)\n",
    "            feat_slice_period = self.features_df.loc[\n",
    "                (slice(None), lookback_close.index), :\n",
    "            ].reindex(idx_product)\n",
    "            atrp_mean = feat_slice_period[\"ATRP\"].groupby(level=\"Ticker\").mean()\n",
    "\n",
    "            # 1. Package the Observation (The 'State')\n",
    "            observation: MarketObservation = {\n",
    "                \"lookback_close\": lookback_close,\n",
    "                \"lookback_returns\": lookback_close.ffill().pct_change(),\n",
    "                \"atrp\": atrp_mean,\n",
    "                \"roc_1\": feat_slice_current[\"ROC_1\"],\n",
    "                \"roc_3\": feat_slice_current[\"ROC_3\"],\n",
    "                \"roc_5\": feat_slice_current[\"ROC_5\"],\n",
    "                \"roc_10\": feat_slice_current[\"ROC_10\"],\n",
    "                \"roc_21\": feat_slice_current[\"ROC_21\"],\n",
    "            }\n",
    "\n",
    "            # 2. Run the Strategy (The 'Agent')\n",
    "            if inputs.metric not in METRIC_REGISTRY:\n",
    "                return [], pd.DataFrame(), {}, f\"Strategy '{inputs.metric}' not found.\"\n",
    "\n",
    "            metric_vals = METRIC_REGISTRY[inputs.metric](observation)\n",
    "            sorted_tickers = metric_vals.sort_values(ascending=False)\n",
    "            start_r = max(0, inputs.rank_start - 1)\n",
    "            end_r = inputs.rank_end\n",
    "            selected_tickers = sorted_tickers.iloc[start_r:end_r].index.tolist()\n",
    "\n",
    "            # --- VERIFICATION ADDITION: Ranking Audit (Bot Version) ---\n",
    "            debug_dict[\"full_universe_ranking\"] = pd.DataFrame(\n",
    "                {\n",
    "                    \"Strategy_Score\": metric_vals,\n",
    "                    \"Lookback_Return_Ann\": observation[\"lookback_returns\"].mean() * 252,\n",
    "                    \"Lookback_ATRP\": observation[\"atrp\"],\n",
    "                }\n",
    "            )\n",
    "\n",
    "            if not selected_tickers:\n",
    "                return (\n",
    "                    [],\n",
    "                    pd.DataFrame(),\n",
    "                    debug_dict,\n",
    "                    \"No tickers generated from ranking.\",\n",
    "                )\n",
    "\n",
    "            results_table = pd.DataFrame(\n",
    "                {\n",
    "                    \"Rank\": range(\n",
    "                        inputs.rank_start, inputs.rank_start + len(selected_tickers)\n",
    "                    ),\n",
    "                    \"Ticker\": selected_tickers,\n",
    "                    \"Strategy Value\": sorted_tickers.loc[selected_tickers].values,\n",
    "                }\n",
    "            ).set_index(\"Ticker\")\n",
    "\n",
    "            return selected_tickers, results_table, debug_dict, None\n",
    "\n",
    "    def _filter_universe(self, date_ts, thresholds, audit_container=None):\n",
    "        avail_dates = (\n",
    "            self.features_df.index.get_level_values(\"Date\").unique().sort_values()\n",
    "        )\n",
    "        valid_dates = avail_dates[avail_dates <= date_ts]\n",
    "        if valid_dates.empty:\n",
    "            return []\n",
    "        target_date = valid_dates[-1]\n",
    "        day_features = self.features_df.xs(target_date, level=\"Date\")\n",
    "\n",
    "        vol_cutoff = thresholds.get(\"min_median_dollar_volume\", 0)\n",
    "        percentile_used = \"N/A\"\n",
    "        if \"min_liquidity_percentile\" in thresholds:\n",
    "            percentile_used = thresholds[\"min_liquidity_percentile\"]\n",
    "            dynamic_val = day_features[\"RollMedDollarVol\"].quantile(percentile_used)\n",
    "            vol_cutoff = max(vol_cutoff, dynamic_val)\n",
    "\n",
    "        mask = (\n",
    "            (day_features[\"RollMedDollarVol\"] >= vol_cutoff)\n",
    "            & (day_features[\"RollingStalePct\"] <= thresholds[\"max_stale_pct\"])\n",
    "            & (day_features[\"RollingSameVolCount\"] <= thresholds[\"max_same_vol_count\"])\n",
    "        )\n",
    "\n",
    "        if audit_container is not None:\n",
    "            audit_container[\"date\"] = target_date\n",
    "            audit_container[\"total_tickers_available\"] = len(day_features)\n",
    "            audit_container[\"percentile_setting\"] = percentile_used\n",
    "            audit_container[\"final_cutoff_usd\"] = vol_cutoff\n",
    "            audit_container[\"tickers_passed\"] = mask.sum()\n",
    "            snapshot = day_features.copy()\n",
    "            snapshot[\"Calculated_Cutoff\"] = vol_cutoff\n",
    "            snapshot[\"Passed_Vol_Check\"] = snapshot[\"RollMedDollarVol\"] >= vol_cutoff\n",
    "            snapshot[\"Passed_Final\"] = mask\n",
    "            snapshot = snapshot.sort_values(\"RollMedDollarVol\", ascending=False)\n",
    "            audit_container[\"universe_snapshot\"] = snapshot\n",
    "\n",
    "        return day_features[mask].index.tolist()\n",
    "\n",
    "\n",
    "\n",
    "    # def _calculate_period_metrics(\n",
    "    #     self, f_val, f_ret, f_atrp, decision_date, h_val, h_ret, h_atrp, prefix\n",
    "    # ):\n",
    "    #     metrics = {}\n",
    "    #     slices = {}\n",
    "\n",
    "    #     # 1. Slice 'Full' stream to get the Lookback period\n",
    "    #     lb_val = f_val.loc[:decision_date]\n",
    "    #     lb_ret = f_ret.loc[:decision_date]\n",
    "    #     lb_atrp = f_atrp.loc[:decision_date]\n",
    "\n",
    "    #     # 2. FULL (Drifted Path)\n",
    "    #     metrics[f\"full_{prefix}_gain\"] = calculate_summary_gain(f_val)\n",
    "    #     metrics[f\"full_{prefix}_sharpe\"] = calculate_summary_sharpe(f_ret)\n",
    "    #     metrics[f\"full_{prefix}_sharpe_atr\"] = calculate_summary_sharpe_atr(f_ret, f_atrp)\n",
    "\n",
    "    #     # 3. LOOKBACK (Drifted Path)\n",
    "    #     metrics[f\"lookback_{prefix}_gain\"] = calculate_summary_gain(lb_val)\n",
    "    #     metrics[f\"lookback_{prefix}_sharpe\"] = calculate_summary_sharpe(lb_ret)\n",
    "    #     metrics[f\"lookback_{prefix}_sharpe_atr\"] = calculate_summary_sharpe_atr(lb_ret, lb_atrp)\n",
    "\n",
    "    #     # 4. HOLDING (Fresh Re-Initialized Path)\n",
    "    #     metrics[f\"holding_{prefix}_gain\"] = calculate_summary_gain(h_val)\n",
    "    #     metrics[f\"holding_{prefix}_sharpe\"] = calculate_summary_sharpe(h_ret)\n",
    "    #     metrics[f\"holding_{prefix}_sharpe_atr\"] = calculate_summary_sharpe_atr(h_ret, h_atrp)\n",
    "\n",
    "    #     # Store for audit\n",
    "    #     slices[\"lookback_val\"], slices[\"lookback_ret\"] = lb_val, lb_ret\n",
    "    #     slices[\"holding_val\"], slices[\"holding_ret\"], slices[\"holding_atrp\"] = h_val, h_ret, h_atrp\n",
    "\n",
    "    #     return metrics, slices\n",
    "\n",
    "\n",
    "    def _calculate_period_metrics(\n",
    "        self, f_val, f_ret, f_atrp, decision_date, h_val, h_ret, h_atrp, prefix\n",
    "    ):\n",
    "        metrics = {}\n",
    "        slices = {}\n",
    "\n",
    "        # Slices for Lookback (Derived from 'Full' track)\n",
    "        lb_val = f_val.loc[:decision_date]\n",
    "        lb_ret = f_ret.loc[:decision_date]\n",
    "        lb_atrp = f_atrp.loc[:decision_date]\n",
    "\n",
    "        # 1. GAIN\n",
    "        metrics[f\"full_{prefix}_gain\"] = calculate_summary_gain(f_val)\n",
    "        metrics[f\"lookback_{prefix}_gain\"] = calculate_summary_gain(lb_val)\n",
    "        metrics[f\"holding_{prefix}_gain\"] = calculate_summary_gain(h_val)\n",
    "\n",
    "        # 2. SHARPE\n",
    "        metrics[f\"full_{prefix}_sharpe\"] = calculate_summary_sharpe(f_ret)\n",
    "        metrics[f\"lookback_{prefix}_sharpe\"] = calculate_summary_sharpe(lb_ret)\n",
    "        metrics[f\"holding_{prefix}_sharpe\"] = calculate_summary_sharpe(h_ret)\n",
    "\n",
    "        # 3. SHARPE (ATR)\n",
    "        metrics[f\"full_{prefix}_sharpe_atr\"] = calculate_summary_sharpe_atr(f_ret, f_atrp)\n",
    "        metrics[f\"lookback_{prefix}_sharpe_atr\"] = calculate_summary_sharpe_atr(lb_ret, lb_atrp)\n",
    "        metrics[f\"holding_{prefix}_sharpe_atr\"] = calculate_summary_sharpe_atr(h_ret, h_atrp)\n",
    "\n",
    "        # 4. CAPTURE ALL SLICES FOR EXPORT (This was what was missing)\n",
    "        slices[f\"full_val\"] = f_val\n",
    "        slices[f\"full_ret\"] = f_ret\n",
    "        slices[f\"full_atrp\"] = f_atrp\n",
    "        \n",
    "        slices[f\"lookback_val\"] = lb_val\n",
    "        slices[f\"lookback_ret\"] = lb_ret\n",
    "        slices[f\"lookback_atrp\"] = lb_atrp\n",
    "        \n",
    "        slices[f\"holding_val\"] = h_val\n",
    "        slices[f\"holding_ret\"] = h_ret\n",
    "        slices[f\"holding_atrp\"] = h_atrp\n",
    "\n",
    "        return metrics, slices\n",
    "\n",
    "\n",
    "\n",
    "    def _get_normalized_plot_data(self, tickers, start_date, end_date):\n",
    "        if not tickers:\n",
    "            return pd.DataFrame()\n",
    "        data = self.df_close[list(set(tickers))].loc[start_date:end_date]\n",
    "        if data.empty:\n",
    "            return pd.DataFrame()\n",
    "        return data / data.bfill().iloc[0]\n",
    "\n",
    "    def _error_result(self, msg):\n",
    "        return EngineOutput(\n",
    "            portfolio_series=pd.Series(dtype=float),\n",
    "            benchmark_series=pd.Series(dtype=float),\n",
    "            normalized_plot_data=pd.DataFrame(),\n",
    "            tickers=[],\n",
    "            initial_weights=pd.Series(dtype=float),\n",
    "            perf_metrics={},\n",
    "            results_df=pd.DataFrame(),\n",
    "            start_date=pd.Timestamp.min,\n",
    "            decision_date=pd.Timestamp.min,\n",
    "            buy_date=pd.Timestamp.min,\n",
    "            holding_end_date=pd.Timestamp.min,\n",
    "            error_msg=msg,\n",
    "        )\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION E: THE UI (Visualization) - UPDATED v2.4 (Complete Timeline)\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "def plot_walk_forward_analyzer(\n",
    "    df_ohlcv,\n",
    "    precomputed_features=None,\n",
    "    precomputed_close=None,\n",
    "    default_start_date=\"2025-01-17\",\n",
    "    default_lookback=10,\n",
    "    default_holding=5,\n",
    "    default_strategy=\"Sharpe (ATR)\",\n",
    "    default_rank_start=1,\n",
    "    default_rank_end=10,\n",
    "    default_benchmark_ticker=GLOBAL_SETTINGS[\"benchmark_ticker\"],\n",
    "    master_calendar_ticker=GLOBAL_SETTINGS[\"calendar_ticker\"],\n",
    "    quality_thresholds=GLOBAL_SETTINGS[\"thresholds\"],\n",
    "    debug=False,\n",
    "):\n",
    "\n",
    "    engine = AlphaEngine(\n",
    "        df_ohlcv,\n",
    "        features_df=precomputed_features,\n",
    "        df_close_wide=precomputed_close,\n",
    "        master_ticker=master_calendar_ticker,\n",
    "    )\n",
    "\n",
    "    # Initialize containers\n",
    "    results_container = [None]\n",
    "    debug_container = [{}]\n",
    "\n",
    "    # If no thresholds passed, use the global Source of Truth\n",
    "    if quality_thresholds is None:\n",
    "        quality_thresholds = GLOBAL_SETTINGS[\"thresholds\"]\n",
    "\n",
    "    # --- Widgets ---\n",
    "    mode_selector = widgets.RadioButtons(\n",
    "        options=[\"Ranking\", \"Manual List\"],\n",
    "        value=\"Ranking\",\n",
    "        description=\"Mode:\",\n",
    "        layout={\"width\": \"max-content\"},\n",
    "        style={\"description_width\": \"initial\"},\n",
    "    )\n",
    "    lookback_input = widgets.IntText(\n",
    "        value=default_lookback,\n",
    "        description=\"Lookback (Days):\",\n",
    "        layout={\"width\": \"200px\"},\n",
    "        style={\"description_width\": \"initial\"},\n",
    "    )\n",
    "    decision_date_picker = widgets.DatePicker(\n",
    "        description=\"Decision Date:\",\n",
    "        value=pd.to_datetime(default_start_date),\n",
    "        layout={\"width\": \"auto\"},\n",
    "        style={\"description_width\": \"initial\"},\n",
    "    )\n",
    "    holding_input = widgets.IntText(\n",
    "        value=default_holding,\n",
    "        description=\"Holding (Days):\",\n",
    "        layout={\"width\": \"200px\"},\n",
    "        style={\"description_width\": \"initial\"},\n",
    "    )\n",
    "    strategy_dropdown = widgets.Dropdown(\n",
    "        options=list(METRIC_REGISTRY.keys()),\n",
    "        value=default_strategy,\n",
    "        description=\"Strategy:\",\n",
    "        layout={\"width\": \"220px\"},\n",
    "        style={\"description_width\": \"initial\"},\n",
    "    )\n",
    "    benchmark_input = widgets.Text(\n",
    "        value=default_benchmark_ticker,\n",
    "        description=\"Benchmark:\",\n",
    "        placeholder=\"Enter Ticker\",\n",
    "        layout={\"width\": \"180px\"},\n",
    "        style={\"description_width\": \"initial\"},\n",
    "    )\n",
    "    rank_start_input = widgets.IntText(\n",
    "        value=default_rank_start,\n",
    "        description=\"Rank Start:\",\n",
    "        layout={\"width\": \"150px\"},\n",
    "        style={\"description_width\": \"initial\"},\n",
    "    )\n",
    "    rank_end_input = widgets.IntText(\n",
    "        value=default_rank_end,\n",
    "        description=\"Rank End:\",\n",
    "        layout={\"width\": \"150px\"},\n",
    "        style={\"description_width\": \"initial\"},\n",
    "    )\n",
    "    manual_tickers_input = widgets.Textarea(\n",
    "        value=\"\",\n",
    "        placeholder=\"Enter tickers...\",\n",
    "        description=\"Manual Tickers:\",\n",
    "        layout={\"width\": \"400px\", \"height\": \"80px\"},\n",
    "        style={\"description_width\": \"initial\"},\n",
    "    )\n",
    "    update_button = widgets.Button(description=\"Run Simulation\", button_style=\"primary\")\n",
    "    ticker_list_output = widgets.Output()\n",
    "\n",
    "    # --- Layouts ---\n",
    "    timeline_box = widgets.HBox(\n",
    "        [lookback_input, decision_date_picker, holding_input],\n",
    "        layout=widgets.Layout(\n",
    "            justify_content=\"space-between\",\n",
    "            border=\"1px solid #ddd\",\n",
    "            padding=\"10px\",\n",
    "            margin=\"5px\",\n",
    "        ),\n",
    "    )\n",
    "    strategy_box = widgets.HBox([strategy_dropdown, benchmark_input])\n",
    "    ranking_box = widgets.HBox([rank_start_input, rank_end_input])\n",
    "\n",
    "    def on_mode_change(c):\n",
    "        ranking_box.layout.display = \"flex\" if c[\"new\"] == \"Ranking\" else \"none\"\n",
    "        manual_tickers_input.layout.display = (\n",
    "            \"none\" if c[\"new\"] == \"Ranking\" else \"flex\"\n",
    "        )\n",
    "        strategy_dropdown.disabled = c[\"new\"] == \"Manual List\"\n",
    "\n",
    "    mode_selector.observe(on_mode_change, names=\"value\")\n",
    "    on_mode_change({\"new\": mode_selector.value})\n",
    "\n",
    "    ui = widgets.VBox(\n",
    "        [\n",
    "            widgets.HTML(\n",
    "                \"<b>1. Timeline Configuration:</b> (Past <--- Decision ---> Future)\"\n",
    "            ),\n",
    "            timeline_box,\n",
    "            widgets.HTML(\"<b>2. Strategy Settings:</b>\"),\n",
    "            widgets.HBox([mode_selector, strategy_box]),\n",
    "            ranking_box,\n",
    "            manual_tickers_input,\n",
    "            widgets.HTML(\"<hr>\"),\n",
    "            update_button,\n",
    "            ticker_list_output,\n",
    "        ],\n",
    "        layout=widgets.Layout(margin=\"10px 0 20px 0\"),\n",
    "    )\n",
    "\n",
    "    fig = go.FigureWidget()\n",
    "    fig.update_layout(\n",
    "        title=\"Event-Driven Walk-Forward Analysis\",\n",
    "        height=600,\n",
    "        template=\"plotly_white\",\n",
    "        hovermode=\"x unified\",\n",
    "    )\n",
    "    for i in range(50):\n",
    "        fig.add_trace(go.Scatter(visible=False, line=dict(width=2)))\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            name=\"Benchmark\",\n",
    "            visible=True,\n",
    "            line=dict(color=\"black\", width=3, dash=\"dash\"),\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            name=\"Group Portfolio\", visible=True, line=dict(color=\"green\", width=3)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # --- Update Logic ---\n",
    "    def update_plot(b):\n",
    "        ticker_list_output.clear_output()\n",
    "        manual_list = [\n",
    "            t.strip().upper()\n",
    "            for t in manual_tickers_input.value.split(\",\")\n",
    "            if t.strip()\n",
    "        ]\n",
    "        decision_date_raw = pd.to_datetime(decision_date_picker.value)\n",
    "\n",
    "        inputs = EngineInput(\n",
    "            mode=mode_selector.value,\n",
    "            start_date=decision_date_raw,\n",
    "            lookback_period=lookback_input.value,\n",
    "            holding_period=holding_input.value,\n",
    "            metric=strategy_dropdown.value,\n",
    "            benchmark_ticker=benchmark_input.value.strip().upper(),\n",
    "            rank_start=rank_start_input.value,\n",
    "            rank_end=rank_end_input.value,\n",
    "            quality_thresholds=quality_thresholds,\n",
    "            manual_tickers=manual_list,\n",
    "            debug=debug,\n",
    "        )\n",
    "\n",
    "        # --- CAPTURE INPUTS FOR AUDIT ---\n",
    "        debug_container[0][\"inputs\"] = inputs\n",
    "\n",
    "        with ticker_list_output:\n",
    "            res = engine.run(inputs)\n",
    "            results_container[0] = res\n",
    "\n",
    "            # --- MERGE ENGINE DEBUG DATA ---\n",
    "            if res.debug_data:\n",
    "                debug_container[0].update(res.debug_data)\n",
    "\n",
    "            if res.error_msg:\n",
    "                print(f\"‚ö†Ô∏è Simulation Stopped: {res.error_msg}\")\n",
    "                return\n",
    "\n",
    "            # Plotting\n",
    "            with fig.batch_update():\n",
    "                cols = res.normalized_plot_data.columns.tolist()\n",
    "                for i in range(50):\n",
    "                    if i < len(cols):\n",
    "                        fig.data[i].update(\n",
    "                            x=res.normalized_plot_data.index,\n",
    "                            y=res.normalized_plot_data[cols[i]],\n",
    "                            name=cols[i],\n",
    "                            visible=True,\n",
    "                        )\n",
    "                    else:\n",
    "                        fig.data[i].visible = False\n",
    "\n",
    "                fig.data[50].update(\n",
    "                    x=res.benchmark_series.index,\n",
    "                    y=res.benchmark_series.values,\n",
    "                    name=f\"Benchmark ({inputs.benchmark_ticker})\",\n",
    "                    visible=not res.benchmark_series.empty,\n",
    "                )\n",
    "                fig.data[51].update(\n",
    "                    x=res.portfolio_series.index,\n",
    "                    y=res.portfolio_series.values,\n",
    "                    visible=True,\n",
    "                )\n",
    "\n",
    "                # Visual Lines\n",
    "                fig.layout.shapes = [\n",
    "                    dict(\n",
    "                        type=\"line\",\n",
    "                        x0=res.decision_date,\n",
    "                        y0=0,\n",
    "                        x1=res.decision_date,\n",
    "                        y1=1,\n",
    "                        xref=\"x\",\n",
    "                        yref=\"paper\",\n",
    "                        line=dict(color=\"red\", width=2, dash=\"dash\"),\n",
    "                    ),\n",
    "                    dict(\n",
    "                        type=\"line\",\n",
    "                        x0=res.buy_date,\n",
    "                        y0=0,\n",
    "                        x1=res.buy_date,\n",
    "                        y1=1,\n",
    "                        xref=\"x\",\n",
    "                        yref=\"paper\",\n",
    "                        line=dict(color=\"blue\", width=2, dash=\"dot\"),\n",
    "                    ),\n",
    "                ]\n",
    "\n",
    "                fig.layout.annotations = [\n",
    "                    dict(\n",
    "                        x=res.decision_date,\n",
    "                        y=0.05,\n",
    "                        xref=\"x\",\n",
    "                        yref=\"paper\",\n",
    "                        text=\"DECISION\",\n",
    "                        showarrow=False,\n",
    "                        bgcolor=\"red\",\n",
    "                        font=dict(color=\"white\"),\n",
    "                    ),\n",
    "                    dict(\n",
    "                        x=res.buy_date,\n",
    "                        y=1.0,\n",
    "                        xref=\"x\",\n",
    "                        yref=\"paper\",\n",
    "                        text=\"ENTRY (T+1)\",\n",
    "                        showarrow=False,\n",
    "                        bgcolor=\"blue\",\n",
    "                        font=dict(color=\"white\"),\n",
    "                    ),\n",
    "                ]\n",
    "\n",
    "            start_date = res.start_date.date()\n",
    "            act_date = res.decision_date.date()\n",
    "            entry_date = res.buy_date.date()\n",
    "\n",
    "            # Liquidity Audit Print\n",
    "            if (\n",
    "                inputs.mode == \"Ranking\"\n",
    "                and res.debug_data\n",
    "                and \"audit_liquidity\" in res.debug_data\n",
    "            ):\n",
    "                audit = res.debug_data[\"audit_liquidity\"]\n",
    "                if audit:\n",
    "                    raw_percentile = audit.get(\"percentile_setting\", 0)\n",
    "                    keep_pct = (\n",
    "                        1 - raw_percentile\n",
    "                    ) * 100  # Calculates the actual portion kept\n",
    "                    cut_val = audit.get(\"final_cutoff_usd\", 0)\n",
    "\n",
    "                    print(\"-\" * 60)\n",
    "                    print(f\"üîç LIQUIDITY CHECK (On Decision Date: {act_date})\")\n",
    "                    print(\n",
    "                        f\"   Universe Size: {audit.get('total_tickers_available')} tickers\"\n",
    "                    )\n",
    "                    print(\n",
    "                        f\"   Liquidity Threshold: {raw_percentile*100:.0f}th Percentile\"\n",
    "                    )\n",
    "                    print(f\"   Action: Keeping the Top {keep_pct:.0f}% of Market\")\n",
    "                    print(f\"   Calculated Cutoff: ${cut_val:,.0f} / day\")\n",
    "                    print(f\"   Tickers Remaining: {audit.get('tickers_passed')}\")\n",
    "                    print(\"-\" * 60)\n",
    "\n",
    "            # --- UPDATED TIMELINE PRINT ---\n",
    "            print(\n",
    "                f\"Timeline: Start [ {start_date} ] --> Decision [ {act_date} ] --> Cash (1d) --> Entry [ {entry_date} ] --> End [ {res.holding_end_date.date()} ]\"\n",
    "            )\n",
    "\n",
    "            if inputs.mode == \"Ranking\":\n",
    "                print(f\"Ranked Tickers ({len(res.tickers)}):\")\n",
    "                for i in range(0, len(res.tickers), 10):\n",
    "                    print(\", \".join(res.tickers[i : i + 10]))\n",
    "            else:\n",
    "                print(\"Manual Portfolio Tickers:\")\n",
    "                for i in range(0, len(res.tickers), 10):\n",
    "                    print(\", \".join(res.tickers[i : i + 10]))\n",
    "\n",
    "            m = res.perf_metrics\n",
    "\n",
    "            # --- DRY UI GENERATION ---\n",
    "            # 1. Define the metrics we want to display\n",
    "            metrics_to_show = [\n",
    "                (\"Gain\", \"gain\"),\n",
    "                (\"Sharpe\", \"sharpe\"),\n",
    "                (\"Sharpe (ATR)\", \"sharpe_atr\"),\n",
    "            ]\n",
    "\n",
    "            rows = []\n",
    "            for label, key in metrics_to_show:\n",
    "                p_row = {\n",
    "                    \"Metric\": f\"Group {label}\",\n",
    "                    \"Full\": m.get(f\"full_p_{key}\"),\n",
    "                    \"Lookback\": m.get(f\"lookback_p_{key}\"),\n",
    "                    \"Holding\": m.get(f\"holding_p_{key}\"),\n",
    "                }\n",
    "                b_row = {\n",
    "                    \"Metric\": f\"Benchmark {label}\",\n",
    "                    \"Full\": m.get(f\"full_b_{key}\"),\n",
    "                    \"Lookback\": m.get(f\"lookback_b_{key}\"),\n",
    "                    \"Holding\": m.get(f\"holding_b_{key}\"),\n",
    "                }\n",
    "\n",
    "                # Delta calculation\n",
    "                d_row = {\"Metric\": f\"== {label} Delta\"}\n",
    "                for col in [\"Full\", \"Lookback\", \"Holding\"]:\n",
    "                    d_row[col] = (p_row[col] or 0) - (b_row[col] or 0)\n",
    "\n",
    "                rows.extend([p_row, b_row, d_row])\n",
    "\n",
    "            df_report = pd.DataFrame(rows).set_index(\"Metric\")\n",
    "\n",
    "            # --- 2. STYLING (The \"Senior\" Design) ---\n",
    "            # --- 1. PREP DATA (Flattening the Index) ---\n",
    "            # We convert the index to a column so \"Metric\" sits on the same row as other headers\n",
    "            df_report = pd.DataFrame(rows)\n",
    "            df_report = df_report.set_index(\"Metric\")\n",
    "\n",
    "            # --- 2. THE STYLING (Sleek & Proportional) ---\n",
    "            def apply_sleek_style(styler):\n",
    "                # Match notebook font size (usually 13px)\n",
    "                styler.format(\"{:+.4f}\", na_rep=\"N/A\")\n",
    "\n",
    "                # Dynamic Row Highlighting\n",
    "                def row_logic(row):\n",
    "                    if \"Delta\" in row.name:\n",
    "                        return [\n",
    "                            \"background-color: #f9f9f9; font-weight: 600; border-top: 1px solid #ddd\"\n",
    "                        ] * len(row)\n",
    "                    if \"Group\" in row.name:\n",
    "                        return [\"color: #2c5e8f; background-color: #fcfdfe\"] * len(row)\n",
    "                    return [\"color: #555\"] * len(\n",
    "                        row\n",
    "                    )  # Benchmark rows are slightly muted\n",
    "\n",
    "                styler.apply(row_logic, axis=1)\n",
    "\n",
    "                styler.set_table_styles(\n",
    "                    [\n",
    "                        # Base Table Font - Scaling down to match standard text\n",
    "                        {\n",
    "                            \"selector\": \"\",\n",
    "                            \"props\": [\n",
    "                                (\"font-family\", \"inherit\"),\n",
    "                                (\"font-size\", \"12px\"),\n",
    "                                (\"border-collapse\", \"collapse\"),\n",
    "                                (\"width\", \"auto\"),\n",
    "                                (\"margin-left\", \"0\"),\n",
    "                            ],\n",
    "                        },\n",
    "                        # Header Row - Flattened and Muted\n",
    "                        {\n",
    "                            \"selector\": \"th\",\n",
    "                            \"props\": [\n",
    "                                (\"background-color\", \"white\"),\n",
    "                                (\"color\", \"#222\"),\n",
    "                                (\"font-weight\", \"600\"),\n",
    "                                (\"padding\", \"6px 12px\"),\n",
    "                                (\"border-bottom\", \"2px solid #444\"),\n",
    "                                (\"text-align\", \"center\"),\n",
    "                                (\n",
    "                                    \"vertical-align\",\n",
    "                                    \"bottom\",\n",
    "                                ),  # Aligns 'Metric' with others\n",
    "                            ],\n",
    "                        },\n",
    "                        # Index Column (The \"Metric\" labels)\n",
    "                        {\n",
    "                            \"selector\": \"th.row_heading\",\n",
    "                            \"props\": [\n",
    "                                (\"text-align\", \"left\"),\n",
    "                                (\"padding-right\", \"30px\"),\n",
    "                                (\"border-bottom\", \"1px solid #eee\"),\n",
    "                            ],\n",
    "                        },\n",
    "                        # Cell Data - Tighter padding\n",
    "                        {\n",
    "                            \"selector\": \"td\",\n",
    "                            \"props\": [\n",
    "                                (\"padding\", \"4px 12px\"),\n",
    "                                (\"border-bottom\", \"1px solid #eee\"),\n",
    "                            ],\n",
    "                        },\n",
    "                        # Remove the extra \"Index Name\" row completely\n",
    "                        {\n",
    "                            \"selector\": \"thead tr:nth-child(1) th\",\n",
    "                            \"props\": [(\"display\", \"table-cell\")],\n",
    "                        },\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                # Hack to fix the 'Metric' alignment:\n",
    "                # We remove the index name and set it as the horizontal label for the index\n",
    "                styler.index.name = None\n",
    "\n",
    "                return styler\n",
    "\n",
    "            display(apply_sleek_style(df_report.style))\n",
    "\n",
    "    update_button.on_click(update_plot)\n",
    "    update_plot(None)\n",
    "    display(ui, fig)\n",
    "    return results_container, debug_container\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48017a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SECTION F: UTILITIES\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "def export_debug_to_csv(container, source_label=\"Simulation\"):\n",
    "    \"\"\"\n",
    "    Flattens the debug_container and saves all components to high-precision CSVs.\n",
    "    \"\"\"\n",
    "    if not container or not container[0]:\n",
    "        print(\"‚ùå Error: Debug container is empty.\")\n",
    "        return\n",
    "\n",
    "    data = container[0]\n",
    "    inputs = data.get(\"inputs\")\n",
    "\n",
    "    # 1. Create a clean folder name\n",
    "    # e.g., Audit_Golden_20251211_SharpeATR\n",
    "    date_str = inputs.start_date.strftime(\"%Y-%m-%d\")\n",
    "    strategy_str = inputs.metric.replace(\" \", \"\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "    folder_name = f\"Audit_{source_label}_{date_str}_{strategy_str}\"\n",
    "\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    print(f\"üìÇ Exporting audit data to: ./{folder_name}/\")\n",
    "\n",
    "    # 2. Recursive function to traverse the dictionary and save files\n",
    "    def process_item(item, path_prefix=\"\"):\n",
    "        # Handle Nested Dictionaries (like 'verification' or 'raw_components')\n",
    "        if isinstance(item, dict):\n",
    "            for key, value in item.items():\n",
    "                new_prefix = f\"{path_prefix}{key}_\" if path_prefix else f\"{key}_\"\n",
    "                process_item(value, new_prefix)\n",
    "\n",
    "        # Handle DataFrames\n",
    "        elif isinstance(item, pd.DataFrame):\n",
    "            filename = f\"{path_prefix.strip('_')}.csv\"\n",
    "            item.to_csv(os.path.join(folder_name, filename), float_format=\"%.8f\")\n",
    "            print(f\"   ‚úÖ Saved DataFrame: {filename}\")\n",
    "\n",
    "        # Handle Series (Convert to DataFrame for CSV preservation of Index)\n",
    "        elif isinstance(item, pd.Series):\n",
    "            filename = f\"{path_prefix.strip('_')}.csv\"\n",
    "            item.to_frame().to_csv(\n",
    "                os.path.join(folder_name, filename), float_format=\"%.8f\"\n",
    "            )\n",
    "            print(f\"   ‚úÖ Saved Series:    {filename}\")\n",
    "\n",
    "        # Handle Dataclasses (like 'inputs')\n",
    "        elif is_dataclass(item):\n",
    "            filename = f\"{path_prefix}Metadata.csv\"\n",
    "            # Convert to a vertical 2-column table for easy Excel reading\n",
    "            meta_df = pd.DataFrame.from_dict(\n",
    "                asdict(item), orient=\"index\", columns=[\"Value\"]\n",
    "            )\n",
    "            meta_df.to_csv(os.path.join(folder_name, filename))\n",
    "            print(f\"   ‚úÖ Saved Metadata:  {filename}\")\n",
    "\n",
    "    # 3. Start the extraction\n",
    "    process_item(data)\n",
    "    print(f\"\\n‚ú® Export Complete. All numbers saved with 8 decimal places.\")\n",
    "\n",
    "\n",
    "def print_nested(d, indent=0, width=4):\n",
    "    \"\"\"Pretty-print nested containers.\n",
    "    Leaves are rendered as two lines:  key\\\\nvalue .\"\"\"\n",
    "    spacing = \" \" * indent\n",
    "\n",
    "    def _kind(node):\n",
    "        if not isinstance(node, dict):\n",
    "            return None\n",
    "        return \"sep\" if all(isinstance(v, dict) for v in node.values()) else \"nest\"\n",
    "\n",
    "    if isinstance(d, dict):\n",
    "        for k, v in d.items():\n",
    "            kind = _kind(v)\n",
    "            tag = \"\" if kind is None else f\"  [{'SEP' if kind == 'sep' else 'NEST'}]\"\n",
    "            print(f\"{spacing}{k}{tag}\")\n",
    "            print_nested(v, indent + width, width)\n",
    "\n",
    "    elif isinstance(d, (list, tuple)):\n",
    "        for idx, item in enumerate(d):\n",
    "            print(f\"{spacing}[{idx}]\")\n",
    "            print_nested(item, indent + width, width)\n",
    "\n",
    "    else:  # leaf ‚Äì primitive value\n",
    "        print(f\"{spacing}{d}\")\n",
    "\n",
    "\n",
    "def get_ticker_OHLCV(\n",
    "    df_ohlcv: pd.DataFrame,\n",
    "    tickers: Union[str, List[str]],\n",
    "    date_start: str,\n",
    "    date_end: str,\n",
    "    return_format: str = \"dataframe\",\n",
    "    verbose: bool = True,\n",
    ") -> Union[pd.DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    Get OHLCV data for specified tickers within a date range.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_ohlcv : pd.DataFrame\n",
    "        DataFrame with MultiIndex of (ticker, date) and OHLCV columns\n",
    "    tickers : str or list of str\n",
    "        Ticker symbol(s) to retrieve\n",
    "    date_start : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    date_end : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    return_format : str, optional\n",
    "        Format to return data in. Options:\n",
    "        - 'dataframe': Single DataFrame with MultiIndex (default)\n",
    "        - 'dict': Dictionary with tickers as keys and DataFrames as values\n",
    "        - 'separate': List of separate DataFrames for each ticker\n",
    "    verbose : bool, optional\n",
    "        Whether to print summary information (default: True)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Union[pd.DataFrame, dict, list]\n",
    "        Filtered OHLCV data in specified format\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If input parameters are invalid\n",
    "    KeyError\n",
    "        If tickers not found in DataFrame\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> # Get data for single ticker\n",
    "    >>> vlo_data = get_ticker_OHLCV(df_ohlcv, 'VLO', '2025-08-13', '2025-09-04')\n",
    "\n",
    "    >>> # Get data for multiple tickers\n",
    "    >>> multi_data = get_ticker_OHLCV(df_ohlcv, ['VLO', 'JPST'], '2025-08-13', '2025-09-04')\n",
    "\n",
    "    >>> # Get data as dictionary\n",
    "    >>> data_dict = get_ticker_OHLCV(df_ohlcv, ['VLO', 'JPST'], '2025-08-13',\n",
    "    ...                              '2025-09-04', return_format='dict')\n",
    "    \"\"\"\n",
    "\n",
    "    # Input validation\n",
    "    if not isinstance(df_ohlcv, pd.DataFrame):\n",
    "        raise TypeError(\"df_ohlcv must be a pandas DataFrame\")\n",
    "\n",
    "    if not isinstance(df_ohlcv.index, pd.MultiIndex):\n",
    "        raise ValueError(\"DataFrame must have MultiIndex of (ticker, date)\")\n",
    "\n",
    "    if len(df_ohlcv.index.levels) != 2:\n",
    "        raise ValueError(\"MultiIndex must have exactly 2 levels: (ticker, date)\")\n",
    "\n",
    "    # Convert single ticker to list for consistent processing\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "    elif not isinstance(tickers, list):\n",
    "        raise TypeError(\"tickers must be a string or list of strings\")\n",
    "\n",
    "    # Convert dates to Timestamps\n",
    "    try:\n",
    "        start_date = pd.Timestamp(date_start)\n",
    "        end_date = pd.Timestamp(date_end)\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"Invalid date format. Use 'YYYY-MM-DD': {e}\")\n",
    "\n",
    "    if start_date > end_date:\n",
    "        raise ValueError(\"date_start must be before or equal to date_end\")\n",
    "\n",
    "    # Check if tickers exist in the DataFrame\n",
    "    available_tickers = df_ohlcv.index.get_level_values(0).unique()\n",
    "    missing_tickers = [t for t in tickers if t not in available_tickers]\n",
    "\n",
    "    if missing_tickers:\n",
    "        raise KeyError(f\"Ticker(s) not found in DataFrame: {missing_tickers}\")\n",
    "\n",
    "    # Filter the data using MultiIndex slicing\n",
    "    try:\n",
    "        filtered_data = df_ohlcv.loc[(tickers, slice(date_start, date_end)), :]\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error filtering data: {e}\")\n",
    "\n",
    "    # Handle empty results\n",
    "    if filtered_data.empty:\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"No data found for tickers {tickers} in date range {date_start} to {date_end}\"\n",
    "            )\n",
    "        return filtered_data\n",
    "\n",
    "    # Print summary if verbose\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"Data retrieved for {len(tickers)} ticker(s) from {date_start} to {date_end}\"\n",
    "        )\n",
    "        print(f\"Total rows: {len(filtered_data)}\")\n",
    "        print(\n",
    "            f\"Date range in data: {filtered_data.index.get_level_values(1).min()} to \"\n",
    "            f\"{filtered_data.index.get_level_values(1).max()}\"\n",
    "        )\n",
    "\n",
    "        # Print ticker-specific counts\n",
    "        ticker_counts = filtered_data.index.get_level_values(0).value_counts()\n",
    "        for ticker in tickers:\n",
    "            count = ticker_counts.get(ticker, 0)\n",
    "            if count > 0:\n",
    "                print(f\"  {ticker}: {count} rows\")\n",
    "            else:\n",
    "                print(f\"  {ticker}: No data in range\")\n",
    "\n",
    "    # Return in requested format\n",
    "    if return_format == \"dict\":\n",
    "        result = {}\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result[ticker] = filtered_data.xs(ticker, level=0).loc[\n",
    "                    date_start:date_end\n",
    "                ]\n",
    "            except KeyError:\n",
    "                result[ticker] = pd.DataFrame()\n",
    "        return result\n",
    "\n",
    "    elif return_format == \"separate\":\n",
    "        result = []\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result.append(\n",
    "                    filtered_data.xs(ticker, level=0).loc[date_start:date_end]\n",
    "                )\n",
    "            except KeyError:\n",
    "                result.append(pd.DataFrame())\n",
    "        return result\n",
    "\n",
    "    elif return_format == \"dataframe\":\n",
    "        return filtered_data\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Invalid return_format: {return_format}. \"\n",
    "            f\"Must be 'dataframe', 'dict', or 'separate'\"\n",
    "        )\n",
    "\n",
    "\n",
    "def get_ticker_features(\n",
    "    features_df: pd.DataFrame,\n",
    "    tickers: Union[str, List[str]],\n",
    "    date_start: str,\n",
    "    date_end: str,\n",
    "    return_format: str = \"dataframe\",\n",
    "    verbose: bool = True,\n",
    ") -> Union[pd.DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    Get features data for specified tickers within a date range.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    features_df : pd.DataFrame\n",
    "        DataFrame with MultiIndex of (ticker, date) and feature columns\n",
    "    tickers : str or list of str\n",
    "        Ticker symbol(s) to retrieve\n",
    "    date_start : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    date_end : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    return_format : str, optional\n",
    "        Format to return data in. Options:\n",
    "        - 'dataframe': Single DataFrame with MultiIndex (default)\n",
    "        - 'dict': Dictionary with tickers as keys and DataFrames as values\n",
    "        - 'separate': List of separate DataFrames for each ticker\n",
    "    verbose : bool, optional\n",
    "        Whether to print summary information (default: True)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Union[pd.DataFrame, dict, list]\n",
    "        Filtered features data in specified format\n",
    "    \"\"\"\n",
    "    # Convert single ticker to list for consistent processing\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "\n",
    "    # Filter the data using MultiIndex slicing\n",
    "    try:\n",
    "        filtered_data = features_df.loc[(tickers, slice(date_start, date_end)), :]\n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"Error filtering data: {e}\")\n",
    "        return pd.DataFrame() if return_format == \"dataframe\" else {}\n",
    "\n",
    "    # Handle empty results\n",
    "    if filtered_data.empty:\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"No data found for tickers {tickers} in date range {date_start} to {date_end}\"\n",
    "            )\n",
    "        return filtered_data\n",
    "\n",
    "    # Print summary if verbose\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"Features data retrieved for {len(tickers)} ticker(s) from {date_start} to {date_end}\"\n",
    "        )\n",
    "        print(f\"Total rows: {len(filtered_data)}\")\n",
    "        print(\n",
    "            f\"Date range in data: {filtered_data.index.get_level_values(1).min()} to \"\n",
    "            f\"{filtered_data.index.get_level_values(1).max()}\"\n",
    "        )\n",
    "        print(f\"Available features: {', '.join(filtered_data.columns.tolist())}\")\n",
    "\n",
    "        # Print ticker-specific counts\n",
    "        ticker_counts = filtered_data.index.get_level_values(0).value_counts()\n",
    "        for ticker in tickers:\n",
    "            count = ticker_counts.get(ticker, 0)\n",
    "            if count > 0:\n",
    "                print(f\"  {ticker}: {count} rows\")\n",
    "            else:\n",
    "                print(f\"  {ticker}: No data in range\")\n",
    "\n",
    "    # Return in requested format\n",
    "    if return_format == \"dict\":\n",
    "        result = {}\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result[ticker] = filtered_data.xs(ticker, level=0).loc[\n",
    "                    date_start:date_end\n",
    "                ]\n",
    "            except KeyError:\n",
    "                result[ticker] = pd.DataFrame()\n",
    "        return result\n",
    "\n",
    "    elif return_format == \"separate\":\n",
    "        result = []\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result.append(\n",
    "                    filtered_data.xs(ticker, level=0).loc[date_start:date_end]\n",
    "                )\n",
    "            except KeyError:\n",
    "                result.append(pd.DataFrame())\n",
    "        return result\n",
    "\n",
    "    elif return_format == \"dataframe\":\n",
    "        return filtered_data\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Invalid return_format: {return_format}. \"\n",
    "            f\"Must be 'dataframe', 'dict', or 'separate'\"\n",
    "        )\n",
    "\n",
    "\n",
    "def create_combined_dict(\n",
    "    df_ohlcv: pd.DataFrame,\n",
    "    features_df: pd.DataFrame,\n",
    "    tickers: Union[str, List[str]],\n",
    "    date_start: str,\n",
    "    date_end: str,\n",
    "    verbose: bool = True,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Create a combined dictionary with both OHLCV and features data for each ticker.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_ohlcv : pd.DataFrame\n",
    "        DataFrame with OHLCV data (MultiIndex: ticker, date)\n",
    "    features_df : pd.DataFrame\n",
    "        DataFrame with features data (MultiIndex: ticker, date)\n",
    "    tickers : str or list of str\n",
    "        Ticker symbol(s) to retrieve\n",
    "    date_start : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    date_end : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    verbose : bool, optional\n",
    "        Whether to print progress information (default: True)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with tickers as keys and combined DataFrames (OHLCV + features) as values\n",
    "    \"\"\"\n",
    "    # Convert single ticker to list\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Creating combined dictionary for {len(tickers)} ticker(s)\")\n",
    "        print(f\"Date range: {date_start} to {date_end}\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "    # Get OHLCV data as dictionary\n",
    "    ohlcv_dict = get_ticker_OHLCV(\n",
    "        df_ohlcv, tickers, date_start, date_end, return_format=\"dict\", verbose=verbose\n",
    "    )\n",
    "\n",
    "    # Get features data as dictionary\n",
    "    features_dict = get_ticker_features(\n",
    "        features_df,\n",
    "        tickers,\n",
    "        date_start,\n",
    "        date_end,\n",
    "        return_format=\"dict\",\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "    # Create combined_dict\n",
    "    combined_dict = {}\n",
    "\n",
    "    for ticker in tickers:\n",
    "        if verbose:\n",
    "            print(f\"\\nProcessing {ticker}...\")\n",
    "\n",
    "        # Check if ticker exists in both dictionaries\n",
    "        if ticker in ohlcv_dict and ticker in features_dict:\n",
    "            ohlcv_data = ohlcv_dict[ticker]\n",
    "            features_data = features_dict[ticker]\n",
    "\n",
    "            # Check if both dataframes have data\n",
    "            if not ohlcv_data.empty and not features_data.empty:\n",
    "                # Combine OHLCV and features data\n",
    "                # Note: Both dataframes have the same index (dates), so we can concatenate\n",
    "                combined_df = pd.concat([ohlcv_data, features_data], axis=1)\n",
    "\n",
    "                # Ensure proper index naming\n",
    "                combined_df.index.name = \"Date\"\n",
    "\n",
    "                # Store in combined_dict\n",
    "                combined_dict[ticker] = combined_df\n",
    "\n",
    "                if verbose:\n",
    "                    print(f\"  ‚úì Successfully combined data\")\n",
    "                    print(f\"  OHLCV shape: {ohlcv_data.shape}\")\n",
    "                    print(f\"  Features shape: {features_data.shape}\")\n",
    "                    print(f\"  Combined shape: {combined_df.shape}\")\n",
    "                    print(\n",
    "                        f\"  Date range: {combined_df.index.min()} to {combined_df.index.max()}\"\n",
    "                    )\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"  ‚úó Cannot combine: One or both dataframes are empty\")\n",
    "                    print(f\"    OHLCV empty: {ohlcv_data.empty}\")\n",
    "                    print(f\"    Features empty: {features_data.empty}\")\n",
    "                combined_dict[ticker] = pd.DataFrame()\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(f\"  ‚úó Ticker not found in both dictionaries\")\n",
    "                if ticker not in ohlcv_dict:\n",
    "                    print(f\"    Not in OHLCV data\")\n",
    "                if ticker not in features_dict:\n",
    "                    print(f\"    Not in features data\")\n",
    "            combined_dict[ticker] = pd.DataFrame()\n",
    "\n",
    "    # Print summary\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"SUMMARY\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Total tickers processed: {len(tickers)}\")\n",
    "\n",
    "        tickers_with_data = [\n",
    "            ticker for ticker, df in combined_dict.items() if not df.empty\n",
    "        ]\n",
    "        print(f\"Tickers with combined data: {len(tickers_with_data)}\")\n",
    "\n",
    "        if tickers_with_data:\n",
    "            print(\"\\nTicker details:\")\n",
    "            for ticker in tickers_with_data:\n",
    "                df = combined_dict[ticker]\n",
    "                print(f\"  {ticker}: {df.shape} - {df.index.min()} to {df.index.max()}\")\n",
    "                print(f\"    Columns: {len(df.columns)}\")\n",
    "\n",
    "        empty_tickers = [ticker for ticker, df in combined_dict.items() if df.empty]\n",
    "        if empty_tickers:\n",
    "            print(f\"\\nTickers with no data: {', '.join(empty_tickers)}\")\n",
    "\n",
    "    return combined_dict\n",
    "\n",
    "\n",
    "def export_debug_to_csv(container, source_label=\"Simulation\"):\n",
    "    \"\"\"\n",
    "    Flattens the debug_container and saves all components to high-precision CSVs.\n",
    "    \"\"\"\n",
    "    if not container or not container[0]:\n",
    "        print(\"‚ùå Error: Debug container is empty.\")\n",
    "        return\n",
    "\n",
    "    data = container[0]\n",
    "    inputs = data.get(\"inputs\")\n",
    "\n",
    "    # 1. Create a clean folder name\n",
    "    # e.g., Audit_Golden_20251211_SharpeATR\n",
    "    date_str = inputs.start_date.strftime(\"%Y-%m-%d\")\n",
    "    strategy_str = inputs.metric.replace(\" \", \"\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "    folder_name = f\"Audit_{source_label}_{date_str}_{strategy_str}\"\n",
    "\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    print(f\"üìÇ Exporting audit data to: ./{folder_name}/\")\n",
    "\n",
    "    # 2. Recursive function to traverse the dictionary and save files\n",
    "    def process_item(item, path_prefix=\"\"):\n",
    "        # Handle Nested Dictionaries (like 'verification' or 'raw_components')\n",
    "        if isinstance(item, dict):\n",
    "            for key, value in item.items():\n",
    "                new_prefix = f\"{path_prefix}{key}_\" if path_prefix else f\"{key}_\"\n",
    "                process_item(value, new_prefix)\n",
    "\n",
    "        # Handle DataFrames\n",
    "        elif isinstance(item, pd.DataFrame):\n",
    "            filename = f\"{path_prefix.strip('_')}.csv\"\n",
    "            item.to_csv(os.path.join(folder_name, filename), float_format=\"%.8f\")\n",
    "            print(f\"   ‚úÖ Saved DataFrame: {filename}\")\n",
    "\n",
    "        # Handle Series (Convert to DataFrame for CSV preservation of Index)\n",
    "        elif isinstance(item, pd.Series):\n",
    "            filename = f\"{path_prefix.strip('_')}.csv\"\n",
    "            item.to_frame().to_csv(\n",
    "                os.path.join(folder_name, filename), float_format=\"%.8f\"\n",
    "            )\n",
    "            print(f\"   ‚úÖ Saved Series:    {filename}\")\n",
    "\n",
    "        # Handle Dataclasses (like 'inputs')\n",
    "        elif is_dataclass(item):\n",
    "            filename = f\"{path_prefix}Metadata.csv\"\n",
    "            # Convert to a vertical 2-column table for easy Excel reading\n",
    "            meta_df = pd.DataFrame.from_dict(\n",
    "                asdict(item), orient=\"index\", columns=[\"Value\"]\n",
    "            )\n",
    "            meta_df.to_csv(os.path.join(folder_name, filename))\n",
    "            print(f\"   ‚úÖ Saved Metadata:  {filename}\")\n",
    "\n",
    "    # 3. Start the extraction\n",
    "    process_item(data)\n",
    "    print(f\"\\n‚ú® Export Complete. All numbers saved with 8 decimal places.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2989c8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SECTION G: UNIT TEST FOR GENERATED FEATURES\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "def test_true_range_calculation():\n",
    "    \"\"\"Test TR = max(High-Low, |High-PrevClose|, |Low-PrevClose|) using robust pandas testing\"\"\"\n",
    "    print(\"Running test_true_range_calculation (Robust Version)...\")\n",
    "\n",
    "    # 1. SETUP: Create test data\n",
    "    test_data = {\n",
    "        \"Adj Open\": [100, 105, 95, 98, 102],\n",
    "        \"Adj High\": [105, 108, 97, 102, 105],\n",
    "        \"Adj Low\": [95, 103, 93, 100, 98],\n",
    "        \"Adj Close\": [100, 106, 96, 99, 103],\n",
    "        \"Volume\": [1000, 1200, 800, 900, 1100],\n",
    "    }\n",
    "\n",
    "    index = pd.MultiIndex.from_tuples(\n",
    "        [\n",
    "            (\"TEST\", pd.Timestamp(\"2024-01-01\")),\n",
    "            (\"TEST\", pd.Timestamp(\"2024-01-02\")),\n",
    "            (\"TEST\", pd.Timestamp(\"2024-01-03\")),\n",
    "            (\"TEST\", pd.Timestamp(\"2024-01-04\")),\n",
    "            (\"TEST\", pd.Timestamp(\"2024-01-05\")),\n",
    "        ],\n",
    "        names=[\"Ticker\", \"Date\"],\n",
    "    )\n",
    "\n",
    "    df_test = pd.DataFrame(test_data, index=index)\n",
    "    print(f\"test_true_range_df input:\\n{df_test}\\n\")\n",
    "\n",
    "    # 2. EXECUTION: Run function\n",
    "    result = generate_features(df_test, quality_window=5, quality_min_periods=2)\n",
    "\n",
    "    # 3. ASSERTION: Define EXACT expected series\n",
    "    # Day 1: NaN (No prev close)\n",
    "    # Day 2: 8.0 (PrevClose=100, High=108, Low=103. |108-100|=8)\n",
    "    # Day 3: 13.0 (PrevClose=106, High=97, Low=93. |93-106|=13)\n",
    "    # Day 4: 6.0 (PrevClose=96, High=102, Low=100. |102-96|=6)\n",
    "    # Day 5: 7.0 (PrevClose=99, High=105, Low=98. High-Low=7)\n",
    "    expected_tr_values = [np.nan, 8.0, 13.0, 6.0, 7.0]\n",
    "\n",
    "    expected_series = pd.Series(\n",
    "        expected_tr_values, index=result.index, name=\"TR\", dtype=\"float64\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Check Series Equality\n",
    "        # check_exact=False allows for minor floating point differences (rtol=1e-4)\n",
    "        assert_series_equal(result[\"TR\"], expected_series, check_exact=False, rtol=1e-4)\n",
    "\n",
    "        print(\"‚úÖ PD Testing Assertion Passed! All TR values match expected logic.\")\n",
    "        return True\n",
    "\n",
    "    except AssertionError as e:\n",
    "        print(f\"‚ùå PD Testing Assertion Failed: {e}\")\n",
    "\n",
    "        # Helper output to see what went wrong\n",
    "        print(\"\\nDetailed Comparison (Actual vs Expected):\")\n",
    "        comparison = pd.concat(\n",
    "            [result[\"TR\"], expected_series], axis=1, keys=[\"Actual_TR\", \"Expected_TR\"]\n",
    "        )\n",
    "        comparison[\"Diff\"] = comparison[\"Actual_TR\"] - comparison[\"Expected_TR\"]\n",
    "        print(comparison)\n",
    "\n",
    "        return False\n",
    "\n",
    "\n",
    "def test_atr_calculation():\n",
    "    \"\"\"Test ATR = EWMA of TR with alpha=1/period\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Running test_atr_calculation...\")\n",
    "\n",
    "    # Test data with 5 days\n",
    "    test_data = {\n",
    "        \"Adj Open\": [100, 102, 103, 110, 108],\n",
    "        \"Adj High\": [101, 103, 103, 112, 110],\n",
    "        \"Adj Low\": [99, 101, 103, 108, 107],\n",
    "        \"Adj Close\": [100, 102, 103, 111, 109],\n",
    "        \"Volume\": [1000, 1000, 1000, 1000, 1000],  # All non-zero for simplicity\n",
    "    }\n",
    "\n",
    "    index = pd.MultiIndex.from_tuples(\n",
    "        [(\"TEST\", pd.Timestamp(f\"2024-01-{i:02d}\")) for i in range(1, 6)],\n",
    "        names=[\"Ticker\", \"Date\"],\n",
    "    )\n",
    "\n",
    "    df_test = pd.DataFrame(test_data, index=index)\n",
    "\n",
    "    print(f\"test_true_range_df:\\n{df_test}\\n\")\n",
    "\n",
    "    result = generate_features(df_test, atr_period=14)\n",
    "\n",
    "    print(\"\\nATR Calculation Results:\")\n",
    "    print(result[[\"TR\", \"ATR\", \"ATRP\"]])\n",
    "\n",
    "    # Manual calculation from our earlier example\n",
    "    # CORRECTED EXPECTED VALUES WITH MORE PRECISION\n",
    "    expected_atr = {\n",
    "        \"2024-01-02\": 3.0,\n",
    "        \"2024-01-03\": 40 / 14,  # ‚âà 2.857142857142857\n",
    "        \"2024-01-04\": 646 / 196,  # ‚âà 3.2959183673469388\n",
    "        \"2024-01-05\": 9182 / 2744,  # ‚âà 3.3462099125364433\n",
    "    }\n",
    "\n",
    "    all_passed = True\n",
    "    for date_str, expected in expected_atr.items():\n",
    "        actual = result.loc[(\"TEST\", pd.Timestamp(date_str)), \"ATR\"]\n",
    "        if abs(actual - expected) < 0.0001:\n",
    "            print(f\"‚úì {date_str} ATR: {actual:.6f} ‚âà {expected:.6f}\")\n",
    "        else:\n",
    "            print(f\"‚úó {date_str} ATR: {actual:.6f} != {expected:.6f}\")\n",
    "            all_passed = False\n",
    "\n",
    "    if all_passed:\n",
    "        print(\"\\n‚úÖ All ATR tests passed!\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå Some ATR tests failed!\")\n",
    "\n",
    "    return all_passed\n",
    "\n",
    "\n",
    "def test_is_stale_calculation():\n",
    "    \"\"\"Test IsStale = 1 when Volume=0 OR High=Low\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Running test_is_stale_calculation...\")\n",
    "\n",
    "    test_data = {\n",
    "        \"Adj Open\": [100, 102, 103, 104],\n",
    "        \"Adj High\": [101, 103, 103, 105],  # Day 3: High=Low\n",
    "        \"Adj Low\": [99, 101, 103, 104],\n",
    "        \"Adj Close\": [100, 102, 103, 105],\n",
    "        \"Volume\": [1000, 0, 500, 1000],  # Day 2: Volume=0\n",
    "    }\n",
    "\n",
    "    index = pd.MultiIndex.from_tuples(\n",
    "        [(\"TEST\", pd.Timestamp(f\"2024-01-{i:02d}\")) for i in range(1, 5)],\n",
    "        names=[\"Ticker\", \"Date\"],\n",
    "    )\n",
    "\n",
    "    df_test = pd.DataFrame(test_data, index=index)\n",
    "\n",
    "    print(f\"test_is_stale_df:\\n{df_test}\\n\")\n",
    "\n",
    "    # Create IsStale manually to verify\n",
    "    is_stale_manual = np.where(\n",
    "        (df_test[\"Volume\"] == 0) | (df_test[\"Adj High\"] == df_test[\"Adj Low\"]), 1, 0\n",
    "    )\n",
    "\n",
    "    print(\"\\nüìä Manual IsStale Calculation:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"IsStale = 1 if EITHER condition is true:\")\n",
    "    print(\"  1. Volume == 0\")\n",
    "    print(\"  2. Adj High == Adj Low (no price movement)\")\n",
    "    print(\"Otherwise, IsStale = 0\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Create a temporary DataFrame to display the calculation clearly\n",
    "    manual_calc_df = df_test.copy()\n",
    "    manual_calc_df[\"IsStale_Manual\"] = is_stale_manual\n",
    "    manual_calc_df[\"Volume==0\"] = manual_calc_df[\"Volume\"] == 0\n",
    "    manual_calc_df[\"High==Low\"] = (\n",
    "        manual_calc_df[\"Adj High\"] == manual_calc_df[\"Adj Low\"]\n",
    "    )\n",
    "\n",
    "    print(\"\\nCalculation details:\")\n",
    "    for idx, row in manual_calc_df.iterrows():\n",
    "        ticker_date = f\"{idx[0]}, {idx[1].strftime('%Y-%m-%d')}\"\n",
    "        conditions = []\n",
    "        if row[\"Volume==0\"]:\n",
    "            conditions.append(\"Volume=0\")\n",
    "        if row[\"High==Low\"]:\n",
    "            conditions.append(\"High=Low\")\n",
    "\n",
    "        condition_str = \" OR \".join(conditions) if conditions else \"None (both False)\"\n",
    "        result = row[\"IsStale_Manual\"]\n",
    "\n",
    "        print(f\"  {ticker_date}:\")\n",
    "        print(\n",
    "            f\"    Volume={row['Volume']}, High={row['Adj High']}, Low={row['Adj Low']}\"\n",
    "        )\n",
    "        print(f\"    Conditions met: {condition_str}\")\n",
    "        print(f\"    ‚Üí IsStale = {result}\")\n",
    "        print()\n",
    "\n",
    "    expected = [\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "    ]  # Day 1: normal, Day 2: vol=0, Day 3: high=low, Day 4: normal\n",
    "\n",
    "    print(f\"\\nManual IsStale calculation: {is_stale_manual}\")\n",
    "    print(f\"Expected: {expected}\")\n",
    "\n",
    "    if list(is_stale_manual) == expected:\n",
    "        print(\"‚úì IsStale calculation logic is correct\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\n",
    "            f\"‚úó IsStale calculation failed. Got {is_stale_manual}, expected {expected}\"\n",
    "        )\n",
    "        return False\n",
    "\n",
    "\n",
    "def test_multiple_tickers():\n",
    "    \"\"\"Test that calculations don't mix data between tickers\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Running test_multiple_tickers...\")\n",
    "\n",
    "    test_data = {\n",
    "        \"Adj Open\": [100, 102, 50, 51],\n",
    "        \"Adj High\": [101, 103, 52, 53],\n",
    "        \"Adj Low\": [99, 101, 48, 49],\n",
    "        \"Adj Close\": [100, 102, 49, 52],\n",
    "        \"Volume\": [1000, 1000, 2000, 2000],\n",
    "    }\n",
    "\n",
    "    index = pd.MultiIndex.from_tuples(\n",
    "        [\n",
    "            (\"A\", pd.Timestamp(\"2024-01-01\")),\n",
    "            (\"A\", pd.Timestamp(\"2024-01-02\")),\n",
    "            (\"B\", pd.Timestamp(\"2024-01-01\")),\n",
    "            (\"B\", pd.Timestamp(\"2024-01-02\")),\n",
    "        ],\n",
    "        names=[\"Ticker\", \"Date\"],\n",
    "    )\n",
    "\n",
    "    df_test = pd.DataFrame(test_data, index=index)\n",
    "\n",
    "    print(f\"test_multiple_tickers_df:\\n{df_test}\\n\")\n",
    "\n",
    "    result = generate_features(df_test)\n",
    "\n",
    "    print(\"\\nMultiple Ticker Results:\")\n",
    "    print(result[[\"TR\", \"ATR\"]])\n",
    "\n",
    "    # Ticker A day 2 TR should use A day 1 close, not B day 1 close\n",
    "    tr_a2 = result.loc[(\"A\", \"2024-01-02\"), \"TR\"]\n",
    "    expected_a2 = 3.0  # max(103-101=2, |103-100|=3, |101-100|=1) = 3\n",
    "\n",
    "    tr_b2 = result.loc[(\"B\", \"2024-01-02\"), \"TR\"]\n",
    "    expected_b2 = 4.0  # max(53-49=4, |53-49|=4, |49-49|=0) = 4\n",
    "\n",
    "    tests_passed = 0\n",
    "    total_tests = 2\n",
    "\n",
    "    if abs(tr_a2 - expected_a2) < 0.0001:\n",
    "        print(f\"‚úì Ticker A TR: {tr_a2} (expected {expected_a2})\")\n",
    "        tests_passed += 1\n",
    "    else:\n",
    "        print(f\"‚úó Ticker A TR: {tr_a2} != {expected_a2}\")\n",
    "\n",
    "    if abs(tr_b2 - expected_b2) < 0.0001:\n",
    "        print(f\"‚úì Ticker B TR: {tr_b2} (expected {expected_b2})\")\n",
    "        tests_passed += 1\n",
    "    else:\n",
    "        print(f\"‚úó Ticker B TR: {tr_b2} != {expected_b2}\")\n",
    "\n",
    "    if tests_passed == total_tests:\n",
    "        print(\"‚úÖ Ticker separation test passed!\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"‚ùå Ticker separation test failed: {tests_passed}/{total_tests} passed\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def test_edge_cases():\n",
    "    \"\"\"Test edge cases like zero price, single row, etc.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Running test_edge_cases...\")\n",
    "\n",
    "    all_passed = True\n",
    "\n",
    "    # Test 1: Very low price (penny stock)\n",
    "    print(\"\\n1. Testing penny stock with low price...\")\n",
    "    test_data = {\n",
    "        \"Adj Open\": [0.10, 0.11],\n",
    "        \"Adj High\": [0.10, 0.11],\n",
    "        \"Adj Low\": [0.10, 0.11],\n",
    "        \"Adj Close\": [0.10, 0.11],\n",
    "        \"Volume\": [1000, 1000],\n",
    "    }\n",
    "\n",
    "    index = pd.MultiIndex.from_tuples(\n",
    "        [\n",
    "            (\"PENNY\", pd.Timestamp(\"2024-01-01\")),\n",
    "            (\"PENNY\", pd.Timestamp(\"2024-01-02\")),\n",
    "        ],\n",
    "        names=[\"Ticker\", \"Date\"],\n",
    "    )\n",
    "\n",
    "    df_penny = pd.DataFrame(test_data, index=index)\n",
    "\n",
    "    print(f\"df_penny_stock:\\n{df_penny}\\n\")\n",
    "\n",
    "    result = generate_features(df_penny)\n",
    "\n",
    "    # Check ATRP is reasonable (not inf/nan)\n",
    "    atrp_val = result.loc[(\"PENNY\", \"2024-01-02\"), \"ATRP\"]\n",
    "    if pd.isna(atrp_val) or np.isinf(atrp_val):\n",
    "        print(f\"‚úó Penny stock ATRP is {atrp_val} (should be finite)\")\n",
    "        all_passed = False\n",
    "    else:\n",
    "        print(f\"‚úì Penny stock ATRP is {atrp_val:.4f}\")\n",
    "\n",
    "    # Test 2: Single row\n",
    "    print(\"\\n2. Testing single row data...\")\n",
    "    test_data_single = {\n",
    "        \"Adj Open\": [100],\n",
    "        \"Adj High\": [101],\n",
    "        \"Adj Low\": [99],\n",
    "        \"Adj Close\": [100],\n",
    "        \"Volume\": [1000],\n",
    "    }\n",
    "\n",
    "    index_single = pd.MultiIndex.from_tuples(\n",
    "        [(\"SINGLE\", pd.Timestamp(\"2024-01-01\"))], names=[\"Ticker\", \"Date\"]\n",
    "    )\n",
    "\n",
    "    df_single = pd.DataFrame(test_data_single, index=index_single)\n",
    "\n",
    "    print(f\"df_single:\\n{df_single}\\n\")\n",
    "\n",
    "    result_single = generate_features(\n",
    "        df_single, quality_window=3, quality_min_periods=2\n",
    "    )\n",
    "\n",
    "    # TR should be NaN (no previous close)\n",
    "    if pd.isna(result_single.loc[(\"SINGLE\", \"2024-01-01\"), \"TR\"]):\n",
    "        print(\"‚úì Single row TR is NaN (correct)\")\n",
    "    else:\n",
    "        print(\n",
    "            f\"‚úó Single row TR should be NaN but got {result_single.loc[('SINGLE', '2024-01-01'), 'TR']}\"\n",
    "        )\n",
    "        all_passed = False\n",
    "\n",
    "    # Rolling metrics should be NaN with min_periods=2\n",
    "    if pd.isna(result_single.loc[(\"SINGLE\", \"2024-01-01\"), \"RollingStalePct\"]):\n",
    "        print(\"‚úì Single row rolling metrics are NaN (correct - insufficient periods)\")\n",
    "    else:\n",
    "        print(\n",
    "            f\"‚úó Rolling metrics should be NaN but got {result_single.loc[('SINGLE', '2024-01-01'), 'RollingStalePct']}\"\n",
    "        )\n",
    "        all_passed = False\n",
    "\n",
    "    if all_passed:\n",
    "        print(\"\\n‚úÖ All edge case tests passed!\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå Some edge case tests failed!\")\n",
    "\n",
    "    return all_passed\n",
    "\n",
    "\n",
    "def test_zero_division_protection():\n",
    "    \"\"\"Test that Zero Price doesn't cause Inf values in ATRP\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Running test_zero_division_protection...\")\n",
    "\n",
    "    test_data = {\n",
    "        \"Adj Open\": [10, 10, 10],\n",
    "        \"Adj High\": [12, 12, 12],\n",
    "        \"Adj Low\": [8, 8, 8],\n",
    "        \"Adj Close\": [10, 0, 10],  # Day 2 Price is ZERO\n",
    "        \"Volume\": [1000, 1000, 1000],\n",
    "    }\n",
    "    index = pd.MultiIndex.from_tuples(\n",
    "        [(\"ZERO\", pd.Timestamp(f\"2024-01-0{i}\")) for i in range(1, 4)],\n",
    "        names=[\"Ticker\", \"Date\"],\n",
    "    )\n",
    "    df_test = pd.DataFrame(test_data, index=index)\n",
    "\n",
    "    print(f\"test_zero_division_protection_df:\\n{df_test}\\n\")\n",
    "\n",
    "    # Run features\n",
    "    result = generate_features(df_test, atr_period=2)\n",
    "\n",
    "    # Check Day 2 ATRP\n",
    "    atrp_val = result.loc[(\"ZERO\", \"2024-01-02\"), \"ATRP\"]\n",
    "\n",
    "    if pd.isna(atrp_val):\n",
    "        print(\"‚úÖ Zero Division Test Passed: ATRP is NaN when Close is 0.\")\n",
    "        return True\n",
    "    elif np.isinf(atrp_val):\n",
    "        print(f\"‚ùå Zero Division Test Failed: ATRP is Infinite ({atrp_val}).\")\n",
    "        return False\n",
    "    else:\n",
    "        print(f\"‚ùå Zero Division Test Failed: Unexpected value {atrp_val}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def test_unsorted_input_handling():\n",
    "    \"\"\"Test that function handles unsorted dates correctly via sorting\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Running test_unsorted_input_handling...\")\n",
    "\n",
    "    # Data is out of order: Day 2, Day 1, Day 3\n",
    "    index = pd.MultiIndex.from_tuples(\n",
    "        [\n",
    "            (\"A\", pd.Timestamp(\"2024-01-02\")),\n",
    "            (\"A\", pd.Timestamp(\"2024-01-01\")),\n",
    "            (\"A\", pd.Timestamp(\"2024-01-03\")),\n",
    "        ],\n",
    "        names=[\"Ticker\", \"Date\"],\n",
    "    )\n",
    "\n",
    "    # Prices: 100 -> 105 -> 110\n",
    "    # If processed in order given:\n",
    "    # 1. 105 (No prev)\n",
    "    # 2. 100 (Prev is 105) -> Change -5\n",
    "    # 3. 110 (Prev is 100) -> Change +10\n",
    "\n",
    "    # If sorted correctly:\n",
    "    # 1. 100 (No prev)\n",
    "    # 2. 105 (Prev is 100) -> Change +5\n",
    "    # 3. 110 (Prev is 105) -> Change +5\n",
    "\n",
    "    test_data = {\n",
    "        \"Adj Open\": [100, 100, 100],\n",
    "        \"Adj High\": [105, 100, 110],\n",
    "        \"Adj Low\": [105, 100, 110],\n",
    "        \"Adj Close\": [105, 100, 110],  # 105, 100, 110\n",
    "        \"Volume\": [100, 100, 100],\n",
    "    }\n",
    "\n",
    "    df_test = pd.DataFrame(test_data, index=index)\n",
    "\n",
    "    print(f\"test_unsorted_input_handling_df:\\n{df_test}\\n\")\n",
    "\n",
    "    # Run features\n",
    "    result = generate_features(df_test)\n",
    "\n",
    "    # Inspect 2024-01-02 (Should be Day 2 in sorted order)\n",
    "    # Prev close (Jan 1) was 100. Current High 105. TR should be roughly 5.\n",
    "    tr_day_2 = result.loc[(\"A\", \"2024-01-02\"), \"TR\"]\n",
    "\n",
    "    # If it wasn't sorted, Day 2 would be treated as the first row (TR=NaN)\n",
    "    # or compared against whatever came before it in memory.\n",
    "\n",
    "    if pd.isna(tr_day_2):\n",
    "        print(\"‚ùå Sorting Test Failed: Day 2 TR is NaN (likely treated as first row).\")\n",
    "        return False\n",
    "    elif abs(tr_day_2 - 5.0) < 0.1:\n",
    "        print(\"‚úÖ Sorting Test Passed: Logic applied in correct chronological order.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"‚ùå Sorting Test Failed: Day 2 TR is {tr_day_2}, expected ~5.0\")\n",
    "        return False\n",
    "\n",
    "    \"\"\"Test TR = max(High-Low, |High-PrevClose|, |Low-PrevClose|) using robust pandas testing\"\"\"\n",
    "    print(\"Running test_true_range_calculation (Robust Version)...\")\n",
    "\n",
    "    # 1. SETUP: Create test data\n",
    "    test_data = {\n",
    "        \"Adj Open\": [100, 105, 95, 98, 102],\n",
    "        \"Adj High\": [105, 108, 97, 102, 105],\n",
    "        \"Adj Low\": [95, 103, 93, 100, 98],\n",
    "        \"Adj Close\": [100, 106, 96, 99, 103],\n",
    "        \"Volume\": [1000, 1200, 800, 900, 1100],\n",
    "    }\n",
    "\n",
    "    index = pd.MultiIndex.from_tuples(\n",
    "        [\n",
    "            (\"TEST\", pd.Timestamp(\"2024-01-01\")),\n",
    "            (\"TEST\", pd.Timestamp(\"2024-01-02\")),\n",
    "            (\"TEST\", pd.Timestamp(\"2024-01-03\")),\n",
    "            (\"TEST\", pd.Timestamp(\"2024-01-04\")),\n",
    "            (\"TEST\", pd.Timestamp(\"2024-01-05\")),\n",
    "        ],\n",
    "        names=[\"Ticker\", \"Date\"],\n",
    "    )\n",
    "\n",
    "    df_test = pd.DataFrame(test_data, index=index)\n",
    "    print(f\"test_true_range_df input:\\n{df_test}\\n\")\n",
    "\n",
    "    # 2. EXECUTION: Run function\n",
    "    result = generate_features(df_test, quality_window=5, quality_min_periods=2)\n",
    "\n",
    "    # 3. ASSERTION: Define EXACT expected series\n",
    "    # Day 1: NaN (No prev close)\n",
    "    # Day 2: 8.0 (PrevClose=100, High=108, Low=103. |108-100|=8)\n",
    "    # Day 3: 13.0 (PrevClose=106, High=97, Low=93. |93-106|=13)\n",
    "    # Day 4: 6.0 (PrevClose=96, High=102, Low=100. |102-96|=6)\n",
    "    # Day 5: 7.0 (PrevClose=99, High=105, Low=98. High-Low=7)\n",
    "    expected_tr_values = [np.nan, 8.0, 13.0, 6.0, 7.0]\n",
    "\n",
    "    expected_series = pd.Series(\n",
    "        expected_tr_values, index=result.index, name=\"TR\", dtype=\"float64\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Check Series Equality\n",
    "        # check_exact=False allows for minor floating point differences (rtol=1e-4)\n",
    "        assert_series_equal(result[\"TR\"], expected_series, check_exact=False, rtol=1e-4)\n",
    "\n",
    "        print(\"‚úÖ PD Testing Assertion Passed! All TR values match expected logic.\")\n",
    "        return True\n",
    "\n",
    "    except AssertionError as e:\n",
    "        print(f\"‚ùå PD Testing Assertion Failed: {e}\")\n",
    "\n",
    "        # Helper output to see what went wrong\n",
    "        print(\"\\nDetailed Comparison (Actual vs Expected):\")\n",
    "        comparison = pd.concat(\n",
    "            [result[\"TR\"], expected_series], axis=1, keys=[\"Actual_TR\", \"Expected_TR\"]\n",
    "        )\n",
    "        comparison[\"Diff\"] = comparison[\"Actual_TR\"] - comparison[\"Expected_TR\"]\n",
    "        print(comparison)\n",
    "\n",
    "        return False\n",
    "\n",
    "\n",
    "def test_quality_rolling_features():\n",
    "    \"\"\"\n",
    "    Test RollingStalePct, RollMedDollarVol, and RollingSameVolCount\n",
    "    verifying logic for Stale(Vol=0), Stale(H=L), SameVolume, and Median calculations.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Running test_quality_rolling_features...\")\n",
    "\n",
    "    # 1. SETUP: Create specific test data\n",
    "    # We set up 5 days to test a window of 4\n",
    "    test_data = {\n",
    "        # Day 1: Normal Base Day. $Vol = 10*100 = 1000.\n",
    "        # Day 2: Same Volume as D1. $Vol = 10*100 = 1000.\n",
    "        # Day 3: Stale (Volume=0). $Vol = 20*0 = 0.\n",
    "        # Day 4: Stale (High=Low). $Vol = 20*50 = 1000.\n",
    "        # Day 5: Normal High Vol. $Vol = 30*200 = 6000.\n",
    "        \"Adj Open\": [10, 10, 20, 20, 30],\n",
    "        \"Adj High\": [12, 12, 22, 20, 35],  # Day 4 High=20\n",
    "        \"Adj Low\": [8, 8, 18, 20, 25],  # Day 4 Low=20 (H=L)\n",
    "        \"Adj Close\": [10, 10, 20, 20, 30],\n",
    "        \"Volume\": [100, 100, 0, 50, 200],  # Day 2 same as D1, Day 3 is 0\n",
    "    }\n",
    "\n",
    "    index = pd.MultiIndex.from_tuples(\n",
    "        [(\"TEST\", pd.Timestamp(f\"2024-01-0{i}\")) for i in range(1, 6)],\n",
    "        names=[\"Ticker\", \"Date\"],\n",
    "    )\n",
    "\n",
    "    df_test = pd.DataFrame(test_data, index=index)\n",
    "    print(f\"Input Data:\\n{df_test}\")\n",
    "\n",
    "    # 2. EXECUTION: Use window=4, min_periods=2 to capture partial rolling\n",
    "    # We expect Day 1 to be NaN (count=1 < min_periods=2)\n",
    "    result = generate_features(df_test, quality_window=4, quality_min_periods=2)\n",
    "\n",
    "    # 3. VERIFICATION\n",
    "\n",
    "    # --- A. Test RollingStalePct ---\n",
    "    print(\"\\n--- Testing RollingStalePct ---\")\n",
    "    # Logic:\n",
    "    # Day 1: IsStale=0. Result=NaN (min_periods)\n",
    "    # Day 2: IsStale=0. Window=[0,0]. Mean=0.0\n",
    "    # Day 3: IsStale=1 (Vol=0). Window=[0,0,1]. Mean=1/3 (~0.333)\n",
    "    # Day 4: IsStale=1 (High=Low). Window=[0,0,1,1]. Mean=2/4 = 0.5\n",
    "    # Day 5: IsStale=0. Window=[0,1,1,0] (Day 1 drops off). Mean=2/4 = 0.5\n",
    "\n",
    "    expected_stale = pd.Series(\n",
    "        [np.nan, 0.0, 1 / 3, 0.5, 0.5], index=result.index, name=\"RollingStalePct\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        assert_series_equal(\n",
    "            result[\"RollingStalePct\"], expected_stale, check_exact=False, rtol=1e-4\n",
    "        )\n",
    "        print(\"‚úÖ RollingStalePct Passed\")\n",
    "    except AssertionError as e:\n",
    "        print(f\"‚ùå RollingStalePct Failed: {e}\")\n",
    "        return False\n",
    "\n",
    "    # --- B. Test RollMedDollarVol ---\n",
    "    print(\"\\n--- Testing RollMedDollarVol ---\")\n",
    "    # Logic: $Vol = Close * Volume\n",
    "    # D1: 1000. Result=NaN\n",
    "    # D2: 1000. Window=[1000, 1000]. Median=1000\n",
    "    # D3: 0.    Window=[1000, 1000, 0]. Sorted=[0, 1000, 1000]. Median=1000\n",
    "    # D4: 1000. Window=[1000, 1000, 0, 1000]. Sorted=[0, 1000, 1000, 1000]. Median=(1000+1000)/2 = 1000\n",
    "    # D5: 6000. Window=[1000, 0, 1000, 6000]. Sorted=[0, 1000, 1000, 6000]. Median=1000\n",
    "\n",
    "    expected_dollar = pd.Series(\n",
    "        [np.nan, 1000.0, 1000.0, 1000.0, 1000.0],\n",
    "        index=result.index,\n",
    "        name=\"RollMedDollarVol\",\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        assert_series_equal(\n",
    "            result[\"RollMedDollarVol\"], expected_dollar, check_exact=False, rtol=1e-4\n",
    "        )\n",
    "        print(\"‚úÖ RollMedDollarVol Passed\")\n",
    "    except AssertionError as e:\n",
    "        print(f\"‚ùå RollMedDollarVol Failed: {e}\")\n",
    "        return False\n",
    "\n",
    "    # --- C. Test RollingSameVolCount ---\n",
    "    print(\"\\n--- Testing RollingSameVolCount ---\")\n",
    "    # Logic: HasSameVolume = (Volume == PrevVolume)\n",
    "    # D1: NaN/0 (First row diff is NaN, astype(int) -> 0). Result=NaN (min_periods)\n",
    "    # D2: 1 (100==100). Window=[0, 1]. Sum=1\n",
    "    # D3: 0 (0!=100).   Window=[0, 1, 0]. Sum=1\n",
    "    # D4: 0 (50!=0).    Window=[0, 1, 0, 0]. Sum=1\n",
    "    # D5: 0 (200!=50).  Window=[1, 0, 0, 0] (D1 drops). Sum=1\n",
    "\n",
    "    expected_same_vol = pd.Series(\n",
    "        [np.nan, 1.0, 1.0, 1.0, 1.0], index=result.index, name=\"RollingSameVolCount\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        assert_series_equal(\n",
    "            result[\"RollingSameVolCount\"],\n",
    "            expected_same_vol,\n",
    "            check_exact=False,\n",
    "            rtol=1e-4,\n",
    "        )\n",
    "        print(\"‚úÖ RollingSameVolCount Passed\")\n",
    "    except AssertionError as e:\n",
    "        print(f\"‚ùå RollingSameVolCount Failed: {e}\")\n",
    "        return False\n",
    "\n",
    "    print(\"\\nüéâ All Rolling Quality Feature Tests Passed!\")\n",
    "    return True\n",
    "\n",
    "\n",
    "def test_math_metrics():\n",
    "    \"\"\"Verifies calculate_gain and calculate_sharpe are mathematically precise.\"\"\"\n",
    "    print(\"Running test_math_metrics...\")\n",
    "    all_passed = True\n",
    "\n",
    "    # --- 1. Test calculate_gain ---\n",
    "    s_gain = pd.Series([100, 105, 110])\n",
    "    res_gain = calculate_gain(s_gain)\n",
    "    if abs(res_gain - 0.10) < 1e-9:\n",
    "        print(\"‚úÖ Gain Calc (Positive): Passed\")\n",
    "    else:\n",
    "        print(f\"‚ùå Gain Calc (Positive): Failed. Got {res_gain}\")\n",
    "        all_passed = False\n",
    "\n",
    "    s_loss = pd.Series([100, 95, 90])\n",
    "    res_loss = calculate_gain(s_loss)\n",
    "    if abs(res_loss - (-0.10)) < 1e-9:\n",
    "        print(\"‚úÖ Gain Calc (Negative): Passed\")\n",
    "    else:\n",
    "        print(f\"‚ùå Gain Calc (Negative): Failed. Got {res_loss}\")\n",
    "        all_passed = False\n",
    "\n",
    "    # --- 2. Test calculate_sharpe ---\n",
    "    s_flat = pd.Series([0.01, 0.01, 0.01])\n",
    "    res_sharpe_flat = calculate_sharpe(s_flat)\n",
    "    if res_sharpe_flat == 0.0:\n",
    "        print(\"‚úÖ Sharpe (Zero Volatility): Passed (Returns 0.0)\")\n",
    "    else:\n",
    "        print(f\"‚ùå Sharpe (Zero Volatility): Failed. Got {res_sharpe_flat}\")\n",
    "        all_passed = False\n",
    "\n",
    "    return all_passed\n",
    "\n",
    "\n",
    "def test_engine_lag_logic():\n",
    "    \"\"\"\n",
    "    CRITICAL TEST: Verifies the '1-Day Lag' logic using NEW Variable Names.\n",
    "    \"\"\"\n",
    "    print(\"\\nRunning test_engine_lag_logic...\")\n",
    "\n",
    "    # 1. Setup Mock Data\n",
    "    dates = pd.to_datetime([\"2024-01-01\", \"2024-01-02\", \"2024-01-03\", \"2024-01-04\"])\n",
    "    # Prices:\n",
    "    # Jan 1: 100\n",
    "    # Jan 2: 100 (Decision T0)\n",
    "    # Jan 3: 110 (Entry T1 - We buy HERE)\n",
    "    # Jan 4: 121 (Exit - We sell HERE)\n",
    "    prices = [100.0, 100.0, 110.0, 121.0]\n",
    "\n",
    "    df_ohlcv = pd.DataFrame(\n",
    "        {\n",
    "            \"Adj Close\": prices,\n",
    "            \"Adj High\": prices,\n",
    "            \"Adj Low\": prices,\n",
    "            \"Adj Open\": prices,\n",
    "            \"Volume\": [1000] * 4,\n",
    "        },\n",
    "        index=pd.MultiIndex.from_product([[\"MOCK\"], dates], names=[\"Ticker\", \"Date\"]),\n",
    "    )\n",
    "\n",
    "    # 2. Initialize Engine\n",
    "    engine = AlphaEngine(df_ohlcv)\n",
    "\n",
    "    # 3. Run Strategy\n",
    "    # Decision Date = 2024-01-02.\n",
    "    inputs = EngineInput(\n",
    "        mode=\"Manual List\",\n",
    "        start_date=pd.Timestamp(\"2024-01-02\"),\n",
    "        lookback_period=1,\n",
    "        holding_period=1,  # <--- FIXED: Set to 1 to fit the 4-day dataset\n",
    "        metric=\"Price\",\n",
    "        benchmark_ticker=\"MOCK\",\n",
    "        manual_tickers=[\"MOCK\"],\n",
    "    )\n",
    "\n",
    "    res = engine.run(inputs)\n",
    "\n",
    "    # --- SAFETY CHECK ---\n",
    "    if res.error_msg:\n",
    "        print(f\"‚ùå TEST FAILED: Engine returned error: {res.error_msg}\")\n",
    "        return False\n",
    "\n",
    "    # 4. Analyze Results\n",
    "    metrics = res.perf_metrics\n",
    "\n",
    "    print(f\"  Decision Date: {res.decision_date.date()}\")\n",
    "    print(f\"  Buy Date (T+1): {res.buy_date.date()}\")\n",
    "\n",
    "    # Use the NEW metric key\n",
    "    if \"holding_p_gain\" in metrics:\n",
    "        holding_gain = metrics[\"holding_p_gain\"]\n",
    "        print(f\"  Holding Gain: {holding_gain:.4f}\")\n",
    "    else:\n",
    "        print(\"‚ùå 'holding_p_gain' not found in metrics!\")\n",
    "        return False\n",
    "\n",
    "    # Verification Logic\n",
    "    # Buy @ Jan 3 Close (110) -> Sell @ Jan 4 Close (121)\n",
    "    # Math: (121 / 110) - 1 = 1.1 - 1 = 0.10\n",
    "    expected_gain = 0.10\n",
    "\n",
    "    if abs(holding_gain - expected_gain) < 1e-4:\n",
    "        print(f\"‚úÖ LAG VERIFIED: Holding Gain is {holding_gain:.2%}.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"‚ùå LAG FAILURE: Holding Gain is {holding_gain:.2%}.\")\n",
    "        print(f\"   Expected {expected_gain:.2%} (based on 121/110).\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def run_all_tests():\n",
    "    \"\"\"Run all tests\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"STARTING UNIT TESTS\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # Run the math tests\n",
    "    results[\"Math Metrics\"] = test_math_metrics()\n",
    "\n",
    "    # Run the engine logic test (Requires updated Engine code)\n",
    "    try:\n",
    "        results[\"Engine Lag Logic\"] = test_engine_lag_logic()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Engine Logic crashed: {e}\")\n",
    "        results[\"Engine Lag Logic\"] = False\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"TEST SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    passed = sum(results.values())\n",
    "    total = len(results)\n",
    "\n",
    "    for test_name, result in results.items():\n",
    "        status = \"‚úÖ PASS\" if result else \"‚ùå FAIL\"\n",
    "        print(f\"{status}: {test_name}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "    return passed == total\n",
    "\n",
    "\n",
    "# run_all_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b12a184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SECTION H: UNIT TEST FOR GENERATED FEATURES\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "def verify_portfolio_construction(df_close_wide, res_container):\n",
    "    \"\"\"\n",
    "    Independent Auditor:\n",
    "    1. Reads Tickers & Weights from the Engine Output.\n",
    "    2. Re-pulls raw price data from the source.\n",
    "    3. Re-calculates the weighted sum (Portfolio Value).\n",
    "    4. Compares it against the Engine's reported Portfolio Series.\n",
    "    \"\"\"\n",
    "    if not res_container[0]:\n",
    "        print(\"‚ö†Ô∏è No results found. Run simulation first.\")\n",
    "        return\n",
    "\n",
    "    res = res_container[0]\n",
    "\n",
    "    print(f\"--- üèóÔ∏è PORTFOLIO CONSTRUCTION AUDIT ---\")\n",
    "    print(f\"Period: {res.start_date.date()} to {res.holding_end_date.date()}\")\n",
    "    print(f\"Tickers ({len(res.tickers)}): {', '.join(res.tickers)}\")\n",
    "\n",
    "    # 1. RECONSTRUCT WEIGHTS\n",
    "    # We verify that weights sum to 1.0\n",
    "    weights = res.initial_weights\n",
    "    print(f\"\\n1. WEIGHT DISTRIBUTION:\")\n",
    "    print(weights.to_string())\n",
    "    if abs(weights.sum() - 1.0) > 1e-6:\n",
    "        print(f\"‚ö†Ô∏è WARNING: Weights do not sum to 1.0! Sum: {weights.sum()}\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Weights sum to 1.0\")\n",
    "\n",
    "    # 2. RECONSTRUCT RAW DATA\n",
    "    # We pull the exact slice the engine claimed to use\n",
    "    raw_slice = df_close_wide[res.tickers].loc[res.start_date : res.holding_end_date]\n",
    "\n",
    "    # 3. RECONSTRUCT NORMALIZATION (The \"Index\" Logic)\n",
    "    # The engine normalizes everyone to start at 1.0 based on the first valid price\n",
    "    start_prices = raw_slice.bfill().iloc[0]\n",
    "    normalized_prices = raw_slice / start_prices\n",
    "\n",
    "    # 4. APPLY WEIGHTS\n",
    "    # Multiply every column by its weight\n",
    "    weighted_components = normalized_prices.mul(weights)\n",
    "\n",
    "    # 5. CALCULATE SHADOW SERIES\n",
    "    # Sum across the row\n",
    "    shadow_series = weighted_components.sum(axis=1)\n",
    "\n",
    "    # 6. COMPARE VS ENGINE\n",
    "    engine_series = res.portfolio_series\n",
    "\n",
    "    # Align indexes just in case\n",
    "    shadow_series, engine_series = shadow_series.align(engine_series, join=\"inner\")\n",
    "\n",
    "    delta = shadow_series - engine_series\n",
    "    max_error = delta.abs().max()\n",
    "\n",
    "    print(f\"\\n2. SERIES COMPARISON:\")\n",
    "    df_audit = pd.DataFrame(\n",
    "        {\n",
    "            \"Shadow_Calc\": shadow_series,\n",
    "            \"Engine_Output\": engine_series,\n",
    "            \"Difference\": delta,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Show Head (Start of sim)\n",
    "    print(\"\\n--- Start of Simulation (Head) ---\")\n",
    "    print(df_audit.head())\n",
    "\n",
    "    # Show T1 (The Entry Point)\n",
    "    if res.buy_date in df_audit.index:\n",
    "        print(f\"\\n--- Entry Date (T+1: {res.buy_date.date()}) ---\")\n",
    "        print(df_audit.loc[[res.buy_date]])\n",
    "\n",
    "    # Show Tail (End of sim)\n",
    "    print(\"\\n--- End of Simulation (Tail) ---\")\n",
    "    print(df_audit.tail())\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "    if max_error < 1e-9:\n",
    "        print(\n",
    "            f\"‚úÖ SUCCESS: Portfolio Construction Verified (Max Error: {max_error:.12f})\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"‚ùå FAILURE: Series Mismatch (Max Error: {max_error:.12f})\")\n",
    "\n",
    "    return df_audit\n",
    "\n",
    "\n",
    "def verify_ticker_ranking_logic(df_close_wide, features_df, inputs, res_container):\n",
    "    \"\"\"\n",
    "    Shadow Ranker:\n",
    "    1. Re-applies Liquidity Filters on the full universe.\n",
    "    2. Re-calculates the Strategy Metric for ALL eligible stocks.\n",
    "    3. Sorts them independently.\n",
    "    4. Slices the Top N.\n",
    "    5. Compares the \"Shadow List\" against the \"Engine List\".\n",
    "    \"\"\"\n",
    "    if not res_container[0]:\n",
    "        print(\"‚ö†Ô∏è No results found. Run simulation first.\")\n",
    "        return\n",
    "\n",
    "    res = res_container[0]\n",
    "    decision_date = res.decision_date\n",
    "    print(f\"--- üïµÔ∏è TICKER SELECTION AUDIT ---\")\n",
    "    print(f\"Decision Date: {decision_date.date()}\")\n",
    "    print(f\"Strategy:      {inputs.metric}\")\n",
    "    print(f\"Rank Window:   {inputs.rank_start} to {inputs.rank_end}\")\n",
    "\n",
    "    # --- STEP 1: SHADOW FILTERING (Replicating Universe Selection) ---\n",
    "    # We manually inspect the feature dataframe at the decision date\n",
    "    day_feats = features_df.xs(decision_date, level=\"Date\")\n",
    "\n",
    "    # Re-apply thresholds manually\n",
    "    thresh = inputs.quality_thresholds\n",
    "\n",
    "    # Handle dynamic percentile if present\n",
    "    vol_cutoff = thresh.get(\"min_median_dollar_volume\", 0)\n",
    "    if \"min_liquidity_percentile\" in thresh:\n",
    "        dynamic_val = day_feats[\"RollMedDollarVol\"].quantile(\n",
    "            thresh[\"min_liquidity_percentile\"]\n",
    "        )\n",
    "        vol_cutoff = max(vol_cutoff, dynamic_val)\n",
    "\n",
    "    # Boolean Mask\n",
    "    mask = (\n",
    "        (day_feats[\"RollMedDollarVol\"] >= vol_cutoff)\n",
    "        & (day_feats[\"RollingStalePct\"] <= thresh[\"max_stale_pct\"])\n",
    "        & (day_feats[\"RollingSameVolCount\"] <= thresh[\"max_same_vol_count\"])\n",
    "    )\n",
    "\n",
    "    shadow_universe = day_feats[mask].index.tolist()\n",
    "\n",
    "    print(f\"\\n1. UNIVERSE FILTERING:\")\n",
    "    print(f\"   Total Tickers: {len(day_feats)}\")\n",
    "    print(f\"   Eligible:      {len(shadow_universe)}\")\n",
    "\n",
    "    # --- STEP 2: SHADOW SCORING (Re-calculating the Metric) ---\n",
    "    # We need to build the 'ingredients' dictionary for the metric function\n",
    "    # but ONLY for the eligible universe\n",
    "\n",
    "    start_date = res.start_date  # Start of lookback\n",
    "\n",
    "    # Pull Raw Data\n",
    "    lookback_close = df_close_wide.loc[start_date:decision_date, shadow_universe]\n",
    "\n",
    "    # Re-assemble Ingredients (Independent of Engine internals)\n",
    "    # We grab features specifically for the ranking\n",
    "    feat_slice_period = features_df.loc[(slice(None), lookback_close.index), :].reindex(\n",
    "        pd.MultiIndex.from_product(\n",
    "            [shadow_universe, lookback_close.index], names=[\"Ticker\", \"Date\"]\n",
    "        )\n",
    "    )\n",
    "    atrp_mean = feat_slice_period[\"ATRP\"].groupby(level=\"Ticker\").mean()\n",
    "    current_feats = day_feats.loc[shadow_universe]\n",
    "\n",
    "    shadow_ingredients = {\n",
    "        \"lookback_close\": lookback_close,\n",
    "        \"lookback_returns\": lookback_close.ffill().pct_change(),\n",
    "        \"atrp\": atrp_mean,\n",
    "        \"roc_1\": current_feats[\"ROC_1\"],\n",
    "        \"roc_3\": current_feats[\"ROC_3\"],\n",
    "        \"roc_5\": current_feats[\"ROC_5\"],\n",
    "        \"roc_10\": current_feats[\"ROC_10\"],\n",
    "        \"roc_21\": current_feats[\"ROC_21\"],\n",
    "    }\n",
    "\n",
    "    # Calculate Score\n",
    "    if inputs.metric not in METRIC_REGISTRY:\n",
    "        print(f\"‚ùå Cannot verify unknown metric: {inputs.metric}\")\n",
    "        return\n",
    "\n",
    "    shadow_scores = METRIC_REGISTRY[inputs.metric](shadow_ingredients)\n",
    "    shadow_scores = shadow_scores.sort_values(ascending=False)\n",
    "\n",
    "    # --- STEP 3: SHADOW RANKING ---\n",
    "    # Apply the Rank Window (e.g., 1 to 10)\n",
    "    # Python index is 0-based, so Rank 1 is index 0.\n",
    "    start_idx = max(0, inputs.rank_start - 1)\n",
    "    end_idx = inputs.rank_end\n",
    "\n",
    "    shadow_picks = shadow_scores.iloc[start_idx:end_idx]\n",
    "    shadow_tickers = shadow_picks.index.tolist()\n",
    "\n",
    "    # --- STEP 4: COMPARISON ---\n",
    "    engine_tickers = res.tickers\n",
    "\n",
    "    print(f\"\\n2. SELECTION COMPARISON:\")\n",
    "\n",
    "    match = shadow_tickers == engine_tickers\n",
    "\n",
    "    comparison_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Rank\": range(inputs.rank_start, inputs.rank_start + len(shadow_tickers)),\n",
    "            \"Shadow_Ticker\": shadow_tickers,\n",
    "            \"Shadow_Score\": shadow_picks.values,\n",
    "            \"Engine_Ticker\": (\n",
    "                engine_tickers + [\"\"] * (len(shadow_tickers) - len(engine_tickers))\n",
    "                if len(shadow_tickers) > len(engine_tickers)\n",
    "                else engine_tickers[: len(shadow_tickers)]\n",
    "            ),\n",
    "        }\n",
    "    ).set_index(\"Rank\")\n",
    "\n",
    "    # Check for mismatches\n",
    "    comparison_df[\"MATCH\"] = (\n",
    "        comparison_df[\"Shadow_Ticker\"] == comparison_df[\"Engine_Ticker\"]\n",
    "    )\n",
    "\n",
    "    print(comparison_df)\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    if match:\n",
    "        print(\"‚úÖ SUCCESS: Ticker Selection Logic Verified (Exact Match).\")\n",
    "    else:\n",
    "        print(\"‚ùå FAILURE: Ticker Mismatch detected.\")\n",
    "        # Debugging hint\n",
    "        if len(shadow_tickers) != len(engine_tickers):\n",
    "            print(\n",
    "                f\"   Count Mismatch: Shadow {len(shadow_tickers)} vs Engine {len(engine_tickers)}\"\n",
    "            )\n",
    "        else:\n",
    "            print(\"   Order or Identity Mismatch. Check Strategy Logic.\")\n",
    "\n",
    "\n",
    "def verify_engine_integrity(res_container, debug_container):\n",
    "    \"\"\"\n",
    "    Loops through reported metrics and recalculates them using the\n",
    "    raw verification series stored in debug_container.\n",
    "    \"\"\"\n",
    "    if not res_container[0] or not debug_container[0]:\n",
    "        print(\"‚ö†Ô∏è No results found. Run the simulation first.\")\n",
    "        return\n",
    "\n",
    "    metrics = res_container[0].perf_metrics\n",
    "    verification_data = debug_container[0][\"verification\"]\n",
    "\n",
    "    print(\n",
    "        f\"{'METRIC':<30} | {'REPORTED':<12} | {'CALCULATED':<12} | {'DIFF':<12} | {'STATUS'}\"\n",
    "    )\n",
    "    print(\"-\" * 85)\n",
    "\n",
    "    # 1. Map prefixes to the keys in the verification dictionary\n",
    "    targets = [(\"p\", \"portfolio\"), (\"b\", \"benchmark\")]\n",
    "\n",
    "    # 2. Define the periods we explicitly saved in v2.2\n",
    "    # (Note: v2.2 saved Lookback and Holding. Full is implied but not explicitly saved in slices)\n",
    "    periods = [\"lookback\", \"holding\"]\n",
    "\n",
    "    for prefix, target_key in targets:\n",
    "        slices = verification_data[target_key]\n",
    "\n",
    "        for period in periods:\n",
    "            # --- A. VERIFY GAIN ---\n",
    "            metric_name = f\"{period}_{prefix}_gain\"\n",
    "            val_key = f\"{period}_val\"\n",
    "\n",
    "            if val_key in slices and not slices[val_key].empty:\n",
    "                s = slices[val_key]\n",
    "                # Gain Formula: (End / Start) - 1\n",
    "                calc_gain = (s.iloc[-1] / s.iloc[0]) - 1\n",
    "                reported_gain = metrics.get(metric_name, 0.0)\n",
    "\n",
    "                diff = abs(calc_gain - reported_gain)\n",
    "                status = \"‚úÖ PASS\" if diff < 1e-8 else \"‚ùå FAIL\"\n",
    "                print(\n",
    "                    f\"{metric_name:<30} | {reported_gain:12.6f} | {calc_gain:12.6f} | {diff:12.9f} | {status}\"\n",
    "                )\n",
    "\n",
    "            # --- B. VERIFY SHARPE ---\n",
    "            metric_name = f\"{period}_{prefix}_sharpe\"\n",
    "            ret_key = f\"{period}_ret\"\n",
    "\n",
    "            if ret_key in slices and not slices[ret_key].empty:\n",
    "                s = slices[ret_key]\n",
    "                # Sharpe Formula: (Mean / Std) * sqrt(252)\n",
    "                # Note: Pandas std() uses ddof=1 by default, which is correct\n",
    "                if s.std() > 0:\n",
    "                    calc_sharpe = (s.mean() / s.std()) * np.sqrt(252)\n",
    "                else:\n",
    "                    calc_sharpe = 0.0\n",
    "\n",
    "                reported_sharpe = metrics.get(metric_name, 0.0)\n",
    "\n",
    "                diff = abs(calc_sharpe - reported_sharpe)\n",
    "                status = \"‚úÖ PASS\" if diff < 1e-8 else \"‚ùå FAIL\"\n",
    "                print(\n",
    "                    f\"{metric_name:<30} | {reported_sharpe:12.6f} | {calc_sharpe:12.6f} | {diff:12.9f} | {status}\"\n",
    "                )\n",
    "\n",
    "            # --- C. VERIFY SHARPE (ATR) ---\n",
    "            metric_name = f\"{period}_{prefix}_sharpe_atr\"\n",
    "            atrp_key = f\"{period}_atrp\"\n",
    "\n",
    "            # Only verify if we saved the ATRP slice (v2.2 saves holding_atrp)\n",
    "            if ret_key in slices and atrp_key in slices:\n",
    "                s_ret = slices[ret_key]\n",
    "                s_atrp = slices[atrp_key]\n",
    "\n",
    "                if not s_ret.empty and not s_atrp.empty:\n",
    "                    # Sharpe ATR Formula: Mean(Returns) / Mean(ATRP)\n",
    "                    mean_atrp = s_atrp.mean()\n",
    "                    if mean_atrp > 0:\n",
    "                        calc_sharpe_atr = s_ret.mean() / mean_atrp\n",
    "                    else:\n",
    "                        calc_sharpe_atr = 0.0\n",
    "\n",
    "                    reported_satr = metrics.get(metric_name, 0.0)\n",
    "\n",
    "                    diff = abs(calc_sharpe_atr - reported_satr)\n",
    "                    status = \"‚úÖ PASS\" if diff < 1e-8 else \"‚ùå FAIL\"\n",
    "                    print(\n",
    "                        f\"{metric_name:<30} | {reported_satr:12.6f} | {calc_sharpe_atr:12.6f} | {diff:12.9f} | {status}\"\n",
    "                    )\n",
    "\n",
    "\n",
    "def run_full_system_audit(df_close_wide, features_df, res_container, deb_container):\n",
    "    \"\"\"\n",
    "    Automated wrapper that executes the 3 Audit Functions on the latest simulation.\n",
    "    It attempts to detect '‚ùå' in the output to determine Pass/Fail status\n",
    "    without needing to rewrite the void functions.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üöÄ STARTING FULL SYSTEM AUDIT\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # 0. Pre-Flight Checks\n",
    "    if not res_container[0] or not deb_container[0]:\n",
    "        print(\"‚ùå ABORT: No simulation results found. Run the visualizer first.\")\n",
    "        return False\n",
    "\n",
    "    inputs = deb_container[0].get(\"inputs\")\n",
    "    if not inputs:\n",
    "        print(\n",
    "            \"‚ùå ABORT: 'inputs' not found in debug_container. Update plot_walk_forward_analyzer to v2.3+.\"\n",
    "        )\n",
    "        return False\n",
    "\n",
    "    summary = {}\n",
    "\n",
    "    # Helper to run a test and capture output to check for failure symbols\n",
    "    def run_auditor(name, func, *args):\n",
    "        print(f\"\\n>>> Running {name}...\")\n",
    "        try:\n",
    "            # We assume the auditor prints to stdout.\n",
    "            # If it prints a '‚ùå', we consider it a logical failure.\n",
    "            # If it throws an exception, it's a code failure.\n",
    "\n",
    "            # (Optional: Capture stdout if you wanted to suppress printing,\n",
    "            # but seeing the details is better for audits. We just track execution here.)\n",
    "            func(*args)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå CRITICAL ERROR in {name}: {e}\")\n",
    "            import traceback\n",
    "\n",
    "            traceback.print_exc()\n",
    "            return False\n",
    "\n",
    "    # --- 1. Verify Engine Integrity (Math Check) ---\n",
    "    summary[\"Math Integrity\"] = run_auditor(\n",
    "        \"Engine Integrity Check\", verify_engine_integrity, res_container, deb_container\n",
    "    )\n",
    "\n",
    "    # --- 2. Verify Portfolio Construction (Assembly Check) ---\n",
    "    summary[\"Portfolio Construction\"] = run_auditor(\n",
    "        \"Portfolio Construction Auditor\",\n",
    "        verify_portfolio_construction,\n",
    "        df_close_wide,\n",
    "        res_container,\n",
    "    )\n",
    "\n",
    "    # --- 3. Verify Ticker Ranking (Selection Check) ---\n",
    "    summary[\"Ranking Logic\"] = run_auditor(\n",
    "        \"Ticker Ranking Logic Auditor\",\n",
    "        verify_ticker_ranking_logic,\n",
    "        df_close_wide,\n",
    "        features_df,\n",
    "        inputs,\n",
    "        res_container,\n",
    "    )\n",
    "\n",
    "    # --- SUMMARY REPORT ---\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"{'AUDIT MODULE':<40} | {'STATUS'}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    all_passed = True\n",
    "    for name, executed in summary.items():\n",
    "        # Note: This checks if the function RAN successfully.\n",
    "        # You still need to visually check the printed table for '‚úÖ' vs '‚ùå'\n",
    "        status = \"‚úÖ EXECUTED\" if executed else \"‚ùå CRASHED\"\n",
    "        print(f\"{name:<40} | {status}\")\n",
    "        if not executed:\n",
    "            all_passed = False\n",
    "\n",
    "    print(\"-\" * 80)\n",
    "    if all_passed:\n",
    "        print(\n",
    "            \"‚ÑπÔ∏è  NOTE: Check individual module outputs above for specific math failures.\"\n",
    "        )\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "232740e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 9459773 entries, ('A', Timestamp('1999-11-18 00:00:00')) to ('ZWS', Timestamp('2025-12-19 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   Adj Open   float64\n",
      " 1   Adj High   float64\n",
      " 2   Adj Low    float64\n",
      " 3   Adj Close  float64\n",
      " 4   Volume     int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 397.6+ MB\n",
      "df_ohlcv.info():\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Adj Open</th>\n",
       "      <th>Adj High</th>\n",
       "      <th>Adj Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">A</th>\n",
       "      <th>1999-11-18</th>\n",
       "      <td>27.2452</td>\n",
       "      <td>29.9398</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>26.3470</td>\n",
       "      <td>74716411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-19</th>\n",
       "      <td>25.7108</td>\n",
       "      <td>25.7482</td>\n",
       "      <td>23.8396</td>\n",
       "      <td>24.1764</td>\n",
       "      <td>18198349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-22</th>\n",
       "      <td>24.7378</td>\n",
       "      <td>26.3470</td>\n",
       "      <td>23.9893</td>\n",
       "      <td>26.3470</td>\n",
       "      <td>7857766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-23</th>\n",
       "      <td>25.4488</td>\n",
       "      <td>26.1225</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>7138324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-24</th>\n",
       "      <td>24.0267</td>\n",
       "      <td>25.1120</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>24.5881</td>\n",
       "      <td>5785609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ZWS</th>\n",
       "      <th>2025-12-15</th>\n",
       "      <td>47.4700</td>\n",
       "      <td>47.5700</td>\n",
       "      <td>47.0100</td>\n",
       "      <td>47.4200</td>\n",
       "      <td>1065100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-16</th>\n",
       "      <td>47.6800</td>\n",
       "      <td>47.6800</td>\n",
       "      <td>46.8700</td>\n",
       "      <td>47.1600</td>\n",
       "      <td>862500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-17</th>\n",
       "      <td>47.0100</td>\n",
       "      <td>47.6800</td>\n",
       "      <td>46.3500</td>\n",
       "      <td>46.6400</td>\n",
       "      <td>1070400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-18</th>\n",
       "      <td>47.1900</td>\n",
       "      <td>47.7100</td>\n",
       "      <td>46.9800</td>\n",
       "      <td>47.3600</td>\n",
       "      <td>1119300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-19</th>\n",
       "      <td>47.0500</td>\n",
       "      <td>47.6600</td>\n",
       "      <td>47.0500</td>\n",
       "      <td>47.5000</td>\n",
       "      <td>2019500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9459773 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Adj Open  Adj High  Adj Low  Adj Close    Volume\n",
       "Ticker Date                                                        \n",
       "A      1999-11-18   27.2452   29.9398  23.9518    26.3470  74716411\n",
       "       1999-11-19   25.7108   25.7482  23.8396    24.1764  18198349\n",
       "       1999-11-22   24.7378   26.3470  23.9893    26.3470   7857766\n",
       "       1999-11-23   25.4488   26.1225  23.9518    23.9518   7138324\n",
       "       1999-11-24   24.0267   25.1120  23.9518    24.5881   5785609\n",
       "...                     ...       ...      ...        ...       ...\n",
       "ZWS    2025-12-15   47.4700   47.5700  47.0100    47.4200   1065100\n",
       "       2025-12-16   47.6800   47.6800  46.8700    47.1600    862500\n",
       "       2025-12-17   47.0100   47.6800  46.3500    46.6400   1070400\n",
       "       2025-12-18   47.1900   47.7100  46.9800    47.3600   1119300\n",
       "       2025-12-19   47.0500   47.6600  47.0500    47.5000   2019500\n",
       "\n",
       "[9459773 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = (\n",
    "    r\"c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet\"\n",
    ")\n",
    "df_ohlcv = pd.read_parquet(data_path, engine=\"pyarrow\")\n",
    "print(f\"df_ohlcv.info():\\n{df_ohlcv.info()}\")\n",
    "df_ohlcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "957c5c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating features... this might take few minutes...\n",
      "1. Calculating Features...\n",
      "2. Pivoting Price Matrix...\n",
      "‚úÖ Optimization Complete. Ready for UI.\n"
     ]
    }
   ],
   "source": [
    "# Calculate features ONCE and store them in a variable\n",
    "print(\"Calculating features... this might take few minutes...\")\n",
    "print(\"1. Calculating Features...\")\n",
    "my_features = generate_features(\n",
    "    df_ohlcv=df_ohlcv, atr_period=14, quality_window=252, quality_min_periods=126\n",
    ")\n",
    "\n",
    "print(\"2. Pivoting Price Matrix...\")\n",
    "# This is the line that takes 12 seconds, but now we only run it ONCE.\n",
    "my_close_matrix = df_ohlcv[\"Adj Close\"].unstack(level=0)\n",
    "\n",
    "print(\"‚úÖ Optimization Complete. Ready for UI.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaa8a33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_features:\n",
      "                      ATR    ATRP   ROC_1   ROC_3   ROC_5  ROC_10  ROC_21  RollingStalePct  RollMedDollarVol  RollingSameVolCount\n",
      "Ticker Date                                                                                                                      \n",
      "A      1999-11-18     NaN     NaN     NaN     NaN     NaN     NaN     NaN              NaN               NaN                  NaN\n",
      "       1999-11-19  2.5074  0.1037 -0.0824     NaN     NaN     NaN     NaN              NaN               NaN                  NaN\n",
      "       1999-11-22  2.4967  0.0948  0.0898     NaN     NaN     NaN     NaN              NaN               NaN                  NaN\n",
      "       1999-11-23  2.4895  0.1039 -0.0909 -0.0909     NaN     NaN     NaN              NaN               NaN                  NaN\n",
      "       1999-11-24  2.3945  0.0974  0.0266  0.0170     NaN     NaN     NaN              NaN               NaN                  NaN\n",
      "...                   ...     ...     ...     ...     ...     ...     ...              ...               ...                  ...\n",
      "ZWS    2025-12-15  1.0519  0.0222  0.0059  0.0120  0.0224 -0.0067  0.0247              0.0        3.2634e+07                  0.0\n",
      "       2025-12-16  1.0346  0.0219 -0.0055 -0.0090  0.0268 -0.0138  0.0259              0.0        3.2634e+07                  0.0\n",
      "       2025-12-17  1.0557  0.0226 -0.0110 -0.0106 -0.0047 -0.0171  0.0424              0.0        3.2650e+07                  0.0\n",
      "       2025-12-18  1.0568  0.0223  0.0154 -0.0013 -0.0048  0.0094  0.0527              0.0        3.2650e+07                  0.0\n",
      "       2025-12-19  1.0248  0.0216  0.0030  0.0072  0.0076  0.0137  0.0476              0.0        3.2650e+07                  0.0\n",
      "\n",
      "[9459773 rows x 10 columns]\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 9459773 entries, ('A', Timestamp('1999-11-18 00:00:00')) to ('ZWS', Timestamp('2025-12-19 00:00:00'))\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Dtype  \n",
      "---  ------               -----  \n",
      " 0   ATR                  float64\n",
      " 1   ATRP                 float64\n",
      " 2   ROC_1                float64\n",
      " 3   ROC_3                float64\n",
      " 4   ROC_5                float64\n",
      " 5   ROC_10               float64\n",
      " 6   ROC_21               float64\n",
      " 7   RollingStalePct      float64\n",
      " 8   RollMedDollarVol     float64\n",
      " 9   RollingSameVolCount  float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 758.5+ MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"my_features:\\n{my_features}\\n\")\n",
    "my_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "96d82578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ‚öôÔ∏è Initializing AlphaEngine v2.2 (Sanitized) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c8e8a1b52445abbb133dc27625b471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>1. Timeline Configuration:</b> (Past <--- Decision ---> Future)'), HBox(children‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68713cfa8470488ebc99625492a2330c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'width': 2},\n",
       "              'name': 'SNX',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd3116de8-fbb8-4d4c-9f93-1c9b7956a78e',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 1, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 6, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 7, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 23, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 24, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 28, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.01245041, 1.01562609, 1.05794529, 1.04824424, 1.15050115,\n",
       "                          1.14045208, 1.16792824, 1.16981625, 1.17762929, 1.17702896, 1.20853344,\n",
       "                          1.2147978 , 1.22931022, 1.2271525 , 1.21587666, 1.22104476])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'QRVO',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c212b53f-7fbc-419b-8a13-0d5454bac29a',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 1, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 6, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 7, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 23, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 24, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 28, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.01247133, 1.03411697, 1.05547592, 1.04759174, 1.02766628,\n",
       "                          1.03081995, 1.04386468, 1.06307339, 1.05490252, 1.20713876, 1.25544725,\n",
       "                          1.24842317, 1.29830849, 1.27494266, 1.25616399, 1.2296445 ])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'TRGP',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e611a267-9bc9-44ad-b139-cc999c24f022',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 1, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 6, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 7, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 23, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 24, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 28, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.01699117, 1.01693534, 1.02600325, 1.04872887, 1.055943  ,\n",
       "                          1.07871888, 1.10008208, 1.12258436, 1.16328388, 1.17841568, 1.18660696,\n",
       "                          1.15410429, 1.15476317, 1.14208819, 1.08838983, 1.10548709])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'MINT',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e2b239f5-6d7a-402d-91b0-517c6b358e33',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 1, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 6, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 7, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 23, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 24, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 28, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00049935, 1.00069805, 1.00059818, 1.00099766, 1.00109753,\n",
       "                          1.00129623, 1.00149597, 1.00179454, 1.00209415, 1.00259246, 1.00259246,\n",
       "                          1.00279115, 1.00299089, 1.0034892 , 1.0034892 , 1.0034892 ])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'SHV',\n",
       "              'type': 'scatter',\n",
       "              'uid': '293ba060-8ccb-4613-a301-d790183cb39c',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 1, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 6, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 7, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 23, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 24, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 28, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00027431, 1.00045403, 1.00063374, 1.00063374, 1.00090805,\n",
       "                          1.00108777, 1.00118236, 1.00136208, 1.00145666, 1.00191069, 1.00209041,\n",
       "                          1.00209041, 1.00227013, 1.00263902, 1.00281874, 1.00290387])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'RPRX',\n",
       "              'type': 'scatter',\n",
       "              'uid': '09d289f6-a700-4fe8-a2af-75ba4ed2d018',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 1, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 6, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 7, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 23, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 24, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 28, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00193989, 0.99844968, 1.00969546, 1.01589674, 1.14346818,\n",
       "                          1.16285513, 1.16440545, 1.19193754, 1.20007871, 1.19232313, 1.17487607,\n",
       "                          1.16634534, 1.18728261, 1.20434408, 1.22993628, 1.23846701])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'BIL',\n",
       "              'type': 'scatter',\n",
       "              'uid': '0a0ce8e5-274c-4069-9755-51644b9837fd',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 1, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 6, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 7, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 23, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 24, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 28, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00010939, 1.00021878, 1.00043642, 1.00065519, 1.00098336,\n",
       "                          1.00109275, 1.00131152, 1.00142091, 1.00142091, 1.00196786, 1.00196786,\n",
       "                          1.00218663, 1.00218663, 1.00262419, 1.00273358, 1.00273358])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'SGOV',\n",
       "              'type': 'scatter',\n",
       "              'uid': '43ca939c-fd29-419d-9cc9-1d75e1c5d429',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 1, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 6, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 7, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 23, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 24, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 28, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00029902, 1.00029902, 1.00049836, 1.00069771, 1.0010964 ,\n",
       "                          1.00129575, 1.00139542, 1.00149509, 1.00149509, 1.00199346, 1.00209313,\n",
       "                          1.00229248, 1.00239215, 1.00269117, 1.00269117, 1.00299019])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'LNG',\n",
       "              'type': 'scatter',\n",
       "              'uid': '3b3f1305-e32f-48d9-9881-24ff51ede8da',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 1, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 6, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 7, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 23, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 24, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 28, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.0085232 , 1.01500595, 1.01319425, 1.02080703, 1.02094428,\n",
       "                          1.04007228, 1.10194894, 1.11459877, 1.14986733, 1.14578644, 1.13159484,\n",
       "                          1.05784152, 1.06205966, 1.0510431 , 1.01749931, 1.02661268])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'USFR',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ef199438-4165-470d-a6d6-89b7b575bd08',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 1, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 6, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 7, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 23, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 24, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 28, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00019819, 1.00039638, 1.00059663, 1.00079482, 1.00139145,\n",
       "                          1.00158964, 1.00198602, 1.00198602, 1.00198602, 1.00238446, 1.00258265,\n",
       "                          1.00238446, 1.00258265, 1.00298109, 1.00317928, 1.00341875])},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '93a7c75b-c074-427f-8a63-12d8bc25ba46', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '6524c7e4-b445-4807-a472-47db2771f414', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '60955427-1587-4d86-909c-fd77d67b1f8e', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'c23f8e8a-a09f-4b2c-9726-e1c856bd947d', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'b7297f54-4643-40b5-b9d0-41239245b1d7', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '037a6512-9c02-4fd7-9a55-b43ca5ba24e5', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'a59bd430-1565-48d4-bf8c-b9c0469aa144', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '30d11ea9-69e2-4afd-ad0a-c0219991d32c', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '8980a5d3-8d1f-4b5d-9cc2-a3bad55e397d', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '49944842-db7d-4fc0-b428-517fd8e28edc', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '0821a2f7-3693-42ad-8b95-8972fe5937c4', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '2a1dccb4-3c9d-4cb6-a2ae-8bf4789c1c35', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'af55b90a-97fa-4b88-94a4-a67fe526da82', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'd981a2b9-ffc6-4ad9-8d53-0165ae20b81a', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '7e78c834-88ab-4a36-b7fe-30b1037b44aa', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'a8699975-c113-4b97-bfff-b8677fd6b5ea', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '718ff389-c2ea-47e7-b207-e88c50221e10', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'd996db44-46c2-45b1-bb48-2c9ba4e075c7', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '1098014b-04d6-4075-b26c-56afd4398f6d', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '7488a998-1500-4023-bcca-338604534af2', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'e3aa9b3e-9916-45aa-8d96-7600f2768c99', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '54fd42ba-c146-4321-9d7a-93f9879cd64f', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '78af51de-de84-461d-bc94-777db16ea55c', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '7d2b3834-802d-4508-b42a-eb27eda0ad6e', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'c2c6e54f-e8f6-4b21-a472-6e39c5fbbf67', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'e7af65df-f0bd-4202-9042-11f09232950c', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'd0cf7492-b7cf-4f7b-b79c-cebd0c8e7926', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '4d4ed282-68ef-4019-b9d0-d6ebee44abf4', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'ca190f6d-d87b-4978-959f-8e7d86145ce3', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'f57466b9-9d84-4658-a616-df04fdb8ce7f', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '1c03df61-1db5-4797-99f4-aaa128ff910e', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '3bb3d3b8-a6ed-4a45-8ab2-437b15e799ec', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '213fe9e0-5099-4561-92aa-0d3c4ec01215', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'a51e02d2-c9eb-47d3-9527-1e3f14e63d35', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '03cffeeb-e38b-49c7-a96e-705fe76aa8c6', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'e130b741-abf6-42f9-93b5-2308338ec37b', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '13c6dc67-52ae-4233-b9bd-473e9a66f16a', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'f1dc1b05-efba-4c11-b83b-ee51f01d3107', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '31adf54f-494e-47f8-bfe0-9fa161e15b0c', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '11e71a35-ec1b-4166-94c5-f67780d8def1', 'visible': False},\n",
       "             {'line': {'color': 'black', 'dash': 'dash', 'width': 3},\n",
       "              'name': 'Benchmark (SPY)',\n",
       "              'type': 'scatter',\n",
       "              'uid': '641cf9e1-50b6-4734-b262-4ff2227c762e',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 1, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 6, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 7, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 23, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 24, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 28, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.01250316, 1.01833681, 1.00682525, 1.00829621, 0.99290132,\n",
       "                          0.9944415 , 0.99581036, 1.01392393, 1.01197361, 1.02213362, 1.03148892,\n",
       "                          1.03728797, 1.0429503 , 1.03990454, 1.02519495, 1.0340034 ])},\n",
       "             {'line': {'color': 'green', 'width': 3},\n",
       "              'name': 'Group Portfolio',\n",
       "              'type': 'scatter',\n",
       "              'uid': '9486e8f9-43d3-4932-a37e-b57f70972c33',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 1, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 6, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 7, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 23, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 24, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 28, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00537562, 1.00822003, 1.01650775, 1.01850477, 1.04039997,\n",
       "                          1.04592805, 1.05856007, 1.06700689, 1.07542146, 1.09115419, 1.09683851,\n",
       "                          1.08532573, 1.09441466, 1.09139952, 1.0822778 , 1.08367916])}],\n",
       "    'layout': {'annotations': [{'bgcolor': 'red',\n",
       "                                'font': {'color': 'white'},\n",
       "                                'showarrow': False,\n",
       "                                'text': 'DECISION',\n",
       "                                'x': Timestamp('2025-01-17 00:00:00'),\n",
       "                                'xref': 'x',\n",
       "                                'y': 0.05,\n",
       "                                'yref': 'paper'},\n",
       "                               {'bgcolor': 'blue',\n",
       "                                'font': {'color': 'white'},\n",
       "                                'showarrow': False,\n",
       "                                'text': 'ENTRY (T+1)',\n",
       "                                'x': Timestamp('2025-01-21 00:00:00'),\n",
       "                                'xref': 'x',\n",
       "                                'y': 1.0,\n",
       "                                'yref': 'paper'}],\n",
       "               'height': 600,\n",
       "               'hovermode': 'x unified',\n",
       "               'shapes': [{'line': {'color': 'red', 'dash': 'dash', 'width': 2},\n",
       "                           'type': 'line',\n",
       "                           'x0': Timestamp('2025-01-17 00:00:00'),\n",
       "                           'x1': Timestamp('2025-01-17 00:00:00'),\n",
       "                           'xref': 'x',\n",
       "                           'y0': 0,\n",
       "                           'y1': 1,\n",
       "                           'yref': 'paper'},\n",
       "                          {'line': {'color': 'blue', 'dash': 'dot', 'width': 2},\n",
       "                           'type': 'line',\n",
       "                           'x0': Timestamp('2025-01-21 00:00:00'),\n",
       "                           'x1': Timestamp('2025-01-21 00:00:00'),\n",
       "                           'xref': 'x',\n",
       "                           'y0': 0,\n",
       "                           'y1': 1,\n",
       "                           'yref': 'paper'}],\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Event-Driven Walk-Forward Analysis'}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_container, debug_container = plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    precomputed_features=my_features,  \n",
    "    precomputed_close=my_close_matrix, \n",
    "    default_start_date=\"2025-01-17\",\n",
    "    default_lookback=10,\n",
    "    default_holding=5,\n",
    "    default_strategy=\"Sharpe (ATR)\",\n",
    "    default_rank_start=1,\n",
    "    default_rank_end=10,\n",
    "    default_benchmark_ticker=GLOBAL_SETTINGS[\"benchmark_ticker\"],\n",
    "    master_calendar_ticker=GLOBAL_SETTINGS[\"calendar_ticker\"],\n",
    "    quality_thresholds=GLOBAL_SETTINGS[\"thresholds\"],\n",
    "    debug=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6ab55888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Exporting audit data to: ./Audit_bot_v46_2025-01-17_SharpeATR/\n",
      "   ‚úÖ Saved Metadata:  inputs_Metadata.csv\n",
      "   ‚úÖ Saved DataFrame: audit_liquidity_universe_snapshot.csv\n",
      "   ‚úÖ Saved DataFrame: full_universe_ranking.csv\n",
      "   ‚úÖ Saved Series:    verification_portfolio_full_val.csv\n",
      "   ‚úÖ Saved Series:    verification_portfolio_full_ret.csv\n",
      "   ‚úÖ Saved Series:    verification_portfolio_full_atrp.csv\n",
      "   ‚úÖ Saved Series:    verification_portfolio_lookback_val.csv\n",
      "   ‚úÖ Saved Series:    verification_portfolio_lookback_ret.csv\n",
      "   ‚úÖ Saved Series:    verification_portfolio_lookback_atrp.csv\n",
      "   ‚úÖ Saved Series:    verification_portfolio_holding_val.csv\n",
      "   ‚úÖ Saved Series:    verification_portfolio_holding_ret.csv\n",
      "   ‚úÖ Saved Series:    verification_portfolio_holding_atrp.csv\n",
      "   ‚úÖ Saved Series:    verification_benchmark_full_val.csv\n",
      "   ‚úÖ Saved Series:    verification_benchmark_full_ret.csv\n",
      "   ‚úÖ Saved Series:    verification_benchmark_full_atrp.csv\n",
      "   ‚úÖ Saved Series:    verification_benchmark_lookback_val.csv\n",
      "   ‚úÖ Saved Series:    verification_benchmark_lookback_ret.csv\n",
      "   ‚úÖ Saved Series:    verification_benchmark_lookback_atrp.csv\n",
      "   ‚úÖ Saved Series:    verification_benchmark_holding_val.csv\n",
      "   ‚úÖ Saved Series:    verification_benchmark_holding_ret.csv\n",
      "   ‚úÖ Saved Series:    verification_benchmark_holding_atrp.csv\n",
      "   ‚úÖ Saved DataFrame: portfolio_raw_components_prices.csv\n",
      "   ‚úÖ Saved DataFrame: portfolio_raw_components_atrp.csv\n",
      "   ‚úÖ Saved DataFrame: benchmark_raw_components_prices.csv\n",
      "   ‚úÖ Saved DataFrame: benchmark_raw_components_atrp.csv\n",
      "\n",
      "‚ú® Export Complete. All numbers saved with 8 decimal places.\n"
     ]
    }
   ],
   "source": [
    "export_debug_to_csv(debug_container, source_label=\"bot_v46\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed26de38",
   "metadata": {},
   "source": [
    "### Why this is a \"Pure\" Audit:\n",
    "\n",
    "1.  **Manual Portfolio Re-construction:** It doesn't trust the engine's `portfolio_series`. It loads the raw `prices` for RPRX and SGOV and manually normalizes them and sums them with `init_w = 0.5`. If the weights in the engine were wrong, this script would catch it.\n",
    "2.  **Standard Pandas Logic:** It uses `.pct_change()`, `.mean()`, and `.std()` directly. This proves that the results in your image aren't \"magic numbers\" from a proprietary formula‚Äîthey are standard financial stats.\n",
    "3.  **Cross-Check on Sharpe (ATR):** It implements the `Sharpe (ATR)` logic using the exact rule we discussed: the numerator is the mean of returns (skipping the first NaN), and the denominator is the mean of all ATRP observations (including the first day).\n",
    "4.  **Independent Period Slicing:** It uses the `Metadata.csv` to determine the boundaries for Full, Lookback, and Holding periods, ensuring it is testing the exact same windows as the UI.\n",
    "\n",
    "### How to use:\n",
    "1.  Save this script as `auditor.py` in the same directory where your Audit folder is located.\n",
    "2.  Run it using `python auditor.py`.\n",
    "3.  Compare the terminal output table to your screenshot image. They should match to the 4th decimal place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac74e23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç STARTING PURE INDEPENDENT AUDIT\n",
      "-----------------------------------------------------------------\n",
      "Metric                    |       Full |   Lookback |    Holding\n",
      "-----------------------------------------------------------------\n",
      "Group Gain                |     0.0340 |     0.0221 |     0.0024 | \n",
      "Bench Gain                |     0.0340 |     0.0221 |     0.0024 | \n",
      "-----------------------------------------------------------------\n",
      "Group Sharpe              |     3.5752 |     3.4735 |     0.8946 | \n",
      "Bench Sharpe              |     3.5752 |     3.4735 |     0.8946 | \n",
      "-----------------------------------------------------------------\n",
      "Group Sharpe (ATR)        |     0.1746 |     0.1789 |     0.0446 | \n",
      "Bench Sharpe (ATR)        |     0.1746 |     0.1789 |     0.0446 | \n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# ==============================================================================\n",
    "# AUDIT CONFIGURATION\n",
    "# ==============================================================================\n",
    "FOLDER_PATH = \"Audit_bot_v46_2025-01-17_SharpeATR\"\n",
    "ANNUALIZATION_FACTOR = 252\n",
    "\n",
    "\n",
    "def find_file(keyword):\n",
    "    pattern = os.path.join(FOLDER_PATH, f\"*{keyword}*.csv\")\n",
    "    files = glob.glob(pattern)\n",
    "    if files:\n",
    "        return files[0]\n",
    "    raise FileNotFoundError(f\"‚ùå Missing file: {keyword}\")\n",
    "\n",
    "\n",
    "def run_pure_audit():\n",
    "    print(f\"üîç STARTING PURE INDEPENDENT AUDIT\")\n",
    "    print(\"-\" * 65)\n",
    "\n",
    "    # 1. LOAD ATOMIC DATA (Prices and ATRP for individual tickers)\n",
    "    raw_prices = pd.read_csv(\n",
    "        find_file(\"raw_components_prices\"), index_col=0, parse_dates=True\n",
    "    ).sort_index()\n",
    "    raw_atrp = pd.read_csv(\n",
    "        find_file(\"raw_components_atrp\"), index_col=0, parse_dates=True\n",
    "    ).sort_index()\n",
    "    b_val = pd.read_csv(\n",
    "        find_file(\"verification_benchmark_full_val\"), index_col=0, parse_dates=True\n",
    "    ).iloc[:, 0]\n",
    "    b_atrp_raw = pd.read_csv(\n",
    "        find_file(\"benchmark_raw_components_atrp\"), index_col=0, parse_dates=True\n",
    "    ).iloc[:, 0]\n",
    "    meta = pd.read_csv(find_file(\"Metadata\"), index_col=0)\n",
    "\n",
    "    # 2. DEFINE TIMELINE\n",
    "    decision_dt = pd.to_datetime(meta.loc[\"start_date\", \"Value\"])\n",
    "    all_dates = raw_prices.index.sort_values()\n",
    "    start_dt, end_dt = all_dates[0], all_dates[-1]\n",
    "    buy_dt = all_dates[all_dates > decision_dt][0]\n",
    "\n",
    "    # 3. MANUALLY RECONSTRUCT GROUP PORTFOLIO (Equal Weights @ Start)\n",
    "    # This audits the engine's weight-drift logic\n",
    "    init_w = 1.0 / raw_prices.shape[1]\n",
    "    norm_prices = raw_prices.div(raw_prices.bfill().iloc[0])\n",
    "    val_contrib = norm_prices * init_w\n",
    "    port_val = val_contrib.sum(axis=1)\n",
    "\n",
    "    # 4. MANUALLY RECONSTRUCT GROUP ATRP (Dynamic Weights)\n",
    "    # Ticker Weight_t = Ticker Value_t / Total Port Value_t\n",
    "    dyn_weights = val_contrib.div(port_val, axis=0).to_numpy()\n",
    "    atrp_vals = raw_atrp.to_numpy()\n",
    "    port_atrp = pd.Series(\n",
    "        np.sum(dyn_weights * atrp_vals, axis=1), index=raw_prices.index\n",
    "    )\n",
    "\n",
    "    # 5. DEFINE INDEPENDENT MATH FUNCTIONS\n",
    "    def audit_period(v_series, a_series):\n",
    "        # GAIN: Calculated on the full slice\n",
    "        gain = (v_series.iloc[-1] / v_series.iloc[0]) - 1\n",
    "\n",
    "        # RETURNS: Calculated locally (Day 1 becomes NaN)\n",
    "        rets = v_series.pct_change().dropna()\n",
    "\n",
    "        # SHARPE: mu/std * sqrt(252) (skips Day 1 NaN automatically)\n",
    "        mu, std = rets.mean(), rets.std()\n",
    "        sharpe = (mu / std) * np.sqrt(ANNUALIZATION_FACTOR) if std > 1e-9 else 0.0\n",
    "\n",
    "        # SHARPE ATR: Mean(Returns) / Mean(ATRP)\n",
    "        # rets.mean() has N-1 observations; a_series.mean() has N observations\n",
    "        sharpe_atr = rets.mean() / a_series.mean() if a_series.mean() > 1e-9 else 0.0\n",
    "\n",
    "        return gain, sharpe, sharpe_atr\n",
    "\n",
    "    # 6. CALCULATE ACROSS PERIODS\n",
    "    periods = [\n",
    "        (\"Full\", start_dt, end_dt),\n",
    "        (\"Lookback\", start_dt, decision_dt),\n",
    "        (\"Holding\", buy_dt, end_dt),\n",
    "    ]\n",
    "    results = []\n",
    "\n",
    "    for name, s, e in periods:\n",
    "        g_gain, g_sharpe, g_satr = audit_period(port_val.loc[s:e], port_atrp.loc[s:e])\n",
    "        b_gain, b_sharpe, b_satr = audit_period(b_val.loc[s:e], b_atrp_raw.loc[s:e])\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"name\": name,\n",
    "                \"group\": [g_gain, g_sharpe, g_satr],\n",
    "                \"bench\": [b_gain, b_sharpe, b_satr],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # 7. OUTPUT\n",
    "    print(f\"{'Metric':<25} | {'Full':>10} | {'Lookback':>10} | {'Holding':>10}\")\n",
    "    print(\"-\" * 65)\n",
    "    for label, idx in [(\"Gain\", 0), (\"Sharpe\", 1), (\"Sharpe (ATR)\", 2)]:\n",
    "        g_row = f\"Group {label:<19} | \"\n",
    "        b_row = f\"Bench {label:<19} | \"\n",
    "        for res in results:\n",
    "            g_row += f\"{res['group'][idx]:>10.4f} | \"\n",
    "            b_row += f\"{res['bench'][idx]:>10.4f} | \"\n",
    "        print(g_row)\n",
    "        print(b_row)\n",
    "        print(\"-\" * 65)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pure_audit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac0b352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43d0aedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.precision\", 8)  # Sets display precision to 8\n",
    "pd.options.display.float_format = (\n",
    "    \"{:.8f}\".format\n",
    ")  # Forces 8 decimals (prevents scientific notation)\n",
    "\n",
    "_rows = debug_container[0][\"full_universe_ranking\"]\n",
    "pd.DataFrame(_rows).to_csv(\"bot_v46_full_universe_ranking.csv\", index=True)\n",
    "\n",
    "_rows = debug_container[0][\"audit_liquidity\"][\"universe_snapshot\"]\n",
    "pd.DataFrame(_rows).to_csv(\"bot_v46_universe_snapshot.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc58d17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.precision\", 8)  # Sets display precision to 8\n",
    "pd.options.display.float_format = (\n",
    "    \"{:.8f}\".format\n",
    ")  # Forces 8 decimals (prevents scientific notation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff5a670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "166bd685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice the rows you want\n",
    "sub = my_features.loc[\"SGOV\"].loc[\"2025-01-02\":\"2025-01-28\"]\n",
    "\n",
    "# write to CSV (index will be the date)\n",
    "sub.to_csv(\"SGOV_2025-01-02_to_2025-01-28.csv\")\n",
    "\n",
    "\n",
    "# slice the rows you want\n",
    "sub = my_features.loc[\"RPRX\"].loc[\"2025-01-02\":\"2025-01-28\"]\n",
    "\n",
    "# write to CSV (index will be the date)\n",
    "sub.to_csv(\"RPRX_2025-01-02_to_2025-01-28.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc170223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ATR</th>\n",
       "      <th>ATRP</th>\n",
       "      <th>ROC_1</th>\n",
       "      <th>ROC_3</th>\n",
       "      <th>ROC_5</th>\n",
       "      <th>ROC_10</th>\n",
       "      <th>ROC_21</th>\n",
       "      <th>RollingStalePct</th>\n",
       "      <th>RollMedDollarVol</th>\n",
       "      <th>RollingSameVolCount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-01-02</th>\n",
       "      <td>0.02349904</td>\n",
       "      <td>0.00024398</td>\n",
       "      <td>0.00019939</td>\n",
       "      <td>0.00049861</td>\n",
       "      <td>0.00089786</td>\n",
       "      <td>0.00201725</td>\n",
       "      <td>0.00391497</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>392484992.60699999</td>\n",
       "      <td>0.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-03</th>\n",
       "      <td>0.02456340</td>\n",
       "      <td>0.00025496</td>\n",
       "      <td>0.00029902</td>\n",
       "      <td>0.00079778</td>\n",
       "      <td>0.00109728</td>\n",
       "      <td>0.00209585</td>\n",
       "      <td>0.00411469</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>392484992.60699999</td>\n",
       "      <td>0.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-06</th>\n",
       "      <td>0.02418030</td>\n",
       "      <td>0.00025098</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00049846</td>\n",
       "      <td>0.00079778</td>\n",
       "      <td>0.00189681</td>\n",
       "      <td>0.00391484</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>393459336.84920001</td>\n",
       "      <td>0.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-07</th>\n",
       "      <td>0.02451028</td>\n",
       "      <td>0.00025435</td>\n",
       "      <td>0.00019929</td>\n",
       "      <td>0.00049836</td>\n",
       "      <td>0.00099723</td>\n",
       "      <td>0.00189643</td>\n",
       "      <td>0.00401447</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>394166687.47405005</td>\n",
       "      <td>0.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-08</th>\n",
       "      <td>0.02413097</td>\n",
       "      <td>0.00025037</td>\n",
       "      <td>0.00019925</td>\n",
       "      <td>0.00039857</td>\n",
       "      <td>0.00089724</td>\n",
       "      <td>0.00189501</td>\n",
       "      <td>0.00371464</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>394716394.71165001</td>\n",
       "      <td>0.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-10</th>\n",
       "      <td>0.02583590</td>\n",
       "      <td>0.00026795</td>\n",
       "      <td>0.00039841</td>\n",
       "      <td>0.00079715</td>\n",
       "      <td>0.00109640</td>\n",
       "      <td>0.00199525</td>\n",
       "      <td>0.00401416</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>395032906.39565003</td>\n",
       "      <td>0.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-13</th>\n",
       "      <td>0.02536191</td>\n",
       "      <td>0.00026298</td>\n",
       "      <td>0.00019913</td>\n",
       "      <td>0.00079699</td>\n",
       "      <td>0.00099643</td>\n",
       "      <td>0.00209480</td>\n",
       "      <td>0.00401440</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>395179282.11425000</td>\n",
       "      <td>0.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-14</th>\n",
       "      <td>0.02423606</td>\n",
       "      <td>0.00025128</td>\n",
       "      <td>0.00009954</td>\n",
       "      <td>0.00069722</td>\n",
       "      <td>0.00109607</td>\n",
       "      <td>0.00189473</td>\n",
       "      <td>0.00411434</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>395616438.02260000</td>\n",
       "      <td>0.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-15</th>\n",
       "      <td>0.02319062</td>\n",
       "      <td>0.00024042</td>\n",
       "      <td>0.00009953</td>\n",
       "      <td>0.00039826</td>\n",
       "      <td>0.00099623</td>\n",
       "      <td>0.00199445</td>\n",
       "      <td>0.00411498</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>396153487.02560002</td>\n",
       "      <td>0.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-16</th>\n",
       "      <td>0.02290558</td>\n",
       "      <td>0.00023746</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00019909</td>\n",
       "      <td>0.00079683</td>\n",
       "      <td>0.00169478</td>\n",
       "      <td>0.00361455</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>397317430.77790004</td>\n",
       "      <td>0.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-17</th>\n",
       "      <td>0.02538375</td>\n",
       "      <td>0.00026302</td>\n",
       "      <td>0.00049762</td>\n",
       "      <td>0.00059720</td>\n",
       "      <td>0.00089607</td>\n",
       "      <td>0.00199346</td>\n",
       "      <td>0.00401473</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>398766227.62740004</td>\n",
       "      <td>0.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-21</th>\n",
       "      <td>0.02494206</td>\n",
       "      <td>0.00025842</td>\n",
       "      <td>0.00009947</td>\n",
       "      <td>0.00059714</td>\n",
       "      <td>0.00079635</td>\n",
       "      <td>0.00179358</td>\n",
       "      <td>0.00411460</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>399381182.34350002</td>\n",
       "      <td>0.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-22</th>\n",
       "      <td>0.02453191</td>\n",
       "      <td>0.00025412</td>\n",
       "      <td>0.00019893</td>\n",
       "      <td>0.00079619</td>\n",
       "      <td>0.00089581</td>\n",
       "      <td>0.00199286</td>\n",
       "      <td>0.00409289</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>399714791.92400002</td>\n",
       "      <td>0.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-23</th>\n",
       "      <td>0.02346534</td>\n",
       "      <td>0.00024305</td>\n",
       "      <td>0.00009944</td>\n",
       "      <td>0.00039790</td>\n",
       "      <td>0.00089572</td>\n",
       "      <td>0.00189284</td>\n",
       "      <td>0.00399329</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>399714791.92400002</td>\n",
       "      <td>0.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-24</th>\n",
       "      <td>0.02453211</td>\n",
       "      <td>0.00025402</td>\n",
       "      <td>0.00029831</td>\n",
       "      <td>0.00059679</td>\n",
       "      <td>0.00119429</td>\n",
       "      <td>0.00199207</td>\n",
       "      <td>0.00409230</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>399952638.04320002</td>\n",
       "      <td>0.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-27</th>\n",
       "      <td>0.02415124</td>\n",
       "      <td>0.00025008</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00039778</td>\n",
       "      <td>0.00069632</td>\n",
       "      <td>0.00159302</td>\n",
       "      <td>0.00389086</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>402082683.68849999</td>\n",
       "      <td>0.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-28</th>\n",
       "      <td>0.02448329</td>\n",
       "      <td>0.00025344</td>\n",
       "      <td>0.00029822</td>\n",
       "      <td>0.00059661</td>\n",
       "      <td>0.00089518</td>\n",
       "      <td>0.00169225</td>\n",
       "      <td>0.00389074</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>406068488.36790001</td>\n",
       "      <td>0.00000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ATR       ATRP      ROC_1      ROC_3      ROC_5     ROC_10     ROC_21  RollingStalePct   RollMedDollarVol  RollingSameVolCount\n",
       "Date                                                                                                                                            \n",
       "2025-01-02 0.02349904 0.00024398 0.00019939 0.00049861 0.00089786 0.00201725 0.00391497       0.00000000 392484992.60699999           0.00000000\n",
       "2025-01-03 0.02456340 0.00025496 0.00029902 0.00079778 0.00109728 0.00209585 0.00411469       0.00000000 392484992.60699999           0.00000000\n",
       "2025-01-06 0.02418030 0.00025098 0.00000000 0.00049846 0.00079778 0.00189681 0.00391484       0.00000000 393459336.84920001           0.00000000\n",
       "2025-01-07 0.02451028 0.00025435 0.00019929 0.00049836 0.00099723 0.00189643 0.00401447       0.00000000 394166687.47405005           0.00000000\n",
       "2025-01-08 0.02413097 0.00025037 0.00019925 0.00039857 0.00089724 0.00189501 0.00371464       0.00000000 394716394.71165001           0.00000000\n",
       "2025-01-10 0.02583590 0.00026795 0.00039841 0.00079715 0.00109640 0.00199525 0.00401416       0.00000000 395032906.39565003           0.00000000\n",
       "2025-01-13 0.02536191 0.00026298 0.00019913 0.00079699 0.00099643 0.00209480 0.00401440       0.00000000 395179282.11425000           0.00000000\n",
       "2025-01-14 0.02423606 0.00025128 0.00009954 0.00069722 0.00109607 0.00189473 0.00411434       0.00000000 395616438.02260000           0.00000000\n",
       "2025-01-15 0.02319062 0.00024042 0.00009953 0.00039826 0.00099623 0.00199445 0.00411498       0.00000000 396153487.02560002           0.00000000\n",
       "2025-01-16 0.02290558 0.00023746 0.00000000 0.00019909 0.00079683 0.00169478 0.00361455       0.00000000 397317430.77790004           0.00000000\n",
       "2025-01-17 0.02538375 0.00026302 0.00049762 0.00059720 0.00089607 0.00199346 0.00401473       0.00000000 398766227.62740004           0.00000000\n",
       "2025-01-21 0.02494206 0.00025842 0.00009947 0.00059714 0.00079635 0.00179358 0.00411460       0.00000000 399381182.34350002           0.00000000\n",
       "2025-01-22 0.02453191 0.00025412 0.00019893 0.00079619 0.00089581 0.00199286 0.00409289       0.00000000 399714791.92400002           0.00000000\n",
       "2025-01-23 0.02346534 0.00024305 0.00009944 0.00039790 0.00089572 0.00189284 0.00399329       0.00000000 399714791.92400002           0.00000000\n",
       "2025-01-24 0.02453211 0.00025402 0.00029831 0.00059679 0.00119429 0.00199207 0.00409230       0.00000000 399952638.04320002           0.00000000\n",
       "2025-01-27 0.02415124 0.00025008 0.00000000 0.00039778 0.00069632 0.00159302 0.00389086       0.00000000 402082683.68849999           0.00000000\n",
       "2025-01-28 0.02448329 0.00025344 0.00029822 0.00059661 0.00089518 0.00169225 0.00389074       0.00000000 406068488.36790001           0.00000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_features.loc[\"SGOV\"][\"2025-01-02\":\"2025-01-28\"]\n",
    "# my_features.loc[\"SGOV\"][\"2025-01-02\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c34f99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date,Adj Open,Adj High,Adj Low,Adj Close,Volume\n",
      "2025-01-02,582.549,584.269,573.762,577.854,50793553\n",
      "2025-01-03,580.711,585.722,579.623,585.079,38333433\n",
      "2025-01-06,589.349,592.739,586.71,588.45,48239308\n",
      "2025-01-07,590.486,590.812,579.969,581.798,61102306\n",
      "2025-01-08,581.867,583.725,578.408,582.648,47860204\n",
      "2025-01-10,579.08,579.149,571.835,573.752,73963484\n",
      "2025-01-13,569.087,574.998,568.672,574.642,48472715\n",
      "2025-01-14,577.577,578.21,571.637,575.433,48989215\n",
      "2025-01-15,583.478,587.046,582.361,585.9,57568393\n",
      "2025-01-16,587.274,587.451,584.071,584.773,43828408\n",
      "2025-01-17,590.031,592.403,588.697,590.644,58752533\n",
      "2025-01-21,593.698,596.06,591.721,596.05,43032370\n",
      "2025-01-22,598.887,600.765,598.334,599.401,48761974\n",
      "2025-01-23,598.769,602.673,598.492,602.673,41635359\n",
      "2025-01-24,602.732,603.691,599.757,600.913,35011069\n",
      "2025-01-27,587.906,592.73,587.738,592.413,71187359\n",
      "2025-01-28,593.649,598.344,590.318,597.503,44955084\n",
      "\n",
      "Date,ATR,ATRP,ROC_1,ROC_3,ROC_5,ROC_10,ROC_21,RollingStalePct,RollMedDollarVol,RollingSameVolCount\n",
      "2025-01-02,6.971400839437074,0.012064294509403887,-0.002456510443190396,-0.017428890128276642,-0.02770724911285316,-0.029262204064353647,-0.028199427535476218,0.0,28448970903.186996,0.0\n",
      "2025-01-03,7.035443636620136,0.01202477552026331,0.012503158237201717,0.006339945613380138,-0.015615115418265102,0.013069428307744602,-0.016505350497060145,0.0,28400995665.875,0.0\n",
      "2025-01-06,7.08005480543299,0.012031701598152757,0.005761615098132111,0.015835256707930734,0.000588331315549695,0.019218711570371028,-0.01694309312520037,0.0,28378186103.284,0.0\n",
      "2025-01-07,7.348836605044917,0.012631251061442144,-0.011304273940011988,0.006825253437719558,0.0006966028142754155,-0.00426330120881957,-0.02645384006546103,0.0,28378186103.284,0.0\n",
      "2025-01-08,7.203705418970281,0.01236373491193702,0.0014609881780274225,-0.004154994453740346,0.005819323052701941,-0.008742963012111526,-0.02687644052510274,0.0,28368300595.295498,0.0\n",
      "2025-01-10,7.461512174758117,0.013004768915416623,-0.01526822369595382,-0.024977483218625363,-0.007098678905052336,-0.03460924315311098,-0.03677451956411171,0.0,28368300595.295498,0.0\n",
      "2025-01-13,7.380404162275396,0.0128434819631621,0.0015511928498725958,-0.012299801649369613,-0.01783861666544162,-0.033175180025573625,-0.0322715369523664,0.0,28336585941.5645,0.0\n",
      "2025-01-14,7.322732436398589,0.012725603912877066,0.0013765092005109114,-0.01238311982534912,-0.022120825898547136,-0.021545508957599435,-0.03837264683027097,0.0,28303270556.144,0.0\n",
      "2025-01-15,7.629180119512979,0.013021300767217919,0.018189780565243785,0.02117291094410123,0.007050557066198282,0.007752071318368081,-0.015810197005939775,0.0,28336585941.5645,0.0\n",
      "2025-01-16,7.325667253833481,0.012527369173736614,-0.0019235364396653631,0.017630107092763803,0.0036471420137029753,0.00948768896400165,-0.017508577035386663,0.0,28303270556.144,0.0\n",
      "2025-01-17,7.34740530713109,0.012439651138640347,0.010039793218907134,0.026434007086837186,0.02944129170791565,0.022133618526478882,-0.011863116598492707,0.0,28303270556.144,0.0\n",
      "2025-01-21,7.20944778519315,0.012095374188731065,0.009152721436262778,0.01732377538829155,0.03725449932305658,0.018751313925128077,0.0013052834581779305,0.0,28283332131.766,0.0\n",
      "2025-01-22,7.031272943393643,0.011730499187344772,0.0056220115762100065,0.02501483481624489,0.04165211240926392,0.018609907383804858,0.0378680971237908,0.0,28283332131.766,0.0\n",
      "2025-01-23,6.827682018865528,0.011328999339385583,0.005458783018380098,0.020365905689383013,0.02862775217613933,0.03588015084273244,0.04385351101750401,0.0,28228328106.4225,0.0\n",
      "2025-01-24,6.620990446089425,0.011018218021725982,-0.0029203232930626877,0.008158711517490147,0.027600453509310396,0.03134825829660448,0.02845167374364399,0.0,28228328106.4225,0.0\n",
      "2025-01-27,7.089133985654463,0.011966540210384416,-0.014145142474867423,-0.011658305541698999,0.0029950359268866578,0.03252450536120155,0.007870197877802632,0.0,28228328106.4225,0.0\n",
      "2025-01-28,7.156052986679149,0.011976597584747103,0.008591978906607345,-0.008578449673371735,0.0024377149567991196,0.03978303013006346,0.005354009028790907,0.0,28161284058.247498,0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ticker = 'SPY'\n",
    "_df = df_ohlcv.loc[_ticker]['2025-01-02':'2025-01-28']\n",
    "print(_df.to_csv())\n",
    "\n",
    "_df = my_features.loc[_ticker][\"2025-01-02\":\"2025-01-28\"]\n",
    "print(_df.to_csv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d17851a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['prices', 'atrp']\n"
     ]
    }
   ],
   "source": [
    "print(list(debug_container[0][\"portfolio_raw_components\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bde0948e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['inputs', 'audit_liquidity', 'full_universe_ranking', 'verification', 'portfolio_raw_components', 'benchmark_raw_components']\n"
     ]
    }
   ],
   "source": [
    "print(list(debug_container[0].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0dd948ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "    EngineOutput(portfolio_series=Date\n",
      "2025-01-02   1.00000000\n",
      "2025-01-03   1.00537562\n",
      "2025-01-06   1.00822003\n",
      "2025-01-07   1.01650775\n",
      "2025-01-08   1.01850477\n",
      "2025-01-10   1.04039997\n",
      "2025-01-13   1.04592805\n",
      "2025-01-14   1.05856007\n",
      "2025-01-15   1.06700689\n",
      "2025-01-16   1.07542146\n",
      "2025-01-17   1.09115419\n",
      "2025-01-21   1.09683851\n",
      "2025-01-22   1.08532573\n",
      "2025-01-23   1.09441466\n",
      "2025-01-24   1.09139952\n",
      "2025-01-27   1.08227780\n",
      "2025-01-28   1.08367916\n",
      "dtype: float64, benchmark_series=Date\n",
      "2025-01-02   1.00000000\n",
      "2025-01-03   1.01250316\n",
      "2025-01-06   1.01833681\n",
      "2025-01-07   1.00682525\n",
      "2025-01-08   1.00829621\n",
      "2025-01-10   0.99290132\n",
      "2025-01-13   0.99444150\n",
      "2025-01-14   0.99581036\n",
      "2025-01-15   1.01392393\n",
      "2025-01-16   1.01197361\n",
      "2025-01-17   1.02213362\n",
      "2025-01-21   1.03148892\n",
      "2025-01-22   1.03728797\n",
      "2025-01-23   1.04295030\n",
      "2025-01-24   1.03990454\n",
      "2025-01-27   1.02519495\n",
      "2025-01-28   1.03400340\n",
      "dtype: float64, normalized_plot_data=Ticker            SNX       QRVO       TRGP       MINT        SHV       RPRX        BIL       SGOV        LNG       USFR\n",
      "Date                                                                                                                    \n",
      "2025-01-02 1.00000000 1.00000000 1.00000000 1.00000000 1.00000000 1.00000000 1.00000000 1.00000000 1.00000000 1.00000000\n",
      "2025-01-03 1.01245041 1.01247133 1.01699117 1.00049935 1.00027431 1.00193989 1.00010939 1.00029902 1.00852320 1.00019819\n",
      "2025-01-06 1.01562609 1.03411697 1.01693534 1.00069805 1.00045403 0.99844968 1.00021878 1.00029902 1.01500595 1.00039638\n",
      "2025-01-07 1.05794529 1.05547592 1.02600325 1.00059818 1.00063374 1.00969546 1.00043642 1.00049836 1.01319425 1.00059663\n",
      "2025-01-08 1.04824424 1.04759174 1.04872887 1.00099766 1.00063374 1.01589674 1.00065519 1.00069771 1.02080703 1.00079482\n",
      "2025-01-10 1.15050115 1.02766628 1.05594300 1.00109753 1.00090805 1.14346818 1.00098336 1.00109640 1.02094428 1.00139145\n",
      "2025-01-13 1.14045208 1.03081995 1.07871888 1.00129623 1.00108777 1.16285513 1.00109275 1.00129575 1.04007228 1.00158964\n",
      "2025-01-14 1.16792824 1.04386468 1.10008208 1.00149597 1.00118236 1.16440545 1.00131152 1.00139542 1.10194894 1.00198602\n",
      "2025-01-15 1.16981625 1.06307339 1.12258436 1.00179454 1.00136208 1.19193754 1.00142091 1.00149509 1.11459877 1.00198602\n",
      "2025-01-16 1.17762929 1.05490252 1.16328388 1.00209415 1.00145666 1.20007871 1.00142091 1.00149509 1.14986733 1.00198602\n",
      "2025-01-17 1.17702896 1.20713876 1.17841568 1.00259246 1.00191069 1.19232313 1.00196786 1.00199346 1.14578644 1.00238446\n",
      "2025-01-21 1.20853344 1.25544725 1.18660696 1.00259246 1.00209041 1.17487607 1.00196786 1.00209313 1.13159484 1.00258265\n",
      "2025-01-22 1.21479780 1.24842317 1.15410429 1.00279115 1.00209041 1.16634534 1.00218663 1.00229248 1.05784152 1.00238446\n",
      "2025-01-23 1.22931022 1.29830849 1.15476317 1.00299089 1.00227013 1.18728261 1.00218663 1.00239215 1.06205966 1.00258265\n",
      "2025-01-24 1.22715250 1.27494266 1.14208819 1.00348920 1.00263902 1.20434408 1.00262419 1.00269117 1.05104310 1.00298109\n",
      "2025-01-27 1.21587666 1.25616399 1.08838983 1.00348920 1.00281874 1.22993628 1.00273358 1.00269117 1.01749931 1.00317928\n",
      "2025-01-28 1.22104476 1.22964450 1.10548709 1.00348920 1.00290387 1.23846701 1.00273358 1.00299019 1.02661268 1.00341875, tickers=['RPRX', 'SGOV', 'SHV', 'BIL', 'SNX', 'MINT', 'TRGP', 'QRVO', 'LNG', 'USFR'], initial_weights=RPRX   0.10000000\n",
      "SGOV   0.10000000\n",
      "SHV    0.10000000\n",
      "BIL    0.10000000\n",
      "SNX    0.10000000\n",
      "MINT   0.10000000\n",
      "TRGP   0.10000000\n",
      "QRVO   0.10000000\n",
      "LNG    0.10000000\n",
      "USFR   0.10000000\n",
      "dtype: float64, perf_metrics={'full_p_gain': 0.08367916291332378, 'lookback_p_gain': 0.0911541890494405, 'holding_p_gain': -0.011997521082268148, 'full_p_sharpe': 10.048113883624927, 'lookback_p_sharpe': 23.58781837694053, 'holding_p_sharpe': -4.989320677738094, 'full_p_sharpe_atr': 0.39085195465369743, 'lookback_p_sharpe_atr': 0.7154367400507659, 'holding_p_sharpe_atr': -0.16786446454741205, 'full_b_gain': 0.034003398782391336, 'lookback_b_gain': 0.022133618526478882, 'holding_b_gain': 0.0024377149567988976, 'full_b_sharpe': 3.575198806729765, 'lookback_b_sharpe': 3.4734882627039427, 'holding_b_sharpe': 0.8946109530190065, 'full_b_sharpe_atr': 0.17460173866005643, 'lookback_b_sharpe_atr': 0.17886456441078652, 'holding_b_sharpe_atr': 0.04462261227411548}, results_df=        Rank  Strategy Value  Holding Gain\n",
      "Ticker                                    \n",
      "RPRX       1      0.84695201    0.05412566\n",
      "SGOV       2      0.78875453    0.00089518\n",
      "SHV        3      0.78522923    0.00081176\n",
      "BIL        4      0.78463742    0.00076422\n",
      "SNX        5      0.71752921    0.01035247\n",
      "MINT       6      0.70803663    0.00089443\n",
      "TRGP       7      0.70611655   -0.06836288\n",
      "QRVO       8      0.70285869   -0.02055264\n",
      "LNG        9      0.69695735   -0.09277363\n",
      "USFR      10      0.67743481    0.00083395, start_date=Timestamp('2025-01-02 00:00:00'), decision_date=Timestamp('2025-01-17 00:00:00'), buy_date=Timestamp('2025-01-21 00:00:00'), holding_end_date=Timestamp('2025-01-28 00:00:00'), error_msg=None, debug_data={'audit_liquidity': {'date': Timestamp('2025-01-17 00:00:00'), 'total_tickers_available': 1561, 'percentile_setting': 0.4, 'final_cutoff_usd': 63919777.73594999, 'tickers_passed': 929, 'universe_snapshot':                ATR       ATRP       ROC_1       ROC_3       ROC_5      ROC_10      ROC_21  RollingStalePct     RollMedDollarVol  RollingSameVolCount  Calculated_Cutoff  Passed_Vol_Check  Passed_Final\n",
      "Ticker                                                                                                                                                                                                 \n",
      "NVDA    5.80564749 0.04217014  0.03099608  0.04515502  0.01324031 -0.00433927  0.04325422       0.00000000 35389803487.87730408           0.00000000  63919777.73594999              True          True\n",
      "SPY     7.34740531 0.01243965  0.01003979  0.02643401  0.02944129  0.02213362 -0.01186312       0.00000000 28303270556.14400101           0.00000000  63919777.73594999              True          True\n",
      "TSLA   24.27798367 0.05692376  0.03064134  0.07604198  0.08045802  0.12449905 -0.07887348       0.00000000 18898512016.00000000           0.00000000  63919777.73594999              True          True\n",
      "QQQ     8.86820884 0.01706160  0.01687766  0.03298429  0.02868701  0.02255911 -0.02896609       0.00000000 15981210672.20349884           0.00000000  63919777.73594999              True          True\n",
      "AAPL    5.04876072 0.02205229  0.00753855 -0.01414546 -0.02900536 -0.05687698 -0.08389020       0.00000000 10079251624.32500076           0.00000000  63919777.73594999              True          True\n",
      "...            ...        ...         ...         ...         ...         ...         ...              ...                  ...                  ...                ...               ...           ...\n",
      "LTM     0.55333676 0.02102495 -0.00474595  0.02790623  0.02212168 -0.00329104 -0.04884766              NaN                  NaN                  NaN  63919777.73594999             False         False\n",
      "NBIS    2.98691869 0.08287788 -0.04123437 -0.02304147  0.08619650  0.18125205  0.07904192              NaN                  NaN                  NaN  63919777.73594999             False         False\n",
      "SARO    0.87681548 0.03558504  0.03442485  0.02623907  0.06161137  0.00407498 -0.05918289              NaN                  NaN                  NaN  63919777.73594999             False         False\n",
      "SMBS    0.12778094 0.00537717 -0.00100053  0.01402176  0.01217320  0.00176632 -0.00552819              NaN                  NaN                  NaN  63919777.73594999             False         False\n",
      "TTAN    5.94496678 0.06058874 -0.02241706  0.01964044 -0.03100928 -0.03330049 -0.06792059              NaN                  NaN                  NaN  63919777.73594999             False         False\n",
      "\n",
      "[1561 rows x 13 columns]}, 'full_universe_ranking':         Strategy_Score  Lookback_Return_Ann  Lookback_ATRP\n",
      "Ticker                                                    \n",
      "A           0.44105365           2.53065642     0.02276886\n",
      "AA          0.11005732           1.08357368     0.03906960\n",
      "AAL         0.21539307           1.89489245     0.03491020\n",
      "AAPL       -0.29456135          -1.43760630     0.01936706\n",
      "ABBV       -0.18171387          -0.87989736     0.01921513\n",
      "...                ...                  ...            ...\n",
      "ZBRA        0.25074999           1.43783959     0.02275459\n",
      "ZION        0.25674500           1.84033508     0.02844424\n",
      "ZM         -0.15280102          -1.08947654     0.02829379\n",
      "ZS          0.09620805           0.85056552     0.03508293\n",
      "ZTS         0.09490106           0.52869614     0.02210724\n",
      "\n",
      "[929 rows x 3 columns], 'verification': {'portfolio': {'full_val': Date\n",
      "2025-01-02   1.00000000\n",
      "2025-01-03   1.00537562\n",
      "2025-01-06   1.00822003\n",
      "2025-01-07   1.01650775\n",
      "2025-01-08   1.01850477\n",
      "2025-01-10   1.04039997\n",
      "2025-01-13   1.04592805\n",
      "2025-01-14   1.05856007\n",
      "2025-01-15   1.06700689\n",
      "2025-01-16   1.07542146\n",
      "2025-01-17   1.09115419\n",
      "2025-01-21   1.09683851\n",
      "2025-01-22   1.08532573\n",
      "2025-01-23   1.09441466\n",
      "2025-01-24   1.09139952\n",
      "2025-01-27   1.08227780\n",
      "2025-01-28   1.08367916\n",
      "dtype: float64, 'full_ret': Date\n",
      "2025-01-02           NaN\n",
      "2025-01-03    0.00537562\n",
      "2025-01-06    0.00282919\n",
      "2025-01-07    0.00822015\n",
      "2025-01-08    0.00196459\n",
      "2025-01-10    0.02149739\n",
      "2025-01-13    0.00531342\n",
      "2025-01-14    0.01207733\n",
      "2025-01-15    0.00797954\n",
      "2025-01-16    0.00788614\n",
      "2025-01-17    0.01462937\n",
      "2025-01-21    0.00520945\n",
      "2025-01-22   -0.01049633\n",
      "2025-01-23    0.00837438\n",
      "2025-01-24   -0.00275503\n",
      "2025-01-27   -0.00835782\n",
      "2025-01-28    0.00129482\n",
      "dtype: float64, 'full_atrp': Date\n",
      "2025-01-02   0.01147520\n",
      "2025-01-03   0.01130452\n",
      "2025-01-06   0.01130399\n",
      "2025-01-07   0.01140030\n",
      "2025-01-08   0.01146641\n",
      "2025-01-10   0.01269632\n",
      "2025-01-13   0.01286422\n",
      "2025-01-14   0.01295694\n",
      "2025-01-15   0.01290162\n",
      "2025-01-16   0.01298565\n",
      "2025-01-17   0.01359739\n",
      "2025-01-21   0.01376068\n",
      "2025-01-22   0.01426161\n",
      "2025-01-23   0.01411845\n",
      "2025-01-24   0.01409279\n",
      "2025-01-27   0.01464299\n",
      "2025-01-28   0.01447782\n",
      "dtype: float64, 'lookback_val': Date\n",
      "2025-01-02   1.00000000\n",
      "2025-01-03   1.00537562\n",
      "2025-01-06   1.00822003\n",
      "2025-01-07   1.01650775\n",
      "2025-01-08   1.01850477\n",
      "2025-01-10   1.04039997\n",
      "2025-01-13   1.04592805\n",
      "2025-01-14   1.05856007\n",
      "2025-01-15   1.06700689\n",
      "2025-01-16   1.07542146\n",
      "2025-01-17   1.09115419\n",
      "dtype: float64, 'lookback_ret': Date\n",
      "2025-01-02          NaN\n",
      "2025-01-03   0.00537562\n",
      "2025-01-06   0.00282919\n",
      "2025-01-07   0.00822015\n",
      "2025-01-08   0.00196459\n",
      "2025-01-10   0.02149739\n",
      "2025-01-13   0.00531342\n",
      "2025-01-14   0.01207733\n",
      "2025-01-15   0.00797954\n",
      "2025-01-16   0.00788614\n",
      "2025-01-17   0.01462937\n",
      "dtype: float64, 'lookback_atrp': Date\n",
      "2025-01-02   0.01147520\n",
      "2025-01-03   0.01130452\n",
      "2025-01-06   0.01130399\n",
      "2025-01-07   0.01140030\n",
      "2025-01-08   0.01146641\n",
      "2025-01-10   0.01269632\n",
      "2025-01-13   0.01286422\n",
      "2025-01-14   0.01295694\n",
      "2025-01-15   0.01290162\n",
      "2025-01-16   0.01298565\n",
      "2025-01-17   0.01359739\n",
      "dtype: float64, 'holding_val': Date\n",
      "2025-01-21   1.09683851\n",
      "2025-01-22   1.08532573\n",
      "2025-01-23   1.09441466\n",
      "2025-01-24   1.09139952\n",
      "2025-01-27   1.08227780\n",
      "2025-01-28   1.08367916\n",
      "dtype: float64, 'holding_ret': Date\n",
      "2025-01-21           NaN\n",
      "2025-01-22   -0.01049633\n",
      "2025-01-23    0.00837438\n",
      "2025-01-24   -0.00275503\n",
      "2025-01-27   -0.00835782\n",
      "2025-01-28    0.00129482\n",
      "dtype: float64, 'holding_atrp': Date\n",
      "2025-01-21   0.01376068\n",
      "2025-01-22   0.01426161\n",
      "2025-01-23   0.01411845\n",
      "2025-01-24   0.01409279\n",
      "2025-01-27   0.01464299\n",
      "2025-01-28   0.01447782\n",
      "dtype: float64}, 'benchmark': {'full_val': Date\n",
      "2025-01-02   1.00000000\n",
      "2025-01-03   1.01250316\n",
      "2025-01-06   1.01833681\n",
      "2025-01-07   1.00682525\n",
      "2025-01-08   1.00829621\n",
      "2025-01-10   0.99290132\n",
      "2025-01-13   0.99444150\n",
      "2025-01-14   0.99581036\n",
      "2025-01-15   1.01392393\n",
      "2025-01-16   1.01197361\n",
      "2025-01-17   1.02213362\n",
      "2025-01-21   1.03148892\n",
      "2025-01-22   1.03728797\n",
      "2025-01-23   1.04295030\n",
      "2025-01-24   1.03990454\n",
      "2025-01-27   1.02519495\n",
      "2025-01-28   1.03400340\n",
      "dtype: float64, 'full_ret': Date\n",
      "2025-01-02           NaN\n",
      "2025-01-03    0.01250316\n",
      "2025-01-06    0.00576162\n",
      "2025-01-07   -0.01130427\n",
      "2025-01-08    0.00146099\n",
      "2025-01-10   -0.01526822\n",
      "2025-01-13    0.00155119\n",
      "2025-01-14    0.00137651\n",
      "2025-01-15    0.01818978\n",
      "2025-01-16   -0.00192354\n",
      "2025-01-17    0.01003979\n",
      "2025-01-21    0.00915272\n",
      "2025-01-22    0.00562201\n",
      "2025-01-23    0.00545878\n",
      "2025-01-24   -0.00292032\n",
      "2025-01-27   -0.01414514\n",
      "2025-01-28    0.00859198\n",
      "dtype: float64, 'full_atrp': Date\n",
      "2025-01-02   0.01206429\n",
      "2025-01-03   0.01202478\n",
      "2025-01-06   0.01203170\n",
      "2025-01-07   0.01263125\n",
      "2025-01-08   0.01236373\n",
      "2025-01-10   0.01300477\n",
      "2025-01-13   0.01284348\n",
      "2025-01-14   0.01272560\n",
      "2025-01-15   0.01302130\n",
      "2025-01-16   0.01252737\n",
      "2025-01-17   0.01243965\n",
      "2025-01-21   0.01209537\n",
      "2025-01-22   0.01173050\n",
      "2025-01-23   0.01132900\n",
      "2025-01-24   0.01101822\n",
      "2025-01-27   0.01196654\n",
      "2025-01-28   0.01197660\n",
      "dtype: float64, 'lookback_val': Date\n",
      "2025-01-02   1.00000000\n",
      "2025-01-03   1.01250316\n",
      "2025-01-06   1.01833681\n",
      "2025-01-07   1.00682525\n",
      "2025-01-08   1.00829621\n",
      "2025-01-10   0.99290132\n",
      "2025-01-13   0.99444150\n",
      "2025-01-14   0.99581036\n",
      "2025-01-15   1.01392393\n",
      "2025-01-16   1.01197361\n",
      "2025-01-17   1.02213362\n",
      "dtype: float64, 'lookback_ret': Date\n",
      "2025-01-02           NaN\n",
      "2025-01-03    0.01250316\n",
      "2025-01-06    0.00576162\n",
      "2025-01-07   -0.01130427\n",
      "2025-01-08    0.00146099\n",
      "2025-01-10   -0.01526822\n",
      "2025-01-13    0.00155119\n",
      "2025-01-14    0.00137651\n",
      "2025-01-15    0.01818978\n",
      "2025-01-16   -0.00192354\n",
      "2025-01-17    0.01003979\n",
      "dtype: float64, 'lookback_atrp': Date\n",
      "2025-01-02   0.01206429\n",
      "2025-01-03   0.01202478\n",
      "2025-01-06   0.01203170\n",
      "2025-01-07   0.01263125\n",
      "2025-01-08   0.01236373\n",
      "2025-01-10   0.01300477\n",
      "2025-01-13   0.01284348\n",
      "2025-01-14   0.01272560\n",
      "2025-01-15   0.01302130\n",
      "2025-01-16   0.01252737\n",
      "2025-01-17   0.01243965\n",
      "dtype: float64, 'holding_val': Date\n",
      "2025-01-21   1.03148892\n",
      "2025-01-22   1.03728797\n",
      "2025-01-23   1.04295030\n",
      "2025-01-24   1.03990454\n",
      "2025-01-27   1.02519495\n",
      "2025-01-28   1.03400340\n",
      "dtype: float64, 'holding_ret': Date\n",
      "2025-01-21           NaN\n",
      "2025-01-22    0.00562201\n",
      "2025-01-23    0.00545878\n",
      "2025-01-24   -0.00292032\n",
      "2025-01-27   -0.01414514\n",
      "2025-01-28    0.00859198\n",
      "dtype: float64, 'holding_atrp': Date\n",
      "2025-01-21   0.01209537\n",
      "2025-01-22   0.01173050\n",
      "2025-01-23   0.01132900\n",
      "2025-01-24   0.01101822\n",
      "2025-01-27   0.01196654\n",
      "2025-01-28   0.01197660\n",
      "dtype: float64}}, 'portfolio_raw_components': {'prices': Ticker            RPRX        SGOV          SHV         BIL          SNX        MINT         TRGP        QRVO          LNG        USFR\n",
      "Date                                                                                                                                  \n",
      "2025-01-02 25.15610000 96.31500000 105.72100000 87.76050000 114.93600000 96.12510000 179.09300000 69.76000000 218.58000000 48.43870000\n",
      "2025-01-03 25.20490000 96.34380000 105.75000000 87.77010000 116.36700000 96.17310000 182.13600000 70.63000000 220.44300000 48.44830000\n",
      "2025-01-06 25.11710000 96.34380000 105.76900000 87.77970000 116.73200000 96.19220000 182.12600000 72.14000000 221.86000000 48.45790000\n",
      "2025-01-07 25.40000000 96.36300000 105.78800000 87.79880000 121.59600000 96.18260000 183.75000000 73.63000000 221.46400000 48.46760000\n",
      "2025-01-08 25.55600000 96.38220000 105.78800000 87.81800000 120.48100000 96.22100000 187.82000000 73.08000000 223.12800000 48.47720000\n",
      "2025-01-10 28.76520000 96.42060000 105.81700000 87.84680000 132.23400000 96.23060000 189.11200000 71.69000000 223.15800000 48.50610000\n",
      "2025-01-13 29.25290000 96.43980000 105.83600000 87.85640000 131.07900000 96.24970000 193.19100000 71.91000000 227.33900000 48.51570000\n",
      "2025-01-14 29.29190000 96.44940000 105.84600000 87.87560000 134.23700000 96.26890000 197.01700000 72.82000000 240.86400000 48.53490000\n",
      "2025-01-15 29.98450000 96.45900000 105.86500000 87.88520000 134.45400000 96.29760000 201.04700000 74.16000000 243.62900000 48.53490000\n",
      "2025-01-16 30.18930000 96.45900000 105.87500000 87.88520000 135.35200000 96.32640000 208.33600000 73.59000000 251.33800000 48.53490000\n",
      "2025-01-17 29.99420000 96.50700000 105.92300000 87.93320000 135.28300000 96.37430000 211.04600000 84.21000000 250.44600000 48.55420000\n",
      "2025-01-21 29.55530000 96.51660000 105.94200000 87.93320000 138.90400000 96.37430000 212.51300000 87.58000000 247.34400000 48.56380000\n",
      "2025-01-22 29.34070000 96.53580000 105.94200000 87.95240000 139.62400000 96.39340000 206.69200000 87.09000000 231.22300000 48.55420000\n",
      "2025-01-23 29.86740000 96.54540000 105.96100000 87.95240000 141.29200000 96.41260000 206.81000000 90.57000000 232.14500000 48.56380000\n",
      "2025-01-24 30.29660000 96.57420000 106.00000000 87.99080000 141.04400000 96.46050000 204.54000000 88.94000000 229.73700000 48.58310000\n",
      "2025-01-27 30.94040000 96.57420000 106.01900000 88.00040000 139.74800000 96.46050000 194.92300000 87.63000000 222.40500000 48.59270000\n",
      "2025-01-28 31.15500000 96.60300000 106.02800000 88.00040000 140.34200000 96.46050000 197.98500000 85.78000000 224.39700000 48.60430000, 'atrp': Ticker           RPRX       SGOV        SHV        BIL        SNX       MINT       TRGP       QRVO        LNG       USFR\n",
      "Date                                                                                                                    \n",
      "2025-01-02 0.01840948 0.00024398 0.00025470 0.00024212 0.02136244 0.00034719 0.02449333 0.02976644 0.01927521 0.00035710\n",
      "2025-01-03 0.01771124 0.00025496 0.00026279 0.00024816 0.02090066 0.00037206 0.02410977 0.02912015 0.01908277 0.00035984\n",
      "2025-01-06 0.01843147 0.00025098 0.00025680 0.00024603 0.02120665 0.00035960 0.02363957 0.02869206 0.01857627 0.00034822\n",
      "2025-01-07 0.01832335 0.00025435 0.00025125 0.00025176 0.02177317 0.00035526 0.02369678 0.02810189 0.01866388 0.00035172\n",
      "2025-01-08 0.01856028 0.00025037 0.00023938 0.00024934 0.02237039 0.00035826 0.02340260 0.02805032 0.01872401 0.00034068\n",
      "2025-01-10 0.02423748 0.00026795 0.00024854 0.00026268 0.02552493 0.00037532 0.02337096 0.02835515 0.01927464 0.00035872\n",
      "2025-01-13 0.02520348 0.00026298 0.00024357 0.00025950 0.02598075 0.00036974 0.02312422 0.02810174 0.01943660 0.00034716\n",
      "2025-01-14 0.02463254 0.00025128 0.00023290 0.00025652 0.02545279 0.00036463 0.02342839 0.02701902 0.02114266 0.00036462\n",
      "2025-01-15 0.02422690 0.00024042 0.00022905 0.00024597 0.02546818 0.00036689 0.02286185 0.02677881 0.02101338 0.00035271\n",
      "2025-01-16 0.02460098 0.00023746 0.00021941 0.00023620 0.02476764 0.00036906 0.02303524 0.02641752 0.02164561 0.00034164\n",
      "2025-01-17 0.02429546 0.00026302 0.00023602 0.00025820 0.02393793 0.00038514 0.02339331 0.03067403 0.02194021 0.00034550\n",
      "2025-01-21 0.02417985 0.00025842 0.00023193 0.00024756 0.02420076 0.00036475 0.02279889 0.03139969 0.02239995 0.00034900\n",
      "2025-01-22 0.02398243 0.00025412 0.00022211 0.00024542 0.02338605 0.00036701 0.02510699 0.03124830 0.02740132 0.00033826\n",
      "2025-01-23 0.02328792 0.00024305 0.00021901 0.00023568 0.02288084 0.00036206 0.02479722 0.03118613 0.02655932 0.00034228\n",
      "2025-01-24 0.02244487 0.00025402 0.00023564 0.00024993 0.02249168 0.00037150 0.02485335 0.03180463 0.02737011 0.00036019\n",
      "2025-01-27 0.02223201 0.00025008 0.00023157 0.00023984 0.02212100 0.00035911 0.02854408 0.03325928 0.02942863 0.00036262\n",
      "2025-01-28 0.02166237 0.00025344 0.00022107 0.00023050 0.02132533 0.00034057 0.02756005 0.03478886 0.02860427 0.00036500}, 'benchmark_raw_components': {'atrp': Ticker            SPY\n",
      "Date                 \n",
      "2025-01-02 0.01206429\n",
      "2025-01-03 0.01202478\n",
      "2025-01-06 0.01203170\n",
      "2025-01-07 0.01263125\n",
      "2025-01-08 0.01236373\n",
      "2025-01-10 0.01300477\n",
      "2025-01-13 0.01284348\n",
      "2025-01-14 0.01272560\n",
      "2025-01-15 0.01302130\n",
      "2025-01-16 0.01252737\n",
      "2025-01-17 0.01243965\n",
      "2025-01-21 0.01209537\n",
      "2025-01-22 0.01173050\n",
      "2025-01-23 0.01132900\n",
      "2025-01-24 0.01101822\n",
      "2025-01-27 0.01196654\n",
      "2025-01-28 0.01197660}})\n"
     ]
    }
   ],
   "source": [
    "print_nested(results_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e39fb7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs\n",
      "    EngineInput(mode='Ranking', start_date=Timestamp('2025-01-17 00:00:00'), lookback_period=10, holding_period=5, metric='Sharpe (ATR)', benchmark_ticker='SPY', rank_start=1, rank_end=10, quality_thresholds={'min_median_dollar_volume': 1000000, 'min_liquidity_percentile': 0.4, 'max_stale_pct': 0.05, 'max_same_vol_count': 10}, manual_tickers=[], debug=True)\n",
      "audit_liquidity  [NEST]\n",
      "    date\n",
      "        2025-01-17 00:00:00\n",
      "    total_tickers_available\n",
      "        1561\n",
      "    percentile_setting\n",
      "        0.4\n",
      "    final_cutoff_usd\n",
      "        63919777.73594999\n",
      "    tickers_passed\n",
      "        929\n",
      "    universe_snapshot\n",
      "                       ATR       ATRP       ROC_1       ROC_3       ROC_5      ROC_10      ROC_21  RollingStalePct     RollMedDollarVol  RollingSameVolCount  Calculated_Cutoff  Passed_Vol_Check  Passed_Final\n",
      "Ticker                                                                                                                                                                                                 \n",
      "NVDA    5.80564749 0.04217014  0.03099608  0.04515502  0.01324031 -0.00433927  0.04325422       0.00000000 35389803487.87730408           0.00000000  63919777.73594999              True          True\n",
      "SPY     7.34740531 0.01243965  0.01003979  0.02643401  0.02944129  0.02213362 -0.01186312       0.00000000 28303270556.14400101           0.00000000  63919777.73594999              True          True\n",
      "TSLA   24.27798367 0.05692376  0.03064134  0.07604198  0.08045802  0.12449905 -0.07887348       0.00000000 18898512016.00000000           0.00000000  63919777.73594999              True          True\n",
      "QQQ     8.86820884 0.01706160  0.01687766  0.03298429  0.02868701  0.02255911 -0.02896609       0.00000000 15981210672.20349884           0.00000000  63919777.73594999              True          True\n",
      "AAPL    5.04876072 0.02205229  0.00753855 -0.01414546 -0.02900536 -0.05687698 -0.08389020       0.00000000 10079251624.32500076           0.00000000  63919777.73594999              True          True\n",
      "...            ...        ...         ...         ...         ...         ...         ...              ...                  ...                  ...                ...               ...           ...\n",
      "LTM     0.55333676 0.02102495 -0.00474595  0.02790623  0.02212168 -0.00329104 -0.04884766              NaN                  NaN                  NaN  63919777.73594999             False         False\n",
      "NBIS    2.98691869 0.08287788 -0.04123437 -0.02304147  0.08619650  0.18125205  0.07904192              NaN                  NaN                  NaN  63919777.73594999             False         False\n",
      "SARO    0.87681548 0.03558504  0.03442485  0.02623907  0.06161137  0.00407498 -0.05918289              NaN                  NaN                  NaN  63919777.73594999             False         False\n",
      "SMBS    0.12778094 0.00537717 -0.00100053  0.01402176  0.01217320  0.00176632 -0.00552819              NaN                  NaN                  NaN  63919777.73594999             False         False\n",
      "TTAN    5.94496678 0.06058874 -0.02241706  0.01964044 -0.03100928 -0.03330049 -0.06792059              NaN                  NaN                  NaN  63919777.73594999             False         False\n",
      "\n",
      "[1561 rows x 13 columns]\n",
      "full_universe_ranking\n",
      "            Strategy_Score  Lookback_Return_Ann  Lookback_ATRP\n",
      "Ticker                                                    \n",
      "A           0.44105365           2.53065642     0.02276886\n",
      "AA          0.11005732           1.08357368     0.03906960\n",
      "AAL         0.21539307           1.89489245     0.03491020\n",
      "AAPL       -0.29456135          -1.43760630     0.01936706\n",
      "ABBV       -0.18171387          -0.87989736     0.01921513\n",
      "...                ...                  ...            ...\n",
      "ZBRA        0.25074999           1.43783959     0.02275459\n",
      "ZION        0.25674500           1.84033508     0.02844424\n",
      "ZM         -0.15280102          -1.08947654     0.02829379\n",
      "ZS          0.09620805           0.85056552     0.03508293\n",
      "ZTS         0.09490106           0.52869614     0.02210724\n",
      "\n",
      "[929 rows x 3 columns]\n",
      "verification  [SEP]\n",
      "    portfolio  [NEST]\n",
      "        full_val\n",
      "            Date\n",
      "2025-01-02   1.00000000\n",
      "2025-01-03   1.00537562\n",
      "2025-01-06   1.00822003\n",
      "2025-01-07   1.01650775\n",
      "2025-01-08   1.01850477\n",
      "2025-01-10   1.04039997\n",
      "2025-01-13   1.04592805\n",
      "2025-01-14   1.05856007\n",
      "2025-01-15   1.06700689\n",
      "2025-01-16   1.07542146\n",
      "2025-01-17   1.09115419\n",
      "2025-01-21   1.09683851\n",
      "2025-01-22   1.08532573\n",
      "2025-01-23   1.09441466\n",
      "2025-01-24   1.09139952\n",
      "2025-01-27   1.08227780\n",
      "2025-01-28   1.08367916\n",
      "dtype: float64\n",
      "        full_ret\n",
      "            Date\n",
      "2025-01-02           NaN\n",
      "2025-01-03    0.00537562\n",
      "2025-01-06    0.00282919\n",
      "2025-01-07    0.00822015\n",
      "2025-01-08    0.00196459\n",
      "2025-01-10    0.02149739\n",
      "2025-01-13    0.00531342\n",
      "2025-01-14    0.01207733\n",
      "2025-01-15    0.00797954\n",
      "2025-01-16    0.00788614\n",
      "2025-01-17    0.01462937\n",
      "2025-01-21    0.00520945\n",
      "2025-01-22   -0.01049633\n",
      "2025-01-23    0.00837438\n",
      "2025-01-24   -0.00275503\n",
      "2025-01-27   -0.00835782\n",
      "2025-01-28    0.00129482\n",
      "dtype: float64\n",
      "        full_atrp\n",
      "            Date\n",
      "2025-01-02   0.01147520\n",
      "2025-01-03   0.01130452\n",
      "2025-01-06   0.01130399\n",
      "2025-01-07   0.01140030\n",
      "2025-01-08   0.01146641\n",
      "2025-01-10   0.01269632\n",
      "2025-01-13   0.01286422\n",
      "2025-01-14   0.01295694\n",
      "2025-01-15   0.01290162\n",
      "2025-01-16   0.01298565\n",
      "2025-01-17   0.01359739\n",
      "2025-01-21   0.01376068\n",
      "2025-01-22   0.01426161\n",
      "2025-01-23   0.01411845\n",
      "2025-01-24   0.01409279\n",
      "2025-01-27   0.01464299\n",
      "2025-01-28   0.01447782\n",
      "dtype: float64\n",
      "        lookback_val\n",
      "            Date\n",
      "2025-01-02   1.00000000\n",
      "2025-01-03   1.00537562\n",
      "2025-01-06   1.00822003\n",
      "2025-01-07   1.01650775\n",
      "2025-01-08   1.01850477\n",
      "2025-01-10   1.04039997\n",
      "2025-01-13   1.04592805\n",
      "2025-01-14   1.05856007\n",
      "2025-01-15   1.06700689\n",
      "2025-01-16   1.07542146\n",
      "2025-01-17   1.09115419\n",
      "dtype: float64\n",
      "        lookback_ret\n",
      "            Date\n",
      "2025-01-02          NaN\n",
      "2025-01-03   0.00537562\n",
      "2025-01-06   0.00282919\n",
      "2025-01-07   0.00822015\n",
      "2025-01-08   0.00196459\n",
      "2025-01-10   0.02149739\n",
      "2025-01-13   0.00531342\n",
      "2025-01-14   0.01207733\n",
      "2025-01-15   0.00797954\n",
      "2025-01-16   0.00788614\n",
      "2025-01-17   0.01462937\n",
      "dtype: float64\n",
      "        lookback_atrp\n",
      "            Date\n",
      "2025-01-02   0.01147520\n",
      "2025-01-03   0.01130452\n",
      "2025-01-06   0.01130399\n",
      "2025-01-07   0.01140030\n",
      "2025-01-08   0.01146641\n",
      "2025-01-10   0.01269632\n",
      "2025-01-13   0.01286422\n",
      "2025-01-14   0.01295694\n",
      "2025-01-15   0.01290162\n",
      "2025-01-16   0.01298565\n",
      "2025-01-17   0.01359739\n",
      "dtype: float64\n",
      "        holding_val\n",
      "            Date\n",
      "2025-01-21   1.09683851\n",
      "2025-01-22   1.08532573\n",
      "2025-01-23   1.09441466\n",
      "2025-01-24   1.09139952\n",
      "2025-01-27   1.08227780\n",
      "2025-01-28   1.08367916\n",
      "dtype: float64\n",
      "        holding_ret\n",
      "            Date\n",
      "2025-01-21           NaN\n",
      "2025-01-22   -0.01049633\n",
      "2025-01-23    0.00837438\n",
      "2025-01-24   -0.00275503\n",
      "2025-01-27   -0.00835782\n",
      "2025-01-28    0.00129482\n",
      "dtype: float64\n",
      "        holding_atrp\n",
      "            Date\n",
      "2025-01-21   0.01376068\n",
      "2025-01-22   0.01426161\n",
      "2025-01-23   0.01411845\n",
      "2025-01-24   0.01409279\n",
      "2025-01-27   0.01464299\n",
      "2025-01-28   0.01447782\n",
      "dtype: float64\n",
      "    benchmark  [NEST]\n",
      "        full_val\n",
      "            Date\n",
      "2025-01-02   1.00000000\n",
      "2025-01-03   1.01250316\n",
      "2025-01-06   1.01833681\n",
      "2025-01-07   1.00682525\n",
      "2025-01-08   1.00829621\n",
      "2025-01-10   0.99290132\n",
      "2025-01-13   0.99444150\n",
      "2025-01-14   0.99581036\n",
      "2025-01-15   1.01392393\n",
      "2025-01-16   1.01197361\n",
      "2025-01-17   1.02213362\n",
      "2025-01-21   1.03148892\n",
      "2025-01-22   1.03728797\n",
      "2025-01-23   1.04295030\n",
      "2025-01-24   1.03990454\n",
      "2025-01-27   1.02519495\n",
      "2025-01-28   1.03400340\n",
      "dtype: float64\n",
      "        full_ret\n",
      "            Date\n",
      "2025-01-02           NaN\n",
      "2025-01-03    0.01250316\n",
      "2025-01-06    0.00576162\n",
      "2025-01-07   -0.01130427\n",
      "2025-01-08    0.00146099\n",
      "2025-01-10   -0.01526822\n",
      "2025-01-13    0.00155119\n",
      "2025-01-14    0.00137651\n",
      "2025-01-15    0.01818978\n",
      "2025-01-16   -0.00192354\n",
      "2025-01-17    0.01003979\n",
      "2025-01-21    0.00915272\n",
      "2025-01-22    0.00562201\n",
      "2025-01-23    0.00545878\n",
      "2025-01-24   -0.00292032\n",
      "2025-01-27   -0.01414514\n",
      "2025-01-28    0.00859198\n",
      "dtype: float64\n",
      "        full_atrp\n",
      "            Date\n",
      "2025-01-02   0.01206429\n",
      "2025-01-03   0.01202478\n",
      "2025-01-06   0.01203170\n",
      "2025-01-07   0.01263125\n",
      "2025-01-08   0.01236373\n",
      "2025-01-10   0.01300477\n",
      "2025-01-13   0.01284348\n",
      "2025-01-14   0.01272560\n",
      "2025-01-15   0.01302130\n",
      "2025-01-16   0.01252737\n",
      "2025-01-17   0.01243965\n",
      "2025-01-21   0.01209537\n",
      "2025-01-22   0.01173050\n",
      "2025-01-23   0.01132900\n",
      "2025-01-24   0.01101822\n",
      "2025-01-27   0.01196654\n",
      "2025-01-28   0.01197660\n",
      "dtype: float64\n",
      "        lookback_val\n",
      "            Date\n",
      "2025-01-02   1.00000000\n",
      "2025-01-03   1.01250316\n",
      "2025-01-06   1.01833681\n",
      "2025-01-07   1.00682525\n",
      "2025-01-08   1.00829621\n",
      "2025-01-10   0.99290132\n",
      "2025-01-13   0.99444150\n",
      "2025-01-14   0.99581036\n",
      "2025-01-15   1.01392393\n",
      "2025-01-16   1.01197361\n",
      "2025-01-17   1.02213362\n",
      "dtype: float64\n",
      "        lookback_ret\n",
      "            Date\n",
      "2025-01-02           NaN\n",
      "2025-01-03    0.01250316\n",
      "2025-01-06    0.00576162\n",
      "2025-01-07   -0.01130427\n",
      "2025-01-08    0.00146099\n",
      "2025-01-10   -0.01526822\n",
      "2025-01-13    0.00155119\n",
      "2025-01-14    0.00137651\n",
      "2025-01-15    0.01818978\n",
      "2025-01-16   -0.00192354\n",
      "2025-01-17    0.01003979\n",
      "dtype: float64\n",
      "        lookback_atrp\n",
      "            Date\n",
      "2025-01-02   0.01206429\n",
      "2025-01-03   0.01202478\n",
      "2025-01-06   0.01203170\n",
      "2025-01-07   0.01263125\n",
      "2025-01-08   0.01236373\n",
      "2025-01-10   0.01300477\n",
      "2025-01-13   0.01284348\n",
      "2025-01-14   0.01272560\n",
      "2025-01-15   0.01302130\n",
      "2025-01-16   0.01252737\n",
      "2025-01-17   0.01243965\n",
      "dtype: float64\n",
      "        holding_val\n",
      "            Date\n",
      "2025-01-21   1.03148892\n",
      "2025-01-22   1.03728797\n",
      "2025-01-23   1.04295030\n",
      "2025-01-24   1.03990454\n",
      "2025-01-27   1.02519495\n",
      "2025-01-28   1.03400340\n",
      "dtype: float64\n",
      "        holding_ret\n",
      "            Date\n",
      "2025-01-21           NaN\n",
      "2025-01-22    0.00562201\n",
      "2025-01-23    0.00545878\n",
      "2025-01-24   -0.00292032\n",
      "2025-01-27   -0.01414514\n",
      "2025-01-28    0.00859198\n",
      "dtype: float64\n",
      "        holding_atrp\n",
      "            Date\n",
      "2025-01-21   0.01209537\n",
      "2025-01-22   0.01173050\n",
      "2025-01-23   0.01132900\n",
      "2025-01-24   0.01101822\n",
      "2025-01-27   0.01196654\n",
      "2025-01-28   0.01197660\n",
      "dtype: float64\n",
      "portfolio_raw_components  [NEST]\n",
      "    prices\n",
      "        Ticker            RPRX        SGOV          SHV         BIL          SNX        MINT         TRGP        QRVO          LNG        USFR\n",
      "Date                                                                                                                                  \n",
      "2025-01-02 25.15610000 96.31500000 105.72100000 87.76050000 114.93600000 96.12510000 179.09300000 69.76000000 218.58000000 48.43870000\n",
      "2025-01-03 25.20490000 96.34380000 105.75000000 87.77010000 116.36700000 96.17310000 182.13600000 70.63000000 220.44300000 48.44830000\n",
      "2025-01-06 25.11710000 96.34380000 105.76900000 87.77970000 116.73200000 96.19220000 182.12600000 72.14000000 221.86000000 48.45790000\n",
      "2025-01-07 25.40000000 96.36300000 105.78800000 87.79880000 121.59600000 96.18260000 183.75000000 73.63000000 221.46400000 48.46760000\n",
      "2025-01-08 25.55600000 96.38220000 105.78800000 87.81800000 120.48100000 96.22100000 187.82000000 73.08000000 223.12800000 48.47720000\n",
      "2025-01-10 28.76520000 96.42060000 105.81700000 87.84680000 132.23400000 96.23060000 189.11200000 71.69000000 223.15800000 48.50610000\n",
      "2025-01-13 29.25290000 96.43980000 105.83600000 87.85640000 131.07900000 96.24970000 193.19100000 71.91000000 227.33900000 48.51570000\n",
      "2025-01-14 29.29190000 96.44940000 105.84600000 87.87560000 134.23700000 96.26890000 197.01700000 72.82000000 240.86400000 48.53490000\n",
      "2025-01-15 29.98450000 96.45900000 105.86500000 87.88520000 134.45400000 96.29760000 201.04700000 74.16000000 243.62900000 48.53490000\n",
      "2025-01-16 30.18930000 96.45900000 105.87500000 87.88520000 135.35200000 96.32640000 208.33600000 73.59000000 251.33800000 48.53490000\n",
      "2025-01-17 29.99420000 96.50700000 105.92300000 87.93320000 135.28300000 96.37430000 211.04600000 84.21000000 250.44600000 48.55420000\n",
      "2025-01-21 29.55530000 96.51660000 105.94200000 87.93320000 138.90400000 96.37430000 212.51300000 87.58000000 247.34400000 48.56380000\n",
      "2025-01-22 29.34070000 96.53580000 105.94200000 87.95240000 139.62400000 96.39340000 206.69200000 87.09000000 231.22300000 48.55420000\n",
      "2025-01-23 29.86740000 96.54540000 105.96100000 87.95240000 141.29200000 96.41260000 206.81000000 90.57000000 232.14500000 48.56380000\n",
      "2025-01-24 30.29660000 96.57420000 106.00000000 87.99080000 141.04400000 96.46050000 204.54000000 88.94000000 229.73700000 48.58310000\n",
      "2025-01-27 30.94040000 96.57420000 106.01900000 88.00040000 139.74800000 96.46050000 194.92300000 87.63000000 222.40500000 48.59270000\n",
      "2025-01-28 31.15500000 96.60300000 106.02800000 88.00040000 140.34200000 96.46050000 197.98500000 85.78000000 224.39700000 48.60430000\n",
      "    atrp\n",
      "        Ticker           RPRX       SGOV        SHV        BIL        SNX       MINT       TRGP       QRVO        LNG       USFR\n",
      "Date                                                                                                                    \n",
      "2025-01-02 0.01840948 0.00024398 0.00025470 0.00024212 0.02136244 0.00034719 0.02449333 0.02976644 0.01927521 0.00035710\n",
      "2025-01-03 0.01771124 0.00025496 0.00026279 0.00024816 0.02090066 0.00037206 0.02410977 0.02912015 0.01908277 0.00035984\n",
      "2025-01-06 0.01843147 0.00025098 0.00025680 0.00024603 0.02120665 0.00035960 0.02363957 0.02869206 0.01857627 0.00034822\n",
      "2025-01-07 0.01832335 0.00025435 0.00025125 0.00025176 0.02177317 0.00035526 0.02369678 0.02810189 0.01866388 0.00035172\n",
      "2025-01-08 0.01856028 0.00025037 0.00023938 0.00024934 0.02237039 0.00035826 0.02340260 0.02805032 0.01872401 0.00034068\n",
      "2025-01-10 0.02423748 0.00026795 0.00024854 0.00026268 0.02552493 0.00037532 0.02337096 0.02835515 0.01927464 0.00035872\n",
      "2025-01-13 0.02520348 0.00026298 0.00024357 0.00025950 0.02598075 0.00036974 0.02312422 0.02810174 0.01943660 0.00034716\n",
      "2025-01-14 0.02463254 0.00025128 0.00023290 0.00025652 0.02545279 0.00036463 0.02342839 0.02701902 0.02114266 0.00036462\n",
      "2025-01-15 0.02422690 0.00024042 0.00022905 0.00024597 0.02546818 0.00036689 0.02286185 0.02677881 0.02101338 0.00035271\n",
      "2025-01-16 0.02460098 0.00023746 0.00021941 0.00023620 0.02476764 0.00036906 0.02303524 0.02641752 0.02164561 0.00034164\n",
      "2025-01-17 0.02429546 0.00026302 0.00023602 0.00025820 0.02393793 0.00038514 0.02339331 0.03067403 0.02194021 0.00034550\n",
      "2025-01-21 0.02417985 0.00025842 0.00023193 0.00024756 0.02420076 0.00036475 0.02279889 0.03139969 0.02239995 0.00034900\n",
      "2025-01-22 0.02398243 0.00025412 0.00022211 0.00024542 0.02338605 0.00036701 0.02510699 0.03124830 0.02740132 0.00033826\n",
      "2025-01-23 0.02328792 0.00024305 0.00021901 0.00023568 0.02288084 0.00036206 0.02479722 0.03118613 0.02655932 0.00034228\n",
      "2025-01-24 0.02244487 0.00025402 0.00023564 0.00024993 0.02249168 0.00037150 0.02485335 0.03180463 0.02737011 0.00036019\n",
      "2025-01-27 0.02223201 0.00025008 0.00023157 0.00023984 0.02212100 0.00035911 0.02854408 0.03325928 0.02942863 0.00036262\n",
      "2025-01-28 0.02166237 0.00025344 0.00022107 0.00023050 0.02132533 0.00034057 0.02756005 0.03478886 0.02860427 0.00036500\n",
      "benchmark_raw_components  [NEST]\n",
      "    atrp\n",
      "        Ticker            SPY\n",
      "Date                 \n",
      "2025-01-02 0.01206429\n",
      "2025-01-03 0.01202478\n",
      "2025-01-06 0.01203170\n",
      "2025-01-07 0.01263125\n",
      "2025-01-08 0.01236373\n",
      "2025-01-10 0.01300477\n",
      "2025-01-13 0.01284348\n",
      "2025-01-14 0.01272560\n",
      "2025-01-15 0.01302130\n",
      "2025-01-16 0.01252737\n",
      "2025-01-17 0.01243965\n",
      "2025-01-21 0.01209537\n",
      "2025-01-22 0.01173050\n",
      "2025-01-23 0.01132900\n",
      "2025-01-24 0.01101822\n",
      "2025-01-27 0.01196654\n",
      "2025-01-28 0.01197660\n"
     ]
    }
   ],
   "source": [
    "print_nested(debug_container[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2e9dfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHV\n",
      "                   Adj Open     Adj High      Adj Low    Adj Close   Volume        ATR       ATRP      ROC_1      ROC_3      ROC_5     ROC_10     ROC_21  RollingStalePct   RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                         \n",
      "2025-11-26 109.71200000 109.72200000 109.71200000 109.71200000  1910952 0.01921050 0.00017510 0.00018233 0.00036472 0.00081187 0.00154277 0.00291609       0.00000000 329635724.89749998           0.00000000\n",
      "2025-11-28 109.75200000 109.75200000 109.74200000 109.74200000  2520560 0.02069547 0.00018858 0.00027344 0.00054704 0.00099423 0.00172519 0.00328205       0.00000000 326997819.68349993           0.00000000\n",
      "2025-12-01 109.76400000 109.76400000 109.75400000 109.76400000  3517277 0.02078865 0.00018939 0.00020047 0.00065638 0.00083886 0.00165172 0.00339144       0.00000000 326997819.68349993           0.00000000\n",
      "2025-12-02 109.77400000 109.78400000 109.77400000 109.78400000  1894327 0.02073232 0.00018885 0.00018221 0.00065626 0.00092996 0.00174281 0.00339082       0.00000000 326997819.68349993           0.00000000\n",
      "2025-12-03 109.79400000 109.80400000 109.79400000 109.80400000  4593358 0.02068001 0.00018834 0.00018218 0.00056496 0.00102104 0.00174249 0.00328935       0.00000000 326997819.68349993           0.00000000\n",
      "2025-12-04 109.81400000 109.82400000 109.80400000 109.80400000  3680806 0.02063144 0.00018789 0.00000000 0.00036442 0.00083856 0.00165111 0.00319769       0.00000000 326997819.68349993           0.00000000\n",
      "2025-12-05 109.84400000 109.85300000 109.84400000 109.84400000  2297632 0.02265776 0.00020627 0.00036429 0.00054653 0.00092945 0.00192460 0.00347146       0.00000000 326997819.68349993           0.00000000\n",
      "2025-12-08 109.85300000 109.86300000 109.85300000 109.85300000  2931683 0.02239649 0.00020388 0.00008193 0.00044625 0.00081083 0.00165038 0.00337036       0.00000000 325423431.75999999           0.00000000\n",
      "2025-12-09 109.87300000 109.87300000 109.86300000 109.86300000  2471494 0.02222532 0.00020230 0.00009103 0.00053732 0.00071959 0.00165023 0.00310437       0.00000000 325423431.75999999           0.00000000\n",
      "2025-12-10 109.88300000 109.89300000 109.87300000 109.89300000  4019502 0.02278065 0.00020730 0.00027307 0.00044609 0.00081054 0.00183240 0.00328668       0.00000000 326997819.68349993           0.00000000\n",
      "2025-12-11 109.90300000 109.91300000 109.89300000 109.91300000  2282884 0.02258203 0.00020545 0.00018200 0.00054618 0.00099268 0.00183207 0.00346927       0.00000000 326997819.68349993           0.00000000\n",
      "2025-12-12 109.94300000 109.94300000 109.93300000 109.94300000  1890013 0.02311189 0.00021022 0.00027294 0.00072818 0.00090128 0.00183157 0.00365153       0.00000000 326997819.68349993           0.00000000\n",
      "2025-12-15 109.96300000 109.96300000 109.95300000 109.96300000  2462967 0.02288961 0.00020816 0.00018191 0.00063698 0.00100134 0.00181298 0.00374248       0.00000000 326997819.68349993           0.00000000\n",
      "2025-12-16 109.97300000 109.97300000 109.96300000 109.97300000  2432669 0.02196892 0.00019977 0.00009094 0.00054589 0.00100125 0.00172156 0.00355895       0.00000000 326997819.68349993           0.00000000\n",
      "2025-12-17 109.98300000 109.98300000 109.97300000 109.98300000  1993147 0.02111400 0.00019198 0.00009093 0.00036382 0.00081898 0.00163018 0.00355862       0.00000000 326997819.68349993           0.00000000\n",
      "2025-12-18 109.99300000 110.00300000 109.99300000 110.00300000  2107818 0.02103443 0.00019122 0.00018185 0.00036376 0.00081883 0.00181232 0.00355797       0.00000000 326997819.68349993           0.00000000\n",
      "2025-12-19 110.02000000 110.03000000 110.02000000 110.02000000  3178600 0.02146054 0.00019506 0.00015454 0.00042738 0.00070036 0.00160227 0.00362150       0.00000000 329635724.89749998           0.00000000\n",
      "CFLT\n",
      "                  Adj Open    Adj High     Adj Low   Adj Close     Volume        ATR       ATRP       ROC_1       ROC_3       ROC_5      ROC_10      ROC_21  RollingStalePct   RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                            \n",
      "2025-11-26 21.83000000 22.15500000 21.58000000 21.83000000    4071600 1.02367776 0.04689316  0.00000000  0.05306319 -0.03535130 -0.10385878 -0.08084211       0.00000000 124871108.00000000           0.00000000\n",
      "2025-11-28 22.03000000 22.40000000 21.84000000 22.25000000    1861800 0.99127221 0.04455156  0.01923958  0.05650522  0.03392193 -0.04914530 -0.05919662       0.00000000 124114517.00000000           0.00000000\n",
      "2025-12-01 21.84000000 22.63500000 21.66000000 21.87000000    5725100 0.99010991 0.04527252 -0.01707865  0.00183234  0.05499276 -0.06137339 -0.07015306       0.00000000 124114517.00000000           0.00000000\n",
      "2025-12-02 22.45000000 23.17000000 22.41000000 23.06000000    4780600 1.01224491 0.04389614  0.05441244  0.05634448  0.09496676  0.01765225 -0.01326487       0.00000000 124114517.00000000           0.00000000\n",
      "2025-12-03 23.02500000 23.66500000 22.41500000 23.65000000    6132700 1.02922742 0.04351913  0.02558543  0.06292135  0.08337151  0.04368932  0.00895904       0.00000000 124681543.50000000           0.00000000\n",
      "2025-12-04 23.48000000 23.77000000 23.21500000 23.35000000    5132900 0.99535403 0.04262758 -0.01268499  0.06767261  0.06962895  0.03181617  0.02999559       0.00000000 124681543.50000000           0.00000000\n",
      "2025-12-05 23.11000000 23.50500000 22.91000000 23.14000000    5564000 0.96675732 0.04177862 -0.00899358  0.00346921  0.04000000  0.07527881  0.02661934       0.00000000 125397501.50000000           0.00000000\n",
      "2025-12-08 29.84000000 29.95000000 29.70000000 29.87000000  146309900 1.38413179 0.04633853  0.29083838  0.26300211  0.36579790  0.44090690  0.32109686       0.00000000 125397501.50000000           0.00000000\n",
      "2025-12-09 29.83300000 29.90000000 29.80000000 29.90000000   55523200 1.29240809 0.04322435  0.00100435  0.28051392  0.29661752  0.41975309  0.31834215       0.00000000 125825077.00000000           0.00000000\n",
      "2025-12-10 29.89000000 30.04000000 29.88000000 30.00000000   32223700 1.21152180 0.04038406  0.00334448  0.29645635  0.26849894  0.37425561  0.27496813       0.00000000 126202207.00000000           0.00000000\n",
      "2025-12-11 30.01000000 30.22500000 30.00000000 30.14000000   19440400 1.14105596 0.03785853  0.00466667  0.00903917  0.29079229  0.38066880  0.23271984       0.00000000 126202207.00000000           0.00000000\n",
      "2025-12-12 30.10000000 30.13000000 30.02000000 30.05000000   12145100 1.06812339 0.03554487 -0.00298607  0.00501672  0.29861711  0.35056180  0.23357964       0.00000000 126202207.00000000           0.00000000\n",
      "2025-12-15 30.08000000 30.15000000 30.05000000 30.07000000   17174900 0.99897172 0.03322154  0.00066556  0.00233333  0.00669568  0.37494284  0.28504274       0.00000000 127276927.00000000           0.00000000\n",
      "2025-12-16 30.08000000 30.10000000 29.96000000 29.96000000   19851800 0.93761660 0.03129561 -0.00365813 -0.00597213  0.00200669  0.29921943  0.28583691       0.00000000 128481744.00000000           0.00000000\n",
      "2025-12-17 30.01000000 30.04500000 30.00000000 30.00000000   11790800 0.87671541 0.02922385  0.00133511 -0.00166389  0.00000000  0.26849894  0.32391880       0.00000000 128481744.00000000           0.00000000\n",
      "2025-12-18 30.04000000 30.07000000 29.95000000 29.95000000   15446800 0.82266431 0.02746792 -0.00166667 -0.00399069 -0.00630392  0.28265525  0.32171227       0.00000000 128830928.00000000           0.00000000\n",
      "2025-12-19 29.98000000 30.02500000 29.94500000 29.96000000   13172300 0.76961686 0.02568815  0.00033389  0.00000000 -0.00299501  0.29472774  0.32390632       0.00000000 129118550.00000000           0.00000000\n"
     ]
    }
   ],
   "source": [
    "my_tickers = [\"SHV\", \"CFLT\"]\n",
    "date_start = \"2025-11-26\"\n",
    "date_end = \"2025-12-19\"\n",
    "\n",
    "# Create combined dictionary\n",
    "combined_dict = create_combined_dict(\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    features_df=my_features,\n",
    "    tickers=my_tickers,\n",
    "    date_start=date_start,\n",
    "    date_end=date_end,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print_nested(combined_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2056f0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üöÄ STARTING FULL SYSTEM AUDIT\n",
      "================================================================================\n",
      "\n",
      ">>> Running Engine Integrity Check...\n",
      "METRIC                         | REPORTED     | CALCULATED   | DIFF         | STATUS\n",
      "-------------------------------------------------------------------------------------\n",
      "lookback_p_gain                |     0.091154 |     0.091154 |  0.000000000 | ‚úÖ PASS\n",
      "lookback_p_sharpe              |    23.587818 |    23.587818 |  0.000000000 | ‚úÖ PASS\n",
      "lookback_p_sharpe_atr          |     0.715437 |     0.715437 |  0.000000000 | ‚úÖ PASS\n",
      "holding_p_gain                 |    -0.011998 |    -0.011998 |  0.000000000 | ‚úÖ PASS\n",
      "holding_p_sharpe               |    -4.989321 |    -4.989321 |  0.000000000 | ‚úÖ PASS\n",
      "holding_p_sharpe_atr           |    -0.167864 |    -0.167864 |  0.000000000 | ‚úÖ PASS\n",
      "lookback_b_gain                |     0.022134 |     0.022134 |  0.000000000 | ‚úÖ PASS\n",
      "lookback_b_sharpe              |     3.473488 |     3.473488 |  0.000000000 | ‚úÖ PASS\n",
      "lookback_b_sharpe_atr          |     0.178865 |     0.178865 |  0.000000000 | ‚úÖ PASS\n",
      "holding_b_gain                 |     0.002438 |     0.002438 |  0.000000000 | ‚úÖ PASS\n",
      "holding_b_sharpe               |     0.894611 |     0.894611 |  0.000000000 | ‚úÖ PASS\n",
      "holding_b_sharpe_atr           |     0.044623 |     0.044623 |  0.000000000 | ‚úÖ PASS\n",
      "\n",
      ">>> Running Portfolio Construction Auditor...\n",
      "--- üèóÔ∏è PORTFOLIO CONSTRUCTION AUDIT ---\n",
      "Period: 2025-01-02 to 2025-01-28\n",
      "Tickers (10): RPRX, SGOV, SHV, BIL, SNX, MINT, TRGP, QRVO, LNG, USFR\n",
      "\n",
      "1. WEIGHT DISTRIBUTION:\n",
      "RPRX   0.10000000\n",
      "SGOV   0.10000000\n",
      "SHV    0.10000000\n",
      "BIL    0.10000000\n",
      "SNX    0.10000000\n",
      "MINT   0.10000000\n",
      "TRGP   0.10000000\n",
      "QRVO   0.10000000\n",
      "LNG    0.10000000\n",
      "USFR   0.10000000\n",
      "‚úÖ Weights sum to 1.0\n",
      "\n",
      "2. SERIES COMPARISON:\n",
      "\n",
      "--- Start of Simulation (Head) ---\n",
      "            Shadow_Calc  Engine_Output  Difference\n",
      "Date                                              \n",
      "2025-01-02   1.00000000     1.00000000  0.00000000\n",
      "2025-01-03   1.00537562     1.00537562  0.00000000\n",
      "2025-01-06   1.00822003     1.00822003  0.00000000\n",
      "2025-01-07   1.01650775     1.01650775  0.00000000\n",
      "2025-01-08   1.01850477     1.01850477  0.00000000\n",
      "\n",
      "--- Entry Date (T+1: 2025-01-21) ---\n",
      "            Shadow_Calc  Engine_Output  Difference\n",
      "Date                                              \n",
      "2025-01-21   1.09683851     1.09683851  0.00000000\n",
      "\n",
      "--- End of Simulation (Tail) ---\n",
      "            Shadow_Calc  Engine_Output  Difference\n",
      "Date                                              \n",
      "2025-01-22   1.08532573     1.08532573  0.00000000\n",
      "2025-01-23   1.09441466     1.09441466  0.00000000\n",
      "2025-01-24   1.09139952     1.09139952  0.00000000\n",
      "2025-01-27   1.08227780     1.08227780  0.00000000\n",
      "2025-01-28   1.08367916     1.08367916  0.00000000\n",
      "------------------------------------------------------------\n",
      "‚úÖ SUCCESS: Portfolio Construction Verified (Max Error: 0.000000000000)\n",
      "\n",
      ">>> Running Ticker Ranking Logic Auditor...\n",
      "--- üïµÔ∏è TICKER SELECTION AUDIT ---\n",
      "Decision Date: 2025-01-17\n",
      "Strategy:      Sharpe (ATR)\n",
      "Rank Window:   1 to 10\n",
      "\n",
      "1. UNIVERSE FILTERING:\n",
      "   Total Tickers: 1561\n",
      "   Eligible:      929\n",
      "\n",
      "2. SELECTION COMPARISON:\n",
      "     Shadow_Ticker  Shadow_Score Engine_Ticker  MATCH\n",
      "Rank                                                 \n",
      "1             RPRX    0.84695201          RPRX   True\n",
      "2             SGOV    0.78875453          SGOV   True\n",
      "3              SHV    0.78522923           SHV   True\n",
      "4              BIL    0.78463742           BIL   True\n",
      "5              SNX    0.71752921           SNX   True\n",
      "6             MINT    0.70803663          MINT   True\n",
      "7             TRGP    0.70611655          TRGP   True\n",
      "8             QRVO    0.70285869          QRVO   True\n",
      "9              LNG    0.69695735           LNG   True\n",
      "10            USFR    0.67743481          USFR   True\n",
      "------------------------------------------------------------\n",
      "‚úÖ SUCCESS: Ticker Selection Logic Verified (Exact Match).\n",
      "\n",
      "================================================================================\n",
      "AUDIT MODULE                             | STATUS\n",
      "--------------------------------------------------------------------------------\n",
      "Math Integrity                           | ‚úÖ EXECUTED\n",
      "Portfolio Construction                   | ‚úÖ EXECUTED\n",
      "Ranking Logic                            | ‚úÖ EXECUTED\n",
      "--------------------------------------------------------------------------------\n",
      "‚ÑπÔ∏è  NOTE: Check individual module outputs above for specific math failures.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# EXECUTION\n",
    "# ==============================================================================\n",
    "# Run this after clicking \"Run Simulation\" in the UI\n",
    "# Assuming global variables: precomputed_close, precomputed_features\n",
    "run_full_system_audit(\n",
    "    df_close_wide=my_close_matrix,\n",
    "    features_df=my_features,\n",
    "    res_container=results_container,\n",
    "    deb_container=debug_container,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86cc1ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COHR\n",
      "                   Adj Open     Adj High      Adj Low    Adj Close    Volume        ATR       ATRP       ROC_1       ROC_3       ROC_5      ROC_10      ROC_21  RollingStalePct   RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                               \n",
      "2025-07-30 107.17000000 109.09000000 105.13000000 107.23000000   2307400 3.72104923 0.03470157  0.00233689  0.07080088  0.08940364  0.09619710  0.20199529       0.00000000 229447054.00000000           0.00000000\n",
      "2025-07-31 109.66000000 111.61000000 106.83000000 107.60000000   3412300 3.79668857 0.03528521  0.00345053  0.03163950  0.08995138  0.07299561  0.24192059       0.00000000 230610042.50000000           0.00000000\n",
      "2025-08-01 101.50000000 104.60000000  98.95000000 102.79000000   3434300 4.14335368 0.04030892 -0.04470260 -0.03916620  0.02646295  0.03202811  0.16330919       0.00000000 230610042.50000000           0.00000000\n",
      "2025-08-04 103.84000000 106.84000000 102.67000000 106.74000000   2453500 4.14525699 0.03883509  0.03842786 -0.00456962  0.02339406  0.06868242  0.17425743       0.00000000 231129099.50000000           0.00000000\n",
      "2025-08-05 107.26000000 107.99000000 103.77000000 105.60000000   2126200 4.15059577 0.03930488 -0.01068016 -0.01858736 -0.01289961  0.08843537  0.19931857       0.00000000 231129099.50000000           0.00000000\n",
      "2025-08-06 108.17000000 108.45000000 105.05000000 107.15000000   2456800 4.09698179 0.03823595  0.01467803  0.04241658 -0.00074606  0.08859088  0.18528761       0.00000000 231646769.00000000           0.00000000\n",
      "2025-08-07 111.96000000 114.26000000 110.36000000 113.82000000   4458300 4.31219738 0.03788611  0.06224918  0.06632940  0.05780669  0.15295786  0.24734247       0.00000000 232258130.00000000           0.00000000\n",
      "2025-08-08 114.23000000 115.92000000 112.59000000 115.44000000   3484900 4.24204042 0.03674671  0.01423300  0.09318182  0.12306645  0.15278610  0.23175416       0.00000000 232892836.00000000           0.00000000\n",
      "2025-08-11 115.06000000 118.00000000 113.52000000 113.60000000   4006200 4.25903753 0.03749153 -0.01593902  0.06019599  0.06426832  0.08916587  0.21757771       0.00000000 233900596.00000000           0.00000000\n",
      "2025-08-12 114.60000000 118.00000000 114.26000000 116.56000000   4019300 4.26910628 0.03662583  0.02605634  0.02407310  0.10378788  0.08954945  0.23317816       0.00000000 234987207.00000000           0.00000000\n",
      "2025-08-13 120.36000000 123.25000000 112.14000000 114.01000000  10793700 4.75774155 0.04173091 -0.02187714 -0.01238739  0.06402240  0.06322857  0.18673884       0.00000000 236791245.00000000           0.00000000\n",
      "2025-08-14  91.10000000  93.08000000  86.50000000  91.65000000  28971800 6.38290286 0.06964433 -0.19612315 -0.19322183 -0.19478123 -0.14823420 -0.06307504       0.00000000 238410948.00000000           0.00000000\n",
      "2025-08-15  91.25000000  95.37000000  90.29000000  93.40000000   8990800 6.28983837 0.06734302  0.01909438 -0.19869595 -0.19092169 -0.09135130 -0.06860790       0.00000000 239136348.00000000           0.00000000\n",
      "2025-08-18  92.08000000  93.25000000  89.90000000  90.49000000   4692800 6.09056420 0.06730649 -0.03115632 -0.20629769 -0.20343310 -0.15223909 -0.09146586       0.00000000 239965808.00000000           0.00000000\n",
      "2025-08-19  89.85000000  90.07000000  87.75000000  87.76000000   4490000 5.85123819 0.06667318 -0.03016908 -0.04244408 -0.24708305 -0.16893939 -0.12134561       0.00000000 239965808.00000000           0.00000000\n",
      "2025-08-20  86.50000000  87.24000000  84.35000000  86.55000000   4682600 5.67686403 0.06559057 -0.01378760 -0.07334047 -0.24085607 -0.19225385 -0.10791589       0.00000000 239965808.00000000           0.00000000\n",
      "2025-08-21  86.33000000  87.45000000  85.52000000  86.60000000   3057700 5.40923089 0.06246225  0.00057770 -0.04298818 -0.05510093 -0.23914953 -0.12018693       0.00000000 239965808.00000000           0.00000000\n",
      "APP\n",
      "                   Adj Open     Adj High      Adj Low    Adj Close    Volume         ATR       ATRP       ROC_1       ROC_3       ROC_5      ROC_10     ROC_21  RollingStalePct    RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                                \n",
      "2025-07-30 362.53000000 366.80000000 358.55000000 363.31000000   2247100 16.21809674 0.04463983  0.00464563 -0.00227934  0.00328620  0.02196906 0.03779136       0.00000000 1570080901.50000000           0.00000000\n",
      "2025-07-31 380.00000000 397.92000000 377.52000000 390.70000000   7940700 17.53180412 0.04487280  0.07539016  0.05321328  0.08545869  0.07400077 0.16041462       0.00000000 1590490686.50000000           0.00000000\n",
      "2025-08-01 377.46000000 385.92000000 366.47000000 379.17000000   6336300 18.01024668 0.04749913 -0.02951113  0.04850261  0.04127533  0.04036108 0.12848214       0.00000000 1595553107.50000000           0.00000000\n",
      "2025-08-04 383.01000000 395.56000000 368.18800000 395.01000000   4986200 18.67894334 0.04728727  0.04177546  0.08725331  0.06483179  0.07876123 0.15621707       0.00000000 1596847903.50000000           0.00000000\n",
      "2025-08-05 398.00000000 399.94000000 376.90900000 377.93000000   6389800 18.98980453 0.05024688 -0.04323941 -0.03268492  0.04507369  0.07980000 0.09544928       0.00000000 1598124716.00000000           0.00000000\n",
      "2025-08-06 385.19000000 393.45000000 378.36000000 390.57000000  12843900 18.74196135 0.04798618  0.03344535  0.03006567  0.07503234  0.07856512 0.13290790       0.00000000 1615124662.50000000           0.00000000\n",
      "2025-08-07 397.25000000 453.76000000 385.10000000 437.34000000  20738700 22.30753554 0.05100731  0.11974806  0.10716184  0.11937548  0.21503584 0.23983671       0.00000000 1641910251.50000000           0.00000000\n",
      "2025-08-08 448.60000000 464.98000000 447.01800000 455.98000000   9487800 22.68842586 0.04975750  0.04262130  0.20651973  0.20257404  0.25221069 0.31664357       0.00000000 1654918995.00000000           0.00000000\n",
      "2025-08-11 455.00000000 473.70000000 449.21100000 465.58000000   5976600 22.81703830 0.04900777  0.02105355  0.19205264  0.17865370  0.25506793 0.38937631       0.00000000 1661124167.00000000           0.00000000\n",
      "2025-08-12 466.92000000 470.28000000 458.48000000 467.00000000   4536800 22.03010699 0.04717368  0.00304996  0.06781909  0.23567856  0.29137516 0.31216634       0.00000000 1665113442.00000000           0.00000000\n",
      "2025-08-13 470.38000000 472.05000000 438.77000000 446.40000000   6334100 22.83367078 0.05115070 -0.04411135 -0.02100969  0.14294493  0.22870276 0.26473255       0.00000000 1667215018.00000000           0.00000000\n",
      "2025-08-14 434.58000000 445.00000000 426.00000000 433.34000000   5005100 22.65983715 0.05229113 -0.02925627 -0.06924696 -0.00914620  0.10913745 0.21895921       0.00000000 1670167137.00000000           0.00000000\n",
      "2025-08-15 434.50000000 441.50000000 421.40000000 438.68000000   3404000 22.47699164 0.05123779  0.01232289 -0.06064240 -0.03794026  0.15694807 0.20589367       0.00000000 1670167137.00000000           0.00000000\n",
      "2025-08-18 438.00500000 444.00000000 432.61000000 438.54000000   2713000 21.68506367 0.04944831 -0.00031914 -0.01760753 -0.05807810  0.11019974 0.20325962       0.00000000 1670167137.00000000           0.00000000\n",
      "2025-08-19 430.64000000 434.07000000 407.52000000 412.60000000   5456700 22.35184483 0.05417316 -0.05915082 -0.04786080 -0.11648822  0.09173656 0.12679903       0.00000000 1672790536.00000000           0.00000000\n",
      "2025-08-20 405.02000000 412.81000000 385.19000000 412.38000000   6374400 22.72814163 0.05511456 -0.00053320 -0.05995259 -0.07620968  0.05584146 0.17822857       0.00000000 1676028960.00000000           0.00000000\n",
      "2025-08-21 411.62000000 431.86000000 408.80000000 418.76000000   5061500 22.75184580 0.05433147  0.01547117 -0.04510421 -0.03364564 -0.04248411 0.15641224       0.00000000 1677867128.00000000           0.00000000\n"
     ]
    }
   ],
   "source": [
    "my_tickers = [\"COHR\", \"APP\"]\n",
    "date_start = \"2025-07-30\"\n",
    "date_end = \"2025-08-21\"\n",
    "\n",
    "# Create combined dictionary\n",
    "combined_dict = create_combined_dict(\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    features_df=my_features,\n",
    "    tickers=my_tickers,\n",
    "    date_start=date_start,\n",
    "    date_end=date_end,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print_nested(combined_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bcc3faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "_rows = debug_container[0][\"full_universe_ranking\"]\n",
    "pd.DataFrame(_rows).to_csv(\"GOLDEN_bot_v45_full_universe_ranking.csv\", index=True)\n",
    "\n",
    "_rows = debug_container[0][\"audit_liquidity\"][\"universe_snapshot\"]\n",
    "pd.DataFrame(_rows).to_csv(\"GOLDEN_bot_v45_universe_snapshot.csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d210b89",
   "metadata": {},
   "source": [
    "================================  \n",
    "================================  \n",
    "================================  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
