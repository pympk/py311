{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6df4ac28",
   "metadata": {},
   "source": [
    "v53  \n",
    "Looking at this registry with a quant lens, the list is **comprehensive but bloated**â€”we have **momentum measured five times under different names** (rocâ‚, rocâ‚ƒ, rocâ‚…, rocâ‚â‚€, rocâ‚‚â‚ and their negative twins â€œPullbackâ€).  \n",
    "Thatâ€™s **10 slots** telling us almost the same story at slightly different lags; in a rank-based engine they will **crowd the signal space** and inflate turnover without adding IC.\n",
    "\n",
    "Duplicate / redundant cluster  \n",
    "- Momentum 1 D â†” Pullback 1 D (perfect mirror)  \n",
    "- Same for 3 D, 5 D, 10 D, 21 D.  \n",
    "**Keep one side only**â€”momentum is enough; the portfolio constructor can always **reverse the rank** if it wants â€œoversoldâ€.\n",
    "\n",
    "Close cousins that can be merged  \n",
    "- â€œSharpeâ€ vs â€œSharpe (ATRP)â€ â€“ both are return / vol; keep **ATRP version** because it is regime-aware and smoother.  \n",
    "- â€œRVolâ€ vs â€œVol_Regimeâ€ â€“ both capture vol expansion; keep the **longer-memory one** (Vol_Regime) and drop the intraday snapshot.\n",
    "\n",
    "Gaps that matter to a quant  \n",
    "1. **Consistency sensor**: nowhere do we ask â€œhow often did the ticker close higher than it opened?â€ â€“ add **5-day win-rate** or **up-day hit-ratio**.  \n",
    "2. **Risk-adjusted intraday strength**: no **Sharpe(on-balance volume)** or **volume-momentum efficiency**; OBV_Score is raw, not risk-scaled.  \n",
    "3. **Benchmark-relative consistency**: â€œAlpha (RelStrength)â€ is cumulative; add **rolling information ratio vs SPY** to catch *sustained* alpha, not one gap.  \n",
    "4. **Tail flag**: no **skew** or **max-drawdown** metric; a single 20 % gap stock can poison the book.  \n",
    "5. **Macro regime overlay**: no **beta-to-SPY** or **correlation-break** sensor; mid-2022 macro swings showed that low-beta names behaved like a different asset class.\n",
    "\n",
    "Recommended minimal clean set (â‰¤ 12 metrics)\n",
    "\n",
    "1. Sharpe(ATRP) â€“ strategic anchor  \n",
    "2. Momentum 21 D â€“ slow trend  \n",
    "3. Momentum 5 D â€“ fast trend  \n",
    "4. 5-day win-rate â€“ consistency  \n",
    "5. RSI(Trend) â€“ strength confirmation  \n",
    "6. OBV_Score â€“ volume conviction  \n",
    "7. Vol_Regime â€“ vol expansion filter  \n",
    "8. Alpha(RelStrength) 63-day IR â€“ benchmark consistency  \n",
    "9. Max 21-day drawdown â€“ tail guard  \n",
    "10. Beta-to-SPY â€“ macro regime tag  \n",
    "\n",
    "Drop everything else; the freed-up slots reduce collinearity, cut turnover, and leave head-room for **interaction terms** (e.g. momentum Ã— consistency) that actually add orthogonal signal.\n",
    "\n",
    "\n",
    "\n",
    "Below is a single, fully-vectorised block that adds the **five gap metrics** to your existing MultiIndex OHLCV frame.  \n",
    "It never loops over tickers; everything is done with `groupby(level=0).rolling(...)` so it runs in C-speed and keeps the same index.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ----------  CONFIG  -------------------------------------------------\n",
    "LKB_RET   = 21          # look-back for return-based metrics\n",
    "LKB_CONS  = 5           # consistency window (days)\n",
    "LKB_IR    = 63          # IR window\n",
    "LKB_BETA  = 63          # beta window\n",
    "LKB_TAIL  = 21          # max-drawdown window\n",
    "BENCH     = 'SPY'       # ticker that exists in your universe\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 1.  DAILY RETURNS ----------------------------------------------------\n",
    "df['ret'] = df.groupby(level=0)['Adj Close'].pct_change()\n",
    "\n",
    "# 2.  CONSISTENCY SENSOR  (5-day win-rate) -----------------------------\n",
    "df['up']  = df['ret'].gt(0).astype(int)\n",
    "df['consistency_5d'] = (df.groupby(level=0)['up']\n",
    "                          .rolling(LKB_CONS).mean()\n",
    "                          .reset_index(level=0, drop=True))\n",
    "\n",
    "# 3.  BENCHMARK-RELATIVE CONSISTENCY  (63-day IR vs SPY) ---------------\n",
    "# need benchmark return\n",
    "bench_ret = df.xs(BENCH, level=0)['ret'].rename('bench_ret')\n",
    "df = df.join(bench_ret, how='left')          # broadcast to all tickers\n",
    "\n",
    "df['active'] = df['ret'] - df['bench_ret']\n",
    "g = df.groupby(level=0)\n",
    "active_mean  = g['active'].rolling(LKB_IR).mean()\n",
    "active_std   = g['active'].rolling(LKB_IR).std()\n",
    "df['IR_63d'] = active_mean / active_std      # Information Ratio\n",
    "\n",
    "# 4.  TAIL FLAG  (21-day max drawdown) ---------------------------------\n",
    "roll_max = g['Adj Close'].rolling(LKB_TAIL).max()\n",
    "dd = (df['Adj Close'] - roll_max) / roll_max\n",
    "df['max_dd_21d'] = dd.groupby(level=0).rolling(LKB_TAIL).min()\n",
    "\n",
    "# 5.  MACRO REGIME OVERLAY  (beta to SPY) ------------------------------\n",
    "cov  = g['ret'].rolling(LKB_BETA).cov(df['bench_ret'])\n",
    "var  = df['bench_ret'].groupby(level=0).rolling(LKB_BETA).var()\n",
    "df['beta_SPY'] = cov / var\n",
    "\n",
    "# 6.  RISK-ADJUSTED INTRADAY STRENGTH  (OBV Sharpe) --------------------\n",
    "# OBV\n",
    "df['close_chg'] = df.groupby(level=0)['Adj Close'].diff()\n",
    "df['vol_dir']   = np.where(df['close_chg'] > 0,  df['Volume'],\n",
    "                   np.where(df['close_chg'] < 0, -df['Volume'], 0))\n",
    "df['obv'] = df.groupby(level=0)['vol_dir'].cumsum()\n",
    "\n",
    "# OBV return & vol\n",
    "df['obv_ret'] = df.groupby(level=0)['obv'].pct_change()\n",
    "obv_mean = g['obv_ret'].rolling(LKB_RET).mean()\n",
    "obv_std  = g['obv_ret'].rolling(LKB_RET).std()\n",
    "df['OBV_Sharpe_21d'] = obv_mean / obv_std\n",
    "\n",
    "# drop helper columns --------------------------------------------------\n",
    "df.drop(columns=['up','bench_ret','active','close_chg','vol_dir'], inplace=True)\n",
    "```\n",
    "\n",
    "After the block you have five new columns:\n",
    "\n",
    "- `consistency_5d`      â€“ 5-day win-rate (0-1)  \n",
    "- `IR_63d`              â€“ 63-day Information Ratio vs SPY  \n",
    "- `max_dd_21d`          â€“ 21-day maximum drawdown (â‰¤ 0)  \n",
    "- `beta_SPY`            â€“ rolling beta to SPY  \n",
    "- `OBV_Sharpe_21d`      â€“ OBV risk-adjusted momentum  \n",
    "\n",
    "All are aligned to the original MultiIndex and ready to be ranked or z-scored inside your Alpha Engine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9716794",
   "metadata": {},
   "source": [
    "v52  \n",
    "- **verify_engine_results_short_form**\n",
    "- **verify_engine_results_long_form**\n",
    "-  **The Temporal Alignment Fix:** We synchronized the \"Reward\" (Returns) and \"Risk\" (Volatility) by implementing the $N-1$ denominator logic. This ensures that Day 1's volatility no longer dilutes your Sharpe scores.\n",
    "-  **The Event-Driven Re-normalization:** We verified that the Engine correctly resets capital and weights at the start of the Holding period, giving you an accurate \"Fresh Start\" performance metric.\n",
    "-  **The Double-Blind Verification:** We proved that the Engine's True Range (TRP) math is flawless by recreating it from raw High/Low/Close data and achieving an 8-decimal match.\n",
    "-  **Mathematical Fortification:** We centralized all logic into a polymorphic `QuantUtils` kernel that handles both single-portfolio reports and whole-universe rankings with built-in numerical safety.\n",
    "-  **Volatility Evolution:** We successfully added `TRP` (True Range Percent) and the `Sharpe (TRP)` metric, giving you a raw, high-frequency alternative to the smoothed ATR.\n",
    "-  **Data Integrity:** We implemented the \"Momentum Collapse\" tripwire (`verify_ranking_integrity`) to ensure that your risk-adjusted rankings never accidentally devolve into simple price momentum.\n",
    "-  **The \"Audit Pack\" Architecture:** We collapsed fragmented results into a single, atomic container, ensuring that your inputs, results, and debug data are always perfectly synchronized.\n",
    "-  **Total Transparency:** We replaced scattered CSV files with a unified **Excel Audit Report**, allowing for 1-to-1 manual verification of every calculation in the system.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9817eb05",
   "metadata": {},
   "source": [
    "v51\n",
    "\n",
    "UNDO v50, Calculate Sharpe(ATR) using mean over lookback period.  \n",
    "\n",
    "Comment out ``# --- PINPOINT START: ATRP SWITCH ---`` in function ``_select_tickers`` can switch between ``Averaged ATRP over lookback period`` and ``Current ATRP``  \n",
    "    # --- PINPOINT START: ATRP SWITCH ---  \n",
    "    # To switch between Old (Averaged ATRP) and New (Current ATRP):  \n",
    "    # 1. Comment out the logic you DON'T want.  \n",
    "    # 2. Uncomment the logic you DO want.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eb349d",
   "metadata": {},
   "source": [
    "v50\n",
    "\n",
    "Ticker selection based on atrp_value_for_obs based on decision day, was based on average over lookback period. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31dde13",
   "metadata": {},
   "source": [
    "v48  \n",
    "### Summary of what you just accomplished:\n",
    "1.  **Strict Math:** `QuantUtils` now contains an `assert` that prevents any dev (or AI) from filling the first day with 0.0.\n",
    "2.  **Semantic Protection:** Variables are now named `returns_WITH_BOUNDARY_NAN`, signaling to the AI that the Null value is part of its identity.\n",
    "3.  **Complete SOLID Separation:** The Engine CONDUCTS the simulation, while `QuantUtils` CALCULATES the results. They no longer share logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61923b0e",
   "metadata": {},
   "source": [
    "**1. Data Flow of `plot_walk_forward_analyzer`**\n",
    "The function acts as a **UI wrapper** around the `AlphaEngine` class. The flow is:\n",
    "1.  **Input:** User selects parameters (Dates, Lookback, Strategy).\n",
    "2.  **State Construction:** `AlphaEngine` slices the historical data (`df_ohlcv`, `df_atrp`) up to the `decision_date`.\n",
    "3.  **Policy Execution (Hardcoded):** The engine applies the logic (e.g., `METRIC_REGISTRY['Sharpe']`) to rank stocks based *only* on the Lookback window.\n",
    "4.  **Environment Step:** It simulates a \"Buy\" at `decision_date + 1` and calculates the returns over the `holding_period`.\n",
    "5.  **Reward Generation:** It outputs performance metrics (`holding_p_gain`, `holding_p_sharpe`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1110f2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ðŸ›¡ï¸ Starting Final Integrity Audit ---\n",
      "âœ… Series Boundary: OK\n",
      "âœ… DataFrame Boundary: OK\n",
      "âœ… AUDIT PASSED: Mathematical boundaries are strictly enforced.\n",
      "\n",
      "--- ðŸ›¡ï¸ Starting Feature Engineering Audit ---\n",
      "âš¡ Generating Features (Base: 21d, Ratio Clip: 10.0)...\n",
      "Audit Values:\n",
      "[ nan 25.  17.5]\n",
      "âœ… FEATURE INTEGRITY PASSED: Wilder's ATR logic is strictly enforced.\n",
      "--- ðŸ›¡ï¸ Starting Ranking Kernel Audit ---\n",
      "âœ… RANKING INTEGRITY PASSED: Volatility normalization is strictly enforced.\n",
      "\n",
      "--- ðŸ›¡ï¸ Starting Volatility Alignment Audit ---\n",
      "âœ… Series Temporal Coupling: OK\n",
      "âœ… DataFrame Temporal Coupling: OK\n",
      "âœ… AUDIT PASSED: Reward and Risk are strictly synchronized.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from dataclasses import dataclass, field, asdict, is_dataclass\n",
    "from typing import List, Dict, Optional, Any, Union, TypedDict, Tuple\n",
    "from collections import Counter\n",
    "from datetime import datetime, date\n",
    "from pandas.testing import assert_series_equal\n",
    "\n",
    "\n",
    "# pd.set_option('display.max_rows', None)  display all rows\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"display.max_colwidth\", 50)\n",
    "pd.set_option(\"display.precision\", 4)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# GLOBAL SETTINGS: The \"Control Panel\" for the Strategy\n",
    "# ==============================================================================\n",
    "\n",
    "GLOBAL_SETTINGS = {\n",
    "    # ENVIRONMENT (The \"Where\")\n",
    "    \"benchmark_ticker\": \"SPY\",\n",
    "    \"calendar_ticker\": \"SPY\",  # Used as the \"Master Clock\" for trading days\n",
    "    # DATA SANITIZER (The \"Glitches & Gaps\" Protector)\n",
    "    \"handle_zeros_as_nan\": True,  # Convert 0.0 prices to NaN to prevent math errors\n",
    "    \"max_data_gap_ffill\": 1,  # Max consecutive days to \"Forward Fill\" missing data\n",
    "    # IMPLICATION OF nan_price_replacement:\n",
    "    # - This defines what happens if the \"Forward Fill\" limit is exceeded.\n",
    "    # - If set to 0.0: A permanent data gap will look like a \"total loss\" (-100%).\n",
    "    #   The equity curve will plummet. Good for \"disaster detection.\"\n",
    "    #   Sharpe and Sharpe(ATR) drop because: return (gets smaller) / std (gets larger)\n",
    "    # - If set to np.nan: A permanent gap will cause portfolio calculations to return NaN.\n",
    "    #   The chart may break or show gaps. Good for \"math integrity.\"\n",
    "    \"nan_price_replacement\": 0.0,\n",
    "    # STRATEGY & MATH\n",
    "    \"annual_period\": 252,  # Replaces hardcoded 252 in Sharpe calculations\n",
    "    \"atr_period\": 14,  # Used for volatility normalization\n",
    "    \"rsi_period\": 14,  # <--- NEW: Control for RSI logic\n",
    "    # FEATURE ENGINE WINDOWS\n",
    "    \"features_base_window\": 21,  # Replaces hardcoded 21 (The \"Monthly\" anchor)\n",
    "    \"features_fast_window\": 5,  # Replaces hardcoded 5 (The \"Weekly\" anchor)\n",
    "    # FEATURE GUARDRAILS (CLIPS)\n",
    "    \"feature_zscore_clip\": 5.0,  # Replaces hardcoded 5.0 in OBV Z-Scores\n",
    "    \"feature_ratio_clip\": 10.0,  # Replaces hardcoded 10.0 in RVol ratios\n",
    "    # QUALITY/LIQUIDITY\n",
    "    \"quality_window\": 252,  # 1 year lookback for liquidity/quality stats\n",
    "    \"quality_min_periods\": 126,  # min period that ticker has to meet quality thresholds\n",
    "    # QUALITY THRESHOLDS (The \"Rules\")\n",
    "    \"thresholds\": {\n",
    "        # HARD LIQUIDITY FLOOR\n",
    "        # Logic: Calculates (Adj Close * Volume) daily, then takes the ROLLING MEDIAN\n",
    "        # over the quality_window (252 days). Filters out stocks where the\n",
    "        # typical daily dollar turnover is below this absolute value.\n",
    "        \"min_median_dollar_volume\": 1_000_000,\n",
    "        # DYNAMIC LIQUIDITY CUTOFF (Relative to Universe)\n",
    "        # Logic: On the decision date, the engine calculates the X-quantile\n",
    "        # of 'RollMedDollarVol' across ALL available stocks.\n",
    "        # Setting this to 0.40 calculates the 60th percentile and requires\n",
    "        # stocks to be above itâ€”effectively keeping only the TOP 60% of the market.\n",
    "        \"min_liquidity_percentile\": 0.40,\n",
    "        # PRICE/VOLUME STALENESS\n",
    "        # Logic: Creates a binary flag (1 if Volume is 0 OR High equals Low).\n",
    "        # It then calculates the ROLLING MEAN of this flag.\n",
    "        # A value of 0.05 means the stock is rejected if it was \"stale\"\n",
    "        # for more than 5% of the trading days in the rolling window.\n",
    "        \"max_stale_pct\": 0.05,\n",
    "        # DATA INTEGRITY (FROZEN VOLUME)\n",
    "        # Logic: Checks if Volume is identical to the previous day (Volume.diff() == 0).\n",
    "        # It calculates the ROLLING SUM of these occurrences over the window.\n",
    "        # If the exact same volume is reported more than 10 times, the stock\n",
    "        # is rejected as having \"frozen\" or low-quality data.\n",
    "        \"max_same_vol_count\": 10,\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION A: CORE KERNELS & QUANT UTILITIES (THE SAFE ROOM)\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "class QuantUtils:\n",
    "    \"\"\"\n",
    "    MATHEMATICAL KERNEL REGISTRY: THE SINGLE SOURCE OF TRUTH.\n",
    "    Handles both pd.Series (Report) and pd.DataFrame (Ranking) robustly.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_returns(\n",
    "        data: Union[pd.Series, pd.DataFrame],\n",
    "    ) -> Union[pd.Series, pd.DataFrame]:\n",
    "        return data.pct_change().replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_gain(data: Union[pd.Series, pd.DataFrame]) -> Union[float, pd.Series]:\n",
    "        if data.empty:\n",
    "            return 0.0\n",
    "        res = (data.ffill().iloc[-1] / data.bfill().iloc[0]) - 1\n",
    "\n",
    "        if isinstance(res, (pd.Series, pd.DataFrame)):\n",
    "            return res.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "        return float(res) if np.isfinite(res) else 0.0\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_sharpe(\n",
    "        data: Union[pd.Series, pd.DataFrame],\n",
    "        periods: int = None,  # Default to None to trigger global lookup\n",
    "    ) -> Union[float, pd.Series]:\n",
    "        if periods is None:\n",
    "            periods = GLOBAL_SETTINGS[\"annual_period\"]\n",
    "        mu, std = data.mean(), data.std()\n",
    "        # Use np.maximum for universal floor (works on scalars and Series)\n",
    "        res = (mu / np.maximum(std, 1e-8)) * np.sqrt(periods)\n",
    "\n",
    "        if isinstance(res, (pd.Series, pd.DataFrame)):\n",
    "            return res.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "        return float(res) if np.isfinite(res) else 0.0\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_sharpe_vol(\n",
    "        returns: Union[pd.Series, pd.DataFrame],\n",
    "        vol_data: Union[pd.Series, pd.DataFrame],\n",
    "    ) -> Union[float, pd.Series]:\n",
    "        \"\"\"\n",
    "        Aligned Reward / Risk.\n",
    "        Filters out volatility observations where no return exists (e.g. Day 1 NaN).\n",
    "        \"\"\"\n",
    "        # 1. Identify valid timestamps (Pandas .mean() skips NaNs in returns)\n",
    "        # but we must manually force the volatility denominator to skip those same rows.\n",
    "        mask = returns.notna()\n",
    "        avg_ret = returns.mean()\n",
    "\n",
    "        # 2. Handle Logic Branches\n",
    "        if isinstance(returns, pd.DataFrame) and isinstance(vol_data, pd.Series):\n",
    "            # RANKING MODE: vol_data is usually a pre-calculated snapshot Series\n",
    "            avg_vol = vol_data\n",
    "        else:\n",
    "            # REPORT MODE (Series) or Cross-Sectional DataFrame\n",
    "            # Filter vol_data to only include rows where returns exist\n",
    "            avg_vol = vol_data.where(mask).mean()\n",
    "\n",
    "        # 3. Final Division\n",
    "        res = avg_ret / np.maximum(avg_vol, 1e-8)\n",
    "\n",
    "        if isinstance(res, (pd.Series, pd.DataFrame)):\n",
    "            return res.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "        return float(res) if np.isfinite(res) else 0.0\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_portfolio_stats(\n",
    "        prices: pd.DataFrame,\n",
    "        atrp_matrix: pd.DataFrame,\n",
    "        trp_matrix: pd.DataFrame,\n",
    "        weights: pd.Series,\n",
    "    ) -> Tuple[pd.Series, pd.Series, pd.Series, pd.Series]:\n",
    "        \"\"\"\n",
    "        MATRIX KERNEL: Calculates equity curve and weighted volatility.\n",
    "        \"\"\"\n",
    "        # 1. Equity Curve Logic (Price-Weighted Drift)\n",
    "        norm_prices = prices.div(prices.bfill().iloc[0])\n",
    "        weighted_components = norm_prices.mul(weights, axis=1)\n",
    "        equity_curve = weighted_components.sum(axis=1)\n",
    "\n",
    "        # MANDATORY: Use internal compute_returns to preserve boundary NaN\n",
    "        returns_WITH_BOUNDARY_NAN = QuantUtils.compute_returns(equity_curve)\n",
    "\n",
    "        # 2. Portfolio Volatility Logic (Weighted Average)\n",
    "        # We calculate current_weights (rebalanced daily by price drift)\n",
    "        current_weights = weighted_components.div(equity_curve, axis=0)\n",
    "\n",
    "        # Weighted average of ATRP and TRP\n",
    "        portfolio_atrp = (current_weights * atrp_matrix).sum(axis=1, min_count=1)\n",
    "        portfolio_trp = (current_weights * trp_matrix).sum(axis=1, min_count=1)\n",
    "\n",
    "        return equity_curve, returns_WITH_BOUNDARY_NAN, portfolio_atrp, portfolio_trp\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION B: STRATEGY HELPERS & FEATURES\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "def generate_features(\n",
    "    df_ohlcv: pd.DataFrame,\n",
    "    df_indices: pd.DataFrame = None,\n",
    "    benchmark_ticker: str = None,\n",
    "    atr_period: int = None,\n",
    "    rsi_period: int = None,\n",
    "    features_base_window: int = None,\n",
    "    features_fast_window: int = None,\n",
    "    feature_zscore_clip: float = None,\n",
    "    feature_ratio_clip: float = None,\n",
    "    quality_window: int = None,\n",
    "    quality_min_periods: int = None,\n",
    ") -> pd.DataFrame:\n",
    "    # --- 1. RESOLVE GLOBALS ---\n",
    "    benchmark_ticker = benchmark_ticker or GLOBAL_SETTINGS[\"benchmark_ticker\"]\n",
    "    atr_period = atr_period or GLOBAL_SETTINGS[\"atr_period\"]\n",
    "    rsi_period = rsi_period or GLOBAL_SETTINGS[\"rsi_period\"]\n",
    "    features_base_window = (\n",
    "        features_base_window or GLOBAL_SETTINGS[\"features_base_window\"]\n",
    "    )\n",
    "    features_fast_window = (\n",
    "        features_fast_window or GLOBAL_SETTINGS[\"features_fast_window\"]\n",
    "    )\n",
    "    feature_zscore_clip = feature_zscore_clip or GLOBAL_SETTINGS[\"feature_zscore_clip\"]\n",
    "    feature_ratio_clip = feature_ratio_clip or GLOBAL_SETTINGS[\"feature_ratio_clip\"]\n",
    "    quality_window = quality_window or GLOBAL_SETTINGS[\"quality_window\"]\n",
    "    quality_min_periods = quality_min_periods or GLOBAL_SETTINGS[\"quality_min_periods\"]\n",
    "\n",
    "    print(\n",
    "        f\"âš¡ Generating Features (Base: {features_base_window}d, Ratio Clip: {feature_ratio_clip})...\"\n",
    "    )\n",
    "\n",
    "    if not df_ohlcv.index.is_monotonic_increasing:\n",
    "        df_ohlcv = df_ohlcv.sort_index()\n",
    "    grouped = df_ohlcv.groupby(level=\"Ticker\")\n",
    "\n",
    "    # 2. VECTORIZED ATR\n",
    "    prev_close = grouped[\"Adj Close\"].shift(1)\n",
    "    tr = pd.concat(\n",
    "        [\n",
    "            df_ohlcv[\"Adj High\"] - df_ohlcv[\"Adj Low\"],\n",
    "            abs(df_ohlcv[\"Adj High\"] - prev_close),\n",
    "            abs(df_ohlcv[\"Adj Low\"] - prev_close),\n",
    "        ],\n",
    "        axis=1,\n",
    "    ).max(axis=1, skipna=False)\n",
    "\n",
    "    atr = (\n",
    "        tr.groupby(level=\"Ticker\")\n",
    "        .ewm(alpha=1 / atr_period, adjust=False)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    atrp = (atr / df_ohlcv[\"Adj Close\"]).replace([np.inf, -np.inf], np.nan)\n",
    "    trp = (tr / df_ohlcv[\"Adj Close\"]).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # 3. VECTORIZED RSI\n",
    "    delta = grouped[\"Adj Close\"].diff()\n",
    "    up, down = delta.clip(lower=0), -1 * delta.clip(upper=0)\n",
    "    ma_up = (\n",
    "        up.groupby(level=\"Ticker\")\n",
    "        .ewm(alpha=1 / rsi_period, adjust=False)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    ma_down = (\n",
    "        down.groupby(level=\"Ticker\")\n",
    "        .ewm(alpha=1 / rsi_period, adjust=False)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    rsi = 100 - (100 / (1 + (ma_up / ma_down))).replace([np.inf, -np.inf], 50).fillna(\n",
    "        50\n",
    "    )\n",
    "\n",
    "    # 4. OBV Score (Ticker Specific)\n",
    "    direction = np.sign(delta).fillna(0)\n",
    "    obv_raw = (direction * df_ohlcv[\"Volume\"]).groupby(level=\"Ticker\").cumsum()\n",
    "    obv_roll_mean = (\n",
    "        obv_raw.groupby(level=\"Ticker\")\n",
    "        .rolling(features_base_window)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    obv_roll_std = (\n",
    "        obv_raw.groupby(level=\"Ticker\")\n",
    "        .rolling(features_base_window)\n",
    "        .std()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    obv_score = (\n",
    "        ((obv_raw - obv_roll_mean) / obv_roll_std)\n",
    "        .fillna(0.0)\n",
    "        .clip(lower=-feature_zscore_clip, upper=feature_zscore_clip)\n",
    "    )\n",
    "\n",
    "    # 5. BENCHMARK SENSORS\n",
    "    dollar_vol_series = df_ohlcv[\"Adj Close\"] * df_ohlcv[\"Volume\"]\n",
    "    rel_strength_base = pd.Series(0.0, index=df_ohlcv.index)\n",
    "    spy_rvol = pd.Series(1.0, index=df_ohlcv.index)\n",
    "    spy_obv_score = pd.Series(0.0, index=df_ohlcv.index)\n",
    "\n",
    "    found_bench = False\n",
    "    if (\n",
    "        df_indices is not None\n",
    "        and benchmark_ticker in df_indices.index.get_level_values(0)\n",
    "    ):\n",
    "        bench_close = df_indices.xs(benchmark_ticker, level=0)[\"Adj Close\"]\n",
    "        bench_vol = df_indices.xs(benchmark_ticker, level=0)[\"Volume\"]\n",
    "        found_bench = True\n",
    "    elif benchmark_ticker in df_ohlcv.index.get_level_values(0):\n",
    "        bench_close = df_ohlcv.xs(benchmark_ticker, level=0)[\"Adj Close\"]\n",
    "        bench_vol = df_ohlcv.xs(benchmark_ticker, level=0)[\"Volume\"]\n",
    "        found_bench = True\n",
    "\n",
    "    if found_bench:\n",
    "        try:\n",
    "            # Relative Strength (Using Base Window)\n",
    "            bench_close_aligned = bench_close.reindex(\n",
    "                df_ohlcv.index.get_level_values(\"Date\")\n",
    "            ).values\n",
    "            rel_strength_base = (\n",
    "                (df_ohlcv[\"Adj Close\"] / bench_close_aligned)\n",
    "                .groupby(level=\"Ticker\")\n",
    "                .pct_change(features_base_window, fill_method=None)\n",
    "                .fillna(0.0)\n",
    "            )\n",
    "\n",
    "            # SPY RVol\n",
    "            bench_dvol = bench_close * bench_vol\n",
    "            bench_dvol_avg = bench_dvol.rolling(features_base_window).mean()\n",
    "            spy_rvol_vals = (\n",
    "                (bench_dvol / bench_dvol_avg)\n",
    "                .reindex(df_ohlcv.index.get_level_values(\"Date\"))\n",
    "                .fillna(1.0)\n",
    "                .values\n",
    "            )\n",
    "            spy_rvol = pd.Series(spy_rvol_vals, index=df_ohlcv.index).clip(\n",
    "                upper=feature_ratio_clip\n",
    "            )\n",
    "\n",
    "            # SPY OBV\n",
    "            spy_dir = np.sign(bench_close.diff()).fillna(0)\n",
    "            spy_obv = (spy_dir * bench_vol).cumsum()\n",
    "            spy_obv_z = (\n",
    "                (\n",
    "                    (spy_obv - spy_obv.rolling(features_base_window).mean())\n",
    "                    / spy_obv.rolling(features_base_window).std()\n",
    "                )\n",
    "                .fillna(0.0)\n",
    "                .clip(lower=-feature_zscore_clip, upper=feature_zscore_clip)\n",
    "            )\n",
    "            spy_obv_score = pd.Series(\n",
    "                spy_obv_z.reindex(df_ohlcv.index.get_level_values(\"Date\")).values,\n",
    "                index=df_ohlcv.index,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Benchmark Math Error: {e}\")\n",
    "\n",
    "    # 6. TICKER RVol\n",
    "    dvol_avg = (\n",
    "        dollar_vol_series.groupby(level=\"Ticker\")\n",
    "        .rolling(features_base_window)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    ticker_rvol = (\n",
    "        (dollar_vol_series / dvol_avg)\n",
    "        .replace([np.inf, -np.inf], 1.0)\n",
    "        .fillna(1.0)\n",
    "        .clip(upper=feature_ratio_clip)\n",
    "    )\n",
    "\n",
    "    # 7. MOMENTUM VECTORS (Static as requested)\n",
    "    roc_1 = grouped[\"Adj Close\"].pct_change(1, fill_method=None)\n",
    "    roc_3 = grouped[\"Adj Close\"].pct_change(3, fill_method=None)\n",
    "    roc_5 = grouped[\"Adj Close\"].pct_change(5, fill_method=None)\n",
    "    roc_10 = grouped[\"Adj Close\"].pct_change(10, fill_method=None)\n",
    "    roc_21 = grouped[\"Adj Close\"].pct_change(21, fill_method=None)\n",
    "\n",
    "    # 8. VOLATILITY REGIME (Fast / Base)\n",
    "    rets = grouped[\"Adj Close\"].pct_change(1, fill_method=None)\n",
    "    std_fast = (\n",
    "        rets.groupby(level=\"Ticker\")\n",
    "        .rolling(features_fast_window)\n",
    "        .std()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    std_base = (\n",
    "        rets.groupby(level=\"Ticker\")\n",
    "        .rolling(features_base_window)\n",
    "        .std()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    vol_regime = (std_fast / std_base).replace([np.inf, -np.inf], 1.0)\n",
    "\n",
    "    # 9. OUTPUT\n",
    "    indicator_df = pd.DataFrame(\n",
    "        {\n",
    "            \"ATR\": atr,\n",
    "            \"ATRP\": atrp,\n",
    "            \"TRP\": trp,\n",
    "            \"RSI\": rsi,\n",
    "            \"RelStrength\": rel_strength_base,\n",
    "            \"VolRegime\": vol_regime,\n",
    "            \"RVol\": ticker_rvol,\n",
    "            \"Spy_RVol\": spy_rvol,\n",
    "            \"OBV_Score\": obv_score,\n",
    "            \"Spy_OBV_Score\": spy_obv_score,\n",
    "            \"ROC_1\": roc_1,\n",
    "            \"ROC_3\": roc_3,\n",
    "            \"ROC_5\": roc_5,\n",
    "            \"ROC_10\": roc_10,\n",
    "            \"ROC_21\": roc_21,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # 10. QUALITY/LIQUIDITY\n",
    "    quality_temp = pd.DataFrame(\n",
    "        {\n",
    "            \"IsStale\": np.where(\n",
    "                (df_ohlcv[\"Volume\"] == 0)\n",
    "                | (df_ohlcv[\"Adj High\"] == df_ohlcv[\"Adj Low\"]),\n",
    "                1,\n",
    "                0,\n",
    "            ),\n",
    "            \"DollarVolume\": dollar_vol_series,\n",
    "            \"HasSameVolume\": (grouped[\"Volume\"].diff() == 0).astype(int),\n",
    "        },\n",
    "        index=df_ohlcv.index,\n",
    "    )\n",
    "\n",
    "    rolling_quality = (\n",
    "        quality_temp.groupby(level=\"Ticker\")\n",
    "        .rolling(window=quality_window, min_periods=quality_min_periods)\n",
    "        .agg({\"IsStale\": \"mean\", \"DollarVolume\": \"median\", \"HasSameVolume\": \"sum\"})\n",
    "        .rename(\n",
    "            columns={\n",
    "                \"IsStale\": \"RollingStalePct\",\n",
    "                \"DollarVolume\": \"RollMedDollarVol\",\n",
    "                \"HasSameVolume\": \"RollingSameVolCount\",\n",
    "            }\n",
    "        )\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    return pd.concat([indicator_df, rolling_quality], axis=1)\n",
    "\n",
    "\n",
    "def _prepare_initial_weights(tickers: List[str]) -> pd.Series:\n",
    "    \"\"\"\n",
    "    METADATA: Converts a list of tickers into a weight map.\n",
    "    Example: ['AAPL', 'AAPL', 'TSLA'] -> {'AAPL': 0.66, 'TSLA': 0.33}\n",
    "    \"\"\"\n",
    "    ticker_counts = Counter(tickers)\n",
    "    total = len(tickers)\n",
    "    return pd.Series({t: c / total for t, c in ticker_counts.items()})\n",
    "\n",
    "\n",
    "def calculate_buy_and_hold_performance(\n",
    "    df_close_wide: pd.DataFrame,  # Use the WIDE version\n",
    "    df_atrp_wide: pd.DataFrame,  # Use the WIDE version\n",
    "    df_trp_wide: pd.DataFrame,  # <--- Added\n",
    "    tickers: List[str],\n",
    "    start_date: pd.Timestamp,\n",
    "    end_date: pd.Timestamp,\n",
    "):\n",
    "    if not tickers:\n",
    "        return pd.Series(), pd.Series(), pd.Series()\n",
    "\n",
    "    initial_weights = _prepare_initial_weights(tickers)\n",
    "\n",
    "    # SLICE (Fix Part B)\n",
    "    ticker_list = initial_weights.index.tolist()\n",
    "    p_slice = df_close_wide.reindex(columns=ticker_list).loc[start_date:end_date]\n",
    "    a_slice = df_atrp_wide.reindex(columns=ticker_list).loc[start_date:end_date]\n",
    "    t_slice = df_trp_wide.reindex(columns=ticker_list).loc[start_date:end_date]\n",
    "    # KERNEL - Pure Math\n",
    "    return QuantUtils.compute_portfolio_stats(\n",
    "        p_slice, a_slice, t_slice, initial_weights\n",
    "    )\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION C: METRIC REGISTRY\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "class MarketObservation(TypedDict):\n",
    "    \"\"\"\n",
    "    The 'STATE' (Observation) in Reinforcement Learning.\n",
    "    This defines the context given to the agent to make a decision.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- The Movie (Time Series) ---\n",
    "    lookback_returns: pd.DataFrame  # (Time x Tickers)\n",
    "    lookback_close: pd.DataFrame  # (Time x Tickers)\n",
    "\n",
    "    # --- The Snapshot (Scalar values at Decision Time) ---\n",
    "    atrp: pd.Series  # Volatility (Mean over lookback)\n",
    "    trp: pd.Series  # Volatility (Snapshot)\n",
    "\n",
    "    # NEW SENSORS\n",
    "    rsi: pd.Series  # Internal Momentum (0-100)\n",
    "    rel_strength: pd.Series  # Performance vs SPY\n",
    "    vol_regime: pd.Series  # Volatility Expansion/Compression\n",
    "    rvol: pd.Series  # Ticker Conviction\n",
    "    spy_rvol: pd.Series  # Market Participation\n",
    "    obv_score: pd.Series  # Ticker Accumulation/Distribution\n",
    "    spy_obv_score: pd.Series  # Market Tide\n",
    "\n",
    "    # MOMENTUM VECTORS\n",
    "    roc_1: pd.Series\n",
    "    roc_3: pd.Series\n",
    "    roc_5: pd.Series\n",
    "    roc_10: pd.Series\n",
    "    roc_21: pd.Series\n",
    "\n",
    "\n",
    "METRIC_REGISTRY = {\n",
    "    # --- CLASSIC METRICS ---\n",
    "    \"Price\": lambda obs: QuantUtils.calculate_gain(obs[\"lookback_close\"]),\n",
    "    \"Sharpe\": lambda obs: QuantUtils.calculate_sharpe(obs[\"lookback_returns\"]),\n",
    "    \"Sharpe (ATRP)\": lambda obs: QuantUtils.calculate_sharpe_vol(\n",
    "        obs[\"lookback_returns\"], obs[\"atrp\"]\n",
    "    ),\n",
    "    \"Sharpe (TRP)\": lambda obs: QuantUtils.calculate_sharpe_vol(\n",
    "        obs[\"lookback_returns\"], obs[\"trp\"]\n",
    "    ),  # <--- New Strategy\n",
    "    # --- MOMENTUM VECTORS ---\n",
    "    \"Momentum 1D\": lambda obs: obs[\"roc_1\"],\n",
    "    \"Momentum 3D\": lambda obs: obs[\"roc_3\"],\n",
    "    \"Momentum 5D\": lambda obs: obs[\"roc_5\"],\n",
    "    \"Momentum 10D\": lambda obs: obs[\"roc_10\"],\n",
    "    \"Momentum 1M\": lambda obs: obs[\"roc_21\"],\n",
    "    # --- PULLBACK VECTORS ---\n",
    "    \"Pullback 1D\": lambda obs: -obs[\"roc_1\"],\n",
    "    \"Pullback 3D\": lambda obs: -obs[\"roc_3\"],\n",
    "    \"Pullback 5D\": lambda obs: -obs[\"roc_5\"],\n",
    "    \"Pullback 10D\": lambda obs: -obs[\"roc_10\"],\n",
    "    \"Pullback 1M\": lambda obs: -obs[\"roc_21\"],\n",
    "    # --- NEW SOTA SENSORS ---\n",
    "    \"RSI (Reversal)\": lambda obs: -obs[\"rsi\"],  # Rank Low RSI (Oversold) higher\n",
    "    \"RSI (Trend)\": lambda obs: obs[\"rsi\"],  # Rank High RSI (Strong Trend) higher\n",
    "    \"Alpha (RelStrength)\": lambda obs: obs[\"rel_strength\"],  # Rank stocks beating SPY\n",
    "    \"OBV_Score (Accumulation)\": lambda obs: obs[\"obv_score\"],  # Rank High OBV Score\n",
    "    \"$V Inc (Cur$V / Avg$V21)\": lambda obs: obs[\"rvol\"],  # Rank High Relative Volume\n",
    "    \"Vol Inc (5dStDev / 21dStDev)\": lambda obs: obs[\n",
    "        \"vol_regime\"\n",
    "    ],  # Rank High Volatility Expansion\n",
    "}\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION D: DATA CONTRACTS\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EngineInput:\n",
    "    mode: str\n",
    "    start_date: pd.Timestamp\n",
    "    lookback_period: int\n",
    "    holding_period: int\n",
    "    metric: str\n",
    "    benchmark_ticker: str\n",
    "    rank_start: int = 1\n",
    "    rank_end: int = 10\n",
    "    # Default factory pulls from Global thresholds\n",
    "    quality_thresholds: Dict[str, float] = field(\n",
    "        default_factory=lambda: GLOBAL_SETTINGS[\"thresholds\"].copy()\n",
    "    )\n",
    "    manual_tickers: List[str] = field(default_factory=list)\n",
    "    debug: bool = False\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EngineOutput:\n",
    "    # 1. CORE DATA (Required - No Defaults)\n",
    "    portfolio_series: pd.Series\n",
    "    benchmark_series: pd.Series\n",
    "    normalized_plot_data: pd.DataFrame\n",
    "    tickers: List[str]\n",
    "    initial_weights: pd.Series\n",
    "    perf_metrics: Dict[str, float]\n",
    "    results_df: pd.DataFrame\n",
    "\n",
    "    # 2. TIMELINE (Required - No Defaults)\n",
    "    start_date: pd.Timestamp\n",
    "    decision_date: pd.Timestamp\n",
    "    buy_date: pd.Timestamp\n",
    "    holding_end_date: pd.Timestamp\n",
    "\n",
    "    # 3. OPTIONAL / AUDIT DATA (Must be at the bottom because they have defaults)\n",
    "    portfolio_atrp_series: Optional[pd.Series] = None\n",
    "    benchmark_atrp_series: Optional[pd.Series] = None\n",
    "    portfolio_trp_series: Optional[pd.Series] = None\n",
    "    benchmark_trp_series: Optional[pd.Series] = None\n",
    "    error_msg: Optional[str] = None\n",
    "    debug_data: Optional[Dict[str, Any]] = None\n",
    "\n",
    "\n",
    "class AlphaEngine:\n",
    "    def __init__(\n",
    "        self,\n",
    "        df_ohlcv: pd.DataFrame,\n",
    "        features_df: pd.DataFrame = None,\n",
    "        df_close_wide: pd.DataFrame = None,\n",
    "        df_atrp_wide: pd.DataFrame = None,\n",
    "        df_trp_wide: pd.DataFrame = None,\n",
    "        master_ticker: str = GLOBAL_SETTINGS[\"calendar_ticker\"],\n",
    "    ):\n",
    "        print(\"--- âš™ï¸ Initializing AlphaEngine v2.2 (Sanitized) ---\")\n",
    "\n",
    "        # 1. SETUP PRICES (CLEAN-AT-ENTRY)\n",
    "        if df_close_wide is not None:\n",
    "            self.df_close = df_close_wide\n",
    "        else:\n",
    "            print(\"ðŸ¢ Pivoting and Sanitizing Price Data...\")\n",
    "            self.df_close = df_ohlcv[\"Adj Close\"].unstack(level=0)\n",
    "\n",
    "        # STORE RAW SOURCE (The \"Transparency\" Line)\n",
    "        self.df_ohlcv_raw = df_ohlcv\n",
    "\n",
    "        # 3. DATA SANITIZER STEP 1: Handle Zeros\n",
    "        if GLOBAL_SETTINGS[\"handle_zeros_as_nan\"]:\n",
    "            # Replace 0.0 with NaN so math functions (mean/std) ignore them\n",
    "            self.df_close = self.df_close.replace(0, np.nan)\n",
    "\n",
    "        # Smooth over 1-2 day glitches (The \"FNV\" Fix)\n",
    "        self.df_close = self.df_close.ffill(limit=GLOBAL_SETTINGS[\"max_data_gap_ffill\"])\n",
    "\n",
    "        # Handle the remaining \"unfillable\" gaps\n",
    "        self.df_close = self.df_close.fillna(GLOBAL_SETTINGS[\"nan_price_replacement\"])\n",
    "\n",
    "        # 2. SETUP FEATURES\n",
    "        if features_df is not None:\n",
    "            self.features_df = features_df\n",
    "        else:\n",
    "            # We pass the cleaned price data if needed, or calculate from raw\n",
    "            self.features_df = generate_features(\n",
    "                df_ohlcv,\n",
    "                atr_period=GLOBAL_SETTINGS[\"atr_period\"],\n",
    "                quality_window=GLOBAL_SETTINGS[\"quality_window\"],\n",
    "                quality_min_periods=GLOBAL_SETTINGS[\"quality_min_periods\"],\n",
    "            )\n",
    "\n",
    "        # 1. SETUP ATRP\n",
    "        if df_atrp_wide is not None:\n",
    "            # INSTANT: Use the matrix precomputed outside the UI\n",
    "            self.df_atrp = df_atrp_wide\n",
    "        else:\n",
    "            # SLOW FALLBACK: Only runs if you forget to precompute\n",
    "            print(\"ðŸš€ Pre-aligning Volatility (ATRP) Matrix (Slow Fallback)...\")\n",
    "            self.df_atrp = self.features_df[\"ATRP\"].unstack(level=0)\n",
    "\n",
    "        # 2. SETUP TRP\n",
    "        if df_trp_wide is not None:\n",
    "            self.df_trp = df_trp_wide\n",
    "        else:\n",
    "            print(\"ðŸš€ Pre-aligning Volatility (TRP) Matrix (Slow Fallback)...\")\n",
    "            self.df_trp = self.features_df[\"TRP\"].unstack(level=0)\n",
    "\n",
    "        # 3. FINAL ALIGNMENT (The \"Safety Seal\")\n",
    "        # Ensures all matrices have the exact same Dimensions, Tickers, and Dates\n",
    "        common_idx = self.df_close.index\n",
    "        common_cols = self.df_close.columns\n",
    "\n",
    "        self.df_atrp = self.df_atrp.reindex(index=common_idx, columns=common_cols)\n",
    "        self.df_trp = self.df_trp.reindex(index=common_idx, columns=common_cols)\n",
    "\n",
    "        # 3. Setup Calendar\n",
    "        if master_ticker not in self.df_close.columns:\n",
    "            master_ticker = self.df_close.columns[0]\n",
    "        self.trading_calendar = (\n",
    "            self.df_close[master_ticker].dropna().index.unique().sort_values()\n",
    "        )\n",
    "\n",
    "    def run(self, inputs: EngineInput) -> EngineOutput:\n",
    "        dates, error = self._validate_timeline(inputs)\n",
    "        if error:\n",
    "            return self._error_result(error)\n",
    "        (safe_start, safe_decision, safe_buy, safe_end) = dates\n",
    "\n",
    "        # 1. Pass the debug flag into the selection logic\n",
    "        tickers_to_trade, results_table, debug_dict, error = self._select_tickers(\n",
    "            inputs, safe_start, safe_decision\n",
    "        )\n",
    "        if error:\n",
    "            return self._error_result(error)\n",
    "\n",
    "        # 2. CORE PERFORMANCE CALCULATION (Required for all modes)\n",
    "        p_f_val, p_f_ret, p_f_atrp, p_f_trp = calculate_buy_and_hold_performance(\n",
    "            self.df_close,\n",
    "            self.df_atrp,\n",
    "            self.df_trp,\n",
    "            tickers_to_trade,\n",
    "            safe_start,\n",
    "            safe_end,\n",
    "        )\n",
    "        b_f_val, b_f_ret, b_f_atrp, b_f_trp = calculate_buy_and_hold_performance(\n",
    "            self.df_close,\n",
    "            self.df_atrp,\n",
    "            self.df_trp,\n",
    "            [inputs.benchmark_ticker],\n",
    "            safe_start,\n",
    "            safe_end,\n",
    "        )\n",
    "\n",
    "        p_h_val, p_h_ret, p_h_atrp, p_h_trp = calculate_buy_and_hold_performance(\n",
    "            self.df_close,\n",
    "            self.df_atrp,\n",
    "            self.df_trp,\n",
    "            tickers_to_trade,\n",
    "            safe_buy,\n",
    "            safe_end,\n",
    "        )\n",
    "        b_h_val, b_h_ret, b_h_atrp, b_h_trp = calculate_buy_and_hold_performance(\n",
    "            self.df_close,\n",
    "            self.df_atrp,\n",
    "            self.df_trp,\n",
    "            [inputs.benchmark_ticker],\n",
    "            safe_buy,\n",
    "            safe_end,\n",
    "        )\n",
    "\n",
    "        p_metrics, p_slices = self._calculate_period_metrics(\n",
    "            p_f_val,\n",
    "            p_f_ret,\n",
    "            p_f_atrp,\n",
    "            p_f_trp,\n",
    "            safe_decision,\n",
    "            p_h_val,\n",
    "            p_h_ret,\n",
    "            p_h_atrp,\n",
    "            p_h_trp,\n",
    "            prefix=\"p\",\n",
    "        )\n",
    "        b_metrics, b_slices = self._calculate_period_metrics(\n",
    "            b_f_val,\n",
    "            b_f_ret,\n",
    "            b_f_atrp,\n",
    "            b_f_trp,\n",
    "            safe_decision,\n",
    "            b_h_val,\n",
    "            b_h_ret,\n",
    "            b_h_atrp,\n",
    "            b_h_trp,\n",
    "            prefix=\"b\",\n",
    "        )\n",
    "\n",
    "        # 3. CONDITIONAL DEBUG GATING (The RL \"Fast Path\")\n",
    "        # If debug is False, we skip the most memory-intensive tasks\n",
    "        final_debug_data = None\n",
    "        if inputs.debug:\n",
    "            idx_slice = pd.IndexSlice\n",
    "            debug_dict[\"inputs_snapshot\"] = inputs\n",
    "            debug_dict[\"verification\"] = {\"portfolio\": p_slices, \"benchmark\": b_slices}\n",
    "\n",
    "            debug_dict[\"portfolio_raw_components\"] = {\n",
    "                \"prices\": self.df_close[tickers_to_trade].loc[safe_start:safe_end],\n",
    "                \"atrp\": self.df_atrp[tickers_to_trade].loc[safe_start:safe_end],\n",
    "                \"trp\": self.df_trp[tickers_to_trade].loc[safe_start:safe_end],\n",
    "                \"ohlcv_raw\": self.df_ohlcv_raw.loc[\n",
    "                    idx_slice[tickers_to_trade, safe_start:safe_end], :\n",
    "                ],\n",
    "            }\n",
    "\n",
    "            debug_dict[\"benchmark_raw_components\"] = {\n",
    "                \"prices\": self.df_close[[inputs.benchmark_ticker]].loc[\n",
    "                    safe_start:safe_end\n",
    "                ],\n",
    "                \"atrp\": self.df_atrp[[inputs.benchmark_ticker]].loc[\n",
    "                    safe_start:safe_end\n",
    "                ],\n",
    "                \"trp\": self.df_trp[[inputs.benchmark_ticker]].loc[safe_start:safe_end],\n",
    "                \"ohlcv_raw\": self.df_ohlcv_raw.loc[\n",
    "                    idx_slice[[inputs.benchmark_ticker], safe_start:safe_end], :\n",
    "                ],\n",
    "            }\n",
    "            debug_dict[\"selection_audit\"] = debug_dict.get(\"full_universe_ranking\")\n",
    "            final_debug_data = debug_dict\n",
    "\n",
    "        # 4. FINAL OUTPUT SEAL\n",
    "        return EngineOutput(\n",
    "            portfolio_series=p_f_val,\n",
    "            benchmark_series=b_f_val,\n",
    "            portfolio_atrp_series=p_f_atrp if inputs.debug else None,\n",
    "            benchmark_atrp_series=b_f_atrp if inputs.debug else None,\n",
    "            portfolio_trp_series=p_f_trp if inputs.debug else None,\n",
    "            benchmark_trp_series=b_f_trp if inputs.debug else None,\n",
    "            normalized_plot_data=(\n",
    "                self._get_normalized_plot_data(tickers_to_trade, safe_start, safe_end)\n",
    "                if inputs.debug\n",
    "                else pd.DataFrame()\n",
    "            ),\n",
    "            tickers=tickers_to_trade,\n",
    "            initial_weights=_prepare_initial_weights(tickers_to_trade),\n",
    "            perf_metrics={**p_metrics, **b_metrics},\n",
    "            results_df=results_table,\n",
    "            start_date=safe_start,\n",
    "            decision_date=safe_decision,\n",
    "            buy_date=safe_buy,\n",
    "            holding_end_date=safe_end,\n",
    "            debug_data=final_debug_data,  # None if RL search mode\n",
    "        )\n",
    "\n",
    "    def _select_tickers(self, inputs: EngineInput, start_date, decision_date):\n",
    "        debug_dict = {}\n",
    "        # Only pass the container into the filter if we are in debug mode\n",
    "        audit_info = {} if inputs.debug else None\n",
    "\n",
    "        if inputs.mode == \"Manual List\":\n",
    "            # (Logic for manual list remains same)\n",
    "            ...\n",
    "        else:\n",
    "            eligible_tickers = self._filter_universe(\n",
    "                decision_date, inputs.quality_thresholds, audit_info\n",
    "            )\n",
    "            if inputs.debug:\n",
    "                debug_dict[\"audit_liquidity\"] = audit_info\n",
    "\n",
    "            # ... (Ranking logic remains same) ...\n",
    "\n",
    "            if inputs.debug:\n",
    "                debug_dict[\"full_universe_ranking\"] = pd.DataFrame(\n",
    "                    {\n",
    "                        \"Strategy_Score\": metric_vals,\n",
    "                        \"Lookback_Return_Ann\": observation[\"lookback_returns\"].mean()\n",
    "                        * 252,\n",
    "                        \"Lookback_ATRP\": observation[\"atrp\"],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            return selected_tickers, results_table, debug_dict, None\n",
    "\n",
    "    # ==============================================================================\n",
    "    # INTERNAL LOGIC MODULES\n",
    "    # ==============================================================================\n",
    "\n",
    "    def _validate_timeline(self, inputs: EngineInput):\n",
    "        cal = self.trading_calendar\n",
    "        last_idx = len(cal) - 1\n",
    "\n",
    "        if len(cal) <= inputs.lookback_period:\n",
    "            return (\n",
    "                None,\n",
    "                f\"âŒ Dataset too small.\\nNeed > {inputs.lookback_period} days of history.\",\n",
    "            )\n",
    "\n",
    "        # 2. Check \"Past\" Constraints (Lookback)\n",
    "        min_decision_date = cal[inputs.lookback_period]\n",
    "        if inputs.start_date < min_decision_date:\n",
    "            # Added \\n here\n",
    "            return None, (\n",
    "                f\"âŒ Not enough history for a {inputs.lookback_period}-day lookback.\\n\"\n",
    "                f\"Earliest valid Decision Date: {min_decision_date.date()}\"\n",
    "            )\n",
    "\n",
    "        # 3. Check \"Future\" Constraints (Entry T+1 and Holding Period)\n",
    "        required_future_days = 1 + inputs.holding_period\n",
    "        latest_valid_idx = last_idx - required_future_days\n",
    "\n",
    "        if latest_valid_idx < 0:\n",
    "            return (\n",
    "                None,\n",
    "                f\"âŒ Holding period too long.\\n{inputs.holding_period} days exceeds available data.\",\n",
    "            )\n",
    "\n",
    "        # If user picked a date beyond the available \"future\" runway\n",
    "        if inputs.start_date > cal[latest_valid_idx]:\n",
    "            latest_date = cal[latest_valid_idx].date()\n",
    "            # Added \\n here and shortened the text slightly to fit better\n",
    "            return None, (\n",
    "                f\"âŒ Decision Date too late for a {inputs.holding_period}-day hold.\\n\"\n",
    "                f\"Latest valid date: {latest_date}. Please move picker back.\"\n",
    "            )\n",
    "\n",
    "        # 4. Map the safe indices\n",
    "        decision_idx = cal.searchsorted(inputs.start_date)\n",
    "        if decision_idx > latest_valid_idx:\n",
    "            decision_idx = latest_valid_idx\n",
    "\n",
    "        start_idx = decision_idx - inputs.lookback_period\n",
    "        entry_idx = decision_idx + 1\n",
    "        end_idx = entry_idx + inputs.holding_period\n",
    "\n",
    "        return (cal[start_idx], cal[decision_idx], cal[entry_idx], cal[end_idx]), None\n",
    "\n",
    "    def _select_tickers(self, inputs: EngineInput, start_date, decision_date):\n",
    "        debug_dict = {}\n",
    "\n",
    "        # --- PATH A: MANUAL LIST ---\n",
    "        if inputs.mode == \"Manual List\":\n",
    "            validation_errors = []\n",
    "            valid_tickers = []\n",
    "            for t in inputs.manual_tickers:\n",
    "                if t not in self.df_close.columns:\n",
    "                    validation_errors.append(f\"âŒ {t}: Not found.\")\n",
    "                    continue\n",
    "                if pd.isna(self.df_close.at[start_date, t]):\n",
    "                    validation_errors.append(f\"âš ï¸ {t}: No data on start date.\")\n",
    "                    continue\n",
    "                valid_tickers.append(t)\n",
    "\n",
    "            if validation_errors:\n",
    "                return [], pd.DataFrame(), {}, \"\\n\".join(validation_errors)\n",
    "            if not valid_tickers:\n",
    "                return [], pd.DataFrame(), {}, \"No valid tickers found.\"\n",
    "            return valid_tickers, pd.DataFrame(index=valid_tickers), {}, None\n",
    "\n",
    "        # --- PATH B: RANKING ---\n",
    "        else:\n",
    "            audit_info = {}\n",
    "            eligible_tickers = self._filter_universe(\n",
    "                decision_date, inputs.quality_thresholds, audit_info\n",
    "            )\n",
    "            debug_dict[\"audit_liquidity\"] = audit_info\n",
    "\n",
    "            if not eligible_tickers:\n",
    "                return (\n",
    "                    [],\n",
    "                    pd.DataFrame(),\n",
    "                    debug_dict,\n",
    "                    \"No tickers passed quality filters.\",\n",
    "                )\n",
    "\n",
    "            lookback_close = self.df_close.loc[\n",
    "                start_date:decision_date, eligible_tickers\n",
    "            ]\n",
    "\n",
    "            # 1. Get the Snapshot of Features for the Decision Date\n",
    "            feat_slice_current = self.features_df.xs(\n",
    "                decision_date, level=\"Date\"\n",
    "            ).reindex(eligible_tickers)\n",
    "\n",
    "            # Calculate mean ATRP over the lookback period\n",
    "            idx_product = pd.MultiIndex.from_product(\n",
    "                [eligible_tickers, lookback_close.index], names=[\"Ticker\", \"Date\"]\n",
    "            )\n",
    "            feat_slice_period = self.features_df.reindex(idx_product)\n",
    "            atrp_value_for_obs = (\n",
    "                feat_slice_period[\"ATRP\"].groupby(level=\"Ticker\").mean()\n",
    "            )\n",
    "\n",
    "            # --- PINPOINT CHANGE: Calculate mean TRP over lookback ---\n",
    "            trp_value_for_obs = feat_slice_period[\"TRP\"].groupby(level=\"Ticker\").mean()\n",
    "\n",
    "            # Update the observation dictionary\n",
    "            observation: MarketObservation = {\n",
    "                # ...\n",
    "                \"atrp\": atrp_value_for_obs,\n",
    "                \"trp\": trp_value_for_obs,  # <--- PINPOINT CHANGE: Pass the lookback mean\n",
    "                # ...\n",
    "            }\n",
    "\n",
    "            # 2. Package the Observation (The 'State')\n",
    "            observation: MarketObservation = {\n",
    "                # Time Series Data\n",
    "                \"lookback_close\": lookback_close,\n",
    "                \"lookback_returns\": lookback_close.ffill().pct_change(),\n",
    "                # Snapshot Data (Scalar values for today)\n",
    "                \"atrp\": atrp_value_for_obs,  # <--- USES THE TOGGLED VALUE HERE\n",
    "                \"trp\": trp_value_for_obs,  # <--- PINPOINT CHANGE: Pass the lookback mean\n",
    "                \"rsi\": feat_slice_current[\"RSI\"],\n",
    "                \"rel_strength\": feat_slice_current[\"RelStrength\"],\n",
    "                \"vol_regime\": feat_slice_current[\"VolRegime\"],\n",
    "                \"rvol\": feat_slice_current[\"RVol\"],\n",
    "                \"spy_rvol\": feat_slice_current[\"Spy_RVol\"],\n",
    "                \"obv_score\": feat_slice_current[\"OBV_Score\"],\n",
    "                \"spy_obv_score\": feat_slice_current[\"Spy_OBV_Score\"],\n",
    "                # Momentum Vectors\n",
    "                \"roc_1\": feat_slice_current[\"ROC_1\"],\n",
    "                \"roc_3\": feat_slice_current[\"ROC_3\"],\n",
    "                \"roc_5\": feat_slice_current[\"ROC_5\"],\n",
    "                \"roc_10\": feat_slice_current[\"ROC_10\"],\n",
    "                \"roc_21\": feat_slice_current[\"ROC_21\"],\n",
    "            }\n",
    "\n",
    "            # 3. Run the Strategy (The 'Agent')\n",
    "            if inputs.metric not in METRIC_REGISTRY:\n",
    "                return [], pd.DataFrame(), {}, f\"Strategy '{inputs.metric}' not found.\"\n",
    "\n",
    "            metric_vals = METRIC_REGISTRY[inputs.metric](observation)\n",
    "            sorted_tickers = metric_vals.sort_values(ascending=False)\n",
    "            start_r = max(0, inputs.rank_start - 1)\n",
    "            end_r = inputs.rank_end\n",
    "            selected_tickers = sorted_tickers.iloc[start_r:end_r].index.tolist()\n",
    "\n",
    "            # Audit\n",
    "            debug_dict[\"full_universe_ranking\"] = pd.DataFrame(\n",
    "                {\n",
    "                    \"Strategy_Score\": metric_vals,\n",
    "                    \"Lookback_Return_Ann\": observation[\"lookback_returns\"].mean() * 252,\n",
    "                    \"Lookback_ATRP\": observation[\"atrp\"],\n",
    "                }\n",
    "            )\n",
    "\n",
    "            if not selected_tickers:\n",
    "                return (\n",
    "                    [],\n",
    "                    pd.DataFrame(),\n",
    "                    debug_dict,\n",
    "                    \"No tickers generated from ranking.\",\n",
    "                )\n",
    "\n",
    "            results_table = pd.DataFrame(\n",
    "                {\n",
    "                    \"Rank\": range(\n",
    "                        inputs.rank_start, inputs.rank_start + len(selected_tickers)\n",
    "                    ),\n",
    "                    \"Ticker\": selected_tickers,\n",
    "                    \"Strategy Value\": sorted_tickers.loc[selected_tickers].values,\n",
    "                }\n",
    "            ).set_index(\"Ticker\")\n",
    "\n",
    "            return selected_tickers, results_table, debug_dict, None\n",
    "\n",
    "    def _filter_universe(self, date_ts, thresholds, audit_container=None):\n",
    "        avail_dates = (\n",
    "            self.features_df.index.get_level_values(\"Date\").unique().sort_values()\n",
    "        )\n",
    "        valid_dates = avail_dates[avail_dates <= date_ts]\n",
    "        if valid_dates.empty:\n",
    "            return []\n",
    "        target_date = valid_dates[-1]\n",
    "        day_features = self.features_df.xs(target_date, level=\"Date\")\n",
    "\n",
    "        vol_cutoff = thresholds.get(\"min_median_dollar_volume\", 0)\n",
    "        percentile_used = \"N/A\"\n",
    "        if \"min_liquidity_percentile\" in thresholds:\n",
    "            percentile_used = thresholds[\"min_liquidity_percentile\"]\n",
    "            dynamic_val = day_features[\"RollMedDollarVol\"].quantile(percentile_used)\n",
    "            vol_cutoff = max(vol_cutoff, dynamic_val)\n",
    "\n",
    "        mask = (\n",
    "            (day_features[\"RollMedDollarVol\"] >= vol_cutoff)\n",
    "            & (day_features[\"RollingStalePct\"] <= thresholds[\"max_stale_pct\"])\n",
    "            & (day_features[\"RollingSameVolCount\"] <= thresholds[\"max_same_vol_count\"])\n",
    "        )\n",
    "\n",
    "        if audit_container is not None:\n",
    "            audit_container[\"date\"] = target_date\n",
    "            audit_container[\"total_tickers_available\"] = len(day_features)\n",
    "            audit_container[\"percentile_setting\"] = percentile_used\n",
    "            audit_container[\"final_cutoff_usd\"] = vol_cutoff\n",
    "            audit_container[\"tickers_passed\"] = mask.sum()\n",
    "            snapshot = day_features.copy()\n",
    "            snapshot[\"Calculated_Cutoff\"] = vol_cutoff\n",
    "            snapshot[\"Passed_Vol_Check\"] = snapshot[\"RollMedDollarVol\"] >= vol_cutoff\n",
    "            snapshot[\"Passed_Final\"] = mask\n",
    "            snapshot = snapshot.sort_values(\"RollMedDollarVol\", ascending=False)\n",
    "            audit_container[\"universe_snapshot\"] = snapshot\n",
    "\n",
    "        return day_features[mask].index.tolist()\n",
    "\n",
    "    def _calculate_period_metrics(\n",
    "        self,\n",
    "        f_val,\n",
    "        f_ret,\n",
    "        f_atrp,\n",
    "        f_trp,\n",
    "        decision_date,\n",
    "        h_val,\n",
    "        h_ret,\n",
    "        h_atrp,\n",
    "        h_trp,\n",
    "        prefix,  # <--- Added trp args\n",
    "    ):\n",
    "        metrics = {}\n",
    "        slices = {}\n",
    "\n",
    "        # 1. Temporal Slicing (Routing)\n",
    "        lb_val, lb_ret, lb_atrp, lb_trp = (\n",
    "            f_val.loc[:decision_date],\n",
    "            f_ret.loc[:decision_date],\n",
    "            f_atrp.loc[:decision_date],\n",
    "            f_trp.loc[:decision_date],\n",
    "        )\n",
    "\n",
    "        # Use the new unified QuantUtils calls\n",
    "        metrics[f\"full_{prefix}_gain\"] = QuantUtils.calculate_gain(f_val)\n",
    "        metrics[f\"full_{prefix}_sharpe\"] = QuantUtils.calculate_sharpe(f_ret)\n",
    "        metrics[f\"full_{prefix}_sharpe_atrp\"] = QuantUtils.calculate_sharpe_vol(\n",
    "            f_ret, f_atrp\n",
    "        )\n",
    "        metrics[f\"full_{prefix}_sharpe_trp\"] = QuantUtils.calculate_sharpe_vol(\n",
    "            f_ret, f_trp\n",
    "        )\n",
    "\n",
    "        metrics[f\"lookback_{prefix}_gain\"] = QuantUtils.calculate_gain(lb_val)\n",
    "        metrics[f\"lookback_{prefix}_sharpe\"] = QuantUtils.calculate_sharpe(lb_ret)\n",
    "        metrics[f\"lookback_{prefix}_sharpe_atrp\"] = QuantUtils.calculate_sharpe_vol(\n",
    "            lb_ret, lb_atrp\n",
    "        )\n",
    "        metrics[f\"lookback_{prefix}_sharpe_trp\"] = QuantUtils.calculate_sharpe_vol(\n",
    "            lb_ret, lb_trp\n",
    "        )\n",
    "\n",
    "        metrics[f\"holding_{prefix}_gain\"] = QuantUtils.calculate_gain(h_val)\n",
    "        metrics[f\"holding_{prefix}_sharpe\"] = QuantUtils.calculate_sharpe(h_ret)\n",
    "        metrics[f\"holding_{prefix}_sharpe_atrp\"] = QuantUtils.calculate_sharpe_vol(\n",
    "            h_ret, h_atrp\n",
    "        )\n",
    "        metrics[f\"holding_{prefix}_sharpe_trp\"] = QuantUtils.calculate_sharpe_vol(\n",
    "            h_ret, h_trp\n",
    "        )\n",
    "\n",
    "        # 5. Metadata Collection\n",
    "        (\n",
    "            slices[\"full_val\"],\n",
    "            slices[\"full_ret\"],\n",
    "            slices[\"full_atrp\"],\n",
    "            slices[\"full_trp\"],\n",
    "        ) = (\n",
    "            f_val,\n",
    "            f_ret,\n",
    "            f_atrp,\n",
    "            f_trp,\n",
    "        )\n",
    "        (\n",
    "            slices[\"lookback_val\"],\n",
    "            slices[\"lookback_ret\"],\n",
    "            slices[\"lookback_atrp\"],\n",
    "            slices[\"lookback_trp\"],\n",
    "        ) = (\n",
    "            lb_val,\n",
    "            lb_ret,\n",
    "            lb_atrp,\n",
    "            lb_trp,\n",
    "        )\n",
    "        (\n",
    "            slices[\"holding_val\"],\n",
    "            slices[\"holding_ret\"],\n",
    "            slices[\"holding_atrp\"],\n",
    "            slices[\"holding_trp\"],\n",
    "        ) = (\n",
    "            h_val,\n",
    "            h_ret,\n",
    "            h_atrp,\n",
    "            h_trp,\n",
    "        )\n",
    "\n",
    "        return metrics, slices\n",
    "\n",
    "    def _get_normalized_plot_data(self, tickers, start_date, end_date):\n",
    "        if not tickers:\n",
    "            return pd.DataFrame()\n",
    "        data = self.df_close[list(set(tickers))].loc[start_date:end_date]\n",
    "        if data.empty:\n",
    "            return pd.DataFrame()\n",
    "        return data / data.bfill().iloc[0]\n",
    "\n",
    "    def _error_result(self, msg):\n",
    "        return EngineOutput(\n",
    "            portfolio_series=pd.Series(dtype=float),\n",
    "            benchmark_series=pd.Series(dtype=float),\n",
    "            normalized_plot_data=pd.DataFrame(),\n",
    "            tickers=[],\n",
    "            initial_weights=pd.Series(dtype=float),\n",
    "            perf_metrics={},\n",
    "            results_df=pd.DataFrame(),\n",
    "            start_date=pd.Timestamp.min,\n",
    "            decision_date=pd.Timestamp.min,\n",
    "            buy_date=pd.Timestamp.min,\n",
    "            holding_end_date=pd.Timestamp.min,\n",
    "            error_msg=msg,\n",
    "        )\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION E: THE UI (Visualization)\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "def plot_walk_forward_analyzer(\n",
    "    df_ohlcv,\n",
    "    features_df=None,\n",
    "    df_close_wide=None,\n",
    "    df_atrp_wide=None,\n",
    "    df_trp_wide=None,\n",
    "    default_start_date=\"2025-01-17\",\n",
    "    default_lookback=10,\n",
    "    default_holding=5,\n",
    "    default_strategy=\"Sharpe (ATRP)\",\n",
    "    default_rank_start=1,\n",
    "    default_rank_end=10,\n",
    "    default_benchmark_ticker=GLOBAL_SETTINGS[\"benchmark_ticker\"],\n",
    "    master_calendar_ticker=GLOBAL_SETTINGS[\"calendar_ticker\"],\n",
    "    quality_thresholds=GLOBAL_SETTINGS[\"thresholds\"],\n",
    "    debug=True,\n",
    "):\n",
    "\n",
    "    engine = AlphaEngine(\n",
    "        df_ohlcv,\n",
    "        features_df=features_df,\n",
    "        df_close_wide=df_close_wide,\n",
    "        df_atrp_wide=df_atrp_wide,\n",
    "        df_trp_wide=df_trp_wide,  # <--- Update your class to accept this\n",
    "        master_ticker=master_calendar_ticker,\n",
    "    )\n",
    "\n",
    "    # Initialize containers\n",
    "    audit_pack = [None]  # Unified container\n",
    "\n",
    "    # If no thresholds passed, use the global Source of Truth\n",
    "    if quality_thresholds is None:\n",
    "        quality_thresholds = GLOBAL_SETTINGS[\"thresholds\"]\n",
    "\n",
    "    # --- Widgets ---\n",
    "    mode_selector = widgets.RadioButtons(\n",
    "        options=[\"Ranking\", \"Manual List\"],\n",
    "        value=\"Ranking\",\n",
    "        description=\"Mode:\",\n",
    "        layout={\"width\": \"max-content\"},\n",
    "        style={\"description_width\": \"initial\"},\n",
    "    )\n",
    "    lookback_input = widgets.IntText(\n",
    "        value=default_lookback,\n",
    "        description=\"Lookback (Days):\",\n",
    "        layout={\"width\": \"200px\"},\n",
    "        style={\"description_width\": \"initial\"},\n",
    "    )\n",
    "    decision_date_picker = widgets.DatePicker(\n",
    "        description=\"Decision Date:\",\n",
    "        value=pd.to_datetime(default_start_date),\n",
    "        layout={\"width\": \"auto\"},\n",
    "        style={\"description_width\": \"initial\"},\n",
    "    )\n",
    "    holding_input = widgets.IntText(\n",
    "        value=default_holding,\n",
    "        description=\"Holding (Days):\",\n",
    "        layout={\"width\": \"200px\"},\n",
    "        style={\"description_width\": \"initial\"},\n",
    "    )\n",
    "    strategy_dropdown = widgets.Dropdown(\n",
    "        options=list(METRIC_REGISTRY.keys()),\n",
    "        value=default_strategy,\n",
    "        description=\"Strategy:\",\n",
    "        layout={\"width\": \"220px\"},\n",
    "        style={\"description_width\": \"initial\"},\n",
    "    )\n",
    "    benchmark_input = widgets.Text(\n",
    "        value=default_benchmark_ticker,\n",
    "        description=\"Benchmark:\",\n",
    "        placeholder=\"Enter Ticker\",\n",
    "        layout={\"width\": \"180px\"},\n",
    "        style={\"description_width\": \"initial\"},\n",
    "    )\n",
    "    rank_start_input = widgets.IntText(\n",
    "        value=default_rank_start,\n",
    "        description=\"Rank Start:\",\n",
    "        layout={\"width\": \"150px\"},\n",
    "        style={\"description_width\": \"initial\"},\n",
    "    )\n",
    "    rank_end_input = widgets.IntText(\n",
    "        value=default_rank_end,\n",
    "        description=\"Rank End:\",\n",
    "        layout={\"width\": \"150px\"},\n",
    "        style={\"description_width\": \"initial\"},\n",
    "    )\n",
    "    manual_tickers_input = widgets.Textarea(\n",
    "        value=\"\",\n",
    "        placeholder=\"Enter tickers...\",\n",
    "        description=\"Manual Tickers:\",\n",
    "        layout={\"width\": \"400px\", \"height\": \"80px\"},\n",
    "        style={\"description_width\": \"initial\"},\n",
    "    )\n",
    "    update_button = widgets.Button(description=\"Run Simulation\", button_style=\"primary\")\n",
    "    ticker_list_output = widgets.Output()\n",
    "\n",
    "    # --- Layouts ---\n",
    "    timeline_box = widgets.HBox(\n",
    "        [lookback_input, decision_date_picker, holding_input],\n",
    "        layout=widgets.Layout(\n",
    "            justify_content=\"space-between\",\n",
    "            border=\"1px solid #ddd\",\n",
    "            padding=\"10px\",\n",
    "            margin=\"5px\",\n",
    "        ),\n",
    "    )\n",
    "    strategy_box = widgets.HBox([strategy_dropdown, benchmark_input])\n",
    "    ranking_box = widgets.HBox([rank_start_input, rank_end_input])\n",
    "\n",
    "    def on_mode_change(c):\n",
    "        ranking_box.layout.display = \"flex\" if c[\"new\"] == \"Ranking\" else \"none\"\n",
    "        manual_tickers_input.layout.display = (\n",
    "            \"none\" if c[\"new\"] == \"Ranking\" else \"flex\"\n",
    "        )\n",
    "        strategy_dropdown.disabled = c[\"new\"] == \"Manual List\"\n",
    "\n",
    "    mode_selector.observe(on_mode_change, names=\"value\")\n",
    "    on_mode_change({\"new\": mode_selector.value})\n",
    "\n",
    "    ui = widgets.VBox(\n",
    "        [\n",
    "            widgets.HTML(\n",
    "                \"<b>1. Timeline Configuration:</b> (Past <--- Decision ---> Future)\"\n",
    "            ),\n",
    "            timeline_box,\n",
    "            widgets.HTML(\"<b>2. Strategy Settings:</b>\"),\n",
    "            widgets.HBox([mode_selector, strategy_box]),\n",
    "            ranking_box,\n",
    "            manual_tickers_input,\n",
    "            widgets.HTML(\"<hr>\"),\n",
    "            update_button,\n",
    "            ticker_list_output,\n",
    "        ],\n",
    "        layout=widgets.Layout(margin=\"10px 0 20px 0\"),\n",
    "    )\n",
    "\n",
    "    fig = go.FigureWidget()\n",
    "    fig.update_layout(\n",
    "        title=\"Event-Driven Walk-Forward Analysis\",\n",
    "        height=600,\n",
    "        template=\"plotly_white\",\n",
    "        hovermode=\"x unified\",\n",
    "    )\n",
    "    for i in range(50):\n",
    "        fig.add_trace(go.Scatter(visible=False, line=dict(width=2)))\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            name=\"Benchmark\",\n",
    "            visible=True,\n",
    "            line=dict(color=\"black\", width=3, dash=\"dash\"),\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            name=\"Group Portfolio\", visible=True, line=dict(color=\"green\", width=3)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # --- Update Logic ---\n",
    "    def update_plot(b):\n",
    "        ticker_list_output.clear_output()\n",
    "        manual_list = [\n",
    "            t.strip().upper()\n",
    "            for t in manual_tickers_input.value.split(\",\")\n",
    "            if t.strip()\n",
    "        ]\n",
    "        decision_date_raw = pd.to_datetime(decision_date_picker.value)\n",
    "\n",
    "        inputs = EngineInput(\n",
    "            mode=mode_selector.value,\n",
    "            start_date=decision_date_raw,\n",
    "            lookback_period=lookback_input.value,\n",
    "            holding_period=holding_input.value,\n",
    "            metric=strategy_dropdown.value,\n",
    "            benchmark_ticker=benchmark_input.value.strip().upper(),\n",
    "            rank_start=rank_start_input.value,\n",
    "            rank_end=rank_end_input.value,\n",
    "            quality_thresholds=quality_thresholds,\n",
    "            manual_tickers=manual_list,\n",
    "            debug=debug,\n",
    "        )\n",
    "\n",
    "        ########################################\n",
    "        with ticker_list_output:\n",
    "            res = engine.run(inputs)\n",
    "\n",
    "            # CLEANUP: audit_pack now stores the exact output object.\n",
    "            # No need to manually map 'debug' or 'results' since res contains both.\n",
    "            audit_pack[0] = res\n",
    "\n",
    "            if res.error_msg:\n",
    "                print(f\"âš ï¸ Simulation Stopped: {res.error_msg}\")\n",
    "                return\n",
    "\n",
    "            # ... (Plotting code only runs if res.normalized_plot_data is not empty) ...\n",
    "            if not res.normalized_plot_data.empty:\n",
    "                # Plotting\n",
    "                with fig.batch_update():\n",
    "                    cols = res.normalized_plot_data.columns.tolist()\n",
    "                    for i in range(50):\n",
    "                        if i < len(cols):\n",
    "                            fig.data[i].update(\n",
    "                                x=res.normalized_plot_data.index,\n",
    "                                y=res.normalized_plot_data[cols[i]],\n",
    "                                name=cols[i],\n",
    "                                visible=True,\n",
    "                            )\n",
    "                        else:\n",
    "                            fig.data[i].visible = False\n",
    "\n",
    "                    fig.data[50].update(\n",
    "                        x=res.benchmark_series.index,\n",
    "                        y=res.benchmark_series.values,\n",
    "                        name=f\"Benchmark ({inputs.benchmark_ticker})\",\n",
    "                        visible=not res.benchmark_series.empty,\n",
    "                    )\n",
    "                    fig.data[51].update(\n",
    "                        x=res.portfolio_series.index,\n",
    "                        y=res.portfolio_series.values,\n",
    "                        visible=True,\n",
    "                    )\n",
    "\n",
    "                    # Visual Lines\n",
    "                    fig.layout.shapes = [\n",
    "                        dict(\n",
    "                            type=\"line\",\n",
    "                            x0=res.decision_date,\n",
    "                            y0=0,\n",
    "                            x1=res.decision_date,\n",
    "                            y1=1,\n",
    "                            xref=\"x\",\n",
    "                            yref=\"paper\",\n",
    "                            line=dict(color=\"red\", width=2, dash=\"dash\"),\n",
    "                        ),\n",
    "                        dict(\n",
    "                            type=\"line\",\n",
    "                            x0=res.buy_date,\n",
    "                            y0=0,\n",
    "                            x1=res.buy_date,\n",
    "                            y1=1,\n",
    "                            xref=\"x\",\n",
    "                            yref=\"paper\",\n",
    "                            line=dict(color=\"blue\", width=2, dash=\"dot\"),\n",
    "                        ),\n",
    "                    ]\n",
    "\n",
    "                    fig.layout.annotations = [\n",
    "                        dict(\n",
    "                            x=res.decision_date,\n",
    "                            y=0.05,\n",
    "                            xref=\"x\",\n",
    "                            yref=\"paper\",\n",
    "                            text=\"DECISION\",\n",
    "                            showarrow=False,\n",
    "                            bgcolor=\"red\",\n",
    "                            font=dict(color=\"white\"),\n",
    "                        ),\n",
    "                        dict(\n",
    "                            x=res.buy_date,\n",
    "                            y=1.0,\n",
    "                            xref=\"x\",\n",
    "                            yref=\"paper\",\n",
    "                            text=\"ENTRY (T+1)\",\n",
    "                            showarrow=False,\n",
    "                            bgcolor=\"blue\",\n",
    "                            font=dict(color=\"white\"),\n",
    "                        ),\n",
    "                    ]\n",
    "\n",
    "                start_date = res.start_date.date()\n",
    "                act_date = res.decision_date.date()\n",
    "                entry_date = res.buy_date.date()\n",
    "\n",
    "            # Liquidity Audit Print\n",
    "            if (\n",
    "                inputs.mode == \"Ranking\"\n",
    "                and res.debug_data\n",
    "                and \"audit_liquidity\" in res.debug_data\n",
    "            ):\n",
    "                audit = res.debug_data[\"audit_liquidity\"]\n",
    "                if audit:\n",
    "                    raw_percentile = audit.get(\"percentile_setting\", 0)\n",
    "                    keep_pct = (\n",
    "                        1 - raw_percentile\n",
    "                    ) * 100  # Calculates the actual portion kept\n",
    "                    cut_val = audit.get(\"final_cutoff_usd\", 0)\n",
    "\n",
    "                    print(\"-\" * 60)\n",
    "                    print(f\"ðŸ” LIQUIDITY CHECK (On Decision Date: {act_date})\")\n",
    "                    print(\n",
    "                        f\"   Universe Size: {audit.get('total_tickers_available')} tickers\"\n",
    "                    )\n",
    "                    print(\n",
    "                        f\"   Liquidity Threshold: {raw_percentile*100:.0f}th Percentile\"\n",
    "                    )\n",
    "                    print(f\"   Action: Keeping the Top {keep_pct:.0f}% of Market\")\n",
    "                    print(f\"   Calculated Cutoff: ${cut_val:,.0f} / day\")\n",
    "                    print(f\"   Tickers Remaining: {audit.get('tickers_passed')}\")\n",
    "                    print(\"-\" * 60)\n",
    "\n",
    "            # --- UPDATED TIMELINE PRINT ---\n",
    "            print(\n",
    "                f\"Timeline: Start [ {start_date} ] --> Decision [ {act_date} ] --> Cash (1d) --> Entry [ {entry_date} ] --> End [ {res.holding_end_date.date()} ]\"\n",
    "            )\n",
    "\n",
    "            if inputs.mode == \"Ranking\":\n",
    "                print(f\"Ranked Tickers ({len(res.tickers)}):\")\n",
    "                for i in range(0, len(res.tickers), 10):\n",
    "                    print(\", \".join(res.tickers[i : i + 10]))\n",
    "            else:\n",
    "                print(\"Manual Portfolio Tickers:\")\n",
    "                for i in range(0, len(res.tickers), 10):\n",
    "                    print(\", \".join(res.tickers[i : i + 10]))\n",
    "\n",
    "            m = res.perf_metrics\n",
    "\n",
    "            # --- DRY UI GENERATION ---\n",
    "            # 1. Define the metrics we want to display\n",
    "            metrics_to_show = [\n",
    "                (\"Gain\", \"gain\"),\n",
    "                (\"Sharpe\", \"sharpe\"),\n",
    "                (\"Sharpe (ATRP)\", \"sharpe_atrp\"),\n",
    "                (\"Sharpe (TRP)\", \"sharpe_trp\"),  # <--- PINPOINT CHANGE: Add this line\n",
    "            ]\n",
    "\n",
    "            rows = []\n",
    "            for label, key in metrics_to_show:\n",
    "                p_row = {\n",
    "                    \"Metric\": f\"Group {label}\",\n",
    "                    \"Full\": m.get(f\"full_p_{key}\"),\n",
    "                    \"Lookback\": m.get(f\"lookback_p_{key}\"),\n",
    "                    \"Holding\": m.get(f\"holding_p_{key}\"),\n",
    "                }\n",
    "                b_row = {\n",
    "                    \"Metric\": f\"Benchmark {label}\",\n",
    "                    \"Full\": m.get(f\"full_b_{key}\"),\n",
    "                    \"Lookback\": m.get(f\"lookback_b_{key}\"),\n",
    "                    \"Holding\": m.get(f\"holding_b_{key}\"),\n",
    "                }\n",
    "\n",
    "                # Delta calculation\n",
    "                d_row = {\"Metric\": f\"== {label} Delta\"}\n",
    "                for col in [\"Full\", \"Lookback\", \"Holding\"]:\n",
    "                    d_row[col] = (p_row[col] or 0) - (b_row[col] or 0)\n",
    "\n",
    "                rows.extend([p_row, b_row, d_row])\n",
    "\n",
    "            df_report = pd.DataFrame(rows).set_index(\"Metric\")\n",
    "\n",
    "            # --- 2. STYLING (The \"Senior\" Design) ---\n",
    "            # --- 1. PREP DATA (Flattening the Index) ---\n",
    "            # We convert the index to a column so \"Metric\" sits on the same row as other headers\n",
    "            df_report = pd.DataFrame(rows)\n",
    "            df_report = df_report.set_index(\"Metric\")\n",
    "\n",
    "            # --- 2. THE STYLING (Sleek & Proportional) ---\n",
    "            def apply_sleek_style(styler):\n",
    "                # Match notebook font size (usually 13px)\n",
    "                styler.format(\"{:+.4f}\", na_rep=\"N/A\")\n",
    "\n",
    "                # Dynamic Row Highlighting\n",
    "                def row_logic(row):\n",
    "                    if \"Delta\" in row.name:\n",
    "                        return [\n",
    "                            \"background-color: #f9f9f9; font-weight: 600; border-top: 1px solid #ddd\"\n",
    "                        ] * len(row)\n",
    "                    if \"Group\" in row.name:\n",
    "                        return [\"color: #2c5e8f; background-color: #fcfdfe\"] * len(row)\n",
    "                    return [\"color: #555\"] * len(\n",
    "                        row\n",
    "                    )  # Benchmark rows are slightly muted\n",
    "\n",
    "                styler.apply(row_logic, axis=1)\n",
    "\n",
    "                styler.set_table_styles(\n",
    "                    [\n",
    "                        # Base Table Font - Scaling down to match standard text\n",
    "                        {\n",
    "                            \"selector\": \"\",\n",
    "                            \"props\": [\n",
    "                                (\"font-family\", \"inherit\"),\n",
    "                                (\"font-size\", \"12px\"),\n",
    "                                (\"border-collapse\", \"collapse\"),\n",
    "                                (\"width\", \"auto\"),\n",
    "                                (\"margin-left\", \"0\"),\n",
    "                            ],\n",
    "                        },\n",
    "                        # Header Row - Flattened and Muted\n",
    "                        {\n",
    "                            \"selector\": \"th\",\n",
    "                            \"props\": [\n",
    "                                (\"background-color\", \"white\"),\n",
    "                                (\"color\", \"#222\"),\n",
    "                                (\"font-weight\", \"600\"),\n",
    "                                (\"padding\", \"6px 12px\"),\n",
    "                                (\"border-bottom\", \"2px solid #444\"),\n",
    "                                (\"text-align\", \"center\"),\n",
    "                                (\n",
    "                                    \"vertical-align\",\n",
    "                                    \"bottom\",\n",
    "                                ),  # Aligns 'Metric' with others\n",
    "                            ],\n",
    "                        },\n",
    "                        # Index Column (The \"Metric\" labels)\n",
    "                        {\n",
    "                            \"selector\": \"th.row_heading\",\n",
    "                            \"props\": [\n",
    "                                (\"text-align\", \"left\"),\n",
    "                                (\"padding-right\", \"30px\"),\n",
    "                                (\"border-bottom\", \"1px solid #eee\"),\n",
    "                            ],\n",
    "                        },\n",
    "                        # Cell Data - Tighter padding\n",
    "                        {\n",
    "                            \"selector\": \"td\",\n",
    "                            \"props\": [\n",
    "                                (\"padding\", \"4px 12px\"),\n",
    "                                (\"border-bottom\", \"1px solid #eee\"),\n",
    "                            ],\n",
    "                        },\n",
    "                        # Remove the extra \"Index Name\" row completely\n",
    "                        {\n",
    "                            \"selector\": \"thead tr:nth-child(1) th\",\n",
    "                            \"props\": [(\"display\", \"table-cell\")],\n",
    "                        },\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                # Hack to fix the 'Metric' alignment:\n",
    "                # We remove the index name and set it as the horizontal label for the index\n",
    "                styler.index.name = None\n",
    "\n",
    "                return styler\n",
    "\n",
    "            display(apply_sleek_style(df_report.style))\n",
    "\n",
    "    update_button.on_click(update_plot)\n",
    "    update_plot(None)\n",
    "    display(ui, fig)\n",
    "    return audit_pack  # <--- Return ONLY ONE\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION F: INSPECTION TOOLS\n",
    "# ==============================================================================\n",
    "\n",
    "from dataclasses import is_dataclass, fields\n",
    "import pandas as pd\n",
    "\n",
    "_AUDIT_REGISTRY = {}\n",
    "_SEEN_MEM_IDS = {}\n",
    "\n",
    "\n",
    "def verify_engine_results_short_form(\n",
    "    item, name=\"audit_pack\", indent=0, reset=True, path=\"\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Categorized audit inspector with Breadcrumb Path tracking.\n",
    "    \"\"\"\n",
    "    global _AUDIT_REGISTRY, _SEEN_MEM_IDS\n",
    "\n",
    "    if reset and indent == 0:\n",
    "        _AUDIT_REGISTRY = {}\n",
    "        _SEEN_MEM_IDS = {}\n",
    "        path = name\n",
    "        print(f\"\\n{'='*65}\\nðŸ” HIGH-TRANSPARENCY AUDIT MAP\\n{'='*65}\")\n",
    "\n",
    "    mem_id = id(item)\n",
    "\n",
    "    # 1. Deduplication Guard\n",
    "    if mem_id in _SEEN_MEM_IDS and isinstance(\n",
    "        item, (dict, list, pd.DataFrame, pd.Series)\n",
    "    ):\n",
    "        prev_idx = _SEEN_MEM_IDS[mem_id]\n",
    "        print(f\"      {'  '*indent}â•°â”€â”€ {name} --> [See ID {prev_idx}]\")\n",
    "        return\n",
    "\n",
    "    # 2. Register with Breadcrumbs\n",
    "    idx = len(_AUDIT_REGISTRY)\n",
    "    current_path = f\"{path} -> {name}\" if indent > 0 else name\n",
    "    _AUDIT_REGISTRY[idx] = {\"data\": item, \"path\": current_path}\n",
    "    _SEEN_MEM_IDS[mem_id] = idx\n",
    "\n",
    "    # 3. Visual Headers for Major Sections\n",
    "    if indent == 1:\n",
    "        headers = {\n",
    "            \"inputs\": \"âš™ï¸ SYSTEM CONFIGURATION & THRESHOLDS\",\n",
    "            \"results\": \"ðŸ“ˆ PERFORMANCE & EQUITY CURVES\",\n",
    "            \"debug\": \"ðŸ” AUDIT TRAIL & VERIFICATION MATRICES\",\n",
    "        }\n",
    "        if name in headers:\n",
    "            print(f\"\\n{headers[name]}\\n{'-'*45}\")\n",
    "\n",
    "    # 4. Icon & Metadata Resolution\n",
    "    icon = \"ðŸ“‚\"\n",
    "    if isinstance(item, pd.DataFrame):\n",
    "        icon = \"ðŸ§®\"\n",
    "    elif isinstance(item, pd.Series):\n",
    "        icon = \"ðŸ“ˆ\"\n",
    "    elif isinstance(item, (pd.Timestamp, datetime, date)):\n",
    "        icon = \"ðŸ“…\"\n",
    "    elif isinstance(item, (int, float)):\n",
    "        icon = \"ðŸ”¢\"\n",
    "    elif is_dataclass(item):\n",
    "        icon = \"ðŸ“¦\"\n",
    "\n",
    "    # 5. Print Tree Line\n",
    "    spacing = \"  \" * indent\n",
    "    shape = f\" shape={item.shape}\" if hasattr(item, \"shape\") else \"\"\n",
    "\n",
    "    # Handle Simple Lists\n",
    "    if isinstance(item, list) and all(isinstance(x, (str, int, float)) for x in item):\n",
    "        content = (\n",
    "            str(item) if len(str(item)) < 50 else f\"{item[:3]}... [+ {len(item)-3}]\"\n",
    "        )\n",
    "        print(f\"[{idx: >3}] {spacing}{icon} {name}: {content}\")\n",
    "        return\n",
    "\n",
    "    print(f\"[{idx: >3}] {spacing}{icon} {name} ({type(item).__name__}{shape})\")\n",
    "\n",
    "    # 6. Recursion\n",
    "    if isinstance(item, list):\n",
    "        for i, val in enumerate(item):\n",
    "            verify_engine_results_short_form(\n",
    "                val,\n",
    "                name=f\"index_{i}\",\n",
    "                indent=indent + 1,\n",
    "                reset=False,\n",
    "                path=current_path,\n",
    "            )\n",
    "    elif isinstance(item, dict):\n",
    "        for k in sorted(item.keys()):\n",
    "            verify_engine_results_short_form(\n",
    "                item[k], name=k, indent=indent + 1, reset=False, path=current_path\n",
    "            )\n",
    "    elif is_dataclass(item):\n",
    "        for field in fields(item):\n",
    "            verify_engine_results_short_form(\n",
    "                getattr(item, field.name),\n",
    "                name=field.name,\n",
    "                indent=indent + 1,\n",
    "                reset=False,\n",
    "                path=current_path,\n",
    "            )\n",
    "\n",
    "\n",
    "def get_audit(idx: int):\n",
    "    \"\"\"\n",
    "    Fetches an object with a 'Smart Header' breadcrumb trail.\n",
    "    \"\"\"\n",
    "    entry = _AUDIT_REGISTRY.get(idx)\n",
    "    if not entry:\n",
    "        print(f\"âŒ ID [{idx}] not found.\")\n",
    "        return None\n",
    "\n",
    "    obj = entry[\"data\"]\n",
    "    path = entry[\"path\"]\n",
    "\n",
    "    # Generate the Smart Header\n",
    "    type_name = type(obj).__name__\n",
    "    meta = f\"Shape: {obj.shape}\" if hasattr(obj, \"shape\") else f\"Value: {obj}\"\n",
    "\n",
    "    print(f\"\\nðŸ“Œ FETCHING ID [{idx}]: {path}\")\n",
    "    print(f\"   [Type: {type_name} | {meta}]\")\n",
    "    print(\"-\" * 75)\n",
    "\n",
    "    return obj\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# INTEGRITY PROTECTION: THE TRIPWIRE\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "def verify_math_integrity():\n",
    "    \"\"\"\n",
    "    ðŸ›¡ï¸ TRIPWIRE: Ensures Sample Boundary Integrity.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- ðŸ›¡ï¸ Starting Final Integrity Audit ---\")\n",
    "\n",
    "    try:\n",
    "        # Test 1: Series Input\n",
    "        mock_series = pd.Series([100.0, 102.0, 101.0])\n",
    "        rets_s = QuantUtils.compute_returns(mock_series)\n",
    "        # Verify first value is actually NaN\n",
    "        if not pd.isna(rets_s.iloc[0]):\n",
    "            raise ValueError(\"Series Leading NaN missing\")\n",
    "        print(\"âœ… Series Boundary: OK\")\n",
    "\n",
    "        # Test 2: DataFrame Input\n",
    "        mock_df = pd.DataFrame({\"A\": [100, 101], \"B\": [200, 202]})\n",
    "        rets_df = QuantUtils.compute_returns(mock_df)\n",
    "        if not rets_df.iloc[0].isna().all():\n",
    "            raise ValueError(\"DataFrame Leading NaN missing\")\n",
    "        print(\"âœ… DataFrame Boundary: OK\")\n",
    "\n",
    "        print(\"âœ… AUDIT PASSED: Mathematical boundaries are strictly enforced.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ðŸ”¥ SYSTEM BREACH: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "\n",
    "def verify_feature_engineering_integrity():\n",
    "    \"\"\"\n",
    "    ðŸ›¡ï¸ TRIPWIRE: Validates Feature Engineering Logic.\n",
    "    Enforces:\n",
    "    1. Day 1 ATR must be NaN (No PrevClose).\n",
    "    2. Wilder's Smoothing must use Alpha = 1/Period.\n",
    "    3. Recursion must match manual calculation.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- ðŸ›¡ï¸ Starting Feature Engineering Audit ---\")\n",
    "\n",
    "    # 1. Create Synthetic Data (3 Days)\n",
    "    # Day 1: High-Low = 10. No PrevClose.\n",
    "    # Day 2: High-Low = 20. Gap up implies TR might be larger.\n",
    "    # Day 3: High-Low = 10.\n",
    "    dates = pd.to_datetime([\"2020-01-01\", \"2020-01-02\", \"2020-01-03\"])\n",
    "    idx = pd.MultiIndex.from_product([[\"TEST\"], dates], names=[\"Ticker\", \"Date\"])\n",
    "\n",
    "    df_mock = pd.DataFrame(\n",
    "        {\n",
    "            \"Adj Open\": [100, 110, 110],\n",
    "            \"Adj High\": [110, 130, 120],\n",
    "            \"Adj Low\": [100, 110, 110],\n",
    "            \"Adj Close\": [105, 120, 115],  # PrevClose: NaN, 105, 120\n",
    "            \"Volume\": [1000, 1000, 1000],\n",
    "        },\n",
    "        index=idx,\n",
    "    )\n",
    "\n",
    "    # 2. Run the Generator\n",
    "    # We use Period=2 to make manual math easy (Alpha = 1/2 = 0.5)\n",
    "    feats = generate_features(\n",
    "        df_mock, atr_period=2, rsi_period=2, quality_min_periods=1\n",
    "    )\n",
    "    atr_series = feats[\"ATR\"]\n",
    "\n",
    "    # 3. MANUAL CALCULATION (The \"Truth\")\n",
    "    # Day 1:\n",
    "    #   TR = Max(H-L, |H-PC|, |L-PC|)\n",
    "    #   TR = Max(10, NaN, NaN) -> NaN (Because skipna=False)\n",
    "    #   Expected ATR: NaN\n",
    "\n",
    "    # Day 2:\n",
    "    #   PrevClose = 105\n",
    "    #   H-L=20, |130-105|=25, |110-105|=5\n",
    "    #   TR = 25\n",
    "    #   Expected ATR: First valid observation = 25.0\n",
    "\n",
    "    # Day 3:\n",
    "    #   PrevClose = 120\n",
    "    #   H-L=10, |120-120|=0, |110-120|=10\n",
    "    #   TR = 10\n",
    "    #   Wilder's Smoothing (Alpha=0.5):\n",
    "    #   ATR_3 = (TR_3 * alpha) + (ATR_2 * (1-alpha))\n",
    "    #   ATR_3 = (10 * 0.5) + (25 * 0.5) = 5 + 12.5 = 17.5\n",
    "\n",
    "    print(f\"Audit Values:\\n{atr_series.values}\")\n",
    "\n",
    "    # 4. ASSERTIONS\n",
    "    try:\n",
    "        # Check Day 1\n",
    "        if not np.isnan(atr_series.iloc[0]):\n",
    "            raise AssertionError(\n",
    "                f\"Day 1 Regression: Expected NaN, got {atr_series.iloc[0]}. (Check skipna=False)\"\n",
    "            )\n",
    "\n",
    "        # Check Day 2 (Initialization)\n",
    "        if not np.isclose(atr_series.iloc[1], 25.0):\n",
    "            raise AssertionError(\n",
    "                f\"Initialization Regression: Expected 25.0, got {atr_series.iloc[1]}.\"\n",
    "            )\n",
    "\n",
    "        # Check Day 3 (Recursion)\n",
    "        if not np.isclose(atr_series.iloc[2], 17.5):\n",
    "            raise AssertionError(\n",
    "                f\"Wilder's Logic Regression: Expected 17.5, got {atr_series.iloc[2]}. (Check Alpha=1/N)\"\n",
    "            )\n",
    "\n",
    "        print(\"âœ… FEATURE INTEGRITY PASSED: Wilder's ATR logic is strictly enforced.\")\n",
    "\n",
    "    except AssertionError as e:\n",
    "        print(f\"ðŸ”¥ LOGIC FAILURE: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "\n",
    "def verify_ranking_integrity():\n",
    "    \"\"\"\n",
    "    ðŸ›¡ï¸ TRIPWIRE: Prevents 'Momentum Collapse' in Volatility-Adjusted Ranking.\n",
    "    Ensures that Sharpe(Vol) distinguishes between High-Vol and Low-Vol stocks.\n",
    "    \"\"\"\n",
    "    print(\"--- ðŸ›¡ï¸ Starting Ranking Kernel Audit ---\")\n",
    "\n",
    "    # 1. Setup Mock Universe (2 Tickers, 2 Days)\n",
    "    # Ticker 'VOLATILE': 10% return, but 10% Volatility\n",
    "    # Ticker 'STABLE': 2% return, but 1% Volatility (The 'Sharpe' Winner)\n",
    "    data = {\"VOLATILE\": [1.0, 1.10], \"STABLE\": [1.0, 1.02]}  # +10%  # +2%\n",
    "    df_returns = pd.DataFrame(data).pct_change().dropna()\n",
    "\n",
    "    # Pre-calculated Mean Volatility per ticker (as provided by Engine Observation)\n",
    "    vol_series = pd.Series({\"VOLATILE\": 0.10, \"STABLE\": 0.01})\n",
    "\n",
    "    # 2. Run Kernel\n",
    "    results = QuantUtils.calculate_sharpe_vol(df_returns, vol_series)\n",
    "\n",
    "    # 3. CALCULATE EXPECTED (Pure Math)\n",
    "    # Volatile Sharpe: 0.10 / 0.10 = 1.0\n",
    "    # Stable Sharpe:   0.02 / 0.01 = 2.0\n",
    "\n",
    "    try:\n",
    "        # Check A: Diversity. If they are the same, normalization didn't happen.\n",
    "        if np.isclose(results[\"VOLATILE\"], results[\"STABLE\"]):\n",
    "            raise AssertionError(\n",
    "                \"RANKING COLLAPSE: Both tickers have the same normalized score.\"\n",
    "            )\n",
    "\n",
    "        # Check B: Direction. STABLE must rank higher than VOLATILE.\n",
    "        if results[\"STABLE\"] < results[\"VOLATILE\"]:\n",
    "            # This is exactly what happens when the bug turns it into Momentum\n",
    "            raise AssertionError(\n",
    "                f\"MOMENTUM REGRESSION: 'STABLE' ({results['STABLE']:.2f}) \"\n",
    "                f\"ranked below 'VOLATILE' ({results['VOLATILE']:.2f}). \"\n",
    "                \"The denominator was likely collapsed to a market average.\"\n",
    "            )\n",
    "\n",
    "        # Check C: Absolute Precision\n",
    "        if not np.isclose(results[\"STABLE\"], 2.0):\n",
    "            raise AssertionError(\n",
    "                f\"MATH ERROR: Expected 2.0 for STABLE, got {results['STABLE']}\"\n",
    "            )\n",
    "\n",
    "        print(\n",
    "            \"âœ… RANKING INTEGRITY PASSED: Volatility normalization is strictly enforced.\"\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ðŸ”¥ KERNEL BREACH: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "\n",
    "def verify_vol_alignment_integrity():\n",
    "    \"\"\"\n",
    "    ðŸ›¡ï¸ TRIPWIRE: Verifies Temporal Coupling between Returns and Volatility.\n",
    "    Ensures that the volatility average is only calculated over days where a return exists.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- ðŸ›¡ï¸ Starting Volatility Alignment Audit ---\")\n",
    "\n",
    "    # 1. SETUP SYNTHETIC DATA (2 Days)\n",
    "    # Day 1: Return = NaN, Vol = 0.90 (Extreme 'Trap' Volatility)\n",
    "    # Day 2: Return = 0.10, Vol = 0.10 (Target Reward/Risk)\n",
    "    rets_s = pd.Series([np.nan, 0.10])\n",
    "    vol_s = pd.Series([0.90, 0.10])\n",
    "\n",
    "    # 2. RUN KERNEL (Series Mode)\n",
    "    # Calculation Logic:\n",
    "    # If aligned: 0.10 / 0.10 = 1.0\n",
    "    # If misaligned: 0.10 / mean(0.90, 0.10) = 0.10 / 0.50 = 0.2\n",
    "    res_series = QuantUtils.calculate_sharpe_vol(rets_s, vol_s)\n",
    "\n",
    "    # 3. RUN KERNEL (DataFrame Mode)\n",
    "    # Ensures vectorized alignment works across columns\n",
    "    rets_df = pd.DataFrame({\"A\": [np.nan, 0.10], \"B\": [np.nan, 0.20]})\n",
    "    vol_df = pd.DataFrame({\"A\": [0.90, 0.10], \"B\": [0.05, 0.20]})\n",
    "    res_df = QuantUtils.calculate_sharpe_vol(rets_df, vol_df)\n",
    "\n",
    "    try:\n",
    "        # Check Series Alignment\n",
    "        if not np.isclose(res_series, 1.0):\n",
    "            raise AssertionError(\n",
    "                f\"DENOMINATOR MISMATCH: Series result {res_series:.2f} != 1.0. \"\n",
    "                \"The volatility denominator is likely including the leading NaN day.\"\n",
    "            )\n",
    "        print(\"âœ… Series Temporal Coupling: OK\")\n",
    "\n",
    "        # Check DataFrame Alignment (Ticker A: 0.1/0.1=1.0 | Ticker B: 0.2/0.2=1.0)\n",
    "        if not (np.isclose(res_df[\"A\"], 1.0) and np.isclose(res_df[\"B\"], 1.0)):\n",
    "            raise AssertionError(\n",
    "                f\"VECTORIZED MISMATCH: DataFrame results {res_df.values} != [1.0, 1.0]. \"\n",
    "                \"The logic is failing to align individual columns.\"\n",
    "            )\n",
    "        print(\"âœ… DataFrame Temporal Coupling: OK\")\n",
    "\n",
    "        print(\"âœ… AUDIT PASSED: Reward and Risk are strictly synchronized.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ðŸ”¥ ALIGNMENT BREACH: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "\n",
    "# Auto-run the checks\n",
    "verify_math_integrity()\n",
    "\n",
    "verify_feature_engineering_integrity()\n",
    "\n",
    "verify_ranking_integrity()\n",
    "\n",
    "verify_vol_alignment_integrity()\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "301d104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SECTION G: AUDIT ENGINE RESULTS\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "def visualize_audit_structure(obj):\n",
    "    \"\"\"\n",
    "    Generates the Map and returns a Registry of dictionaries:\n",
    "    [{'name': str, 'path': str, 'obj': object}, ...]\n",
    "    \"\"\"\n",
    "    id_memory = {}\n",
    "    registry = []\n",
    "    output = [\n",
    "        \"====================================================================\",\n",
    "        \"ðŸ” HIGH-TRANSPARENCY AUDIT MAP\",\n",
    "        \"====================================================================\",\n",
    "    ]\n",
    "\n",
    "    def get_icon(val):\n",
    "        if isinstance(val, pd.DataFrame):\n",
    "            return \"ðŸ§®\"\n",
    "        if isinstance(val, pd.Series):\n",
    "            return \"ðŸ“ˆ\"\n",
    "        if isinstance(val, (list, tuple, dict)):\n",
    "            return \"ðŸ“‚\"\n",
    "        if isinstance(val, pd.Timestamp):\n",
    "            return \"ðŸ“…\"\n",
    "        if is_dataclass(val):\n",
    "            return \"ðŸ“¦\"\n",
    "        return \"ðŸ”¢\" if isinstance(val, (int, float)) else \"ðŸ“„\"\n",
    "\n",
    "    def process(item, name, level=0, path=\"\"):\n",
    "        indent = \"  \" * level\n",
    "        item_id = id(item)\n",
    "\n",
    "        # Build the breadcrumb path\n",
    "        current_path = f\"{path} -> {name}\" if path else name\n",
    "\n",
    "        is_primitive = isinstance(item, (int, float, str, bool, type(None)))\n",
    "        if not is_primitive and item_id in id_memory:\n",
    "            output.append(\n",
    "                f\"{indent}          â•°â”€â”€ {name} --> [See ID {id_memory[item_id]}]\"\n",
    "            )\n",
    "            return\n",
    "\n",
    "        # 1. Store Index, Object, Name, and Path in Registry\n",
    "        curr_idx = len(registry)\n",
    "        registry.append({\"name\": name, \"path\": current_path, \"obj\": item})\n",
    "\n",
    "        if not is_primitive:\n",
    "            id_memory[item_id] = curr_idx\n",
    "\n",
    "        # 2. Metadata for display\n",
    "        meta = f\"{type(item).__name__}\"\n",
    "        if hasattr(item, \"shape\"):\n",
    "            meta = f\"shape={item.shape}\"\n",
    "        elif isinstance(item, (list, dict)):\n",
    "            meta = f\"len={len(item)}\"\n",
    "\n",
    "        output.append(f\"[{curr_idx:>3}] {indent}{get_icon(item)} {name} ({meta})\")\n",
    "\n",
    "        # 3. Recurse\n",
    "        if isinstance(item, dict):\n",
    "            for k, v in item.items():\n",
    "                process(v, k, level + 1, current_path)\n",
    "        elif isinstance(item, (list, tuple)):\n",
    "            for i, v in enumerate(item):\n",
    "                process(v, f\"index_{i}\", level + 1, current_path)\n",
    "        elif is_dataclass(item):\n",
    "            for f in fields(item):\n",
    "                process(getattr(item, f.name), f.name, level + 1, current_path)\n",
    "\n",
    "    process(obj, \"audit_pack\")\n",
    "    print(\"\\n\".join(output))\n",
    "\n",
    "    return registry\n",
    "\n",
    "\n",
    "def peek(idx, reg):\n",
    "    \"\"\"\n",
    "    Displays metadata and RETURNS the object for further use.\n",
    "    \"\"\"\n",
    "    if idx < 0 or idx >= len(reg):\n",
    "        print(f\"âŒ Index {idx} out of range.\")\n",
    "        return None\n",
    "\n",
    "    entry = reg[idx]\n",
    "\n",
    "    # 1. Print the Header (for humans)\n",
    "    print(f\" {'='*60}\")\n",
    "    print(f\" ðŸ“ INDEX: [{idx}]\")\n",
    "    print(f\" ðŸ·ï¸  NAME:  {entry['name']}\")\n",
    "    print(f\" ðŸ“‚ PATH:  {entry['path']}\")\n",
    "    print(f\" {'='*60}\\n\")\n",
    "\n",
    "    # 2. Display the data (for the UI)\n",
    "    from IPython.display import display\n",
    "\n",
    "    display(entry[\"obj\"])\n",
    "\n",
    "    # 3. RETURN the data (for other functions)\n",
    "    return entry[\"obj\"]\n",
    "\n",
    "\n",
    "def verify_engine_results_short_form(audit_pack):\n",
    "    \"\"\"\n",
    "    MASTER INTEGRITY REPORT: Performs a 3-layer reconciliation\n",
    "    between Engine Output and Raw Data.\n",
    "    \"\"\"\n",
    "    # --------------------------------------------------------------------------\n",
    "    # 0. INITIALIZATION & CONTEXT\n",
    "    # --------------------------------------------------------------------------\n",
    "    res = audit_pack[0]\n",
    "    if not res or res.debug_data is None:\n",
    "        print(\"âŒ AUDIT ABORTED: No debug data found. Run UI with debug=True.\")\n",
    "        return\n",
    "\n",
    "    debug = res.debug_data\n",
    "    inputs = debug[\"inputs_snapshot\"]\n",
    "    thresholds = inputs.quality_thresholds\n",
    "\n",
    "    # --- TRANSPARENCY BLOCK ---\n",
    "\n",
    "    print(\n",
    "        f\"ðŸ•µï¸  STARTING MULTI-LAYER AUDIT: {inputs.metric} @ {res.decision_date.date()}\"\n",
    "    )\n",
    "    print(\"\\n\")\n",
    "    print(\"=\" * 85)\n",
    "    print(\"*\" * 85)\n",
    "    print(\n",
    "        f\"âš ï¸  ASSUMPTION: Verification logic is independent, but trusts Engine source DataFrames\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   (engine.features_df, engine.df_close, and debug['portfolio_raw_components'])\"\n",
    "    )\n",
    "    print(\"*\" * 85)\n",
    "    print(\"=\" * 85, \"\\n\" * 2)\n",
    "\n",
    "    print(\n",
    "        f\"ðŸ•µï¸  STARTING MULTI-LAYER AUDIT: {inputs.metric} @ {res.decision_date.date()}\"\n",
    "    )\n",
    "    print(\"=\" * 85)\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # LAYER 1: SURVIVAL AUDIT\n",
    "    # --------------------------------------------------------------------------\n",
    "    l_audit = debug[\"audit_liquidity\"]\n",
    "    snapshot = l_audit[\"universe_snapshot\"]\n",
    "\n",
    "    m_quantile = snapshot[\"RollMedDollarVol\"].quantile(\n",
    "        thresholds[\"min_liquidity_percentile\"]\n",
    "    )\n",
    "    m_cutoff = max(m_quantile, thresholds[\"min_median_dollar_volume\"])\n",
    "\n",
    "    m_survivors = snapshot[\n",
    "        (snapshot[\"RollMedDollarVol\"] >= m_cutoff)\n",
    "        & (snapshot[\"RollingStalePct\"] <= thresholds[\"max_stale_pct\"])\n",
    "        & (snapshot[\"RollingSameVolCount\"] <= thresholds[\"max_same_vol_count\"])\n",
    "    ]\n",
    "\n",
    "    s_status = \"âœ… PASS\" if len(m_survivors) == l_audit[\"tickers_passed\"] else \"âŒ FAIL\"\n",
    "    print(\n",
    "        f\"LAYER 1: SURVIVAL  | Universe: {len(snapshot)} -> Survivors: {len(m_survivors)} | {s_status}\"\n",
    "    )\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # LAYER 2: SELECTION AUDIT (Ranking & Scoring)\n",
    "    # --------------------------------------------------------------------------\n",
    "    survivor_list = m_survivors.index.tolist()\n",
    "    idx = pd.IndexSlice\n",
    "\n",
    "    # Independent Data Reconstruction\n",
    "    feat_period = engine.features_df.loc[\n",
    "        idx[survivor_list, res.start_date : res.decision_date], :\n",
    "    ]\n",
    "    atrp_mean = feat_period[\"ATRP\"].groupby(level=\"Ticker\").mean()\n",
    "    trp_mean = feat_period[\"TRP\"].groupby(level=\"Ticker\").mean()\n",
    "    feat_now = engine.features_df.xs(res.decision_date, level=\"Date\").reindex(\n",
    "        survivor_list\n",
    "    )\n",
    "    lookback_prices = engine.df_close.loc[\n",
    "        res.start_date : res.decision_date, survivor_list\n",
    "    ]\n",
    "\n",
    "    # BUILD COMPLETE OBSERVATION (Satisfies all METRIC_REGISTRY keys)\n",
    "    audit_obs = {\n",
    "        \"lookback_close\": lookback_prices,\n",
    "        \"lookback_returns\": lookback_prices.ffill().pct_change(),  # <--- FIXED: Added missing key\n",
    "        \"atrp\": atrp_mean,\n",
    "        \"trp\": trp_mean,\n",
    "        \"rsi\": feat_now[\"RSI\"],\n",
    "        \"rel_strength\": feat_now[\"RelStrength\"],\n",
    "        \"vol_regime\": feat_now[\"VolRegime\"],\n",
    "        \"rvol\": feat_now[\"RVol\"],\n",
    "        \"obv_score\": feat_now[\"OBV_Score\"],\n",
    "        \"roc_1\": feat_now[\"ROC_1\"],\n",
    "        \"roc_3\": feat_now[\"ROC_3\"],\n",
    "        \"roc_5\": feat_now[\"ROC_5\"],\n",
    "        \"roc_10\": feat_now[\"ROC_10\"],\n",
    "        \"roc_21\": feat_now[\"ROC_21\"],\n",
    "    }\n",
    "\n",
    "    # Re-run Strategy Formula\n",
    "    manual_scores = METRIC_REGISTRY[inputs.metric](audit_obs)\n",
    "\n",
    "    # Comparison logic\n",
    "    audit_results = []\n",
    "    for rank, ticker in enumerate(res.tickers, start=inputs.rank_start):\n",
    "        # We handle cases where the engine result table might use different indexing\n",
    "        eng_score = res.results_df.loc[ticker, \"Strategy Value\"]\n",
    "        audit_score = manual_scores.loc[ticker]\n",
    "        audit_results.append(\n",
    "            {\n",
    "                \"Rank\": rank,\n",
    "                \"Ticker\": ticker,\n",
    "                \"Engine\": eng_score,\n",
    "                \"Manual\": audit_score,\n",
    "                \"Delta\": eng_score - audit_score,\n",
    "                \"Match\": np.isclose(eng_score, audit_score),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    sel_df = pd.DataFrame(audit_results)\n",
    "    sel_status = \"âœ… PASS\" if sel_df[\"Match\"].all() else \"âŒ FAIL\"\n",
    "    print(\n",
    "        f\"LAYER 2: SELECTION | Strategy: {inputs.metric} | Selection Match: {sel_status}\"\n",
    "    )\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # LAYER 3: PERFORMANCE AUDIT (Returns & Risk)\n",
    "    # --------------------------------------------------------------------------\n",
    "    def run_kernel(df_p, df_atrp, df_trp, w):\n",
    "        norm = df_p.div(df_p.bfill().iloc[0])\n",
    "        eq = (norm * w).sum(axis=1)\n",
    "        drift_w = (norm * w).div(eq, axis=0)\n",
    "        p_atrp = (drift_w * df_atrp).sum(axis=1)\n",
    "        rets = eq.pct_change()\n",
    "        v_mask = rets.notna()\n",
    "        # Gain, Sharpe, Sharpe(ATRP)\n",
    "        g = eq.iloc[-1] / eq.iloc[0] - 1\n",
    "        s = (rets.mean() / rets.std() * np.sqrt(252)) if rets.std() > 0 else 0\n",
    "        sa = rets.mean() / p_atrp.where(v_mask).mean()\n",
    "        return g, s, sa\n",
    "\n",
    "    p_comp = debug[\"portfolio_raw_components\"]\n",
    "\n",
    "    # Re-calculate on the specific holding window\n",
    "    m_gain, m_sharpe, m_s_atrp = run_kernel(\n",
    "        p_comp[\"prices\"].loc[res.buy_date : res.holding_end_date],\n",
    "        p_comp[\"atrp\"].loc[res.buy_date : res.holding_end_date],\n",
    "        p_comp[\"trp\"].loc[res.buy_date : res.holding_end_date],\n",
    "        res.initial_weights,\n",
    "    )\n",
    "\n",
    "    e_gain = res.perf_metrics[\"holding_p_gain\"]\n",
    "    perf_status = \"âœ… PASS\" if np.isclose(m_gain, e_gain, atol=1e-7) else \"âŒ FAIL\"\n",
    "    print(\n",
    "        f\"LAYER 3: PERFORMANCE | Holding Gain: {e_gain:.4f} vs Manual: {m_gain:.4f} | {perf_status}\"\n",
    "    )\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # DISPLAY TABLES\n",
    "    # --------------------------------------------------------------------------\n",
    "    print(\"=\" * 85)\n",
    "    display(\n",
    "        sel_df.set_index(\"Rank\")\n",
    "        .style.format({\"Engine\": \"{:.6f}\", \"Manual\": \"{:.6f}\", \"Delta\": \"{:.8f}\"})\n",
    "        .set_caption(\"Layer 2: Selection Reconciliation\")\n",
    "    )\n",
    "\n",
    "    perf_summary = pd.DataFrame(\n",
    "        {\n",
    "            \"Metric\": [\"Holding Gain\", \"Holding Sharpe\", \"Sharpe (ATRP)\"],\n",
    "            \"Engine\": [\n",
    "                e_gain,\n",
    "                res.perf_metrics[\"holding_p_sharpe\"],\n",
    "                res.perf_metrics[\"holding_p_sharpe_atrp\"],\n",
    "            ],\n",
    "            \"Manual\": [m_gain, m_sharpe, m_s_atrp],\n",
    "        }\n",
    "    ).set_index(\"Metric\")\n",
    "    perf_summary[\"Delta\"] = perf_summary[\"Engine\"] - perf_summary[\"Manual\"]\n",
    "    display(\n",
    "        perf_summary.style.format(\"{:.8f}\").set_caption(\n",
    "            \"Layer 3: Performance Reconciliation\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def verify_engine_results_long_form(audit_pack):\n",
    "    \"\"\"\n",
    "    Run independent verification of Engine run results\n",
    "    \"\"\"\n",
    "    # 1. SETUP: Access the object directly (no longer using [\"results\"] key)\n",
    "    res = audit_pack[0]\n",
    "\n",
    "    # ==============================================================================\n",
    "    # MODULAR EVENT-DRIVEN AUDIT\n",
    "    # ==============================================================================\n",
    "\n",
    "    print(\"=\" * 78)\n",
    "    print(\"MODULAR EVENT-DRIVEN AUDIT -- START\")\n",
    "    print(\"=\" * 78)\n",
    "\n",
    "    # Ensure debug data exists before proceeding\n",
    "    if res.debug_data is None:\n",
    "        raise ValueError(\n",
    "            \"âŒ Audit failed: The Engine was run with debug=False. Re-run UI with debug enabled.\"\n",
    "        )\n",
    "\n",
    "    m = res.perf_metrics\n",
    "    init_weights = res.initial_weights\n",
    "\n",
    "    # Period Definitions\n",
    "    periods = {\n",
    "        \"Full\": (res.start_date, res.holding_end_date),\n",
    "        \"Lookback\": (res.start_date, res.decision_date),\n",
    "        \"Holding\": (res.buy_date, res.holding_end_date),\n",
    "    }\n",
    "\n",
    "    # ==============================================================================\n",
    "    # 2. FETCH RAW DATA (Double-Blind Source from the debug_data dictionary)\n",
    "    # ==============================================================================\n",
    "    # These remain brackets because debug_data is still a dictionary\n",
    "    p_raw_components = res.debug_data[\"portfolio_raw_components\"]\n",
    "    b_raw_components = res.debug_data[\"benchmark_raw_components\"]\n",
    "\n",
    "    p_ohlcv = p_raw_components[\"ohlcv_raw\"]\n",
    "    p_raw_price = p_raw_components[\"prices\"]\n",
    "\n",
    "    b_ohlcv = b_raw_components[\"ohlcv_raw\"]\n",
    "    b_raw_price = b_raw_components[\"prices\"]\n",
    "\n",
    "    # ==============================================================================\n",
    "    # 2. CALCULATE VOLATILITY MANUALLY (From Raw High/Low/Close)\n",
    "    # ==============================================================================\n",
    "    def calculate_manual_vol(df_ohlcv, atr_period=14):\n",
    "        df = df_ohlcv.copy()\n",
    "        df[\"PC\"] = df.groupby(level=\"Ticker\")[\"Adj Close\"].shift(1)\n",
    "\n",
    "        # True Range math\n",
    "        tr = pd.concat(\n",
    "            [\n",
    "                df[\"Adj High\"] - df[\"Adj Low\"],\n",
    "                (df[\"Adj High\"] - df[\"PC\"]).abs(),\n",
    "                (df[\"Adj Low\"] - df[\"PC\"]).abs(),\n",
    "            ],\n",
    "            axis=1,\n",
    "        ).max(axis=1)\n",
    "\n",
    "        # Wilder's ATR math\n",
    "        atr = tr.groupby(level=\"Ticker\").ewm(alpha=1 / atr_period, adjust=False).mean()\n",
    "        atr = atr.reset_index(level=0, drop=True)\n",
    "\n",
    "        # Convert to Ticker-Wide Matrices\n",
    "        manual_trp = (tr / df[\"Adj Close\"]).unstack(level=\"Ticker\")\n",
    "        manual_atrp = (atr / df[\"Adj Close\"]).unstack(level=\"Ticker\")\n",
    "        return manual_atrp, manual_trp\n",
    "\n",
    "    # Generate our own \"Verified Ground Truth\" matrices\n",
    "    p_manual_atrp, p_manual_trp = calculate_manual_vol(p_ohlcv)\n",
    "    b_manual_atrp, b_manual_trp = calculate_manual_vol(b_ohlcv)\n",
    "\n",
    "    # ==============================================================================\n",
    "    # 3. CONSOLIDATE INTO THE AUDIT INPUTS\n",
    "    #    Use Engine's pre-aligned Ticker ATRP (Warm Start)\n",
    "    #    Do not use manual_atrp (Cold Start)\n",
    "    # ==============================================================================\n",
    "    p_raw = {\n",
    "        \"price\": p_raw_price,\n",
    "        \"atrp\": res.debug_data[\"portfolio_raw_components\"][\n",
    "            \"atrp\"\n",
    "        ],  # <--- Use Engine's \"Deep\" ATRP\n",
    "        \"trp\": p_manual_trp,  # <--- Keep your \"Double-Blind\" TRP\n",
    "    }\n",
    "    b_raw = {\n",
    "        \"price\": b_raw_price,\n",
    "        \"atrp\": res.debug_data[\"benchmark_raw_components\"][\n",
    "            \"atrp\"\n",
    "        ],  # <--- Use Engine's \"Deep\" ATRP\n",
    "        \"trp\": b_manual_trp,  # <--- Keep your \"Double-Blind\" TRP\n",
    "    }\n",
    "\n",
    "    # 2. THE MODULAR AUDIT KERNEL\n",
    "    def run_period_audit(df_p, df_atrp, df_trp, weights):\n",
    "        \"\"\"\n",
    "        Replicates the Engine's logic for a specific 'Slate Reset' window.\n",
    "        \"\"\"\n",
    "        # A. Price Normalization (Fresh Capital Reset)\n",
    "        # We divide by the first valid price in THIS specific slice\n",
    "        norm_prices = df_p.div(df_p.bfill().iloc[0])\n",
    "\n",
    "        # B. Equity & Drifted Weights\n",
    "        weighted_components = norm_prices.mul(weights, axis=1)\n",
    "        equity_curve = weighted_components.sum(axis=1)\n",
    "        # Drifted weights are used to aggregate volatility (weighted average)\n",
    "        current_weights = weighted_components.div(equity_curve, axis=0)\n",
    "\n",
    "        # C. Volatility Aggregation\n",
    "        port_atrp = (current_weights * df_atrp).sum(axis=1)\n",
    "        port_trp = (current_weights * df_trp).sum(axis=1)\n",
    "\n",
    "        # D. Return Calculation (Produces leading NaN)\n",
    "        returns = equity_curve.pct_change()\n",
    "        valid_mask = returns.notna()  # ALIGNMENT FIX: Identify days where returns exist\n",
    "\n",
    "        # E. Statistical Kernels (Applying the Aligned Math)\n",
    "        # Gain: Last / First - 1\n",
    "        gain = (equity_curve.iloc[-1] / equity_curve.iloc[0]) - 1\n",
    "\n",
    "        # Sharpe: Mean(Returns) / Std(Returns) * sqrt(252)\n",
    "        sharpe = (\n",
    "            (returns.mean() / returns.std()) * np.sqrt(252) if returns.std() > 0 else 0\n",
    "        )\n",
    "\n",
    "        # Sharpe(Vol): Mean(Returns) / Mean(Vol[Only on Return Days])\n",
    "        # This aligns the N-1 denominator for both numerator and denominator\n",
    "        s_atrp = returns.mean() / port_atrp.where(valid_mask).mean()\n",
    "        s_trp = returns.mean() / port_trp.where(valid_mask).mean()\n",
    "\n",
    "        return gain, sharpe, s_atrp, s_trp\n",
    "\n",
    "    # 3. EXECUTION LOOP\n",
    "    audit_rows = []\n",
    "\n",
    "    for p_label, (d_start, d_end) in periods.items():\n",
    "        # --- AUDIT GROUP (PORTFOLIO) ---\n",
    "        g, s, sa, st = run_period_audit(\n",
    "            p_raw[\"price\"].loc[d_start:d_end],\n",
    "            p_raw[\"atrp\"].loc[d_start:d_end],\n",
    "            p_raw[\"trp\"].loc[d_start:d_end],\n",
    "            init_weights,\n",
    "        )\n",
    "\n",
    "        # --- AUDIT BENCHMARK ---\n",
    "        # Dynamically grab the ticker name from the benchmark price columns\n",
    "        b_ticker_name = b_raw[\"price\"].columns[0]\n",
    "        b_weights = pd.Series({b_ticker_name: 1.0})  # âœ… Guaranteed to match the index\n",
    "\n",
    "        bg, bs, bsa, bst = run_period_audit(\n",
    "            b_raw[\"price\"].loc[d_start:d_end],\n",
    "            b_raw[\"atrp\"].loc[d_start:d_end],\n",
    "            b_raw[\"trp\"].loc[d_start:d_end],\n",
    "            b_weights,\n",
    "        )\n",
    "\n",
    "        # Mapping to Engine Metric Keys\n",
    "        mapping = [\n",
    "            (\"Gain\", g, f\"{p_label.lower()}_p_gain\", bg, f\"{p_label.lower()}_b_gain\"),\n",
    "            (\n",
    "                \"Sharpe\",\n",
    "                s,\n",
    "                f\"{p_label.lower()}_p_sharpe\",\n",
    "                bs,\n",
    "                f\"{p_label.lower()}_b_sharpe\",\n",
    "            ),\n",
    "            (\n",
    "                \"Sharpe (ATRP)\",\n",
    "                sa,\n",
    "                f\"{p_label.lower()}_p_sharpe_atrp\",\n",
    "                bsa,\n",
    "                f\"{p_label.lower()}_b_sharpe_atrp\",\n",
    "            ),\n",
    "            (\n",
    "                \"Sharpe (TRP)\",\n",
    "                st,\n",
    "                f\"{p_label.lower()}_p_sharpe_trp\",\n",
    "                bst,\n",
    "                f\"{p_label.lower()}_b_sharpe_trp\",\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        for metric, manual_p, key_p, manual_b, key_b in mapping:\n",
    "            # Compare Portfolio\n",
    "            eng_p = m.get(key_p, 0)\n",
    "            audit_rows.append(\n",
    "                {\n",
    "                    \"Entity\": \"Group\",\n",
    "                    \"Period\": p_label,\n",
    "                    \"Metric\": metric,\n",
    "                    \"Engine\": eng_p,\n",
    "                    \"Manual\": manual_p,\n",
    "                    \"Delta\": eng_p - manual_p,\n",
    "                }\n",
    "            )\n",
    "            # Compare Benchmark\n",
    "            eng_b = m.get(key_b, 0)\n",
    "            audit_rows.append(\n",
    "                {\n",
    "                    \"Entity\": \"Benchmark\",\n",
    "                    \"Period\": p_label,\n",
    "                    \"Metric\": metric,\n",
    "                    \"Engine\": eng_b,\n",
    "                    \"Manual\": manual_b,\n",
    "                    \"Delta\": eng_b - manual_b,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    # 4. REPORTING\n",
    "    df_final = pd.DataFrame(audit_rows)\n",
    "    df_final[\"Status\"] = df_final[\"Delta\"].apply(\n",
    "        lambda x: \"âœ… PASS\" if abs(x) < 1e-7 else \"âŒ FAIL\"\n",
    "    )\n",
    "\n",
    "    # --- 5. DETAILED PRECISION REPORT (FIXED FOR PANDAS 2.1+) ---\n",
    "    # This replicates the table you saw, but displays all values with 8 decimals.\n",
    "    styled_final = df_final.style.format(\n",
    "        {\"Engine\": \"{:.8f}\", \"Manual\": \"{:.8f}\", \"Delta\": \"{:.8f}\"}\n",
    "    )\n",
    "\n",
    "    def highlight_noise(val):\n",
    "        # If the delta is exactly zero, keep it gray.\n",
    "        # If there is even a tiny floating point difference, turn it red.\n",
    "        color = \"red\" if abs(val) > 1e-12 else \"gray\"\n",
    "        return f\"color: {color}\"\n",
    "\n",
    "    print(f\"ðŸ“ FINAL INTEGRITY REPORT (MODULAR)\")\n",
    "    display(\n",
    "        df_final.pivot_table(\n",
    "            index=[\"Entity\", \"Metric\"],\n",
    "            columns=\"Period\",\n",
    "            values=\"Status\",\n",
    "            aggfunc=\"first\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    display(styled_final.map(highlight_noise, subset=[\"Delta\"]))\n",
    "\n",
    "    print(\"=\" * 78)\n",
    "    print(\"MODULAR EVENT-DRIVEN AUDIT -- END\")\n",
    "    print(\"=\" * 78)\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    ################################################################################\n",
    "    ################################################################################\n",
    "\n",
    "    # ==============================================================================\n",
    "    # SURVIVAL AUDIT: LIQUIDITY & DATA INTEGRITY POST-MORTEM\n",
    "    # ==============================================================================\n",
    "    print(\"=\" * 78)\n",
    "    print(\"SURVIVAL AUDIT: LIQUIDITY & DATA INTEGRITY POST-MORTEM -- START\")\n",
    "    print(\"=\" * 78)\n",
    "\n",
    "    # Check if debug was enabled\n",
    "    if res.debug_data is None:\n",
    "        raise ValueError(\n",
    "            \"âŒ Audit Failed: debug_data is None. Re-run UI with 'Run Simulation' (Debug=True).\"\n",
    "        )\n",
    "\n",
    "    # Use dot notation for the object, then brackets for the internal dictionary\n",
    "    audit = res.debug_data[\"audit_liquidity\"]\n",
    "    snapshot = audit[\"universe_snapshot\"]\n",
    "\n",
    "    # IMPORTANT: Since 'inputs' are not stored inside EngineOutput by default,\n",
    "    # we usually grab them from the last run or the audit pack.\n",
    "    # See 'Step 2' below to ensure your UI is providing these.\n",
    "    thresholds = res.debug_data.get(\"inputs_snapshot\").quality_thresholds\n",
    "    ##################################\n",
    "\n",
    "    # 2. VERIFY THE \"DYNAMIC CUTOFF\" LOGIC\n",
    "    # The engine calculates the X-percentile, then applies a hard floor.\n",
    "    manual_quantile_val = snapshot[\"RollMedDollarVol\"].quantile(\n",
    "        thresholds[\"min_liquidity_percentile\"]\n",
    "    )\n",
    "    manual_final_cutoff = max(\n",
    "        manual_quantile_val, thresholds[\"min_median_dollar_volume\"]\n",
    "    )\n",
    "\n",
    "    print(\"ðŸ” SECTION 1: DYNAMIC CUTOFF VERIFICATION\")\n",
    "    print(f\"{'Metric':<30} | {'Value':<15}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\n",
    "        f\"{'Target Percentile':<30} | {thresholds['min_liquidity_percentile']*100:>14.1f}%\"\n",
    "    )\n",
    "    print(f\"{'Manual Quantile Value':<30} | ${manual_quantile_val:>13,.0f}\")\n",
    "    print(\n",
    "        f\"{'Hard Dollar Floor':<30} | ${thresholds['min_median_dollar_volume']:>13,.0f}\"\n",
    "    )\n",
    "    print(f\"{'Engine Calculated Cutoff':<30} | ${audit['final_cutoff_usd']:>13,.0f}\")\n",
    "    print(f\"{'Manual Final Cutoff':<30} | ${manual_final_cutoff:>13,.0f}\")\n",
    "\n",
    "    cutoff_match = (\n",
    "        \"âœ… PASS\"\n",
    "        if np.isclose(audit[\"final_cutoff_usd\"], manual_final_cutoff)\n",
    "        else \"âŒ FAIL\"\n",
    "    )\n",
    "    print(f\"\\nCutoff Integrity: {cutoff_match}\")\n",
    "\n",
    "    # 3. REJECTION BREAKDOWN (Why did they die?)\n",
    "    # Logic: We identify which specific rule(s) killed each ticker\n",
    "    total_start = len(snapshot)\n",
    "    fail_vol = snapshot[snapshot[\"RollMedDollarVol\"] < audit[\"final_cutoff_usd\"]]\n",
    "    fail_stale = snapshot[snapshot[\"RollingStalePct\"] > thresholds[\"max_stale_pct\"]]\n",
    "    fail_frozen = snapshot[\n",
    "        snapshot[\"RollingSameVolCount\"] > thresholds[\"max_same_vol_count\"]\n",
    "    ]\n",
    "\n",
    "    # Survival logic verification: Passed_Final must equal (Not Vol Fail AND Not Stale Fail AND Not Frozen Fail)\n",
    "    manual_survivors = snapshot[\n",
    "        (snapshot[\"RollMedDollarVol\"] >= audit[\"final_cutoff_usd\"])\n",
    "        & (snapshot[\"RollingStalePct\"] <= thresholds[\"max_stale_pct\"])\n",
    "        & (snapshot[\"RollingSameVolCount\"] <= thresholds[\"max_same_vol_count\"])\n",
    "    ]\n",
    "\n",
    "    print(\"\\nðŸ” SECTION 2: SURVIVAL MORTALITY REPORT\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{'Initial Universe Size':<30} | {total_start:>14}\")\n",
    "    print(f\"{'Killed by Low Liquidity':<30} | {len(fail_vol):>14}\")\n",
    "    print(f\"{'Killed by Price Staleness':<30} | {len(fail_stale):>14}\")\n",
    "    print(f\"{'Killed by Frozen Volume':<30} | {len(fail_frozen):>14}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{'Engine Final Survivors':<30} | {audit['tickers_passed']:>14}\")\n",
    "    print(f\"{'Manual Audit Survivors':<30} | {len(manual_survivors):>14}\")\n",
    "\n",
    "    survival_match = (\n",
    "        \"âœ… PASS\" if audit[\"tickers_passed\"] == len(manual_survivors) else \"âŒ FAIL\"\n",
    "    )\n",
    "    print(f\"\\nSurvival Integrity: {survival_match}\")\n",
    "\n",
    "    # 4. BOUNDARY INSPECTION (The \"Cutoff Edge\")\n",
    "    # Verify that the lowest survivor is actually above the cutoff\n",
    "    survivors_sorted = manual_survivors.sort_values(\"RollMedDollarVol\")\n",
    "    victims_sorted = fail_vol.sort_values(\"RollMedDollarVol\", ascending=False)\n",
    "\n",
    "    print(\"\\nðŸ” SECTION 3: BOUNDARY INTEGRITY (The Cutoff Edge)\")\n",
    "    print(\"-\" * 85)\n",
    "    if not survivors_sorted.empty:\n",
    "        lowest = survivors_sorted.iloc[0]\n",
    "        print(\n",
    "            f\"LOWEST SURVIVOR: {lowest.name:<8} Vol: ${lowest['RollMedDollarVol']:>15,.0f} (Cutoff: ${audit['final_cutoff_usd']:,.0f})\"\n",
    "        )\n",
    "    if not victims_sorted.empty:\n",
    "        highest = victims_sorted.iloc[0]\n",
    "        print(\n",
    "            f\"HIGHEST VICTIM:   {highest.name:<8} Vol: ${highest['RollMedDollarVol']:>15,.0f}\"\n",
    "        )\n",
    "\n",
    "    # Verification: Lowest Survivor >= Cutoff > Highest Victim\n",
    "    boundary_check = (\n",
    "        \"âœ… PASS\"\n",
    "        if (\n",
    "            survivors_sorted.empty\n",
    "            or lowest[\"RollMedDollarVol\"] >= audit[\"final_cutoff_usd\"]\n",
    "        )\n",
    "        else \"âŒ FAIL\"\n",
    "    )\n",
    "\n",
    "    print(f\"Boundary Logic: {boundary_check}\")\n",
    "\n",
    "    print(\"=\" * 78)\n",
    "    print(\"SURVIVAL AUDIT: LIQUIDITY & DATA INTEGRITY POST-MORTEM -- END\")\n",
    "    print(\"=\" * 78)\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    ################################################################################\n",
    "    ################################################################################\n",
    "\n",
    "    # ==============================================================================\n",
    "    # UNIVERSAL SELECTION AUDIT: LEADERBOARD & RANKING INTEGRITY\n",
    "    # ==============================================================================\n",
    "\n",
    "    print(\"=\" * 78)\n",
    "    print(\"UNIVERSAL SELECTION AUDIT: LEADERBOARD & RANKING INTEGRITY -- START\")\n",
    "    print(\"=\" * 78)\n",
    "\n",
    "    # Check if debug was enabled (RL mode skips this data)\n",
    "    if res.debug_data is None:\n",
    "        raise ValueError(\n",
    "            \"âŒ Audit Failed: debug_data is None. Re-run UI with 'Run Simulation' (Debug=True).\"\n",
    "        )\n",
    "\n",
    "    # Map variables using dot notation for the object\n",
    "    debug = res.debug_data\n",
    "    inputs = debug[\"inputs_snapshot\"]  # Retrieve the inputs we saved inside debug_data\n",
    "\n",
    "    # Identify context\n",
    "    strategy_name = inputs.metric\n",
    "    decision_date = res.decision_date\n",
    "\n",
    "    # 2. INDEPENDENT DATA RECONSTRUCTION (CORRECTED FOR PERIOD MEANS)\n",
    "    idx = pd.IndexSlice\n",
    "    survivors = (\n",
    "        debug[\"audit_liquidity\"][\"universe_snapshot\"]\n",
    "        .query(\"Passed_Final\")\n",
    "        .index.tolist()\n",
    "    )\n",
    "\n",
    "    # A. FETCH THE PERIOD MEAN FOR VOLATILITY (Using pd.IndexSlice to ignore weekends)\n",
    "    # This selects all survivors for the date range, skipping non-trading days automatically\n",
    "    feat_period = engine.features_df.loc[\n",
    "        idx[survivors, res.start_date : res.decision_date], :\n",
    "    ]\n",
    "\n",
    "    # Calculate means per ticker\n",
    "    atrp_lookback_mean = feat_period[\"ATRP\"].groupby(level=\"Ticker\").mean()\n",
    "    trp_lookback_mean = feat_period[\"TRP\"].groupby(level=\"Ticker\").mean()\n",
    "\n",
    "    # B. FETCH SNAPSHOTS FOR INDICATORS (As of Decision Date)\n",
    "    feat_current = engine.features_df.xs(res.decision_date, level=\"Date\").reindex(\n",
    "        survivors\n",
    "    )\n",
    "\n",
    "    # C. FETCH RAW PRICES FOR MOMENTUM\n",
    "    lookback_prices = engine.df_close.loc[res.start_date : res.decision_date, survivors]\n",
    "\n",
    "    # Build the Audit Observation\n",
    "    audit_obs: MarketObservation = {\n",
    "        \"lookback_close\": lookback_prices,\n",
    "        \"lookback_returns\": lookback_prices.ffill().pct_change(),\n",
    "        \"atrp\": atrp_lookback_mean,\n",
    "        \"trp\": trp_lookback_mean,\n",
    "        \"rsi\": feat_current[\"RSI\"],\n",
    "        \"rel_strength\": feat_current[\"RelStrength\"],\n",
    "        \"vol_regime\": feat_current[\"VolRegime\"],\n",
    "        \"rvol\": feat_current[\"RVol\"],\n",
    "        \"spy_rvol\": feat_current[\"Spy_RVol\"],\n",
    "        \"obv_score\": feat_current[\"OBV_Score\"],\n",
    "        \"spy_obv_score\": feat_current[\"Spy_OBV_Score\"],\n",
    "        \"roc_1\": feat_current[\"ROC_1\"],\n",
    "        \"roc_3\": feat_current[\"ROC_3\"],\n",
    "        \"roc_5\": feat_current[\"ROC_5\"],\n",
    "        \"roc_10\": feat_current[\"ROC_10\"],\n",
    "        \"roc_21\": feat_current[\"ROC_21\"],\n",
    "    }\n",
    "\n",
    "    # 3. INDEPENDENT SCORING\n",
    "    # We execute the METRIC_REGISTRY blindly using the audit observation\n",
    "    manual_scores = METRIC_REGISTRY[strategy_name](audit_obs)\n",
    "\n",
    "    # 4. INDEPENDENT SORTING & RANKING\n",
    "    # We sort descending and apply the rank_start/rank_end slice\n",
    "    full_leaderboard = manual_scores.sort_values(ascending=False)\n",
    "    rank_start_idx = max(0, inputs.rank_start - 1)\n",
    "    rank_end_idx = inputs.rank_end\n",
    "    audit_selection = full_leaderboard.iloc[rank_start_idx:rank_end_idx]\n",
    "\n",
    "    # 5. RECONCILIATION TABLE (Engine vs Audit)\n",
    "    audit_results = []\n",
    "    # Check the tickers the engine actually TRADE\n",
    "    for rank, ticker in enumerate(res.tickers, start=inputs.rank_start):\n",
    "        engine_score = res.results_df.loc[ticker, \"Strategy Value\"]\n",
    "        audit_score = manual_scores.loc[ticker]\n",
    "\n",
    "        audit_results.append(\n",
    "            {\n",
    "                \"Rank\": rank,\n",
    "                \"Ticker\": ticker,\n",
    "                \"Engine_Score\": engine_score,\n",
    "                \"Audit_Score\": audit_score,\n",
    "                \"Delta\": engine_score - audit_score,\n",
    "                \"Status\": (\n",
    "                    \"âœ… PASS\" if np.isclose(engine_score, audit_score) else \"âŒ FAIL\"\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df_selection_audit = pd.DataFrame(audit_results).set_index(\"Rank\")\n",
    "\n",
    "    print(f\"ðŸ” SELECTION AUDIT: Strategy [{strategy_name}]\")\n",
    "    print(\n",
    "        f\"   Decision Date: {decision_date.date()} | Universe Survivors: {len(survivors)}\"\n",
    "    )\n",
    "    print(\"-\" * 85)\n",
    "\n",
    "    print(\n",
    "        df_selection_audit.style.format(\n",
    "            {\"Engine_Score\": \"{:.8f}\", \"Audit_Score\": \"{:.8f}\", \"Delta\": \"{:.8f}\"}\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 6. LEADERBOARD IDENTITY CHECK\n",
    "    engine_set = set(res.tickers)\n",
    "    audit_set = set(audit_selection.index)\n",
    "\n",
    "    identity_match = \"âœ… PASS\" if engine_set == audit_set else \"âŒ FAIL\"\n",
    "    print(f\"\\nLeaderboard Identity Match: {identity_match}\")\n",
    "    if identity_match == \"âŒ FAIL\":\n",
    "        print(f\"   Engine Tickers: {engine_set}\")\n",
    "        print(f\"   Audit Tickers:  {audit_set}\")\n",
    "\n",
    "    # 7. THE \"BUBBLE\" ANALYSIS (The Near Misses)\n",
    "    print(\"\\nðŸ” THE BUBBLE (Rank #3 to #5 - The Next in Line)\")\n",
    "    print(\"-\" * 55)\n",
    "    bubble_slice = full_leaderboard.iloc[inputs.rank_end : inputs.rank_end + 3]\n",
    "    for r, (t, s) in enumerate(bubble_slice.items(), start=inputs.rank_end + 1):\n",
    "        margin = audit_selection.iloc[-1] - s\n",
    "        print(\n",
    "            f\"Rank #{r}: {t:<8} Score: {s:>10.6f} (Gap to Last Selection: {margin:>10.6f})\"\n",
    "        )\n",
    "\n",
    "    print(\"=\" * 78)\n",
    "    print(\"UNIVERSAL SELECTION AUDIT: LEADERBOARD & RANKING INTEGRITY -- END\")\n",
    "    print(\"=\" * 78)\n",
    "\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a48017a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SECTION H: UTILITIES\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "def export_debug_to_csv(audit_pack, source_label=\"Audit\"):\n",
    "    \"\"\"\n",
    "    High-Transparency Exporter (Hardened Version).\n",
    "    Dumps the entire simulation state into a folder for manual Excel verification.\n",
    "    \"\"\"\n",
    "    if not audit_pack or not audit_pack[0]:\n",
    "        print(\"âŒ Error: Audit Pack is empty. Run a simulation first.\")\n",
    "        return\n",
    "\n",
    "    data = audit_pack[0]\n",
    "    # Handle the fact that 'inputs' might be a key or a dataclass attribute\n",
    "    inputs = data.get(\"inputs\")\n",
    "\n",
    "    # 1. Folder Setup\n",
    "    date_str = inputs.start_date.strftime(\"%Y-%m-%d\")\n",
    "    strat = inputs.metric.replace(\" \", \"\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "    folder_name = f\"{source_label}_{strat}_{date_str}\"\n",
    "\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    print(f\"ðŸ“‚ [AUDIT EXPORT] Folder: ./{folder_name}/\")\n",
    "\n",
    "    def process_item(item, path_prefix=\"\"):\n",
    "        # A. Handle Nested Dicts\n",
    "        if isinstance(item, dict):\n",
    "            for k, v in item.items():\n",
    "                process_item(v, f\"{path_prefix}{k}_\" if path_prefix else f\"{k}_\")\n",
    "\n",
    "        # B. Handle DataFrames (Matrices - High Precision)\n",
    "        elif isinstance(item, pd.DataFrame):\n",
    "            fn = f\"Matrix_{path_prefix.strip('_')}.csv\"\n",
    "            item.to_csv(os.path.join(folder_name, fn), float_format=\"%.8f\")\n",
    "            print(f\"   âœ… Matrix: {fn}\")\n",
    "\n",
    "        # C. Handle Series (Vectors)\n",
    "        elif isinstance(item, pd.Series):\n",
    "            fn = f\"Vector_{path_prefix.strip('_')}.csv\"\n",
    "            item.to_frame().to_csv(os.path.join(folder_name, fn), float_format=\"%.8f\")\n",
    "            print(f\"   âœ… Vector: {fn}\")\n",
    "\n",
    "        # D. Handle Dataclasses (Metadata & Results)\n",
    "        elif is_dataclass(item):\n",
    "            class_name = item.__class__.__name__\n",
    "            fn = f\"Summary_{class_name}_{path_prefix.strip('_')}\".strip(\"_\") + \".csv\"\n",
    "\n",
    "            # --- THE FIX: Create a Safe Dictionary for Pandas ---\n",
    "            raw_dict = asdict(item)\n",
    "            summary_ready_dict = {}\n",
    "\n",
    "            for k, v in raw_dict.items():\n",
    "                # If it's a big data object, just note its existence in the summary\n",
    "                if isinstance(v, (pd.DataFrame, pd.Series)):\n",
    "                    summary_ready_dict[k] = f\"<{v.__class__.__name__} shape={v.shape}>\"\n",
    "                # If it's a list or dict (the crash cause), stringify it for Excel\n",
    "                elif isinstance(v, (list, dict)):\n",
    "                    summary_ready_dict[k] = str(v)\n",
    "                else:\n",
    "                    summary_ready_dict[k] = v\n",
    "\n",
    "            # Save the clean key-value summary\n",
    "            pd.DataFrame.from_dict(\n",
    "                summary_ready_dict, orient=\"index\", columns=[\"Value\"]\n",
    "            ).to_csv(os.path.join(folder_name, fn))\n",
    "            print(f\"   ðŸ“‘ Summary: {fn}\")\n",
    "\n",
    "            # E. RECURSION: Now find the actual DataFrames inside the dataclass\n",
    "            # We iterate the object attributes directly to avoid the 'asdict' list confusion\n",
    "            for k in item.__dataclass_fields__.keys():\n",
    "                val = getattr(item, k)\n",
    "                if isinstance(val, (pd.DataFrame, pd.Series, dict)):\n",
    "                    process_item(val, f\"{path_prefix}{k}_\")\n",
    "\n",
    "    # 3. Execute Extraction\n",
    "    process_item(data)\n",
    "    print(f\"\\nâœ¨ Export Complete. Open ./{folder_name}/ to verify results.\")\n",
    "\n",
    "\n",
    "def export_audit_to_excel(audit_pack, filename=\"Audit_Verification_Report.xlsx\"):\n",
    "    \"\"\"\n",
    "    Consolidates the audit_pack into a multi-sheet Excel workbook.\n",
    "    Organizes data by shared axes (Date vs Ticker) for manual formula checking.\n",
    "    \"\"\"\n",
    "    if not audit_pack or not audit_pack[0]:\n",
    "        print(\"âŒ Error: Audit Pack is empty.\")\n",
    "        return\n",
    "\n",
    "    data = audit_pack[0]\n",
    "    res = data[\"results\"]\n",
    "    inputs = data[\"inputs\"]\n",
    "    debug = data.get(\"debug\", {})\n",
    "\n",
    "    print(f\"ðŸ“‚ [EXCEL AUDIT] Creating Report: {filename}\")\n",
    "\n",
    "    with pd.ExcelWriter(filename, engine=\"openpyxl\") as writer:\n",
    "\n",
    "        # --- SHEET 1: OVERVIEW (The Settings & Final Totals) ---\n",
    "        # Combines Input settings and Result scalars into one vertical table\n",
    "        meta_dict = {\n",
    "            **asdict(inputs),\n",
    "            **{\n",
    "                k: v\n",
    "                for k, v in asdict(res).items()\n",
    "                if not isinstance(v, (pd.DataFrame, pd.Series, dict))\n",
    "            },\n",
    "        }\n",
    "        # Stringify lists/dicts to prevent Excel/Pandas export crashes\n",
    "        clean_meta = {\n",
    "            k: (str(v) if isinstance(v, (list, dict)) else v)\n",
    "            for k, v in meta_dict.items()\n",
    "        }\n",
    "\n",
    "        df_overview = pd.DataFrame.from_dict(\n",
    "            clean_meta, orient=\"index\", columns=[\"Value\"]\n",
    "        )\n",
    "        df_overview.to_excel(writer, sheet_name=\"OVERVIEW\")\n",
    "\n",
    "        # --- SHEET 2: DAILY_AUDIT (Axis = Date) ---\n",
    "        # Concatenates everything that happens day-by-day\n",
    "        daily_items = {\n",
    "            \"Port_Value\": res.portfolio_series,\n",
    "            \"Port_Ret\": QuantUtils.compute_returns(res.portfolio_series),\n",
    "            \"Port_ATRP\": res.portfolio_atrp_series,  # <--- DIRECT ACCESS\n",
    "            \"Port_TRP\": res.portfolio_trp_series,  # <--- DIRECT ACCESS\n",
    "            \"Bench_Value\": res.benchmark_series,\n",
    "            \"Bench_Ret\": QuantUtils.compute_returns(res.benchmark_series),\n",
    "            \"Bench_ATRP\": res.benchmark_atrp_series,  # <--- DIRECT ACCESS\n",
    "            \"Bench_TRP\": res.benchmark_trp_series,  # <--- DIRECT ACCESS\n",
    "        }\n",
    "\n",
    "        # Filter out None values and concatenate side-by-side\n",
    "        df_daily = pd.concat(\n",
    "            {k: v for k, v in daily_items.items() if v is not None}, axis=1\n",
    "        )\n",
    "        df_daily.to_excel(writer, sheet_name=\"DAILY_AUDIT\", float_format=\"%.8f\")\n",
    "\n",
    "        # --- SHEET 3: SELECTION_SNAPSHOT (Axis = Ticker) ---\n",
    "        # Focuses on the selected 10-20 tickers and their performance\n",
    "        if \"full_universe_ranking\" in debug:\n",
    "            df_rank = debug[\"full_universe_ranking\"]\n",
    "            # Filter the leaderboard for only the tickers we actually bought\n",
    "            df_composition = df_rank.reindex(res.tickers)\n",
    "            df_composition.to_excel(\n",
    "                writer, sheet_name=\"PORTFOLIO_SNAPSHOT\", float_format=\"%.8f\"\n",
    "            )\n",
    "\n",
    "        # --- SHEET 4: FULL_UNIVERSE_RANKING ---\n",
    "        if \"full_universe_ranking\" in debug:\n",
    "            debug[\"full_universe_ranking\"].to_excel(\n",
    "                writer, sheet_name=\"FULL_RANKING\", float_format=\"%.8f\"\n",
    "            )\n",
    "\n",
    "        # --- SHEET 5: RAW_PRICES_MATRIX ---\n",
    "        if \"portfolio_raw_components\" in debug:\n",
    "            raw_p = debug[\"portfolio_raw_components\"].get(\"prices\")\n",
    "            if raw_p is not None:\n",
    "                raw_p.to_excel(writer, sheet_name=\"RAW_PRICES\", float_format=\"%.8f\")\n",
    "\n",
    "        # --- SHEET 6: RAW_VOL_MATRIX (TRP) ---\n",
    "        if \"portfolio_raw_components\" in debug:\n",
    "            # Re-extracting TRP matrix for the specific tickers\n",
    "            raw_v = debug[\"portfolio_raw_components\"].get(\n",
    "                \"atrp\"\n",
    "            )  # Or trp if stored specifically\n",
    "            if raw_v is not None:\n",
    "                raw_v.to_excel(writer, sheet_name=\"RAW_VOL_DATA\", float_format=\"%.8f\")\n",
    "\n",
    "    print(f\"âœ¨ Audit Report Complete. Manual verification ready in {filename}\")\n",
    "\n",
    "\n",
    "def print_nested(d, indent=0, width=4):\n",
    "    \"\"\"Pretty-print nested containers.\n",
    "    Leaves are rendered as two lines:  key\\\\nvalue .\"\"\"\n",
    "    spacing = \" \" * indent\n",
    "\n",
    "    def _kind(node):\n",
    "        if not isinstance(node, dict):\n",
    "            return None\n",
    "        return \"sep\" if all(isinstance(v, dict) for v in node.values()) else \"nest\"\n",
    "\n",
    "    if isinstance(d, dict):\n",
    "        for k, v in d.items():\n",
    "            kind = _kind(v)\n",
    "            tag = \"\" if kind is None else f\"  [{'SEP' if kind == 'sep' else 'NEST'}]\"\n",
    "            print(f\"{spacing}{k}{tag}\")\n",
    "            print_nested(v, indent + width, width)\n",
    "\n",
    "    elif isinstance(d, (list, tuple)):\n",
    "        for idx, item in enumerate(d):\n",
    "            print(f\"{spacing}[{idx}]\")\n",
    "            print_nested(item, indent + width, width)\n",
    "\n",
    "    else:  # leaf â€“ primitive value\n",
    "        print(f\"{spacing}{d}\")\n",
    "\n",
    "\n",
    "def get_ticker_OHLCV(\n",
    "    df_ohlcv: pd.DataFrame,\n",
    "    tickers: Union[str, List[str]],\n",
    "    date_start: str,\n",
    "    date_end: str,\n",
    "    return_format: str = \"dataframe\",\n",
    "    verbose: bool = True,\n",
    ") -> Union[pd.DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    Get OHLCV data for specified tickers within a date range.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_ohlcv : pd.DataFrame\n",
    "        DataFrame with MultiIndex of (ticker, date) and OHLCV columns\n",
    "    tickers : str or list of str\n",
    "        Ticker symbol(s) to retrieve\n",
    "    date_start : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    date_end : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    return_format : str, optional\n",
    "        Format to return data in. Options:\n",
    "        - 'dataframe': Single DataFrame with MultiIndex (default)\n",
    "        - 'dict': Dictionary with tickers as keys and DataFrames as values\n",
    "        - 'separate': List of separate DataFrames for each ticker\n",
    "    verbose : bool, optional\n",
    "        Whether to print summary information (default: True)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Union[pd.DataFrame, dict, list]\n",
    "        Filtered OHLCV data in specified format\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If input parameters are invalid\n",
    "    KeyError\n",
    "        If tickers not found in DataFrame\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> # Get data for single ticker\n",
    "    >>> vlo_data = get_ticker_OHLCV(df_ohlcv, 'VLO', '2025-08-13', '2025-09-04')\n",
    "\n",
    "    >>> # Get data for multiple tickers\n",
    "    >>> multi_data = get_ticker_OHLCV(df_ohlcv, ['VLO', 'JPST'], '2025-08-13', '2025-09-04')\n",
    "\n",
    "    >>> # Get data as dictionary\n",
    "    >>> data_dict = get_ticker_OHLCV(df_ohlcv, ['VLO', 'JPST'], '2025-08-13',\n",
    "    ...                              '2025-09-04', return_format='dict')\n",
    "    \"\"\"\n",
    "\n",
    "    # Input validation\n",
    "    if not isinstance(df_ohlcv, pd.DataFrame):\n",
    "        raise TypeError(\"df_ohlcv must be a pandas DataFrame\")\n",
    "\n",
    "    if not isinstance(df_ohlcv.index, pd.MultiIndex):\n",
    "        raise ValueError(\"DataFrame must have MultiIndex of (ticker, date)\")\n",
    "\n",
    "    if len(df_ohlcv.index.levels) != 2:\n",
    "        raise ValueError(\"MultiIndex must have exactly 2 levels: (ticker, date)\")\n",
    "\n",
    "    # Convert single ticker to list for consistent processing\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "    elif not isinstance(tickers, list):\n",
    "        raise TypeError(\"tickers must be a string or list of strings\")\n",
    "\n",
    "    # Convert dates to Timestamps\n",
    "    try:\n",
    "        start_date = pd.Timestamp(date_start)\n",
    "        end_date = pd.Timestamp(date_end)\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"Invalid date format. Use 'YYYY-MM-DD': {e}\")\n",
    "\n",
    "    if start_date > end_date:\n",
    "        raise ValueError(\"date_start must be before or equal to date_end\")\n",
    "\n",
    "    # Check if tickers exist in the DataFrame\n",
    "    available_tickers = df_ohlcv.index.get_level_values(0).unique()\n",
    "    missing_tickers = [t for t in tickers if t not in available_tickers]\n",
    "\n",
    "    if missing_tickers:\n",
    "        raise KeyError(f\"Ticker(s) not found in DataFrame: {missing_tickers}\")\n",
    "\n",
    "    # Filter the data using MultiIndex slicing\n",
    "    try:\n",
    "        filtered_data = df_ohlcv.loc[(tickers, slice(date_start, date_end)), :]\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error filtering data: {e}\")\n",
    "\n",
    "    # Handle empty results\n",
    "    if filtered_data.empty:\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"No data found for tickers {tickers} in date range {date_start} to {date_end}\"\n",
    "            )\n",
    "        return filtered_data\n",
    "\n",
    "    # Print summary if verbose\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"Data retrieved for {len(tickers)} ticker(s) from {date_start} to {date_end}\"\n",
    "        )\n",
    "        print(f\"Total rows: {len(filtered_data)}\")\n",
    "        print(\n",
    "            f\"Date range in data: {filtered_data.index.get_level_values(1).min()} to \"\n",
    "            f\"{filtered_data.index.get_level_values(1).max()}\"\n",
    "        )\n",
    "\n",
    "        # Print ticker-specific counts\n",
    "        ticker_counts = filtered_data.index.get_level_values(0).value_counts()\n",
    "        for ticker in tickers:\n",
    "            count = ticker_counts.get(ticker, 0)\n",
    "            if count > 0:\n",
    "                print(f\"  {ticker}: {count} rows\")\n",
    "            else:\n",
    "                print(f\"  {ticker}: No data in range\")\n",
    "\n",
    "    # Return in requested format\n",
    "    if return_format == \"dict\":\n",
    "        result = {}\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result[ticker] = filtered_data.xs(ticker, level=0).loc[\n",
    "                    date_start:date_end\n",
    "                ]\n",
    "            except KeyError:\n",
    "                result[ticker] = pd.DataFrame()\n",
    "        return result\n",
    "\n",
    "    elif return_format == \"separate\":\n",
    "        result = []\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result.append(\n",
    "                    filtered_data.xs(ticker, level=0).loc[date_start:date_end]\n",
    "                )\n",
    "            except KeyError:\n",
    "                result.append(pd.DataFrame())\n",
    "        return result\n",
    "\n",
    "    elif return_format == \"dataframe\":\n",
    "        return filtered_data\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Invalid return_format: {return_format}. \"\n",
    "            f\"Must be 'dataframe', 'dict', or 'separate'\"\n",
    "        )\n",
    "\n",
    "\n",
    "def get_ticker_features(\n",
    "    features_df: pd.DataFrame,\n",
    "    tickers: Union[str, List[str]],\n",
    "    date_start: str,\n",
    "    date_end: str,\n",
    "    return_format: str = \"dataframe\",\n",
    "    verbose: bool = True,\n",
    ") -> Union[pd.DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    Get features data for specified tickers within a date range.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    features_df : pd.DataFrame\n",
    "        DataFrame with MultiIndex of (ticker, date) and feature columns\n",
    "    tickers : str or list of str\n",
    "        Ticker symbol(s) to retrieve\n",
    "    date_start : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    date_end : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    return_format : str, optional\n",
    "        Format to return data in. Options:\n",
    "        - 'dataframe': Single DataFrame with MultiIndex (default)\n",
    "        - 'dict': Dictionary with tickers as keys and DataFrames as values\n",
    "        - 'separate': List of separate DataFrames for each ticker\n",
    "    verbose : bool, optional\n",
    "        Whether to print summary information (default: True)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Union[pd.DataFrame, dict, list]\n",
    "        Filtered features data in specified format\n",
    "    \"\"\"\n",
    "    # Convert single ticker to list for consistent processing\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "\n",
    "    # Filter the data using MultiIndex slicing\n",
    "    try:\n",
    "        filtered_data = features_df.loc[(tickers, slice(date_start, date_end)), :]\n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"Error filtering data: {e}\")\n",
    "        return pd.DataFrame() if return_format == \"dataframe\" else {}\n",
    "\n",
    "    # Handle empty results\n",
    "    if filtered_data.empty:\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"No data found for tickers {tickers} in date range {date_start} to {date_end}\"\n",
    "            )\n",
    "        return filtered_data\n",
    "\n",
    "    # Print summary if verbose\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"Features data retrieved for {len(tickers)} ticker(s) from {date_start} to {date_end}\"\n",
    "        )\n",
    "        print(f\"Total rows: {len(filtered_data)}\")\n",
    "        print(\n",
    "            f\"Date range in data: {filtered_data.index.get_level_values(1).min()} to \"\n",
    "            f\"{filtered_data.index.get_level_values(1).max()}\"\n",
    "        )\n",
    "        print(f\"Available features: {', '.join(filtered_data.columns.tolist())}\")\n",
    "\n",
    "        # Print ticker-specific counts\n",
    "        ticker_counts = filtered_data.index.get_level_values(0).value_counts()\n",
    "        for ticker in tickers:\n",
    "            count = ticker_counts.get(ticker, 0)\n",
    "            if count > 0:\n",
    "                print(f\"  {ticker}: {count} rows\")\n",
    "            else:\n",
    "                print(f\"  {ticker}: No data in range\")\n",
    "\n",
    "    # Return in requested format\n",
    "    if return_format == \"dict\":\n",
    "        result = {}\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result[ticker] = filtered_data.xs(ticker, level=0).loc[\n",
    "                    date_start:date_end\n",
    "                ]\n",
    "            except KeyError:\n",
    "                result[ticker] = pd.DataFrame()\n",
    "        return result\n",
    "\n",
    "    elif return_format == \"separate\":\n",
    "        result = []\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result.append(\n",
    "                    filtered_data.xs(ticker, level=0).loc[date_start:date_end]\n",
    "                )\n",
    "            except KeyError:\n",
    "                result.append(pd.DataFrame())\n",
    "        return result\n",
    "\n",
    "    elif return_format == \"dataframe\":\n",
    "        return filtered_data\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Invalid return_format: {return_format}. \"\n",
    "            f\"Must be 'dataframe', 'dict', or 'separate'\"\n",
    "        )\n",
    "\n",
    "\n",
    "def create_combined_dict(\n",
    "    df_ohlcv: pd.DataFrame,\n",
    "    features_df: pd.DataFrame,\n",
    "    tickers: Union[str, List[str]],\n",
    "    date_start: str,\n",
    "    date_end: str,\n",
    "    verbose: bool = True,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Create a combined dictionary with both OHLCV and features data for each ticker.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_ohlcv : pd.DataFrame\n",
    "        DataFrame with OHLCV data (MultiIndex: ticker, date)\n",
    "    features_df : pd.DataFrame\n",
    "        DataFrame with features data (MultiIndex: ticker, date)\n",
    "    tickers : str or list of str\n",
    "        Ticker symbol(s) to retrieve\n",
    "    date_start : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    date_end : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    verbose : bool, optional\n",
    "        Whether to print progress information (default: True)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with tickers as keys and combined DataFrames (OHLCV + features) as values\n",
    "    \"\"\"\n",
    "    # Convert single ticker to list\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Creating combined dictionary for {len(tickers)} ticker(s)\")\n",
    "        print(f\"Date range: {date_start} to {date_end}\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "    # Get OHLCV data as dictionary\n",
    "    ohlcv_dict = get_ticker_OHLCV(\n",
    "        df_ohlcv, tickers, date_start, date_end, return_format=\"dict\", verbose=verbose\n",
    "    )\n",
    "\n",
    "    # Get features data as dictionary\n",
    "    features_dict = get_ticker_features(\n",
    "        features_df,\n",
    "        tickers,\n",
    "        date_start,\n",
    "        date_end,\n",
    "        return_format=\"dict\",\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "    # Create combined_dict\n",
    "    combined_dict = {}\n",
    "\n",
    "    for ticker in tickers:\n",
    "        if verbose:\n",
    "            print(f\"\\nProcessing {ticker}...\")\n",
    "\n",
    "        # Check if ticker exists in both dictionaries\n",
    "        if ticker in ohlcv_dict and ticker in features_dict:\n",
    "            ohlcv_data = ohlcv_dict[ticker]\n",
    "            features_data = features_dict[ticker]\n",
    "\n",
    "            # Check if both dataframes have data\n",
    "            if not ohlcv_data.empty and not features_data.empty:\n",
    "                # Combine OHLCV and features data\n",
    "                # Note: Both dataframes have the same index (dates), so we can concatenate\n",
    "                combined_df = pd.concat([ohlcv_data, features_data], axis=1)\n",
    "\n",
    "                # Ensure proper index naming\n",
    "                combined_df.index.name = \"Date\"\n",
    "\n",
    "                # Store in combined_dict\n",
    "                combined_dict[ticker] = combined_df\n",
    "\n",
    "                if verbose:\n",
    "                    print(f\"  âœ“ Successfully combined data\")\n",
    "                    print(f\"  OHLCV shape: {ohlcv_data.shape}\")\n",
    "                    print(f\"  Features shape: {features_data.shape}\")\n",
    "                    print(f\"  Combined shape: {combined_df.shape}\")\n",
    "                    print(\n",
    "                        f\"  Date range: {combined_df.index.min()} to {combined_df.index.max()}\"\n",
    "                    )\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"  âœ— Cannot combine: One or both dataframes are empty\")\n",
    "                    print(f\"    OHLCV empty: {ohlcv_data.empty}\")\n",
    "                    print(f\"    Features empty: {features_data.empty}\")\n",
    "                combined_dict[ticker] = pd.DataFrame()\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(f\"  âœ— Ticker not found in both dictionaries\")\n",
    "                if ticker not in ohlcv_dict:\n",
    "                    print(f\"    Not in OHLCV data\")\n",
    "                if ticker not in features_dict:\n",
    "                    print(f\"    Not in features data\")\n",
    "            combined_dict[ticker] = pd.DataFrame()\n",
    "\n",
    "    # Print summary\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"SUMMARY\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Total tickers processed: {len(tickers)}\")\n",
    "\n",
    "        tickers_with_data = [\n",
    "            ticker for ticker, df in combined_dict.items() if not df.empty\n",
    "        ]\n",
    "        print(f\"Tickers with combined data: {len(tickers_with_data)}\")\n",
    "\n",
    "        if tickers_with_data:\n",
    "            print(\"\\nTicker details:\")\n",
    "            for ticker in tickers_with_data:\n",
    "                df = combined_dict[ticker]\n",
    "                print(f\"  {ticker}: {df.shape} - {df.index.min()} to {df.index.max()}\")\n",
    "                print(f\"    Columns: {len(df.columns)}\")\n",
    "\n",
    "        empty_tickers = [ticker for ticker, df in combined_dict.items() if df.empty]\n",
    "        if empty_tickers:\n",
    "            print(f\"\\nTickers with no data: {', '.join(empty_tickers)}\")\n",
    "\n",
    "    return combined_dict\n",
    "\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6d867e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_indices.parquet\"\n",
    "\n",
    "df_indices = pd.read_parquet(data_path, engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf150180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 129839 entries, ('^AXJO', Timestamp('1992-11-22 00:00:00')) to ('^STOXX50E', Timestamp('2026-01-09 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   Adj Open   129839 non-null  float64\n",
      " 1   Adj High   129839 non-null  float64\n",
      " 2   Adj Low    129839 non-null  float64\n",
      " 3   Adj Close  129839 non-null  float64\n",
      " 4   Volume     129839 non-null  int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_indices.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "232740e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = (\n",
    "    r\"c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet\"\n",
    ")\n",
    "\n",
    "df_ohlcv = pd.read_parquet(data_path, engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "239275a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 9443363 entries, ('A', Timestamp('1999-11-18 00:00:00')) to ('ZWS', Timestamp('2026-01-09 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   Adj Open   float64\n",
      " 1   Adj High   float64\n",
      " 2   Adj Low    float64\n",
      " 3   Adj Close  float64\n",
      " 4   Volume     int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 397.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_ohlcv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88954119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating features... this might take about 3 minutes...\n",
      "âš¡ Generating Features (Base: 21d, Ratio Clip: 10.0)...\n",
      "ðŸš€ Generating Wide Matrices for Instant Backtesting...\n",
      "   - Unstacking ATRP...\n",
      "   - Unstacking TRP...\n",
      "âœ… Pre-computation Complete. df_close_wide, df_atrp_wide, and df_trp_wide are ready.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# DATA PRE-COMPUTATION (The \"Fast-Track\" Setup)\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"Calculating features... this might take about 3 minutes...\")\n",
    "features_df = generate_features(\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    # atr_period=GLOBAL_SETTINGS[\"atr_period\"],\n",
    "    # quality_window=GLOBAL_SETTINGS[\"quality_window\"],\n",
    "    # quality_min_periods=GLOBAL_SETTINGS[\"quality_min_periods\"],\n",
    ")\n",
    "\n",
    "print(\"ðŸš€ Generating Wide Matrices for Instant Backtesting...\")\n",
    "\n",
    "# 1. Price Matrix\n",
    "df_close_wide = df_ohlcv[\"Adj Close\"].unstack(level=0)\n",
    "\n",
    "# 2. Volatility Matrices (Unstack and Align)\n",
    "# Using reindex_like ensures Dates and Tickers match df_close_wide exactly\n",
    "print(\"   - Unstacking ATRP...\")\n",
    "df_atrp_wide = features_df[\"ATRP\"].unstack(level=0).reindex_like(df_close_wide)\n",
    "\n",
    "print(\"   - Unstacking TRP...\")\n",
    "df_trp_wide = features_df[\"TRP\"].unstack(level=0).reindex_like(df_close_wide)\n",
    "\n",
    "# 3. Handle Data Gaps (Sanitize the Wide Matrices)\n",
    "# This prevents NaN propagation during matrix multiplication\n",
    "if GLOBAL_SETTINGS[\"handle_zeros_as_nan\"]:\n",
    "    df_close_wide = df_close_wide.replace(0, np.nan)\n",
    "\n",
    "# Forward fill up to the limit, then fill remaining with the \"Disaster Detection\" value\n",
    "df_close_wide = df_close_wide.ffill(limit=GLOBAL_SETTINGS[\"max_data_gap_ffill\"])\n",
    "df_close_wide = df_close_wide.fillna(GLOBAL_SETTINGS[\"nan_price_replacement\"])\n",
    "\n",
    "print(\n",
    "    \"âœ… Pre-computation Complete. df_close_wide, df_atrp_wide, and df_trp_wide are ready.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca6930d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- âš™ï¸ Initializing AlphaEngine v2.2 (Sanitized) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2df3634c360c433babc74b334adbc71b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>1. Timeline Configuration:</b> (Past <--- Decision ---> Future)'), HBox(childrenâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffbc9b3797df43db89a452d6c8ae4ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'width': 2},\n",
       "              'name': 'LNG',\n",
       "              'type': 'scatter',\n",
       "              'uid': '717b9b0d-266a-4a6f-b412-a8d06ce4c520',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 1, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 6, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 7, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 23, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 24, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 28, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.0085232 , 1.01500595, 1.01319425, 1.02080703, 1.02094428,\n",
       "                          1.04007228, 1.10194894, 1.11459877, 1.14986733, 1.14578644, 1.13159484,\n",
       "                          1.05784152, 1.06205966, 1.0510431 , 1.01749931, 1.02661268])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'SHV',\n",
       "              'type': 'scatter',\n",
       "              'uid': '706340de-6fd0-4d79-89d0-8c20b1f3b0b7',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 1, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 6, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 7, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 23, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 24, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 28, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00027431, 1.00045403, 1.00063374, 1.00063374, 1.00090805,\n",
       "                          1.00108777, 1.00118236, 1.00136208, 1.00145666, 1.00191069, 1.00209041,\n",
       "                          1.00209041, 1.00227013, 1.00263902, 1.00281874, 1.00290387])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'USFR',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd0ddec8e-e97b-458e-b644-1acdd83c8394',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 1, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 6, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 7, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 23, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 24, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 28, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00019881, 1.00039762, 1.00059642, 1.00079523, 1.00139165,\n",
       "                          1.00159046, 1.001986  , 1.001986  , 1.001986  , 1.00238362, 1.00258243,\n",
       "                          1.00238362, 1.00258243, 1.00298004, 1.00317885, 1.00341908])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'QRVO',\n",
       "              'type': 'scatter',\n",
       "              'uid': '499787e5-59c4-401b-ad7f-019252f1fbdf',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 1, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 6, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 7, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 23, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 24, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 28, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.01247133, 1.03411697, 1.05547592, 1.04759174, 1.02766628,\n",
       "                          1.03081995, 1.04386468, 1.06307339, 1.05490252, 1.20713876, 1.25544725,\n",
       "                          1.24842317, 1.29830849, 1.27494266, 1.25616399, 1.2296445 ])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'RPRX',\n",
       "              'type': 'scatter',\n",
       "              'uid': '85802a61-945e-4029-b2d8-e4a1cc9f77d8',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 1, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 6, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 7, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 23, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 24, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 28, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00193989, 0.99844968, 1.00969546, 1.01589674, 1.14346818,\n",
       "                          1.16285513, 1.16440545, 1.19193754, 1.20007871, 1.19232313, 1.17487607,\n",
       "                          1.16634534, 1.18728261, 1.20434408, 1.22993628, 1.23846701])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'SNX',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd99093d6-c10d-4d44-9141-5da987a4c795',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 1, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 6, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 7, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 23, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 24, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 28, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.01245041, 1.01562609, 1.05794529, 1.04824424, 1.15050115,\n",
       "                          1.14045208, 1.16792824, 1.16981625, 1.17762929, 1.17702896, 1.20853344,\n",
       "                          1.2147978 , 1.22931022, 1.2271525 , 1.21587666, 1.22104476])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'TRGP',\n",
       "              'type': 'scatter',\n",
       "              'uid': '1dca6bd5-9af5-47fa-a85b-213390c0a416',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 1, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 6, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 7, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 23, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 24, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 28, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.01699117, 1.01693534, 1.02600325, 1.04872887, 1.055943  ,\n",
       "                          1.07871888, 1.10008208, 1.12258436, 1.16328388, 1.17841568, 1.18660696,\n",
       "                          1.15410429, 1.15476317, 1.14208819, 1.08838983, 1.10548709])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'BIL',\n",
       "              'type': 'scatter',\n",
       "              'uid': '3ead6f0b-e584-4429-a5a9-e7e343bb9f89',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 1, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 6, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 7, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 23, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 24, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 28, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00010939, 1.00021878, 1.00043755, 1.00065519, 1.00098336,\n",
       "                          1.00109275, 1.00131152, 1.00142091, 1.00142091, 1.00196786, 1.00196786,\n",
       "                          1.00218663, 1.00218663, 1.00262419, 1.00273358, 1.00273358])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'MINT',\n",
       "              'type': 'scatter',\n",
       "              'uid': '3c179f44-6017-483b-a100-57db27193e9a',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 1, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 6, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 7, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 23, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 24, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 28, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00049801, 1.00069742, 1.00059824, 1.00099706, 1.00109625,\n",
       "                          1.00129566, 1.00149507, 1.00179367, 1.00209331, 1.00259132, 1.00259132,\n",
       "                          1.00279073, 1.00299014, 1.00348815, 1.00348815, 1.00348815])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'SGOV',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a722a84a-d343-4dbd-842a-dfd00b37575c',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 1, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 6, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 7, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 23, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 24, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 28, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00029902, 1.00029902, 1.00049836, 1.00069771, 1.0010964 ,\n",
       "                          1.00129575, 1.00139542, 1.00149509, 1.00149509, 1.00199346, 1.00209313,\n",
       "                          1.00229248, 1.00239215, 1.00269117, 1.00269117, 1.00299019])},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'd3419c02-06b6-4303-b028-a3456112241b', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'ab0830e9-d28e-4229-9ad9-b5a4b1534cab', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '98846993-30ff-45bc-9e8c-fbc08452c63b', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'dcf62ed1-8351-4ca3-a2ce-b297d910a0ee', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '7c31c485-b120-4128-8241-c4a35eb8dcf3', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '6d949e4f-55c6-40fd-82bf-f3c07d0f484c', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '23a95b15-0537-4c03-8b18-b7c0bbd84f3d', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '73fadcbd-9fd3-49d7-8df5-b7e6f0ae5e9c', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '6d9feaec-ef20-45be-8b24-79e6de43f3cd', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'b0990821-a3c6-42f9-8ca7-fb57c3f453b5', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'f9a578de-5fe9-401e-af6d-dccb1d5a4b31', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'ab5a2a59-135e-4243-b3db-14f06b61f664', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '9856180d-9d5b-4a51-8ac2-e0bf7e4ce013', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '359fbf5b-fa9d-4785-87a9-ba6bc26a5abc', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'dfc1be2c-905c-4c18-a7a3-ee8fc1923b59', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '99b10297-05ff-472d-bac4-9128d5ec554f', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '9921895e-79ab-488e-b9c9-523de197b050', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '3eba0271-e9a7-4f2c-96aa-03223f9f700b', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '2955e615-fe56-4f09-9f4b-115594d7eb17', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '867a68f6-4433-4778-a6e1-61be058f7dab', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'cf057a17-04ce-49bd-b07d-e3aa912fc9aa', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '218e844d-4896-40c8-871e-7dc4991eeb91', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'bfacb1c2-2319-405f-8b5e-60865815ab3e', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'bb1b0102-c60a-491d-9276-1cd3c0258141', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'e38565cf-e376-4508-9112-21a0ce8018e9', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '7798e82f-36d8-4801-82d4-55fd20cb8c97', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '96b2b41d-76b1-4dea-b883-b1beda1f46e6', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '0a42777f-8b98-46ba-8335-233d75e7ad11', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'bfa7bbfb-9739-46fa-bcec-1fb356c84f58', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'b309d17e-8446-44d5-8075-803b6933e423', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '0fb73414-4ae0-4e32-bfb2-2bbfd8288b7e', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '892cf013-f8c9-4a79-9a83-0b483369bbf9', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '7460cfa0-9f4b-44e2-a2d8-62808627e24f', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '3cee4ca0-1b93-47a1-9677-fc0d5e2fb4be', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'ae3a2032-94c4-46e8-bc02-7d069ef1b8cc', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '971eef4f-a17e-4b98-bdbf-0209022c0443', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '53536a6b-0bfb-4e8a-b9be-1cf8db96a325', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'e6b8937a-3342-4e38-a478-454a2a593c0d', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '8fb704e5-e435-4ffe-bf7d-2ca1a10ea08b', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'c5ecc2a6-7c45-485e-8d33-1bb58fe88fcd', 'visible': False},\n",
       "             {'line': {'color': 'black', 'dash': 'dash', 'width': 3},\n",
       "              'name': 'Benchmark (SPY)',\n",
       "              'type': 'scatter',\n",
       "              'uid': '324c12d2-5fe5-435e-9f8b-d8b15d807536',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 1, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 6, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 7, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 23, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 24, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 28, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.01250316, 1.01833681, 1.00682525, 1.00829621, 0.99290132,\n",
       "                          0.9944415 , 0.99581036, 1.01392393, 1.01197361, 1.02213362, 1.03148892,\n",
       "                          1.03728797, 1.0429503 , 1.03990454, 1.02519495, 1.0340034 ])},\n",
       "             {'line': {'color': 'green', 'width': 3},\n",
       "              'name': 'Group Portfolio',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c0dc4d46-a75b-4e05-a2da-90c778d24fed',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 1, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 6, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 7, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 23, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 24, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 1, 28, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00537555, 1.00822009, 1.01650785, 1.01850476, 1.04039986,\n",
       "                          1.04592807, 1.05855998, 1.06700681, 1.07542137, 1.09115399, 1.09683837,\n",
       "                          1.0853256 , 1.09441456, 1.09139931, 1.08227766, 1.08367909])}],\n",
       "    'layout': {'annotations': [{'bgcolor': 'red',\n",
       "                                'font': {'color': 'white'},\n",
       "                                'showarrow': False,\n",
       "                                'text': 'DECISION',\n",
       "                                'x': Timestamp('2025-01-17 00:00:00'),\n",
       "                                'xref': 'x',\n",
       "                                'y': 0.05,\n",
       "                                'yref': 'paper'},\n",
       "                               {'bgcolor': 'blue',\n",
       "                                'font': {'color': 'white'},\n",
       "                                'showarrow': False,\n",
       "                                'text': 'ENTRY (T+1)',\n",
       "                                'x': Timestamp('2025-01-21 00:00:00'),\n",
       "                                'xref': 'x',\n",
       "                                'y': 1.0,\n",
       "                                'yref': 'paper'}],\n",
       "               'height': 600,\n",
       "               'hovermode': 'x unified',\n",
       "               'shapes': [{'line': {'color': 'red', 'dash': 'dash', 'width': 2},\n",
       "                           'type': 'line',\n",
       "                           'x0': Timestamp('2025-01-17 00:00:00'),\n",
       "                           'x1': Timestamp('2025-01-17 00:00:00'),\n",
       "                           'xref': 'x',\n",
       "                           'y0': 0,\n",
       "                           'y1': 1,\n",
       "                           'yref': 'paper'},\n",
       "                          {'line': {'color': 'blue', 'dash': 'dot', 'width': 2},\n",
       "                           'type': 'line',\n",
       "                           'x0': Timestamp('2025-01-21 00:00:00'),\n",
       "                           'x1': Timestamp('2025-01-21 00:00:00'),\n",
       "                           'xref': 'x',\n",
       "                           'y0': 0,\n",
       "                           'y1': 1,\n",
       "                           'yref': 'paper'}],\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Event-Driven Walk-Forward Analysis'}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "audit_pack = plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_ohlcv.copy(),\n",
    "    features_df=features_df,\n",
    "    df_close_wide=df_close_wide,\n",
    "    df_atrp_wide=df_atrp_wide,\n",
    "    df_trp_wide=df_trp_wide,  # <--- Update your class to accept this\n",
    "    default_start_date=\"2025-01-17\",\n",
    "    default_lookback=10,\n",
    "    default_holding=5,\n",
    "    default_strategy=\"Sharpe (ATRP)\",\n",
    "    default_rank_start=1,\n",
    "    default_rank_end=10,\n",
    "    default_benchmark_ticker=GLOBAL_SETTINGS[\"benchmark_ticker\"],\n",
    "    master_calendar_ticker=GLOBAL_SETTINGS[\"calendar_ticker\"],\n",
    "    quality_thresholds=GLOBAL_SETTINGS[\"thresholds\"],\n",
    "    debug=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad0fb1c",
   "metadata": {},
   "source": [
    "## View audit_pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "509032b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================\n",
      "ðŸ” HIGH-TRANSPARENCY AUDIT MAP\n",
      "====================================================================\n",
      "[  0] ðŸ“‚ audit_pack (len=1)\n",
      "[  1]   ðŸ“¦ index_0 (EngineOutput)\n",
      "[  2]     ðŸ“ˆ portfolio_series (shape=(17,))\n",
      "[  3]     ðŸ“ˆ benchmark_series (shape=(17,))\n",
      "[  4]     ðŸ§® normalized_plot_data (shape=(17, 10))\n",
      "[  5]     ðŸ“‚ tickers (len=10)\n",
      "[  6]       ðŸ“„ index_0 (str)\n",
      "[  7]       ðŸ“„ index_1 (str)\n",
      "[  8]       ðŸ“„ index_2 (str)\n",
      "[  9]       ðŸ“„ index_3 (str)\n",
      "[ 10]       ðŸ“„ index_4 (str)\n",
      "[ 11]       ðŸ“„ index_5 (str)\n",
      "[ 12]       ðŸ“„ index_6 (str)\n",
      "[ 13]       ðŸ“„ index_7 (str)\n",
      "[ 14]       ðŸ“„ index_8 (str)\n",
      "[ 15]       ðŸ“„ index_9 (str)\n",
      "[ 16]     ðŸ“ˆ initial_weights (shape=(10,))\n",
      "[ 17]     ðŸ“‚ perf_metrics (len=24)\n",
      "[ 18]       ðŸ”¢ full_p_gain (float)\n",
      "[ 19]       ðŸ”¢ full_p_sharpe (float)\n",
      "[ 20]       ðŸ”¢ full_p_sharpe_atrp (float)\n",
      "[ 21]       ðŸ”¢ full_p_sharpe_trp (float)\n",
      "[ 22]       ðŸ”¢ lookback_p_gain (float)\n",
      "[ 23]       ðŸ”¢ lookback_p_sharpe (float)\n",
      "[ 24]       ðŸ”¢ lookback_p_sharpe_atrp (float)\n",
      "[ 25]       ðŸ”¢ lookback_p_sharpe_trp (float)\n",
      "[ 26]       ðŸ”¢ holding_p_gain (float)\n",
      "[ 27]       ðŸ”¢ holding_p_sharpe (float)\n",
      "[ 28]       ðŸ”¢ holding_p_sharpe_atrp (float)\n",
      "[ 29]       ðŸ”¢ holding_p_sharpe_trp (float)\n",
      "[ 30]       ðŸ”¢ full_b_gain (float)\n",
      "[ 31]       ðŸ”¢ full_b_sharpe (float)\n",
      "[ 32]       ðŸ”¢ full_b_sharpe_atrp (float)\n",
      "[ 33]       ðŸ”¢ full_b_sharpe_trp (float)\n",
      "[ 34]       ðŸ”¢ lookback_b_gain (float)\n",
      "[ 35]       ðŸ”¢ lookback_b_sharpe (float)\n",
      "[ 36]       ðŸ”¢ lookback_b_sharpe_atrp (float)\n",
      "[ 37]       ðŸ”¢ lookback_b_sharpe_trp (float)\n",
      "[ 38]       ðŸ”¢ holding_b_gain (float)\n",
      "[ 39]       ðŸ”¢ holding_b_sharpe (float)\n",
      "[ 40]       ðŸ”¢ holding_b_sharpe_atrp (float)\n",
      "[ 41]       ðŸ”¢ holding_b_sharpe_trp (float)\n",
      "[ 42]     ðŸ§® results_df (shape=(10, 2))\n",
      "[ 43]     ðŸ“… start_date (Timestamp)\n",
      "[ 44]     ðŸ“… decision_date (Timestamp)\n",
      "[ 45]     ðŸ“… buy_date (Timestamp)\n",
      "[ 46]     ðŸ“… holding_end_date (Timestamp)\n",
      "[ 47]     ðŸ“ˆ portfolio_atrp_series (shape=(17,))\n",
      "[ 48]     ðŸ“ˆ benchmark_atrp_series (shape=(17,))\n",
      "[ 49]     ðŸ“ˆ portfolio_trp_series (shape=(17,))\n",
      "[ 50]     ðŸ“ˆ benchmark_trp_series (shape=(17,))\n",
      "[ 51]     ðŸ“„ error_msg (NoneType)\n",
      "[ 52]     ðŸ“‚ debug_data (len=7)\n",
      "[ 53]       ðŸ“‚ audit_liquidity (len=6)\n",
      "[ 54]         ðŸ“… date (Timestamp)\n",
      "[ 55]         ðŸ”¢ total_tickers_available (int)\n",
      "[ 56]         ðŸ”¢ percentile_setting (float)\n",
      "[ 57]         ðŸ”¢ final_cutoff_usd (shape=())\n",
      "[ 58]         ðŸ“„ tickers_passed (shape=())\n",
      "[ 59]         ðŸ§® universe_snapshot (shape=(1554, 21))\n",
      "[ 60]       ðŸ§® full_universe_ranking (shape=(924, 3))\n",
      "[ 61]       ðŸ“¦ inputs_snapshot (EngineInput)\n",
      "[ 62]         ðŸ“„ mode (str)\n",
      "[ 63]         ðŸ“… start_date (Timestamp)\n",
      "[ 64]         ðŸ”¢ lookback_period (int)\n",
      "[ 65]         ðŸ”¢ holding_period (int)\n",
      "[ 66]         ðŸ“„ metric (str)\n",
      "[ 67]         ðŸ“„ benchmark_ticker (str)\n",
      "[ 68]         ðŸ”¢ rank_start (int)\n",
      "[ 69]         ðŸ”¢ rank_end (int)\n",
      "[ 70]         ðŸ“‚ quality_thresholds (len=4)\n",
      "[ 71]           ðŸ”¢ min_median_dollar_volume (int)\n",
      "[ 72]           ðŸ”¢ min_liquidity_percentile (float)\n",
      "[ 73]           ðŸ”¢ max_stale_pct (float)\n",
      "[ 74]           ðŸ”¢ max_same_vol_count (int)\n",
      "[ 75]         ðŸ“‚ manual_tickers (len=0)\n",
      "[ 76]         ðŸ”¢ debug (bool)\n",
      "[ 77]       ðŸ“‚ verification (len=2)\n",
      "[ 78]         ðŸ“‚ portfolio (len=12)\n",
      "                    â•°â”€â”€ full_val --> [See ID 2]\n",
      "[ 79]           ðŸ“ˆ full_ret (shape=(17,))\n",
      "                    â•°â”€â”€ full_atrp --> [See ID 47]\n",
      "                    â•°â”€â”€ full_trp --> [See ID 49]\n",
      "[ 80]           ðŸ“ˆ lookback_val (shape=(11,))\n",
      "[ 81]           ðŸ“ˆ lookback_ret (shape=(11,))\n",
      "[ 82]           ðŸ“ˆ lookback_atrp (shape=(11,))\n",
      "[ 83]           ðŸ“ˆ lookback_trp (shape=(11,))\n",
      "[ 84]           ðŸ“ˆ holding_val (shape=(6,))\n",
      "[ 85]           ðŸ“ˆ holding_ret (shape=(6,))\n",
      "[ 86]           ðŸ“ˆ holding_atrp (shape=(6,))\n",
      "[ 87]           ðŸ“ˆ holding_trp (shape=(6,))\n",
      "[ 88]         ðŸ“‚ benchmark (len=12)\n",
      "                    â•°â”€â”€ full_val --> [See ID 3]\n",
      "[ 89]           ðŸ“ˆ full_ret (shape=(17,))\n",
      "                    â•°â”€â”€ full_atrp --> [See ID 48]\n",
      "                    â•°â”€â”€ full_trp --> [See ID 50]\n",
      "[ 90]           ðŸ“ˆ lookback_val (shape=(11,))\n",
      "[ 91]           ðŸ“ˆ lookback_ret (shape=(11,))\n",
      "[ 92]           ðŸ“ˆ lookback_atrp (shape=(11,))\n",
      "[ 93]           ðŸ“ˆ lookback_trp (shape=(11,))\n",
      "[ 94]           ðŸ“ˆ holding_val (shape=(6,))\n",
      "[ 95]           ðŸ“ˆ holding_ret (shape=(6,))\n",
      "[ 96]           ðŸ“ˆ holding_atrp (shape=(6,))\n",
      "[ 97]           ðŸ“ˆ holding_trp (shape=(6,))\n",
      "[ 98]       ðŸ“‚ portfolio_raw_components (len=4)\n",
      "[ 99]         ðŸ§® prices (shape=(17, 10))\n",
      "[100]         ðŸ§® atrp (shape=(17, 10))\n",
      "[101]         ðŸ§® trp (shape=(17, 10))\n",
      "[102]         ðŸ§® ohlcv_raw (shape=(170, 5))\n",
      "[103]       ðŸ“‚ benchmark_raw_components (len=4)\n",
      "[104]         ðŸ§® prices (shape=(17, 1))\n",
      "[105]         ðŸ§® atrp (shape=(17, 1))\n",
      "[106]         ðŸ§® trp (shape=(17, 1))\n",
      "[107]         ðŸ§® ohlcv_raw (shape=(17, 5))\n",
      "                â•°â”€â”€ selection_audit --> [See ID 60]\n"
     ]
    }
   ],
   "source": [
    "# 1. Generate the map and capture registry\n",
    "reg = visualize_audit_structure(audit_pack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03e6fa5",
   "metadata": {},
   "source": [
    "## Expose AlphaEngine to:\n",
    "- verify_engine_results_short_form\n",
    "- verify_engine_results_long_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0547d3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- âš™ï¸ Initializing AlphaEngine v2.2 (Sanitized) ---\n"
     ]
    }
   ],
   "source": [
    "engine = AlphaEngine(\n",
    "    df_ohlcv=df_ohlcv.copy(),\n",
    "    features_df=features_df,\n",
    "    df_close_wide=df_close_wide,\n",
    "    df_atrp_wide=df_atrp_wide,\n",
    "    df_trp_wide=df_trp_wide,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be31704",
   "metadata": {},
   "source": [
    "## Short Form Verification of Engine Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12463524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ•µï¸  STARTING MULTI-LAYER AUDIT: Sharpe (ATRP) @ 2025-01-17\n",
      "\n",
      "\n",
      "=====================================================================================\n",
      "*************************************************************************************\n",
      "âš ï¸  ASSUMPTION: Verification logic is independent, but trusts Engine source DataFrames\n",
      "   (engine.features_df, engine.df_close, and debug['portfolio_raw_components'])\n",
      "*************************************************************************************\n",
      "===================================================================================== \n",
      "\n",
      "\n",
      "ðŸ•µï¸  STARTING MULTI-LAYER AUDIT: Sharpe (ATRP) @ 2025-01-17\n",
      "=====================================================================================\n",
      "LAYER 1: SURVIVAL  | Universe: 1554 -> Survivors: 924 | âœ… PASS\n",
      "LAYER 2: SELECTION | Strategy: Sharpe (ATRP) | Selection Match: âœ… PASS\n",
      "LAYER 3: PERFORMANCE | Holding Gain: -0.0113 vs Manual: -0.0113 | âœ… PASS\n",
      "=====================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_0c4b6\">\n",
       "  <caption>Layer 2: Selection Reconciliation</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0c4b6_level0_col0\" class=\"col_heading level0 col0\" >Ticker</th>\n",
       "      <th id=\"T_0c4b6_level0_col1\" class=\"col_heading level0 col1\" >Engine</th>\n",
       "      <th id=\"T_0c4b6_level0_col2\" class=\"col_heading level0 col2\" >Manual</th>\n",
       "      <th id=\"T_0c4b6_level0_col3\" class=\"col_heading level0 col3\" >Delta</th>\n",
       "      <th id=\"T_0c4b6_level0_col4\" class=\"col_heading level0 col4\" >Match</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Rank</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0c4b6_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_0c4b6_row0_col0\" class=\"data row0 col0\" >RPRX</td>\n",
       "      <td id=\"T_0c4b6_row0_col1\" class=\"data row0 col1\" >0.846955</td>\n",
       "      <td id=\"T_0c4b6_row0_col2\" class=\"data row0 col2\" >0.846955</td>\n",
       "      <td id=\"T_0c4b6_row0_col3\" class=\"data row0 col3\" >0.00000000</td>\n",
       "      <td id=\"T_0c4b6_row0_col4\" class=\"data row0 col4\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c4b6_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "      <td id=\"T_0c4b6_row1_col0\" class=\"data row1 col0\" >SGOV</td>\n",
       "      <td id=\"T_0c4b6_row1_col1\" class=\"data row1 col1\" >0.788671</td>\n",
       "      <td id=\"T_0c4b6_row1_col2\" class=\"data row1 col2\" >0.788671</td>\n",
       "      <td id=\"T_0c4b6_row1_col3\" class=\"data row1 col3\" >0.00000000</td>\n",
       "      <td id=\"T_0c4b6_row1_col4\" class=\"data row1 col4\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c4b6_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "      <td id=\"T_0c4b6_row2_col0\" class=\"data row2 col0\" >SHV</td>\n",
       "      <td id=\"T_0c4b6_row2_col1\" class=\"data row2 col1\" >0.785095</td>\n",
       "      <td id=\"T_0c4b6_row2_col2\" class=\"data row2 col2\" >0.785095</td>\n",
       "      <td id=\"T_0c4b6_row2_col3\" class=\"data row2 col3\" >0.00000000</td>\n",
       "      <td id=\"T_0c4b6_row2_col4\" class=\"data row2 col4\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c4b6_level0_row3\" class=\"row_heading level0 row3\" >4</th>\n",
       "      <td id=\"T_0c4b6_row3_col0\" class=\"data row3 col0\" >BIL</td>\n",
       "      <td id=\"T_0c4b6_row3_col1\" class=\"data row3 col1\" >0.784746</td>\n",
       "      <td id=\"T_0c4b6_row3_col2\" class=\"data row3 col2\" >0.784746</td>\n",
       "      <td id=\"T_0c4b6_row3_col3\" class=\"data row3 col3\" >0.00000000</td>\n",
       "      <td id=\"T_0c4b6_row3_col4\" class=\"data row3 col4\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c4b6_level0_row4\" class=\"row_heading level0 row4\" >5</th>\n",
       "      <td id=\"T_0c4b6_row4_col0\" class=\"data row4 col0\" >SNX</td>\n",
       "      <td id=\"T_0c4b6_row4_col1\" class=\"data row4 col1\" >0.717529</td>\n",
       "      <td id=\"T_0c4b6_row4_col2\" class=\"data row4 col2\" >0.717529</td>\n",
       "      <td id=\"T_0c4b6_row4_col3\" class=\"data row4 col3\" >0.00000000</td>\n",
       "      <td id=\"T_0c4b6_row4_col4\" class=\"data row4 col4\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c4b6_level0_row5\" class=\"row_heading level0 row5\" >6</th>\n",
       "      <td id=\"T_0c4b6_row5_col0\" class=\"data row5 col0\" >MINT</td>\n",
       "      <td id=\"T_0c4b6_row5_col1\" class=\"data row5 col1\" >0.707706</td>\n",
       "      <td id=\"T_0c4b6_row5_col2\" class=\"data row5 col2\" >0.707706</td>\n",
       "      <td id=\"T_0c4b6_row5_col3\" class=\"data row5 col3\" >0.00000000</td>\n",
       "      <td id=\"T_0c4b6_row5_col4\" class=\"data row5 col4\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c4b6_level0_row6\" class=\"row_heading level0 row6\" >7</th>\n",
       "      <td id=\"T_0c4b6_row6_col0\" class=\"data row6 col0\" >TRGP</td>\n",
       "      <td id=\"T_0c4b6_row6_col1\" class=\"data row6 col1\" >0.706117</td>\n",
       "      <td id=\"T_0c4b6_row6_col2\" class=\"data row6 col2\" >0.706117</td>\n",
       "      <td id=\"T_0c4b6_row6_col3\" class=\"data row6 col3\" >0.00000000</td>\n",
       "      <td id=\"T_0c4b6_row6_col4\" class=\"data row6 col4\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c4b6_level0_row7\" class=\"row_heading level0 row7\" >8</th>\n",
       "      <td id=\"T_0c4b6_row7_col0\" class=\"data row7 col0\" >QRVO</td>\n",
       "      <td id=\"T_0c4b6_row7_col1\" class=\"data row7 col1\" >0.702859</td>\n",
       "      <td id=\"T_0c4b6_row7_col2\" class=\"data row7 col2\" >0.702859</td>\n",
       "      <td id=\"T_0c4b6_row7_col3\" class=\"data row7 col3\" >0.00000000</td>\n",
       "      <td id=\"T_0c4b6_row7_col4\" class=\"data row7 col4\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c4b6_level0_row8\" class=\"row_heading level0 row8\" >9</th>\n",
       "      <td id=\"T_0c4b6_row8_col0\" class=\"data row8 col0\" >LNG</td>\n",
       "      <td id=\"T_0c4b6_row8_col1\" class=\"data row8 col1\" >0.696957</td>\n",
       "      <td id=\"T_0c4b6_row8_col2\" class=\"data row8 col2\" >0.696957</td>\n",
       "      <td id=\"T_0c4b6_row8_col3\" class=\"data row8 col3\" >0.00000000</td>\n",
       "      <td id=\"T_0c4b6_row8_col4\" class=\"data row8 col4\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c4b6_level0_row9\" class=\"row_heading level0 row9\" >10</th>\n",
       "      <td id=\"T_0c4b6_row9_col0\" class=\"data row9 col0\" >USFR</td>\n",
       "      <td id=\"T_0c4b6_row9_col1\" class=\"data row9 col1\" >0.677129</td>\n",
       "      <td id=\"T_0c4b6_row9_col2\" class=\"data row9 col2\" >0.677129</td>\n",
       "      <td id=\"T_0c4b6_row9_col3\" class=\"data row9 col3\" >0.00000000</td>\n",
       "      <td id=\"T_0c4b6_row9_col4\" class=\"data row9 col4\" >True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x29d2d6904d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_92725\">\n",
       "  <caption>Layer 3: Performance Reconciliation</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_92725_level0_col0\" class=\"col_heading level0 col0\" >Engine</th>\n",
       "      <th id=\"T_92725_level0_col1\" class=\"col_heading level0 col1\" >Manual</th>\n",
       "      <th id=\"T_92725_level0_col2\" class=\"col_heading level0 col2\" >Delta</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Metric</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_92725_level0_row0\" class=\"row_heading level0 row0\" >Holding Gain</th>\n",
       "      <td id=\"T_92725_row0_col0\" class=\"data row0 col0\" >-0.01130108</td>\n",
       "      <td id=\"T_92725_row0_col1\" class=\"data row0 col1\" >-0.01130108</td>\n",
       "      <td id=\"T_92725_row0_col2\" class=\"data row0 col2\" >0.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92725_level0_row1\" class=\"row_heading level0 row1\" >Holding Sharpe</th>\n",
       "      <td id=\"T_92725_row1_col0\" class=\"data row1 col0\" >-5.07128664</td>\n",
       "      <td id=\"T_92725_row1_col1\" class=\"data row1 col1\" >-5.07128664</td>\n",
       "      <td id=\"T_92725_row1_col2\" class=\"data row1 col2\" >0.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92725_level0_row2\" class=\"row_heading level0 row2\" >Sharpe (ATRP)</th>\n",
       "      <td id=\"T_92725_row2_col0\" class=\"data row2 col0\" >-0.17096725</td>\n",
       "      <td id=\"T_92725_row2_col1\" class=\"data row2 col1\" >-0.17096725</td>\n",
       "      <td id=\"T_92725_row2_col2\" class=\"data row2 col2\" >0.00000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x29d2d5c9e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the audit\n",
    "verify_engine_results_short_form(audit_pack=audit_pack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622b25fa",
   "metadata": {},
   "source": [
    "## Long Form Verification of Engine Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0d5129f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================================\n",
      "MODULAR EVENT-DRIVEN AUDIT -- START\n",
      "==============================================================================\n",
      "ðŸ“ FINAL INTEGRITY REPORT (MODULAR)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Period</th>\n",
       "      <th>Full</th>\n",
       "      <th>Holding</th>\n",
       "      <th>Lookback</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entity</th>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Benchmark</th>\n",
       "      <th>Gain</th>\n",
       "      <td>âœ… PASS</td>\n",
       "      <td>âœ… PASS</td>\n",
       "      <td>âœ… PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe</th>\n",
       "      <td>âœ… PASS</td>\n",
       "      <td>âœ… PASS</td>\n",
       "      <td>âœ… PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe (ATRP)</th>\n",
       "      <td>âœ… PASS</td>\n",
       "      <td>âœ… PASS</td>\n",
       "      <td>âœ… PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe (TRP)</th>\n",
       "      <td>âœ… PASS</td>\n",
       "      <td>âœ… PASS</td>\n",
       "      <td>âœ… PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Group</th>\n",
       "      <th>Gain</th>\n",
       "      <td>âœ… PASS</td>\n",
       "      <td>âœ… PASS</td>\n",
       "      <td>âœ… PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe</th>\n",
       "      <td>âœ… PASS</td>\n",
       "      <td>âœ… PASS</td>\n",
       "      <td>âœ… PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe (ATRP)</th>\n",
       "      <td>âœ… PASS</td>\n",
       "      <td>âœ… PASS</td>\n",
       "      <td>âœ… PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe (TRP)</th>\n",
       "      <td>âœ… PASS</td>\n",
       "      <td>âœ… PASS</td>\n",
       "      <td>âœ… PASS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Period                     Full Holding Lookback\n",
       "Entity    Metric                                \n",
       "Benchmark Gain           âœ… PASS  âœ… PASS   âœ… PASS\n",
       "          Sharpe         âœ… PASS  âœ… PASS   âœ… PASS\n",
       "          Sharpe (ATRP)  âœ… PASS  âœ… PASS   âœ… PASS\n",
       "          Sharpe (TRP)   âœ… PASS  âœ… PASS   âœ… PASS\n",
       "Group     Gain           âœ… PASS  âœ… PASS   âœ… PASS\n",
       "          Sharpe         âœ… PASS  âœ… PASS   âœ… PASS\n",
       "          Sharpe (ATRP)  âœ… PASS  âœ… PASS   âœ… PASS\n",
       "          Sharpe (TRP)   âœ… PASS  âœ… PASS   âœ… PASS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b1096_row0_col5, #T_b1096_row1_col5, #T_b1096_row2_col5, #T_b1096_row3_col5, #T_b1096_row4_col5, #T_b1096_row5_col5, #T_b1096_row6_col5, #T_b1096_row7_col5, #T_b1096_row8_col5, #T_b1096_row9_col5, #T_b1096_row10_col5, #T_b1096_row11_col5, #T_b1096_row12_col5, #T_b1096_row13_col5, #T_b1096_row14_col5, #T_b1096_row15_col5, #T_b1096_row16_col5, #T_b1096_row17_col5, #T_b1096_row18_col5, #T_b1096_row19_col5, #T_b1096_row20_col5, #T_b1096_row21_col5, #T_b1096_row22_col5, #T_b1096_row23_col5 {\n",
       "  color: gray;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b1096\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b1096_level0_col0\" class=\"col_heading level0 col0\" >Entity</th>\n",
       "      <th id=\"T_b1096_level0_col1\" class=\"col_heading level0 col1\" >Period</th>\n",
       "      <th id=\"T_b1096_level0_col2\" class=\"col_heading level0 col2\" >Metric</th>\n",
       "      <th id=\"T_b1096_level0_col3\" class=\"col_heading level0 col3\" >Engine</th>\n",
       "      <th id=\"T_b1096_level0_col4\" class=\"col_heading level0 col4\" >Manual</th>\n",
       "      <th id=\"T_b1096_level0_col5\" class=\"col_heading level0 col5\" >Delta</th>\n",
       "      <th id=\"T_b1096_level0_col6\" class=\"col_heading level0 col6\" >Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b1096_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b1096_row0_col0\" class=\"data row0 col0\" >Group</td>\n",
       "      <td id=\"T_b1096_row0_col1\" class=\"data row0 col1\" >Full</td>\n",
       "      <td id=\"T_b1096_row0_col2\" class=\"data row0 col2\" >Gain</td>\n",
       "      <td id=\"T_b1096_row0_col3\" class=\"data row0 col3\" >0.08367909</td>\n",
       "      <td id=\"T_b1096_row0_col4\" class=\"data row0 col4\" >0.08367909</td>\n",
       "      <td id=\"T_b1096_row0_col5\" class=\"data row0 col5\" >0.00000000</td>\n",
       "      <td id=\"T_b1096_row0_col6\" class=\"data row0 col6\" >âœ… PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1096_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b1096_row1_col0\" class=\"data row1 col0\" >Benchmark</td>\n",
       "      <td id=\"T_b1096_row1_col1\" class=\"data row1 col1\" >Full</td>\n",
       "      <td id=\"T_b1096_row1_col2\" class=\"data row1 col2\" >Gain</td>\n",
       "      <td id=\"T_b1096_row1_col3\" class=\"data row1 col3\" >0.03400340</td>\n",
       "      <td id=\"T_b1096_row1_col4\" class=\"data row1 col4\" >0.03400340</td>\n",
       "      <td id=\"T_b1096_row1_col5\" class=\"data row1 col5\" >0.00000000</td>\n",
       "      <td id=\"T_b1096_row1_col6\" class=\"data row1 col6\" >âœ… PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1096_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b1096_row2_col0\" class=\"data row2 col0\" >Group</td>\n",
       "      <td id=\"T_b1096_row2_col1\" class=\"data row2 col1\" >Full</td>\n",
       "      <td id=\"T_b1096_row2_col2\" class=\"data row2 col2\" >Sharpe</td>\n",
       "      <td id=\"T_b1096_row2_col3\" class=\"data row2 col3\" >10.04813861</td>\n",
       "      <td id=\"T_b1096_row2_col4\" class=\"data row2 col4\" >10.04813861</td>\n",
       "      <td id=\"T_b1096_row2_col5\" class=\"data row2 col5\" >0.00000000</td>\n",
       "      <td id=\"T_b1096_row2_col6\" class=\"data row2 col6\" >âœ… PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1096_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b1096_row3_col0\" class=\"data row3 col0\" >Benchmark</td>\n",
       "      <td id=\"T_b1096_row3_col1\" class=\"data row3 col1\" >Full</td>\n",
       "      <td id=\"T_b1096_row3_col2\" class=\"data row3 col2\" >Sharpe</td>\n",
       "      <td id=\"T_b1096_row3_col3\" class=\"data row3 col3\" >3.57519881</td>\n",
       "      <td id=\"T_b1096_row3_col4\" class=\"data row3 col4\" >3.57519881</td>\n",
       "      <td id=\"T_b1096_row3_col5\" class=\"data row3 col5\" >0.00000000</td>\n",
       "      <td id=\"T_b1096_row3_col6\" class=\"data row3 col6\" >âœ… PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1096_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_b1096_row4_col0\" class=\"data row4 col0\" >Group</td>\n",
       "      <td id=\"T_b1096_row4_col1\" class=\"data row4 col1\" >Full</td>\n",
       "      <td id=\"T_b1096_row4_col2\" class=\"data row4 col2\" >Sharpe (ATRP)</td>\n",
       "      <td id=\"T_b1096_row4_col3\" class=\"data row4 col3\" >0.38807400</td>\n",
       "      <td id=\"T_b1096_row4_col4\" class=\"data row4 col4\" >0.38807400</td>\n",
       "      <td id=\"T_b1096_row4_col5\" class=\"data row4 col5\" >0.00000000</td>\n",
       "      <td id=\"T_b1096_row4_col6\" class=\"data row4 col6\" >âœ… PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1096_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_b1096_row5_col0\" class=\"data row5 col0\" >Benchmark</td>\n",
       "      <td id=\"T_b1096_row5_col1\" class=\"data row5 col1\" >Full</td>\n",
       "      <td id=\"T_b1096_row5_col2\" class=\"data row5 col2\" >Sharpe (ATRP)</td>\n",
       "      <td id=\"T_b1096_row5_col3\" class=\"data row5 col3\" >0.17446208</td>\n",
       "      <td id=\"T_b1096_row5_col4\" class=\"data row5 col4\" >0.17446208</td>\n",
       "      <td id=\"T_b1096_row5_col5\" class=\"data row5 col5\" >0.00000000</td>\n",
       "      <td id=\"T_b1096_row5_col6\" class=\"data row5 col6\" >âœ… PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1096_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_b1096_row6_col0\" class=\"data row6 col0\" >Group</td>\n",
       "      <td id=\"T_b1096_row6_col1\" class=\"data row6 col1\" >Full</td>\n",
       "      <td id=\"T_b1096_row6_col2\" class=\"data row6 col2\" >Sharpe (TRP)</td>\n",
       "      <td id=\"T_b1096_row6_col3\" class=\"data row6 col3\" >0.31121600</td>\n",
       "      <td id=\"T_b1096_row6_col4\" class=\"data row6 col4\" >0.31121600</td>\n",
       "      <td id=\"T_b1096_row6_col5\" class=\"data row6 col5\" >0.00000000</td>\n",
       "      <td id=\"T_b1096_row6_col6\" class=\"data row6 col6\" >âœ… PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1096_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_b1096_row7_col0\" class=\"data row7 col0\" >Benchmark</td>\n",
       "      <td id=\"T_b1096_row7_col1\" class=\"data row7 col1\" >Full</td>\n",
       "      <td id=\"T_b1096_row7_col2\" class=\"data row7 col2\" >Sharpe (TRP)</td>\n",
       "      <td id=\"T_b1096_row7_col3\" class=\"data row7 col3\" >0.17062179</td>\n",
       "      <td id=\"T_b1096_row7_col4\" class=\"data row7 col4\" >0.17062179</td>\n",
       "      <td id=\"T_b1096_row7_col5\" class=\"data row7 col5\" >0.00000000</td>\n",
       "      <td id=\"T_b1096_row7_col6\" class=\"data row7 col6\" >âœ… PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1096_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_b1096_row8_col0\" class=\"data row8 col0\" >Group</td>\n",
       "      <td id=\"T_b1096_row8_col1\" class=\"data row8 col1\" >Lookback</td>\n",
       "      <td id=\"T_b1096_row8_col2\" class=\"data row8 col2\" >Gain</td>\n",
       "      <td id=\"T_b1096_row8_col3\" class=\"data row8 col3\" >0.09115399</td>\n",
       "      <td id=\"T_b1096_row8_col4\" class=\"data row8 col4\" >0.09115399</td>\n",
       "      <td id=\"T_b1096_row8_col5\" class=\"data row8 col5\" >0.00000000</td>\n",
       "      <td id=\"T_b1096_row8_col6\" class=\"data row8 col6\" >âœ… PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1096_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_b1096_row9_col0\" class=\"data row9 col0\" >Benchmark</td>\n",
       "      <td id=\"T_b1096_row9_col1\" class=\"data row9 col1\" >Lookback</td>\n",
       "      <td id=\"T_b1096_row9_col2\" class=\"data row9 col2\" >Gain</td>\n",
       "      <td id=\"T_b1096_row9_col3\" class=\"data row9 col3\" >0.02213362</td>\n",
       "      <td id=\"T_b1096_row9_col4\" class=\"data row9 col4\" >0.02213362</td>\n",
       "      <td id=\"T_b1096_row9_col5\" class=\"data row9 col5\" >0.00000000</td>\n",
       "      <td id=\"T_b1096_row9_col6\" class=\"data row9 col6\" >âœ… PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1096_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_b1096_row10_col0\" class=\"data row10 col0\" >Group</td>\n",
       "      <td id=\"T_b1096_row10_col1\" class=\"data row10 col1\" >Lookback</td>\n",
       "      <td id=\"T_b1096_row10_col2\" class=\"data row10 col2\" >Sharpe</td>\n",
       "      <td id=\"T_b1096_row10_col3\" class=\"data row10 col3\" >23.58794227</td>\n",
       "      <td id=\"T_b1096_row10_col4\" class=\"data row10 col4\" >23.58794227</td>\n",
       "      <td id=\"T_b1096_row10_col5\" class=\"data row10 col5\" >0.00000000</td>\n",
       "      <td id=\"T_b1096_row10_col6\" class=\"data row10 col6\" >âœ… PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1096_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_b1096_row11_col0\" class=\"data row11 col0\" >Benchmark</td>\n",
       "      <td id=\"T_b1096_row11_col1\" class=\"data row11 col1\" >Lookback</td>\n",
       "      <td id=\"T_b1096_row11_col2\" class=\"data row11 col2\" >Sharpe</td>\n",
       "      <td id=\"T_b1096_row11_col3\" class=\"data row11 col3\" >3.47348826</td>\n",
       "      <td id=\"T_b1096_row11_col4\" class=\"data row11 col4\" >3.47348826</td>\n",
       "      <td id=\"T_b1096_row11_col5\" class=\"data row11 col5\" >0.00000000</td>\n",
       "      <td id=\"T_b1096_row11_col6\" class=\"data row11 col6\" >âœ… PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1096_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_b1096_row12_col0\" class=\"data row12 col0\" >Group</td>\n",
       "      <td id=\"T_b1096_row12_col1\" class=\"data row12 col1\" >Lookback</td>\n",
       "      <td id=\"T_b1096_row12_col2\" class=\"data row12 col2\" >Sharpe (ATRP)</td>\n",
       "      <td id=\"T_b1096_row12_col3\" class=\"data row12 col3\" >0.71083911</td>\n",
       "      <td id=\"T_b1096_row12_col4\" class=\"data row12 col4\" >0.71083911</td>\n",
       "      <td id=\"T_b1096_row12_col5\" class=\"data row12 col5\" >0.00000000</td>\n",
       "      <td id=\"T_b1096_row12_col6\" class=\"data row12 col6\" >âœ… PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1096_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_b1096_row13_col0\" class=\"data row13 col0\" >Benchmark</td>\n",
       "      <td id=\"T_b1096_row13_col1\" class=\"data row13 col1\" >Lookback</td>\n",
       "      <td id=\"T_b1096_row13_col2\" class=\"data row13 col2\" >Sharpe (ATRP)</td>\n",
       "      <td id=\"T_b1096_row13_col3\" class=\"data row13 col3\" >0.17822363</td>\n",
       "      <td id=\"T_b1096_row13_col4\" class=\"data row13 col4\" >0.17822363</td>\n",
       "      <td id=\"T_b1096_row13_col5\" class=\"data row13 col5\" >0.00000000</td>\n",
       "      <td id=\"T_b1096_row13_col6\" class=\"data row13 col6\" >âœ… PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1096_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_b1096_row14_col0\" class=\"data row14 col0\" >Group</td>\n",
       "      <td id=\"T_b1096_row14_col1\" class=\"data row14 col1\" >Lookback</td>\n",
       "      <td id=\"T_b1096_row14_col2\" class=\"data row14 col2\" >Sharpe (TRP)</td>\n",
       "      <td id=\"T_b1096_row14_col3\" class=\"data row14 col3\" >0.53243333</td>\n",
       "      <td id=\"T_b1096_row14_col4\" class=\"data row14 col4\" >0.53243333</td>\n",
       "      <td id=\"T_b1096_row14_col5\" class=\"data row14 col5\" >0.00000000</td>\n",
       "      <td id=\"T_b1096_row14_col6\" class=\"data row14 col6\" >âœ… PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1096_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_b1096_row15_col0\" class=\"data row15 col0\" >Benchmark</td>\n",
       "      <td id=\"T_b1096_row15_col1\" class=\"data row15 col1\" >Lookback</td>\n",
       "      <td id=\"T_b1096_row15_col2\" class=\"data row15 col2\" >Sharpe (TRP)</td>\n",
       "      <td id=\"T_b1096_row15_col3\" class=\"data row15 col3\" >0.16703731</td>\n",
       "      <td id=\"T_b1096_row15_col4\" class=\"data row15 col4\" >0.16703731</td>\n",
       "      <td id=\"T_b1096_row15_col5\" class=\"data row15 col5\" >0.00000000</td>\n",
       "      <td id=\"T_b1096_row15_col6\" class=\"data row15 col6\" >âœ… PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1096_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_b1096_row16_col0\" class=\"data row16 col0\" >Group</td>\n",
       "      <td id=\"T_b1096_row16_col1\" class=\"data row16 col1\" >Holding</td>\n",
       "      <td id=\"T_b1096_row16_col2\" class=\"data row16 col2\" >Gain</td>\n",
       "      <td id=\"T_b1096_row16_col3\" class=\"data row16 col3\" >-0.01130108</td>\n",
       "      <td id=\"T_b1096_row16_col4\" class=\"data row16 col4\" >-0.01130108</td>\n",
       "      <td id=\"T_b1096_row16_col5\" class=\"data row16 col5\" >0.00000000</td>\n",
       "      <td id=\"T_b1096_row16_col6\" class=\"data row16 col6\" >âœ… PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1096_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_b1096_row17_col0\" class=\"data row17 col0\" >Benchmark</td>\n",
       "      <td id=\"T_b1096_row17_col1\" class=\"data row17 col1\" >Holding</td>\n",
       "      <td id=\"T_b1096_row17_col2\" class=\"data row17 col2\" >Gain</td>\n",
       "      <td id=\"T_b1096_row17_col3\" class=\"data row17 col3\" >0.00243771</td>\n",
       "      <td id=\"T_b1096_row17_col4\" class=\"data row17 col4\" >0.00243771</td>\n",
       "      <td id=\"T_b1096_row17_col5\" class=\"data row17 col5\" >0.00000000</td>\n",
       "      <td id=\"T_b1096_row17_col6\" class=\"data row17 col6\" >âœ… PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1096_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_b1096_row18_col0\" class=\"data row18 col0\" >Group</td>\n",
       "      <td id=\"T_b1096_row18_col1\" class=\"data row18 col1\" >Holding</td>\n",
       "      <td id=\"T_b1096_row18_col2\" class=\"data row18 col2\" >Sharpe</td>\n",
       "      <td id=\"T_b1096_row18_col3\" class=\"data row18 col3\" >-5.07128664</td>\n",
       "      <td id=\"T_b1096_row18_col4\" class=\"data row18 col4\" >-5.07128664</td>\n",
       "      <td id=\"T_b1096_row18_col5\" class=\"data row18 col5\" >0.00000000</td>\n",
       "      <td id=\"T_b1096_row18_col6\" class=\"data row18 col6\" >âœ… PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1096_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_b1096_row19_col0\" class=\"data row19 col0\" >Benchmark</td>\n",
       "      <td id=\"T_b1096_row19_col1\" class=\"data row19 col1\" >Holding</td>\n",
       "      <td id=\"T_b1096_row19_col2\" class=\"data row19 col2\" >Sharpe</td>\n",
       "      <td id=\"T_b1096_row19_col3\" class=\"data row19 col3\" >0.89461095</td>\n",
       "      <td id=\"T_b1096_row19_col4\" class=\"data row19 col4\" >0.89461095</td>\n",
       "      <td id=\"T_b1096_row19_col5\" class=\"data row19 col5\" >0.00000000</td>\n",
       "      <td id=\"T_b1096_row19_col6\" class=\"data row19 col6\" >âœ… PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1096_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_b1096_row20_col0\" class=\"data row20 col0\" >Group</td>\n",
       "      <td id=\"T_b1096_row20_col1\" class=\"data row20 col1\" >Holding</td>\n",
       "      <td id=\"T_b1096_row20_col2\" class=\"data row20 col2\" >Sharpe (ATRP)</td>\n",
       "      <td id=\"T_b1096_row20_col3\" class=\"data row20 col3\" >-0.17096725</td>\n",
       "      <td id=\"T_b1096_row20_col4\" class=\"data row20 col4\" >-0.17096725</td>\n",
       "      <td id=\"T_b1096_row20_col5\" class=\"data row20 col5\" >0.00000000</td>\n",
       "      <td id=\"T_b1096_row20_col6\" class=\"data row20 col6\" >âœ… PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1096_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_b1096_row21_col0\" class=\"data row21 col0\" >Benchmark</td>\n",
       "      <td id=\"T_b1096_row21_col1\" class=\"data row21 col1\" >Holding</td>\n",
       "      <td id=\"T_b1096_row21_col2\" class=\"data row21 col2\" >Sharpe (ATRP)</td>\n",
       "      <td id=\"T_b1096_row21_col3\" class=\"data row21 col3\" >0.04493777</td>\n",
       "      <td id=\"T_b1096_row21_col4\" class=\"data row21 col4\" >0.04493777</td>\n",
       "      <td id=\"T_b1096_row21_col5\" class=\"data row21 col5\" >0.00000000</td>\n",
       "      <td id=\"T_b1096_row21_col6\" class=\"data row21 col6\" >âœ… PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1096_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_b1096_row22_col0\" class=\"data row22 col0\" >Group</td>\n",
       "      <td id=\"T_b1096_row22_col1\" class=\"data row22 col1\" >Holding</td>\n",
       "      <td id=\"T_b1096_row22_col2\" class=\"data row22 col2\" >Sharpe (TRP)</td>\n",
       "      <td id=\"T_b1096_row22_col3\" class=\"data row22 col3\" >-0.15524509</td>\n",
       "      <td id=\"T_b1096_row22_col4\" class=\"data row22 col4\" >-0.15524509</td>\n",
       "      <td id=\"T_b1096_row22_col5\" class=\"data row22 col5\" >0.00000000</td>\n",
       "      <td id=\"T_b1096_row22_col6\" class=\"data row22 col6\" >âœ… PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1096_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_b1096_row23_col0\" class=\"data row23 col0\" >Benchmark</td>\n",
       "      <td id=\"T_b1096_row23_col1\" class=\"data row23 col1\" >Holding</td>\n",
       "      <td id=\"T_b1096_row23_col2\" class=\"data row23 col2\" >Sharpe (TRP)</td>\n",
       "      <td id=\"T_b1096_row23_col3\" class=\"data row23 col3\" >0.04572424</td>\n",
       "      <td id=\"T_b1096_row23_col4\" class=\"data row23 col4\" >0.04572424</td>\n",
       "      <td id=\"T_b1096_row23_col5\" class=\"data row23 col5\" >0.00000000</td>\n",
       "      <td id=\"T_b1096_row23_col6\" class=\"data row23 col6\" >âœ… PASS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x29d2d6cc950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================================\n",
      "MODULAR EVENT-DRIVEN AUDIT -- END\n",
      "==============================================================================\n",
      "\n",
      "\n",
      "\n",
      "==============================================================================\n",
      "SURVIVAL AUDIT: LIQUIDITY & DATA INTEGRITY POST-MORTEM -- START\n",
      "==============================================================================\n",
      "ðŸ” SECTION 1: DYNAMIC CUTOFF VERIFICATION\n",
      "Metric                         | Value          \n",
      "--------------------------------------------------\n",
      "Target Percentile              |           40.0%\n",
      "Manual Quantile Value          | $   64,410,367\n",
      "Hard Dollar Floor              | $    1,000,000\n",
      "Engine Calculated Cutoff       | $   64,410,367\n",
      "Manual Final Cutoff            | $   64,410,367\n",
      "\n",
      "Cutoff Integrity: âœ… PASS\n",
      "\n",
      "ðŸ” SECTION 2: SURVIVAL MORTALITY REPORT\n",
      "--------------------------------------------------\n",
      "Initial Universe Size          |           1554\n",
      "Killed by Low Liquidity        |            618\n",
      "Killed by Price Staleness      |              6\n",
      "Killed by Frozen Volume        |              5\n",
      "--------------------------------------------------\n",
      "Engine Final Survivors         |            924\n",
      "Manual Audit Survivors         |            924\n",
      "\n",
      "Survival Integrity: âœ… PASS\n",
      "\n",
      "ðŸ” SECTION 3: BOUNDARY INTEGRITY (The Cutoff Edge)\n",
      "-------------------------------------------------------------------------------------\n",
      "LOWEST SURVIVOR: WPC      Vol: $     64,446,158 (Cutoff: $64,410,367)\n",
      "HIGHEST VICTIM:   AN       Vol: $     64,401,420\n",
      "Boundary Logic: âœ… PASS\n",
      "==============================================================================\n",
      "SURVIVAL AUDIT: LIQUIDITY & DATA INTEGRITY POST-MORTEM -- END\n",
      "==============================================================================\n",
      "\n",
      "\n",
      "\n",
      "==============================================================================\n",
      "UNIVERSAL SELECTION AUDIT: LEADERBOARD & RANKING INTEGRITY -- START\n",
      "==============================================================================\n",
      "ðŸ” SELECTION AUDIT: Strategy [Sharpe (ATRP)]\n",
      "   Decision Date: 2025-01-17 | Universe Survivors: 924\n",
      "-------------------------------------------------------------------------------------\n",
      "<pandas.io.formats.style.Styler object at 0x0000029D2D6AD010>\n",
      "\n",
      "Leaderboard Identity Match: âœ… PASS\n",
      "\n",
      "ðŸ” THE BUBBLE (Rank #3 to #5 - The Next in Line)\n",
      "-------------------------------------------------------\n",
      "Rank #11: ONTO     Score:   0.676092 (Gap to Last Selection:   0.001036)\n",
      "Rank #12: C        Score:   0.661535 (Gap to Last Selection:   0.015593)\n",
      "Rank #13: TD       Score:   0.644206 (Gap to Last Selection:   0.032923)\n",
      "==============================================================================\n",
      "UNIVERSAL SELECTION AUDIT: LEADERBOARD & RANKING INTEGRITY -- END\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "verify_engine_results_long_form(audit_pack=audit_pack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbf136b",
   "metadata": {},
   "source": [
    "## Combine Ticker's OHLCV with its Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d54f73b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tickers: ['RPRX', 'SGOV', 'SHV', 'BIL', 'SNX', 'MINT', 'TRGP', 'QRVO', 'LNG', 'USFR']\n",
      "start_date: 2025-01-02 00:00:00\n",
      "decision_date: 2025-01-17 00:00:00\n",
      "buy_date: 2025-01-21 00:00:00\n",
      "end_date: 2025-01-28 00:00:00\n",
      "Creating combined dictionary for 10 ticker(s)\n",
      "Date range: 2025-01-02 00:00:00 to 2025-01-28 00:00:00\n",
      "============================================================\n",
      "Data retrieved for 10 ticker(s) from 2025-01-02 00:00:00 to 2025-01-28 00:00:00\n",
      "Total rows: 170\n",
      "Date range in data: 2025-01-02 00:00:00 to 2025-01-28 00:00:00\n",
      "  RPRX: 17 rows\n",
      "  SGOV: 17 rows\n",
      "  SHV: 17 rows\n",
      "  BIL: 17 rows\n",
      "  SNX: 17 rows\n",
      "  MINT: 17 rows\n",
      "  TRGP: 17 rows\n",
      "  QRVO: 17 rows\n",
      "  LNG: 17 rows\n",
      "  USFR: 17 rows\n",
      "Features data retrieved for 10 ticker(s) from 2025-01-02 00:00:00 to 2025-01-28 00:00:00\n",
      "Total rows: 170\n",
      "Date range in data: 2025-01-02 00:00:00 to 2025-01-28 00:00:00\n",
      "Available features: ATR, ATRP, TRP, RSI, RelStrength, VolRegime, RVol, Spy_RVol, OBV_Score, Spy_OBV_Score, ROC_1, ROC_3, ROC_5, ROC_10, ROC_21, RollingStalePct, RollMedDollarVol, RollingSameVolCount\n",
      "  RPRX: 17 rows\n",
      "  SGOV: 17 rows\n",
      "  SHV: 17 rows\n",
      "  BIL: 17 rows\n",
      "  SNX: 17 rows\n",
      "  MINT: 17 rows\n",
      "  TRGP: 17 rows\n",
      "  QRVO: 17 rows\n",
      "  LNG: 17 rows\n",
      "  USFR: 17 rows\n",
      "\n",
      "Processing RPRX...\n",
      "  âœ“ Successfully combined data\n",
      "  OHLCV shape: (17, 5)\n",
      "  Features shape: (17, 18)\n",
      "  Combined shape: (17, 23)\n",
      "  Date range: 2025-01-02 00:00:00 to 2025-01-28 00:00:00\n",
      "\n",
      "Processing SGOV...\n",
      "  âœ“ Successfully combined data\n",
      "  OHLCV shape: (17, 5)\n",
      "  Features shape: (17, 18)\n",
      "  Combined shape: (17, 23)\n",
      "  Date range: 2025-01-02 00:00:00 to 2025-01-28 00:00:00\n",
      "\n",
      "Processing SHV...\n",
      "  âœ“ Successfully combined data\n",
      "  OHLCV shape: (17, 5)\n",
      "  Features shape: (17, 18)\n",
      "  Combined shape: (17, 23)\n",
      "  Date range: 2025-01-02 00:00:00 to 2025-01-28 00:00:00\n",
      "\n",
      "Processing BIL...\n",
      "  âœ“ Successfully combined data\n",
      "  OHLCV shape: (17, 5)\n",
      "  Features shape: (17, 18)\n",
      "  Combined shape: (17, 23)\n",
      "  Date range: 2025-01-02 00:00:00 to 2025-01-28 00:00:00\n",
      "\n",
      "Processing SNX...\n",
      "  âœ“ Successfully combined data\n",
      "  OHLCV shape: (17, 5)\n",
      "  Features shape: (17, 18)\n",
      "  Combined shape: (17, 23)\n",
      "  Date range: 2025-01-02 00:00:00 to 2025-01-28 00:00:00\n",
      "\n",
      "Processing MINT...\n",
      "  âœ“ Successfully combined data\n",
      "  OHLCV shape: (17, 5)\n",
      "  Features shape: (17, 18)\n",
      "  Combined shape: (17, 23)\n",
      "  Date range: 2025-01-02 00:00:00 to 2025-01-28 00:00:00\n",
      "\n",
      "Processing TRGP...\n",
      "  âœ“ Successfully combined data\n",
      "  OHLCV shape: (17, 5)\n",
      "  Features shape: (17, 18)\n",
      "  Combined shape: (17, 23)\n",
      "  Date range: 2025-01-02 00:00:00 to 2025-01-28 00:00:00\n",
      "\n",
      "Processing QRVO...\n",
      "  âœ“ Successfully combined data\n",
      "  OHLCV shape: (17, 5)\n",
      "  Features shape: (17, 18)\n",
      "  Combined shape: (17, 23)\n",
      "  Date range: 2025-01-02 00:00:00 to 2025-01-28 00:00:00\n",
      "\n",
      "Processing LNG...\n",
      "  âœ“ Successfully combined data\n",
      "  OHLCV shape: (17, 5)\n",
      "  Features shape: (17, 18)\n",
      "  Combined shape: (17, 23)\n",
      "  Date range: 2025-01-02 00:00:00 to 2025-01-28 00:00:00\n",
      "\n",
      "Processing USFR...\n",
      "  âœ“ Successfully combined data\n",
      "  OHLCV shape: (17, 5)\n",
      "  Features shape: (17, 18)\n",
      "  Combined shape: (17, 23)\n",
      "  Date range: 2025-01-02 00:00:00 to 2025-01-28 00:00:00\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "Total tickers processed: 10\n",
      "Tickers with combined data: 10\n",
      "\n",
      "Ticker details:\n",
      "  RPRX: (17, 23) - 2025-01-02 00:00:00 to 2025-01-28 00:00:00\n",
      "    Columns: 23\n",
      "  SGOV: (17, 23) - 2025-01-02 00:00:00 to 2025-01-28 00:00:00\n",
      "    Columns: 23\n",
      "  SHV: (17, 23) - 2025-01-02 00:00:00 to 2025-01-28 00:00:00\n",
      "    Columns: 23\n",
      "  BIL: (17, 23) - 2025-01-02 00:00:00 to 2025-01-28 00:00:00\n",
      "    Columns: 23\n",
      "  SNX: (17, 23) - 2025-01-02 00:00:00 to 2025-01-28 00:00:00\n",
      "    Columns: 23\n",
      "  MINT: (17, 23) - 2025-01-02 00:00:00 to 2025-01-28 00:00:00\n",
      "    Columns: 23\n",
      "  TRGP: (17, 23) - 2025-01-02 00:00:00 to 2025-01-28 00:00:00\n",
      "    Columns: 23\n",
      "  QRVO: (17, 23) - 2025-01-02 00:00:00 to 2025-01-28 00:00:00\n",
      "    Columns: 23\n",
      "  LNG: (17, 23) - 2025-01-02 00:00:00 to 2025-01-28 00:00:00\n",
      "    Columns: 23\n",
      "  USFR: (17, 23) - 2025-01-02 00:00:00 to 2025-01-28 00:00:00\n",
      "    Columns: 23\n"
     ]
    }
   ],
   "source": [
    "tickers = audit_pack[0].tickers\n",
    "start_date = audit_pack[0].start_date\n",
    "decision_date = audit_pack[0].decision_date\n",
    "buy_date = audit_pack[0].buy_date\n",
    "end_date = audit_pack[0].holding_end_date\n",
    "\n",
    "print(f\"tickers: {tickers}\")\n",
    "print(f\"start_date: {start_date}\")\n",
    "print(f\"decision_date: {decision_date}\")\n",
    "print(f\"buy_date: {buy_date}\")\n",
    "print(f\"end_date: {end_date}\")\n",
    "\n",
    "combined = create_combined_dict(\n",
    "    df_ohlcv=df_ohlcv.copy(),\n",
    "    features_df=features_df,\n",
    "    tickers=tickers,\n",
    "    date_start=start_date,\n",
    "    date_end=end_date,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "811ae76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPRX:\n",
      "              Adj Open    Adj High     Adj Low   Adj Close   Volume        ATR       ATRP        TRP         RSI  RelStrength  VolRegime       RVol   Spy_RVol  OBV_Score  Spy_OBV_Score       ROC_1      ROC_3      ROC_5     ROC_10      ROC_21  RollingStalePct  RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                                                                                                                     \n",
      "2025-01-02 24.92200000 25.25370000 24.92200000 25.15610000  1559633 0.46310787 0.01840937 0.01473599 53.27301649   0.00409894 0.59443325 0.49181131 0.95948701 1.75716631    -1.85742390  0.01097536 0.00978633 0.02219432 0.02667064 -0.02421607       0.00000000 65301327.60555001           0.00000000\n",
      "2025-01-03 25.17560000 25.31710000 25.08780000 25.20490000  2135384 0.44640731 0.01771113 0.00909744 54.00255380  -0.00251833 0.58926537 0.68707340 0.72618501 1.85776099    -1.30009257  0.00193989 0.02053633 0.01732343 0.05598569 -0.01898212       0.00000000 65191539.62335000           0.00000000\n",
      "2025-01-06 25.09760000 25.45360000 24.77570000 25.11710000  2288549 0.46294250 0.01843137 0.02698958 52.41689255   0.00359393 0.63083089 0.74287430 0.91573720 1.32849963    -0.72081492 -0.00348345 0.00940803 0.00822084 0.06054503 -0.01341006       0.00000000 65138494.43020000           0.00000000\n",
      "2025-01-07 25.00010000 25.41950000 24.92200000 25.40000000  2796022 0.46541089 0.01832326 0.01958661 56.81671274   0.01354960 0.50213671 0.91336563 1.11578161 1.56891078    -1.25091243  0.01126324 0.00969546 0.02843585 0.04494498 -0.01326268       0.00000000 65191539.62335000           0.00000000\n",
      "2025-01-08 25.34140000 25.72190000 25.13170000 25.55600000  2281885 0.47432440 0.01856020 0.02309438 59.06451646   0.03911750 0.52114988 0.77555037 0.86376045 1.67240949    -0.66589328  0.00614173 0.01392983 0.02704658 0.03762170  0.01118972       0.00000000 65138494.43020000           0.00000000\n",
      "\n",
      "SGOV:\n",
      "              Adj Open    Adj High     Adj Low   Adj Close   Volume        ATR       ATRP        TRP         RSI  RelStrength  VolRegime       RVol   Spy_RVol  OBV_Score  Spy_OBV_Score      ROC_1      ROC_3      ROC_5     ROC_10     ROC_21  RollingStalePct   RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                                                                                                                    \n",
      "2025-01-02 96.31500000 96.31500000 96.30540000 96.31500000  7847904 0.02350266 0.00024402 0.00019935 99.72031592   0.03304629 0.93799126 1.21140307 0.95948701 1.66873645    -1.85742390 0.00019939 0.00049861 0.00089786 0.00201725 0.00391497       0.00000000 392484945.38405001           0.00000000\n",
      "2025-01-03 96.35340000 96.35340000 96.34380000 96.34380000  7011349 0.02456676 0.00025499 0.00039857 99.75048327   0.02096609 0.93365202 1.07438043 0.72618501 1.67757245    -1.30009257 0.00029902 0.00079778 0.00109728 0.00209689 0.00411469       0.00000000 392484945.38405001           0.00000000\n",
      "2025-01-06 96.35340000 96.36300000 96.34380000 96.34380000  7228249 0.02418342 0.00025101 0.00019929 99.75048327   0.02121742 1.03821015 1.09440349 0.91573720 1.52146449    -0.72081492 0.00000000 0.00049846 0.00079778 0.00189681 0.00391484       0.00000000 393459289.21860003           0.00000000\n",
      "2025-01-07 96.37260000 96.37260000 96.36300000 96.36300000  7075940 0.02451317 0.00025438 0.00029887 99.76969029   0.03129622 0.84614872 1.05629280 1.11578161 1.55449845    -1.25091243 0.00019929 0.00049836 0.00099723 0.00189643 0.00401447       0.00000000 394166639.84345007           0.00000000\n",
      "2025-01-08 96.37260000 96.38220000 96.37260000 96.38220000  6356063 0.02413366 0.00025040 0.00019921 99.78732099   0.03143597 0.86596944 0.93981545 0.86376045 1.56473469    -0.66589328 0.00019925 0.00039857 0.00089724 0.00189605 0.00371464       0.00000000 394716394.71165001           0.00000000\n",
      "\n",
      "SHV:\n",
      "               Adj Open     Adj High      Adj Low    Adj Close   Volume        ATR       ATRP        TRP         RSI  RelStrength  VolRegime       RVol   Spy_RVol  OBV_Score  Spy_OBV_Score      ROC_1      ROC_3      ROC_5     ROC_10     ROC_21  RollingStalePct   RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                                                                                                                        \n",
      "2025-01-02 105.72100000 105.72100000 105.71200000 105.72100000  2580088 0.02693367 0.00025476 0.00017972 99.71323861   0.03320051 0.63868548 0.94937867 0.95948701 1.81624675    -1.85742390 0.00017975 0.00053945 0.00099417 0.00206629 0.00406485       0.00000000 274051514.08899999           0.00000000\n",
      "2025-01-03 105.76000000 105.76000000 105.75000000 105.75000000  2234451 0.02779555 0.00026284 0.00036879 99.74154384   0.02091428 0.68947253 0.81636184 0.72618501 1.73968751    -1.30009257 0.00027431 0.00054876 0.00108865 0.00217968 0.00406373       0.00000000 274051514.08899999           0.00000000\n",
      "2025-01-06 105.76000000 105.76900000 105.76000000 105.76900000  2720509 0.02716730 0.00025685 0.00017964 99.75837189   0.02155238 0.69076339 1.01428195 0.91573720 1.70766447    -0.72081492 0.00017967 0.00063386 0.00099372 0.00209383 0.00424413       0.00000000 275455617.60899997           0.00000000\n",
      "2025-01-07 105.76900000 105.78800000 105.76900000 105.78800000  2544565 0.02658392 0.00025129 0.00017960 99.77420431   0.03144320 0.60209666 0.94146220 1.11578161 1.66891728    -1.25091243 0.00017964 0.00063374 0.00090830 0.00199854 0.00415757       0.00000000 275455617.60899997           0.00000000\n",
      "2025-01-08 105.77900000 105.78800000 105.77900000 105.78800000  4510674 0.02532792 0.00023942 0.00008508 99.77420431   0.03142119 1.03529836 1.61050497 0.86376045 1.50691957    -0.66589328 0.00000000 0.00035934 0.00081361 0.00190364 0.00370026       0.00000000 275666540.23800004           0.00000000\n",
      "\n",
      "BIL:\n",
      "              Adj Open    Adj High     Adj Low   Adj Close    Volume        ATR       ATRP        TRP         RSI  RelStrength  VolRegime       RVol   Spy_RVol  OBV_Score  Spy_OBV_Score      ROC_1      ROC_3      ROC_5     ROC_10     ROC_21  RollingStalePct   RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                                                                                                                     \n",
      "2025-01-02 87.76050000 87.76050000 87.75090000 87.76050000  11209130 0.02124300 0.00024206 0.00021878 99.62704425   0.03310963 1.15689702 1.47762230 0.95948701 1.62830449    -1.85742390 0.00021883 0.00043775 0.00109508 0.00189510 0.00397653       0.00000000 552412968.36925006           0.00000000\n",
      "2025-01-03 87.78930000 87.78930000 87.77010000 87.77010000   8167412 0.02178279 0.00024818 0.00032813 99.64271877   0.02071425 1.20518133 1.06175064 0.72618501 1.66526814    -1.30009257 0.00010939 0.00054718 0.00098536 0.00200469 0.00386701       0.00000000 552412968.36925006           0.00000000\n",
      "2025-01-06 87.77970000 87.78930000 87.77970000 87.77970000   8156157 0.02159830 0.00024605 0.00021873 99.65818938   0.02116833 0.67940018 1.04781837 0.91573720 1.69421600    -0.72081492 0.00010938 0.00043765 0.00065662 0.00197245 0.00386658       0.00000000 553084831.18785000           0.00000000\n",
      "2025-01-07 87.79890000 87.80840000 87.78930000 87.79890000   7249270 0.02210557 0.00025177 0.00032688 99.68734837   0.03125781 0.44785156 0.92517129 1.11578161 1.69790066    -1.25091243 0.00021873 0.00043755 0.00087549 0.00175252 0.00397708       0.00000000 553933418.51900005           0.00000000\n",
      "2025-01-08 87.81800000 87.81800000 87.80840000 87.81800000   6953644 0.02189088 0.00024928 0.00021750 99.71352924   0.03147953 0.49124243 0.88224862 0.86376045 1.69431032    -0.66589328 0.00021754 0.00054574 0.00087416 0.00197044 0.00375703       0.00000000 554770259.12879992           0.00000000\n",
      "\n",
      "SNX:\n",
      "               Adj Open     Adj High      Adj Low    Adj Close  Volume        ATR       ATRP        TRP         RSI  RelStrength  VolRegime       RVol   Spy_RVol   OBV_Score  Spy_OBV_Score       ROC_1       ROC_3       ROC_5      ROC_10      ROC_21  RollingStalePct  RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                                                                                                                            \n",
      "2025-01-02 116.69200000 116.99800000 114.68900000 114.93600000  384091 2.45531357 0.02136244 0.02008944 42.14100846  -0.01842312 0.77916558 0.57222993 0.95948701 -1.28079400    -1.85742390 -0.00681789 -0.01555434 -0.02306012 -0.02997772 -0.04610303       0.00000000 67361622.69100000           0.00000000\n",
      "2025-01-03 115.24200000 116.71200000 114.58100000 116.36700000  536207 2.43214831 0.02090067 0.01831275 46.40866903  -0.02027100 0.88565129 0.80385245 0.72618501 -0.89487914    -1.30009257  0.01245041  0.01288222 -0.01692152  0.01236233 -0.03644177       0.00000000 67361622.69100000           0.00000000\n",
      "2025-01-06 116.96900000 119.40600000 116.55400000 116.73200000  468409 2.47549486 0.02120665 0.02603399 47.47291070  -0.02685694 0.81001090 0.70654566 0.91573720 -0.56673917    -0.72081492  0.00313663  0.00870166 -0.00017130  0.00689191 -0.04334500       0.00000000 67361622.69100000           0.00000000\n",
      "2025-01-07 118.47800000 121.61600000 117.92600000 121.59600000  766865 2.64753094 0.02177317 0.04016579 59.12260051   0.03718662 1.09118741 1.17559173 1.11578161 -0.07880111    -1.25091243  0.04166809  0.05794529  0.05839651  0.05414824  0.00974905       0.00000000 67505119.21700001           0.00000000\n",
      "2025-01-08 120.46200000 120.97500000 118.28100000 120.48100000  813382 2.69520730 0.02237039 0.02751471 56.05357615   0.01819577 1.22908145 1.20464664 0.86376045 -0.48327182    -0.66589328 -0.00916971  0.03535367  0.04109743  0.03562065 -0.00916971       0.00000000 67505119.21700001           0.00000000\n",
      "\n",
      "MINT:\n",
      "              Adj Open    Adj High     Adj Low   Adj Close   Volume        ATR       ATRP        TRP         RSI  RelStrength  VolRegime       RVol   Spy_RVol  OBV_Score  Spy_OBV_Score       ROC_1      ROC_3      ROC_5     ROC_10     ROC_21  RollingStalePct  RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                                                                                                                    \n",
      "2025-01-02 95.80050000 95.80050000 95.77180000 95.78140000  2948179 0.03326020 0.00034725 0.00029964 90.46300345   0.03291616 1.43588016 2.03128828 0.95948701 1.46345479    -1.85742390 -0.00019937 0.00059755 0.00109431 0.00179165 0.00378852       0.00000000 93075600.18400000           0.00000000\n",
      "2025-01-03 95.84820000 95.84820000 95.81960000 95.82910000  1396583 0.03565590 0.00037208 0.00069707 91.78340203   0.02093944 1.48169902 0.95145552 0.72618501 1.63524985    -1.30009257  0.00049801 0.00079789 0.00139400 0.00229055 0.00408848       0.00000000 93518582.12154999           0.00000000\n",
      "2025-01-06 95.83870000 95.84820000 95.82910000 95.84820000  1149190 0.03447334 0.00035967 0.00019927 92.24631691   0.02139429 1.49074039 0.77415594 0.91573720 1.73160279    -0.72081492  0.00019931 0.00049791 0.00129539 0.00258994 0.00408871       0.00000000 93518582.12154999           0.00000000\n",
      "2025-01-07 95.84820000 95.85780000 95.82910000 95.83870000  1405276 0.03406096 0.00035540 0.00029946 89.54409520   0.03116655 1.61231174 0.93212923 1.11578161 1.30188670    -1.25091243 -0.00009912 0.00059824 0.00089815 0.00199272 0.00388823       0.00000000 93785988.08309999           0.00000000\n",
      "2025-01-08 95.85780000 95.87690000 95.85780000 95.87690000   885145 0.03435660 0.00035834 0.00039843 90.72113523   0.03161492 1.50174834 0.58838865 0.86376045 1.40058010    -0.66589328  0.00039859 0.00049880 0.00079749 0.00229255 0.00388878       0.00000000 93785988.08309999           0.00000000\n",
      "\n",
      "TRGP:\n",
      "               Adj Open     Adj High      Adj Low    Adj Close   Volume        ATR       ATRP        TRP         RSI  RelStrength  VolRegime       RVol   Spy_RVol  OBV_Score  Spy_OBV_Score       ROC_1      ROC_3      ROC_5     ROC_10      ROC_21  RollingStalePct   RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                                                                                                                          \n",
      "2025-01-02 176.26600000 179.33800000 175.39500000 179.09300000  1170972 4.38658364 0.02449333 0.02627685 50.02955574  -0.03170961 0.80299367 0.64134614 0.95948701 0.83904250    -1.85742390  0.02554515 0.03213518 0.01294654 0.01015269 -0.05901484       0.00000000 193548170.04500002           0.00000000\n",
      "2025-01-03 180.36500000 183.54500000 180.10100000 182.13600000  1181807 4.39125624 0.02410977 0.02444327 54.24218361  -0.03975096 0.62525144 0.66559467 0.72618501 1.18987695    -1.30009257  0.01699117 0.04731237 0.04648798 0.08276362 -0.05560021       0.00000000 194559900.74699998           0.00000000\n",
      "2025-01-06 183.89700000 183.89700000 180.70800000 182.12600000  1953426 4.30538079 0.02363957 0.01750986 54.22600541  -0.03111701 0.58818321 1.08974982 0.91573720 0.67691404    -0.72081492 -0.00005490 0.04291310 0.04961474 0.07899663 -0.04753288       0.00000000 195252090.71420002           0.00000000\n",
      "2025-01-07 182.49800000 185.12000000 180.13000000 183.75000000  1623681 4.35428216 0.02369677 0.02715646 56.49534506  -0.02726352 0.55406046 0.90755342 1.11578161 1.16543665    -1.25091243  0.00891690 0.02600325 0.05659314 0.06239051 -0.05299614       0.00000000 195917862.11320001           0.00000000\n",
      "2025-01-08 183.72100000 187.90800000 182.97700000 187.82000000  1252744 4.39547629 0.02340260 0.02625386 61.62952340   0.01513894 0.55162835 0.72154755 0.86376045 1.45171461    -0.66589328  0.02214966 0.03120745 0.07551881 0.07630154 -0.01214439       0.00000000 195917862.11320001           0.00000000\n",
      "\n",
      "QRVO:\n",
      "              Adj Open    Adj High     Adj Low   Adj Close   Volume        ATR       ATRP        TRP         RSI  RelStrength  VolRegime       RVol   Spy_RVol  OBV_Score  Spy_OBV_Score       ROC_1       ROC_3       ROC_5      ROC_10      ROC_21  RollingStalePct   RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                                                                                                                         \n",
      "2025-01-02 70.72000000 70.98000000 69.20000000 69.76000000  1849100 2.07650701 0.02976644 0.02551606 43.71158237   0.01390220 0.76244738 0.48901200 0.95948701 1.17384752    -1.85742390 -0.00243100 -0.02324279 -0.02433566 -0.01677237 -0.01468927       0.00000000 130352514.50000000           0.00000000\n",
      "2025-01-03 69.90000000 71.10000000 69.30000000 70.63000000  3891200 2.05675651 0.02912015 0.02548492 47.88284751   0.01966970 0.91820308 1.01192047 0.72618501 1.25179263    -1.30009257  0.01247133  0.01290693 -0.01396063  0.03109489  0.00283970       0.00000000 130352514.50000000           0.00000000\n",
      "2025-01-06 71.10000000 72.87000000 71.07000000 72.14000000  2669600 2.06984533 0.02869206 0.03105073 54.22349700   0.04713671 1.13193668 0.70000052 0.91573720 1.25591242    -0.72081492  0.02137902  0.03160303  0.01008121  0.04854651  0.02939498       0.00000000 130352514.50000000           0.00000000\n",
      "2025-01-07 72.68000000 74.20000000 72.36000000 73.63000000  2607900 2.06914209 0.02810189 0.02797773 59.46416016   0.10104416 0.71664666 0.68623844 1.11578161 1.25414359    -1.25091243  0.02065428  0.05547592  0.05593002  0.03923783  0.07191731       0.00000000 130441063.50000000           0.00000000\n",
      "2025-01-08 73.13000000 73.33000000 71.83000000 73.08000000  3260800 2.04991766 0.02805032 0.02463054 56.87575696   0.09905425 0.89171525 0.86178479 0.86376045 0.99236218    -0.66589328 -0.00746978  0.03468781  0.04504505  0.02152642  0.06951559       0.00000000 130522152.50000000           0.00000000\n",
      "\n",
      "LNG:\n",
      "               Adj Open     Adj High      Adj Low    Adj Close   Volume        ATR       ATRP        TRP         RSI  RelStrength  VolRegime       RVol   Spy_RVol  OBV_Score  Spy_OBV_Score       ROC_1      ROC_3      ROC_5     ROC_10      ROC_21  RollingStalePct   RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                                                                                                                          \n",
      "2025-01-02 215.50900000 220.16600000 214.46800000 218.58000000  2145846 4.21318073 0.01927523 0.03322811 64.40420626   0.01990954 0.83076686 1.48447924 0.95948701 1.48995181    -1.85742390  0.02666473 0.04807891 0.04802865 0.04708480 -0.00885132       0.00000000 270742251.27300000           0.00000000\n",
      "2025-01-03 219.96700000 222.70200000 219.43200000 220.44300000  1430497 4.20666782 0.01908279 0.01869871 66.59668588   0.01391230 0.70634800 0.98202277 0.72618501 1.85342910    -1.30009257  0.00852320 0.04416467 0.05806715 0.07660262 -0.00282267       0.00000000 271521811.01999998           0.00000000\n",
      "2025-01-06 221.70100000 223.45500000 220.71100000 221.86000000  1472380 4.12133440 0.01857628 0.01357613 68.20100922   0.01809783 0.60946039 1.00775921 0.91573720 2.11492754    -0.72081492  0.00642797 0.04207080 0.06380632 0.08726122  0.00084810       0.00000000 271888802.29799998           0.00000000\n",
      "2025-01-07 222.27600000 223.89100000 219.60100000 221.46400000  1084226 4.13338195 0.01866390 0.01937109 67.22922362   0.01621503 0.78298747 0.75507908 1.11578161 1.68167744    -1.25091243 -0.00178491 0.01319425 0.04900080 0.06999328 -0.01066776       0.00000000 271521811.01999998           0.00000000\n",
      "2025-01-08 220.12600000 223.46500000 218.70900000 223.12800000  1386393 4.17785466 0.01872403 0.02131512 69.21427547   0.04271304 0.81678917 0.96930405 0.86376045 1.92136888    -0.66589328  0.00751364 0.01218002 0.04802657 0.07550744  0.01468863       0.00000000 271888802.29799998           0.00000000\n",
      "\n",
      "USFR:\n",
      "              Adj Open    Adj High     Adj Low   Adj Close   Volume        ATR       ATRP        TRP         RSI  RelStrength  VolRegime       RVol   Spy_RVol  OBV_Score  Spy_OBV_Score      ROC_1      ROC_3      ROC_5     ROC_10     ROC_21  RollingStalePct   RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                                                                                                                    \n",
      "2025-01-02 48.26870000 48.28790000 48.26870000 48.28790000  6914552 0.01723972 0.00035702 0.00039762 98.13051226   0.03358546 1.26643138 1.31269752 0.95948701 1.63905776    -1.85742390 0.00019885 0.00079586 0.00145174 0.00244550 0.00443894       0.00000000 190240788.34390000           0.00000000\n",
      "2025-01-03 48.29750000 48.30710000 48.28790000 48.29750000  5822858 0.01737974 0.00035985 0.00039754 98.24455069   0.02170073 1.35249820 1.07590847 0.72618501 1.65083630    -1.30009257 0.00019881 0.00099483 0.00119403 0.00264479 0.00483720       0.00000000 191041239.18309999           0.00000000\n",
      "2025-01-06 48.30710000 48.30710000 48.29750000 48.30710000  3213902 0.01682404 0.00034827 0.00019873 98.35276129   0.02195275 1.39196219 0.59080345 0.91573720 1.58890472    -0.72081492 0.00019877 0.00059654 0.00119379 0.00244661 0.00463771       0.00000000 191041239.18309999           0.00000000\n",
      "2025-01-07 48.30710000 48.31670000 48.29750000 48.31670000  4012608 0.01699375 0.00035172 0.00039738 98.45530498   0.03193758 1.13698734 0.73045139 1.11578161 1.56236658    -1.25091243 0.00019873 0.00059642 0.00139276 0.00224858 0.00463887       0.00000000 191041239.18309999           0.00000000\n",
      "2025-01-08 48.32630000 48.32630000 48.31670000 48.32630000  3608825 0.01646563 0.00034072 0.00019865 98.55235574   0.03238477 0.00039892 0.66336260 0.86376045 1.52793832    -0.66589328 0.00019869 0.00059630 0.00099424 0.00224813 0.00463795       0.00000000 191041239.18309999           0.00000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ticker in tickers:\n",
    "    with pd.option_context(\"display.float_format\", \"{:.8f}\".format):\n",
    "        print(f\"{ticker}:\\n{combined[ticker].head()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43de0c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0039da56",
   "metadata": {},
   "source": [
    "## 2-Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "36612929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- âš™ï¸ Initializing AlphaEngine v2.2 (Sanitized) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d63e1f08b0644a8b7facb47134610e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>1. Timeline Configuration:</b> (Past <--- Decision ---> Future)'), HBox(childrenâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32125d6dca7a4594a4623cf3517ea57b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'width': 2},\n",
       "              'name': 'ITUB',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c6ad40d0-e6e6-4dc5-a3df-d2bfde91c47a',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.        , 1.02420717, ..., 1.68842586, 1.65319915,\n",
       "                          1.66963893])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'JAAA',\n",
       "              'type': 'scatter',\n",
       "              'uid': '5a080cc9-9707-4a1a-b5d3-9c984bf5dc78',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00078728, 1.00098566, ..., 1.0517411 , 1.05194992,\n",
       "                          1.05278106])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'VEU',\n",
       "              'type': 'scatter',\n",
       "              'uid': '15f4d11d-75ac-4591-8de8-c9c1cc9b9392',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00577633, 0.9947176 , ..., 1.25236478, 1.24333547,\n",
       "                          1.25304587])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'AU',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'cc3f2749-4b09-497e-9125-e3097955d9b0',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.02326552, 1.03329485, ..., 3.54060614, 3.56251896,\n",
       "                          3.61055861])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'RGTI',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ddc49793-e7a1-4660-8423-ad7c76bb5599',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.02054795, 1.48173516, ..., 5.47031963, 5.13013699,\n",
       "                          5.21004566])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'EZU',\n",
       "              'type': 'scatter',\n",
       "              'uid': '753b69b4-4c16-44f3-b10e-b0879d649cee',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 0.99715795, 0.99147384, ..., 1.33970425, 1.3274849 ,\n",
       "                          1.33675475])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'GOOGL',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c4bccd10-a699-4e2a-98b9-ae2f2bebb5b5',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00493013, 1.06108877, ..., 1.76362977, 1.70696489,\n",
       "                          1.73998585])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'VCSH',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c1544231-6e44-4aaf-b350-e08613323f3f',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 0.99923569, 0.99923569, ..., 1.06081807, 1.06081807,\n",
       "                          1.06216528])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'CAT',\n",
       "              'type': 'scatter',\n",
       "              'uid': '0509787c-995b-428e-91f5-ebd42bb3985b',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.01070787, 0.9831917 , ..., 1.51336364, 1.4438794 ,\n",
       "                          1.45400395])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'WDC',\n",
       "              'type': 'scatter',\n",
       "              'uid': '51ec65eb-8461-401f-a557-4e8cfe343706',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 0.99535818, 0.96834257, ..., 3.26235436, 3.10687957,\n",
       "                          3.27038971])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'IEFA',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd3e9da00-57c8-4704-956f-b4de3f49dd96',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 0.9987937 , 0.99075217, ..., 1.24782824, 1.23822304,\n",
       "                          1.24726322])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'PLTR',\n",
       "              'type': 'scatter',\n",
       "              'uid': '87161464-ca7c-4b0b-8ccc-e63a6d4da5f6',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 0.94917474, 0.92860886, ..., 2.45939219, 2.32237359,\n",
       "                          2.43240765])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'INSM',\n",
       "              'type': 'scatter',\n",
       "              'uid': '6ea6f244-1f46-44e4-88e9-73bbb60d241c',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 0.96511936, 0.96312997, ..., 2.66140584, 2.63209549,\n",
       "                          2.20888594])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'BBIO',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e0a2a9b8-29f3-4a0c-bb43-c8c6094d1e65',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.02466134, 1.00868357, ..., 2.62903786, 2.57103161,\n",
       "                          2.57519972])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'TPR',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c7f82957-7d37-4bff-9eb1-63ac7ebe30f5',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00032157, 0.98618536, ..., 2.00926852, 1.99457731,\n",
       "                          2.04697598])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'BOXX',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f8f41c21-46b3-44ba-b2c2-fcc49823eea3',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.        , 1.00027298, ..., 1.044495  , 1.04476797,\n",
       "                          1.04504095])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'NEM',\n",
       "              'type': 'scatter',\n",
       "              'uid': '8a2ee190-192c-4c42-86a7-08d45c07ba70',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.0150824 , 1.00924437, ..., 2.42500853, 2.46013566,\n",
       "                          2.45741454])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'BE',\n",
       "              'type': 'scatter',\n",
       "              'uid': '09c9d32b-0d71-4aa4-a699-347977f8e039',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 0.98153619, 0.86669129, ..., 3.23522895, 2.84231905,\n",
       "                          2.96196455])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'GLDM',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'babbe7f4-c4c4-4c40-831e-d5dea201b7f1',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00977948, 1.02281879, ..., 1.63413231, 1.64755513,\n",
       "                          1.64487057])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'EFV',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f7aa0622-064f-4d99-8b19-2b3de690a189',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00145286, 0.99491788, ..., 1.35754638, 1.35503813,\n",
       "                          1.3598617 ])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'IAU',\n",
       "              'type': 'scatter',\n",
       "              'uid': '70ef1f74-b708-4ea3-8cf9-14751a6064b6',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00986312, 1.02314815, ..., 1.63204509, 1.64573269,\n",
       "                          1.64311594])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'SPDW',\n",
       "              'type': 'scatter',\n",
       "              'uid': '78c9ee9e-8a56-455f-857e-7f5c6f9e0656',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 0.99806675, 0.99004636, ..., 1.2702607 , 1.26113725,\n",
       "                          1.26911991])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'IDXX',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f109b6d9-bcca-4260-9d4e-5f34d250ff0a',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.0344052 , 1.02072575, ..., 1.5909936 , 1.596548  ,\n",
       "                          1.59999082])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'LRCX',\n",
       "              'type': 'scatter',\n",
       "              'uid': '878e29e2-e956-4b49-901f-989dc6271c28',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.0112288 , 0.98093774, ..., 2.15773711, 2.04830392,\n",
       "                          2.17676897])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'QBTS',\n",
       "              'type': 'scatter',\n",
       "              'uid': '43d476f9-9314-4047-b806-f65a35eedafa',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 0.91897233, 0.92490119, ..., 5.04347826, 4.70355731,\n",
       "                          4.91897233])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'NXT',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f6b5725d-bcd0-4622-a62b-324f7727e20e',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.05676495, 1.01818683, ..., 2.42491044, 2.36511436,\n",
       "                          2.40810141])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'HOOD',\n",
       "              'type': 'scatter',\n",
       "              'uid': '522f67aa-3057-475a-9af6-8dcf3d58a572',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 0.94888409, 0.89656827, ..., 2.86537077, 2.77897768,\n",
       "                          2.81161507])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'USFR',\n",
       "              'type': 'scatter',\n",
       "              'uid': '60c9d548-f1d0-4313-a085-d62c49994c28',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00019749, 1.00019749, ..., 1.04427772, 1.04448561,\n",
       "                          1.04448561])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'RY',\n",
       "              'type': 'scatter',\n",
       "              'uid': '79672f38-f374-4ce3-ab96-b49fc69fe41b',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 0.99929161, 0.99897405, ..., 1.35466115, 1.34586729,\n",
       "                          1.36093085])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'GOOG',\n",
       "              'type': 'scatter',\n",
       "              'uid': '75e9c812-f9df-48b1-98f8-08221595aa7c',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00459551, 1.05809027, ..., 1.75238887, 1.69732241,\n",
       "                          1.7297245 ])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'TEL',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'fc97818c-a986-4439-95e6-202da20fdde3',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 0.99409565, 0.98589332, ..., 1.50703673, 1.47927501,\n",
       "                          1.50079367])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'CHRW',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd130d758-8095-4625-b0d4-47b006621a9c',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.02570614, 1.03585484, ..., 1.54159316, 1.55186786,\n",
       "                          1.59965493])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'PSLV',\n",
       "              'type': 'scatter',\n",
       "              'uid': '95621a30-cb9e-4cb3-bbd9-a3fcdd3ca932',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.02305476, 1.02305476, ..., 2.0259366 , 2.10566763,\n",
       "                          2.07492795])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'RPRX',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a2261c58-d2c1-4d1f-9fc5-08b6d2be3129',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00385784, 0.98764699, ..., 1.51860469, 1.51583496,\n",
       "                          1.52058307])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'ATI',\n",
       "              'type': 'scatter',\n",
       "              'uid': '5dd14d40-7f44-488c-b566-cfc2594cffd9',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 0.98505647, 0.99200695, ..., 1.88809731, 1.87471764,\n",
       "                          1.90721112])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'WPM',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f9d0b27e-70b3-4300-ab5e-26b55364b2b5',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.01385851, 1.00733609, ..., 1.8735593 , 1.88403709,\n",
       "                          1.89009456])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'AG',\n",
       "              'type': 'scatter',\n",
       "              'uid': '9a5eb280-9989-405d-92a5-0e2851fbe523',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.06568002, 1.05090164, ..., 2.6983448 , 2.69505413,\n",
       "                          2.65721149])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'STX',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c53a33d4-853f-4137-be5a-08dc0a7e88b6',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00466941, 0.99066118, ..., 2.99592795, 2.88695422,\n",
       "                          3.0361689 ])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'BBD',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'cc035c51-04e6-44bf-a3a1-bc4fa1ea896a',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 0.98049049, 1.01951475, ..., 1.75360536, 1.73266679,\n",
       "                          1.73790143])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'GDX',\n",
       "              'type': 'scatter',\n",
       "              'uid': '0df9fb1d-5bb5-4106-9999-1e46252d8b2f',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.02960396, 1.03150541, ..., 2.33096044, 2.35843876,\n",
       "                          2.35404356])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'GSK',\n",
       "              'type': 'scatter',\n",
       "              'uid': '0447b277-7880-4c00-a222-e11d5f5b922a',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.04107585, 1.01851505, ..., 1.47167079, 1.46955892,\n",
       "                          1.45688771])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'GH',\n",
       "              'type': 'scatter',\n",
       "              'uid': '6651e8c1-a6a1-4d74-8dc9-eb6e20b93d95',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 0.98643884, 0.96365609, ..., 2.71223217, 2.64361269,\n",
       "                          2.63357743])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'SGOL',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f919eb13-1296-4819-ab61-1e855c2fd62f',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00955034, 1.02228412, ..., 1.63270991, 1.64663749,\n",
       "                          1.64305611])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'KGC',\n",
       "              'type': 'scatter',\n",
       "              'uid': '93c33fd5-2fd0-4f69-b3f8-1c59586d3901',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.0174357 , 1.0338496 , ..., 2.87034227, 2.88375991,\n",
       "                          2.88892054])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'VEA',\n",
       "              'type': 'scatter',\n",
       "              'uid': '2e112755-982e-4527-be92-bd469752d9b9',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 0.99763383, 0.99034074, ..., 1.27149422, 1.26253882,\n",
       "                          1.27251273])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'SGI',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e33a26f8-70ab-4019-a4a5-32c4d44e0015',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00836088, 1.00490727, ..., 1.66997545, 1.63111324,\n",
       "                          1.64907785])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'BSV',\n",
       "              'type': 'scatter',\n",
       "              'uid': '65609591-e3e4-4fc1-b569-0539d13ad3c6',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 0.99935767, 0.99897147, ..., 1.05498676, 1.05485266,\n",
       "                          1.05615341])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'GDXJ',\n",
       "              'type': 'scatter',\n",
       "              'uid': '8c6d3ebe-0f89-4062-93b6-b48a043caa0a',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.04121907, 1.04206417, ..., 2.45500017, 2.48514423,\n",
       "                          2.47602782])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'BTI',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ab915c31-42a0-4a82-aef0-9664a452ea41',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00158804, 0.99814776, ..., 1.62358174, 1.62017879,\n",
       "                          1.61649441])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'PAAS',\n",
       "              'type': 'scatter',\n",
       "              'uid': '26223d44-5ec3-45d1-96a3-d4ad6fe38694',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.05006892, 1.04285383, ..., 2.24095498, 2.27461934,\n",
       "                          2.27689396])},\n",
       "             {'line': {'color': 'black', 'dash': 'dash', 'width': 3},\n",
       "              'name': 'Benchmark (SPY)',\n",
       "              'type': 'scatter',\n",
       "              'uid': '521d7a02-0970-4fc5-af48-7611781fbe4d',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 0.99485085, 0.99175769, ..., 1.1304907 , 1.11805124,\n",
       "                          1.12649397])},\n",
       "             {'line': {'color': 'green', 'width': 3},\n",
       "              'name': 'Group Portfolio',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'afa84cae-7724-418f-95e7-725954029dd3',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2024, 12, 6, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2024, 12, 10, 0, 0), ...,\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00276742, 1.00040571, ..., 1.91752208, 1.88584551,\n",
       "                          1.90444404])}],\n",
       "    'layout': {'annotations': [{'bgcolor': 'red',\n",
       "                                'font': {'color': 'white'},\n",
       "                                'showarrow': False,\n",
       "                                'text': 'DECISION',\n",
       "                                'x': Timestamp('2025-12-10 00:00:00'),\n",
       "                                'xref': 'x',\n",
       "                                'y': 0.05,\n",
       "                                'yref': 'paper'},\n",
       "                               {'bgcolor': 'blue',\n",
       "                                'font': {'color': 'white'},\n",
       "                                'showarrow': False,\n",
       "                                'text': 'ENTRY (T+1)',\n",
       "                                'x': Timestamp('2025-12-11 00:00:00'),\n",
       "                                'xref': 'x',\n",
       "                                'y': 1.0,\n",
       "                                'yref': 'paper'}],\n",
       "               'height': 600,\n",
       "               'hovermode': 'x unified',\n",
       "               'shapes': [{'line': {'color': 'red', 'dash': 'dash', 'width': 2},\n",
       "                           'type': 'line',\n",
       "                           'x0': Timestamp('2025-12-10 00:00:00'),\n",
       "                           'x1': Timestamp('2025-12-10 00:00:00'),\n",
       "                           'xref': 'x',\n",
       "                           'y0': 0,\n",
       "                           'y1': 1,\n",
       "                           'yref': 'paper'},\n",
       "                          {'line': {'color': 'blue', 'dash': 'dot', 'width': 2},\n",
       "                           'type': 'line',\n",
       "                           'x0': Timestamp('2025-12-11 00:00:00'),\n",
       "                           'x1': Timestamp('2025-12-11 00:00:00'),\n",
       "                           'xref': 'x',\n",
       "                           'y0': 0,\n",
       "                           'y1': 1,\n",
       "                           'yref': 'paper'}],\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Event-Driven Walk-Forward Analysis'}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# STEP 1: RUN THE COARSE FILTER (THE NET)\n",
    "# ==============================================================================\n",
    "# We set Rank End to 100 to find the \"Top 100 Quality Stocks\"\n",
    "audit_pack_1 = plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_ohlcv.copy(),\n",
    "    features_df=features_df,\n",
    "    df_close_wide=df_close_wide,\n",
    "    df_atrp_wide=df_atrp_wide,\n",
    "    df_trp_wide=df_trp_wide,\n",
    "    default_start_date=\"2025-12-10\",  # <--- SHARED DECISION DATE\n",
    "    default_strategy=\"Sharpe (ATRP)\",  # Use a stable, long-term metric\n",
    "    default_lookback=252,  # 1-year stability check\n",
    "    default_rank_end=100,  # Keep the top 100 candidates\n",
    "    default_holding=5,  # Holding period doesn't matter for selection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ac84e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generate the map and capture registry\n",
    "reg = visualize_audit_structure(audit_pack_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "567be3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- âš™ï¸ Initializing AlphaEngine v2.2 (Sanitized) ---\n"
     ]
    }
   ],
   "source": [
    "engine = AlphaEngine(\n",
    "    df_ohlcv=df_ohlcv.copy(),\n",
    "    features_df=features_df,\n",
    "    df_close_wide=df_close_wide,\n",
    "    df_atrp_wide=df_atrp_wide,\n",
    "    df_trp_wide=df_trp_wide,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58335920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the audit\n",
    "verify_engine_results_short_form(audit_pack_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3db9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_engine_results_long_form(audit_pack_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c541cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ‚ï¸ Funneling 100 candidates + benchmark 'SPY' into the Sniper...\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# STEP 2: DYNAMIC SUBSETTING (THE FUNNEL)\n",
    "# ==============================================================================\n",
    "\n",
    "# 1. ACCESS the EngineOutput directly from the pack\n",
    "res = audit_pack_1[0]\n",
    "\n",
    "# 2. Programmatic fetch of tickers\n",
    "# .tickers is a direct attribute of EngineOutput (Ref ID [5] in your map)\n",
    "candidates = res.tickers\n",
    "\n",
    "# 3. Programmatic fetch of the Benchmark\n",
    "# This is tucked inside the inputs_snapshot (Ref ID [157] in your map)\n",
    "benchmark = res.debug_data[\"inputs_snapshot\"].benchmark_ticker\n",
    "\n",
    "# 4. Create the surgical subset universe\n",
    "subset_universe = list(set(candidates + [benchmark]))\n",
    "\n",
    "print(\n",
    "    f\"âœ‚ï¸ Funneling {len(candidates)} candidates + benchmark '{benchmark}' into the Sniper...\"\n",
    ")\n",
    "\n",
    "# 5. Slice the data surgically\n",
    "# (Note: These wide dataframes must exist in your global scope)\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "# Multi-indexed data slicing (Ticker is level 0)\n",
    "df_ohlcv_sub = df_ohlcv.loc[idx[subset_universe, :], :].sort_index()\n",
    "features_df_sub = features_df.loc[idx[subset_universe, :], :].sort_index()\n",
    "\n",
    "# Wide-format data slicing (Ticker as Column Name)\n",
    "df_close_sub = df_close_wide[subset_universe]\n",
    "df_atrp_sub = df_atrp_wide[subset_universe]\n",
    "df_trp_sub = df_trp_wide[subset_universe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e4e8affb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- âš™ï¸ Initializing AlphaEngine v2.2 (Sanitized) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cbc681b8e1d49bdbca0f42b056ec8ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>1. Timeline Configuration:</b> (Past <--- Decision ---> Future)'), HBox(childrenâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df0fc1a273f04607a1b6c9a4b3ab64c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'width': 2},\n",
       "              'name': 'TD',\n",
       "              'type': 'scatter',\n",
       "              'uid': '0073040f-16cb-4b16-a4fc-91c751ca1f32',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 11, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 11, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 11, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 1, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 4, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 5, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 11, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 12, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.01372859, 1.01968169, 1.01445754, 1.02721419, 1.02502734,\n",
       "                          1.04580245, 1.07301664, 1.0707083 , 1.08297898, 1.10873527, 1.11566031,\n",
       "                          1.11067914, 1.11821164, 1.11347345, 1.10739886, 1.12404325])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'BCS',\n",
       "              'type': 'scatter',\n",
       "              'uid': '3e0d3c1d-13be-423a-847e-a6413143ac9f',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 11, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 11, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 11, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 1, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 4, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 5, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 11, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 12, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.03181189, 1.05071462, 1.04887045, 1.06454587, 1.07238359,\n",
       "                          1.07883817, 1.07053942, 1.07238359, 1.06685108, 1.09820194, 1.11526049,\n",
       "                          1.09912402, 1.12217612, 1.11848778, 1.12355924, 1.14292301])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'SHV',\n",
       "              'type': 'scatter',\n",
       "              'uid': '3b8bad3f-6b57-4c5c-81d5-eb5113448cb7',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 11, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 11, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 11, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 1, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 4, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 5, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 11, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 12, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00018233, 1.00045582, 1.00065638, 1.00083871, 1.00102104,\n",
       "                          1.00102104, 1.0013857 , 1.00146775, 1.00155891, 1.0018324 , 1.00201473,\n",
       "                          1.00228823, 1.00247055, 1.00256172, 1.00265288, 1.00283521])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'SLV',\n",
       "              'type': 'scatter',\n",
       "              'uid': '6bcc5329-347b-4a4c-99bd-a741f02874ed',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 11, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 11, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 11, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 1, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 4, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 5, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 11, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 12, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.03706878, 1.09727877, 1.12534819, 1.13841868, 1.13713306,\n",
       "                          1.10906364, 1.13456182, 1.12941933, 1.18212985, 1.20141418, 1.2346261 ,\n",
       "                          1.202057  , 1.24512535, 1.23698307, 1.29119349, 1.27105207])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'PSLV',\n",
       "              'type': 'scatter',\n",
       "              'uid': '9e294030-b3ae-4b30-96be-0c8726d90d47',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 11, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 11, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 11, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 1, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 4, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 5, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 11, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 12, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.03636364, 1.09384164, 1.13255132, 1.15014663, 1.15014663,\n",
       "                          1.11671554, 1.14252199, 1.13665689, 1.1771261 , 1.20410557, 1.23225806,\n",
       "                          1.19648094, 1.24281525, 1.23695015, 1.2856305 , 1.26686217])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'RY',\n",
       "              'type': 'scatter',\n",
       "              'uid': '46d0c002-e586-4607-aa13-f19225e74ad3',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 11, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 11, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 11, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 1, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 4, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 5, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 11, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 12, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00637236, 1.01228485, 1.00440152, 1.01451846, 1.0292997 ,\n",
       "                          1.05478912, 1.06740244, 1.07338063, 1.07213244, 1.08487715, 1.0972277 ,\n",
       "                          1.08960715, 1.09768756, 1.09295756, 1.08586257, 1.09801603])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'WBD',\n",
       "              'type': 'scatter',\n",
       "              'uid': '6d0c8c65-6dd1-48a3-ae83-06256ac342a6',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 11, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 11, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 11, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 1, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 4, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 5, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 11, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 12, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.04006969, 1.04529617, 1.03963415, 1.06837979, 1.07012195,\n",
       "                          1.06881533, 1.1358885 , 1.18597561, 1.23083624, 1.28614983, 1.28440767,\n",
       "                          1.30574913, 1.29398955, 1.2587108 , 1.22865854, 1.20252613])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'BIL',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f5cf3d2d-1a03-4ea7-88d4-a3c60e5c3fed',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 11, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 11, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 11, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 1, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 4, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 5, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 11, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 12, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00010875, 1.0004361 , 1.00055693, 1.00088537, 1.00099412,\n",
       "                          1.00110397, 1.00132257, 1.00143242, 1.00165101, 1.00165101, 1.00175976,\n",
       "                          1.00219806, 1.00219806, 1.00230681, 1.00241665, 1.00258142])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'MINT',\n",
       "              'type': 'scatter',\n",
       "              'uid': '96258bbc-b6d3-47f5-9b1f-338e8994badd',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 11, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 11, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 11, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 1, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 4, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 5, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 11, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 12, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00039751, 1.00049764, 1.00069689, 1.00079602, 1.00089615,\n",
       "                          1.00099628, 1.00139479, 1.00129466, 1.00139479, 1.00169517, 1.00199556,\n",
       "                          1.00229595, 1.00239607, 1.00269646, 1.00279659, 1.0028867 ])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'SGOV',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd39d2b6e-1ef9-4a62-b657-5b3ba011c8d6',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 11, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 11, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 11, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 1, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 4, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 5, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 11, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 12, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00010101, 1.00040102, 1.00063103, 1.00083104, 1.00092105,\n",
       "                          1.00112106, 1.00142107, 1.00142107, 1.00152108, 1.00152108, 1.00172109,\n",
       "                          1.00212111, 1.00212111, 1.00222111, 1.00242112, 1.00242112])},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '6641618c-4e85-467f-b9c3-f76c9c455726', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '29fd8c8b-8cd6-4107-8df8-0b8bdcbdadf9', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '40ed2b02-deec-4445-a7b8-725630d26ac1', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'd3c8885d-3411-41a5-be32-ecc641411a41', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'a24eaf7a-eb95-4b32-8770-1692b3675cb4', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '52472507-15ca-43ad-a551-ef66b1a21ac0', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '0b8bd41f-dcbf-42fd-b031-ba6809d29a53', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'd728482b-751b-4619-a298-5cc4681ec139', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'f7ba564c-9921-4576-aa76-8c71ab16ce50', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '6d098712-f8d8-4f0a-b385-6d32400bba03', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '79096ff6-5a42-4e12-9b36-5486c102da47', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'ae8668f8-7f3f-489e-8169-389e5ba0d0e5', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'b52dab25-95e5-4fe5-a3dc-211b2de9ad6c', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'e70b6822-0095-4355-8b13-f236150d7f98', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '95a1a688-1942-4b84-a6e0-a72364112d53', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'e0f0d503-7234-4c51-9b40-a5e86adc08c7', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '60ea0d80-a3fa-4f1d-9503-4a7e175dbca5', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '62cd4dc1-aecd-4386-9cfa-062c54aa51dd', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '113a01b9-8613-49de-9908-580dd93c3030', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'ebc12ba3-6d11-42dd-af60-3b753440606e', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'b995b83f-f513-4611-a197-0bb4bc21eb66', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '52e4525e-3963-42ee-a54e-d332c9ed55c8', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'b1e6050a-3c6a-42df-914f-3660703ca0ff', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'b33f99b0-1115-4843-806d-9863ee657597', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'b0137c17-b360-41ad-959d-3ce9ba9f2a12', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '0669ddf1-e33c-4983-b22d-7321d268790b', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '93715bc1-184c-4234-8e79-aa1932ef93ab', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '1c016f65-2ff9-4565-8a81-232f7ac69cbb', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'aa6d6bfd-7cac-4e1c-93c4-00d8e209c798', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '9342fd36-c80c-4490-ac5e-ba787a231973', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'bb2d8a0b-7506-4767-825c-c4c8f6bc3b82', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'e9c9babc-63fc-4194-9455-9b28a5a98f4d', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '7f837364-7cb5-466b-a5c4-ad359079fe3f', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '1482b24a-99d4-42bf-b346-d0977c342cfe', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '8a4da7a5-5738-4f56-b02c-a4ada3b52129', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'da991d84-1c07-48d6-a557-3e3e3ad7d214', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '1be83de4-153a-4f3f-aa1f-d8143b975895', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'e78ce6f9-7bf2-424b-b858-55f037af8b99', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'ac8c250e-a33c-44ef-87ea-50a9fd47d9c0', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'd7d63999-f7ee-4b3f-ba94-11228a8f59f5', 'visible': False},\n",
       "             {'line': {'color': 'black', 'dash': 'dash', 'width': 3},\n",
       "              'name': 'Benchmark (SPY)',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd4516508-a5c7-4d16-94e0-bc55cc9e35be',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 11, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 11, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 11, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 1, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 4, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 5, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 11, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 12, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00690459, 1.01240062, 1.00777824, 1.00964443, 1.01314055,\n",
       "                          1.01388198, 1.01580759, 1.01275573, 1.01188207, 1.01859201, 1.02096337,\n",
       "                          1.00998468, 1.00845875, 1.00570405, 0.99463769, 1.00214849])},\n",
       "             {'line': {'color': 'green', 'width': 3},\n",
       "              'name': 'Group Portfolio',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f86762fe-a56f-4630-897e-dd55a59f2929',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 11, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 11, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 11, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 1, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 4, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 5, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 9, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 10, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 11, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 12, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 16, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 17, 0, 0),\n",
       "                          datetime.datetime(2025, 12, 18, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.01662045, 1.03208883, 1.03678044, 1.04665748, 1.04879446,\n",
       "                          1.04782666, 1.06294549, 1.06741402, 1.08181805, 1.09901836, 1.10869315,\n",
       "                          1.10126007, 1.11291913, 1.10673489, 1.11325904, 1.11161471])}],\n",
       "    'layout': {'annotations': [{'bgcolor': 'red',\n",
       "                                'font': {'color': 'white'},\n",
       "                                'showarrow': False,\n",
       "                                'text': 'DECISION',\n",
       "                                'x': Timestamp('2025-12-10 00:00:00'),\n",
       "                                'xref': 'x',\n",
       "                                'y': 0.05,\n",
       "                                'yref': 'paper'},\n",
       "                               {'bgcolor': 'blue',\n",
       "                                'font': {'color': 'white'},\n",
       "                                'showarrow': False,\n",
       "                                'text': 'ENTRY (T+1)',\n",
       "                                'x': Timestamp('2025-12-11 00:00:00'),\n",
       "                                'xref': 'x',\n",
       "                                'y': 1.0,\n",
       "                                'yref': 'paper'}],\n",
       "               'height': 600,\n",
       "               'hovermode': 'x unified',\n",
       "               'shapes': [{'line': {'color': 'red', 'dash': 'dash', 'width': 2},\n",
       "                           'type': 'line',\n",
       "                           'x0': Timestamp('2025-12-10 00:00:00'),\n",
       "                           'x1': Timestamp('2025-12-10 00:00:00'),\n",
       "                           'xref': 'x',\n",
       "                           'y0': 0,\n",
       "                           'y1': 1,\n",
       "                           'yref': 'paper'},\n",
       "                          {'line': {'color': 'blue', 'dash': 'dot', 'width': 2},\n",
       "                           'type': 'line',\n",
       "                           'x0': Timestamp('2025-12-11 00:00:00'),\n",
       "                           'x1': Timestamp('2025-12-11 00:00:00'),\n",
       "                           'xref': 'x',\n",
       "                           'y0': 0,\n",
       "                           'y1': 1,\n",
       "                           'yref': 'paper'}],\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Event-Driven Walk-Forward Analysis'}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# STEP 3: RUN THE SNIPER FILTER (THE SYNC'D ENTRY)\n",
    "# ==============================================================================\n",
    "# We use the SUBSETTED data but the EXACT SAME decision date\n",
    "audit_pack_2 = plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_ohlcv_sub.copy(),\n",
    "    features_df=features_df_sub,\n",
    "    df_close_wide=df_close_sub,\n",
    "    df_atrp_wide=df_atrp_sub,\n",
    "    df_trp_wide=df_trp_sub,\n",
    "    default_start_date=res.decision_date,  # <--- Exact Decision Date from Run 1\n",
    "    default_strategy=\"Sharpe (TRP)\",  # Use a faster, conviction metric\n",
    "    default_lookback=10,  # Short-term timing check\n",
    "    default_rank_end=10,  # Select the final tradeable portfolio\n",
    "    default_holding=5,  # This is your actual trade duration\n",
    "    # Disable thresholds because the 100 candidates already passed in Run 1\n",
    "    quality_thresholds={\n",
    "        \"min_median_dollar_volume\": 0,\n",
    "        \"min_liquidity_percentile\": 0.0,\n",
    "        \"max_stale_pct\": 1.0,\n",
    "        \"max_same_vol_count\": 999,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ce963da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ•µï¸  STARTING MULTI-LAYER AUDIT: Sharpe (TRP) @ 2025-12-10\n",
      "\n",
      "\n",
      "=====================================================================================\n",
      "*************************************************************************************\n",
      "âš ï¸  ASSUMPTION: Verification logic is independent, but trusts Engine source DataFrames\n",
      "   (engine.features_df, engine.df_close, and debug['portfolio_raw_components'])\n",
      "*************************************************************************************\n",
      "===================================================================================== \n",
      "\n",
      "\n",
      "ðŸ•µï¸  STARTING MULTI-LAYER AUDIT: Sharpe (TRP) @ 2025-12-10\n",
      "=====================================================================================\n",
      "LAYER 1: SURVIVAL  | Universe: 101 -> Survivors: 101 | âœ… PASS\n",
      "LAYER 2: SELECTION | Strategy: Sharpe (TRP) | Selection Match: âœ… PASS\n",
      "LAYER 3: PERFORMANCE | Holding Gain: 0.0030 vs Manual: 0.0030 | âœ… PASS\n",
      "=====================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_d6af7\">\n",
       "  <caption>Layer 2: Selection Reconciliation</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d6af7_level0_col0\" class=\"col_heading level0 col0\" >Ticker</th>\n",
       "      <th id=\"T_d6af7_level0_col1\" class=\"col_heading level0 col1\" >Engine</th>\n",
       "      <th id=\"T_d6af7_level0_col2\" class=\"col_heading level0 col2\" >Manual</th>\n",
       "      <th id=\"T_d6af7_level0_col3\" class=\"col_heading level0 col3\" >Delta</th>\n",
       "      <th id=\"T_d6af7_level0_col4\" class=\"col_heading level0 col4\" >Match</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Rank</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d6af7_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_d6af7_row0_col0\" class=\"data row0 col0\" >SHV</td>\n",
       "      <td id=\"T_d6af7_row0_col1\" class=\"data row0 col1\" >0.789797</td>\n",
       "      <td id=\"T_d6af7_row0_col2\" class=\"data row0 col2\" >0.789797</td>\n",
       "      <td id=\"T_d6af7_row0_col3\" class=\"data row0 col3\" >0.00000000</td>\n",
       "      <td id=\"T_d6af7_row0_col4\" class=\"data row0 col4\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6af7_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "      <td id=\"T_d6af7_row1_col0\" class=\"data row1 col0\" >SGOV</td>\n",
       "      <td id=\"T_d6af7_row1_col1\" class=\"data row1 col1\" >0.753769</td>\n",
       "      <td id=\"T_d6af7_row1_col2\" class=\"data row1 col2\" >0.753769</td>\n",
       "      <td id=\"T_d6af7_row1_col3\" class=\"data row1 col3\" >0.00000000</td>\n",
       "      <td id=\"T_d6af7_row1_col4\" class=\"data row1 col4\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6af7_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "      <td id=\"T_d6af7_row2_col0\" class=\"data row2 col0\" >BIL</td>\n",
       "      <td id=\"T_d6af7_row2_col1\" class=\"data row2 col1\" >0.689552</td>\n",
       "      <td id=\"T_d6af7_row2_col2\" class=\"data row2 col2\" >0.689552</td>\n",
       "      <td id=\"T_d6af7_row2_col3\" class=\"data row2 col3\" >0.00000000</td>\n",
       "      <td id=\"T_d6af7_row2_col4\" class=\"data row2 col4\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6af7_level0_row3\" class=\"row_heading level0 row3\" >4</th>\n",
       "      <td id=\"T_d6af7_row3_col0\" class=\"data row3 col0\" >MINT</td>\n",
       "      <td id=\"T_d6af7_row3_col1\" class=\"data row3 col1\" >0.667676</td>\n",
       "      <td id=\"T_d6af7_row3_col2\" class=\"data row3 col2\" >0.667676</td>\n",
       "      <td id=\"T_d6af7_row3_col3\" class=\"data row3 col3\" >0.00000000</td>\n",
       "      <td id=\"T_d6af7_row3_col4\" class=\"data row3 col4\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6af7_level0_row4\" class=\"row_heading level0 row4\" >5</th>\n",
       "      <td id=\"T_d6af7_row4_col0\" class=\"data row4 col0\" >WBD</td>\n",
       "      <td id=\"T_d6af7_row4_col1\" class=\"data row4 col1\" >0.646641</td>\n",
       "      <td id=\"T_d6af7_row4_col2\" class=\"data row4 col2\" >0.646641</td>\n",
       "      <td id=\"T_d6af7_row4_col3\" class=\"data row4 col3\" >0.00000000</td>\n",
       "      <td id=\"T_d6af7_row4_col4\" class=\"data row4 col4\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6af7_level0_row5\" class=\"row_heading level0 row5\" >6</th>\n",
       "      <td id=\"T_d6af7_row5_col0\" class=\"data row5 col0\" >TD</td>\n",
       "      <td id=\"T_d6af7_row5_col1\" class=\"data row5 col1\" >0.616072</td>\n",
       "      <td id=\"T_d6af7_row5_col2\" class=\"data row5 col2\" >0.616072</td>\n",
       "      <td id=\"T_d6af7_row5_col3\" class=\"data row5 col3\" >0.00000000</td>\n",
       "      <td id=\"T_d6af7_row5_col4\" class=\"data row5 col4\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6af7_level0_row6\" class=\"row_heading level0 row6\" >7</th>\n",
       "      <td id=\"T_d6af7_row6_col0\" class=\"data row6 col0\" >SLV</td>\n",
       "      <td id=\"T_d6af7_row6_col1\" class=\"data row6 col1\" >0.571533</td>\n",
       "      <td id=\"T_d6af7_row6_col2\" class=\"data row6 col2\" >0.571533</td>\n",
       "      <td id=\"T_d6af7_row6_col3\" class=\"data row6 col3\" >0.00000000</td>\n",
       "      <td id=\"T_d6af7_row6_col4\" class=\"data row6 col4\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6af7_level0_row7\" class=\"row_heading level0 row7\" >8</th>\n",
       "      <td id=\"T_d6af7_row7_col0\" class=\"data row7 col0\" >PSLV</td>\n",
       "      <td id=\"T_d6af7_row7_col1\" class=\"data row7 col1\" >0.568033</td>\n",
       "      <td id=\"T_d6af7_row7_col2\" class=\"data row7 col2\" >0.568033</td>\n",
       "      <td id=\"T_d6af7_row7_col3\" class=\"data row7 col3\" >0.00000000</td>\n",
       "      <td id=\"T_d6af7_row7_col4\" class=\"data row7 col4\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6af7_level0_row8\" class=\"row_heading level0 row8\" >9</th>\n",
       "      <td id=\"T_d6af7_row8_col0\" class=\"data row8 col0\" >RY</td>\n",
       "      <td id=\"T_d6af7_row8_col1\" class=\"data row8 col1\" >0.548323</td>\n",
       "      <td id=\"T_d6af7_row8_col2\" class=\"data row8 col2\" >0.548323</td>\n",
       "      <td id=\"T_d6af7_row8_col3\" class=\"data row8 col3\" >0.00000000</td>\n",
       "      <td id=\"T_d6af7_row8_col4\" class=\"data row8 col4\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6af7_level0_row9\" class=\"row_heading level0 row9\" >10</th>\n",
       "      <td id=\"T_d6af7_row9_col0\" class=\"data row9 col0\" >BCS</td>\n",
       "      <td id=\"T_d6af7_row9_col1\" class=\"data row9 col1\" >0.490987</td>\n",
       "      <td id=\"T_d6af7_row9_col2\" class=\"data row9 col2\" >0.490987</td>\n",
       "      <td id=\"T_d6af7_row9_col3\" class=\"data row9 col3\" >0.00000000</td>\n",
       "      <td id=\"T_d6af7_row9_col4\" class=\"data row9 col4\" >True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x29e15177fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_12fed\">\n",
       "  <caption>Layer 3: Performance Reconciliation</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_12fed_level0_col0\" class=\"col_heading level0 col0\" >Engine</th>\n",
       "      <th id=\"T_12fed_level0_col1\" class=\"col_heading level0 col1\" >Manual</th>\n",
       "      <th id=\"T_12fed_level0_col2\" class=\"col_heading level0 col2\" >Delta</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Metric</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_12fed_level0_row0\" class=\"row_heading level0 row0\" >Holding Gain</th>\n",
       "      <td id=\"T_12fed_row0_col0\" class=\"data row0 col0\" >0.00300983</td>\n",
       "      <td id=\"T_12fed_row0_col1\" class=\"data row0 col1\" >0.00300983</td>\n",
       "      <td id=\"T_12fed_row0_col2\" class=\"data row0 col2\" >0.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_12fed_level0_row1\" class=\"row_heading level0 row1\" >Holding Sharpe</th>\n",
       "      <td id=\"T_12fed_row1_col0\" class=\"data row1 col0\" >1.42832352</td>\n",
       "      <td id=\"T_12fed_row1_col1\" class=\"data row1 col1\" >1.42832352</td>\n",
       "      <td id=\"T_12fed_row1_col2\" class=\"data row1 col2\" >0.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_12fed_level0_row2\" class=\"row_heading level0 row2\" >Sharpe (ATRP)</th>\n",
       "      <td id=\"T_12fed_row2_col0\" class=\"data row2 col0\" >0.04480872</td>\n",
       "      <td id=\"T_12fed_row2_col1\" class=\"data row2 col1\" >0.04480872</td>\n",
       "      <td id=\"T_12fed_row2_col2\" class=\"data row2 col2\" >0.00000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x29d2d81c8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the audit\n",
    "verify_engine_results_short_form(audit_pack_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
