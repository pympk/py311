{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "import ipywidgets as widgets\n",
        "import sys\n",
        "import io\n",
        "import pprint\n",
        "\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List, Dict, Optional, Any, Union\n",
        "from collections import Counter\n",
        "from datetime import datetime, date\n",
        "from pandas.testing import assert_series_equal\n",
        "\n",
        "# pd.set_option('display.max_rows', None)  display all rows\n",
        "pd.set_option(\"display.max_rows\", 100)\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "pd.set_option(\"display.width\", 1000)\n",
        "pd.set_option(\"display.max_colwidth\", 50)\n",
        "pd.set_option(\"display.precision\", 4)\n",
        "\n",
        "# ==============================================================================\n",
        "# SECTION A: CORE HELPER FUNCTIONS & FEATURE GENERATION\n",
        "# (Unchanged from previous version)\n",
        "# ==============================================================================\n",
        "# ... (Keep generate_features, calculate_gain, calculate_sharpe,\n",
        "#      calculate_sharpe_atr, calculate_buy_and_hold_performance as is) ...\n",
        "\n",
        "\n",
        "def generate_features(\n",
        "    df_ohlcv: pd.DataFrame,\n",
        "    atr_period: int = 14,\n",
        "    quality_window: int = 252,\n",
        "    quality_min_periods: int = 126,\n",
        ") -> pd.DataFrame:\n",
        "    # 1. Sort and Group\n",
        "    if not df_ohlcv.index.is_monotonic_increasing:\n",
        "        df_ohlcv = df_ohlcv.sort_index()\n",
        "    grouped = df_ohlcv.groupby(level=\"Ticker\")\n",
        "\n",
        "    # 2. ATR Calculation (Existing)\n",
        "    prev_close = grouped[\"Adj Close\"].shift(1)\n",
        "    tr = pd.concat(\n",
        "        [\n",
        "            df_ohlcv[\"Adj High\"] - df_ohlcv[\"Adj Low\"],\n",
        "            abs(df_ohlcv[\"Adj High\"] - prev_close),\n",
        "            abs(df_ohlcv[\"Adj Low\"] - prev_close),\n",
        "        ],\n",
        "        axis=1,\n",
        "    ).max(axis=1, skipna=False)\n",
        "\n",
        "    atr = tr.groupby(level=\"Ticker\").transform(\n",
        "        lambda x: x.ewm(alpha=1 / atr_period, adjust=False).mean()\n",
        "    )\n",
        "    atrp = (atr / df_ohlcv[\"Adj Close\"]).replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    # 3. --- NEW: MOMENTUM / RETURN FEATURES ---\n",
        "    # We calculate percentage change for specific windows useful for Pullbacks (3D, 5D) and Trends (21D)\n",
        "    # Note: We use grouped.pct_change to respect Ticker boundaries\n",
        "    roc_1 = grouped[\"Adj Close\"].pct_change(1)\n",
        "    roc_3 = grouped[\"Adj Close\"].pct_change(3)\n",
        "    roc_5 = grouped[\"Adj Close\"].pct_change(5)\n",
        "    roc_10 = grouped[\"Adj Close\"].pct_change(10)\n",
        "    roc_21 = grouped[\"Adj Close\"].pct_change(21)\n",
        "\n",
        "    indicator_df = pd.DataFrame(\n",
        "        {\n",
        "            \"TR\": tr,\n",
        "            \"ATR\": atr,\n",
        "            \"ATRP\": atrp,\n",
        "            \"ROC_1\": roc_1,\n",
        "            \"ROC_3\": roc_3,\n",
        "            \"ROC_5\": roc_5,\n",
        "            \"ROC_10\": roc_10,\n",
        "            \"ROC_21\": roc_21,\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # 4. Quality/Liquidity Features (Existing)\n",
        "    quality_temp_df = pd.DataFrame(\n",
        "        {\n",
        "            \"IsStale\": np.where(\n",
        "                (df_ohlcv[\"Volume\"] == 0)\n",
        "                | (df_ohlcv[\"Adj High\"] == df_ohlcv[\"Adj Low\"]),\n",
        "                1,\n",
        "                0,\n",
        "            ),\n",
        "            \"DollarVolume\": df_ohlcv[\"Adj Close\"] * df_ohlcv[\"Volume\"],\n",
        "            \"HasSameVolume\": (grouped[\"Volume\"].diff() == 0).astype(int),\n",
        "        },\n",
        "        index=df_ohlcv.index,\n",
        "    )\n",
        "\n",
        "    rolling_result = (\n",
        "        quality_temp_df.groupby(level=\"Ticker\")\n",
        "        .rolling(window=quality_window, min_periods=quality_min_periods)\n",
        "        .agg({\"IsStale\": \"mean\", \"DollarVolume\": \"median\", \"HasSameVolume\": \"sum\"})\n",
        "        .rename(\n",
        "            columns={\n",
        "                \"IsStale\": \"RollingStalePct\",\n",
        "                \"DollarVolume\": \"RollMedDollarVol\",\n",
        "                \"HasSameVolume\": \"RollingSameVolCount\",\n",
        "            }\n",
        "        )\n",
        "        .reset_index(level=0, drop=True)\n",
        "    )\n",
        "\n",
        "    # 5. Merge\n",
        "    return pd.concat([indicator_df, rolling_result], axis=1)\n",
        "\n",
        "\n",
        "def calculate_gain(price_series):\n",
        "    if price_series.dropna().shape[0] < 2:\n",
        "        return np.nan\n",
        "    return (price_series.ffill().iloc[-1] / price_series.bfill().iloc[0]) - 1\n",
        "\n",
        "\n",
        "def calculate_sharpe(return_series):\n",
        "    if return_series.dropna().shape[0] < 2:\n",
        "        return np.nan\n",
        "    std = return_series.std()\n",
        "    return (return_series.mean() / std * np.sqrt(252)) if std > 0 else 0.0\n",
        "\n",
        "\n",
        "def calculate_sharpe_atr(return_series, atrp_series):\n",
        "    if return_series.dropna().shape[0] < 2 or atrp_series.dropna().empty:\n",
        "        return np.nan\n",
        "    mean_atrp = atrp_series.mean()\n",
        "    return (return_series.mean() / mean_atrp) if mean_atrp > 0 else 0.0\n",
        "\n",
        "\n",
        "def calculate_buy_and_hold_performance(\n",
        "    df_close, features_df, tickers, start_date, end_date\n",
        "):\n",
        "    if not tickers:\n",
        "        return pd.Series(dtype=float), pd.Series(dtype=float), pd.Series(dtype=float)\n",
        "    ticker_counts = Counter(tickers)\n",
        "    initial_weights = pd.Series({t: c / len(tickers) for t, c in ticker_counts.items()})\n",
        "    prices_raw = df_close[initial_weights.index.tolist()].loc[start_date:end_date]\n",
        "    if prices_raw.dropna(how=\"all\").empty:\n",
        "        return pd.Series(dtype=float), pd.Series(dtype=float), pd.Series(dtype=float)\n",
        "    prices_norm = prices_raw.div(prices_raw.bfill().iloc[0])\n",
        "    weighted_growth = prices_norm.mul(initial_weights, axis=\"columns\")\n",
        "    value_series = weighted_growth.sum(axis=1)\n",
        "    return_series = value_series.ffill().pct_change()\n",
        "    full_idx = pd.MultiIndex.from_product(\n",
        "        [initial_weights.index.tolist(), return_series.index], names=[\"Ticker\", \"Date\"]\n",
        "    )\n",
        "    feat_subset = features_df.reindex(full_idx)[\"ATRP\"].unstack(level=\"Ticker\")\n",
        "    atrp_series = (\n",
        "        weighted_growth.div(value_series, axis=\"index\").align(\n",
        "            feat_subset, join=\"inner\", axis=1\n",
        "        )[0]\n",
        "        * weighted_growth.div(value_series, axis=\"index\").align(\n",
        "            feat_subset, join=\"inner\", axis=1\n",
        "        )[1]\n",
        "    ).sum(axis=1)\n",
        "    return value_series, return_series, atrp_series\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# SECTION B: METRIC REGISTRY (UPDATED VARIABLES)\n",
        "# ==============================================================================\n",
        "\n",
        "\n",
        "# Note: We now expect 'lookback_close' instead of 'calc_close' in the dictionary\n",
        "def metric_price(d):\n",
        "    return calculate_gain(d[\"lookback_close\"])\n",
        "\n",
        "\n",
        "def metric_sharpe(d):\n",
        "    r = d[\"lookback_returns\"]  # Was daily_returns\n",
        "    return (\n",
        "        (r.mean() / r.std() * np.sqrt(252)).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "    )\n",
        "\n",
        "\n",
        "def metric_sharpe_atr(d):\n",
        "    return (\n",
        "        (d[\"lookback_returns\"].mean() / d[\"atrp\"])\n",
        "        .replace([np.inf, -np.inf], np.nan)\n",
        "        .fillna(0)\n",
        "    )\n",
        "\n",
        "\n",
        "METRIC_REGISTRY = {\n",
        "    \"Price\": metric_price,\n",
        "    \"Sharpe\": metric_sharpe,\n",
        "    \"Sharpe (ATR)\": metric_sharpe_atr,\n",
        "    # Momentum / Pullback (These use features, so they remain the same)\n",
        "    \"Momentum 1D\": lambda d: d[\"roc_1\"],\n",
        "    \"Momentum 3D\": lambda d: d[\"roc_3\"],\n",
        "    \"Momentum 5D\": lambda d: d[\"roc_5\"],\n",
        "    \"Momentum 10D\": lambda d: d[\"roc_10\"],\n",
        "    \"Momentum 1M\": lambda d: d[\"roc_21\"],\n",
        "    \"Pullback 1D\": lambda d: -d[\"roc_1\"],\n",
        "    \"Pullback 3D\": lambda d: -d[\"roc_3\"],\n",
        "    \"Pullback 5D\": lambda d: -d[\"roc_5\"],\n",
        "    \"Pullback 10D\": lambda d: -d[\"roc_10\"],\n",
        "    \"Pullback 1M\": lambda d: -d[\"roc_21\"],\n",
        "}\n",
        "\n",
        "# ==============================================================================\n",
        "# SECTION C: DATA CONTRACTS (UPDATED v2.2 - Verification Ready)\n",
        "# ==============================================================================\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class EngineInput:\n",
        "    mode: str\n",
        "    start_date: pd.Timestamp\n",
        "    lookback_period: int\n",
        "    holding_period: int\n",
        "    metric: str\n",
        "    benchmark_ticker: str\n",
        "    rank_start: int = 1\n",
        "    rank_end: int = 10\n",
        "    quality_thresholds: Dict[str, float] = field(\n",
        "        default_factory=lambda: {\n",
        "            \"min_median_dollar_volume\": 1_000_000,\n",
        "            \"max_stale_pct\": 0.05,\n",
        "            \"max_same_vol_count\": 10,\n",
        "        }\n",
        "    )\n",
        "    manual_tickers: List[str] = field(default_factory=list)\n",
        "    debug: bool = False\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class EngineOutput:\n",
        "    portfolio_series: pd.Series\n",
        "    benchmark_series: pd.Series\n",
        "    normalized_plot_data: pd.DataFrame\n",
        "    tickers: List[str]\n",
        "    initial_weights: pd.Series\n",
        "    perf_metrics: Dict[str, float]\n",
        "    results_df: pd.DataFrame\n",
        "\n",
        "    # Dates\n",
        "    start_date: pd.Timestamp\n",
        "    decision_date: pd.Timestamp\n",
        "    buy_date: pd.Timestamp\n",
        "    holding_end_date: pd.Timestamp\n",
        "\n",
        "    error_msg: Optional[str] = None\n",
        "    debug_data: Optional[Dict[str, Any]] = None\n",
        "\n",
        "\n",
        "class AlphaEngine:\n",
        "    def __init__(\n",
        "        self,\n",
        "        df_ohlcv: pd.DataFrame,\n",
        "        features_df: pd.DataFrame = None,\n",
        "        df_close_wide: pd.DataFrame = None,\n",
        "        master_ticker: str = \"SPY\",\n",
        "    ):\n",
        "        print(\"--- ‚öôÔ∏è Initializing AlphaEngine v2.2 (Transparent Verification) ---\")\n",
        "\n",
        "        # 1. Setup Features\n",
        "        if features_df is not None:\n",
        "            self.features_df = features_df\n",
        "        else:\n",
        "            print(\"üê¢ Calculating Features from scratch...\")\n",
        "            self.features_df = generate_features(df_ohlcv)\n",
        "\n",
        "        # 2. Setup Prices\n",
        "        if df_close_wide is not None:\n",
        "            self.df_close = df_close_wide\n",
        "        else:\n",
        "            print(\"üê¢ Pivoting Price Data (Slow)...\")\n",
        "            self.df_close = df_ohlcv[\"Adj Close\"].unstack(level=0)\n",
        "\n",
        "        # 3. Setup Calendar\n",
        "        if master_ticker not in self.df_close.columns:\n",
        "            master_ticker = self.df_close.columns[0]\n",
        "        self.trading_calendar = (\n",
        "            self.df_close[master_ticker].dropna().index.unique().sort_values()\n",
        "        )\n",
        "\n",
        "    def run(self, inputs: EngineInput) -> EngineOutput:\n",
        "\n",
        "        # --- Step 1: Validate Timeline ---\n",
        "        dates, error = self._validate_timeline(inputs)\n",
        "        if error:\n",
        "            return self._error_result(error)\n",
        "        (safe_start, safe_decision, safe_buy, safe_end) = dates\n",
        "\n",
        "        # --- Step 2: Select Assets ---\n",
        "        tickers_to_trade, results_table, debug_dict, error = self._select_tickers(\n",
        "            inputs, safe_start, safe_decision\n",
        "        )\n",
        "        if error:\n",
        "            return self._error_result(error)\n",
        "\n",
        "        # --- Step 3: Generate Equity Curves ---\n",
        "        p_val, p_ret, p_atrp = calculate_buy_and_hold_performance(\n",
        "            self.df_close, self.features_df, tickers_to_trade, safe_start, safe_end\n",
        "        )\n",
        "        b_val, b_ret, b_atrp = calculate_buy_and_hold_performance(\n",
        "            self.df_close,\n",
        "            self.features_df,\n",
        "            [inputs.benchmark_ticker],\n",
        "            safe_start,\n",
        "            safe_end,\n",
        "        )\n",
        "\n",
        "        # --- Step 4: Calculate Unified Metrics & CAPTURE SLICES ---\n",
        "        metrics = {}\n",
        "\n",
        "        # Portfolio Calculation\n",
        "        p_metrics, p_slices = self._calculate_period_metrics(\n",
        "            p_val, p_ret, p_atrp, safe_decision, safe_buy, prefix=\"p\"\n",
        "        )\n",
        "        metrics.update(p_metrics)\n",
        "\n",
        "        # Benchmark Calculation\n",
        "        b_metrics, b_slices = self._calculate_period_metrics(\n",
        "            b_val, b_ret, b_atrp, safe_decision, safe_buy, prefix=\"b\"\n",
        "        )\n",
        "        metrics.update(b_metrics)\n",
        "\n",
        "        # Store Verification Data\n",
        "        debug_dict[\"verification\"] = {\"portfolio\": p_slices, \"benchmark\": b_slices}\n",
        "\n",
        "        # --- Step 5: Final Packaging ---\n",
        "        plot_data = self._get_normalized_plot_data(\n",
        "            tickers_to_trade, safe_start, safe_end\n",
        "        )\n",
        "\n",
        "        if not plot_data.empty and not results_table.empty:\n",
        "            holding_period_slice = plot_data.loc[safe_buy:]\n",
        "            if len(holding_period_slice) > 0:\n",
        "                gains = (\n",
        "                    holding_period_slice.iloc[-1] / holding_period_slice.iloc[0]\n",
        "                ) - 1\n",
        "                results_table[\"Holding Gain\"] = results_table.index.map(gains)\n",
        "\n",
        "        ticker_counts = Counter(tickers_to_trade)\n",
        "        weights = pd.Series(\n",
        "            {t: c / len(tickers_to_trade) for t, c in ticker_counts.items()}\n",
        "        )\n",
        "\n",
        "        return EngineOutput(\n",
        "            portfolio_series=p_val,\n",
        "            benchmark_series=b_val,\n",
        "            normalized_plot_data=plot_data,\n",
        "            tickers=tickers_to_trade,\n",
        "            initial_weights=weights,\n",
        "            perf_metrics=metrics,\n",
        "            results_df=results_table,\n",
        "            start_date=safe_start,\n",
        "            decision_date=safe_decision,\n",
        "            buy_date=safe_buy,\n",
        "            holding_end_date=safe_end,\n",
        "            error_msg=None,\n",
        "            debug_data=debug_dict,\n",
        "        )\n",
        "\n",
        "    # ==============================================================================\n",
        "    # INTERNAL LOGIC MODULES\n",
        "    # ==============================================================================\n",
        "\n",
        "    def _validate_timeline(self, inputs: EngineInput):\n",
        "        cal = self.trading_calendar\n",
        "        if len(cal) <= inputs.lookback_period:\n",
        "            return None, f\"Dataset too small. Need > {inputs.lookback_period} days.\"\n",
        "        min_decision_date = cal[inputs.lookback_period]\n",
        "\n",
        "        if inputs.start_date < cal[0]:\n",
        "            return None, f\"‚ùå Date Out of Range. Earliest date is {cal[0].date()}.\"\n",
        "        if inputs.start_date < min_decision_date:\n",
        "            return (\n",
        "                None,\n",
        "                f\"‚ùå Not enough history. Try {min_decision_date.date()} or later.\",\n",
        "            )\n",
        "        if inputs.start_date > cal[-1]:\n",
        "            return None, f\"‚ùå Date Out of Range. Dataset ends on {cal[-1].date()}.\"\n",
        "\n",
        "        decision_idx = cal.searchsorted(inputs.start_date)\n",
        "        if decision_idx >= len(cal):\n",
        "            decision_idx = len(cal) - 1\n",
        "\n",
        "        entry_idx = decision_idx + 1\n",
        "        if entry_idx >= len(cal):\n",
        "            return (\n",
        "                None,\n",
        "                f\"‚ùå Cannot execute T+1. Decision date {cal[decision_idx].date()} is the last available day.\",\n",
        "            )\n",
        "\n",
        "        required_end_idx = entry_idx + inputs.holding_period\n",
        "        if required_end_idx >= len(cal):\n",
        "            valid_idx = len(cal) - 1 - inputs.holding_period - 1\n",
        "            valid_date = cal[valid_idx] if valid_idx >= 0 else \"N/A\"\n",
        "            return None, (\n",
        "                f\"‚ùå Not enough future data. Latest valid Decision Date: {valid_date.date()}\"\n",
        "            )\n",
        "\n",
        "        start_idx = decision_idx - inputs.lookback_period\n",
        "        return (\n",
        "            cal[start_idx],\n",
        "            cal[decision_idx],\n",
        "            cal[entry_idx],\n",
        "            cal[required_end_idx],\n",
        "        ), None\n",
        "\n",
        "    def _select_tickers(self, inputs: EngineInput, start_date, decision_date):\n",
        "        debug_dict = {}\n",
        "        if inputs.mode == \"Manual List\":\n",
        "            validation_errors = []\n",
        "            valid_tickers = []\n",
        "            for t in inputs.manual_tickers:\n",
        "                if t not in self.df_close.columns:\n",
        "                    validation_errors.append(f\"‚ùå {t}: Not found.\")\n",
        "                    continue\n",
        "                if pd.isna(self.df_close.at[start_date, t]):\n",
        "                    validation_errors.append(f\"‚ö†Ô∏è {t}: No data on start date.\")\n",
        "                    continue\n",
        "                valid_tickers.append(t)\n",
        "\n",
        "            if validation_errors:\n",
        "                return [], pd.DataFrame(), {}, \"\\n\".join(validation_errors)\n",
        "            if not valid_tickers:\n",
        "                return [], pd.DataFrame(), {}, \"No valid tickers found.\"\n",
        "            return valid_tickers, pd.DataFrame(index=valid_tickers), {}, None\n",
        "\n",
        "        else:  # Ranking\n",
        "            audit_info = {}\n",
        "            eligible_tickers = self._filter_universe(\n",
        "                decision_date, inputs.quality_thresholds, audit_info\n",
        "            )\n",
        "            debug_dict[\"audit_liquidity\"] = audit_info\n",
        "\n",
        "            if not eligible_tickers:\n",
        "                return (\n",
        "                    [],\n",
        "                    pd.DataFrame(),\n",
        "                    debug_dict,\n",
        "                    \"No tickers passed quality filters.\",\n",
        "                )\n",
        "\n",
        "            lookback_close = self.df_close.loc[\n",
        "                start_date:decision_date, eligible_tickers\n",
        "            ]\n",
        "            idx_product = pd.MultiIndex.from_product(\n",
        "                [eligible_tickers, lookback_close.index], names=[\"Ticker\", \"Date\"]\n",
        "            )\n",
        "\n",
        "            feat_slice_current = self.features_df.xs(\n",
        "                decision_date, level=\"Date\"\n",
        "            ).reindex(eligible_tickers)\n",
        "            feat_slice_period = self.features_df.loc[\n",
        "                (slice(None), lookback_close.index), :\n",
        "            ].reindex(idx_product)\n",
        "            atrp_mean = feat_slice_period[\"ATRP\"].groupby(level=\"Ticker\").mean()\n",
        "\n",
        "            ingredients = {\n",
        "                \"lookback_close\": lookback_close,\n",
        "                \"lookback_returns\": lookback_close.ffill().pct_change(),\n",
        "                \"atrp\": atrp_mean,\n",
        "                \"roc_1\": feat_slice_current[\"ROC_1\"],\n",
        "                \"roc_3\": feat_slice_current[\"ROC_3\"],\n",
        "                \"roc_5\": feat_slice_current[\"ROC_5\"],\n",
        "                \"roc_10\": feat_slice_current[\"ROC_10\"],\n",
        "                \"roc_21\": feat_slice_current[\"ROC_21\"],\n",
        "            }\n",
        "\n",
        "            if inputs.metric not in METRIC_REGISTRY:\n",
        "                return [], pd.DataFrame(), {}, f\"Strategy '{inputs.metric}' not found.\"\n",
        "            metric_vals = METRIC_REGISTRY[inputs.metric](ingredients)\n",
        "            sorted_tickers = metric_vals.sort_values(ascending=False)\n",
        "\n",
        "            start_r = max(0, inputs.rank_start - 1)\n",
        "            end_r = inputs.rank_end\n",
        "            selected_tickers = sorted_tickers.iloc[start_r:end_r].index.tolist()\n",
        "\n",
        "            if not selected_tickers:\n",
        "                return (\n",
        "                    [],\n",
        "                    pd.DataFrame(),\n",
        "                    debug_dict,\n",
        "                    \"No tickers generated from ranking.\",\n",
        "                )\n",
        "\n",
        "            results_table = pd.DataFrame(\n",
        "                {\n",
        "                    \"Rank\": range(\n",
        "                        inputs.rank_start, inputs.rank_start + len(selected_tickers)\n",
        "                    ),\n",
        "                    \"Ticker\": selected_tickers,\n",
        "                    \"Strategy Value\": sorted_tickers.loc[selected_tickers].values,\n",
        "                }\n",
        "            ).set_index(\"Ticker\")\n",
        "\n",
        "            return selected_tickers, results_table, debug_dict, None\n",
        "\n",
        "    def _filter_universe(self, date_ts, thresholds, audit_container=None):\n",
        "        avail_dates = (\n",
        "            self.features_df.index.get_level_values(\"Date\").unique().sort_values()\n",
        "        )\n",
        "        valid_dates = avail_dates[avail_dates <= date_ts]\n",
        "        if valid_dates.empty:\n",
        "            return []\n",
        "        target_date = valid_dates[-1]\n",
        "        day_features = self.features_df.xs(target_date, level=\"Date\")\n",
        "\n",
        "        vol_cutoff = thresholds.get(\"min_median_dollar_volume\", 0)\n",
        "        percentile_used = \"N/A\"\n",
        "        if \"min_liquidity_percentile\" in thresholds:\n",
        "            percentile_used = thresholds[\"min_liquidity_percentile\"]\n",
        "            dynamic_val = day_features[\"RollMedDollarVol\"].quantile(percentile_used)\n",
        "            vol_cutoff = max(vol_cutoff, dynamic_val)\n",
        "\n",
        "        mask = (\n",
        "            (day_features[\"RollMedDollarVol\"] >= vol_cutoff)\n",
        "            & (day_features[\"RollingStalePct\"] <= thresholds[\"max_stale_pct\"])\n",
        "            & (day_features[\"RollingSameVolCount\"] <= thresholds[\"max_same_vol_count\"])\n",
        "        )\n",
        "\n",
        "        if audit_container is not None:\n",
        "            audit_container[\"date\"] = target_date\n",
        "            audit_container[\"total_tickers_available\"] = len(day_features)\n",
        "            audit_container[\"percentile_setting\"] = percentile_used\n",
        "            audit_container[\"final_cutoff_usd\"] = vol_cutoff\n",
        "            audit_container[\"tickers_passed\"] = mask.sum()\n",
        "            snapshot = day_features.copy()\n",
        "            snapshot[\"Calculated_Cutoff\"] = vol_cutoff\n",
        "            snapshot[\"Passed_Vol_Check\"] = snapshot[\"RollMedDollarVol\"] >= vol_cutoff\n",
        "            snapshot[\"Passed_Final\"] = mask\n",
        "            snapshot = snapshot.sort_values(\"RollMedDollarVol\", ascending=False)\n",
        "            audit_container[\"universe_snapshot\"] = snapshot\n",
        "\n",
        "        return day_features[mask].index.tolist()\n",
        "\n",
        "    def _calculate_period_metrics(\n",
        "        self, val_series, ret_series, atrp_series, decision_date, buy_date, prefix\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Returns (metrics_dict, verification_slices_dict)\n",
        "        \"\"\"\n",
        "        metrics = {}\n",
        "        slices = {}  # Store the exact Series used for math\n",
        "\n",
        "        if val_series.empty:\n",
        "            return metrics, slices\n",
        "\n",
        "        def get_gain(s):\n",
        "            return (s.iloc[-1] / s.iloc[0]) - 1 if len(s) > 0 else 0\n",
        "\n",
        "        # --- A. Define Slices ---\n",
        "\n",
        "        # 1. Full\n",
        "        full_val = val_series\n",
        "        full_ret = ret_series\n",
        "        full_atrp = atrp_series\n",
        "\n",
        "        # 2. Lookback (Start -> T0)\n",
        "        lookback_val = val_series.loc[:decision_date]\n",
        "        lookback_ret = ret_series.loc[:decision_date]\n",
        "        lookback_atrp = atrp_series.loc[lookback_ret.index]\n",
        "\n",
        "        # 3. Holding (T1 -> End)\n",
        "        holding_val = val_series.loc[buy_date:]\n",
        "        if not holding_val.empty:\n",
        "            holding_ret = holding_val.pct_change()\n",
        "            holding_atrp = atrp_series.reindex(holding_ret.index)\n",
        "        else:\n",
        "            holding_ret = pd.Series(dtype=float)\n",
        "            holding_atrp = pd.Series(dtype=float)\n",
        "\n",
        "        # --- B. Calculate Metrics ---\n",
        "        metrics[f\"full_{prefix}_gain\"] = get_gain(full_val)\n",
        "        metrics[f\"lookback_{prefix}_gain\"] = get_gain(lookback_val)\n",
        "        metrics[f\"holding_{prefix}_gain\"] = get_gain(holding_val)\n",
        "\n",
        "        metrics[f\"full_{prefix}_sharpe\"] = calculate_sharpe(full_ret)\n",
        "        metrics[f\"lookback_{prefix}_sharpe\"] = calculate_sharpe(lookback_ret)\n",
        "        metrics[f\"holding_{prefix}_sharpe\"] = calculate_sharpe(holding_ret)\n",
        "\n",
        "        metrics[f\"full_{prefix}_sharpe_atr\"] = calculate_sharpe_atr(full_ret, full_atrp)\n",
        "        metrics[f\"lookback_{prefix}_sharpe_atr\"] = calculate_sharpe_atr(\n",
        "            lookback_ret, lookback_atrp\n",
        "        )\n",
        "        metrics[f\"holding_{prefix}_sharpe_atr\"] = calculate_sharpe_atr(\n",
        "            holding_ret, holding_atrp\n",
        "        )\n",
        "\n",
        "        # --- C. Populate Slices for Verification ---\n",
        "        slices[\"lookback_val\"] = lookback_val\n",
        "        slices[\"lookback_ret\"] = lookback_ret\n",
        "        slices[\"holding_val\"] = holding_val\n",
        "        slices[\"holding_ret\"] = (\n",
        "            holding_ret  # This is the exact series passed to sharpe()\n",
        "        )\n",
        "        slices[\"holding_atrp\"] = holding_atrp\n",
        "\n",
        "        return metrics, slices\n",
        "\n",
        "    def _get_normalized_plot_data(self, tickers, start_date, end_date):\n",
        "        if not tickers:\n",
        "            return pd.DataFrame()\n",
        "        data = self.df_close[list(set(tickers))].loc[start_date:end_date]\n",
        "        if data.empty:\n",
        "            return pd.DataFrame()\n",
        "        return data / data.bfill().iloc[0]\n",
        "\n",
        "    def _error_result(self, msg):\n",
        "        return EngineOutput(\n",
        "            portfolio_series=pd.Series(dtype=float),\n",
        "            benchmark_series=pd.Series(dtype=float),\n",
        "            normalized_plot_data=pd.DataFrame(),\n",
        "            tickers=[],\n",
        "            initial_weights=pd.Series(dtype=float),\n",
        "            perf_metrics={},\n",
        "            results_df=pd.DataFrame(),\n",
        "            start_date=pd.Timestamp.min,\n",
        "            decision_date=pd.Timestamp.min,\n",
        "            buy_date=pd.Timestamp.min,\n",
        "            holding_end_date=pd.Timestamp.min,\n",
        "            error_msg=msg,\n",
        "        )\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# SECTION E: THE UI (Visualization) - UPDATED v2.4 (Complete Timeline)\n",
        "# ==============================================================================\n",
        "\n",
        "\n",
        "def plot_walk_forward_analyzer(\n",
        "    df_ohlcv,\n",
        "    precomputed_features=None,\n",
        "    precomputed_close=None,\n",
        "    default_start_date=\"2020-01-01\",\n",
        "    default_lookback=126,\n",
        "    default_holding=63,\n",
        "    default_strategy=\"Sharpe (ATR)\",\n",
        "    default_rank_start=1,\n",
        "    default_rank_end=10,\n",
        "    default_benchmark_ticker=\"SPY\",\n",
        "    master_calendar_ticker=\"XOM\",\n",
        "    quality_thresholds=None,\n",
        "    debug=False,\n",
        "):\n",
        "\n",
        "    engine = AlphaEngine(\n",
        "        df_ohlcv,\n",
        "        features_df=precomputed_features,\n",
        "        df_close_wide=precomputed_close,\n",
        "        master_ticker=master_calendar_ticker,\n",
        "    )\n",
        "\n",
        "    # Initialize containers\n",
        "    results_container = [None]\n",
        "    debug_container = [{}]\n",
        "\n",
        "    if quality_thresholds is None:\n",
        "        quality_thresholds = {\n",
        "            \"min_median_dollar_volume\": 100_000,\n",
        "            \"min_liquidity_percentile\": 0.50,\n",
        "            \"max_stale_pct\": 0.05,\n",
        "            \"max_same_vol_count\": 10,\n",
        "        }\n",
        "\n",
        "    # --- Widgets ---\n",
        "    mode_selector = widgets.RadioButtons(\n",
        "        options=[\"Ranking\", \"Manual List\"],\n",
        "        value=\"Ranking\",\n",
        "        description=\"Mode:\",\n",
        "        layout={\"width\": \"max-content\"},\n",
        "        style={\"description_width\": \"initial\"},\n",
        "    )\n",
        "    lookback_input = widgets.IntText(\n",
        "        value=default_lookback,\n",
        "        description=\"Lookback (Days):\",\n",
        "        layout={\"width\": \"200px\"},\n",
        "        style={\"description_width\": \"initial\"},\n",
        "    )\n",
        "    decision_date_picker = widgets.DatePicker(\n",
        "        description=\"Decision Date:\",\n",
        "        value=pd.to_datetime(default_start_date),\n",
        "        layout={\"width\": \"auto\"},\n",
        "        style={\"description_width\": \"initial\"},\n",
        "    )\n",
        "    holding_input = widgets.IntText(\n",
        "        value=default_holding,\n",
        "        description=\"Holding (Days):\",\n",
        "        layout={\"width\": \"200px\"},\n",
        "        style={\"description_width\": \"initial\"},\n",
        "    )\n",
        "    strategy_dropdown = widgets.Dropdown(\n",
        "        options=list(METRIC_REGISTRY.keys()),\n",
        "        value=default_strategy,\n",
        "        description=\"Strategy:\",\n",
        "        layout={\"width\": \"220px\"},\n",
        "        style={\"description_width\": \"initial\"},\n",
        "    )\n",
        "    benchmark_input = widgets.Text(\n",
        "        value=default_benchmark_ticker,\n",
        "        description=\"Benchmark:\",\n",
        "        placeholder=\"Enter Ticker\",\n",
        "        layout={\"width\": \"180px\"},\n",
        "        style={\"description_width\": \"initial\"},\n",
        "    )\n",
        "    rank_start_input = widgets.IntText(\n",
        "        value=default_rank_start,\n",
        "        description=\"Rank Start:\",\n",
        "        layout={\"width\": \"150px\"},\n",
        "        style={\"description_width\": \"initial\"},\n",
        "    )\n",
        "    rank_end_input = widgets.IntText(\n",
        "        value=default_rank_end,\n",
        "        description=\"Rank End:\",\n",
        "        layout={\"width\": \"150px\"},\n",
        "        style={\"description_width\": \"initial\"},\n",
        "    )\n",
        "    manual_tickers_input = widgets.Textarea(\n",
        "        value=\"\",\n",
        "        placeholder=\"Enter tickers...\",\n",
        "        description=\"Manual Tickers:\",\n",
        "        layout={\"width\": \"400px\", \"height\": \"80px\"},\n",
        "        style={\"description_width\": \"initial\"},\n",
        "    )\n",
        "    update_button = widgets.Button(description=\"Run Simulation\", button_style=\"primary\")\n",
        "    ticker_list_output = widgets.Output()\n",
        "\n",
        "    # --- Layouts ---\n",
        "    timeline_box = widgets.HBox(\n",
        "        [lookback_input, decision_date_picker, holding_input],\n",
        "        layout=widgets.Layout(\n",
        "            justify_content=\"space-between\",\n",
        "            border=\"1px solid #ddd\",\n",
        "            padding=\"10px\",\n",
        "            margin=\"5px\",\n",
        "        ),\n",
        "    )\n",
        "    strategy_box = widgets.HBox([strategy_dropdown, benchmark_input])\n",
        "    ranking_box = widgets.HBox([rank_start_input, rank_end_input])\n",
        "\n",
        "    def on_mode_change(c):\n",
        "        ranking_box.layout.display = \"flex\" if c[\"new\"] == \"Ranking\" else \"none\"\n",
        "        manual_tickers_input.layout.display = (\n",
        "            \"none\" if c[\"new\"] == \"Ranking\" else \"flex\"\n",
        "        )\n",
        "        strategy_dropdown.disabled = c[\"new\"] == \"Manual List\"\n",
        "\n",
        "    mode_selector.observe(on_mode_change, names=\"value\")\n",
        "    on_mode_change({\"new\": mode_selector.value})\n",
        "\n",
        "    ui = widgets.VBox(\n",
        "        [\n",
        "            widgets.HTML(\n",
        "                \"<b>1. Timeline Configuration:</b> (Past <--- Decision ---> Future)\"\n",
        "            ),\n",
        "            timeline_box,\n",
        "            widgets.HTML(\"<b>2. Strategy Settings:</b>\"),\n",
        "            widgets.HBox([mode_selector, strategy_box]),\n",
        "            ranking_box,\n",
        "            manual_tickers_input,\n",
        "            widgets.HTML(\"<hr>\"),\n",
        "            update_button,\n",
        "            ticker_list_output,\n",
        "        ],\n",
        "        layout=widgets.Layout(margin=\"10px 0 20px 0\"),\n",
        "    )\n",
        "\n",
        "    fig = go.FigureWidget()\n",
        "    fig.update_layout(\n",
        "        title=\"Event-Driven Walk-Forward Analysis\",\n",
        "        height=600,\n",
        "        template=\"plotly_white\",\n",
        "        hovermode=\"x unified\",\n",
        "    )\n",
        "    for i in range(50):\n",
        "        fig.add_trace(go.Scatter(visible=False, line=dict(width=2)))\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            name=\"Benchmark\",\n",
        "            visible=True,\n",
        "            line=dict(color=\"black\", width=3, dash=\"dash\"),\n",
        "        )\n",
        "    )\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            name=\"Group Portfolio\", visible=True, line=dict(color=\"green\", width=3)\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # --- Update Logic ---\n",
        "    def update_plot(b):\n",
        "        ticker_list_output.clear_output()\n",
        "        manual_list = [\n",
        "            t.strip().upper()\n",
        "            for t in manual_tickers_input.value.split(\",\")\n",
        "            if t.strip()\n",
        "        ]\n",
        "        decision_date_raw = pd.to_datetime(decision_date_picker.value)\n",
        "\n",
        "        inputs = EngineInput(\n",
        "            mode=mode_selector.value,\n",
        "            start_date=decision_date_raw,\n",
        "            lookback_period=lookback_input.value,\n",
        "            holding_period=holding_input.value,\n",
        "            metric=strategy_dropdown.value,\n",
        "            benchmark_ticker=benchmark_input.value.strip().upper(),\n",
        "            rank_start=rank_start_input.value,\n",
        "            rank_end=rank_end_input.value,\n",
        "            quality_thresholds=quality_thresholds,\n",
        "            manual_tickers=manual_list,\n",
        "            debug=debug,\n",
        "        )\n",
        "\n",
        "        # --- CAPTURE INPUTS FOR AUDIT ---\n",
        "        debug_container[0][\"inputs\"] = inputs\n",
        "\n",
        "        with ticker_list_output:\n",
        "            res = engine.run(inputs)\n",
        "            results_container[0] = res\n",
        "\n",
        "            # --- MERGE ENGINE DEBUG DATA ---\n",
        "            if res.debug_data:\n",
        "                debug_container[0].update(res.debug_data)\n",
        "\n",
        "            if res.error_msg:\n",
        "                print(f\"‚ö†Ô∏è Simulation Stopped: {res.error_msg}\")\n",
        "                return\n",
        "\n",
        "            # Plotting\n",
        "            with fig.batch_update():\n",
        "                cols = res.normalized_plot_data.columns.tolist()\n",
        "                for i in range(50):\n",
        "                    if i < len(cols):\n",
        "                        fig.data[i].update(\n",
        "                            x=res.normalized_plot_data.index,\n",
        "                            y=res.normalized_plot_data[cols[i]],\n",
        "                            name=cols[i],\n",
        "                            visible=True,\n",
        "                        )\n",
        "                    else:\n",
        "                        fig.data[i].visible = False\n",
        "\n",
        "                fig.data[50].update(\n",
        "                    x=res.benchmark_series.index,\n",
        "                    y=res.benchmark_series.values,\n",
        "                    name=f\"Benchmark ({inputs.benchmark_ticker})\",\n",
        "                    visible=not res.benchmark_series.empty,\n",
        "                )\n",
        "                fig.data[51].update(\n",
        "                    x=res.portfolio_series.index,\n",
        "                    y=res.portfolio_series.values,\n",
        "                    visible=True,\n",
        "                )\n",
        "\n",
        "                # Visual Lines\n",
        "                fig.layout.shapes = [\n",
        "                    dict(\n",
        "                        type=\"line\",\n",
        "                        x0=res.decision_date,\n",
        "                        y0=0,\n",
        "                        x1=res.decision_date,\n",
        "                        y1=1,\n",
        "                        xref=\"x\",\n",
        "                        yref=\"paper\",\n",
        "                        line=dict(color=\"red\", width=2, dash=\"dash\"),\n",
        "                    ),\n",
        "                    dict(\n",
        "                        type=\"line\",\n",
        "                        x0=res.buy_date,\n",
        "                        y0=0,\n",
        "                        x1=res.buy_date,\n",
        "                        y1=1,\n",
        "                        xref=\"x\",\n",
        "                        yref=\"paper\",\n",
        "                        line=dict(color=\"blue\", width=2, dash=\"dot\"),\n",
        "                    ),\n",
        "                ]\n",
        "\n",
        "                fig.layout.annotations = [\n",
        "                    dict(\n",
        "                        x=res.decision_date,\n",
        "                        y=0.05,\n",
        "                        xref=\"x\",\n",
        "                        yref=\"paper\",\n",
        "                        text=\"DECISION\",\n",
        "                        showarrow=False,\n",
        "                        bgcolor=\"red\",\n",
        "                        font=dict(color=\"white\"),\n",
        "                    ),\n",
        "                    dict(\n",
        "                        x=res.buy_date,\n",
        "                        y=1.0,\n",
        "                        xref=\"x\",\n",
        "                        yref=\"paper\",\n",
        "                        text=\"ENTRY (T+1)\",\n",
        "                        showarrow=False,\n",
        "                        bgcolor=\"blue\",\n",
        "                        font=dict(color=\"white\"),\n",
        "                    ),\n",
        "                ]\n",
        "\n",
        "            start_date = res.start_date.date()\n",
        "            act_date = res.decision_date.date()\n",
        "            entry_date = res.buy_date.date()\n",
        "\n",
        "            # Liquidity Audit Print\n",
        "            if (\n",
        "                inputs.mode == \"Ranking\"\n",
        "                and res.debug_data\n",
        "                and \"audit_liquidity\" in res.debug_data\n",
        "            ):\n",
        "                audit = res.debug_data[\"audit_liquidity\"]\n",
        "                if audit:\n",
        "                    pct_str = f\"{audit.get('percentile_setting', 0)*100:.0f}%\"\n",
        "                    cut_val = audit.get(\"final_cutoff_usd\", 0)\n",
        "                    print(\"-\" * 60)\n",
        "                    print(f\"üîç LIQUIDITY CHECK (On Decision Date: {act_date})\")\n",
        "                    print(\n",
        "                        f\"   Universe Size: {audit.get('total_tickers_available')} tickers\"\n",
        "                    )\n",
        "                    print(f\"   Filtering: Top {pct_str} of Market\")\n",
        "                    print(f\"   Calculated Cutoff: ${cut_val:,.0f} / day\")\n",
        "                    print(f\"   Tickers Remaining: {audit.get('tickers_passed')}\")\n",
        "                    print(\"-\" * 60)\n",
        "\n",
        "            # --- UPDATED TIMELINE PRINT ---\n",
        "            print(\n",
        "                f\"Timeline: Start [ {start_date} ] --> Decision [ {act_date} ] --> Cash (1d) --> Entry [ {entry_date} ] --> End [ {res.holding_end_date.date()} ]\"\n",
        "            )\n",
        "\n",
        "            if inputs.mode == \"Ranking\":\n",
        "                print(f\"Ranked Tickers ({len(res.tickers)}):\")\n",
        "                for i in range(0, len(res.tickers), 10):\n",
        "                    print(\", \".join(res.tickers[i : i + 10]))\n",
        "            else:\n",
        "                print(\"Manual Portfolio Tickers:\")\n",
        "                for i in range(0, len(res.tickers), 10):\n",
        "                    print(\", \".join(res.tickers[i : i + 10]))\n",
        "\n",
        "            m = res.perf_metrics\n",
        "\n",
        "            rows = [\n",
        "                # Gain\n",
        "                {\n",
        "                    \"Metric\": \"Group Portfolio Gain\",\n",
        "                    \"Full\": m.get(\"full_p_gain\"),\n",
        "                    \"Lookback\": m.get(\"lookback_p_gain\"),\n",
        "                    \"Holding\": m.get(\"holding_p_gain\"),\n",
        "                },\n",
        "                {\n",
        "                    \"Metric\": f\"Benchmark ({inputs.benchmark_ticker}) Gain\",\n",
        "                    \"Full\": m.get(\"full_b_gain\"),\n",
        "                    \"Lookback\": m.get(\"lookback_b_gain\"),\n",
        "                    \"Holding\": m.get(\"holding_b_gain\"),\n",
        "                },\n",
        "                {\n",
        "                    \"Metric\": \"== Gain Delta\",\n",
        "                    \"Full\": m.get(\"full_p_gain\", 0) - m.get(\"full_b_gain\", 0),\n",
        "                    \"Lookback\": m.get(\"lookback_p_gain\", 0)\n",
        "                    - m.get(\"lookback_b_gain\", 0),\n",
        "                    \"Holding\": m.get(\"holding_p_gain\", 0) - m.get(\"holding_b_gain\", 0),\n",
        "                },\n",
        "                # Sharpe\n",
        "                {\n",
        "                    \"Metric\": \"Group Sharpe\",\n",
        "                    \"Full\": m.get(\"full_p_sharpe\"),\n",
        "                    \"Lookback\": m.get(\"lookback_p_sharpe\"),\n",
        "                    \"Holding\": m.get(\"holding_p_sharpe\"),\n",
        "                },\n",
        "                {\n",
        "                    \"Metric\": f\"Benchmark Sharpe\",\n",
        "                    \"Full\": m.get(\"full_b_sharpe\"),\n",
        "                    \"Lookback\": m.get(\"lookback_b_sharpe\"),\n",
        "                    \"Holding\": m.get(\"holding_b_sharpe\"),\n",
        "                },\n",
        "                {\n",
        "                    \"Metric\": \"== Sharpe Delta\",\n",
        "                    \"Full\": m.get(\"full_p_sharpe\", 0) - m.get(\"full_b_sharpe\", 0),\n",
        "                    \"Lookback\": m.get(\"lookback_p_sharpe\", 0)\n",
        "                    - m.get(\"lookback_b_sharpe\", 0),\n",
        "                    \"Holding\": m.get(\"holding_p_sharpe\", 0)\n",
        "                    - m.get(\"holding_b_sharpe\", 0),\n",
        "                },\n",
        "                # Sharpe ATR\n",
        "                {\n",
        "                    \"Metric\": \"Group Sharpe (ATR)\",\n",
        "                    \"Full\": m.get(\"full_p_sharpe_atr\"),\n",
        "                    \"Lookback\": m.get(\"lookback_p_sharpe_atr\"),\n",
        "                    \"Holding\": m.get(\"holding_p_sharpe_atr\"),\n",
        "                },\n",
        "                {\n",
        "                    \"Metric\": f\"Benchmark Sharpe (ATR)\",\n",
        "                    \"Full\": m.get(\"full_b_sharpe_atr\"),\n",
        "                    \"Lookback\": m.get(\"lookback_b_sharpe_atr\"),\n",
        "                    \"Holding\": m.get(\"holding_b_sharpe_atr\"),\n",
        "                },\n",
        "                {\n",
        "                    \"Metric\": \"== Sharpe (ATR) Delta\",\n",
        "                    \"Full\": m.get(\"full_p_sharpe_atr\", 0)\n",
        "                    - m.get(\"full_b_sharpe_atr\", 0),\n",
        "                    \"Lookback\": m.get(\"lookback_p_sharpe_atr\", 0)\n",
        "                    - m.get(\"lookback_b_sharpe_atr\", 0),\n",
        "                    \"Holding\": m.get(\"holding_p_sharpe_atr\", 0)\n",
        "                    - m.get(\"holding_b_sharpe_atr\", 0),\n",
        "                },\n",
        "            ]\n",
        "\n",
        "            display(\n",
        "                pd.DataFrame(rows)\n",
        "                .set_index(\"Metric\")\n",
        "                .style.format(\"{:+.4f}\", na_rep=\"N/A\")\n",
        "            )\n",
        "\n",
        "    update_button.on_click(update_plot)\n",
        "    update_plot(None)\n",
        "    display(ui, fig)\n",
        "    return results_container, debug_container\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "Vi_BpYLx3NAH",
        "outputId": "bcfe76bb-e7bc-42e0-a37e-4fe9de02c461"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using path: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet\n",
            "\n",
            "==== Drop df_ohlcv data older than SPY (i.e. older than 1993-01-29 ====\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "MultiIndex: 8172596 entries, ('A', Timestamp('1999-11-18 00:00:00')) to ('ZWS', Timestamp('2025-12-19 00:00:00'))\n",
            "Data columns (total 5 columns):\n",
            " #   Column     Dtype  \n",
            "---  ------     -----  \n",
            " 0   Adj Open   float64\n",
            " 1   Adj High   float64\n",
            " 2   Adj Low    float64\n",
            " 3   Adj Close  float64\n",
            " 4   Volume     int64  \n",
            "dtypes: float64(4), int64(1)\n",
            "memory usage: 343.6+ MB\n",
            "df_ohlcv.info():\n",
            "None\n",
            "\n",
            "df_ohlcv:\n",
            "                   Adj Open  Adj High  Adj Low  Adj Close    Volume\n",
            "Ticker Date                                                        \n",
            "A      1999-11-18   27.2452   29.9398  23.9518    26.3470  74716411\n",
            "       1999-11-19   25.7108   25.7482  23.8396    24.1764  18198349\n",
            "       1999-11-22   24.7378   26.3470  23.9893    26.3470   7857766\n",
            "       1999-11-23   25.4488   26.1225  23.9518    23.9518   7138324\n",
            "       1999-11-24   24.0267   25.1120  23.9518    24.5881   5785609\n",
            "...                     ...       ...      ...        ...       ...\n",
            "ZWS    2025-12-15   47.4700   47.5700  47.0100    47.4200   1065100\n",
            "       2025-12-16   47.6800   47.6800  46.8700    47.1600    862500\n",
            "       2025-12-17   47.0100   47.6800  46.3500    46.6400   1070400\n",
            "       2025-12-18   47.1900   47.7100  46.9800    47.3600   1119300\n",
            "       2025-12-19   47.0500   47.6600  47.0500    47.5000   2019500\n",
            "\n",
            "[8172596 rows x 5 columns]\n",
            "\n",
            "‚úÇÔ∏è Splitting Data at: 2019-05-21\n",
            "----------------------------------------\n",
            "üìö Training Set: 5,722,014 rows\n",
            "   Range: 1993-01-29 to 2019-05-21\n",
            "----------------------------------------\n",
            "üìù Testing Set:  2,450,582 rows\n",
            "   Range: 2019-05-22 to 2025-12-19\n",
            "----------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Adj Open</th>\n",
              "      <th>Adj High</th>\n",
              "      <th>Adj Low</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ticker</th>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">A</th>\n",
              "      <th>1999-11-18</th>\n",
              "      <td>27.2452</td>\n",
              "      <td>29.9398</td>\n",
              "      <td>23.9518</td>\n",
              "      <td>26.3470</td>\n",
              "      <td>74716411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999-11-19</th>\n",
              "      <td>25.7108</td>\n",
              "      <td>25.7482</td>\n",
              "      <td>23.8396</td>\n",
              "      <td>24.1764</td>\n",
              "      <td>18198349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999-11-22</th>\n",
              "      <td>24.7378</td>\n",
              "      <td>26.3470</td>\n",
              "      <td>23.9893</td>\n",
              "      <td>26.3470</td>\n",
              "      <td>7857766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999-11-23</th>\n",
              "      <td>25.4488</td>\n",
              "      <td>26.1225</td>\n",
              "      <td>23.9518</td>\n",
              "      <td>23.9518</td>\n",
              "      <td>7138324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999-11-24</th>\n",
              "      <td>24.0267</td>\n",
              "      <td>25.1120</td>\n",
              "      <td>23.9518</td>\n",
              "      <td>24.5881</td>\n",
              "      <td>5785609</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Adj Open  Adj High  Adj Low  Adj Close    Volume\n",
              "Ticker Date                                                        \n",
              "A      1999-11-18   27.2452   29.9398  23.9518    26.3470  74716411\n",
              "       1999-11-19   25.7108   25.7482  23.8396    24.1764  18198349\n",
              "       1999-11-22   24.7378   26.3470  23.9893    26.3470   7857766\n",
              "       1999-11-23   25.4488   26.1225  23.9518    23.9518   7138324\n",
              "       1999-11-24   24.0267   25.1120  23.9518    24.5881   5785609"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "# Load Data\n",
        "path_colab = Path(\"/content/df_OHLCV_stocks_etfs.parquet\")\n",
        "path_local = Path(\n",
        "    r\"c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet\"\n",
        ")\n",
        "\n",
        "# Inline conditional (ternary) check\n",
        "data_path = path_colab if path_colab.exists() else path_local\n",
        "print(f\"Using path: {data_path}\")\n",
        "\n",
        "df_ohlcv = pd.read_parquet(data_path, engine='pyarrow')\n",
        "\n",
        "# Drop data older than SPY\n",
        "cutoff_date = '1993-01-29'  # ticker SPY first trading date\n",
        "idx = pd.IndexSlice\n",
        "\n",
        "# .loc[Rows(Level0, Level1), Columns]\n",
        "# We use ':' for all Symbols, and 'cutoff_date:' for all dates from cutoff onwards\n",
        "print(f'\\n==== Drop df_ohlcv data older than SPY (i.e. older than {cutoff_date} ====\\n')\n",
        "df_ohlcv = df_ohlcv.sort_index().loc[idx[:, cutoff_date:], :]\n",
        "print(f\"df_ohlcv.info():\\n{df_ohlcv.info()}\\n\")\n",
        "print(f'df_ohlcv:\\n{df_ohlcv}\\n')\n",
        "\n",
        "# 2. Ensure data is sorted (Crucial for Time Series splitting)\n",
        "# We sort by Ticker first, then Date to ensure the index is monotonic\n",
        "df_ohlcv = df_ohlcv.sort_index()\n",
        "\n",
        "# 3. Calculate the Split Date (Chronological Split)\n",
        "# We get all unique dates, sort them, and find the date at the 80% mark.\n",
        "all_dates = df_ohlcv.index.get_level_values(1).unique().sort_values()\n",
        "cutoff_index = int(len(all_dates) * 0.80)\n",
        "split_date = all_dates[cutoff_index]\n",
        "\n",
        "print(f\"‚úÇÔ∏è Splitting Data at: {split_date.date()}\")\n",
        "\n",
        "# 4. Create Train and Test Dataframes\n",
        "# Train = Everything BEFORE or ON the split date\n",
        "# Test  = Everything AFTER the split date\n",
        "mask_train = df_ohlcv.index.get_level_values(1) <= split_date\n",
        "df_train = df_ohlcv[mask_train].copy()\n",
        "df_test = df_ohlcv[~mask_train].copy()\n",
        "\n",
        "# 5. Verification Output\n",
        "print(\"-\" * 40)\n",
        "print(f\"üìö Training Set: {len(df_train):,} rows\")\n",
        "print(f\"   Range: {df_train.index.get_level_values(1).min().date()} to {df_train.index.get_level_values(1).max().date()}\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"üìù Testing Set:  {len(df_test):,} rows\")\n",
        "print(f\"   Range: {df_test.index.get_level_values(1).min().date()} to {df_test.index.get_level_values(1).max().date()}\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Display head to confirm structure\n",
        "display(df_train.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "df_ohldv.head(SPY):\n",
            "            Adj Open  Adj High  Adj Low  Adj Close   Volume\n",
            "Date                                                       \n",
            "1993-01-29   24.2586   24.2586  24.1380    24.2414  1818298\n",
            "1993-02-01   24.2586   24.4138  24.2586    24.4138   870905\n",
            "\n",
            "df_ohldv.tail(SPY):\n",
            "            Adj Open  Adj High  Adj Low  Adj Close     Volume\n",
            "Date                                                         \n",
            "2025-12-18   675.604   678.734  672.912    674.477  108971155\n",
            "2025-12-19   676.590   681.090  676.470    680.590  103506100\n",
            "\n",
            "df_train.head(SPY):\n",
            "            Adj Open  Adj High  Adj Low  Adj Close   Volume\n",
            "Date                                                       \n",
            "1993-01-29   24.2586   24.2586  24.1380    24.2414  1818298\n",
            "1993-02-01   24.2586   24.4138  24.2586    24.4138   870905\n",
            "\n",
            "df_train.tail(SPY):\n",
            "            Adj Open  Adj High  Adj Low  Adj Close    Volume\n",
            "Date                                                        \n",
            "2019-05-20   256.590   258.306  255.741    256.491  69609143\n",
            "2019-05-21   258.189   259.182  257.936    258.803  51862450\n",
            "\n",
            "df_test.head(SPY):\n",
            "            Adj Open  Adj High  Adj Low  Adj Close     Volume\n",
            "Date                                                         \n",
            "2019-05-22   257.846   258.966  257.529    258.008   54779994\n",
            "2019-05-23   255.777   255.822  253.438    254.856  109304014\n",
            "\n",
            "df_test.tail(SPY):\n",
            "            Adj Open  Adj High  Adj Low  Adj Close     Volume\n",
            "Date                                                         \n",
            "2025-12-18   675.604   678.734  672.912    674.477  108971155\n",
            "2025-12-19   676.590   681.090  676.470    680.590  103506100\n",
            "\n"
          ]
        }
      ],
      "source": [
        "_ticker = 'SPY'\n",
        "print(f'df_ohldv.head({_ticker}):\\n{df_ohlcv.loc[_ticker].head(2)}\\n')\n",
        "print(f\"df_ohldv.tail({_ticker}):\\n{df_ohlcv.loc[_ticker].tail(2)}\\n\")\n",
        "\n",
        "print(f\"df_train.head({_ticker}):\\n{df_train.loc[_ticker].head(2)}\\n\")\n",
        "print(f\"df_train.tail({_ticker}):\\n{df_train.loc[_ticker].tail(2)}\\n\")\n",
        "\n",
        "print(f\"df_test.head({_ticker}):\\n{df_test.loc[_ticker].head(2)}\\n\")\n",
        "print(f\"df_test.tail({_ticker}):\\n{df_test.loc[_ticker].tail(2)}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7A1-beaAh_d"
      },
      "source": [
        "**Generate Features on `df_train`:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K67wWgcb_pGJ",
        "outputId": "c07fba30-416a-4944-be47-d75baf109946"
      },
      "outputs": [],
      "source": [
        "print(\"Feature Generation (Training Data)...\")\n",
        "train_features = generate_features(df_train)\n",
        "train_close = df_train['Adj Close'].unstack(level=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LfG1ynWQxxR"
      },
      "source": [
        "### 3. Visualizing the Learning Process\n",
        "Yes, we absolutely should plot this. We want to see the \"Average Reward\" go up over time (the bot getting smarter) and the \"Loss\" go down."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UAK-W-TBrNJ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def plot_training_history(history_avg_scores, history_best_scores):\n",
        "    sns.set_style(\"whitegrid\")\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    epochs = range(1, len(history_avg_scores) + 1)\n",
        "\n",
        "    # Plot Average Performance (The \"Baseline\")\n",
        "    plt.plot(epochs, history_avg_scores, label='Batch Average Sharpe', color='blue', linewidth=2, marker='o')\n",
        "\n",
        "    # Plot Best Performance (The \"Genius\" moments)\n",
        "    plt.plot(epochs, history_best_scores, label='Max Batch Sharpe', color='green', linestyle='--', alpha=0.6)\n",
        "\n",
        "    plt.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
        "    plt.title('DeepSeek-R1 (RLVR) Training Progress', fontsize=16)\n",
        "    plt.xlabel('Epochs', fontsize=12)\n",
        "    plt.ylabel('Sharpe Ratio (Reward)', fontsize=12)\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2x003qNVUnqa",
        "outputId": "963c956e-42ed-44dd-dd81-2917b0bef19d"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# üõ†Ô∏è HOTFIX: PATCHING HELPER FUNCTIONS FOR ROBUSTNESS\n",
        "# ==============================================================================\n",
        "\n",
        "def calculate_gain(price_series):\n",
        "    \"\"\"\n",
        "    Robust version: Calculates gain per column (Ticker) without\n",
        "    dropping rows for the entire group.\n",
        "    \"\"\"\n",
        "    # If input is empty, return empty Series\n",
        "    if price_series.empty:\n",
        "        return pd.Series(dtype=float)\n",
        "\n",
        "    # ffill() fills missing data forward.\n",
        "    # .iloc[-1] takes the last price, .iloc[0] takes the first price.\n",
        "    return (price_series.ffill().iloc[-1] / price_series.bfill().iloc[0]) - 1\n",
        "\n",
        "# Re-register the metric to ensure it uses the new function\n",
        "def metric_price(d): return calculate_gain(d['lookback_close'])\n",
        "\n",
        "# Update the Registry\n",
        "METRIC_REGISTRY['Price'] = metric_price\n",
        "\n",
        "print(\"‚úÖ System Patched: Helper functions are now robust for messy 1990s data.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJMpN9CVCGUY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Dict, List, Tuple, Any\n",
        "from dataclasses import dataclass, field\n",
        "import random\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. DEFINING THE SEARCH SPACE (The \"Vocabulary\" of the Agent)\n",
        "# ==============================================================================\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class HyperParameterSpace:\n",
        "    \"\"\"Defines the rigid bounds of what the Agent is allowed to choose.\"\"\"\n",
        "\n",
        "    lookbacks: List[int] = field(default_factory=lambda: [10, 21, 42, 63, 126, 252])\n",
        "    holdings: List[int] = field(default_factory=lambda: [3, 5, 10, 21, 42])\n",
        "    # Filter strategies to only valid keys in your METRIC_REGISTRY\n",
        "    strategies: List[str] = field(default_factory=lambda: list(METRIC_REGISTRY.keys()))\n",
        "    ranks: List[Tuple[int, int]] = field(\n",
        "        default_factory=lambda: [(1, 5), (1, 10), (5, 10), (10, 20), (20, 30), (30, 40)]\n",
        "    )\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. THE RL AGENT (The \"Brain\")\n",
        "# ==============================================================================\n",
        "\n",
        "\n",
        "class StrategyAgent(nn.Module):\n",
        "    \"\"\"\n",
        "    A simplified RL Agent.\n",
        "    It learns 'Logits' (preferences) for each parameter.\n",
        "    Initially, all preferences are equal (random).\n",
        "    Over time, it increases the probability of parameters that yield high Sharpe.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, space: HyperParameterSpace):\n",
        "        super().__init__()\n",
        "        self.space = space\n",
        "\n",
        "        # Learnable weights for each category.\n",
        "        # We use Parameter(torch.zeros) which implies uniform probability initially (e^0 = 1).\n",
        "        self.logits_lookback = nn.Parameter(torch.zeros(len(space.lookbacks)))\n",
        "        self.logits_holding = nn.Parameter(torch.zeros(len(space.holdings)))\n",
        "        self.logits_strategy = nn.Parameter(torch.zeros(len(space.strategies)))\n",
        "        self.logits_rank = nn.Parameter(torch.zeros(len(space.ranks)))\n",
        "\n",
        "    def get_policy_distribution(self):\n",
        "        \"\"\"Converts internal weights to Probability Distributions (Categorical).\"\"\"\n",
        "        return {\n",
        "            \"lookback\": torch.distributions.Categorical(logits=self.logits_lookback),\n",
        "            \"holding\": torch.distributions.Categorical(logits=self.logits_holding),\n",
        "            \"strategy\": torch.distributions.Categorical(logits=self.logits_strategy),\n",
        "            \"rank\": torch.distributions.Categorical(logits=self.logits_rank),\n",
        "        }\n",
        "\n",
        "    def sample_action(self) -> Dict[str, Any]:\n",
        "        \"\"\"The Agent makes a decision based on current knowledge.\"\"\"\n",
        "        dists = self.get_policy_distribution()\n",
        "\n",
        "        # Sample indices from the distributions\n",
        "        idx_l = dists[\"lookback\"].sample()\n",
        "        idx_h = dists[\"holding\"].sample()\n",
        "        idx_s = dists[\"strategy\"].sample()\n",
        "        idx_r = dists[\"rank\"].sample()\n",
        "\n",
        "        # Decode indices to actual values\n",
        "        action = {\n",
        "            \"lookback\": self.space.lookbacks[idx_l.item()],\n",
        "            \"holding\": self.space.holdings[idx_h.item()],\n",
        "            \"strategy\": self.space.strategies[idx_s.item()],\n",
        "            \"rank_start\": self.space.ranks[idx_r.item()][0],\n",
        "            \"rank_end\": self.space.ranks[idx_r.item()][1],\n",
        "            # Store log_probs for the \"Learning\" phase (Backpropagation)\n",
        "            \"log_probs\": (\n",
        "                dists[\"lookback\"].log_prob(idx_l)\n",
        "                + dists[\"holding\"].log_prob(idx_h)\n",
        "                + dists[\"strategy\"].log_prob(idx_s)\n",
        "                + dists[\"rank\"].log_prob(idx_r)\n",
        "            ),\n",
        "        }\n",
        "        return action\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. THE TRAINING LOOP (DeepSeek-R1 Logic: Generate -> Verify -> Incentivize)\n",
        "# ==============================================================================\n",
        "\n",
        "\n",
        "class DeepSeekTrader:\n",
        "    def __init__(\n",
        "        self, df_ohlcv: pd.DataFrame, feature_df: pd.DataFrame, close_df: pd.DataFrame\n",
        "    ):\n",
        "        self.df_ohlcv = df_ohlcv\n",
        "        self.engine = AlphaEngine(df_ohlcv, feature_df, close_df)\n",
        "        self.space = HyperParameterSpace()\n",
        "        self.agent = StrategyAgent(self.space)\n",
        "        self.optimizer = optim.Adam(self.agent.parameters(), lr=0.1)\n",
        "\n",
        "        # --- NEW REGIME SAMPLING LOGIC ---\n",
        "        all_dates = self.engine.trading_calendar[252:-50]\n",
        "\n",
        "        # 1. Define the Cutoff (e.g., 2015)\n",
        "        recent_cutoff = pd.Timestamp(\"2015-01-01\")\n",
        "\n",
        "        # 2. Create the Pools\n",
        "        # Note: We convert to list to make random.choice easy\n",
        "        self.recent_pool = [d for d in all_dates if d >= recent_cutoff]\n",
        "        self.old_pool = [d for d in all_dates if d < recent_cutoff]\n",
        "\n",
        "        # 3. Fallback (Keep this just in case)\n",
        "        self.valid_dates = all_dates\n",
        "\n",
        "        print(f\"üìÖ Regime Sampling Initialized:\")\n",
        "        print(f\"   Recent Pool (Post-2015): {len(self.recent_pool)} dates\")\n",
        "        print(f\"   Historic Pool (Pre-2015): {len(self.old_pool)} dates\")\n",
        "\n",
        "    def run_training_epoch(self, batch_size: int = 10, robustness_checks: int = 3):\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        batch_rewards = []\n",
        "        batch_log_probs = []\n",
        "        batch_actions = []\n",
        "\n",
        "        # --- 1. PICK REGIME-BALANCED DATES ---\n",
        "        # Instead of completely random, we force: 2 Recent (Post-2015) + 1 Historic\n",
        "        exam_dates = []\n",
        "\n",
        "        # Pick 2 from Recent\n",
        "        if len(self.recent_pool) > 0:\n",
        "            exam_dates.extend(np.random.choice(self.recent_pool, 2, replace=False))\n",
        "\n",
        "        # Pick 1 from Old (to ensure strategy didn't just get lucky in the AI boom)\n",
        "        if len(self.old_pool) > 0:\n",
        "            exam_dates.extend(np.random.choice(self.old_pool, 1, replace=False))\n",
        "\n",
        "        # Fallback: If we don't have enough dates in pools, just use valid_dates\n",
        "        if len(exam_dates) < 3:\n",
        "            idx = np.random.choice(len(self.valid_dates), 3, replace=False)\n",
        "            exam_dates = [self.valid_dates[i] for i in idx]\n",
        "\n",
        "        # ==========================================================\n",
        "        # üü¢ INSERT THIS CODE SNIPPET HERE\n",
        "        # ==========================================================\n",
        "        date_strs = [d.strftime(\"%Y-%m-%d\") for d in exam_dates]\n",
        "        print(f\"   üóìÔ∏è Exam Dates: {', '.join(date_strs)}\")\n",
        "        # ==========================================================\n",
        "\n",
        "        # --- 2. GENERATION PHASE ---\n",
        "        for _ in range(batch_size):\n",
        "            action = self.agent.sample_action()\n",
        "\n",
        "            multi_date_sharpes = []\n",
        "\n",
        "            for test_date in exam_dates:\n",
        "                inputs = EngineInput(\n",
        "                    mode=\"Ranking\",\n",
        "                    start_date=pd.Timestamp(test_date),\n",
        "                    lookback_period=action[\"lookback\"],\n",
        "                    holding_period=action[\"holding\"],\n",
        "                    metric=action[\"strategy\"],\n",
        "                    benchmark_ticker=\"SPY\",\n",
        "                    rank_start=action[\"rank_start\"],\n",
        "                    rank_end=action[\"rank_end\"],\n",
        "                    debug=False,\n",
        "                )\n",
        "\n",
        "                result = self.engine.run(inputs)\n",
        "\n",
        "                if result.error_msg or \"holding_p_sharpe\" not in result.perf_metrics:\n",
        "                    multi_date_sharpes.append(-1.0)\n",
        "                else:\n",
        "                    s = result.perf_metrics.get(\"holding_p_sharpe\", 0.0)\n",
        "                    multi_date_sharpes.append(s)\n",
        "\n",
        "            avg_sharpe = np.mean(multi_date_sharpes)\n",
        "\n",
        "            # Raised ceiling to 5.0\n",
        "            reward = np.clip(avg_sharpe, -3.0, 5.0)\n",
        "\n",
        "            batch_rewards.append(reward)\n",
        "            batch_log_probs.append(action[\"log_probs\"])\n",
        "            batch_actions.append(\n",
        "                f\"{action['strategy']} (L:{action['lookback']}d, H:{action['holding']}d)\"\n",
        "            )\n",
        "\n",
        "        # --- 3. INCENTIVIZATION PHASE (RL UPDATE) ---\n",
        "        rewards_tensor = torch.tensor(batch_rewards, dtype=torch.float32)\n",
        "        baseline = rewards_tensor.mean()\n",
        "        advantages = rewards_tensor - baseline\n",
        "\n",
        "        policy_loss = []\n",
        "        for log_prob, adv in zip(batch_log_probs, advantages):\n",
        "            policy_loss.append(-log_prob * adv)\n",
        "\n",
        "        # Entropy Regularization\n",
        "        dists = self.agent.get_policy_distribution()\n",
        "        entropy = (\n",
        "            dists[\"lookback\"].entropy()\n",
        "            + dists[\"holding\"].entropy()\n",
        "            + dists[\"strategy\"].entropy()\n",
        "            + dists[\"rank\"].entropy()\n",
        "        ).mean()\n",
        "\n",
        "        ENTROPY_COEFF = 0.05\n",
        "        total_loss = torch.stack(policy_loss).mean() - (ENTROPY_COEFF * entropy)\n",
        "\n",
        "        total_loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        # Logging\n",
        "        print(f\"üìä Batch Robust Score: {baseline:.4f}\")\n",
        "        best_idx = np.argmax(batch_rewards)\n",
        "        print(\n",
        "            f\"üèÜ Best Strategy: {batch_actions[best_idx]} -> Score: {batch_rewards[best_idx]:.4f}\"\n",
        "        )\n",
        "\n",
        "        return baseline.item(), np.max(batch_rewards)\n",
        "\n",
        "    def inspect_brain(self):\n",
        "        \"\"\"Visualizes what the bot has learned so far.\"\"\"\n",
        "        dists = self.agent.get_policy_distribution()\n",
        "        print(\"\\nüß† Agent Preferences (Probabilities):\")\n",
        "\n",
        "        def print_probs(name, probs, labels):\n",
        "            df = pd.DataFrame({\"Value\": labels, \"Probability\": probs.detach().numpy()})\n",
        "            print(f\"--- {name} ---\")\n",
        "            print(df.sort_values(\"Probability\", ascending=False).head(3))\n",
        "\n",
        "        print_probs(\"Strategy\", dists[\"strategy\"].probs, self.space.strategies)\n",
        "        print_probs(\"Lookback\", dists[\"lookback\"].probs, self.space.lookbacks)\n",
        "        print_probs(\"Holding\", dists[\"holding\"].probs, self.space.holdings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMXJ41hjAksu"
      },
      "source": [
        "**Train the Agent:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tbMesgnSTC35",
        "outputId": "b32e1cd5-489f-4e94-e095-e8f2608489ae"
      },
      "outputs": [],
      "source": [
        "# --- 2. Initialize the Trader ---\n",
        "# Ensure you are using the correct dataframes (df_train, etc.)\n",
        "trainer = DeepSeekTrader(df_train, train_features, train_close)\n",
        "\n",
        "# --- 3. Initialize History Lists ---\n",
        "history_avg = []\n",
        "history_best = []\n",
        "total_epochs = 20  # Set this to how many rounds you want to train\n",
        "\n",
        "print(f\"--- üèÅ Starting RLVR Training for {total_epochs} Epochs ---\")\n",
        "\n",
        "# --- 4. The Training Loop ---\n",
        "for i in range(total_epochs):\n",
        "    print(f\"\\nEpoch {i+1}/{total_epochs}\")\n",
        "\n",
        "    # Run the epoch and UNPACK the two values we modified in Step 1\n",
        "    # Note: batch_size=20, robustness_checks=3 (as discussed before)\n",
        "    avg_score, best_score = trainer.run_training_epoch(batch_size=20, robustness_checks=3)\n",
        "\n",
        "    # CAPTURE the values\n",
        "    history_avg.append(avg_score)\n",
        "    history_best.append(best_score)\n",
        "\n",
        "# --- 5. Plot the Results ---\n",
        "print(\"\\n--- üéì Training Complete. Generating Plot... ---\")\n",
        "plot_training_history(history_avg, history_best)\n",
        "\n",
        "# --- 6. Inspect What It Learned ---\n",
        "trainer.inspect_brain()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2T5PYD4rfmn"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URs8nEtvic0W",
        "outputId": "ab623c40-5628-4a6e-a5ab-bcf667ca594b"
      },
      "outputs": [],
      "source": [
        "# Inspect just the Rank distribution\n",
        "dists = trainer.agent.get_policy_distribution()\n",
        "rank_probs = dists['rank'].probs.detach().numpy()\n",
        "labels = trainer.space.ranks\n",
        "\n",
        "df_ranks = pd.DataFrame({'Rank Range': labels, 'Probability': rank_probs})\n",
        "print(df_ranks.sort_values('Probability', ascending=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQIQJyVyTCR4",
        "outputId": "5d81e9e8-43c6-4076-f963-4d86cd67aafa"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# üß™ STEP 4: THE FINAL EXAM (WALK-FORWARD VALIDATION)\n",
        "# ==============================================================================\n",
        "\n",
        "def run_final_test(agent, df_test):\n",
        "    print(\"--- üèÅ STARTING WALK-FORWARD TEST (UNSEEN DATA) ---\")\n",
        "\n",
        "    # 1. SETUP TEST DATA\n",
        "    # We must generate features for the test set, just like we did for training.\n",
        "    print(\"üê¢ Generating Features for Test Set (This might take 10-20 seconds)...\")\n",
        "    test_features = generate_features(df_test)\n",
        "    test_close = df_test['Adj Close'].unstack(level=0)\n",
        "\n",
        "    # 2. EXTRACT THE \"HOLY GRAIL\" STRATEGY\n",
        "    # We ask the bot: \"If you had to pick ONE configuration, what is it?\"\n",
        "    dists = agent.get_policy_distribution()\n",
        "\n",
        "    # Argmax = The option with the highest probability\n",
        "    best_lookback = agent.space.lookbacks[torch.argmax(agent.logits_lookback).item()]\n",
        "    best_holding = agent.space.holdings[torch.argmax(agent.logits_holding).item()]\n",
        "    best_strategy = agent.space.strategies[torch.argmax(agent.logits_strategy).item()]\n",
        "\n",
        "    # Extract Rank (User asked about this!)\n",
        "    best_rank_idx = torch.argmax(agent.logits_rank).item()\n",
        "    best_rank_start = agent.space.ranks[best_rank_idx][0]\n",
        "    best_rank_end = agent.space.ranks[best_rank_idx][1]\n",
        "\n",
        "    print(f\"\\nü§ñ Agent's Chosen 'Holy Grail' Configuration:\")\n",
        "    print(f\"   Strategy:  {best_strategy}\")\n",
        "    print(f\"   Lookback:  {best_lookback} days\")\n",
        "    print(f\"   Holding:   {best_holding} days\")\n",
        "    print(f\"   Rank:      {best_rank_start} to {best_rank_end}\")\n",
        "\n",
        "    # 3. EXECUTE THE EXAM\n",
        "    # We test this specific setup on the Test Set timeline\n",
        "    test_engine = AlphaEngine(df_test, test_features, test_close)\n",
        "\n",
        "    # We create check points every 'Holding Period' to simulate real trading\n",
        "    # e.g., if holding is 10 days, we check every 10 days.\n",
        "    trading_dates = test_engine.trading_calendar[::best_holding]\n",
        "\n",
        "    # Safety: Ensure we have enough data\n",
        "    if len(trading_dates) < 5:\n",
        "        print(\"‚ùå Test Set too short to validate.\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\n--- üìâ Backtesting on {len(trading_dates)} periods in Test Set ---\")\n",
        "\n",
        "    sharpes = []\n",
        "    gains = []\n",
        "\n",
        "    for date in trading_dates:\n",
        "        # Stop if we run out of future data\n",
        "        try:\n",
        "            inputs = EngineInput(\n",
        "                mode='Ranking',\n",
        "                start_date=date,\n",
        "                lookback_period=best_lookback,\n",
        "                holding_period=best_holding,\n",
        "                metric=best_strategy,\n",
        "                benchmark_ticker='SPY',\n",
        "                rank_start=best_rank_start,\n",
        "                rank_end=best_rank_end,\n",
        "                debug=False\n",
        "            )\n",
        "\n",
        "            res = test_engine.run(inputs)\n",
        "\n",
        "            # Only record valid trades\n",
        "            if not res.error_msg and 'holding_p_sharpe' in res.perf_metrics:\n",
        "                s = res.perf_metrics['holding_p_sharpe']\n",
        "                g = res.perf_metrics.get('holding_p_gain', 0.0)\n",
        "\n",
        "                # Filter out bad data errors (Sharpe 0 with 0 gain usually means no trade)\n",
        "                if s != 0 or g != 0:\n",
        "                    sharpes.append(s)\n",
        "                    gains.append(g)\n",
        "                    # Optional: Print every 10th trade to show progress\n",
        "                    # print(f\"   Date: {date.date()} | Sharpe: {s:.2f} | Gain: {g:.2%}\")\n",
        "        except Exception as e:\n",
        "            continue # Skip invalid dates at the very end of the series\n",
        "\n",
        "    # 4. FINAL REPORT CARD\n",
        "    if not sharpes:\n",
        "        print(\"‚ùå No valid trades executed on Test Set.\")\n",
        "        return\n",
        "\n",
        "    avg_test_sharpe = np.mean(sharpes)\n",
        "    avg_test_gain = np.mean(gains)\n",
        "    total_compounded = (np.prod([1 + g for g in gains]) - 1)\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"üéì FINAL TEST RESULTS (Unseen Data):\")\n",
        "    print(f\"   Avg Sharpe Per Trade: {avg_test_sharpe:.4f}\")\n",
        "    print(f\"   Avg Gain Per Trade:   {avg_test_gain:.2%}\")\n",
        "    print(f\"   Total Compounded Return: {total_compounded:.2%}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    if avg_test_sharpe > 1.0:\n",
        "        print(\"‚úÖ PASS: Strategy generalizes well to new data!\")\n",
        "    elif avg_test_sharpe > 0.2:\n",
        "        print(\"‚ö†Ô∏è PASS (MARGINAL): Profitable, but barely beats the benchmark.\")\n",
        "    else:\n",
        "        print(\"‚ùå FAIL: Strategy overfitted. It memorized the past but failed the future.\")\n",
        "\n",
        "# --- RUN IT ---\n",
        "# Ensure trainer is the variable from your training loop\n",
        "run_final_test(trainer.agent, df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K46aS7N220tu",
        "outputId": "a0fca3e2-f2dc-4761-c944-3332c3c1b17a"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# üïµÔ∏è DEEP DIVE: STRATEGY vs. RANK CORRELATION\n",
        "# ==============================================================================\n",
        "\n",
        "def analyze_strategy_rank_correlation(trainer):\n",
        "    print(\"--- üî¨ Analyzing Strategy <-> Rank Relationship ---\")\n",
        "\n",
        "    # We will run a quick simulation of the Agent's brain\n",
        "    # by sampling 1,000 actions and checking the log_probs alignment,\n",
        "    # OR simpler: We just look at the Agent's preferences directly.\n",
        "\n",
        "    # Since the current architecture is Independent, we have to use logic\n",
        "    # to infer the best combo.\n",
        "\n",
        "    strategies = trainer.space.strategies\n",
        "    ranks = trainer.space.ranks\n",
        "\n",
        "    # Get the raw scores (logits) from the brain\n",
        "    strat_logits = trainer.agent.logits_strategy.detach().numpy()\n",
        "    rank_logits = trainer.agent.logits_rank.detach().numpy()\n",
        "\n",
        "    best_strat_idx = np.argmax(strat_logits)\n",
        "    best_rank_idx = np.argmax(rank_logits)\n",
        "\n",
        "    print(f\"Independent Preferences:\")\n",
        "    print(f\"   Favorite Strategy: {strategies[best_strat_idx]}\")\n",
        "    print(f\"   Favorite Rank:     {ranks[best_rank_idx]}\")\n",
        "\n",
        "    print(\"\\n--- üí° QUANT INSIGHT ---\")\n",
        "    if strategies[best_strat_idx] == 'Price':\n",
        "        print(\"Since the agent loves 'Price' (Momentum) and 'Rank (1, 10)':\")\n",
        "        print(\"Interpretaion: The agent is buying a basket of the 10 biggest gainers.\")\n",
        "        print(\"Why? This dilutes the risk of buying one single 'Pump and Dump' stock.\")\n",
        "    elif strategies[best_strat_idx] == 'Sharpe':\n",
        "        print(\"Since the agent loves 'Sharpe' and 'Rank (1, 10)':\")\n",
        "        print(\"Interpretation: The agent is buying a diversified basket of low-volatility stocks.\")\n",
        "\n",
        "analyze_strategy_rank_correlation(trainer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fseqsOGK3RNJ"
      },
      "source": [
        "### How to improve the Model (Advanced)\n",
        "To make the agent learn that \"Rank depends on Strategy,\" we would need to change the Neural Network architecture to be **Autoregressive**.\n",
        "\n",
        "**Current (Independent):**\n",
        "`Input -> [Strategy Head]`, `Input -> [Rank Head]`\n",
        "\n",
        "**Advanced (Conditional):**\n",
        "`Input -> [Strategy Head] -> (Output: Price) -> [Rank Head] -> (Output: Rank 5-10)`\n",
        "\n",
        "*For a high school project, the current Independent model is perfectly fine. It simulates a trader who has a \"favorite setup\" (e.g., Top 10) that they apply to everything.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pCwQq4j4jxh"
      },
      "source": [
        "**The Short Answer: YES.**\n",
        "As a Senior Quant, if a junior developer brought me a strategy with **8,454% returns** and a **Sharpe > 1.3** on a simple \"Price\" strategy, I would immediately assume there is a bug or a data bias.\n",
        "\n",
        "However, **this is a massive success for your RL Code**. Your bot successfully learned to \"exploit\" the simulation. It did exactly what it was supposed to do.\n",
        "\n",
        "Here is the breakdown of why the number is likely fake, and what is happening under the hood.\n",
        "\n",
        "---\n",
        "\n",
        "### 1. The \"Survivorship Bias\" Trap (Most Likely Culprit)\n",
        "Does your dataset (`df_OHLCV_stocks_etfs.parquet`) contain companies that went bankrupt? (e.g., Enron, Bed Bath & Beyond, Silicon Valley Bank)?\n",
        "\n",
        "*   **If NO:** Your bot is picking from a list of companies that we *know* survived until 2025. It‚Äôs like betting on a horse race after you know who won.\n",
        "*   **The Effect:** The \"Price\" strategy (Momentum) is incredibly dangerous in real life because high-flying stocks often crash to zero. If your dataset removes the ones that crashed to zero, the strategy looks like a magic money printer.\n",
        "\n",
        "### 2. The \"Frictionless Trading\" Illusion\n",
        "Your simulation assumes **0% Transaction Costs** and **0% Slippage**.\n",
        "\n",
        "*   **The Math:** You are trading every **10 Days**. That is ~25 trades per year per slot.\n",
        "*   **Avg Gain:** 1.90%.\n",
        "*   **Reality:**\n",
        "    *   **Commission/Spread:** Let's say you lose 0.10% buying and 0.10% selling.\n",
        "    *   **Slippage:** Buying the \"Top 10\" movers is hard. The price moves fast. You might pay 0.20% more than the Close price.\n",
        "    *   **Real Gain:** $1.90\\% - 0.40\\% = 1.50\\%$.\n",
        "*   **Compounding Effect:**\n",
        "    *   Simulated: $1.019^{322} \\approx 428x$\n",
        "    *   Real: $1.015^{322} \\approx 121x$\n",
        "    *   The difference is massive due to the frequency of trading.\n",
        "\n",
        "### 3. The \"Limit Up\" Problem\n",
        "You are buying \"Rank 1 to 10\" based on \"Price\".\n",
        "*   These are the stocks that went up the most.\n",
        "*   In real markets, stocks that jump 50% in a month often become **illiquid** or hit volatility halts. You might not actually be able to buy them at the `Adj Close` price listed in the CSV.\n",
        "\n",
        "---\n",
        "\n",
        "### How to \"Stress Test\" this result (Homework)\n",
        "\n",
        "To see if this strategy is actually robust or just lucky/biased, modify the `calculate_gain` or the Final Exam loop to include a **Transaction Cost**.\n",
        "\n",
        "**Modify this line in `AlphaEngine` or `run_final_test`:**\n",
        "\n",
        "```python\n",
        "# In the loop where you calculate gains:\n",
        "# cost_per_trade = 0.002  # 0.2% (Standard slippage + fees)\n",
        "# net_gain = res.perf_metrics['holding_p_gain'] - cost_per_trade\n",
        "```\n",
        "\n",
        "### Summary for the Student\n",
        "1.  **Did the AI work?** **YES.** It found the mathematical optimum of your simulation. It \"solved\" the game you gave it.\n",
        "2.  **Is the strategy real?** **NO.** 8,000% returns don't exist in the stock market without massive leverage or insider information.\n",
        "3.  **The Lesson:** In Quantitative Finance, if it looks too good to be true, it's usually **Survivorship Bias**.\n",
        "\n",
        "**Excellent work.** You have successfully built a DeepSeek-style Reasoning Agent that can overfit a market simulation. This is exactly what the first stage of research looks like at DeepMind."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zozD1OK8Uaq"
      },
      "source": [
        "## Thank you. That was a great start. As a RL, Dev, Quant, mentor, what   is the logical next step? How to improve on what we built?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcZ09E3-7hAG"
      },
      "source": [
        "**Considering Next Steps**\n",
        "\n",
        "I've been analyzing the student's profile and current system. They're a high schooler with basic Python skills, interested in DeepSeek/RL. They've built a working prototype. My next step is to examine the environment they're in, and then I'll decide where we go from there.\n",
        "\n",
        "\n",
        "**Evaluating Current Limitations**\n",
        "\n",
        "I've examined the `AlphaEngine` setup and identified its core flaws. The `StrategyAgent` operates in a single-state context, essentially a \"Bandit\" problem instead of full RL. From a quant perspective, the simulation is unrealistic, suffering from issues like zero costs and daily granularity. Developmentally, the code is monolithic and notebook-bound, limiting its adaptability.\n",
        "\n",
        "\n",
        "**Mapping Out Improvements**\n",
        "\n",
        "I'm now charting the optimal path forward, breaking it down into distinct phases. First, the simulation needs a reality check; the current environment breeds unrealistic results. Second, contextual awareness is crucial - the agent needs to perceive market states. Finally, I'm thinking about a more advanced architecture, moving towards a small neural network. I've begun to formulate the first iterations of the plan, targeting the simulation for transaction costs, and also formulating contextual bandits for the RL phase.\n",
        "\n",
        "\n",
        "**Adjusting Data Strategy**\n",
        "\n",
        "My focus has shifted to the data strategy. I've considered survivorship bias, acknowledging the limitations given the available data. To circumvent this, I'm proposing a more stringent filter to eliminate penny stocks, raising the minimum dollar volume to $10M. This simulates S&P 500 behavior, offering a safer approach. On the developmental side, portfolio management seems too advanced, so I'll stick with ranking for now.\n",
        "\n",
        "\n",
        "**Refining Contextual Bandits**\n",
        "\n",
        "My thinking has moved towards refining the \"Contextual Bandit\" framework. I'm leaning toward incorporating `SPY_200_SMA` for trend identification, and `VIX` for volatility assessment.  I'm aiming to provide code snippets for these concepts.  The Contextual Bandit approach is the perfect intermediate step, bridging the gap between their current stateless system and full-blown RL. I must keep that in mind when making these changes.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVt5jsWO7j9S"
      },
      "source": [
        "This is the perfect moment in a research project. You have a **Minimum Viable Product (MVP)** that works, but you also know it's \"cheating\" slightly (Survivorship Bias, Zero Costs).\n",
        "\n",
        "As your Mentor Team, we propose a 3-step roadmap to turn this from a \"toy\" into a **serious research engine**.\n",
        "\n",
        "---\n",
        "\n",
        "### Phase 1: The Quant Fix (Add Friction)\n",
        "**\"Physics before Brains.\"**\n",
        "Right now, your Agent thinks trading is free. It buys and sells every 10 days with zero penalty. In reality, every trade costs money (spread, slippage, commissions).\n",
        "\n",
        "**The Task:**\n",
        "Implement **Transaction Costs** in the `AlphaEngine`.\n",
        "1.  Define a cost (e.g., **10 basis points** or 0.10% per trade).\n",
        "2.  Subtract this from the calculated gain.\n",
        "\n",
        "**Why?**\n",
        "The Agent will likely stop choosing `Holding: 10 Days` and move to `Holding: 42 Days` or `63 Days`. It will learn that over-trading is expensive‚Äîa lesson that takes human traders years to learn!\n",
        "\n",
        "---\n",
        "\n",
        "### Phase 2: The RL Upgrade (Give the Bot \"Eyes\")\n",
        "**\"From Static to Dynamic.\"**\n",
        "Currently, your Agent learns **one** global configuration (e.g., \"Always use Price\").\n",
        "But a real trader acts differently in a Crash (2008) vs. a Bubble (2021).\n",
        "\n",
        "**The Task:**\n",
        "Upgrade the Agent from a **Stateless Bandit** to a **Contextual Bandit**.\n",
        "\n",
        "**Input (The \"Context\"):**\n",
        "Before the Agent picks a strategy, give it 2 pieces of data about the market:\n",
        "1.  **Trend:** Is SPY above or below its 200-day Moving Average? (1 = Bull, 0 = Bear).\n",
        "2.  **Volatility:** Is the ATR of SPY high or low? (1 = Panic, 0 = Calm).\n",
        "\n",
        "**The \"Brain\" Change:**\n",
        "Instead of static weights `self.logits_strategy`, use a tiny Neural Network:\n",
        "`[Market Context] -> [Linear Layer] -> [Strategy Probabilities]`\n",
        "\n",
        "**The Result:**\n",
        "The Agent will learn:\n",
        "*   *IF Bull Market:* Use **Price / Momentum**.\n",
        "*   *IF Bear Market:* Use **Sharpe (ATR)** or **Cash**.\n",
        "\n",
        "---\n",
        "\n",
        "### Phase 3: The Data Fix (Harder Universe)\n",
        "**\"Stop playing on Easy Mode.\"**\n",
        "Your Agent is buying \"Rank 1-10\" stocks. These are often penny stocks that exploded by 500%.\n",
        "\n",
        "**The Task:**\n",
        "Tighten the `quality_thresholds` in your code.\n",
        "*   Increase `min_median_dollar_volume` from $100k to **$10 Million**.\n",
        "*   This forces the Agent to trade **Large Cap Stocks** (like Apple, Tesla, Ford).\n",
        "\n",
        "**Why?**\n",
        "It is much harder to get 8,000% returns on Large Caps. If the Agent can squeeze a 1.5 Sharpe Ratio out of Large Caps, you have a truly professional strategy.\n",
        "\n",
        "---\n",
        "\n",
        "### üöÄ Immediate Homework: The \"Contextual\" Upgrade\n",
        "\n",
        "Phase 2 is the most exciting RL step. Here is the blueprint for the **Contextual Agent** class.\n",
        "\n",
        "**Replace your `StrategyAgent` with this:**\n",
        "\n",
        "```python\n",
        "class ContextualAgent(nn.Module):\n",
        "    def __init__(self, space: HyperParameterSpace):\n",
        "        super().__init__()\n",
        "        self.space = space\n",
        "        \n",
        "        # Context Size = 2 (e.g., Market Trend, Volatility)\n",
        "        self.context_size = 2\n",
        "        \n",
        "        # Instead of single weights, we have \"Layers\" that take context as input\n",
        "        self.layer_lookback = nn.Linear(self.context_size, len(space.lookbacks))\n",
        "        self.layer_holding  = nn.Linear(self.context_size, len(space.holdings))\n",
        "        self.layer_strategy = nn.Linear(self.context_size, len(space.strategies))\n",
        "        self.layer_rank     = nn.Linear(self.context_size, len(space.ranks))\n",
        "\n",
        "    def get_policy_distribution(self, context_tensor):\n",
        "        \"\"\"\n",
        "        Now requires 'context_tensor' (e.g., [1.0, 0.0] for Bull Market/Low Vol)\n",
        "        \"\"\"\n",
        "        # Pass context through neural network layers\n",
        "        logits_l = self.layer_lookback(context_tensor)\n",
        "        logits_h = self.layer_holding(context_tensor)\n",
        "        logits_s = self.layer_strategy(context_tensor)\n",
        "        logits_r = self.layer_rank(context_tensor)\n",
        "        \n",
        "        return {\n",
        "            'lookback': torch.distributions.Categorical(logits=logits_l),\n",
        "            'holding':  torch.distributions.Categorical(logits=logits_h),\n",
        "            'strategy': torch.distributions.Categorical(logits=logits_s),\n",
        "            'rank':     torch.distributions.Categorical(logits=logits_r),\n",
        "        }\n",
        "```\n",
        "\n",
        "**Your Challenge:**\n",
        "Can you write the code to calculate the `context` (SPY Trend and Volatility) inside the `DeepSeekTrader` class and pass it to this new agent?\n",
        "\n",
        "This is the bridge between \"High School Project\" and \"University Research.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcE1zlX53UCR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py311-py3.11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
