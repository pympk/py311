{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b8db47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Added to path: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_RLVR\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('c:/Users/ping/Files_win10/python/py311/stocks/notebooks_RLVR')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def add_project_root_to_path():\n",
    "    \"\"\"Find notebooks_RLVR and add to sys.path.\"\"\"\n",
    "    current = Path.cwd()\n",
    "\n",
    "    # Search upward for notebooks_RLVR folder\n",
    "    for path in [current] + list(current.parents):\n",
    "        if path.name == \"notebooks_RLVR\":\n",
    "            sys.path.insert(0, str(path))\n",
    "            print(f\"✓ Added to path: {path}\")\n",
    "            return path\n",
    "        # Also check if notebooks_RLVR exists as child (for running from stocks/)\n",
    "        candidate = path / \"notebooks_RLVR\"\n",
    "        if candidate.exists():\n",
    "            sys.path.insert(0, str(candidate))\n",
    "            print(f\"✓ Added to path: {candidate}\")\n",
    "            return candidate\n",
    "\n",
    "    raise RuntimeError(\"Could not find notebooks_RLVR directory\")\n",
    "\n",
    "\n",
    "# Run once at notebook start\n",
    "add_project_root_to_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2136b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTEBOOKS_RLVR_ROOT: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_RLVR\n",
      "\n",
      "OUTPUT_DIR: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_RLVR\\output\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display\n",
    "from typing import List, Union, Tuple\n",
    "from core.settings import GLOBAL_SETTINGS\n",
    "from core.paths import OUTPUT_DIR\n",
    "\n",
    "# pd.set_option('display.max_rows', None)  display all rows\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"display.max_colwidth\", 50)\n",
    "pd.set_option(\"display.precision\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24036a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_env_and_get_path():\n",
    "    \"\"\"Load .env file and return data path. Works from any subdirectory.\"\"\"\n",
    "\n",
    "    # Start from current file's directory\n",
    "    current_dir = Path.cwd()\n",
    "\n",
    "    # Search upward for the .env folder\n",
    "    for parent in [current_dir] + list(current_dir.parents):\n",
    "        env_file = parent / \".env\" / \"my_api_key.env\"\n",
    "        if env_file.exists():\n",
    "            load_dotenv(env_file)\n",
    "            print(f\"✓ Loaded .env from: {env_file}\")\n",
    "            break\n",
    "\n",
    "    data_ohlcv_path = os.getenv(\"DATA_PATH_OHLCV\")\n",
    "    if not data_ohlcv_path:\n",
    "        raise ValueError(\"DATA_PATH_OHLCV not found in .env file\")\n",
    "\n",
    "    data_indices_path = os.getenv(\"DATA_PATH_INDICES\")\n",
    "    if not data_indices_path:\n",
    "        raise ValueError(\"DATA_PATH_INDICES not found in .env file\")\n",
    "\n",
    "    return data_ohlcv_path, data_indices_path\n",
    "\n",
    "\n",
    "def generate_features(\n",
    "    df_ohlcv: pd.DataFrame,\n",
    "    df_indices: pd.DataFrame = None,\n",
    "    benchmark_ticker: str = GLOBAL_SETTINGS[\"benchmark_ticker\"],\n",
    "    atr_period: int = GLOBAL_SETTINGS[\"atr_period\"],\n",
    "    rsi_period: int = GLOBAL_SETTINGS[\"rsi_period\"],\n",
    "    win_5d: int = GLOBAL_SETTINGS[\"5d_window\"],\n",
    "    win_21d: int = GLOBAL_SETTINGS[\"21d_window\"],\n",
    "    win_63d: int = GLOBAL_SETTINGS[\"63d_window\"],\n",
    "    feature_zscore_clip: float = GLOBAL_SETTINGS[\"feature_zscore_clip\"],\n",
    "    quality_window: int = GLOBAL_SETTINGS[\"quality_window\"],\n",
    "    quality_min_periods: int = GLOBAL_SETTINGS[\"quality_min_periods\"],\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "\n",
    "    print(f\"⚡ Generating Decoupled Features (Benchmark: {benchmark_ticker})...\")\n",
    "\n",
    "    # --- 0. PREP ---\n",
    "    df_ohlcv = df_ohlcv.sort_index(level=[\"Ticker\", \"Date\"])\n",
    "    all_dates = df_ohlcv.index.get_level_values(\"Date\").unique().sort_values()\n",
    "\n",
    "    # --- 1. MACRO ENGINE ---\n",
    "    macro_df = pd.DataFrame(index=all_dates)\n",
    "    if benchmark_ticker in df_ohlcv.index.get_level_values(\"Ticker\"):\n",
    "        mkt_close = (\n",
    "            df_ohlcv.xs(benchmark_ticker, level=\"Ticker\")[\"Adj Close\"]\n",
    "            .reindex(all_dates)\n",
    "            .ffill()\n",
    "        )\n",
    "        macro_df[\"Mkt_Ret\"] = mkt_close.pct_change().fillna(0.0)\n",
    "        macro_df[\"Macro_Trend\"] = (mkt_close / mkt_close.rolling(200).mean()) - 1.0\n",
    "    else:\n",
    "        macro_df[\"Mkt_Ret\"] = 0.0\n",
    "        macro_df[\"Macro_Trend\"] = 0.0\n",
    "\n",
    "    # --- TREND VELOCITY & MOMENTUM ---\n",
    "    macro_df[\"Macro_Trend_Vel\"] = macro_df[\"Macro_Trend\"].diff(win_21d)\n",
    "    macro_df[\"Macro_Trend_Vel_Z\"] = (\n",
    "        macro_df[\"Macro_Trend_Vel\"] / macro_df[\"Macro_Trend\"].rolling(win_63d).std()\n",
    "    ).clip(-feature_zscore_clip, feature_zscore_clip)\n",
    "    macro_df[\"Macro_Trend_Mom\"] = (\n",
    "        np.sign(macro_df[\"Macro_Trend\"])\n",
    "        * np.sign(macro_df[\"Macro_Trend_Vel\"])\n",
    "        * np.abs(macro_df[\"Macro_Trend_Vel\"])\n",
    "    ).fillna(0)\n",
    "\n",
    "    # VIX Extraction (Same as before)\n",
    "    macro_df[\"Macro_Vix_Z\"] = 0.0\n",
    "    macro_df[\"Macro_Vix_Ratio\"] = 1.0\n",
    "    if df_indices is not None:\n",
    "        idx_names = df_indices.index.get_level_values(0).unique()\n",
    "        if \"^VIX\" in idx_names:\n",
    "            v = df_indices.xs(\"^VIX\", level=0)[\"Adj Close\"].reindex(all_dates).ffill()\n",
    "            macro_df[\"Macro_Vix_Z\"] = (\n",
    "                (v - v.rolling(63).mean()) / v.rolling(63).std()\n",
    "            ).clip(-feature_zscore_clip, feature_zscore_clip)\n",
    "        if \"^VIX\" in idx_names and \"^VIX3M\" in idx_names:\n",
    "            v3 = (\n",
    "                df_indices.xs(\"^VIX3M\", level=0)[\"Adj Close\"].reindex(all_dates).ffill()\n",
    "            )\n",
    "            macro_df[\"Macro_Vix_Ratio\"] = (v / v3).fillna(1.0)\n",
    "    macro_df.fillna(0.0, inplace=True)\n",
    "\n",
    "    # --- 2. TICKER ENGINE ---\n",
    "    grouped = df_ohlcv.groupby(level=\"Ticker\")\n",
    "    rets = grouped[\"Adj Close\"].pct_change()\n",
    "    mkt_ret_series = macro_df[\"Mkt_Ret\"]  # The \"Master\" market vector\n",
    "\n",
    "    # A. Hybrid Metrics (Beta & IR)\n",
    "    # 1. IR_63 (Passed previously, kept same logic)\n",
    "    active_ret = rets.sub(mkt_ret_series, axis=0, level=\"Date\")\n",
    "    roll_active = active_ret.groupby(level=\"Ticker\").rolling(win_63d)\n",
    "    ir_63 = (\n",
    "        (roll_active.mean() / roll_active.std())\n",
    "        .reset_index(level=0, drop=True)\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    # 2. Beta_63 (Optimized: Pre-compute market variance, audit-exact calculation)\n",
    "    mkt_var = mkt_ret_series.rolling(win_63d).var()\n",
    "\n",
    "    def calc_rolling_beta(ticker_rets):\n",
    "        dates = ticker_rets.index.get_level_values(\"Date\")\n",
    "        m = mkt_ret_series.reindex(dates)\n",
    "        return ticker_rets.rolling(win_63d).cov(m) / mkt_var.reindex(dates)\n",
    "\n",
    "    beta_63 = (\n",
    "        rets.groupby(level=\"Ticker\", group_keys=False)\n",
    "        .apply(calc_rolling_beta)\n",
    "        .fillna(1.0)\n",
    "    )\n",
    "\n",
    "    # B. Volatility (ATR / TRP) - Optimized\n",
    "    prev_close = grouped[\"Adj Close\"].shift(1)\n",
    "\n",
    "    # Vectorized True Range without pd.concat memory overhead\n",
    "    high_low = df_ohlcv[\"Adj High\"] - df_ohlcv[\"Adj Low\"]\n",
    "    high_close = (df_ohlcv[\"Adj High\"] - prev_close).abs()\n",
    "    low_close = (df_ohlcv[\"Adj Low\"] - prev_close).abs()\n",
    "\n",
    "    # Nested np.maximum avoids creating a 3-column DataFrame\n",
    "    tr = np.maximum(np.maximum(high_low, high_close), low_close)\n",
    "\n",
    "    atr = (\n",
    "        tr.groupby(level=\"Ticker\")\n",
    "        .ewm(alpha=1 / atr_period, adjust=False)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    natr = (atr / df_ohlcv[\"Adj Close\"]).fillna(0)\n",
    "    trp = (tr / df_ohlcv[\"Adj Close\"]).fillna(0)\n",
    "\n",
    "    # C. Momentum & Consistency\n",
    "    mom_21 = grouped[\"Adj Close\"].pct_change(win_21d)\n",
    "    consistency = (\n",
    "        (rets > 0)\n",
    "        .astype(float)\n",
    "        .groupby(level=\"Ticker\")\n",
    "        .rolling(win_5d)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    dd_21 = (\n",
    "        df_ohlcv[\"Adj Close\"]\n",
    "        / grouped[\"Adj Close\"].rolling(win_21d).max().reset_index(level=0, drop=True)\n",
    "    ) - 1.0\n",
    "\n",
    "    # D. RSI (Wilder's Logic)\n",
    "    delta = grouped[\"Adj Close\"].diff()\n",
    "    up, down = delta.clip(lower=0), -1 * delta.clip(upper=0)\n",
    "    ma_up = (\n",
    "        up.groupby(level=\"Ticker\")\n",
    "        .ewm(alpha=1 / rsi_period, adjust=False)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    ma_down = (\n",
    "        down.groupby(level=\"Ticker\")\n",
    "        .ewm(alpha=1 / rsi_period, adjust=False)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    # FIX: Allow division by zero (i.e. no down day) to create inf (correct RSI=100),\n",
    "    # inf→100, -inf→0, NaN→50\n",
    "    # then clean up remaining NaNs (initial periods/no movement)\n",
    "    # - Initial periods: Before the 14-day lookback is filled, the EWM mean is undefined → NaN.\n",
    "    # - Flat prices: If price doesn't move (Avg Up = 0 and Avg Down = 0), RS is 0/0 → NaN.\n",
    "    # - By convention, RSI is set to 50 (neutral) when there is no directional momentum.\n",
    "    rs = ma_up / ma_down  # Keep zero denominator → inf\n",
    "    raw_rsi = 100 - (100 / (1 + rs))\n",
    "    rsi = raw_rsi.replace({np.inf: 100, -np.inf: 0}).fillna(50)\n",
    "\n",
    "    # E. Assemble Features\n",
    "    features_df = pd.DataFrame(\n",
    "        {\n",
    "            \"ATR\": atr,\n",
    "            \"ATRP\": natr,\n",
    "            \"TRP\": trp,\n",
    "            \"RSI\": rsi,\n",
    "            \"Mom_21\": mom_21,\n",
    "            \"Consistency\": consistency,\n",
    "            \"IR_63\": ir_63,\n",
    "            \"Beta_63\": beta_63,\n",
    "            \"DD_21\": dd_21.fillna(0),\n",
    "            \"Ret_1d\": rets,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # F. Quality (Universe Filtering) - Optimized\n",
    "    quality_temp = pd.DataFrame(\n",
    "        {\n",
    "            \"IsStale\": np.where(\n",
    "                (df_ohlcv[\"Volume\"] == 0)\n",
    "                | (df_ohlcv[\"Adj High\"] == df_ohlcv[\"Adj Low\"]),\n",
    "                1,\n",
    "                0,\n",
    "            ),\n",
    "            \"DollarVolume\": df_ohlcv[\"Adj Close\"] * df_ohlcv[\"Volume\"],\n",
    "            \"HasSameVolume\": (grouped[\"Volume\"].diff() == 0).astype(int),\n",
    "        },\n",
    "        index=df_ohlcv.index,\n",
    "    )\n",
    "\n",
    "    # Calculate rolling stats separately (avoid slow dict agg) and use .values to bypass index alignment overhead\n",
    "    grp = quality_temp.groupby(level=\"Ticker\")\n",
    "    rolling_quality = pd.DataFrame(\n",
    "        {\n",
    "            \"RollingStalePct\": grp[\"IsStale\"]\n",
    "            .rolling(window=quality_window, min_periods=quality_min_periods)\n",
    "            .mean()\n",
    "            .values,\n",
    "            \"RollMedDollarVol\": grp[\"DollarVolume\"]\n",
    "            .rolling(window=quality_window, min_periods=quality_min_periods)\n",
    "            .median()\n",
    "            .values,\n",
    "            \"RollingSameVolCount\": grp[\"HasSameVolume\"]\n",
    "            .rolling(window=quality_window, min_periods=quality_min_periods)\n",
    "            .sum()\n",
    "            .values,\n",
    "        },\n",
    "        index=quality_temp.index,\n",
    "    )\n",
    "\n",
    "    return pd.concat([features_df, rolling_quality], axis=1).sort_index(), macro_df\n",
    "\n",
    "\n",
    "def create_combined_dict(\n",
    "    df_ohlcv: pd.DataFrame,\n",
    "    features_df: pd.DataFrame,\n",
    "    tickers: Union[str, List[str]],\n",
    "    date_start: str,\n",
    "    date_end: str,\n",
    "    verbose: bool = True,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Create a combined dictionary with both OHLCV and features data for each ticker.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_ohlcv : pd.DataFrame\n",
    "        DataFrame with OHLCV data (MultiIndex: ticker, date)\n",
    "    features_df : pd.DataFrame\n",
    "        DataFrame with features data (MultiIndex: ticker, date)\n",
    "    tickers : str or list of str\n",
    "        Ticker symbol(s) to retrieve\n",
    "    date_start : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    date_end : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    verbose : bool, optional\n",
    "        Whether to print progress information (default: True)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with tickers as keys and combined DataFrames (OHLCV + features) as values\n",
    "    \"\"\"\n",
    "    # Convert single ticker to list\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Creating combined dictionary for {len(tickers)} ticker(s)\")\n",
    "        print(f\"Date range: {date_start} to {date_end}\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "    # Get OHLCV data as dictionary\n",
    "    ohlcv_dict = get_ticker_OHLCV(\n",
    "        df_ohlcv, tickers, date_start, date_end, return_format=\"dict\", verbose=verbose\n",
    "    )\n",
    "\n",
    "    # Get features data as dictionary\n",
    "    features_dict = get_ticker_features(\n",
    "        features_df,\n",
    "        tickers,\n",
    "        date_start,\n",
    "        date_end,\n",
    "        return_format=\"dict\",\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "    # Create combined_dict\n",
    "    combined_dict = {}\n",
    "\n",
    "    for ticker in tickers:\n",
    "        if verbose:\n",
    "            print(f\"\\nProcessing {ticker}...\")\n",
    "\n",
    "        # Check if ticker exists in both dictionaries\n",
    "        if ticker in ohlcv_dict and ticker in features_dict:\n",
    "            ohlcv_data = ohlcv_dict[ticker]\n",
    "            features_data = features_dict[ticker]\n",
    "\n",
    "            # Check if both dataframes have data\n",
    "            if not ohlcv_data.empty and not features_data.empty:\n",
    "                # Combine OHLCV and features data\n",
    "                # Note: Both dataframes have the same index (dates), so we can concatenate\n",
    "                combined_df = pd.concat([ohlcv_data, features_data], axis=1)\n",
    "\n",
    "                # Ensure proper index naming\n",
    "                combined_df.index.name = \"Date\"\n",
    "\n",
    "                # Store in combined_dict\n",
    "                combined_dict[ticker] = combined_df\n",
    "\n",
    "                if verbose:\n",
    "                    print(f\"  ✓ Successfully combined data\")\n",
    "                    print(f\"  OHLCV shape: {ohlcv_data.shape}\")\n",
    "                    print(f\"  Features shape: {features_data.shape}\")\n",
    "                    print(f\"  Combined shape: {combined_df.shape}\")\n",
    "                    print(\n",
    "                        f\"  Date range: {combined_df.index.min()} to {combined_df.index.max()}\"\n",
    "                    )\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"  ✗ Cannot combine: One or both dataframes are empty\")\n",
    "                    print(f\"    OHLCV empty: {ohlcv_data.empty}\")\n",
    "                    print(f\"    Features empty: {features_data.empty}\")\n",
    "                combined_dict[ticker] = pd.DataFrame()\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(f\"  ✗ Ticker not found in both dictionaries\")\n",
    "                if ticker not in ohlcv_dict:\n",
    "                    print(f\"    Not in OHLCV data\")\n",
    "                if ticker not in features_dict:\n",
    "                    print(f\"    Not in features data\")\n",
    "            combined_dict[ticker] = pd.DataFrame()\n",
    "\n",
    "    # Print summary\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"SUMMARY\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Total tickers processed: {len(tickers)}\")\n",
    "\n",
    "        tickers_with_data = [\n",
    "            ticker for ticker, df in combined_dict.items() if not df.empty\n",
    "        ]\n",
    "        print(f\"Tickers with combined data: {len(tickers_with_data)}\")\n",
    "\n",
    "        if tickers_with_data:\n",
    "            print(\"\\nTicker details:\")\n",
    "            for ticker in tickers_with_data:\n",
    "                df = combined_dict[ticker]\n",
    "                print(f\"  {ticker}: {df.shape} - {df.index.min()} to {df.index.max()}\")\n",
    "                print(f\"    Columns: {len(df.columns)}\")\n",
    "\n",
    "        empty_tickers = [ticker for ticker, df in combined_dict.items() if df.empty]\n",
    "        if empty_tickers:\n",
    "            print(f\"\\nTickers with no data: {', '.join(empty_tickers)}\")\n",
    "\n",
    "    return combined_dict\n",
    "\n",
    "\n",
    "def get_ticker_OHLCV(\n",
    "    df_ohlcv: pd.DataFrame,\n",
    "    tickers: Union[str, List[str]],\n",
    "    date_start: str,\n",
    "    date_end: str,\n",
    "    return_format: str = \"dataframe\",\n",
    "    verbose: bool = True,\n",
    ") -> Union[pd.DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    Get OHLCV data for specified tickers within a date range.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_ohlcv : pd.DataFrame\n",
    "        DataFrame with MultiIndex of (ticker, date) and OHLCV columns\n",
    "    tickers : str or list of str\n",
    "        Ticker symbol(s) to retrieve\n",
    "    date_start : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    date_end : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    return_format : str, optional\n",
    "        Format to return data in. Options:\n",
    "        - 'dataframe': Single DataFrame with MultiIndex (default)\n",
    "        - 'dict': Dictionary with tickers as keys and DataFrames as values\n",
    "        - 'separate': List of separate DataFrames for each ticker\n",
    "    verbose : bool, optional\n",
    "        Whether to print summary information (default: True)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Union[pd.DataFrame, dict, list]\n",
    "        Filtered OHLCV data in specified format\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If input parameters are invalid\n",
    "    KeyError\n",
    "        If tickers not found in DataFrame\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> # Get data for single ticker\n",
    "    >>> vlo_data = get_ticker_OHLCV(df_ohlcv, 'VLO', '2025-08-13', '2025-09-04')\n",
    "\n",
    "    >>> # Get data for multiple tickers\n",
    "    >>> multi_data = get_ticker_OHLCV(df_ohlcv, ['VLO', 'JPST'], '2025-08-13', '2025-09-04')\n",
    "\n",
    "    >>> # Get data as dictionary\n",
    "    >>> data_dict = get_ticker_OHLCV(df_ohlcv, ['VLO', 'JPST'], '2025-08-13',\n",
    "    ...                              '2025-09-04', return_format='dict')\n",
    "    \"\"\"\n",
    "\n",
    "    # Input validation\n",
    "    if not isinstance(df_ohlcv, pd.DataFrame):\n",
    "        raise TypeError(\"df_ohlcv must be a pandas DataFrame\")\n",
    "\n",
    "    if not isinstance(df_ohlcv.index, pd.MultiIndex):\n",
    "        raise ValueError(\"DataFrame must have MultiIndex of (ticker, date)\")\n",
    "\n",
    "    if len(df_ohlcv.index.levels) != 2:\n",
    "        raise ValueError(\"MultiIndex must have exactly 2 levels: (ticker, date)\")\n",
    "\n",
    "    # Convert single ticker to list for consistent processing\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "    elif not isinstance(tickers, list):\n",
    "        raise TypeError(\"tickers must be a string or list of strings\")\n",
    "\n",
    "    # Convert dates to Timestamps\n",
    "    try:\n",
    "        start_date = pd.Timestamp(date_start)\n",
    "        end_date = pd.Timestamp(date_end)\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"Invalid date format. Use 'YYYY-MM-DD': {e}\")\n",
    "\n",
    "    if start_date > end_date:\n",
    "        raise ValueError(\"date_start must be before or equal to date_end\")\n",
    "\n",
    "    # Check if tickers exist in the DataFrame\n",
    "    available_tickers = df_ohlcv.index.get_level_values(0).unique()\n",
    "    missing_tickers = [t for t in tickers if t not in available_tickers]\n",
    "\n",
    "    if missing_tickers:\n",
    "        raise KeyError(f\"Ticker(s) not found in DataFrame: {missing_tickers}\")\n",
    "\n",
    "    # Filter the data using MultiIndex slicing\n",
    "    try:\n",
    "        filtered_data = df_ohlcv.loc[(tickers, slice(date_start, date_end)), :]\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error filtering data: {e}\")\n",
    "\n",
    "    # Handle empty results\n",
    "    if filtered_data.empty:\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"No data found for tickers {tickers} in date range {date_start} to {date_end}\"\n",
    "            )\n",
    "        return filtered_data\n",
    "\n",
    "    # Print summary if verbose\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"Data retrieved for {len(tickers)} ticker(s) from {date_start} to {date_end}\"\n",
    "        )\n",
    "        print(f\"Total rows: {len(filtered_data)}\")\n",
    "        print(\n",
    "            f\"Date range in data: {filtered_data.index.get_level_values(1).min()} to \"\n",
    "            f\"{filtered_data.index.get_level_values(1).max()}\"\n",
    "        )\n",
    "\n",
    "        # Print ticker-specific counts\n",
    "        ticker_counts = filtered_data.index.get_level_values(0).value_counts()\n",
    "        for ticker in tickers:\n",
    "            count = ticker_counts.get(ticker, 0)\n",
    "            if count > 0:\n",
    "                print(f\"  {ticker}: {count} rows\")\n",
    "            else:\n",
    "                print(f\"  {ticker}: No data in range\")\n",
    "\n",
    "    # Return in requested format\n",
    "    if return_format == \"dict\":\n",
    "        result = {}\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result[ticker] = filtered_data.xs(ticker, level=0).loc[\n",
    "                    date_start:date_end\n",
    "                ]\n",
    "            except KeyError:\n",
    "                result[ticker] = pd.DataFrame()\n",
    "        return result\n",
    "\n",
    "    elif return_format == \"separate\":\n",
    "        result = []\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result.append(\n",
    "                    filtered_data.xs(ticker, level=0).loc[date_start:date_end]\n",
    "                )\n",
    "            except KeyError:\n",
    "                result.append(pd.DataFrame())\n",
    "        return result\n",
    "\n",
    "    elif return_format == \"dataframe\":\n",
    "        return filtered_data\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Invalid return_format: {return_format}. \"\n",
    "            f\"Must be 'dataframe', 'dict', or 'separate'\"\n",
    "        )\n",
    "\n",
    "\n",
    "def get_ticker_features(\n",
    "    features_df: pd.DataFrame,\n",
    "    tickers: Union[str, List[str]],\n",
    "    date_start: str,\n",
    "    date_end: str,\n",
    "    return_format: str = \"dataframe\",\n",
    "    verbose: bool = True,\n",
    ") -> Union[pd.DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    Get features data for specified tickers within a date range.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    features_df : pd.DataFrame\n",
    "        DataFrame with MultiIndex of (ticker, date) and feature columns\n",
    "    tickers : str or list of str\n",
    "        Ticker symbol(s) to retrieve\n",
    "    date_start : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    date_end : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    return_format : str, optional\n",
    "        Format to return data in. Options:\n",
    "        - 'dataframe': Single DataFrame with MultiIndex (default)\n",
    "        - 'dict': Dictionary with tickers as keys and DataFrames as values\n",
    "        - 'separate': List of separate DataFrames for each ticker\n",
    "    verbose : bool, optional\n",
    "        Whether to print summary information (default: True)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Union[pd.DataFrame, dict, list]\n",
    "        Filtered features data in specified format\n",
    "    \"\"\"\n",
    "    # Convert single ticker to list for consistent processing\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "\n",
    "    # Filter the data using MultiIndex slicing\n",
    "    try:\n",
    "        filtered_data = features_df.loc[(tickers, slice(date_start, date_end)), :]\n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"Error filtering data: {e}\")\n",
    "        return pd.DataFrame() if return_format == \"dataframe\" else {}\n",
    "\n",
    "    # Handle empty results\n",
    "    if filtered_data.empty:\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"No data found for tickers {tickers} in date range {date_start} to {date_end}\"\n",
    "            )\n",
    "        return filtered_data\n",
    "\n",
    "    # Print summary if verbose\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"Features data retrieved for {len(tickers)} ticker(s) from {date_start} to {date_end}\"\n",
    "        )\n",
    "        print(f\"Total rows: {len(filtered_data)}\")\n",
    "        print(\n",
    "            f\"Date range in data: {filtered_data.index.get_level_values(1).min()} to \"\n",
    "            f\"{filtered_data.index.get_level_values(1).max()}\"\n",
    "        )\n",
    "        print(f\"Available features: {', '.join(filtered_data.columns.tolist())}\")\n",
    "\n",
    "        # Print ticker-specific counts\n",
    "        ticker_counts = filtered_data.index.get_level_values(0).value_counts()\n",
    "        for ticker in tickers:\n",
    "            count = ticker_counts.get(ticker, 0)\n",
    "            if count > 0:\n",
    "                print(f\"  {ticker}: {count} rows\")\n",
    "            else:\n",
    "                print(f\"  {ticker}: No data in range\")\n",
    "\n",
    "    # Return in requested format\n",
    "    if return_format == \"dict\":\n",
    "        result = {}\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result[ticker] = filtered_data.xs(ticker, level=0).loc[\n",
    "                    date_start:date_end\n",
    "                ]\n",
    "            except KeyError:\n",
    "                result[ticker] = pd.DataFrame()\n",
    "        return result\n",
    "\n",
    "    elif return_format == \"separate\":\n",
    "        result = []\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result.append(\n",
    "                    filtered_data.xs(ticker, level=0).loc[date_start:date_end]\n",
    "                )\n",
    "            except KeyError:\n",
    "                result.append(pd.DataFrame())\n",
    "        return result\n",
    "\n",
    "    elif return_format == \"dataframe\":\n",
    "        return filtered_data\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Invalid return_format: {return_format}. \"\n",
    "            f\"Must be 'dataframe', 'dict', or 'separate'\"\n",
    "        )\n",
    "\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65fb6f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded .env from: c:\\Users\\ping\\Files_win10\\python\\py311\\.env\\my_api_key.env\n"
     ]
    }
   ],
   "source": [
    "# Usage in any notebook:\n",
    "data_ohlcv_path, data_indices_path = load_env_and_get_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "131cfab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_ohlcv:\n",
      "                   Adj Open  Adj High  Adj Low  Adj Close    Volume\n",
      "Ticker Date                                                        \n",
      "A      1999-11-18   27.1966   29.8864  23.9091    26.3000  74849954\n",
      "       1999-11-19   25.6649   25.7023  23.7970    24.1333  18230876\n",
      "       1999-11-22   24.6936   26.3000  23.9465    26.3000   7871810\n",
      "       1999-11-23   25.4034   26.0759  23.9091    23.9091   7151080\n",
      "       1999-11-24   23.9838   25.0672  23.9091    24.5442   5795947\n",
      "...                     ...       ...      ...        ...       ...\n",
      "ZWS    2026-02-12   52.5800   53.1700  51.1700    51.3800    956200\n",
      "       2026-02-13   51.2400   51.5700  50.7200    51.3000    768600\n",
      "       2026-02-17   51.3800   51.4900  50.5600    51.1200    793500\n",
      "       2026-02-18   50.7700   51.7800  50.6600    51.2100    667200\n",
      "       2026-02-19   50.8400   51.1550  50.5000    50.9100    379762\n",
      "\n",
      "[9503519 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df_ohlcv = pd.read_parquet(data_ohlcv_path, engine=\"pyarrow\")\n",
    "print(f\"df_ohlcv:\\n{df_ohlcv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "909370c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_indices:\n",
      "                   Adj Open  Adj High  Adj Low  Adj Close  Volume\n",
      "Ticker Date                                                      \n",
      "^AXJO  1992-11-22   1455.00   1455.00  1455.00    1455.00       0\n",
      "       1992-11-23   1458.40   1458.40  1458.40    1458.40       0\n",
      "       1992-11-24   1467.90   1467.90  1467.90    1467.90       0\n",
      "       1992-11-25   1459.00   1459.00  1459.00    1459.00       0\n",
      "       1992-11-26   1458.90   1458.90  1458.90    1458.90       0\n",
      "...                     ...       ...      ...        ...     ...\n",
      "^VIX3M 2026-02-12     20.19     22.35    20.03      22.17       0\n",
      "       2026-02-13     22.24     23.01    21.06      22.17       0\n",
      "       2026-02-17     22.52     23.18    21.33      21.60       0\n",
      "       2026-02-18     21.55     21.72    20.73      21.39       0\n",
      "       2026-02-19     21.86     22.37    21.71      21.88       0\n",
      "\n",
      "[144200 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df_indices = pd.read_parquet(data_indices_path, engine=\"pyarrow\")\n",
    "print(f\"df_indices:\\n{df_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "450ce16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Takes about 2.5 minutes to generate_features\n",
      "⚡ Generating Decoupled Features (Benchmark: SPY)...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Takes about 2.5 minutes to generate_features\")\n",
    "\n",
    "features_df, macro_df = generate_features(\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    df_indices=df_indices,\n",
    "    benchmark_ticker=\"SPY\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7856e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_ranges with same volume: 668\n",
      "['AA', 'AAON', 'ABEV', 'ACGL', 'ACWX', 'ADC', 'ADI', 'ADSK', 'AEG', 'AEIS', 'AEM', 'AEP', 'AFG', 'AFL', 'AG', 'AGCO', 'AGI', 'AIG', 'AIRR', 'AIT', 'AJG', 'ALLY', 'AMAT', 'AMCR', 'AME', 'AMG', 'AMGN', 'AN', 'AOS', 'APA', 'APH', 'ARE', 'ARGX', 'ARKK', 'ARWR', 'ASR', 'ASTS', 'ASX', 'ATO', 'ATR', 'AVB', 'AVDE', 'AVDV', 'AVY', 'AXP', 'AZN', 'BAC', 'BALL', 'BAP', 'BBAX', 'BBEU', 'BBIN', 'BBJP', 'BBVA', 'BBY', 'BCE', 'BCH', 'BCS', 'BDX', 'BEN', 'BEP', 'BF-A', 'BF-B', 'BHP', 'BIIB', 'BIL', 'BIO', 'BK', 'BKLC', 'BLD', 'BMO', 'BN', 'BNS', 'BNT', 'BOKF', 'BOXX', 'BP', 'BPOP', 'BRK-A', 'BRO', 'BSAC', 'BSCQ', 'BSCR', 'BTI', 'BVN', 'BWA', 'BYD', 'C', 'CACI', 'CADE', 'CAE', 'CAG', 'CAH', 'CASY', 'CB', 'CBSH', 'CCJ', 'CCK', 'CDE', 'CDNS', 'CDP', 'CEF', 'CELH', 'CFR', 'CHD', 'CHDN', 'CHT', 'CHTR', 'CIB', 'CIGI', 'CINF', 'CLF', 'CLH', 'CM', 'CMA', 'CMC', 'CMCSA', 'CMI', 'CMS', 'CNA', 'CNP', 'COHR', 'COKE', 'COLB', 'COO', 'CORT', 'COWZ', 'CP', 'CPB', 'CPRT', 'CRH', 'CRK', 'CRS', 'CSGP', 'CSL', 'CTAS', 'CTRA', 'CVE', 'CVS', 'CW', 'CYBR', 'DAY', 'DB', 'DBEF', 'DCI', 'DDS', 'DECK', 'DHI', 'DHR', 'DINO', 'DIS', 'DIVO', 'DKNG', 'DLTR', 'DOC', 'DOV', 'DRS', 'DSGX', 'DSI', 'DTE', 'DVN', 'DXJ', 'DY', 'DYNF', 'E', 'EAGG', 'ECL', 'ED', 'EDV', 'EFAV', 'EFX', 'EGP', 'EHC', 'EIX', 'EMA', 'EMB', 'EME', 'EMXC', 'ENB', 'EOG', 'EQR', 'EQT', 'ERIC', 'ERIE', 'ES', 'ESAB', 'ESGD', 'ESGE', 'ESGU', 'ESLT', 'ESS', 'ETN', 'ETR', 'EUFN', 'EVRG', 'EWT', 'EWY', 'EWZ', 'EXC', 'EXP', 'EXPD', 'EZU', 'FAST', 'FCFS', 'FCNCA', 'FDN', 'FDS', 'FDX', 'FER', 'FERG', 'FEZ', 'FHN', 'FICO', 'FISV', 'FITB', 'FIX', 'FLOT', 'FLS', 'FLUT', 'FNV', 'FRHC', 'FRT', 'FSEC', 'FSS', 'FTCS', 'FTS', 'FTSM', 'GAP', 'GBIL', 'GBTC', 'GD', 'GE', 'GEN', 'GFI', 'GGG', 'GIB', 'GIL', 'GILD', 'GL', 'GMAB', 'GOVT', 'GPN', 'GRID', 'GSK', 'GWW', 'HALO', 'HAS', 'HBAN', 'HBM', 'HD', 'HEFA', 'HEI', 'HEI-A', 'HIMS', 'HMC', 'HMY', 'HOLX', 'HON', 'HPQ', 'HRL', 'HSY', 'HUBB', 'HWM', 'IAGG', 'IBKR', 'IBM', 'ICL', 'ICLR', 'ICSH', 'IDA', 'IDCC', 'IDEV', 'IDV', 'IDXX', 'IEI', 'IESC', 'IEX', 'IFF', 'IGIB', 'IGM', 'IGSB', 'IGV', 'IHG', 'IJJ', 'IJK', 'IJR', 'IJS', 'IJT', 'IMO', 'INCY', 'INDA', 'ING', 'INGR', 'IONS', 'IOO', 'IQLT', 'IRM', 'ISTB', 'ITOT', 'ITW', 'IUSB', 'IUSG', 'IUSV', 'IVW', 'IVZ', 'IWB', 'IWN', 'IWP', 'IWR', 'IWS', 'IWY', 'IX', 'IXJ', 'IXN', 'IXUS', 'IYF', 'IYR', 'IYW', 'J', 'JAAA', 'JAVA', 'JAZZ', 'JBHT', 'JBL', 'JCPB', 'JEF', 'JGLO', 'JHMM', 'JHX', 'JKHY', 'JLL', 'JMBS', 'JMST', 'JMUB', 'JNJ', 'JPST', 'JQUA', 'KEP', 'KGC', 'KIM', 'KLAC', 'KMB', 'KNX', 'KO', 'KR', 'KWEB', 'L', 'LAD', 'LECO', 'LEN', 'LFUS', 'LH', 'LLY', 'LMBS', 'LMT', 'LNC', 'LNG', 'LNT', 'LOGI', 'LOW', 'LRCX', 'LUMN', 'MBB', 'MCD', 'MCHI', 'MCO', 'MDT', 'MDY', 'MGA', 'MGM', 'MHK', 'MIDD', 'MKC', 'MKL', 'MLI', 'MLM', 'MMC', 'MNST', 'MO', 'MOD', 'MOG-A', 'MRK', 'MSI', 'MT', 'MTB', 'MTCH', 'MTUM', 'MTZ', 'MU', 'NBIX', 'NDAQ', 'NDSN', 'NEE', 'NEU', 'NFG', 'NI', 'NKE', 'NLY', 'NNN', 'NTAP', 'NTES', 'NTRA', 'NTRS', 'NUE', 'NVDL', 'NVMI', 'NVO', 'NVR', 'NVS', 'NWG', 'NYT', 'OBDC', 'ODFL', 'OEF', 'OGE', 'OKE', 'OKLO', 'OMC', 'OMFL', 'ONB', 'ONTO', 'ORI', 'ORLY', 'OSK', 'PAAA', 'PAC', 'PAVE', 'PAYX', 'PB', 'PBA', 'PBUS', 'PCAR', 'PDBC', 'PEGA', 'PEP', 'PFE', 'PG', 'PGR', 'PH', 'PHG', 'PHM', 'PJT', 'PNC', 'PNFP', 'PNR', 'PNW', 'POOL', 'PPC', 'PPG', 'PPL', 'PR', 'PRIM', 'PSA', 'PSO', 'PULS', 'PVAL', 'QBTS', 'QGEN', 'QUAL', 'QXO', 'QYLD', 'R', 'RBA', 'RCI', 'RDVY', 'RECS', 'REET', 'REG', 'REGN', 'RELX', 'RF', 'RGC', 'RGEN', 'RGLD', 'RGTI', 'RIO', 'RJF', 'RMD', 'RNR', 'ROL', 'ROP', 'RPM', 'RRC', 'RRX', 'RS', 'RSPT', 'RTO', 'RTX', 'RVTY', 'RWL', 'RY', 'SAN', 'SAP', 'SBS', 'SCCO', 'SCHO', 'SCHW', 'SCI', 'SDVY', 'SEIC', 'SF', 'SGOL', 'SGOV', 'SHEL', 'SHG', 'SHW', 'SIRI', 'SITM', 'SIVR', 'SJM', 'SLYV', 'SMMT', 'SMTC', 'SNA', 'SNN', 'SONY', 'SPAB', 'SPDW', 'SPGI', 'SPHY', 'SPMB', 'SPMD', 'SPMO', 'SPSM', 'SPTI', 'SPTL', 'SPTM', 'SPTS', 'SPXC', 'SPYD', 'SPYG', 'SPYI', 'SPYM', 'SPYV', 'SQM', 'SSB', 'SSD', 'STLA', 'STN', 'STRL', 'STT', 'SU', 'SUB', 'SUI', 'SUZ', 'SW', 'SWK', 'SWKS', 'SYK', 'SYY', 'TAP', 'TD', 'TECH', 'TECK', 'TEF', 'TER', 'TEVA', 'TFC', 'TFII', 'TFLO', 'TFPM', 'TGT', 'THRO', 'TLH', 'TLK', 'TLN', 'TM', 'TMO', 'TOL', 'TPL', 'TROW', 'TRP', 'TRV', 'TSCO', 'TSEM', 'TSN', 'TT', 'TTC', 'TTEK', 'TTWO', 'TU', 'TXN', 'TXT', 'TYL', 'UDR', 'UGI', 'UHAL', 'UHS', 'UL', 'UMBF', 'URBN', 'URTH', 'USB', 'USFR', 'USHY', 'USIG', 'USMV', 'UWMC', 'VB', 'VBK', 'VBR', 'VCLT', 'VCR', 'VDC', 'VFC', 'VFH', 'VFLO', 'VFS', 'VG', 'VGIT', 'VGLT', 'VGSH', 'VGT', 'VIS', 'VIV', 'VLO', 'VLUE', 'VLY', 'VMBS', 'VMC', 'VMI', 'VNO', 'VO', 'VONE', 'VONG', 'VONV', 'VOOG', 'VOOV', 'VOX', 'VPL', 'VPU', 'VRT', 'VRTX', 'VTR', 'VTRS', 'VUG', 'VV', 'VXF', 'WAB', 'WBS', 'WCN', 'WDC', 'WDS', 'WELL', 'WF', 'WFC', 'WM', 'WMB', 'WMT', 'WRB', 'WSM', 'WSO', 'WST', 'WTFC', 'WTRG', 'WTS', 'WWD', 'XAR', 'XEL', 'XLG', 'XLI', 'XLRE', 'XMHQ', 'XMMO', 'XPO', 'YPF', 'ZBRA', 'ZION']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ticker\n",
       "AA       (1962-06-29 00:00:00, 1967-12-05 00:00:00)\n",
       "AAON     (1993-06-16 00:00:00, 2002-03-01 00:00:00)\n",
       "ABEV     (1997-09-02 00:00:00, 2010-12-30 00:00:00)\n",
       "ACGL     (1996-07-26 00:00:00, 2003-02-11 00:00:00)\n",
       "ACWX     (2008-09-26 00:00:00, 2009-06-18 00:00:00)\n",
       "ADC      (1994-10-13 00:00:00, 2002-02-20 00:00:00)\n",
       "ADI      (1981-05-05 00:00:00, 1991-10-04 00:00:00)\n",
       "ADSK     (1986-12-26 00:00:00, 1987-05-26 00:00:00)\n",
       "AEG      (1986-01-23 00:00:00, 1997-09-23 00:00:00)\n",
       "AEIS     (1996-11-26 00:00:00, 1998-04-21 00:00:00)\n",
       "AEM      (1974-03-26 00:00:00, 1997-05-22 00:00:00)\n",
       "AEP      (1974-04-22 00:00:00, 1975-01-02 00:00:00)\n",
       "AFG      (1981-07-22 00:00:00, 1996-10-24 00:00:00)\n",
       "AFL      (1984-08-28 00:00:00, 1985-08-26 00:00:00)\n",
       "AG       (2008-04-14 00:00:00, 2009-04-13 00:00:00)\n",
       "AGCO     (1992-10-14 00:00:00, 1994-05-04 00:00:00)\n",
       "AGI      (2003-10-29 00:00:00, 2013-11-14 00:00:00)\n",
       "AIG      (1973-07-02 00:00:00, 1981-03-13 00:00:00)\n",
       "AIRR     (2015-11-25 00:00:00, 2017-07-06 00:00:00)\n",
       "AIT      (1980-09-12 00:00:00, 2000-04-26 00:00:00)\n",
       "AJG      (1984-12-17 00:00:00, 1997-09-16 00:00:00)\n",
       "ALLY     (2014-07-28 00:00:00, 2015-04-09 00:00:00)\n",
       "AMAT     (1981-08-10 00:00:00, 1984-07-06 00:00:00)\n",
       "AMCR     (2012-11-13 00:00:00, 2020-06-08 00:00:00)\n",
       "AME      (1996-07-12 00:00:00, 1997-08-01 00:00:00)\n",
       "AMG      (1999-06-15 00:00:00, 1999-11-26 00:00:00)\n",
       "AMGN     (1983-12-14 00:00:00, 1986-03-11 00:00:00)\n",
       "AN       (1991-02-21 00:00:00, 1996-03-29 00:00:00)\n",
       "AOS      (1984-03-29 00:00:00, 1996-02-05 00:00:00)\n",
       "APA      (1985-04-02 00:00:00, 1986-11-10 00:00:00)\n",
       "APH      (1997-08-07 00:00:00, 1998-08-06 00:00:00)\n",
       "ARE      (1997-11-21 00:00:00, 1999-11-11 00:00:00)\n",
       "ARGX     (2017-11-14 00:00:00, 2018-09-17 00:00:00)\n",
       "ARKK     (2015-05-04 00:00:00, 2018-04-04 00:00:00)\n",
       "ARWR     (1994-06-16 00:00:00, 2005-09-22 00:00:00)\n",
       "ASR      (2002-12-23 00:00:00, 2003-12-22 00:00:00)\n",
       "ASTS     (2020-05-04 00:00:00, 2021-11-04 00:00:00)\n",
       "ASX      (2001-04-02 00:00:00, 2003-08-29 00:00:00)\n",
       "ATO      (1985-03-21 00:00:00, 1997-09-05 00:00:00)\n",
       "ATR      (1993-10-20 00:00:00, 1995-04-19 00:00:00)\n",
       "AVB      (1997-02-25 00:00:00, 1998-06-08 00:00:00)\n",
       "AVDE     (2020-08-31 00:00:00, 2020-10-05 00:00:00)\n",
       "AVDV     (2020-03-26 00:00:00, 2020-10-07 00:00:00)\n",
       "AVY      (1973-09-26 00:00:00, 1983-06-21 00:00:00)\n",
       "AXP      (1972-11-29 00:00:00, 1982-04-16 00:00:00)\n",
       "AZN      (2009-08-13 00:00:00, 2026-02-19 00:00:00)\n",
       "BAC      (1973-08-20 00:00:00, 1981-04-01 00:00:00)\n",
       "BALL     (1973-08-20 00:00:00, 1986-03-12 00:00:00)\n",
       "BAP      (1997-01-28 00:00:00, 2005-01-07 00:00:00)\n",
       "BBAX     (2019-02-08 00:00:00, 2019-08-12 00:00:00)\n",
       "BBEU     (2018-12-14 00:00:00, 2019-07-09 00:00:00)\n",
       "BBIN     (2020-06-09 00:00:00, 2021-03-03 00:00:00)\n",
       "BBJP     (2018-12-14 00:00:00, 2019-07-08 00:00:00)\n",
       "BBVA     (1989-06-15 00:00:00, 1998-04-07 00:00:00)\n",
       "BBY      (1986-12-17 00:00:00, 1991-08-16 00:00:00)\n",
       "BCE      (1983-05-13 00:00:00, 1991-12-26 00:00:00)\n",
       "BCH      (2003-01-31 00:00:00, 2007-08-14 00:00:00)\n",
       "BCS      (1987-03-09 00:00:00, 2001-12-31 00:00:00)\n",
       "BDX      (1976-01-15 00:00:00, 1980-01-31 00:00:00)\n",
       "BEN      (1984-03-22 00:00:00, 1986-09-15 00:00:00)\n",
       "BEP      (2006-05-17 00:00:00, 2013-12-24 00:00:00)\n",
       "BF-A     (1973-10-30 00:00:00, 2016-02-24 00:00:00)\n",
       "BF-B     (1980-09-12 00:00:00, 1986-10-23 00:00:00)\n",
       "BHP      (1980-09-15 00:00:00, 1997-12-22 00:00:00)\n",
       "BIIB     (1994-03-08 00:00:00, 2007-03-08 00:00:00)\n",
       "BIL      (2007-11-26 00:00:00, 2008-06-26 00:00:00)\n",
       "BIO      (1980-08-25 00:00:00, 2000-10-09 00:00:00)\n",
       "BK       (1973-10-30 00:00:00, 1984-08-23 00:00:00)\n",
       "BKLC     (2020-10-09 00:00:00, 2021-07-21 00:00:00)\n",
       "BLD      (2015-12-14 00:00:00, 2016-06-24 00:00:00)\n",
       "BMO      (1995-04-27 00:00:00, 2001-02-06 00:00:00)\n",
       "BN       (1984-06-28 00:00:00, 2001-10-26 00:00:00)\n",
       "BNS      (2002-12-24 00:00:00, 2003-12-23 00:00:00)\n",
       "BNT      (2024-03-18 00:00:00, 2025-08-25 00:00:00)\n",
       "BOKF     (1992-03-04 00:00:00, 2001-09-07 00:00:00)\n",
       "BOXX     (2023-06-29 00:00:00, 2024-01-24 00:00:00)\n",
       "BP       (1962-06-29 00:00:00, 1976-02-17 00:00:00)\n",
       "BPOP     (1980-09-12 00:00:00, 1994-07-25 00:00:00)\n",
       "BRK-A    (1980-09-12 00:00:00, 2007-02-12 00:00:00)\n",
       "BRO      (1981-08-11 00:00:00, 2000-08-10 00:00:00)\n",
       "BSAC     (1995-07-14 00:00:00, 2003-01-22 00:00:00)\n",
       "BSCQ     (2017-03-23 00:00:00, 2018-05-30 00:00:00)\n",
       "BSCR     (2018-03-28 00:00:00, 2019-05-23 00:00:00)\n",
       "BTI      (1980-10-09 00:00:00, 1995-10-12 00:00:00)\n",
       "BVN      (1997-01-10 00:00:00, 1998-01-08 00:00:00)\n",
       "BWA      (1994-07-28 00:00:00, 1995-07-26 00:00:00)\n",
       "BYD      (1994-11-02 00:00:00, 1999-04-09 00:00:00)\n",
       "C        (1981-03-31 00:00:00, 1982-03-29 00:00:00)\n",
       "CACI     (1980-09-12 00:00:00, 2000-06-14 00:00:00)\n",
       "CADE     (1986-04-14 00:00:00, 2026-02-18 00:00:00)\n",
       "CAE      (2003-01-27 00:00:00, 2004-08-27 00:00:00)\n",
       "CAG      (1980-09-12 00:00:00, 1984-12-11 00:00:00)\n",
       "CAH      (1984-02-01 00:00:00, 1990-02-08 00:00:00)\n",
       "CASY     (1984-04-18 00:00:00, 1993-10-05 00:00:00)\n",
       "CB       (1994-08-17 00:00:00, 1995-08-15 00:00:00)\n",
       "CBSH     (1980-09-12 00:00:00, 1994-09-19 00:00:00)\n",
       "CCJ      (1996-09-11 00:00:00, 2001-08-13 00:00:00)\n",
       "CCK      (1981-03-13 00:00:00, 1982-12-16 00:00:00)\n",
       "CDE      (1981-08-10 00:00:00, 1986-03-12 00:00:00)\n",
       "CDNS     (1988-04-29 00:00:00, 1989-12-21 00:00:00)\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filter where RollingSameVolCount is non-zero AND not NaN\n",
    "nonzero_samevol = features_df[\n",
    "    (features_df[\"RollingSameVolCount\"] > 0) & (features_df[\"RollingStalePct\"] > 0)\n",
    "]\n",
    "\n",
    "# Get unique tickers\n",
    "tickers_with_samevol = nonzero_samevol.index.get_level_values(0).unique()\n",
    "print(f\"date_ranges with same volume: {len(tickers_with_samevol)}\")\n",
    "print(tickers_with_samevol.tolist())\n",
    "\n",
    "# Get date range per ticker\n",
    "date_ranges = nonzero_samevol.groupby(level=0).apply(\n",
    "    lambda x: (x.index.get_level_values(1).min(), x.index.get_level_values(1).max())\n",
    ")\n",
    "\n",
    "# import pandas as pd\n",
    "# pd.set_option(\"display.max_rows\", 100)\n",
    "# print(date_ranges)\n",
    "display(date_ranges.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "064b0bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ticker: BNT\n",
      "Start date: 2024-03-18 00:00:00\n",
      "End date: 2025-08-25 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Find a ticker in data_ranges to download\n",
    "item = 73\n",
    "ticker = date_ranges.index[item]\n",
    "date_range = date_ranges.iloc[item]\n",
    "\n",
    "# Or unpack directly\n",
    "ticker, date_range = date_ranges.index[item], date_ranges.iloc[item]\n",
    "start_date = date_range[0]\n",
    "end_date = date_range[1]\n",
    "\n",
    "print(f\"ticker: {ticker}\")\n",
    "print(f\"Start date: {start_date}\")\n",
    "print(f\"End date: {end_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5607c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticker data to retrieve\n",
    "tickers = [ticker]\n",
    "\n",
    "# number of data rows to retrieve\n",
    "first_nrows = 300\n",
    "\n",
    "output_dir = \"output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60933384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating combined dictionary for 1 ticker(s)\n",
      "Date range: 2024-03-18 00:00:00 to None\n",
      "============================================================\n",
      "Data retrieved for 1 ticker(s) from 2024-03-18 00:00:00 to None\n",
      "Total rows: 483\n",
      "Date range in data: 2024-03-18 00:00:00 to 2026-02-19 00:00:00\n",
      "  BNT: 483 rows\n",
      "Features data retrieved for 1 ticker(s) from 2024-03-18 00:00:00 to None\n",
      "Total rows: 483\n",
      "Date range in data: 2024-03-18 00:00:00 to 2026-02-19 00:00:00\n",
      "Available features: ATR, ATRP, TRP, RSI, Mom_21, Consistency, IR_63, Beta_63, DD_21, Ret_1d, RollingStalePct, RollMedDollarVol, RollingSameVolCount\n",
      "  BNT: 483 rows\n",
      "\n",
      "Processing BNT...\n",
      "  ✓ Successfully combined data\n",
      "  OHLCV shape: (483, 5)\n",
      "  Features shape: (483, 13)\n",
      "  Combined shape: (483, 18)\n",
      "  Date range: 2024-03-18 00:00:00 to 2026-02-19 00:00:00\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "Total tickers processed: 1\n",
      "Tickers with combined data: 1\n",
      "\n",
      "Ticker details:\n",
      "  BNT: (483, 18) - 2024-03-18 00:00:00 to 2026-02-19 00:00:00\n",
      "    Columns: 18\n"
     ]
    }
   ],
   "source": [
    "# 3. Generate the combined dict\n",
    "combined = create_combined_dict(\n",
    "    df_ohlcv=df_ohlcv.copy(),\n",
    "    features_df=features_df,\n",
    "    tickers=tickers,\n",
    "    date_start=start_date,\n",
    "    date_end=None,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c37b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_path: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_RLVR\\output\\combined_BNT_with_SPY_head(300).csv\n"
     ]
    }
   ],
   "source": [
    "# # Export to CSV in the output directory\n",
    "f_name = f\"combined_{ticker}_with_SPY_head({first_nrows}).csv\"\n",
    "file_path = os.path.join(OUTPUT_DIR, f_name)\n",
    "print(f\"file_path: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ff7cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 483 entries, 2024-03-18 to 2026-02-19\n",
      "Data columns (total 19 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Adj Open             483 non-null    float64\n",
      " 1   Adj High             483 non-null    float64\n",
      " 2   Adj Low              483 non-null    float64\n",
      " 3   Adj Close            483 non-null    float64\n",
      " 4   Volume               483 non-null    int64  \n",
      " 5   ATR                  483 non-null    float64\n",
      " 6   ATRP                 483 non-null    float64\n",
      " 7   TRP                  483 non-null    float64\n",
      " 8   RSI                  483 non-null    float64\n",
      " 9   Mom_21               483 non-null    float64\n",
      " 10  Consistency          483 non-null    float64\n",
      " 11  IR_63                483 non-null    float64\n",
      " 12  Beta_63              483 non-null    float64\n",
      " 13  DD_21                483 non-null    float64\n",
      " 14  Ret_1d               483 non-null    float64\n",
      " 15  RollingStalePct      483 non-null    float64\n",
      " 16  RollMedDollarVol     483 non-null    float64\n",
      " 17  RollingSameVolCount  483 non-null    float64\n",
      " 18  SPY_Adj_Close        483 non-null    float64\n",
      "dtypes: float64(18), int64(1)\n",
      "memory usage: 75.5 KB\n",
      "None\n",
      "            Adj Open  Adj High  Adj Low  Adj Close  Volume     ATR    ATRP     TRP      RSI  Mom_21  Consistency   IR_63  Beta_63   DD_21  Ret_1d  RollingStalePct  RollMedDollarVol  RollingSameVolCount  SPY_Adj_Close\n",
      "Date                                                                                                                                                                                                                    \n",
      "2024-03-18   27.0415   27.0415  27.0415    27.0415    1665  0.4590  0.0170  0.0011  50.7604  0.0154          0.2 -0.0500   1.0429 -0.0272 -0.0011           0.0040       230685.8715                  1.0        502.042\n",
      "2024-03-19   27.1438   27.1438  27.1438    27.1438    1968  0.4336  0.0160  0.0038  52.3643  0.0231          0.4 -0.0361   1.0291 -0.0235  0.0038           0.0079       230586.4687                  1.0        504.832\n",
      "2024-03-20   27.3069   27.7975  27.3069    27.7975    2574  0.4493  0.0162  0.0235  61.0871  0.0454          0.4 -0.0035   1.0772  0.0000  0.0241           0.0079       230248.5897                  1.0        509.502\n",
      "2024-03-21   27.7909   28.4380  27.7909    28.1739   10601  0.4634  0.0164  0.0230  65.0550  0.0696          0.6 -0.0104   1.0611  0.0000  0.0135           0.0079       230248.5897                  1.0        511.185\n",
      "2024-03-22   27.7975   27.8041  27.7117    27.7447    3029  0.4633  0.0167  0.0167  57.8155  0.0228          0.6 -0.0609   1.2074 -0.0152 -0.0152           0.0079       230248.5897                  1.0        510.216\n",
      "...              ...       ...      ...        ...     ...     ...     ...     ...      ...     ...          ...     ...      ...     ...     ...              ...               ...                  ...            ...\n",
      "2025-05-21   38.7702   38.9863  37.9326    37.9392   27828  0.9789  0.0258  0.0305  55.3978  0.1412          0.4  0.0162   1.3889 -0.0429 -0.0294           0.0119       431297.2261                  1.0        577.828\n",
      "2025-05-22   37.6002   38.1586  37.6002    37.8927   10078  0.9489  0.0250  0.0147  55.0782  0.1168          0.2  0.0147   1.3924 -0.0441 -0.0012           0.0079       431297.2261                  1.0        578.056\n",
      "2025-05-23   37.7863   38.1586  37.7863    37.9991   20457  0.9077  0.0239  0.0098  55.7079  0.0789          0.2  0.0364   1.3882 -0.0414  0.0028           0.0079       438324.7125                  1.0        574.110\n",
      "2025-05-27   38.3381   38.7170  38.3381    38.6639   12786  0.8942  0.0231  0.0186  59.5257  0.0932          0.4  0.0321   1.3799 -0.0247  0.0175           0.0079       438324.7125                  1.0        586.046\n",
      "2025-05-28   38.7237   38.7237  38.2384    38.3182    7069  0.8650  0.0226  0.0127  56.7847  0.0822          0.4  0.0307   1.3802 -0.0334 -0.0089           0.0079       431297.2261                  1.0        582.656\n",
      "\n",
      "[300 rows x 19 columns]\n",
      "file saved as: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_RLVR\\output\\combined_BNT_with_SPY_head(300).csv\n"
     ]
    }
   ],
   "source": [
    "# Get SPY's Adj Close and rename\n",
    "spy_close = df_ohlcv.loc[\"SPY\"][[\"Adj Close\"]].rename(\n",
    "    columns={\"Adj Close\": \"SPY_Adj_Close\"}\n",
    ")\n",
    "\n",
    "# Left join: keeps only dates from combined[ticker]\n",
    "combined_with_spy = combined[ticker].join(spy_close, how=\"left\")\n",
    "\n",
    "# Verify\n",
    "print(combined_with_spy.info())\n",
    "print(combined_with_spy.head(first_nrows))\n",
    "\n",
    "\n",
    "# Export to CSV in the output directory\n",
    "f_name = f\"combined_{ticker}_with_SPY_head({first_nrows}).csv\"\n",
    "combined_with_spy.head(first_nrows).to_csv(\n",
    "    file_path,\n",
    "    index=True,  # Set to True if you want to keep the index\n",
    ")\n",
    "print(f\"file saved as: {file_path}\")\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26376cef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
