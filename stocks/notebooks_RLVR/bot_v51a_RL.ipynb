{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "import ipywidgets as widgets\n",
        "\n",
        "from dataclasses import dataclass, field, asdict, is_dataclass\n",
        "from typing import List, Dict, Optional, Any, Union, TypedDict, Tuple\n",
        "from collections import Counter\n",
        "from datetime import datetime, date\n",
        "from pandas.testing import assert_series_equal\n",
        "\n",
        "\n",
        "# pd.set_option('display.max_rows', None)  display all rows\n",
        "pd.set_option(\"display.max_rows\", 100)\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "pd.set_option(\"display.width\", 1000)\n",
        "pd.set_option(\"display.max_colwidth\", 50)\n",
        "pd.set_option(\"display.precision\", 4)\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# GLOBAL SETTINGS: The \"Control Panel\" for the Strategy\n",
        "# ==============================================================================\n",
        "\n",
        "GLOBAL_SETTINGS = {\n",
        "    # ENVIRONMENT (The \"Where\")\n",
        "    \"benchmark_ticker\": \"SPY\",\n",
        "    \"calendar_ticker\": \"SPY\",  # Used as the \"Master Clock\" for trading days\n",
        "    # DATA SANITIZER (The \"Glitches & Gaps\" Protector)\n",
        "    \"handle_zeros_as_nan\": True,  # Convert 0.0 prices to NaN to prevent math errors\n",
        "    \"max_data_gap_ffill\": 1,  # Max consecutive days to \"Forward Fill\" missing data\n",
        "    # IMPLICATION OF nan_price_replacement:\n",
        "    # - This defines what happens if the \"Forward Fill\" limit is exceeded.\n",
        "    # - If set to 0.0: A permanent data gap will look like a \"total loss\" (-100%).\n",
        "    #   The equity curve will plummet. Good for \"disaster detection.\"\n",
        "    #   Sharpe and Sharpe(ATR) drop because: return (gets smaller) / std (gets larger)\n",
        "    # - If set to np.nan: A permanent gap will cause portfolio calculations to return NaN.\n",
        "    #   The chart may break or show gaps. Good for \"math integrity.\"\n",
        "    \"nan_price_replacement\": 0.0,\n",
        "    # STRATEGY PARAMETERS (The \"How\")\n",
        "    \"atr_period\": 14,  # Used for volatility normalization\n",
        "    \"quality_window\": 252,  # 1 year lookback for liquidity/quality stats\n",
        "    \"quality_min_periods\": 126,  # Min history required to judge a stock\n",
        "    # QUALITY THRESHOLDS (The \"Rules\")\n",
        "    \"thresholds\": {\n",
        "        # HARD LIQUIDITY FLOOR\n",
        "        # Logic: Calculates (Adj Close * Volume) daily, then takes the ROLLING MEDIAN\n",
        "        # over the quality_window (252 days). Filters out stocks where the\n",
        "        # typical daily dollar turnover is below this absolute value.\n",
        "        \"min_median_dollar_volume\": 1_000_000,\n",
        "        # DYNAMIC LIQUIDITY CUTOFF (Relative to Universe)\n",
        "        # Logic: On the decision date, the engine calculates the X-quantile\n",
        "        # of 'RollMedDollarVol' across ALL available stocks.\n",
        "        # Setting this to 0.40 calculates the 60th percentile and requires\n",
        "        # stocks to be above it‚Äîeffectively keeping only the TOP 60% of the market.\n",
        "        \"min_liquidity_percentile\": 0.40,\n",
        "        # PRICE/VOLUME STALENESS\n",
        "        # Logic: Creates a binary flag (1 if Volume is 0 OR High equals Low).\n",
        "        # It then calculates the ROLLING MEAN of this flag.\n",
        "        # A value of 0.05 means the stock is rejected if it was \"stale\"\n",
        "        # for more than 5% of the trading days in the rolling window.\n",
        "        \"max_stale_pct\": 0.05,\n",
        "        # DATA INTEGRITY (FROZEN VOLUME)\n",
        "        # Logic: Checks if Volume is identical to the previous day (Volume.diff() == 0).\n",
        "        # It calculates the ROLLING SUM of these occurrences over the window.\n",
        "        # If the exact same volume is reported more than 10 times, the stock\n",
        "        # is rejected as having \"frozen\" or low-quality data.\n",
        "        \"max_same_vol_count\": 10,\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# SECTION A: CORE KERNELS & QUANT UTILITIES (THE SAFE ROOM)\n",
        "# ==============================================================================\n",
        "\n",
        "\n",
        "class QuantUtils:\n",
        "    \"\"\"\n",
        "    MATHEMATICAL KERNEL REGISTRY: THE SINGLE SOURCE OF TRUTH.\n",
        "    !!! DANGER: DO NOT REFACTOR NULL HANDLING !!!\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_returns(\n",
        "        series: Union[pd.Series, pd.DataFrame],\n",
        "    ) -> Union[pd.Series, pd.DataFrame]:\n",
        "        # 1. Calculate raw percentage change\n",
        "        returns_WITH_BOUNDARY_NAN = series.pct_change()\n",
        "\n",
        "        # 2. THE AI-PROOF GUARDRAIL (ROBUST VERSION)\n",
        "        if len(returns_WITH_BOUNDARY_NAN) > 0:\n",
        "            # We look at the first observation (scalar for Series, row for DataFrame)\n",
        "            first_obs = returns_WITH_BOUNDARY_NAN.iloc[0]\n",
        "\n",
        "            # np.all handles both a single True/False AND a list of True/False\n",
        "            if not np.all(pd.isna(first_obs)):\n",
        "                raise AssertionError(\n",
        "                    \"!!! REGRESSION: Leading NaN boundary was destroyed !!!\"\n",
        "                )\n",
        "\n",
        "        # 3. Numerical Stability replacement\n",
        "        if isinstance(returns_WITH_BOUNDARY_NAN, (pd.Series, pd.DataFrame)):\n",
        "            returns_WITH_BOUNDARY_NAN = returns_WITH_BOUNDARY_NAN.replace(\n",
        "                [np.inf, -np.inf], np.nan\n",
        "            )\n",
        "\n",
        "        return returns_WITH_BOUNDARY_NAN\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_total_gain(price_series: pd.Series) -> float:\n",
        "        clean = price_series.dropna()\n",
        "        if len(clean) < 2:\n",
        "            return 0.0\n",
        "        res = (clean.iloc[-1] / clean.iloc[0]) - 1\n",
        "        return float(res) if np.isfinite(res) else 0.0\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_sharpe(\n",
        "        returns_WITH_BOUNDARY_NAN: pd.Series, periods: int = 252\n",
        "    ) -> float:\n",
        "        mu, std = returns_WITH_BOUNDARY_NAN.mean(), returns_WITH_BOUNDARY_NAN.std()\n",
        "        if pd.isna(std) or std < 1e-8:\n",
        "            return 0.0\n",
        "        return float((mu / std) * np.sqrt(periods))\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_sharpe_atr(\n",
        "        returns_WITH_BOUNDARY_NAN: pd.Series, atrp_series: pd.Series\n",
        "    ) -> float:\n",
        "        avg_atrp = atrp_series.mean()\n",
        "        if pd.isna(avg_atrp) or avg_atrp < 1e-8:\n",
        "            return 0.0\n",
        "        return float(returns_WITH_BOUNDARY_NAN.mean() / avg_atrp)\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# SECTION B: STRATEGY HELPERS & FEATURES\n",
        "# ==============================================================================\n",
        "# ... (Keep generate_features, calculate_gain, calculate_sharpe,\n",
        "#      calculate_sharpe_atr, calculate_buy_and_hold_performance as is) ...\n",
        "\n",
        "\n",
        "def generate_features(\n",
        "    df_ohlcv: pd.DataFrame,\n",
        "    df_indices: pd.DataFrame = None,\n",
        "    benchmark_ticker: str = \"SPY\",\n",
        "    atr_period: int = 14,\n",
        "    rsi_period: int = 14,\n",
        "    quality_window: int = 252,\n",
        "    quality_min_periods: int = 126,\n",
        ") -> pd.DataFrame:\n",
        "\n",
        "    print(f\"‚ö° Generating SOTA Quant Features (Benchmark: {benchmark_ticker})...\")\n",
        "\n",
        "    # 1. Sort and Group\n",
        "    if not df_ohlcv.index.is_monotonic_increasing:\n",
        "        df_ohlcv = df_ohlcv.sort_index()\n",
        "    grouped = df_ohlcv.groupby(level=\"Ticker\")\n",
        "\n",
        "    # 2. VECTORIZED ATR (Wilder's)\n",
        "    prev_close = grouped[\"Adj Close\"].shift(1)\n",
        "    high_low = df_ohlcv[\"Adj High\"] - df_ohlcv[\"Adj Low\"]\n",
        "    high_prev = abs(df_ohlcv[\"Adj High\"] - prev_close)\n",
        "    low_prev = abs(df_ohlcv[\"Adj Low\"] - prev_close)\n",
        "    tr = pd.concat([high_low, high_prev, low_prev], axis=1).max(axis=1, skipna=False)\n",
        "\n",
        "    atr = (\n",
        "        tr.groupby(level=\"Ticker\")\n",
        "        .ewm(alpha=1 / atr_period, adjust=False)\n",
        "        .mean()\n",
        "        .reset_index(level=0, drop=True)\n",
        "    )\n",
        "    atrp = (atr / df_ohlcv[\"Adj Close\"]).replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    # 3. VECTORIZED RSI\n",
        "    delta = grouped[\"Adj Close\"].diff()\n",
        "    up = delta.clip(lower=0)\n",
        "    down = -1 * delta.clip(upper=0)\n",
        "\n",
        "    ma_up = (\n",
        "        up.groupby(level=\"Ticker\")\n",
        "        .ewm(alpha=1 / rsi_period, adjust=False)\n",
        "        .mean()\n",
        "        .reset_index(level=0, drop=True)\n",
        "    )\n",
        "    ma_down = (\n",
        "        down.groupby(level=\"Ticker\")\n",
        "        .ewm(alpha=1 / rsi_period, adjust=False)\n",
        "        .mean()\n",
        "        .reset_index(level=0, drop=True)\n",
        "    )\n",
        "\n",
        "    rsi = 100 - (100 / (1 + (ma_up / ma_down)))\n",
        "    rsi = rsi.replace([np.inf, -np.inf], 50).fillna(50)\n",
        "\n",
        "    # 4. OBV (Ticker Specific)\n",
        "    direction = np.sign(delta).fillna(0)\n",
        "    obv_raw = (direction * df_ohlcv[\"Volume\"]).groupby(level=\"Ticker\").cumsum()\n",
        "    obv_roll_mean = (\n",
        "        obv_raw.groupby(level=\"Ticker\")\n",
        "        .rolling(21)\n",
        "        .mean()\n",
        "        .reset_index(level=0, drop=True)\n",
        "    )\n",
        "    obv_roll_std = (\n",
        "        obv_raw.groupby(level=\"Ticker\")\n",
        "        .rolling(21)\n",
        "        .std()\n",
        "        .reset_index(level=0, drop=True)\n",
        "    )\n",
        "    obv_score = (\n",
        "        ((obv_raw - obv_roll_mean) / obv_roll_std)\n",
        "        .fillna(0.0)\n",
        "        .clip(lower=-5.0, upper=5.0)\n",
        "    )\n",
        "\n",
        "    # Dollar Volume\n",
        "    dollar_vol_series = df_ohlcv[\"Adj Close\"] * df_ohlcv[\"Volume\"]\n",
        "\n",
        "    # 5. BENCHMARK FEATURES (Price & Volume)\n",
        "    bench_close_series = None\n",
        "    bench_vol_series = None\n",
        "\n",
        "    found_bench = False\n",
        "    if (\n",
        "        df_indices is not None\n",
        "        and benchmark_ticker in df_indices.index.get_level_values(0)\n",
        "    ):\n",
        "        try:\n",
        "            bench_close_series = df_indices.xs(benchmark_ticker, level=0)[\"Adj Close\"]\n",
        "            bench_vol_series = df_indices.xs(benchmark_ticker, level=0)[\"Volume\"]\n",
        "            found_bench = True\n",
        "        except Exception:\n",
        "            pass\n",
        "    if not found_bench and benchmark_ticker in df_ohlcv.index.get_level_values(0):\n",
        "        try:\n",
        "            bench_close_series = df_ohlcv.xs(benchmark_ticker, level=0)[\"Adj Close\"]\n",
        "            bench_vol_series = df_ohlcv.xs(benchmark_ticker, level=0)[\"Volume\"]\n",
        "            found_bench = True\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # Initialize Containers\n",
        "    rel_strength_21 = pd.Series(0.0, index=df_ohlcv.index)\n",
        "    spy_rvol = pd.Series(1.0, index=df_ohlcv.index)\n",
        "    spy_obv_score = pd.Series(0.0, index=df_ohlcv.index)  # <--- NEW CONTAINER\n",
        "\n",
        "    if found_bench:\n",
        "        try:\n",
        "            # A. Relative Strength\n",
        "            bench_close_aligned = bench_close_series.reindex(\n",
        "                df_ohlcv.index.get_level_values(\"Date\")\n",
        "            ).values\n",
        "            rel_ratio = df_ohlcv[\"Adj Close\"] / bench_close_aligned\n",
        "            rel_strength_21 = (\n",
        "                rel_ratio.groupby(level=\"Ticker\")\n",
        "                .pct_change(21, fill_method=None)\n",
        "                .fillna(0.0)\n",
        "            )\n",
        "\n",
        "            # B. Spy RVol (Magnitude)\n",
        "            bench_dvol = bench_close_series * bench_vol_series\n",
        "            bench_dvol_avg = bench_dvol.rolling(21).mean()\n",
        "            bench_rvol_raw = (bench_dvol / bench_dvol_avg).fillna(1.0)\n",
        "\n",
        "            # C. SPY OBV Score (Direction) <--- NEW\n",
        "            # Calculate OBV for SPY specifically\n",
        "            spy_delta = bench_close_series.diff()\n",
        "            spy_direction = np.sign(spy_delta).fillna(0)\n",
        "            spy_obv_raw = (spy_direction * bench_vol_series).cumsum()\n",
        "\n",
        "            # Normalize SPY OBV (Z-Score)\n",
        "            spy_obv_mean = spy_obv_raw.rolling(21).mean()\n",
        "            spy_obv_std = spy_obv_raw.rolling(21).std()\n",
        "            spy_obv_z = (\n",
        "                ((spy_obv_raw - spy_obv_mean) / spy_obv_std)\n",
        "                .fillna(0.0)\n",
        "                .clip(lower=-5.0, upper=5.0)\n",
        "            )\n",
        "\n",
        "            # D. BROADCAST TO ALL TICKERS\n",
        "            # Reindex creates a Series aligned to the full DataFrame (Date-matched)\n",
        "            spy_rvol_values = (\n",
        "                bench_rvol_raw.reindex(df_ohlcv.index.get_level_values(\"Date\"))\n",
        "                .fillna(1.0)\n",
        "                .values\n",
        "            )\n",
        "            spy_obv_values = (\n",
        "                spy_obv_z.reindex(df_ohlcv.index.get_level_values(\"Date\"))\n",
        "                .fillna(0.0)\n",
        "                .values\n",
        "            )\n",
        "\n",
        "            spy_rvol = pd.Series(spy_rvol_values, index=df_ohlcv.index).clip(upper=10.0)\n",
        "            spy_obv_score = pd.Series(spy_obv_values, index=df_ohlcv.index)  # <--- NEW\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Benchmark Math Error: {e}\")\n",
        "\n",
        "    # 6. TICKER RELATIVE VOLUME (RVol)\n",
        "    dvol_grouped = dollar_vol_series.groupby(level=\"Ticker\")\n",
        "    dvol_avg = dvol_grouped.rolling(21).mean().reset_index(level=0, drop=True)\n",
        "    ticker_rvol = (\n",
        "        (dollar_vol_series / dvol_avg)\n",
        "        .replace([np.inf, -np.inf], 1.0)\n",
        "        .fillna(1.0)\n",
        "        .clip(upper=10.0)\n",
        "    )\n",
        "\n",
        "    # 7. MOMENTUM / RETURN FEATURES\n",
        "    daily_returns = grouped[\"Adj Close\"].pct_change(1, fill_method=None)\n",
        "    roc_1 = daily_returns\n",
        "    roc_3 = grouped[\"Adj Close\"].pct_change(3, fill_method=None)\n",
        "    roc_5 = grouped[\"Adj Close\"].pct_change(5, fill_method=None)\n",
        "    roc_10 = grouped[\"Adj Close\"].pct_change(10, fill_method=None)\n",
        "    roc_21 = grouped[\"Adj Close\"].pct_change(21, fill_method=None)\n",
        "\n",
        "    # 8. VOLATILITY REGIME\n",
        "    returns_grouped = daily_returns.groupby(level=\"Ticker\")\n",
        "    std_5 = returns_grouped.rolling(5).std().reset_index(level=0, drop=True)\n",
        "    std_21 = returns_grouped.rolling(21).std().reset_index(level=0, drop=True)\n",
        "\n",
        "    if std_5.index.nlevels > df_ohlcv.index.nlevels:\n",
        "        std_5 = std_5.reset_index(level=0, drop=True)\n",
        "        std_21 = std_21.reset_index(level=0, drop=True)\n",
        "\n",
        "    vol_regime = (std_5 / std_21).replace([np.inf, -np.inf], 1.0)\n",
        "\n",
        "    # 9. MERGE\n",
        "    indicator_df = pd.DataFrame(\n",
        "        {\n",
        "            \"ATR\": atr,\n",
        "            \"ATRP\": atrp,\n",
        "            \"RSI\": rsi,\n",
        "            \"RelStrength\": rel_strength_21,\n",
        "            \"VolRegime\": vol_regime,\n",
        "            \"RVol\": ticker_rvol,\n",
        "            \"Spy_RVol\": spy_rvol,\n",
        "            \"OBV_Score\": obv_score,\n",
        "            \"Spy_OBV_Score\": spy_obv_score,  # <--- NEW\n",
        "            \"ROC_1\": roc_1,\n",
        "            \"ROC_3\": roc_3,\n",
        "            \"ROC_5\": roc_5,\n",
        "            \"ROC_10\": roc_10,\n",
        "            \"ROC_21\": roc_21,\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # 10. Quality/Liquidity Features\n",
        "    quality_temp_df = pd.DataFrame(\n",
        "        {\n",
        "            \"IsStale\": np.where(\n",
        "                (df_ohlcv[\"Volume\"] == 0)\n",
        "                | (df_ohlcv[\"Adj High\"] == df_ohlcv[\"Adj Low\"]),\n",
        "                1,\n",
        "                0,\n",
        "            ),\n",
        "            \"DollarVolume\": dollar_vol_series,\n",
        "            \"HasSameVolume\": (grouped[\"Volume\"].diff() == 0).astype(int),\n",
        "        },\n",
        "        index=df_ohlcv.index,\n",
        "    )\n",
        "\n",
        "    rolling_result = (\n",
        "        quality_temp_df.groupby(level=\"Ticker\")\n",
        "        .rolling(window=quality_window, min_periods=quality_min_periods)\n",
        "        .agg({\"IsStale\": \"mean\", \"DollarVolume\": \"median\", \"HasSameVolume\": \"sum\"})\n",
        "        .rename(\n",
        "            columns={\n",
        "                \"IsStale\": \"RollingStalePct\",\n",
        "                \"DollarVolume\": \"RollMedDollarVol\",\n",
        "                \"HasSameVolume\": \"RollingSameVolCount\",\n",
        "            }\n",
        "        )\n",
        "        .reset_index(level=0, drop=True)\n",
        "    )\n",
        "\n",
        "    return pd.concat([indicator_df, rolling_result], axis=1)\n",
        "\n",
        "\n",
        "def verify_feature_engineering_integrity():\n",
        "    \"\"\"\n",
        "    üõ°Ô∏è TRIPWIRE: Validates Feature Engineering Logic.\n",
        "    Enforces:\n",
        "    1. Day 1 ATR must be NaN (No PrevClose).\n",
        "    2. Wilder's Smoothing must use Alpha = 1/Period.\n",
        "    3. Recursion must match manual calculation.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- üõ°Ô∏è Starting Feature Engineering Audit ---\")\n",
        "\n",
        "    # 1. Create Synthetic Data (3 Days)\n",
        "    # Day 1: High-Low = 10. No PrevClose.\n",
        "    # Day 2: High-Low = 20. Gap up implies TR might be larger.\n",
        "    # Day 3: High-Low = 10.\n",
        "    dates = pd.to_datetime([\"2020-01-01\", \"2020-01-02\", \"2020-01-03\"])\n",
        "    idx = pd.MultiIndex.from_product([[\"TEST\"], dates], names=[\"Ticker\", \"Date\"])\n",
        "\n",
        "    df_mock = pd.DataFrame(\n",
        "        {\n",
        "            \"Adj Open\": [100, 110, 110],\n",
        "            \"Adj High\": [110, 130, 120],\n",
        "            \"Adj Low\": [100, 110, 110],\n",
        "            \"Adj Close\": [105, 120, 115],  # PrevClose: NaN, 105, 120\n",
        "            \"Volume\": [1000, 1000, 1000],\n",
        "        },\n",
        "        index=idx,\n",
        "    )\n",
        "\n",
        "    # 2. Run the Generator\n",
        "    # We use Period=2 to make manual math easy (Alpha = 1/2 = 0.5)\n",
        "    feats = generate_features(\n",
        "        df_mock, atr_period=2, rsi_period=2, quality_min_periods=1\n",
        "    )\n",
        "    atr_series = feats[\"ATR\"]\n",
        "\n",
        "    # 3. MANUAL CALCULATION (The \"Truth\")\n",
        "    # Day 1:\n",
        "    #   TR = Max(H-L, |H-PC|, |L-PC|)\n",
        "    #   TR = Max(10, NaN, NaN) -> NaN (Because skipna=False)\n",
        "    #   Expected ATR: NaN\n",
        "\n",
        "    # Day 2:\n",
        "    #   PrevClose = 105\n",
        "    #   H-L=20, |130-105|=25, |110-105|=5\n",
        "    #   TR = 25\n",
        "    #   Expected ATR: First valid observation = 25.0\n",
        "\n",
        "    # Day 3:\n",
        "    #   PrevClose = 120\n",
        "    #   H-L=10, |120-120|=0, |110-120|=10\n",
        "    #   TR = 10\n",
        "    #   Wilder's Smoothing (Alpha=0.5):\n",
        "    #   ATR_3 = (TR_3 * alpha) + (ATR_2 * (1-alpha))\n",
        "    #   ATR_3 = (10 * 0.5) + (25 * 0.5) = 5 + 12.5 = 17.5\n",
        "\n",
        "    print(f\"Audit Values:\\n{atr_series.values}\")\n",
        "\n",
        "    # 4. ASSERTIONS\n",
        "    try:\n",
        "        # Check Day 1\n",
        "        if not np.isnan(atr_series.iloc[0]):\n",
        "            raise AssertionError(\n",
        "                f\"Day 1 Regression: Expected NaN, got {atr_series.iloc[0]}. (Check skipna=False)\"\n",
        "            )\n",
        "\n",
        "        # Check Day 2 (Initialization)\n",
        "        if not np.isclose(atr_series.iloc[1], 25.0):\n",
        "            raise AssertionError(\n",
        "                f\"Initialization Regression: Expected 25.0, got {atr_series.iloc[1]}.\"\n",
        "            )\n",
        "\n",
        "        # Check Day 3 (Recursion)\n",
        "        if not np.isclose(atr_series.iloc[2], 17.5):\n",
        "            raise AssertionError(\n",
        "                f\"Wilder's Logic Regression: Expected 17.5, got {atr_series.iloc[2]}. (Check Alpha=1/N)\"\n",
        "            )\n",
        "\n",
        "        print(\"‚úÖ FEATURE INTEGRITY PASSED: Wilder's ATR logic is strictly enforced.\")\n",
        "\n",
        "    except AssertionError as e:\n",
        "        print(f\"üî• LOGIC FAILURE: {str(e)}\")\n",
        "        raise e\n",
        "\n",
        "\n",
        "def _compute_vol_adjusted_performance(\n",
        "    prices: pd.DataFrame, atrp_matrix: pd.DataFrame, weights: pd.Series\n",
        ") -> Tuple[pd.Series, pd.Series, pd.Series]:\n",
        "    \"\"\"\n",
        "    KERNEL: Pure Matrix Math.\n",
        "    Calculates drift-adjusted portfolio value and volatility-normalized returns.\n",
        "    \"\"\"\n",
        "    # 1. Equity Curve Logic (Price-Weighted Drift)\n",
        "    norm_prices = prices.div(prices.bfill().iloc[0])\n",
        "    weighted_components = norm_prices.mul(weights, axis=1)\n",
        "    equity_curve = weighted_components.sum(axis=1)\n",
        "\n",
        "    # !!! MANDATORY: Use QuantUtils to preserve boundary NaN !!!\n",
        "    returns_WITH_BOUNDARY_NAN = QuantUtils.compute_returns(equity_curve)\n",
        "\n",
        "    # 2. Portfolio ATRP Logic (Weighted Volatility)\n",
        "    current_weights = weighted_components.div(equity_curve, axis=0)\n",
        "    w, a = current_weights.align(atrp_matrix, join=\"inner\", axis=0)\n",
        "    portfolio_atrp = (w * a).sum(axis=1)\n",
        "\n",
        "    return equity_curve, returns_WITH_BOUNDARY_NAN, portfolio_atrp\n",
        "\n",
        "\n",
        "def _prepare_initial_weights(tickers: List[str]) -> pd.Series:\n",
        "    \"\"\"\n",
        "    METADATA: Converts a list of tickers into a weight map.\n",
        "    Example: ['AAPL', 'AAPL', 'TSLA'] -> {'AAPL': 0.66, 'TSLA': 0.33}\n",
        "    \"\"\"\n",
        "    ticker_counts = Counter(tickers)\n",
        "    total = len(tickers)\n",
        "    return pd.Series({t: c / total for t, c in ticker_counts.items()})\n",
        "\n",
        "\n",
        "def calculate_buy_and_hold_performance(\n",
        "    df_close_wide: pd.DataFrame,  # Use the WIDE version\n",
        "    df_atrp_wide: pd.DataFrame,  # Use the WIDE version\n",
        "    tickers: List[str],\n",
        "    start_date: pd.Timestamp,\n",
        "    end_date: pd.Timestamp,\n",
        "):\n",
        "    if not tickers:\n",
        "        return pd.Series(), pd.Series(), pd.Series()\n",
        "\n",
        "    initial_weights = _prepare_initial_weights(tickers)\n",
        "\n",
        "    ################################\n",
        "    # # SLICE - This is fast because no pivot/unstack is happening\n",
        "    # p_slice = df_close_wide[initial_weights.index].loc[start_date:end_date]\n",
        "    # a_slice = df_atrp_wide[initial_weights.index].loc[start_date:end_date]\n",
        "\n",
        "    # SLICE (Fix Part B)\n",
        "    ticker_list = initial_weights.index.tolist()\n",
        "    p_slice = df_close_wide.reindex(columns=ticker_list).loc[start_date:end_date]\n",
        "    a_slice = df_atrp_wide.reindex(columns=ticker_list).loc[start_date:end_date]\n",
        "\n",
        "    ################################\n",
        "\n",
        "    # KERNEL - Pure Math\n",
        "    return _compute_vol_adjusted_performance(p_slice, a_slice, initial_weights)\n",
        "\n",
        "\n",
        "def calculate_summary_gain(price_series: pd.Series) -> float:\n",
        "    \"\"\"REPORTING: Returns the total return of a single series.\"\"\"\n",
        "    if price_series.dropna().shape[0] < 2:\n",
        "        return 0.0\n",
        "    # (Final Price / Starting Price) - 1\n",
        "    res = (price_series.ffill().iloc[-1] / price_series.bfill().iloc[0]) - 1\n",
        "    return float(res) if np.isfinite(res) else 0.0\n",
        "\n",
        "\n",
        "def calculate_cross_sectional_gain(price_df: pd.DataFrame) -> pd.Series:\n",
        "    \"\"\"RANKING: Returns the total return for every ticker in the universe.\"\"\"\n",
        "    if price_df.empty:\n",
        "        return pd.Series(dtype=float)\n",
        "    # Vectorized calculation across all columns (tickers)\n",
        "    res = (price_df.ffill().iloc[-1] / price_df.bfill().iloc[0]) - 1\n",
        "    return res.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
        "\n",
        "\n",
        "def calculate_summary_sharpe(return_series: pd.Series) -> float:\n",
        "    \"\"\"REPORTING: Returns a single Reward value.\"\"\"\n",
        "    if return_series.dropna().shape[0] < 2:\n",
        "        return 0.0\n",
        "    mu, std = return_series.mean(), return_series.std()\n",
        "\n",
        "    # SENIOR FIX: Volatility floor to prevent 'Infinity' or 'Exploding' rewards\n",
        "    if std < 1e-6:\n",
        "        return 0.0\n",
        "\n",
        "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
        "        res = (mu / std) * np.sqrt(252)\n",
        "    return float(res) if np.isfinite(res) else 0.0\n",
        "\n",
        "\n",
        "def calculate_cross_sectional_sharpe(return_df: pd.DataFrame) -> pd.Series:\n",
        "    \"\"\"RANKING: Returns a Series of values for the whole universe.\"\"\"\n",
        "    if return_df.empty:\n",
        "        return pd.Series(dtype=float)\n",
        "    mu, std = return_df.mean(), return_df.std()\n",
        "\n",
        "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
        "        res = (mu / std) * np.sqrt(252)\n",
        "\n",
        "    # SENIOR FIX: Convert 'Broken' data (std=0) into 0.0 reward\n",
        "    return res.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
        "\n",
        "\n",
        "def calculate_summary_sharpe_atr(\n",
        "    return_series: pd.Series, atrp_input: Union[pd.Series, float]\n",
        ") -> float:\n",
        "    \"\"\"REPORTING: Returns a single Reward value normalized by Volatility.\"\"\"\n",
        "    if return_series.dropna().shape[0] < 2:\n",
        "        return 0.0\n",
        "    avg_atrp = atrp_input.mean() if hasattr(atrp_input, \"mean\") else atrp_input\n",
        "\n",
        "    if avg_atrp < 1e-6:\n",
        "        return 0.0  # Safety floor\n",
        "\n",
        "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
        "        res = return_series.mean() / avg_atrp\n",
        "    return float(res) if np.isfinite(res) else 0.0\n",
        "\n",
        "\n",
        "def calculate_cross_sectional_sharpe_atr(\n",
        "    return_df: pd.DataFrame, atrp_series: pd.Series\n",
        ") -> pd.Series:\n",
        "    \"\"\"RANKING: Returns a Series of Volatility-normalized values.\"\"\"\n",
        "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
        "        res = return_df.mean() / atrp_series\n",
        "    return res.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# SECTION C: METRIC REGISTRY\n",
        "# ==============================================================================\n",
        "\n",
        "\n",
        "class MarketObservation(TypedDict):\n",
        "    \"\"\"\n",
        "    The 'STATE' (Observation) in Reinforcement Learning.\n",
        "    This defines the context given to the agent to make a decision.\n",
        "    \"\"\"\n",
        "\n",
        "    # --- The Movie (Time Series) ---\n",
        "    lookback_returns: pd.DataFrame  # (Time x Tickers)\n",
        "    lookback_close: pd.DataFrame  # (Time x Tickers)\n",
        "\n",
        "    # --- The Snapshot (Scalar values at Decision Time) ---\n",
        "    atrp: pd.Series  # Volatility (Mean over lookback)\n",
        "\n",
        "    # NEW SENSORS\n",
        "    rsi: pd.Series  # Internal Momentum (0-100)\n",
        "    rel_strength: pd.Series  # Performance vs SPY\n",
        "    vol_regime: pd.Series  # Volatility Expansion/Compression\n",
        "    rvol: pd.Series  # Ticker Conviction\n",
        "    spy_rvol: pd.Series  # Market Participation\n",
        "    obv_score: pd.Series  # Ticker Accumulation/Distribution\n",
        "    spy_obv_score: pd.Series  # Market Tide\n",
        "\n",
        "    # MOMENTUM VECTORS\n",
        "    roc_1: pd.Series\n",
        "    roc_3: pd.Series\n",
        "    roc_5: pd.Series\n",
        "    roc_10: pd.Series\n",
        "    roc_21: pd.Series\n",
        "\n",
        "\n",
        "def metric_price(obs: MarketObservation) -> pd.Series:\n",
        "    return calculate_cross_sectional_gain(obs[\"lookback_close\"])\n",
        "\n",
        "\n",
        "def metric_sharpe(obs: MarketObservation) -> pd.Series:\n",
        "    return calculate_cross_sectional_sharpe(obs[\"lookback_returns\"])\n",
        "\n",
        "\n",
        "def metric_sharpe_atr(obs: MarketObservation) -> pd.Series:\n",
        "    return calculate_cross_sectional_sharpe_atr(obs[\"lookback_returns\"], obs[\"atrp\"])\n",
        "\n",
        "\n",
        "METRIC_REGISTRY = {\n",
        "    # --- CLASSIC METRICS ---\n",
        "    \"Price\": metric_price,\n",
        "    \"Sharpe\": metric_sharpe,\n",
        "    \"Sharpe (ATR)\": metric_sharpe_atr,\n",
        "    # --- MOMENTUM VECTORS ---\n",
        "    \"Momentum 1D\": lambda obs: obs[\"roc_1\"],\n",
        "    \"Momentum 3D\": lambda obs: obs[\"roc_3\"],\n",
        "    \"Momentum 5D\": lambda obs: obs[\"roc_5\"],\n",
        "    \"Momentum 10D\": lambda obs: obs[\"roc_10\"],\n",
        "    \"Momentum 1M\": lambda obs: obs[\"roc_21\"],\n",
        "    # --- PULLBACK VECTORS ---\n",
        "    \"Pullback 1D\": lambda obs: -obs[\"roc_1\"],\n",
        "    \"Pullback 3D\": lambda obs: -obs[\"roc_3\"],\n",
        "    \"Pullback 5D\": lambda obs: -obs[\"roc_5\"],\n",
        "    \"Pullback 10D\": lambda obs: -obs[\"roc_10\"],\n",
        "    \"Pullback 1M\": lambda obs: -obs[\"roc_21\"],\n",
        "    # --- NEW SOTA SENSORS ---\n",
        "    \"RSI (Reversal)\": lambda obs: -obs[\"rsi\"],  # Rank Low RSI (Oversold) higher\n",
        "    \"RSI (Trend)\": lambda obs: obs[\"rsi\"],  # Rank High RSI (Strong Trend) higher\n",
        "    \"Alpha (RelStrength)\": lambda obs: obs[\"rel_strength\"],  # Rank stocks beating SPY\n",
        "    \"OBV (Accumulation)\": lambda obs: obs[\"obv_score\"],  # Rank High OBV Score\n",
        "    \"Volume Conviction\": lambda obs: obs[\"rvol\"],  # Rank High Relative Volume\n",
        "    \"Volatility Regime (Breakout)\": lambda obs: obs[\n",
        "        \"vol_regime\"\n",
        "    ],  # Rank High Volatility Expansion\n",
        "}\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# SECTION D: DATA CONTRACTS\n",
        "# ==============================================================================\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class EngineInput:\n",
        "    mode: str\n",
        "    start_date: pd.Timestamp\n",
        "    lookback_period: int\n",
        "    holding_period: int\n",
        "    metric: str\n",
        "    benchmark_ticker: str\n",
        "    rank_start: int = 1\n",
        "    rank_end: int = 10\n",
        "    # Default factory pulls from Global thresholds\n",
        "    quality_thresholds: Dict[str, float] = field(\n",
        "        default_factory=lambda: GLOBAL_SETTINGS[\"thresholds\"].copy()\n",
        "    )\n",
        "    manual_tickers: List[str] = field(default_factory=list)\n",
        "    debug: bool = False\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class EngineOutput:\n",
        "    portfolio_series: pd.Series\n",
        "    benchmark_series: pd.Series\n",
        "    normalized_plot_data: pd.DataFrame\n",
        "    tickers: List[str]\n",
        "    initial_weights: pd.Series\n",
        "    perf_metrics: Dict[str, float]\n",
        "    results_df: pd.DataFrame\n",
        "\n",
        "    # Dates\n",
        "    start_date: pd.Timestamp\n",
        "    decision_date: pd.Timestamp\n",
        "    buy_date: pd.Timestamp\n",
        "    holding_end_date: pd.Timestamp\n",
        "\n",
        "    error_msg: Optional[str] = None\n",
        "    debug_data: Optional[Dict[str, Any]] = None\n",
        "\n",
        "\n",
        "class AlphaEngine:\n",
        "    def __init__(\n",
        "        self,\n",
        "        df_ohlcv: pd.DataFrame,\n",
        "        features_df: pd.DataFrame = None,\n",
        "        df_close_wide: pd.DataFrame = None,\n",
        "        df_atrp_wide: pd.DataFrame = None,  # <--- PINPOINT 1: Add this argument\n",
        "        master_ticker: str = GLOBAL_SETTINGS[\"calendar_ticker\"],\n",
        "    ):\n",
        "        print(\"--- ‚öôÔ∏è Initializing AlphaEngine v2.2 (Sanitized) ---\")\n",
        "\n",
        "        # 1. SETUP PRICES (CLEAN-AT-ENTRY)\n",
        "        if df_close_wide is not None:\n",
        "            self.df_close = df_close_wide\n",
        "        else:\n",
        "            print(\"üê¢ Pivoting and Sanitizing Price Data...\")\n",
        "            self.df_close = df_ohlcv[\"Adj Close\"].unstack(level=0)\n",
        "\n",
        "        # APPLY DATA SANITIZER LOGIC\n",
        "        if GLOBAL_SETTINGS[\"handle_zeros_as_nan\"]:\n",
        "            # Replace 0.0 with NaN so math functions (mean/std) ignore them\n",
        "            self.df_close = self.df_close.replace(0, np.nan)\n",
        "\n",
        "        # Smooth over 1-2 day glitches (The \"FNV\" Fix)\n",
        "        self.df_close = self.df_close.ffill(limit=GLOBAL_SETTINGS[\"max_data_gap_ffill\"])\n",
        "\n",
        "        # Handle the remaining \"unfillable\" gaps\n",
        "        self.df_close = self.df_close.fillna(GLOBAL_SETTINGS[\"nan_price_replacement\"])\n",
        "\n",
        "        # 2. SETUP FEATURES\n",
        "        if features_df is not None:\n",
        "            self.features_df = features_df\n",
        "        else:\n",
        "            # We pass the cleaned price data if needed, or calculate from raw\n",
        "            self.features_df = generate_features(\n",
        "                df_ohlcv,\n",
        "                atr_period=GLOBAL_SETTINGS[\"atr_period\"],\n",
        "                quality_window=GLOBAL_SETTINGS[\"quality_window\"],\n",
        "                quality_min_periods=GLOBAL_SETTINGS[\"quality_min_periods\"],\n",
        "            )\n",
        "\n",
        "        # --- PINPOINT 2: Logic Swap for Speed ---\n",
        "        if df_atrp_wide is not None:\n",
        "            # INSTANT: Use the matrix precomputed outside the UI\n",
        "            self.df_atrp = df_atrp_wide\n",
        "        else:\n",
        "            # SLOW FALLBACK: Only runs if you forget to precompute\n",
        "            print(\"üöÄ Pre-aligning Volatility (ATRP) Matrix (Slow Fallback)...\")\n",
        "            self.df_atrp = self.features_df[\"ATRP\"].unstack(level=0)\n",
        "\n",
        "        # Final safety alignment (Always cheap once already unstacked)\n",
        "        self.df_atrp = self.df_atrp.reindex(\n",
        "            index=self.df_close.index, columns=self.df_close.columns\n",
        "        )\n",
        "\n",
        "        # # --- THE PINPOINT CHANGE: Create Wide Feature Matrix ---\n",
        "        # print(\"üöÄ Pre-aligning Volatility (ATRP) Matrix...\")\n",
        "        # self.df_atrp = self.features_df[\"ATRP\"].unstack(level=0)\n",
        "\n",
        "        # # Ensure the ATRP matrix has the exact same index (Dates) as our Price matrix\n",
        "        # self.df_atrp = self.df_atrp.reindex(self.df_close.index)\n",
        "\n",
        "        # 3. Setup Calendar\n",
        "        if master_ticker not in self.df_close.columns:\n",
        "            master_ticker = self.df_close.columns[0]\n",
        "        self.trading_calendar = (\n",
        "            self.df_close[master_ticker].dropna().index.unique().sort_values()\n",
        "        )\n",
        "\n",
        "    def run(self, inputs: EngineInput) -> EngineOutput:\n",
        "        dates, error = self._validate_timeline(inputs)\n",
        "        if error:\n",
        "            return self._error_result(error)\n",
        "        (safe_start, safe_decision, safe_buy, safe_end) = dates\n",
        "\n",
        "        tickers_to_trade, results_table, debug_dict, error = self._select_tickers(\n",
        "            inputs, safe_start, safe_decision\n",
        "        )\n",
        "        if error:\n",
        "            return self._error_result(error)\n",
        "\n",
        "        # GENERATE TRACKS (Fix Part A)\n",
        "        p_f_val, p_f_ret, p_f_atrp = calculate_buy_and_hold_performance(\n",
        "            self.df_close, self.df_atrp, tickers_to_trade, safe_start, safe_end\n",
        "        )\n",
        "        b_f_val, b_f_ret, b_f_atrp = calculate_buy_and_hold_performance(\n",
        "            self.df_close, self.df_atrp, [inputs.benchmark_ticker], safe_start, safe_end\n",
        "        )\n",
        "\n",
        "        p_h_val, p_h_ret, p_h_atrp = calculate_buy_and_hold_performance(\n",
        "            self.df_close, self.df_atrp, tickers_to_trade, safe_buy, safe_end\n",
        "        )\n",
        "        b_h_val, b_h_ret, b_h_atrp = calculate_buy_and_hold_performance(\n",
        "            self.df_close, self.df_atrp, [inputs.benchmark_ticker], safe_buy, safe_end\n",
        "        )\n",
        "\n",
        "        # CALCULATE METRICS\n",
        "        p_metrics, p_slices = self._calculate_period_metrics(\n",
        "            p_f_val,\n",
        "            p_f_ret,\n",
        "            p_f_atrp,\n",
        "            safe_decision,\n",
        "            p_h_val,\n",
        "            p_h_ret,\n",
        "            p_h_atrp,\n",
        "            prefix=\"p\",\n",
        "        )\n",
        "        b_metrics, b_slices = self._calculate_period_metrics(\n",
        "            b_f_val,\n",
        "            b_f_ret,\n",
        "            b_f_atrp,\n",
        "            safe_decision,\n",
        "            b_h_val,\n",
        "            b_h_ret,\n",
        "            b_h_atrp,\n",
        "            prefix=\"b\",\n",
        "        )\n",
        "\n",
        "        # CONSOLIDATE DEBUG DATA\n",
        "        debug_dict[\"verification\"] = {\"portfolio\": p_slices, \"benchmark\": b_slices}\n",
        "\n",
        "        # ADD RAW COMPONENT EXPORTS\n",
        "        debug_dict[\"portfolio_raw_components\"] = {\n",
        "            \"prices\": self.df_close[tickers_to_trade].loc[safe_start:safe_end],\n",
        "            \"atrp\": self.features_df.loc[\n",
        "                (tickers_to_trade, slice(safe_start, safe_end)), \"ATRP\"\n",
        "            ].unstack(level=0),\n",
        "        }\n",
        "        debug_dict[\"benchmark_raw_components\"] = {\n",
        "            \"prices\": self.df_close[[inputs.benchmark_ticker]].loc[safe_start:safe_end],\n",
        "            \"atrp\": self.features_df.loc[\n",
        "                ([inputs.benchmark_ticker], slice(safe_start, safe_end)), \"ATRP\"\n",
        "            ].unstack(level=0),\n",
        "        }\n",
        "\n",
        "        # FINAL OUTPUT\n",
        "        results_table[\"Holding Gain\"] = (p_h_val.iloc[-1] / p_h_val.iloc[0]) - 1\n",
        "        return EngineOutput(\n",
        "            portfolio_series=p_f_val,\n",
        "            benchmark_series=b_f_val,\n",
        "            normalized_plot_data=self._get_normalized_plot_data(\n",
        "                tickers_to_trade, safe_start, safe_end\n",
        "            ),\n",
        "            tickers=tickers_to_trade,\n",
        "            initial_weights=pd.Series(\n",
        "                {t: 1 / len(tickers_to_trade) for t in tickers_to_trade}\n",
        "            ),\n",
        "            perf_metrics={**p_metrics, **b_metrics},\n",
        "            results_df=results_table,\n",
        "            start_date=safe_start,\n",
        "            decision_date=safe_decision,\n",
        "            buy_date=safe_buy,\n",
        "            holding_end_date=safe_end,\n",
        "            debug_data=debug_dict,\n",
        "        )\n",
        "\n",
        "    # ==============================================================================\n",
        "    # INTERNAL LOGIC MODULES\n",
        "    # ==============================================================================\n",
        "\n",
        "    def _validate_timeline(self, inputs: EngineInput):\n",
        "        cal = self.trading_calendar\n",
        "        last_idx = len(cal) - 1\n",
        "\n",
        "        if len(cal) <= inputs.lookback_period:\n",
        "            return (\n",
        "                None,\n",
        "                f\"‚ùå Dataset too small.\\nNeed > {inputs.lookback_period} days of history.\",\n",
        "            )\n",
        "\n",
        "        # 2. Check \"Past\" Constraints (Lookback)\n",
        "        min_decision_date = cal[inputs.lookback_period]\n",
        "        if inputs.start_date < min_decision_date:\n",
        "            # Added \\n here\n",
        "            return None, (\n",
        "                f\"‚ùå Not enough history for a {inputs.lookback_period}-day lookback.\\n\"\n",
        "                f\"Earliest valid Decision Date: {min_decision_date.date()}\"\n",
        "            )\n",
        "\n",
        "        # 3. Check \"Future\" Constraints (Entry T+1 and Holding Period)\n",
        "        required_future_days = 1 + inputs.holding_period\n",
        "        latest_valid_idx = last_idx - required_future_days\n",
        "\n",
        "        if latest_valid_idx < 0:\n",
        "            return (\n",
        "                None,\n",
        "                f\"‚ùå Holding period too long.\\n{inputs.holding_period} days exceeds available data.\",\n",
        "            )\n",
        "\n",
        "        # If user picked a date beyond the available \"future\" runway\n",
        "        if inputs.start_date > cal[latest_valid_idx]:\n",
        "            latest_date = cal[latest_valid_idx].date()\n",
        "            # Added \\n here and shortened the text slightly to fit better\n",
        "            return None, (\n",
        "                f\"‚ùå Decision Date too late for a {inputs.holding_period}-day hold.\\n\"\n",
        "                f\"Latest valid date: {latest_date}. Please move picker back.\"\n",
        "            )\n",
        "\n",
        "        # 4. Map the safe indices\n",
        "        decision_idx = cal.searchsorted(inputs.start_date)\n",
        "        if decision_idx > latest_valid_idx:\n",
        "            decision_idx = latest_valid_idx\n",
        "\n",
        "        start_idx = decision_idx - inputs.lookback_period\n",
        "        entry_idx = decision_idx + 1\n",
        "        end_idx = entry_idx + inputs.holding_period\n",
        "\n",
        "        return (cal[start_idx], cal[decision_idx], cal[entry_idx], cal[end_idx]), None\n",
        "\n",
        "    def _select_tickers(self, inputs: EngineInput, start_date, decision_date):\n",
        "        debug_dict = {}\n",
        "\n",
        "        # --- PATH A: MANUAL LIST ---\n",
        "        if inputs.mode == \"Manual List\":\n",
        "            validation_errors = []\n",
        "            valid_tickers = []\n",
        "            for t in inputs.manual_tickers:\n",
        "                if t not in self.df_close.columns:\n",
        "                    validation_errors.append(f\"‚ùå {t}: Not found.\")\n",
        "                    continue\n",
        "                if pd.isna(self.df_close.at[start_date, t]):\n",
        "                    validation_errors.append(f\"‚ö†Ô∏è {t}: No data on start date.\")\n",
        "                    continue\n",
        "                valid_tickers.append(t)\n",
        "\n",
        "            if validation_errors:\n",
        "                return [], pd.DataFrame(), {}, \"\\n\".join(validation_errors)\n",
        "            if not valid_tickers:\n",
        "                return [], pd.DataFrame(), {}, \"No valid tickers found.\"\n",
        "            return valid_tickers, pd.DataFrame(index=valid_tickers), {}, None\n",
        "\n",
        "        # --- PATH B: RANKING ---\n",
        "        else:\n",
        "            audit_info = {}\n",
        "            eligible_tickers = self._filter_universe(\n",
        "                decision_date, inputs.quality_thresholds, audit_info\n",
        "            )\n",
        "            debug_dict[\"audit_liquidity\"] = audit_info\n",
        "\n",
        "            if not eligible_tickers:\n",
        "                return (\n",
        "                    [],\n",
        "                    pd.DataFrame(),\n",
        "                    debug_dict,\n",
        "                    \"No tickers passed quality filters.\",\n",
        "                )\n",
        "\n",
        "            lookback_close = self.df_close.loc[\n",
        "                start_date:decision_date, eligible_tickers\n",
        "            ]\n",
        "\n",
        "            # 1. Get the Snapshot of Features for the Decision Date\n",
        "            feat_slice_current = self.features_df.xs(\n",
        "                decision_date, level=\"Date\"\n",
        "            ).reindex(eligible_tickers)\n",
        "\n",
        "            # Calculate mean ATRP over the lookback period\n",
        "            idx_product = pd.MultiIndex.from_product(\n",
        "                [eligible_tickers, lookback_close.index], names=[\"Ticker\", \"Date\"]\n",
        "            )\n",
        "            feat_slice_period = self.features_df.reindex(idx_product)\n",
        "            atrp_value_for_obs = (\n",
        "                feat_slice_period[\"ATRP\"].groupby(level=\"Ticker\").mean()\n",
        "            )\n",
        "\n",
        "            # 2. Package the Observation (The 'State')\n",
        "            observation: MarketObservation = {\n",
        "                # Time Series Data\n",
        "                \"lookback_close\": lookback_close,\n",
        "                \"lookback_returns\": lookback_close.ffill().pct_change(),\n",
        "                # Snapshot Data (Scalar values for today)\n",
        "                \"atrp\": atrp_value_for_obs,  # <--- USES THE TOGGLED VALUE HERE\n",
        "                \"rsi\": feat_slice_current[\"RSI\"],\n",
        "                \"rel_strength\": feat_slice_current[\"RelStrength\"],\n",
        "                \"vol_regime\": feat_slice_current[\"VolRegime\"],\n",
        "                \"rvol\": feat_slice_current[\"RVol\"],\n",
        "                \"spy_rvol\": feat_slice_current[\"Spy_RVol\"],\n",
        "                \"obv_score\": feat_slice_current[\"OBV_Score\"],\n",
        "                \"spy_obv_score\": feat_slice_current[\"Spy_OBV_Score\"],\n",
        "                # Momentum Vectors\n",
        "                \"roc_1\": feat_slice_current[\"ROC_1\"],\n",
        "                \"roc_3\": feat_slice_current[\"ROC_3\"],\n",
        "                \"roc_5\": feat_slice_current[\"ROC_5\"],\n",
        "                \"roc_10\": feat_slice_current[\"ROC_10\"],\n",
        "                \"roc_21\": feat_slice_current[\"ROC_21\"],\n",
        "            }\n",
        "\n",
        "            # 3. Run the Strategy (The 'Agent')\n",
        "            if inputs.metric not in METRIC_REGISTRY:\n",
        "                return [], pd.DataFrame(), {}, f\"Strategy '{inputs.metric}' not found.\"\n",
        "\n",
        "            metric_vals = METRIC_REGISTRY[inputs.metric](observation)\n",
        "            sorted_tickers = metric_vals.sort_values(ascending=False)\n",
        "            start_r = max(0, inputs.rank_start - 1)\n",
        "            end_r = inputs.rank_end\n",
        "            selected_tickers = sorted_tickers.iloc[start_r:end_r].index.tolist()\n",
        "\n",
        "            # Audit\n",
        "            debug_dict[\"full_universe_ranking\"] = pd.DataFrame(\n",
        "                {\n",
        "                    \"Strategy_Score\": metric_vals,\n",
        "                    \"Lookback_Return_Ann\": observation[\"lookback_returns\"].mean() * 252,\n",
        "                    \"Lookback_ATRP\": observation[\"atrp\"],\n",
        "                }\n",
        "            )\n",
        "\n",
        "            if not selected_tickers:\n",
        "                return (\n",
        "                    [],\n",
        "                    pd.DataFrame(),\n",
        "                    debug_dict,\n",
        "                    \"No tickers generated from ranking.\",\n",
        "                )\n",
        "\n",
        "            results_table = pd.DataFrame(\n",
        "                {\n",
        "                    \"Rank\": range(\n",
        "                        inputs.rank_start, inputs.rank_start + len(selected_tickers)\n",
        "                    ),\n",
        "                    \"Ticker\": selected_tickers,\n",
        "                    \"Strategy Value\": sorted_tickers.loc[selected_tickers].values,\n",
        "                }\n",
        "            ).set_index(\"Ticker\")\n",
        "\n",
        "            return selected_tickers, results_table, debug_dict, None\n",
        "\n",
        "    def _filter_universe(self, date_ts, thresholds, audit_container=None):\n",
        "        avail_dates = (\n",
        "            self.features_df.index.get_level_values(\"Date\").unique().sort_values()\n",
        "        )\n",
        "        valid_dates = avail_dates[avail_dates <= date_ts]\n",
        "        if valid_dates.empty:\n",
        "            return []\n",
        "        target_date = valid_dates[-1]\n",
        "        day_features = self.features_df.xs(target_date, level=\"Date\")\n",
        "\n",
        "        vol_cutoff = thresholds.get(\"min_median_dollar_volume\", 0)\n",
        "        percentile_used = \"N/A\"\n",
        "        if \"min_liquidity_percentile\" in thresholds:\n",
        "            percentile_used = thresholds[\"min_liquidity_percentile\"]\n",
        "            dynamic_val = day_features[\"RollMedDollarVol\"].quantile(percentile_used)\n",
        "            vol_cutoff = max(vol_cutoff, dynamic_val)\n",
        "\n",
        "        mask = (\n",
        "            (day_features[\"RollMedDollarVol\"] >= vol_cutoff)\n",
        "            & (day_features[\"RollingStalePct\"] <= thresholds[\"max_stale_pct\"])\n",
        "            & (day_features[\"RollingSameVolCount\"] <= thresholds[\"max_same_vol_count\"])\n",
        "        )\n",
        "\n",
        "        if audit_container is not None:\n",
        "            audit_container[\"date\"] = target_date\n",
        "            audit_container[\"total_tickers_available\"] = len(day_features)\n",
        "            audit_container[\"percentile_setting\"] = percentile_used\n",
        "            audit_container[\"final_cutoff_usd\"] = vol_cutoff\n",
        "            audit_container[\"tickers_passed\"] = mask.sum()\n",
        "            snapshot = day_features.copy()\n",
        "            snapshot[\"Calculated_Cutoff\"] = vol_cutoff\n",
        "            snapshot[\"Passed_Vol_Check\"] = snapshot[\"RollMedDollarVol\"] >= vol_cutoff\n",
        "            snapshot[\"Passed_Final\"] = mask\n",
        "            snapshot = snapshot.sort_values(\"RollMedDollarVol\", ascending=False)\n",
        "            audit_container[\"universe_snapshot\"] = snapshot\n",
        "\n",
        "        return day_features[mask].index.tolist()\n",
        "\n",
        "    def _calculate_period_metrics(\n",
        "        self, f_val, f_ret, f_atrp, decision_date, h_val, h_ret, h_atrp, prefix\n",
        "    ):\n",
        "        metrics = {}\n",
        "        slices = {}\n",
        "\n",
        "        # 1. Temporal Slicing (Routing)\n",
        "        lb_val, lb_ret, lb_atrp = (\n",
        "            f_val.loc[:decision_date],\n",
        "            f_ret.loc[:decision_date],\n",
        "            f_atrp.loc[:decision_date],\n",
        "        )\n",
        "\n",
        "        # 2. GAIN\n",
        "        metrics[f\"full_{prefix}_gain\"] = QuantUtils.calculate_total_gain(f_val)\n",
        "        metrics[f\"lookback_{prefix}_gain\"] = QuantUtils.calculate_total_gain(lb_val)\n",
        "        metrics[f\"holding_{prefix}_gain\"] = QuantUtils.calculate_total_gain(h_val)\n",
        "\n",
        "        # 3. SHARPE\n",
        "        metrics[f\"full_{prefix}_sharpe\"] = QuantUtils.calculate_sharpe(f_ret)\n",
        "        metrics[f\"lookback_{prefix}_sharpe\"] = QuantUtils.calculate_sharpe(lb_ret)\n",
        "        metrics[f\"holding_{prefix}_sharpe\"] = QuantUtils.calculate_sharpe(h_ret)\n",
        "\n",
        "        # 4. SHARPE (ATR)\n",
        "        metrics[f\"full_{prefix}_sharpe_atr\"] = QuantUtils.calculate_sharpe_atr(\n",
        "            f_ret, f_atrp\n",
        "        )\n",
        "        metrics[f\"lookback_{prefix}_sharpe_atr\"] = QuantUtils.calculate_sharpe_atr(\n",
        "            lb_ret, lb_atrp\n",
        "        )\n",
        "        metrics[f\"holding_{prefix}_sharpe_atr\"] = QuantUtils.calculate_sharpe_atr(\n",
        "            h_ret, h_atrp\n",
        "        )\n",
        "\n",
        "        # 5. Metadata Collection\n",
        "        slices[\"full_val\"], slices[\"full_ret\"], slices[\"full_atrp\"] = (\n",
        "            f_val,\n",
        "            f_ret,\n",
        "            f_atrp,\n",
        "        )\n",
        "        slices[\"lookback_val\"], slices[\"lookback_ret\"], slices[\"lookback_atrp\"] = (\n",
        "            lb_val,\n",
        "            lb_ret,\n",
        "            lb_atrp,\n",
        "        )\n",
        "        slices[\"holding_val\"], slices[\"holding_ret\"], slices[\"holding_atrp\"] = (\n",
        "            h_val,\n",
        "            h_ret,\n",
        "            h_atrp,\n",
        "        )\n",
        "\n",
        "        return metrics, slices\n",
        "\n",
        "    def _get_normalized_plot_data(self, tickers, start_date, end_date):\n",
        "        if not tickers:\n",
        "            return pd.DataFrame()\n",
        "        data = self.df_close[list(set(tickers))].loc[start_date:end_date]\n",
        "        if data.empty:\n",
        "            return pd.DataFrame()\n",
        "        return data / data.bfill().iloc[0]\n",
        "\n",
        "    def _error_result(self, msg):\n",
        "        return EngineOutput(\n",
        "            portfolio_series=pd.Series(dtype=float),\n",
        "            benchmark_series=pd.Series(dtype=float),\n",
        "            normalized_plot_data=pd.DataFrame(),\n",
        "            tickers=[],\n",
        "            initial_weights=pd.Series(dtype=float),\n",
        "            perf_metrics={},\n",
        "            results_df=pd.DataFrame(),\n",
        "            start_date=pd.Timestamp.min,\n",
        "            decision_date=pd.Timestamp.min,\n",
        "            buy_date=pd.Timestamp.min,\n",
        "            holding_end_date=pd.Timestamp.min,\n",
        "            error_msg=msg,\n",
        "        )\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# SECTION E: THE UI (Visualization)\n",
        "# ==============================================================================\n",
        "\n",
        "\n",
        "def plot_walk_forward_analyzer(\n",
        "    df_ohlcv,\n",
        "    precomputed_features=None,\n",
        "    precomputed_close=None,\n",
        "    precomputed_atrp=None,  # <--- NEW ARGUMENT\n",
        "    default_start_date=\"2025-01-17\",\n",
        "    default_lookback=10,\n",
        "    default_holding=5,\n",
        "    default_strategy=\"Sharpe (ATR)\",\n",
        "    default_rank_start=1,\n",
        "    default_rank_end=10,\n",
        "    default_benchmark_ticker=GLOBAL_SETTINGS[\"benchmark_ticker\"],\n",
        "    master_calendar_ticker=GLOBAL_SETTINGS[\"calendar_ticker\"],\n",
        "    quality_thresholds=GLOBAL_SETTINGS[\"thresholds\"],\n",
        "    debug=False,\n",
        "):\n",
        "\n",
        "    engine = AlphaEngine(\n",
        "        df_ohlcv,\n",
        "        features_df=precomputed_features,\n",
        "        df_close_wide=precomputed_close,\n",
        "        df_atrp_wide=precomputed_atrp,  # <--- PASS IT HERE\n",
        "        master_ticker=master_calendar_ticker,\n",
        "    )\n",
        "\n",
        "    # Initialize containers\n",
        "    results_container = [None]\n",
        "    debug_container = [{}]\n",
        "\n",
        "    # If no thresholds passed, use the global Source of Truth\n",
        "    if quality_thresholds is None:\n",
        "        quality_thresholds = GLOBAL_SETTINGS[\"thresholds\"]\n",
        "\n",
        "    # --- Widgets ---\n",
        "    mode_selector = widgets.RadioButtons(\n",
        "        options=[\"Ranking\", \"Manual List\"],\n",
        "        value=\"Ranking\",\n",
        "        description=\"Mode:\",\n",
        "        layout={\"width\": \"max-content\"},\n",
        "        style={\"description_width\": \"initial\"},\n",
        "    )\n",
        "    lookback_input = widgets.IntText(\n",
        "        value=default_lookback,\n",
        "        description=\"Lookback (Days):\",\n",
        "        layout={\"width\": \"200px\"},\n",
        "        style={\"description_width\": \"initial\"},\n",
        "    )\n",
        "    decision_date_picker = widgets.DatePicker(\n",
        "        description=\"Decision Date:\",\n",
        "        value=pd.to_datetime(default_start_date),\n",
        "        layout={\"width\": \"auto\"},\n",
        "        style={\"description_width\": \"initial\"},\n",
        "    )\n",
        "    holding_input = widgets.IntText(\n",
        "        value=default_holding,\n",
        "        description=\"Holding (Days):\",\n",
        "        layout={\"width\": \"200px\"},\n",
        "        style={\"description_width\": \"initial\"},\n",
        "    )\n",
        "    strategy_dropdown = widgets.Dropdown(\n",
        "        options=list(METRIC_REGISTRY.keys()),\n",
        "        value=default_strategy,\n",
        "        description=\"Strategy:\",\n",
        "        layout={\"width\": \"220px\"},\n",
        "        style={\"description_width\": \"initial\"},\n",
        "    )\n",
        "    benchmark_input = widgets.Text(\n",
        "        value=default_benchmark_ticker,\n",
        "        description=\"Benchmark:\",\n",
        "        placeholder=\"Enter Ticker\",\n",
        "        layout={\"width\": \"180px\"},\n",
        "        style={\"description_width\": \"initial\"},\n",
        "    )\n",
        "    rank_start_input = widgets.IntText(\n",
        "        value=default_rank_start,\n",
        "        description=\"Rank Start:\",\n",
        "        layout={\"width\": \"150px\"},\n",
        "        style={\"description_width\": \"initial\"},\n",
        "    )\n",
        "    rank_end_input = widgets.IntText(\n",
        "        value=default_rank_end,\n",
        "        description=\"Rank End:\",\n",
        "        layout={\"width\": \"150px\"},\n",
        "        style={\"description_width\": \"initial\"},\n",
        "    )\n",
        "    manual_tickers_input = widgets.Textarea(\n",
        "        value=\"\",\n",
        "        placeholder=\"Enter tickers...\",\n",
        "        description=\"Manual Tickers:\",\n",
        "        layout={\"width\": \"400px\", \"height\": \"80px\"},\n",
        "        style={\"description_width\": \"initial\"},\n",
        "    )\n",
        "    update_button = widgets.Button(description=\"Run Simulation\", button_style=\"primary\")\n",
        "    ticker_list_output = widgets.Output()\n",
        "\n",
        "    # --- Layouts ---\n",
        "    timeline_box = widgets.HBox(\n",
        "        [lookback_input, decision_date_picker, holding_input],\n",
        "        layout=widgets.Layout(\n",
        "            justify_content=\"space-between\",\n",
        "            border=\"1px solid #ddd\",\n",
        "            padding=\"10px\",\n",
        "            margin=\"5px\",\n",
        "        ),\n",
        "    )\n",
        "    strategy_box = widgets.HBox([strategy_dropdown, benchmark_input])\n",
        "    ranking_box = widgets.HBox([rank_start_input, rank_end_input])\n",
        "\n",
        "    def on_mode_change(c):\n",
        "        ranking_box.layout.display = \"flex\" if c[\"new\"] == \"Ranking\" else \"none\"\n",
        "        manual_tickers_input.layout.display = (\n",
        "            \"none\" if c[\"new\"] == \"Ranking\" else \"flex\"\n",
        "        )\n",
        "        strategy_dropdown.disabled = c[\"new\"] == \"Manual List\"\n",
        "\n",
        "    mode_selector.observe(on_mode_change, names=\"value\")\n",
        "    on_mode_change({\"new\": mode_selector.value})\n",
        "\n",
        "    ui = widgets.VBox(\n",
        "        [\n",
        "            widgets.HTML(\n",
        "                \"<b>1. Timeline Configuration:</b> (Past <--- Decision ---> Future)\"\n",
        "            ),\n",
        "            timeline_box,\n",
        "            widgets.HTML(\"<b>2. Strategy Settings:</b>\"),\n",
        "            widgets.HBox([mode_selector, strategy_box]),\n",
        "            ranking_box,\n",
        "            manual_tickers_input,\n",
        "            widgets.HTML(\"<hr>\"),\n",
        "            update_button,\n",
        "            ticker_list_output,\n",
        "        ],\n",
        "        layout=widgets.Layout(margin=\"10px 0 20px 0\"),\n",
        "    )\n",
        "\n",
        "    fig = go.FigureWidget()\n",
        "    fig.update_layout(\n",
        "        title=\"Event-Driven Walk-Forward Analysis\",\n",
        "        height=600,\n",
        "        template=\"plotly_white\",\n",
        "        hovermode=\"x unified\",\n",
        "    )\n",
        "    for i in range(50):\n",
        "        fig.add_trace(go.Scatter(visible=False, line=dict(width=2)))\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            name=\"Benchmark\",\n",
        "            visible=True,\n",
        "            line=dict(color=\"black\", width=3, dash=\"dash\"),\n",
        "        )\n",
        "    )\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            name=\"Group Portfolio\", visible=True, line=dict(color=\"green\", width=3)\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # --- Update Logic ---\n",
        "    def update_plot(b):\n",
        "        ticker_list_output.clear_output()\n",
        "        manual_list = [\n",
        "            t.strip().upper()\n",
        "            for t in manual_tickers_input.value.split(\",\")\n",
        "            if t.strip()\n",
        "        ]\n",
        "        decision_date_raw = pd.to_datetime(decision_date_picker.value)\n",
        "\n",
        "        inputs = EngineInput(\n",
        "            mode=mode_selector.value,\n",
        "            start_date=decision_date_raw,\n",
        "            lookback_period=lookback_input.value,\n",
        "            holding_period=holding_input.value,\n",
        "            metric=strategy_dropdown.value,\n",
        "            benchmark_ticker=benchmark_input.value.strip().upper(),\n",
        "            rank_start=rank_start_input.value,\n",
        "            rank_end=rank_end_input.value,\n",
        "            quality_thresholds=quality_thresholds,\n",
        "            manual_tickers=manual_list,\n",
        "            debug=debug,\n",
        "        )\n",
        "\n",
        "        # --- CAPTURE INPUTS FOR AUDIT ---\n",
        "        debug_container[0][\"inputs\"] = inputs\n",
        "\n",
        "        with ticker_list_output:\n",
        "            res = engine.run(inputs)\n",
        "            results_container[0] = res\n",
        "\n",
        "            # --- MERGE ENGINE DEBUG DATA ---\n",
        "            if res.debug_data:\n",
        "                debug_container[0].update(res.debug_data)\n",
        "\n",
        "            if res.error_msg:\n",
        "                print(f\"‚ö†Ô∏è Simulation Stopped: {res.error_msg}\")\n",
        "                return\n",
        "\n",
        "            # Plotting\n",
        "            with fig.batch_update():\n",
        "                cols = res.normalized_plot_data.columns.tolist()\n",
        "                for i in range(50):\n",
        "                    if i < len(cols):\n",
        "                        fig.data[i].update(\n",
        "                            x=res.normalized_plot_data.index,\n",
        "                            y=res.normalized_plot_data[cols[i]],\n",
        "                            name=cols[i],\n",
        "                            visible=True,\n",
        "                        )\n",
        "                    else:\n",
        "                        fig.data[i].visible = False\n",
        "\n",
        "                fig.data[50].update(\n",
        "                    x=res.benchmark_series.index,\n",
        "                    y=res.benchmark_series.values,\n",
        "                    name=f\"Benchmark ({inputs.benchmark_ticker})\",\n",
        "                    visible=not res.benchmark_series.empty,\n",
        "                )\n",
        "                fig.data[51].update(\n",
        "                    x=res.portfolio_series.index,\n",
        "                    y=res.portfolio_series.values,\n",
        "                    visible=True,\n",
        "                )\n",
        "\n",
        "                # Visual Lines\n",
        "                fig.layout.shapes = [\n",
        "                    dict(\n",
        "                        type=\"line\",\n",
        "                        x0=res.decision_date,\n",
        "                        y0=0,\n",
        "                        x1=res.decision_date,\n",
        "                        y1=1,\n",
        "                        xref=\"x\",\n",
        "                        yref=\"paper\",\n",
        "                        line=dict(color=\"red\", width=2, dash=\"dash\"),\n",
        "                    ),\n",
        "                    dict(\n",
        "                        type=\"line\",\n",
        "                        x0=res.buy_date,\n",
        "                        y0=0,\n",
        "                        x1=res.buy_date,\n",
        "                        y1=1,\n",
        "                        xref=\"x\",\n",
        "                        yref=\"paper\",\n",
        "                        line=dict(color=\"blue\", width=2, dash=\"dot\"),\n",
        "                    ),\n",
        "                ]\n",
        "\n",
        "                fig.layout.annotations = [\n",
        "                    dict(\n",
        "                        x=res.decision_date,\n",
        "                        y=0.05,\n",
        "                        xref=\"x\",\n",
        "                        yref=\"paper\",\n",
        "                        text=\"DECISION\",\n",
        "                        showarrow=False,\n",
        "                        bgcolor=\"red\",\n",
        "                        font=dict(color=\"white\"),\n",
        "                    ),\n",
        "                    dict(\n",
        "                        x=res.buy_date,\n",
        "                        y=1.0,\n",
        "                        xref=\"x\",\n",
        "                        yref=\"paper\",\n",
        "                        text=\"ENTRY (T+1)\",\n",
        "                        showarrow=False,\n",
        "                        bgcolor=\"blue\",\n",
        "                        font=dict(color=\"white\"),\n",
        "                    ),\n",
        "                ]\n",
        "\n",
        "            start_date = res.start_date.date()\n",
        "            act_date = res.decision_date.date()\n",
        "            entry_date = res.buy_date.date()\n",
        "\n",
        "            # Liquidity Audit Print\n",
        "            if (\n",
        "                inputs.mode == \"Ranking\"\n",
        "                and res.debug_data\n",
        "                and \"audit_liquidity\" in res.debug_data\n",
        "            ):\n",
        "                audit = res.debug_data[\"audit_liquidity\"]\n",
        "                if audit:\n",
        "                    raw_percentile = audit.get(\"percentile_setting\", 0)\n",
        "                    keep_pct = (\n",
        "                        1 - raw_percentile\n",
        "                    ) * 100  # Calculates the actual portion kept\n",
        "                    cut_val = audit.get(\"final_cutoff_usd\", 0)\n",
        "\n",
        "                    print(\"-\" * 60)\n",
        "                    print(f\"üîç LIQUIDITY CHECK (On Decision Date: {act_date})\")\n",
        "                    print(\n",
        "                        f\"   Universe Size: {audit.get('total_tickers_available')} tickers\"\n",
        "                    )\n",
        "                    print(\n",
        "                        f\"   Liquidity Threshold: {raw_percentile*100:.0f}th Percentile\"\n",
        "                    )\n",
        "                    print(f\"   Action: Keeping the Top {keep_pct:.0f}% of Market\")\n",
        "                    print(f\"   Calculated Cutoff: ${cut_val:,.0f} / day\")\n",
        "                    print(f\"   Tickers Remaining: {audit.get('tickers_passed')}\")\n",
        "                    print(\"-\" * 60)\n",
        "\n",
        "            # --- UPDATED TIMELINE PRINT ---\n",
        "            print(\n",
        "                f\"Timeline: Start [ {start_date} ] --> Decision [ {act_date} ] --> Cash (1d) --> Entry [ {entry_date} ] --> End [ {res.holding_end_date.date()} ]\"\n",
        "            )\n",
        "\n",
        "            if inputs.mode == \"Ranking\":\n",
        "                print(f\"Ranked Tickers ({len(res.tickers)}):\")\n",
        "                for i in range(0, len(res.tickers), 10):\n",
        "                    print(\", \".join(res.tickers[i : i + 10]))\n",
        "            else:\n",
        "                print(\"Manual Portfolio Tickers:\")\n",
        "                for i in range(0, len(res.tickers), 10):\n",
        "                    print(\", \".join(res.tickers[i : i + 10]))\n",
        "\n",
        "            m = res.perf_metrics\n",
        "\n",
        "            # --- DRY UI GENERATION ---\n",
        "            # 1. Define the metrics we want to display\n",
        "            metrics_to_show = [\n",
        "                (\"Gain\", \"gain\"),\n",
        "                (\"Sharpe\", \"sharpe\"),\n",
        "                (\"Sharpe (ATR)\", \"sharpe_atr\"),\n",
        "            ]\n",
        "\n",
        "            rows = []\n",
        "            for label, key in metrics_to_show:\n",
        "                p_row = {\n",
        "                    \"Metric\": f\"Group {label}\",\n",
        "                    \"Full\": m.get(f\"full_p_{key}\"),\n",
        "                    \"Lookback\": m.get(f\"lookback_p_{key}\"),\n",
        "                    \"Holding\": m.get(f\"holding_p_{key}\"),\n",
        "                }\n",
        "                b_row = {\n",
        "                    \"Metric\": f\"Benchmark {label}\",\n",
        "                    \"Full\": m.get(f\"full_b_{key}\"),\n",
        "                    \"Lookback\": m.get(f\"lookback_b_{key}\"),\n",
        "                    \"Holding\": m.get(f\"holding_b_{key}\"),\n",
        "                }\n",
        "\n",
        "                # Delta calculation\n",
        "                d_row = {\"Metric\": f\"== {label} Delta\"}\n",
        "                for col in [\"Full\", \"Lookback\", \"Holding\"]:\n",
        "                    d_row[col] = (p_row[col] or 0) - (b_row[col] or 0)\n",
        "\n",
        "                rows.extend([p_row, b_row, d_row])\n",
        "\n",
        "            df_report = pd.DataFrame(rows).set_index(\"Metric\")\n",
        "\n",
        "            # --- 2. STYLING (The \"Senior\" Design) ---\n",
        "            # --- 1. PREP DATA (Flattening the Index) ---\n",
        "            # We convert the index to a column so \"Metric\" sits on the same row as other headers\n",
        "            df_report = pd.DataFrame(rows)\n",
        "            df_report = df_report.set_index(\"Metric\")\n",
        "\n",
        "            # --- 2. THE STYLING (Sleek & Proportional) ---\n",
        "            def apply_sleek_style(styler):\n",
        "                # Match notebook font size (usually 13px)\n",
        "                styler.format(\"{:+.4f}\", na_rep=\"N/A\")\n",
        "\n",
        "                # Dynamic Row Highlighting\n",
        "                def row_logic(row):\n",
        "                    if \"Delta\" in row.name:\n",
        "                        return [\n",
        "                            \"background-color: #f9f9f9; font-weight: 600; border-top: 1px solid #ddd\"\n",
        "                        ] * len(row)\n",
        "                    if \"Group\" in row.name:\n",
        "                        return [\"color: #2c5e8f; background-color: #fcfdfe\"] * len(row)\n",
        "                    return [\"color: #555\"] * len(\n",
        "                        row\n",
        "                    )  # Benchmark rows are slightly muted\n",
        "\n",
        "                styler.apply(row_logic, axis=1)\n",
        "\n",
        "                styler.set_table_styles(\n",
        "                    [\n",
        "                        # Base Table Font - Scaling down to match standard text\n",
        "                        {\n",
        "                            \"selector\": \"\",\n",
        "                            \"props\": [\n",
        "                                (\"font-family\", \"inherit\"),\n",
        "                                (\"font-size\", \"12px\"),\n",
        "                                (\"border-collapse\", \"collapse\"),\n",
        "                                (\"width\", \"auto\"),\n",
        "                                (\"margin-left\", \"0\"),\n",
        "                            ],\n",
        "                        },\n",
        "                        # Header Row - Flattened and Muted\n",
        "                        {\n",
        "                            \"selector\": \"th\",\n",
        "                            \"props\": [\n",
        "                                (\"background-color\", \"white\"),\n",
        "                                (\"color\", \"#222\"),\n",
        "                                (\"font-weight\", \"600\"),\n",
        "                                (\"padding\", \"6px 12px\"),\n",
        "                                (\"border-bottom\", \"2px solid #444\"),\n",
        "                                (\"text-align\", \"center\"),\n",
        "                                (\n",
        "                                    \"vertical-align\",\n",
        "                                    \"bottom\",\n",
        "                                ),  # Aligns 'Metric' with others\n",
        "                            ],\n",
        "                        },\n",
        "                        # Index Column (The \"Metric\" labels)\n",
        "                        {\n",
        "                            \"selector\": \"th.row_heading\",\n",
        "                            \"props\": [\n",
        "                                (\"text-align\", \"left\"),\n",
        "                                (\"padding-right\", \"30px\"),\n",
        "                                (\"border-bottom\", \"1px solid #eee\"),\n",
        "                            ],\n",
        "                        },\n",
        "                        # Cell Data - Tighter padding\n",
        "                        {\n",
        "                            \"selector\": \"td\",\n",
        "                            \"props\": [\n",
        "                                (\"padding\", \"4px 12px\"),\n",
        "                                (\"border-bottom\", \"1px solid #eee\"),\n",
        "                            ],\n",
        "                        },\n",
        "                        # Remove the extra \"Index Name\" row completely\n",
        "                        {\n",
        "                            \"selector\": \"thead tr:nth-child(1) th\",\n",
        "                            \"props\": [(\"display\", \"table-cell\")],\n",
        "                        },\n",
        "                    ]\n",
        "                )\n",
        "\n",
        "                # Hack to fix the 'Metric' alignment:\n",
        "                # We remove the index name and set it as the horizontal label for the index\n",
        "                styler.index.name = None\n",
        "\n",
        "                return styler\n",
        "\n",
        "            display(apply_sleek_style(df_report.style))\n",
        "\n",
        "    update_button.on_click(update_plot)\n",
        "    update_plot(None)\n",
        "    display(ui, fig)\n",
        "    return results_container, debug_container\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# INTEGRITY PROTECTION: THE TRIPWIRE\n",
        "# ==============================================================================\n",
        "\n",
        "\n",
        "def verify_math_integrity():\n",
        "    \"\"\"\n",
        "    üõ°Ô∏è TRIPWIRE: Ensures Sample Boundary Integrity.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- üõ°Ô∏è Starting Final Integrity Audit ---\")\n",
        "\n",
        "    try:\n",
        "        # Test 1: Series Input\n",
        "        mock_series = pd.Series([100.0, 102.0, 101.0])\n",
        "        rets_s = QuantUtils.compute_returns(mock_series)\n",
        "        # Verify first value is actually NaN\n",
        "        if not pd.isna(rets_s.iloc[0]):\n",
        "            raise ValueError(\"Series Leading NaN missing\")\n",
        "        print(\"‚úÖ Series Boundary: OK\")\n",
        "\n",
        "        # Test 2: DataFrame Input\n",
        "        mock_df = pd.DataFrame({\"A\": [100, 101], \"B\": [200, 202]})\n",
        "        rets_df = QuantUtils.compute_returns(mock_df)\n",
        "        if not rets_df.iloc[0].isna().all():\n",
        "            raise ValueError(\"DataFrame Leading NaN missing\")\n",
        "        print(\"‚úÖ DataFrame Boundary: OK\")\n",
        "\n",
        "        print(\"‚úÖ AUDIT PASSED: Mathematical boundaries are strictly enforced.\")\n",
        "    except Exception as e:\n",
        "        print(f\"üî• SYSTEM BREACH: {str(e)}\")\n",
        "        raise e\n",
        "\n",
        "\n",
        "# Auto-run the check\n",
        "verify_math_integrity()\n",
        "\n",
        "# Run the Tripwire\n",
        "verify_feature_engineering_integrity()\n",
        "\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShWyA6vI0YDM",
        "outputId": "536b258a-6005-4b56-ed4a-f12b7c114076"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- üõ°Ô∏è Starting Final Integrity Audit ---\n",
            "‚úÖ Series Boundary: OK\n",
            "‚úÖ DataFrame Boundary: OK\n",
            "‚úÖ AUDIT PASSED: Mathematical boundaries are strictly enforced.\n",
            "\n",
            "--- üõ°Ô∏è Starting Feature Engineering Audit ---\n",
            "‚ö° Generating SOTA Quant Features (Benchmark: SPY)...\n",
            "Audit Values:\n",
            "[ nan 25.  17.5]\n",
            "‚úÖ FEATURE INTEGRITY PASSED: Wilder's ATR logic is strictly enforced.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ohlcv = pd.read_parquet('/content/df_OHLCV_stocks_etfs.parquet')"
      ],
      "metadata": {
        "id": "x5NPVCsb2Nn6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate features ONCE and store them in a variable\n",
        "print(\"Calculating features... this might take about 10 minutes...\")\n",
        "print(\"1. Calculating Features...\")\n",
        "features_df = generate_features(\n",
        "    df_ohlcv=df_ohlcv,\n",
        "    atr_period=GLOBAL_SETTINGS[\"atr_period\"],\n",
        "    quality_window=GLOBAL_SETTINGS[\"quality_window\"],\n",
        "    quality_min_periods=GLOBAL_SETTINGS[\"quality_min_periods\"],\n",
        ")\n",
        "\n",
        "print(\"2. Pivoting Price Matrix...\")\n",
        "# This is the line that takes 12 seconds, but now we only run it ONCE.\n",
        "my_close_matrix = df_ohlcv[\"Adj Close\"].unstack(level=0)\n",
        "\n",
        "# --- NEW: PRE-PIVOT ATRP ---\n",
        "print(\"3. Pivoting Volatility (ATRP) Matrix...\")\n",
        "my_atrp_matrix = features_df[\"ATRP\"].unstack(level=0)\n",
        "\n",
        "# --- SENIOR SAFETY: Align them perfectly once ---\n",
        "# This ensures dates and tickers match 100% before the UI even starts\n",
        "my_atrp_matrix = my_atrp_matrix.reindex_like(my_close_matrix)\n",
        "\n",
        "print(\"‚úÖ Pre-computation Complete. UI will now be fast.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agNJ4mLj2Rdd",
        "outputId": "d998cea3-344a-48d2-b1f7-aee0fc8522b6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating features... this might take about 10 minutes...\n",
            "1. Calculating Features...\n",
            "‚ö° Generating SOTA Quant Features (Benchmark: SPY)...\n",
            "2. Pivoting Price Matrix...\n",
            "3. Pivoting Volatility (ATRP) Matrix...\n",
            "‚úÖ Pre-computation Complete. UI will now be fast.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_close_wide = my_close_matrix.copy()\n",
        "df_atrp_wide = my_atrp_matrix.copy()"
      ],
      "metadata": {
        "id": "oMIDX-NH3Aes"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 1. THE RL ENVIRONMENT (Fixed for NaN Safety)\n",
        "# ==============================================================================\n",
        "class TradingEnv:\n",
        "    \"\"\"\n",
        "    The Gym: Where the Agent learns to play.\n",
        "    Wraps AlphaEngine to provide States and accept Actions.\n",
        "    \"\"\"\n",
        "    def __init__(self, engine: AlphaEngine, benchmark_ticker=\"SPY\"):\n",
        "        self.engine = engine\n",
        "        self.benchmark_ticker = benchmark_ticker\n",
        "\n",
        "        # ACTION SPACE: Keys from METRIC_REGISTRY\n",
        "        self.action_map = list(METRIC_REGISTRY.keys())\n",
        "        self.n_actions = len(self.action_map)\n",
        "\n",
        "        # STATE SPACE: Available dates aligned with the engine\n",
        "        self.available_dates = engine.df_close.index\n",
        "        self.current_step = 0\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Resets the game to a random start date.\"\"\"\n",
        "        # Ensure we don't pick the very start (need history) or very end (need future)\n",
        "        valid_range_start = 252\n",
        "        valid_range_end = len(self.available_dates) - 25 # Buffer for holding period\n",
        "\n",
        "        # Safety: Ensure dataset is large enough\n",
        "        if valid_range_end <= valid_range_start:\n",
        "             raise ValueError(\"Dataset too small for RL training\")\n",
        "\n",
        "        self.current_step = np.random.randint(valid_range_start, valid_range_end)\n",
        "        return self._get_observation()\n",
        "\n",
        "    def _get_observation(self):\n",
        "        \"\"\"\n",
        "        Returns the 'State' (Market Context).\n",
        "        \"\"\"\n",
        "        current_date = self.available_dates[self.current_step]\n",
        "\n",
        "        # Get feature vector for the specific date\n",
        "        # We use .mean() to get the \"Market Average\" condition\n",
        "        try:\n",
        "            day_features = self.engine.features_df.xs(current_date, level=\"Date\")\n",
        "\n",
        "            state_values = [\n",
        "                day_features['VolRegime'].mean(),       # 1. Volatility State\n",
        "                day_features['RSI'].mean() / 100.0,     # 2. Overbought/Oversold\n",
        "                day_features['OBV_Score'].mean(),       # 3. Money Flow\n",
        "                day_features['RelStrength'].mean()      # 4. Market Breadth\n",
        "            ]\n",
        "        except KeyError:\n",
        "            # Fallback if date is missing in features\n",
        "            state_values = [0.0, 0.5, 0.0, 0.0]\n",
        "\n",
        "        # PINPOINT FIX: Data Sanitization for Neural Net\n",
        "        # Neural Nets explode if fed NaN or Infinity\n",
        "        clean_state = []\n",
        "        for x in state_values:\n",
        "            if pd.isna(x) or np.isinf(x):\n",
        "                clean_state.append(0.0)\n",
        "            else:\n",
        "                clean_state.append(float(x))\n",
        "\n",
        "        return torch.tensor(clean_state, dtype=torch.float32)\n",
        "\n",
        "    def step(self, action_idx):\n",
        "        \"\"\"\n",
        "        The Agent takes an action. We calculate the reward.\n",
        "        \"\"\"\n",
        "        metric_name = self.action_map[action_idx]\n",
        "        current_date = self.available_dates[self.current_step]\n",
        "\n",
        "        # 1. SETUP ENGINE INPUT\n",
        "        inputs = EngineInput(\n",
        "            mode=\"Ranking\",\n",
        "            start_date=current_date,\n",
        "            lookback_period=20,\n",
        "            holding_period=5,\n",
        "            metric=metric_name,\n",
        "            benchmark_ticker=self.benchmark_ticker,\n",
        "            rank_end=5\n",
        "        )\n",
        "\n",
        "        # 2. RUN SIMULATION\n",
        "        try:\n",
        "            output = self.engine.run(inputs)\n",
        "\n",
        "            # --- PINPOINT FIX: Use QuantUtils for Math Safety ---\n",
        "            # Old Code: Manual division that caused RuntimeWarning/NaN\n",
        "            # New Code: Delegate to the robust kernel\n",
        "\n",
        "            port_gain = QuantUtils.calculate_total_gain(output.portfolio_series)\n",
        "            bench_gain = QuantUtils.calculate_total_gain(output.benchmark_series)\n",
        "\n",
        "            # 3. CALCULATE REWARD (Alpha)\n",
        "            # If the calculation failed (result is 0.0 exactly often implies empty),\n",
        "            # or if it returns huge outliers, we clip it.\n",
        "\n",
        "            reward = port_gain - bench_gain\n",
        "\n",
        "            # Sanity Check: If reward is NaN (e.g., benchmark failed), punish slightly\n",
        "            if np.isnan(reward) or np.isinf(reward):\n",
        "                reward = -0.01\n",
        "\n",
        "        except Exception as e:\n",
        "            # If Engine crashes, give negative reward to teach agent to avoid this state\n",
        "            reward = -0.05\n",
        "\n",
        "        # 4. MOVE TIME FORWARD\n",
        "        self.current_step += 5\n",
        "        done = self.current_step >= (len(self.available_dates) - 20)\n",
        "\n",
        "        next_state = self._get_observation() if not done else torch.zeros(4)\n",
        "\n",
        "        return next_state, reward, done, {}\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. THE AGENT (The Brain)\n",
        "# ==============================================================================\n",
        "class SimpleAgent(nn.Module):\n",
        "    def __init__(self, state_dim, n_actions):\n",
        "        super().__init__()\n",
        "        # A simple Multi-Layer Perceptron (MLP)\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(state_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, n_actions),\n",
        "            # Softmax outputs probabilities (e.g., 20% Momentum, 80% RSI)\n",
        "            nn.Softmax(dim=-1)\n",
        "        )\n",
        "\n",
        "    def forward(self, state):\n",
        "        return self.net(state)\n",
        "\n",
        "    def get_action(self, state):\n",
        "        # 1. Get probabilities from Neural Net\n",
        "        probs = self.forward(state)\n",
        "\n",
        "        # 2. Create a distribution to sample from\n",
        "        dist = Categorical(probs)\n",
        "\n",
        "        # 3. Sample an action (Exploration is built-in via sampling)\n",
        "        action = dist.sample()\n",
        "\n",
        "        return action.item(), dist.log_prob(action)\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. TEST DRIVER (Verification)\n",
        "# ==============================================================================\n",
        "def verify_rl_setup(engine):\n",
        "    print(\"--- ü§ñ Initializing RL Environment ---\")\n",
        "\n",
        "    # 1. Create Env\n",
        "    env = TradingEnv(engine)\n",
        "    obs = env.reset()\n",
        "    print(f\"State Vector: {obs} (Shape: {obs.shape})\")\n",
        "\n",
        "    # 2. Create Agent\n",
        "    state_dim = obs.shape[0]\n",
        "    n_actions = env.n_actions\n",
        "    agent = SimpleAgent(state_dim, n_actions)\n",
        "    print(f\"Agent Action Space: {n_actions} Strategies\")\n",
        "\n",
        "    # 3. Test One Step\n",
        "    action, log_prob = agent.get_action(obs)\n",
        "    print(f\"Agent chose Action Index {action}: '{env.action_map[action]}'\")\n",
        "\n",
        "    next_state, reward, done, _ = env.step(action)\n",
        "    print(f\"Reward (Alpha): {reward:.4f}\")\n",
        "    print(\"‚úÖ RL Setup Verified.\")\n"
      ],
      "metadata": {
        "id": "XTV8AkS18dtv"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the AlphaEngine with precomputed data\n",
        "engine = AlphaEngine(\n",
        "    df_ohlcv=df_ohlcv,\n",
        "    features_df=features_df,\n",
        "    df_close_wide=df_close_wide,\n",
        "    df_atrp_wide=df_atrp_wide,\n",
        "    master_ticker=GLOBAL_SETTINGS[\"calendar_ticker\"],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7rAC4ih9fqI",
        "outputId": "1d904fda-e1fc-4863-bd1c-59127f78e83f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ‚öôÔ∏è Initializing AlphaEngine v2.2 (Sanitized) ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "verify_rl_setup(engine)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5317e43-c2a1-4910-ecbe-e76066d5df44",
        "id": "KtSCsiO39Cd3"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ü§ñ Initializing RL Environment ---\n",
            "State Vector: tensor([0.9859, 0.5563, 0.4250, 0.0000]) (Shape: torch.Size([4]))\n",
            "Agent Action Space: 19 Strategies\n",
            "Agent chose Action Index 18: 'Volatility Regime (Breakout)'\n",
            "Reward (Alpha): 0.0741\n",
            "‚úÖ RL Setup Verified.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3147868895.py:116: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  res = (clean.iloc[-1] / clean.iloc[0]) - 1\n",
            "/tmp/ipython-input-3147868895.py:116: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  res = (clean.iloc[-1] / clean.iloc[0]) - 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4A-6_vJC8gNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1-AG7kgw89Ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cvT3jH0a881Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0HqJ1dBmzYH9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Categorical\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. THE RL ENVIRONMENT (Bridging AlphaEngine to PyTorch)\n",
        "# ==============================================================================\n",
        "class TradingEnv:\n",
        "    \"\"\"\n",
        "    The Gym: Where the Agent learns to play.\n",
        "    It wraps your AlphaEngine to provide States and accept Actions.\n",
        "    \"\"\"\n",
        "    def __init__(self, engine: AlphaEngine, benchmark_ticker=\"SPY\"):\n",
        "        self.engine = engine\n",
        "        self.benchmark_ticker = benchmark_ticker\n",
        "\n",
        "        # ACTION SPACE: The keys from your METRIC_REGISTRY\n",
        "        # 0: Price, 1: Sharpe, 2: Momentum 1D, etc.\n",
        "        self.action_map = list(METRIC_REGISTRY.keys())\n",
        "        self.n_actions = len(self.action_map)\n",
        "\n",
        "        # STATE SPACE: We will use SPY features as the \"Market Context\"\n",
        "        # We need to pre-calculate which features define the \"State\"\n",
        "        # For simplicity, we use: [Spy_RVol, Spy_OBV_Score, VolRegime]\n",
        "        self.available_dates = engine.df_close.index\n",
        "        self.current_step = 0\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Resets the game to a random start date.\"\"\"\n",
        "        # Pick a random index, ensuring we have enough history and future data\n",
        "        valid_range_start = 252 # Need history for lookback\n",
        "        valid_range_end = len(self.available_dates) - 20 # Need future for reward\n",
        "\n",
        "        self.current_step = np.random.randint(valid_range_start, valid_range_end)\n",
        "        return self._get_observation()\n",
        "\n",
        "    def _get_observation(self):\n",
        "        \"\"\"\n",
        "        Returns the 'State' (Market Context) for the Agent to see.\n",
        "        Returns a PyTorch Tensor.\n",
        "        \"\"\"\n",
        "        current_date = self.available_dates[self.current_step]\n",
        "\n",
        "        # We need to grab specific features for the Benchmark (SPY) or Average Market\n",
        "        # Let's use the features_df we already have.\n",
        "        # Note: We take the average of all stocks to get a \"Market Pulse\"\n",
        "        # OR specifically look at SPY if it exists in features.\n",
        "\n",
        "        # Fast vector lookup for the specific date\n",
        "        day_features = self.engine.features_df.xs(current_date, level=\"Date\")\n",
        "\n",
        "        # Simple State: Mean VolRegime, Mean RSI, Mean OBV across the universe\n",
        "        # This tells the agent: \"Is the market hot or cold?\"\n",
        "        state_values = [\n",
        "            day_features['VolRegime'].mean(),       # Volatility State\n",
        "            day_features['RSI'].mean() / 100.0,     # Overbought/Oversold (Normalized)\n",
        "            day_features['OBV_Score'].mean(),       # Money Flow\n",
        "            day_features['RelStrength'].mean()      # Breadth\n",
        "        ]\n",
        "\n",
        "        # Convert to Tensor (The language of PyTorch)\n",
        "        # Handle NaNs by replacing with 0\n",
        "        state_values = [0.0 if np.isnan(x) else x for x in state_values]\n",
        "        return torch.tensor(state_values, dtype=torch.float32)\n",
        "\n",
        "    def step(self, action_idx):\n",
        "        \"\"\"\n",
        "        The Agent takes an action (picks a strategy).\n",
        "        We calculate the reward.\n",
        "        \"\"\"\n",
        "        metric_name = self.action_map[action_idx]\n",
        "        current_date = self.available_dates[self.current_step]\n",
        "\n",
        "        # 1. SETUP THE ENGINE INPUT\n",
        "        # The Agent acts as the \"User\" selecting the dropdown\n",
        "        inputs = EngineInput(\n",
        "            mode=\"Ranking\",\n",
        "            start_date=current_date,\n",
        "            lookback_period=20,     # Fixed for now\n",
        "            holding_period=5,       # Fixed for now\n",
        "            metric=metric_name,\n",
        "            benchmark_ticker=self.benchmark_ticker,\n",
        "            rank_end=5              # Top 5 stocks\n",
        "        )\n",
        "\n",
        "        # 2. RUN THE ENGINE\n",
        "        # We suppress prints to keep training clean\n",
        "        try:\n",
        "            output = self.engine.run(inputs)\n",
        "\n",
        "            # 3. CALCULATE REWARD\n",
        "            # Reward = The Gain of the Portfolio relative to Benchmark\n",
        "            # RLVR Principle: The reward must be Veritable (True Return)\n",
        "\n",
        "            # Extract % return from the portfolio series\n",
        "            if len(output.portfolio_series) > 0:\n",
        "                port_return = (output.portfolio_series.iloc[-1] / output.portfolio_series.iloc[0]) - 1\n",
        "                bench_return = (output.benchmark_series.iloc[-1] / output.benchmark_series.iloc[0]) - 1\n",
        "\n",
        "                # Alpha (Excess Return) is a great reward\n",
        "                reward = port_return - bench_return\n",
        "            else:\n",
        "                reward = -0.01 # Penalty for crashing/no stocks found\n",
        "\n",
        "        except Exception as e:\n",
        "            reward = -0.01 # Penalty for error\n",
        "\n",
        "        # 4. MOVE TIME FORWARD\n",
        "        self.current_step += 5 # Skip ahead by the holding period\n",
        "        done = self.current_step >= (len(self.available_dates) - 20)\n",
        "\n",
        "        next_state = self._get_observation() if not done else torch.zeros(4)\n",
        "\n",
        "        return next_state, reward, done, {}\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. THE AGENT (The Brain)\n",
        "# ==============================================================================\n",
        "class SimpleAgent(nn.Module):\n",
        "    def __init__(self, state_dim, n_actions):\n",
        "        super().__init__()\n",
        "        # A simple Multi-Layer Perceptron (MLP)\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(state_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, n_actions),\n",
        "            # Softmax outputs probabilities (e.g., 20% Momentum, 80% RSI)\n",
        "            nn.Softmax(dim=-1)\n",
        "        )\n",
        "\n",
        "    def forward(self, state):\n",
        "        return self.net(state)\n",
        "\n",
        "    def get_action(self, state):\n",
        "        # 1. Get probabilities from Neural Net\n",
        "        probs = self.forward(state)\n",
        "\n",
        "        # 2. Create a distribution to sample from\n",
        "        dist = Categorical(probs)\n",
        "\n",
        "        # 3. Sample an action (Exploration is built-in via sampling)\n",
        "        action = dist.sample()\n",
        "\n",
        "        return action.item(), dist.log_prob(action)\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. TEST DRIVER (Verification)\n",
        "# ==============================================================================\n",
        "def verify_rl_setup(engine):\n",
        "    print(\"--- ü§ñ Initializing RL Environment ---\")\n",
        "\n",
        "    # 1. Create Env\n",
        "    env = TradingEnv(engine)\n",
        "    obs = env.reset()\n",
        "    print(f\"State Vector: {obs} (Shape: {obs.shape})\")\n",
        "\n",
        "    # 2. Create Agent\n",
        "    state_dim = obs.shape[0]\n",
        "    n_actions = env.n_actions\n",
        "    agent = SimpleAgent(state_dim, n_actions)\n",
        "    print(f\"Agent Action Space: {n_actions} Strategies\")\n",
        "\n",
        "    # 3. Test One Step\n",
        "    action, log_prob = agent.get_action(obs)\n",
        "    print(f\"Agent chose Action Index {action}: '{env.action_map[action]}'\")\n",
        "\n",
        "    next_state, reward, done, _ = env.step(action)\n",
        "    print(f\"Reward (Alpha): {reward:.4f}\")\n",
        "    print(\"‚úÖ RL Setup Verified.\")\n",
        "\n",
        "# To run this, you need the 'engine' instance from the previous plot function\n",
        "# If you ran plot_walk_forward_analyzer, the engine is inside it.\n",
        "# For now, we assume 'engine' exists or we create a quick one:\n",
        "# engine = AlphaEngine(df_ohlcv, features_df=features_df)\n",
        "# verify_rl_setup(engine)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the AlphaEngine with precomputed data\n",
        "engine = AlphaEngine(\n",
        "    df_ohlcv=df_ohlcv,\n",
        "    features_df=features_df,\n",
        "    df_close_wide=df_close_wide,\n",
        "    df_atrp_wide=df_atrp_wide,\n",
        "    master_ticker=GLOBAL_SETTINGS[\"calendar_ticker\"],\n",
        ")\n",
        "\n",
        "verify_rl_setup(engine)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rlvo1ClO2zwk",
        "outputId": "d5af5ef8-bb51-42fd-de14-7e835d4e2e62"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ‚öôÔ∏è Initializing AlphaEngine v2.2 (Sanitized) ---\n",
            "--- ü§ñ Initializing RL Environment ---\n",
            "State Vector: tensor([0.8772, 0.5343, 0.4296, 0.0000]) (Shape: torch.Size([4]))\n",
            "Agent Action Space: 19 Strategies\n",
            "Agent chose Action Index 6: 'Momentum 10D'\n",
            "Reward (Alpha): nan\n",
            "‚úÖ RL Setup Verified.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3147868895.py:116: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  res = (clean.iloc[-1] / clean.iloc[0]) - 1\n",
            "/tmp/ipython-input-2880089974.py:99: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  bench_return = (output.benchmark_series.iloc[-1] / output.benchmark_series.iloc[0]) - 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To run this, you need the 'engine' instance from the previous plot function\n",
        "# If you ran plot_walk_forward_analyzer, the engine is inside it.\n",
        "# For now, we assume 'engine' exists or we create a quick one:\n",
        "# engine = AlphaEngine(df_ohlcv, features_df=features_df)\n",
        "verify_rl_setup(engine)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94dxbWzD3YYv",
        "outputId": "ca935432-fd63-43f6-fddd-57968abdebbb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ü§ñ Initializing RL Environment ---\n",
            "State Vector: tensor([ 0.8182,  0.5165, -0.1428,  0.0000]) (Shape: torch.Size([4]))\n",
            "Agent Action Space: 19 Strategies\n",
            "Agent chose Action Index 12: 'Pullback 1M'\n",
            "Reward (Alpha): nan\n",
            "‚úÖ RL Setup Verified.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3147868895.py:116: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  res = (clean.iloc[-1] / clean.iloc[0]) - 1\n",
            "/tmp/ipython-input-2880089974.py:99: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  bench_return = (output.benchmark_series.iloc[-1] / output.benchmark_series.iloc[0]) - 1\n"
          ]
        }
      ]
    }
  ]
}