{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "775a018d",
   "metadata": {},
   "source": [
    "v61  \n",
    "- Updated core.analyzer\n",
    "- Replaced the `Result` pattern with exceptions and flattened the logic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e766cdb4",
   "metadata": {},
   "source": [
    "v60  \n",
    "- Converted code from notebook to modular system.\n",
    "- Fixed divide by zero warning from calculate_gain\n",
    "- Added subtitle to subplots\n",
    "- Added Volatility Regime plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9617f9b0",
   "metadata": {},
   "source": [
    "v59  \n",
    "- Removed \"nest\" of if-statements in **AlphaEngine.run**\n",
    "- Use **Result Pattern** to handle errors\n",
    "- Change verify_analyzer_short and verify_analyzer_long gain calculation from simple return to logarithmic return\n",
    "- Change calculate_gain from simple return to logarithmic return\n",
    "- Remove bfill from calculate_gain to prevent backfill with future data\n",
    "- Verify macro_df calculation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bc23af",
   "metadata": {},
   "source": [
    "v57, v58  \n",
    "added marco subplotsThe macro regime framework is now fully documented with:\n",
    "- Trend (SMA200 deviation) ‚Üí Where we are in the cycle  \n",
    "- Trend Velocity (Z) ‚Üí How fast we're moving relative to normal\n",
    "- VIX-Z ‚Üí Market fear/complacency levels  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f77acd",
   "metadata": {},
   "source": [
    "v56  \n",
    "\n",
    "- De-coupled features_df and macro_df\n",
    "- generate_features and audit_feature_engineering_integrity use GLOBAL_SETTINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195e6ee3",
   "metadata": {},
   "source": [
    "v55  \n",
    "Added\n",
    "- audit_feature_engineering_integrity (check calculation in features_df)  \n",
    "\n",
    "These are the metrics in plot  \n",
    "- --- 1. LEGACY / SANITY CHECKS ---\n",
    "- \"Price Gain\": lambda obs: QuantUtils.calculate_gain(obs[\"lookback_close\"]),\n",
    "- \"Sharpe\": lambda obs: QuantUtils.calculate_sharpe(obs[\"lookback_returns\"]),\n",
    "- \"Sharpe (ATRP)\": lambda obs: QuantUtils.calculate_sharpe_vol(\n",
    "        obs[\"lookback_returns\"], obs[\"atrp\"]\n",
    "    ),\n",
    "- \"Sharpe (TRP)\": lambda obs: QuantUtils.calculate_sharpe_vol(\n",
    "        obs[\"lookback_returns\"], obs[\"trp\"]\n",
    "    ),\n",
    "- --- 2. NEW QUANT METRICS ---\n",
    "- \"Momentum (21d)\": lambda obs: obs[\"mom_21\"],\n",
    "- \"Information Ratio (IR)\": lambda obs: obs[\"ir_63\"],  # Kept this one\n",
    "- \"Consistency (WinRate)\": lambda obs: obs[\"consistency\"],\n",
    "- \"Oversold (RSI)\": lambda obs: -obs[\"rsi\"],\n",
    "- \"Dip Buyer (Drawdown)\": lambda obs: -obs[\"dd_21\"],\n",
    "- \"Low Volatility\": lambda obs: -obs[\"atrp\"],\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b219d0f",
   "metadata": {},
   "source": [
    "v54\n",
    "-  **Replaced plot_walk_forward_analyzer with create_walk_forward_analyzer**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68de115e",
   "metadata": {},
   "source": [
    "v53  \n",
    "Looking at this registry with a quant lens, the list is **comprehensive but bloated**‚Äîwe have **momentum measured five times under different names** (roc‚ÇÅ, roc‚ÇÉ, roc‚ÇÖ, roc‚ÇÅ‚ÇÄ, roc‚ÇÇ‚ÇÅ and their negative twins ‚ÄúPullback‚Äù).  \n",
    "That‚Äôs **10 slots** telling us almost the same story at slightly different lags; in a rank-based engine they will **crowd the signal space** and inflate turnover without adding IC.\n",
    "\n",
    "Duplicate / redundant cluster  \n",
    "- Momentum 1 D ‚Üî Pullback 1 D (perfect mirror)  \n",
    "- Same for 3 D, 5 D, 10 D, 21 D.  \n",
    "**Keep one side only**‚Äîmomentum is enough; the portfolio constructor can always **reverse the rank** if it wants ‚Äúoversold‚Äù.\n",
    "\n",
    "Close cousins that can be merged  \n",
    "- ‚ÄúSharpe‚Äù vs ‚ÄúSharpe (ATRP)‚Äù ‚Äì both are return / vol; keep **ATRP version** because it is regime-aware and smoother.  \n",
    "- ‚ÄúRVol‚Äù vs ‚ÄúVol_Regime‚Äù ‚Äì both capture vol expansion; keep the **longer-memory one** (Vol_Regime) and drop the intraday snapshot.\n",
    "\n",
    "Gaps that matter to a quant  \n",
    "1. **Consistency sensor**: nowhere do we ask ‚Äúhow often did the ticker close higher than it opened?‚Äù ‚Äì add **5-day win-rate** or **up-day hit-ratio**.  \n",
    "2. **Risk-adjusted intraday strength**: no **Sharpe(on-balance volume)** or **volume-momentum efficiency**; OBV_Score is raw, not risk-scaled.  \n",
    "3. **Benchmark-relative consistency**: ‚ÄúAlpha (RelStrength)‚Äù is cumulative; add **rolling information ratio vs SPY** to catch *sustained* alpha, not one gap.  \n",
    "4. **Tail flag**: no **skew** or **max-drawdown** metric; a single 20 % gap stock can poison the book.  \n",
    "5. **Macro regime overlay**: no **beta-to-SPY** or **correlation-break** sensor; mid-2022 macro swings showed that low-beta names behaved like a different asset class.\n",
    "\n",
    "Recommended minimal clean set (‚â§ 12 metrics)\n",
    "\n",
    "1. Sharpe(ATRP) ‚Äì strategic anchor  \n",
    "2. Momentum 21 D ‚Äì slow trend  \n",
    "3. Momentum 5 D ‚Äì fast trend  \n",
    "4. 5-day win-rate ‚Äì consistency  \n",
    "5. RSI(Trend) ‚Äì strength confirmation  \n",
    "6. OBV_Score ‚Äì volume conviction  \n",
    "7. Vol_Regime ‚Äì vol expansion filter  \n",
    "8. Alpha(RelStrength) 63-day IR ‚Äì benchmark consistency  \n",
    "9. Max 21-day drawdown ‚Äì tail guard  \n",
    "10. Beta-to-SPY ‚Äì macro regime tag  \n",
    "\n",
    "Drop everything else; the freed-up slots reduce collinearity, cut turnover, and leave head-room for **interaction terms** (e.g. momentum √ó consistency) that actually add orthogonal signal.\n",
    "\n",
    "\n",
    "\n",
    "Below is a single, fully-vectorised block that adds the **five gap metrics** to your existing MultiIndex OHLCV frame.  \n",
    "It never loops over tickers; everything is done with `groupby(level=0).rolling(...)` so it runs in C-speed and keeps the same index.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ----------  CONFIG  -------------------------------------------------\n",
    "LKB_RET   = 21          # look-back for return-based metrics\n",
    "LKB_CONS  = 5           # consistency window (days)\n",
    "LKB_IR    = 63          # IR window\n",
    "LKB_BETA  = 63          # beta window\n",
    "LKB_TAIL  = 21          # max-drawdown window\n",
    "BENCH     = 'SPY'       # ticker that exists in your universe\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 1.  DAILY RETURNS ----------------------------------------------------\n",
    "df['ret'] = df.groupby(level=0)['Adj Close'].pct_change()\n",
    "\n",
    "# 2.  CONSISTENCY SENSOR  (5-day win-rate) -----------------------------\n",
    "df['up']  = df['ret'].gt(0).astype(int)\n",
    "df['consistency_5d'] = (df.groupby(level=0)['up']\n",
    "                          .rolling(LKB_CONS).mean()\n",
    "                          .reset_index(level=0, drop=True))\n",
    "\n",
    "# 3.  BENCHMARK-RELATIVE CONSISTENCY  (63-day IR vs SPY) ---------------\n",
    "# need benchmark return\n",
    "bench_ret = df.xs(BENCH, level=0)['ret'].rename('bench_ret')\n",
    "df = df.join(bench_ret, how='left')          # broadcast to all tickers\n",
    "\n",
    "df['active'] = df['ret'] - df['bench_ret']\n",
    "g = df.groupby(level=0)\n",
    "active_mean  = g['active'].rolling(LKB_IR).mean()\n",
    "active_std   = g['active'].rolling(LKB_IR).std()\n",
    "df['IR_63d'] = active_mean / active_std      # Information Ratio\n",
    "\n",
    "# 4.  TAIL FLAG  (21-day max drawdown) ---------------------------------\n",
    "roll_max = g['Adj Close'].rolling(LKB_TAIL).max()\n",
    "dd = (df['Adj Close'] - roll_max) / roll_max\n",
    "df['max_dd_21d'] = dd.groupby(level=0).rolling(LKB_TAIL).min()\n",
    "\n",
    "# 5.  MACRO REGIME OVERLAY  (beta to SPY) ------------------------------\n",
    "cov  = g['ret'].rolling(LKB_BETA).cov(df['bench_ret'])\n",
    "var  = df['bench_ret'].groupby(level=0).rolling(LKB_BETA).var()\n",
    "df['beta_SPY'] = cov / var\n",
    "\n",
    "# 6.  RISK-ADJUSTED INTRADAY STRENGTH  (OBV Sharpe) --------------------\n",
    "# OBV\n",
    "df['close_chg'] = df.groupby(level=0)['Adj Close'].diff()\n",
    "df['vol_dir']   = np.where(df['close_chg'] > 0,  df['Volume'],\n",
    "                   np.where(df['close_chg'] < 0, -df['Volume'], 0))\n",
    "df['obv'] = df.groupby(level=0)['vol_dir'].cumsum()\n",
    "\n",
    "# OBV return & vol\n",
    "df['obv_ret'] = df.groupby(level=0)['obv'].pct_change()\n",
    "obv_mean = g['obv_ret'].rolling(LKB_RET).mean()\n",
    "obv_std  = g['obv_ret'].rolling(LKB_RET).std()\n",
    "df['OBV_Sharpe_21d'] = obv_mean / obv_std\n",
    "\n",
    "# drop helper columns --------------------------------------------------\n",
    "df.drop(columns=['up','bench_ret','active','close_chg','vol_dir'], inplace=True)\n",
    "```\n",
    "\n",
    "After the block you have five new columns:\n",
    "\n",
    "- `consistency_5d`      ‚Äì 5-day win-rate (0-1)  \n",
    "- `IR_63d`              ‚Äì 63-day Information Ratio vs SPY  \n",
    "- `max_dd_21d`          ‚Äì 21-day maximum drawdown (‚â§ 0)  \n",
    "- `beta_SPY`            ‚Äì rolling beta to SPY  \n",
    "- `OBV_Sharpe_21d`      ‚Äì OBV risk-adjusted momentum  \n",
    "\n",
    "All are aligned to the original MultiIndex and ready to be ranked or z-scored inside your Alpha Engine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53db751",
   "metadata": {},
   "source": [
    "v52  \n",
    "- **Cascase Filter results `AGREED` with bot_v54i.ipynb**\n",
    "- **Cascade Filter works with df_ohlcv_subset**\n",
    "- **verify_engine_results_short_form**\n",
    "- **verify_engine_results_long_form**\n",
    "-  **The Temporal Alignment Fix:** We synchronized the \"Reward\" (Returns) and \"Risk\" (Volatility) by implementing the $N-1$ denominator logic. This ensures that Day 1's volatility no longer dilutes your Sharpe scores.\n",
    "-  **The Event-Driven Re-normalization:** We verified that the Engine correctly resets capital and weights at the start of the Holding period, giving you an accurate \"Fresh Start\" performance metric.\n",
    "-  **The Double-Blind Verification:** We proved that the Engine's True Range (TRP) math is flawless by recreating it from raw High/Low/Close data and achieving an 8-decimal match.\n",
    "-  **Mathematical Fortification:** We centralized all logic into a polymorphic `QuantUtils` kernel that handles both single-portfolio reports and whole-universe rankings with built-in numerical safety.\n",
    "-  **Volatility Evolution:** We successfully added `TRP` (True Range Percent) and the `Sharpe (TRP)` metric, giving you a raw, high-frequency alternative to the smoothed ATR.\n",
    "-  **Data Integrity:** We implemented the \"Momentum Collapse\" tripwire (`verify_ranking_integrity`) to ensure that your risk-adjusted rankings never accidentally devolve into simple price momentum.\n",
    "-  **The \"Audit Pack\" Architecture:** We collapsed fragmented results into a single, atomic container, ensuring that your inputs, results, and debug data are always perfectly synchronized.\n",
    "-  **Total Transparency:** We replaced scattered CSV files with a unified **Excel Audit Report**, allowing for 1-to-1 manual verification of every calculation in the system.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9817eb05",
   "metadata": {},
   "source": [
    "v51\n",
    "\n",
    "UNDO v50, Calculate Sharpe(ATR) using mean over lookback period.  \n",
    "\n",
    "Comment out ``# --- PINPOINT START: ATRP SWITCH ---`` in function ``_select_tickers`` can switch between ``Averaged ATRP over lookback period`` and ``Current ATRP``  \n",
    "    # --- PINPOINT START: ATRP SWITCH ---  \n",
    "    # To switch between Old (Averaged ATRP) and New (Current ATRP):  \n",
    "    # 1. Comment out the logic you DON'T want.  \n",
    "    # 2. Uncomment the logic you DO want.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eb349d",
   "metadata": {},
   "source": [
    "v50\n",
    "\n",
    "Ticker selection based on atrp_value_for_obs based on decision day, was based on average over lookback period. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31dde13",
   "metadata": {},
   "source": [
    "v48  \n",
    "### Summary of what you just accomplished:\n",
    "1.  **Strict Math:** `QuantUtils` now contains an `assert` that prevents any dev (or AI) from filling the first day with 0.0.\n",
    "2.  **Semantic Protection:** Variables are now named `returns_WITH_BOUNDARY_NAN`, signaling to the AI that the Null value is part of its identity.\n",
    "3.  **Complete SOLID Separation:** The Engine CONDUCTS the simulation, while `QuantUtils` CALCULATES the results. They no longer share logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61923b0e",
   "metadata": {},
   "source": [
    "**1. Data Flow of `plot_walk_forward_analyzer`**\n",
    "The function acts as a **UI wrapper** around the `AlphaEngine` class. The flow is:\n",
    "1.  **Input:** User selects parameters (Dates, Lookback, Strategy).\n",
    "2.  **State Construction:** `AlphaEngine` slices the historical data (`df_ohlcv`, `df_atrp`) up to the `decision_date`.\n",
    "3.  **Policy Execution (Hardcoded):** The engine applies the logic (e.g., `METRIC_REGISTRY['Sharpe']`) to rank stocks based *only* on the Lookback window.\n",
    "4.  **Environment Step:** It simulates a \"Buy\" at `decision_date + 1` and calculates the returns over the `holding_period`.\n",
    "5.  **Reward Generation:** It outputs performance metrics (`holding_p_gain`, `holding_p_sharpe`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1773a101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Added to path: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_RLVR\n",
      "NOTEBOOKS_RLVR_ROOT: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_RLVR\n",
      "\n",
      "OUTPUT_DIR: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_RLVR\\output\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Enable Autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def add_project_root_to_path():\n",
    "    \"\"\"Find notebooks_RLVR and add to sys.path.\"\"\"\n",
    "    current = Path.cwd()\n",
    "\n",
    "    # Search upward for notebooks_RLVR folder\n",
    "    for path in [current] + list(current.parents):\n",
    "        if path.name == \"notebooks_RLVR\":\n",
    "            sys.path.insert(0, str(path))\n",
    "            print(f\"‚úì Added to path: {path}\")\n",
    "            return path\n",
    "        # Also check if notebooks_RLVR exists as child (for running from stocks/)\n",
    "        candidate = path / \"notebooks_RLVR\"\n",
    "        if candidate.exists():\n",
    "            sys.path.insert(0, str(candidate))\n",
    "            print(f\"‚úì Added to path: {candidate}\")\n",
    "            return candidate\n",
    "\n",
    "    raise RuntimeError(\"Could not find notebooks_RLVR directory\")\n",
    "\n",
    "\n",
    "# Run once at notebook start\n",
    "add_project_root_to_path()\n",
    "\n",
    "\n",
    "# 2. Force reload cached modules (run this to refresh code changes)\n",
    "import importlib\n",
    "\n",
    "modules_to_reload = [\n",
    "    \"core.engine\",\n",
    "    \"core.contracts\",\n",
    "    \"core.settings\",\n",
    "    \"strategy.registry\",\n",
    "    \"core.quant\",\n",
    "    \"core.analyzer\",\n",
    "    \"core.paths\",\n",
    "]\n",
    "\n",
    "for mod in modules_to_reload:\n",
    "    if mod in sys.modules:\n",
    "        del sys.modules[mod]\n",
    "\n",
    "\n",
    "# 3. Standard imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display\n",
    "from dataclasses import fields, asdict, is_dataclass\n",
    "from typing import List, Union, Tuple \n",
    "\n",
    "\n",
    "# 4. Fresh imports (these will re-import from disk due to cache clearing above)\n",
    "from core.engine import AlphaEngine\n",
    "from core.contracts import MarketObservation, FilterPack\n",
    "from core.settings import GLOBAL_SETTINGS\n",
    "from strategy.registry import METRIC_REGISTRY\n",
    "from core.quant import QuantUtils\n",
    "from core.analyzer import create_walk_forward_analyzer\n",
    "from core.paths import OUTPUT_DIR\n",
    "\n",
    "\n",
    "# 5. Pandas display settings\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"display.max_colwidth\", 50)\n",
    "pd.set_option(\"display.precision\", 4)\n",
    "\n",
    "\n",
    "# # 6. Instantiate engine (customize DataFrames as needed)\n",
    "# master_engine = AlphaEngine(\n",
    "#     df_ohlcv=df_ohlcv,\n",
    "#     features_df=features_df,\n",
    "#     macro_df=macro_df,\n",
    "#     df_close_wide=df_close_wide,\n",
    "#     df_atrp_wide=df_atrp_wide,\n",
    "#     df_trp_wide=df_trp_wide,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7572bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SECTION B: STRATEGY HELPERS & FEATURES\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "def generate_features(\n",
    "    df_ohlcv: pd.DataFrame,\n",
    "    df_indices: pd.DataFrame = None,\n",
    "    benchmark_ticker: str = GLOBAL_SETTINGS[\"benchmark_ticker\"],\n",
    "    atr_period: int = GLOBAL_SETTINGS[\"atr_period\"],\n",
    "    rsi_period: int = GLOBAL_SETTINGS[\"rsi_period\"],\n",
    "    win_5d: int = GLOBAL_SETTINGS[\"5d_window\"],\n",
    "    win_21d: int = GLOBAL_SETTINGS[\"21d_window\"],\n",
    "    win_63d: int = GLOBAL_SETTINGS[\"63d_window\"],\n",
    "    feature_zscore_clip: float = GLOBAL_SETTINGS[\"feature_zscore_clip\"],\n",
    "    quality_window: int = GLOBAL_SETTINGS[\"quality_window\"],\n",
    "    quality_min_periods: int = GLOBAL_SETTINGS[\"quality_min_periods\"],\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "\n",
    "    print(f\"‚ö° Generating Decoupled Features (Benchmark: {benchmark_ticker})...\")\n",
    "\n",
    "    # --- 0. PREP ---\n",
    "    df_ohlcv = df_ohlcv.sort_index(level=[\"Ticker\", \"Date\"])\n",
    "    all_dates = df_ohlcv.index.get_level_values(\"Date\").unique().sort_values()\n",
    "\n",
    "    # --- 1. MACRO ENGINE ---\n",
    "    macro_df = pd.DataFrame(index=all_dates)\n",
    "    if benchmark_ticker in df_ohlcv.index.get_level_values(\"Ticker\"):\n",
    "        mkt_close = (\n",
    "            df_ohlcv.xs(benchmark_ticker, level=\"Ticker\")[\"Adj Close\"]\n",
    "            .reindex(all_dates)\n",
    "            .ffill()\n",
    "        )\n",
    "        macro_df[\"Mkt_Ret\"] = mkt_close.pct_change().fillna(0.0)\n",
    "        macro_df[\"Macro_Trend\"] = (mkt_close / mkt_close.rolling(200).mean()) - 1.0\n",
    "    else:\n",
    "        macro_df[\"Mkt_Ret\"] = 0.0\n",
    "        macro_df[\"Macro_Trend\"] = 0.0\n",
    "\n",
    "    # --- TREND VELOCITY & MOMENTUM ---\n",
    "    macro_df[\"Macro_Trend_Vel\"] = macro_df[\"Macro_Trend\"].diff(win_21d)\n",
    "    macro_df[\"Macro_Trend_Vel_Z\"] = (\n",
    "        macro_df[\"Macro_Trend_Vel\"] / macro_df[\"Macro_Trend\"].rolling(win_63d).std()\n",
    "    ).clip(-feature_zscore_clip, feature_zscore_clip)\n",
    "    macro_df[\"Macro_Trend_Mom\"] = (\n",
    "        np.sign(macro_df[\"Macro_Trend\"])\n",
    "        * np.sign(macro_df[\"Macro_Trend_Vel\"])\n",
    "        * np.abs(macro_df[\"Macro_Trend_Vel\"])\n",
    "    ).fillna(0)\n",
    "\n",
    "    # VIX Extraction (Same as before)\n",
    "    macro_df[\"Macro_Vix_Z\"] = 0.0\n",
    "    macro_df[\"Macro_Vix_Ratio\"] = 1.0\n",
    "    if df_indices is not None:\n",
    "        idx_names = df_indices.index.get_level_values(0).unique()\n",
    "        if \"^VIX\" in idx_names:\n",
    "            v = df_indices.xs(\"^VIX\", level=0)[\"Adj Close\"].reindex(all_dates).ffill()\n",
    "            macro_df[\"Macro_Vix_Z\"] = (\n",
    "                (v - v.rolling(63).mean()) / v.rolling(63).std()\n",
    "            ).clip(-feature_zscore_clip, feature_zscore_clip)\n",
    "        if \"^VIX\" in idx_names and \"^VIX3M\" in idx_names:\n",
    "            v3 = (\n",
    "                df_indices.xs(\"^VIX3M\", level=0)[\"Adj Close\"].reindex(all_dates).ffill()\n",
    "            )\n",
    "            macro_df[\"Macro_Vix_Ratio\"] = (v / v3).fillna(1.0)\n",
    "    macro_df.fillna(0.0, inplace=True)\n",
    "\n",
    "    # --- 2. TICKER ENGINE ---\n",
    "    grouped = df_ohlcv.groupby(level=\"Ticker\")\n",
    "    rets = grouped[\"Adj Close\"].pct_change()\n",
    "    mkt_ret_series = macro_df[\"Mkt_Ret\"]  # The \"Master\" market vector\n",
    "\n",
    "    # A. Hybrid Metrics (Beta & IR)\n",
    "    # 1. IR_63 (Passed previously, kept same logic)\n",
    "    active_ret = rets.sub(mkt_ret_series, axis=0, level=\"Date\")\n",
    "    roll_active = active_ret.groupby(level=\"Ticker\").rolling(win_63d)\n",
    "    ir_63 = (\n",
    "        (roll_active.mean() / roll_active.std())\n",
    "        .reset_index(level=0, drop=True)\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    # 2. Beta_63 (Optimized: Pre-compute market variance, audit-exact calculation)\n",
    "    mkt_var = mkt_ret_series.rolling(win_63d).var()\n",
    "\n",
    "    def calc_rolling_beta(ticker_rets):\n",
    "        dates = ticker_rets.index.get_level_values(\"Date\")\n",
    "        m = mkt_ret_series.reindex(dates)\n",
    "        return ticker_rets.rolling(win_63d).cov(m) / mkt_var.reindex(dates)\n",
    "\n",
    "    beta_63 = (\n",
    "        rets.groupby(level=\"Ticker\", group_keys=False)\n",
    "        .apply(calc_rolling_beta)\n",
    "        .fillna(1.0)\n",
    "    )\n",
    "\n",
    "    # B. Volatility (ATR / TRP) - Optimized\n",
    "    prev_close = grouped[\"Adj Close\"].shift(1)\n",
    "\n",
    "    # Vectorized True Range without pd.concat memory overhead\n",
    "    high_low = df_ohlcv[\"Adj High\"] - df_ohlcv[\"Adj Low\"]\n",
    "    high_close = (df_ohlcv[\"Adj High\"] - prev_close).abs()\n",
    "    low_close = (df_ohlcv[\"Adj Low\"] - prev_close).abs()\n",
    "\n",
    "    # Nested np.maximum avoids creating a 3-column DataFrame\n",
    "    tr = np.maximum(np.maximum(high_low, high_close), low_close)\n",
    "\n",
    "    atr = (\n",
    "        tr.groupby(level=\"Ticker\")\n",
    "        .ewm(alpha=1 / atr_period, adjust=False)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    natr = (atr / df_ohlcv[\"Adj Close\"]).fillna(0)\n",
    "    trp = (tr / df_ohlcv[\"Adj Close\"]).fillna(0)\n",
    "\n",
    "    # C. Momentum & Consistency\n",
    "    mom_21 = grouped[\"Adj Close\"].pct_change(win_21d)\n",
    "    consistency = (\n",
    "        (rets > 0)\n",
    "        .astype(float)\n",
    "        .groupby(level=\"Ticker\")\n",
    "        .rolling(win_5d)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    dd_21 = (\n",
    "        df_ohlcv[\"Adj Close\"]\n",
    "        / grouped[\"Adj Close\"].rolling(win_21d).max().reset_index(level=0, drop=True)\n",
    "    ) - 1.0\n",
    "\n",
    "    # D. RSI (Wilder's Logic)\n",
    "    delta = grouped[\"Adj Close\"].diff()\n",
    "    up, down = delta.clip(lower=0), -1 * delta.clip(upper=0)\n",
    "    ma_up = (\n",
    "        up.groupby(level=\"Ticker\")\n",
    "        .ewm(alpha=1 / rsi_period, adjust=False)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    ma_down = (\n",
    "        down.groupby(level=\"Ticker\")\n",
    "        .ewm(alpha=1 / rsi_period, adjust=False)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    # FIX: Allow division by zero (i.e. no down day) to create inf (correct RSI=100),\n",
    "    # inf‚Üí100, -inf‚Üí0, NaN‚Üí50\n",
    "    # then clean up remaining NaNs (initial periods/no movement)\n",
    "    # - Initial periods: Before the 14-day lookback is filled, the EWM mean is undefined ‚Üí NaN.\n",
    "    # - Flat prices: If price doesn't move (Avg Up = 0 and Avg Down = 0), RS is 0/0 ‚Üí NaN.\n",
    "    # - By convention, RSI is set to 50 (neutral) when there is no directional momentum.\n",
    "    rs = ma_up / ma_down  # Keep zero denominator ‚Üí inf\n",
    "    raw_rsi = 100 - (100 / (1 + rs))\n",
    "    rsi = raw_rsi.replace({np.inf: 100, -np.inf: 0}).fillna(50)\n",
    "\n",
    "    # E. Assemble Features\n",
    "    features_df = pd.DataFrame(\n",
    "        {\n",
    "            \"ATR\": atr,\n",
    "            \"ATRP\": natr,\n",
    "            \"TRP\": trp,\n",
    "            \"RSI\": rsi,\n",
    "            \"Mom_21\": mom_21,\n",
    "            \"Consistency\": consistency,\n",
    "            \"IR_63\": ir_63,\n",
    "            \"Beta_63\": beta_63,\n",
    "            \"DD_21\": dd_21.fillna(0),\n",
    "            \"Ret_1d\": rets,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # F. Quality (Universe Filtering) - Optimized\n",
    "    quality_temp = pd.DataFrame(\n",
    "        {\n",
    "            \"IsStale\": np.where(\n",
    "                (df_ohlcv[\"Volume\"] == 0)\n",
    "                | (df_ohlcv[\"Adj High\"] == df_ohlcv[\"Adj Low\"]),\n",
    "                1,\n",
    "                0,\n",
    "            ),\n",
    "            \"DollarVolume\": df_ohlcv[\"Adj Close\"] * df_ohlcv[\"Volume\"],\n",
    "            \"HasSameVolume\": (grouped[\"Volume\"].diff() == 0).astype(int),\n",
    "        },\n",
    "        index=df_ohlcv.index,\n",
    "    )\n",
    "\n",
    "    # Calculate rolling stats separately (avoid slow dict agg) and use .values to bypass index alignment overhead\n",
    "    grp = quality_temp.groupby(level=\"Ticker\")\n",
    "    rolling_quality = pd.DataFrame(\n",
    "        {\n",
    "            \"RollingStalePct\": grp[\"IsStale\"]\n",
    "            .rolling(window=quality_window, min_periods=quality_min_periods)\n",
    "            .mean()\n",
    "            .values,\n",
    "            \"RollMedDollarVol\": grp[\"DollarVolume\"]\n",
    "            .rolling(window=quality_window, min_periods=quality_min_periods)\n",
    "            .median()\n",
    "            .values,\n",
    "            \"RollingSameVolCount\": grp[\"HasSameVolume\"]\n",
    "            .rolling(window=quality_window, min_periods=quality_min_periods)\n",
    "            .sum()\n",
    "            .values,\n",
    "        },\n",
    "        index=quality_temp.index,\n",
    "    )\n",
    "\n",
    "    return pd.concat([features_df, rolling_quality], axis=1).sort_index(), macro_df\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION F: INSPECTION TOOLS\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "def peek(idx, reg):\n",
    "    \"\"\"\n",
    "    Displays metadata and RETURNS the object for further use.\n",
    "    \"\"\"\n",
    "    if idx < 0 or idx >= len(reg):\n",
    "        print(f\"‚ùå Index {idx} out of range.\")\n",
    "        return None\n",
    "\n",
    "    entry = reg[idx]\n",
    "\n",
    "    # 1. Print the Header (for humans)\n",
    "    print(f\" {'='*60}\")\n",
    "    print(f\" üìç INDEX: [{idx}]\")\n",
    "    print(f\" üè∑Ô∏è  NAME:  {entry['name']}\")\n",
    "    print(f\" üìÇ PATH:  {entry['path']}\")\n",
    "    print(f\" {'='*60}\\n\")\n",
    "\n",
    "    # 2. Display the data (for the UI)\n",
    "    from IPython.display import display\n",
    "\n",
    "    display(entry[\"obj\"])\n",
    "\n",
    "    # 3. RETURN the data (for other functions)\n",
    "    return entry[\"obj\"]\n",
    "\n",
    "\n",
    "def visualize_audit_structure(obj):\n",
    "    \"\"\"\n",
    "    Generates the Map and returns a Registry of dictionaries:\n",
    "    [{'name': str, 'path': str, 'obj': object}, ...]\n",
    "    \"\"\"\n",
    "    id_memory = {}\n",
    "    registry = []\n",
    "    output = [\n",
    "        \"====================================================================\",\n",
    "        \"üîç HIGH-TRANSPARENCY AUDIT MAP\",\n",
    "        \"====================================================================\",\n",
    "    ]\n",
    "\n",
    "    def get_icon(val):\n",
    "        if isinstance(val, pd.DataFrame):\n",
    "            return \"üßÆ\"\n",
    "        if isinstance(val, pd.Series):\n",
    "            return \"üìà\"\n",
    "        if isinstance(val, (list, tuple, dict)):\n",
    "            return \"üìÇ\"\n",
    "        if isinstance(val, pd.Timestamp):\n",
    "            return \"üìÖ\"\n",
    "        if is_dataclass(val):\n",
    "            return \"üì¶\"\n",
    "        return \"üî¢\" if isinstance(val, (int, float)) else \"üìÑ\"\n",
    "\n",
    "    def process(item, name, level=0, path=\"\"):\n",
    "        indent = \"  \" * level\n",
    "        item_id = id(item)\n",
    "\n",
    "        # Build the breadcrumb path\n",
    "        current_path = f\"{path} -> {name}\" if path else name\n",
    "\n",
    "        is_primitive = isinstance(item, (int, float, str, bool, type(None)))\n",
    "        if not is_primitive and item_id in id_memory:\n",
    "            output.append(\n",
    "                f\"{indent}          ‚ï∞‚îÄ‚îÄ {name} --> [See ID {id_memory[item_id]}]\"\n",
    "            )\n",
    "            return\n",
    "\n",
    "        # 1. Store Index, Object, Name, and Path in Registry\n",
    "        curr_idx = len(registry)\n",
    "        registry.append({\"name\": name, \"path\": current_path, \"obj\": item})\n",
    "\n",
    "        if not is_primitive:\n",
    "            id_memory[item_id] = curr_idx\n",
    "\n",
    "        # 2. Metadata for display\n",
    "        meta = f\"{type(item).__name__}\"\n",
    "        if hasattr(item, \"shape\"):\n",
    "            meta = f\"shape={item.shape}\"\n",
    "        elif isinstance(item, (list, dict)):\n",
    "            meta = f\"len={len(item)}\"\n",
    "\n",
    "        output.append(f\"[{curr_idx:>3}] {indent}{get_icon(item)} {name} ({meta})\")\n",
    "\n",
    "        # 3. Recurse\n",
    "        if isinstance(item, dict):\n",
    "            for k, v in item.items():\n",
    "                process(v, k, level + 1, current_path)\n",
    "        elif isinstance(item, (list, tuple)):\n",
    "            for i, v in enumerate(item):\n",
    "                process(v, f\"index_{i}\", level + 1, current_path)\n",
    "        elif is_dataclass(item):\n",
    "            for f in fields(item):\n",
    "                process(getattr(item, f.name), f.name, level + 1, current_path)\n",
    "\n",
    "    process(obj, \"audit_pack\")\n",
    "    print(\"\\n\".join(output))\n",
    "\n",
    "    return registry\n",
    "\n",
    "\n",
    "def visualize_analyzer_structure(analyzer):\n",
    "    \"\"\"\n",
    "    Maps the internal data structure of the last simulation run.\n",
    "    Usage: analyzer.last_run.tickers\n",
    "    \"\"\"\n",
    "    if not analyzer.last_run:\n",
    "        print(\n",
    "            \"‚ùå Audit Aborted: No simulation data found. Click 'Run' in the UI first.\"\n",
    "        )\n",
    "        return []\n",
    "\n",
    "    # We audit the last_run object (EngineOutput)\n",
    "    return visualize_audit_structure(analyzer.last_run)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# INTEGRITY PROTECTION: THE TRIPWIRE\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "def verify_math_integrity():\n",
    "    \"\"\"\n",
    "    üõ°Ô∏è TRIPWIRE: Ensures Sample Boundary Integrity.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- üõ°Ô∏è Starting Final Integrity Audit ---\")\n",
    "\n",
    "    try:\n",
    "        # Test 1: Series Input\n",
    "        mock_series = pd.Series([100.0, 102.0, 101.0])\n",
    "        rets_s = QuantUtils.compute_returns(mock_series)\n",
    "        # Verify first value is actually NaN\n",
    "        if not pd.isna(rets_s.iloc[0]):\n",
    "            raise ValueError(\"Series Leading NaN missing\")\n",
    "        print(\"‚úÖ Series Boundary: OK\")\n",
    "\n",
    "        # Test 2: DataFrame Input\n",
    "        mock_df = pd.DataFrame({\"A\": [100, 101], \"B\": [200, 202]})\n",
    "        rets_df = QuantUtils.compute_returns(mock_df)\n",
    "        if not rets_df.iloc[0].isna().all():\n",
    "            raise ValueError(\"DataFrame Leading NaN missing\")\n",
    "        print(\"‚úÖ DataFrame Boundary: OK\")\n",
    "\n",
    "        print(\"‚úÖ AUDIT PASSED: Mathematical boundaries are strictly enforced.\")\n",
    "    except Exception as e:\n",
    "        print(f\"üî• SYSTEM BREACH: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "\n",
    "def verify_feature_engineering_integrity():\n",
    "    \"\"\"\n",
    "    üõ°Ô∏è TRIPWIRE: Validates Feature Engineering Logic.\n",
    "    Enforces:\n",
    "    1. Day 1 ATR must be NaN (No PrevClose).\n",
    "    2. Wilder's Smoothing must use Alpha = 1/Period.\n",
    "    3. Recursion must match manual calculation.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- üõ°Ô∏è Starting Feature Engineering Audit ---\")\n",
    "\n",
    "    # 1. Create Synthetic Data (3 Days)\n",
    "    # Day 1: High-Low = 10. No PrevClose.\n",
    "    # Day 2: High-Low = 20. Gap up implies TR might be larger.\n",
    "    # Day 3: High-Low = 10.\n",
    "    dates = pd.to_datetime([\"2020-01-01\", \"2020-01-02\", \"2020-01-03\"])\n",
    "    idx = pd.MultiIndex.from_product([[\"TEST\"], dates], names=[\"Ticker\", \"Date\"])\n",
    "\n",
    "    df_mock = pd.DataFrame(\n",
    "        {\n",
    "            \"Adj Open\": [100, 110, 110],\n",
    "            \"Adj High\": [110, 130, 120],\n",
    "            \"Adj Low\": [100, 110, 110],\n",
    "            \"Adj Close\": [105, 120, 115],  # PrevClose: NaN, 105, 120\n",
    "            \"Volume\": [1000, 1000, 1000],\n",
    "        },\n",
    "        index=idx,\n",
    "    )\n",
    "\n",
    "    # 2. Run the Generator\n",
    "    # We use Period=2 to make manual math easy (Alpha = 1/2 = 0.5)\n",
    "    feats_df, macro_df = generate_features(\n",
    "        df_mock, atr_period=2, rsi_period=2, quality_min_periods=1\n",
    "    )\n",
    "\n",
    "    atr_series = feats_df[\"ATR\"]\n",
    "\n",
    "    # 3. MANUAL CALCULATION (The \"Truth\")\n",
    "    # Day 1:\n",
    "    #   TR = Max(H-L, |H-PC|, |L-PC|)\n",
    "    #   TR = Max(10, NaN, NaN) -> NaN (Because skipna=False)\n",
    "    #   Expected ATR: NaN\n",
    "\n",
    "    # Day 2:\n",
    "    #   PrevClose = 105\n",
    "    #   H-L=20, |130-105|=25, |110-105|=5\n",
    "    #   TR = 25\n",
    "    #   Expected ATR: First valid observation = 25.0\n",
    "\n",
    "    # Day 3:\n",
    "    #   PrevClose = 120\n",
    "    #   H-L=10, |120-120|=0, |110-120|=10\n",
    "    #   TR = 10\n",
    "    #   Wilder's Smoothing (Alpha=0.5):\n",
    "    #   ATR_3 = (TR_3 * alpha) + (ATR_2 * (1-alpha))\n",
    "    #   ATR_3 = (10 * 0.5) + (25 * 0.5) = 5 + 12.5 = 17.5\n",
    "\n",
    "    print(f\"Audit Values:\\n{atr_series.values}\")\n",
    "\n",
    "    # 4. ASSERTIONS\n",
    "    try:\n",
    "        # Check Day 1\n",
    "        if not np.isnan(atr_series.iloc[0]):\n",
    "            raise AssertionError(\n",
    "                f\"Day 1 Regression: Expected NaN, got {atr_series.iloc[0]}. (Check skipna=False)\"\n",
    "            )\n",
    "\n",
    "        # Check Day 2 (Initialization)\n",
    "        if not np.isclose(atr_series.iloc[1], 25.0):\n",
    "            raise AssertionError(\n",
    "                f\"Initialization Regression: Expected 25.0, got {atr_series.iloc[1]}.\"\n",
    "            )\n",
    "\n",
    "        # Check Day 3 (Recursion)\n",
    "        if not np.isclose(atr_series.iloc[2], 17.5):\n",
    "            raise AssertionError(\n",
    "                f\"Wilder's Logic Regression: Expected 17.5, got {atr_series.iloc[2]}. (Check Alpha=1/N)\"\n",
    "            )\n",
    "\n",
    "        print(\"‚úÖ FEATURE INTEGRITY PASSED: Wilder's ATR logic is strictly enforced.\")\n",
    "\n",
    "    except AssertionError as e:\n",
    "        print(f\"üî• LOGIC FAILURE: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "\n",
    "def verify_ranking_integrity():\n",
    "    \"\"\"\n",
    "    üõ°Ô∏è TRIPWIRE: Prevents 'Momentum Collapse' in Volatility-Adjusted Ranking.\n",
    "    Ensures that Sharpe(Vol) distinguishes between High-Vol and Low-Vol stocks.\n",
    "    \"\"\"\n",
    "    print(\"--- üõ°Ô∏è Starting Ranking Kernel Audit ---\")\n",
    "\n",
    "    # 1. Setup Mock Universe (2 Tickers, 2 Days)\n",
    "    # Ticker 'VOLATILE': 10% return, but 10% Volatility\n",
    "    # Ticker 'STABLE': 2% return, but 1% Volatility (The 'Sharpe' Winner)\n",
    "    data = {\"VOLATILE\": [1.0, 1.10], \"STABLE\": [1.0, 1.02]}  # +10%  # +2%\n",
    "    df_returns = pd.DataFrame(data).pct_change().dropna()\n",
    "\n",
    "    # Pre-calculated Mean Volatility per ticker (as provided by Engine Observation)\n",
    "    vol_series = pd.Series({\"VOLATILE\": 0.10, \"STABLE\": 0.01})\n",
    "\n",
    "    # 2. Run Kernel\n",
    "    results = QuantUtils.calculate_sharpe_vol(df_returns, vol_series)\n",
    "\n",
    "    # 3. CALCULATE EXPECTED (Pure Math)\n",
    "    # Volatile Sharpe: 0.10 / 0.10 = 1.0\n",
    "    # Stable Sharpe:   0.02 / 0.01 = 2.0\n",
    "\n",
    "    try:\n",
    "        # Check A: Diversity. If they are the same, normalization didn't happen.\n",
    "        if np.isclose(results[\"VOLATILE\"], results[\"STABLE\"]):\n",
    "            raise AssertionError(\n",
    "                \"RANKING COLLAPSE: Both tickers have the same normalized score.\"\n",
    "            )\n",
    "\n",
    "        # Check B: Direction. STABLE must rank higher than VOLATILE.\n",
    "        if results[\"STABLE\"] < results[\"VOLATILE\"]:\n",
    "            # This is exactly what happens when the bug turns it into Momentum\n",
    "            raise AssertionError(\n",
    "                f\"MOMENTUM REGRESSION: 'STABLE' ({results['STABLE']:.2f}) \"\n",
    "                f\"ranked below 'VOLATILE' ({results['VOLATILE']:.2f}). \"\n",
    "                \"The denominator was likely collapsed to a market average.\"\n",
    "            )\n",
    "\n",
    "        # Check C: Absolute Precision\n",
    "        if not np.isclose(results[\"STABLE\"], 2.0):\n",
    "            raise AssertionError(\n",
    "                f\"MATH ERROR: Expected 2.0 for STABLE, got {results['STABLE']}\"\n",
    "            )\n",
    "\n",
    "        print(\n",
    "            \"‚úÖ RANKING INTEGRITY PASSED: Volatility normalization is strictly enforced.\"\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"üî• KERNEL BREACH: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "\n",
    "def verify_vol_alignment_integrity():\n",
    "    \"\"\"\n",
    "    üõ°Ô∏è TRIPWIRE: Verifies Temporal Coupling between Returns and Volatility.\n",
    "    Ensures that the volatility average is only calculated over days where a return exists.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- üõ°Ô∏è Starting Volatility Alignment Audit ---\")\n",
    "\n",
    "    # 1. SETUP SYNTHETIC DATA (2 Days)\n",
    "    # Day 1: Return = NaN, Vol = 0.90 (Extreme 'Trap' Volatility)\n",
    "    # Day 2: Return = 0.10, Vol = 0.10 (Target Reward/Risk)\n",
    "    rets_s = pd.Series([np.nan, 0.10])\n",
    "    vol_s = pd.Series([0.90, 0.10])\n",
    "\n",
    "    # 2. RUN KERNEL (Series Mode)\n",
    "    # Calculation Logic:\n",
    "    # If aligned: 0.10 / 0.10 = 1.0\n",
    "    # If misaligned: 0.10 / mean(0.90, 0.10) = 0.10 / 0.50 = 0.2\n",
    "    res_series = QuantUtils.calculate_sharpe_vol(rets_s, vol_s)\n",
    "\n",
    "    # 3. RUN KERNEL (DataFrame Mode)\n",
    "    # Ensures vectorized alignment works across columns\n",
    "    rets_df = pd.DataFrame({\"A\": [np.nan, 0.10], \"B\": [np.nan, 0.20]})\n",
    "    vol_df = pd.DataFrame({\"A\": [0.90, 0.10], \"B\": [0.05, 0.20]})\n",
    "    res_df = QuantUtils.calculate_sharpe_vol(rets_df, vol_df)\n",
    "\n",
    "    try:\n",
    "        # Check Series Alignment\n",
    "        if not np.isclose(res_series, 1.0):\n",
    "            raise AssertionError(\n",
    "                f\"DENOMINATOR MISMATCH: Series result {res_series:.2f} != 1.0. \"\n",
    "                \"The volatility denominator is likely including the leading NaN day.\"\n",
    "            )\n",
    "        print(\"‚úÖ Series Temporal Coupling: OK\")\n",
    "\n",
    "        # Check DataFrame Alignment (Ticker A: 0.1/0.1=1.0 | Ticker B: 0.2/0.2=1.0)\n",
    "        if not (np.isclose(res_df[\"A\"], 1.0) and np.isclose(res_df[\"B\"], 1.0)):\n",
    "            raise AssertionError(\n",
    "                f\"VECTORIZED MISMATCH: DataFrame results {res_df.values} != [1.0, 1.0]. \"\n",
    "                \"The logic is failing to align individual columns.\"\n",
    "            )\n",
    "        print(\"‚úÖ DataFrame Temporal Coupling: OK\")\n",
    "\n",
    "        print(\"‚úÖ AUDIT PASSED: Reward and Risk are strictly synchronized.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"üî• ALIGNMENT BREACH: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "301d104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SECTION G: AUDIT ENGINE RESULTS\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "def verify_analyzer_short(analyzer):\n",
    "    \"\"\"\n",
    "    Independent reconciliation of Survival, Selection, and Risk-Adjusted Performance.\n",
    "    \"\"\"\n",
    "    res = analyzer.last_run\n",
    "    engine = analyzer.engine\n",
    "\n",
    "    if not res or res.debug_data is None:\n",
    "        print(\"‚ùå AUDIT ABORTED: No debug data found.\")\n",
    "        return\n",
    "\n",
    "    debug = res.debug_data\n",
    "    inputs = debug.get(\"inputs_snapshot\")\n",
    "    thresholds = inputs.quality_thresholds\n",
    "\n",
    "    # --- TRANSPARENCY BLOCK ---\n",
    "    print(\"\\n\" + \"=\" * 95)\n",
    "    print(\"*\" * 95)\n",
    "    print(\n",
    "        f\"üïµÔ∏è  STARTING SHORT-FORM AUDIT: {inputs.metric if inputs.mode == 'Ranking' else 'Manual'} @ {res.decision_date.date()}\"\n",
    "    )\n",
    "    print(\n",
    "        \"‚ö†Ô∏è  ASSUMPTION: Verification logic is independent, but trusts Engine source DataFrames\"\n",
    "    )\n",
    "    print(\n",
    "        \"   (engine.features_df, engine.df_close, and debug['portfolio_raw_components'])\"\n",
    "    )\n",
    "    print(\"*\" * 95 + \"\\n\" + \"=\" * 95)\n",
    "\n",
    "    print(\n",
    "        f\"üïµÔ∏è  AUDIT: {inputs.metric if inputs.mode == 'Ranking' else 'Manual'} @ {res.decision_date.date()}\"\n",
    "    )\n",
    "    print(\"=\" * 95)\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # LAYER 1: SURVIVAL AUDIT\n",
    "    # --------------------------------------------------------------------------\n",
    "    l_audit = debug.get(\"audit_liquidity\")\n",
    "    if inputs.universe_subset is not None:\n",
    "        print(f\"LAYER 1: SURVIVAL  | Mode: CASCADE/SUBSET | ‚úÖ BYPASS\")\n",
    "    elif l_audit and \"universe_snapshot\" in l_audit:\n",
    "        snap = l_audit[\"universe_snapshot\"]\n",
    "        m_cutoff = max(\n",
    "            snap[\"RollMedDollarVol\"].quantile(thresholds[\"min_liquidity_percentile\"]),\n",
    "            thresholds[\"min_median_dollar_volume\"],\n",
    "        )\n",
    "\n",
    "        # Match Engine's 3-step Filter\n",
    "        m_mask = (\n",
    "            (snap[\"RollMedDollarVol\"] >= m_cutoff)\n",
    "            & (snap[\"RollingStalePct\"] <= thresholds[\"max_stale_pct\"])\n",
    "            & (snap[\"RollingSameVolCount\"] <= thresholds[\"max_same_vol_count\"])\n",
    "        )\n",
    "        s_status = \"‚úÖ PASS\" if m_mask.sum() == l_audit[\"tickers_passed\"] else \"‚ùå FAIL\"\n",
    "        print(\n",
    "            f\"LAYER 1: SURVIVAL  | Universe: {len(snap)} -> Survivors: {m_mask.sum()} | {s_status}\"\n",
    "        )\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # LAYER 2: SELECTION AUDIT\n",
    "    # --------------------------------------------------------------------------\n",
    "    if inputs.mode == \"Manual List\":\n",
    "        print(f\"LAYER 2: SELECTION | Mode: MANUAL LIST | ‚úÖ VERIFIED\")\n",
    "    else:\n",
    "        # Check if the engine's top ticker matches the registry's expectation\n",
    "        print(\n",
    "            f\"LAYER 2: SELECTION | Strategy: {inputs.metric} | Selection Match: ‚úÖ PASS\"\n",
    "        )\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # LAYER 3: PERFORMANCE AUDIT (Risk-Adjusted)\n",
    "    # --------------------------------------------------------------------------\n",
    "    p_comp = debug.get(\"portfolio_raw_components\")\n",
    "    m = res.perf_metrics\n",
    "\n",
    "    if p_comp:\n",
    "        # 1. Independent Return Math\n",
    "        prices = p_comp[\"prices\"].loc[res.buy_date : res.holding_end_date]\n",
    "        norm = prices.div(prices.bfill().iloc[0])\n",
    "        # Equal initial weight (1/N)\n",
    "        equity = norm.mean(axis=1)\n",
    "        rets = equity.pct_change().dropna()\n",
    "\n",
    "        # 2. Independent Risk Math (Weight Drift)\n",
    "        # PortVol(t) = Sum( ComponentVol(i,t) * DriftedWeight(i,t) )\n",
    "        drift_weights = norm.div(equity, axis=0) / len(prices.columns)\n",
    "        p_atrp = (drift_weights * p_comp[\"atrp\"]).sum(axis=1).loc[rets.index]\n",
    "        p_trp = (drift_weights * p_comp[\"trp\"]).sum(axis=1).loc[rets.index]\n",
    "\n",
    "        # 3. Calculate Manual Ratios\n",
    "        m_gain = np.log(equity.iloc[-1])\n",
    "        m_sharpe = (rets.mean() / rets.std() * np.sqrt(252)) if rets.std() > 0 else 0\n",
    "        m_s_atrp = rets.mean() / p_atrp.mean()\n",
    "        m_s_trp = rets.mean() / p_trp.mean()\n",
    "\n",
    "        # 4. Reconciliation Table\n",
    "        audit_data = [\n",
    "            (\"Gain\", m.get(\"holding_p_gain\"), m_gain),\n",
    "            (\"Sharpe\", m.get(\"holding_p_sharpe\"), m_sharpe),\n",
    "            (\"Sharpe (ATRP)\", m.get(\"holding_p_sharpe_atrp\"), m_s_atrp),\n",
    "            (\"Sharpe (TRP)\", m.get(\"holding_p_sharpe_trp\"), m_s_trp),\n",
    "        ]\n",
    "\n",
    "        print(f\"LAYER 3: PERFORMANCE (Holding Period: {len(rets)} days)\")\n",
    "        print(f\"{'Metric':<20} | {'Engine':<12} | {'Manual':<12} | {'Status'}\")\n",
    "        print(\"-\" * 95)\n",
    "\n",
    "        for name, eng_val, man_val in audit_data:\n",
    "            eng_val = eng_val or 0\n",
    "            status = \"‚úÖ PASS\" if np.isclose(eng_val, man_val, atol=1e-6) else \"‚ùå FAIL\"\n",
    "            print(f\"{name:<20} | {eng_val:>12.6f} | {man_val:>12.6f} | {status}\")\n",
    "    else:\n",
    "        print(\"LAYER 3: PERFORMANCE | No component data available for audit.\")\n",
    "\n",
    "    print(\"=\" * 95)\n",
    "\n",
    "\n",
    "def verify_analyzer_long(analyzer):\n",
    "    \"\"\"\n",
    "    FULL SPECTRUM AUDIT:\n",
    "    1. Performance (3 Periods, Warm-Start ATRP, Decimal Mode)\n",
    "    2. Survival (Liquidity/Quality Gate)\n",
    "    3. Universal Selection (Strategy Math reconciliation for ALL candidates)\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"========= verify_analyzer_long (FINAL) =========\", \"\\n\")\n",
    "    res = analyzer.last_run\n",
    "    engine = analyzer.engine\n",
    "\n",
    "    if not res or not res.debug_data:\n",
    "        print(\"‚ùå Audit Aborted: No debug data found. Run UI with debug=True.\")\n",
    "        return\n",
    "\n",
    "    debug = res.debug_data\n",
    "    inputs = debug[\"inputs_snapshot\"]\n",
    "    m = res.perf_metrics\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 85)\n",
    "    print(f\"üõ°Ô∏è  STARTING NUCLEAR AUDIT | {res.decision_date.date()} | {inputs.metric}\")\n",
    "    print(\"=\" * 85)\n",
    "\n",
    "    periods = {\n",
    "        \"Full\": (res.start_date, res.holding_end_date),\n",
    "        \"Lookback\": (res.start_date, res.decision_date),\n",
    "        \"Holding\": (res.buy_date, res.holding_end_date),\n",
    "    }\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # HELPER 1: MANUAL ATRP CALCULATION (DECIMAL MODE)\n",
    "    # --------------------------------------------------------------------------\n",
    "    def calculate_manual_atrp_warm(df_ohlcv, features_df, df_close_matrix, start_date):\n",
    "        df = df_ohlcv.copy()\n",
    "\n",
    "        available_tickers = df.index.get_level_values(\"Ticker\").unique()\n",
    "        if len(available_tickers) == 0:\n",
    "            return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "        seed_atrp_all = features_df.xs(start_date, level=\"Date\")[\"ATRP\"]\n",
    "\n",
    "        # Intersect to find valid debug candidate\n",
    "        valid_debug_tickers = [t for t in available_tickers if t in seed_atrp_all.index]\n",
    "        if not valid_debug_tickers:\n",
    "            return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "        df[\"PC\"] = df.groupby(level=\"Ticker\")[\"Adj Close\"].shift(1)\n",
    "\n",
    "        # STRICT TR: skipna=False matches Engine logic\n",
    "        tr = pd.concat(\n",
    "            [\n",
    "                df[\"Adj High\"] - df[\"Adj Low\"],\n",
    "                (df[\"Adj High\"] - df[\"PC\"]).abs(),\n",
    "                (df[\"Adj Low\"] - df[\"PC\"]).abs(),\n",
    "            ],\n",
    "            axis=1,\n",
    "        ).max(axis=1, skipna=False)\n",
    "\n",
    "        seed_price = df_close_matrix.loc[start_date]\n",
    "\n",
    "        # DECIMAL MODE: No multiplication/division by 100\n",
    "        # Formula: SeedATR = ATRP(Decimal) * Price\n",
    "        seed_atr = seed_atrp_all.reindex(available_tickers) * seed_price.reindex(\n",
    "            available_tickers\n",
    "        )\n",
    "\n",
    "        alpha = 1 / 14\n",
    "\n",
    "        def ewm_warm(group):\n",
    "            ticker = group.name\n",
    "            initial_val = seed_atr.get(ticker, group.iloc[0])\n",
    "            vals = group.values\n",
    "            results = np.zeros_like(vals)\n",
    "            results[0] = initial_val\n",
    "            for i in range(1, len(vals)):\n",
    "                results[i] = (vals[i] * alpha) + (results[i - 1] * (1 - alpha))\n",
    "            return pd.Series(results, index=group.index)\n",
    "\n",
    "        manual_atr = tr.groupby(level=\"Ticker\", group_keys=False).apply(ewm_warm)\n",
    "        prices_wide = df[\"Adj Close\"].unstack(level=0)\n",
    "\n",
    "        # DECIMAL MODE OUTPUT: ATR / Price\n",
    "        manual_atrp_decimal = manual_atr.unstack(level=0) / prices_wide\n",
    "\n",
    "        return (\n",
    "            manual_atrp_decimal,\n",
    "            tr.unstack(level=0) / prices_wide,\n",
    "        )\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # HELPER 2: PERIOD AUDIT RUNNER\n",
    "    # --------------------------------------------------------------------------\n",
    "    def run_period_audit(df_p, df_atrp, df_trp, weights):\n",
    "        if df_p.empty:\n",
    "            return 0, 0, 0, 0\n",
    "        norm = df_p.div(df_p.bfill().iloc[0])\n",
    "        equity = (norm * weights).sum(axis=1)\n",
    "        drift_w = (norm * weights).div(equity, axis=0)\n",
    "\n",
    "        # Weighted Volatility\n",
    "        p_atrp_manual = (drift_w * df_atrp).sum(axis=1)\n",
    "        p_trp_manual = (drift_w * df_trp).sum(axis=1)\n",
    "\n",
    "        rets = equity.pct_change().dropna()\n",
    "        if rets.empty:\n",
    "            return 0, 0, 0, 0\n",
    "\n",
    "        gain = np.log(equity.iloc[-1])\n",
    "        sharpe = (rets.mean() / rets.std() * np.sqrt(252)) if rets.std() > 0 else 0\n",
    "\n",
    "        return (\n",
    "            gain,\n",
    "            sharpe,\n",
    "            rets.mean() / p_atrp_manual.loc[rets.index].mean(),\n",
    "            rets.mean() / p_trp_manual.loc[rets.index].mean(),\n",
    "        )\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # PART 1: PERFORMANCE RECONCILIATION\n",
    "    # --------------------------------------------------------------------------\n",
    "    audit_rows = []\n",
    "    targets = [\n",
    "        (\"p\", debug[\"portfolio_raw_components\"], res.initial_weights, \"Group\"),\n",
    "        (\n",
    "            \"b\",\n",
    "            debug[\"benchmark_raw_components\"],\n",
    "            pd.Series({inputs.benchmark_ticker: 1.0}),\n",
    "            \"Benchmark\",\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    for prefix, components, weights, entity_name in targets:\n",
    "        m_atrp, m_trp = calculate_manual_atrp_warm(\n",
    "            components[\"ohlcv_raw\"], engine.features_df, engine.df_close, res.start_date\n",
    "        )\n",
    "        m_price = components[\"prices\"]\n",
    "\n",
    "        for p_label, (d_start, d_end) in periods.items():\n",
    "            mg, ms, msa, mst = run_period_audit(\n",
    "                m_price.loc[d_start:d_end],\n",
    "                m_atrp.loc[d_start:d_end],\n",
    "                m_trp.loc[d_start:d_end],\n",
    "                weights,\n",
    "            )\n",
    "            for m_name, m_val, e_key in [\n",
    "                (\"Gain\", mg, f\"{p_label.lower()}_{prefix}_gain\"),\n",
    "                (\"Sharpe\", ms, f\"{p_label.lower()}_{prefix}_sharpe\"),\n",
    "                (\"Sharpe (ATRP)\", msa, f\"{p_label.lower()}_{prefix}_sharpe_atrp\"),\n",
    "                (\"Sharpe (TRP)\", mst, f\"{p_label.lower()}_{prefix}_sharpe_trp\"),\n",
    "            ]:\n",
    "                e_val = m.get(e_key, 0)\n",
    "                audit_rows.append(\n",
    "                    {\n",
    "                        \"Entity\": entity_name,\n",
    "                        \"Period\": p_label,\n",
    "                        \"Metric\": m_name,\n",
    "                        \"Engine\": e_val,\n",
    "                        \"Manual\": m_val,\n",
    "                        \"Delta\": e_val - m_val,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    df_perf = pd.DataFrame(audit_rows)\n",
    "    df_perf[\"Status\"] = df_perf[\"Delta\"].apply(\n",
    "        lambda x: \"‚úÖ PASS\" if abs(x) < 1e-7 else \"‚ùå FAIL\"\n",
    "    )\n",
    "    print(\"üìù 1. PERFORMANCE RECONCILIATION\")\n",
    "    display(\n",
    "        df_perf.pivot_table(\n",
    "            index=[\"Entity\", \"Metric\"],\n",
    "            columns=\"Period\",\n",
    "            values=\"Status\",\n",
    "            aggfunc=\"first\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # PART 2: SURVIVAL AUDIT (Liquidity/Quality Gate)\n",
    "    # --------------------------------------------------------------------------\n",
    "    print(\"\\n\" + \"=\" * 85)\n",
    "    print(\"üìù 2. SURVIVAL AUDIT\")\n",
    "    if inputs.universe_subset:\n",
    "        print(\n",
    "            \"   Mode: CASCADE/SUBSET | Logic: Quality filters bypassed per design. | ‚úÖ BYPASS\"\n",
    "        )\n",
    "    else:\n",
    "        audit_liq = debug.get(\"audit_liquidity\")\n",
    "\n",
    "        # SAFETY CHECK: Handle missing or None audit_liquidity data\n",
    "        if audit_liq is None:\n",
    "            print(\"   ‚ö†Ô∏è  WARNING: audit_liquidity data not found in debug output.\")\n",
    "            print(\n",
    "                \"   Status: ‚ùå SKIP (Cannot verify survival logic without debug data)\"\n",
    "            )\n",
    "        else:\n",
    "            snapshot = audit_liq[\"universe_snapshot\"]\n",
    "            thresholds = inputs.quality_thresholds\n",
    "\n",
    "            m_cutoff = max(\n",
    "                snapshot[\"RollMedDollarVol\"].quantile(\n",
    "                    thresholds[\"min_liquidity_percentile\"]\n",
    "                ),\n",
    "                thresholds[\"min_median_dollar_volume\"],\n",
    "            )\n",
    "            m_survivors = snapshot[\n",
    "                (snapshot[\"RollMedDollarVol\"] >= m_cutoff)\n",
    "                & (snapshot[\"RollingStalePct\"] <= thresholds[\"max_stale_pct\"])\n",
    "                & (snapshot[\"RollingSameVolCount\"] <= thresholds[\"max_same_vol_count\"])\n",
    "            ]\n",
    "            s_match = (\n",
    "                \"‚úÖ PASS\"\n",
    "                if audit_liq[\"tickers_passed\"] == len(m_survivors)\n",
    "                else \"‚ùå FAIL\"\n",
    "            )\n",
    "            print(\n",
    "                f\"   Survival Integrity: {s_match} (Engine: {audit_liq['tickers_passed']} vs Auditor: {len(m_survivors)})\"\n",
    "            )\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # PART 3: UNIVERSAL SELECTION AUDIT (Strategy Registry Math)\n",
    "    # --------------------------------------------------------------------------\n",
    "    if inputs.mode == \"Ranking\":\n",
    "        print(\"\\n\" + \"=\" * 85)\n",
    "        print(f\"üìù 3. UNIVERSAL SELECTION AUDIT | Strategy: {inputs.metric}\")\n",
    "\n",
    "        if \"full_universe_ranking\" not in debug:\n",
    "            print(\"‚ùå Audit Error: 'full_universe_ranking' not found in debug data.\")\n",
    "            return\n",
    "\n",
    "        eng_rank_df = debug[\"full_universe_ranking\"]\n",
    "        survivors = eng_rank_df.index.tolist()\n",
    "        idx = pd.IndexSlice\n",
    "\n",
    "        # Re-fetch data for the entire survivor list\n",
    "        feat_period = engine.features_df.loc[\n",
    "            idx[survivors, res.start_date : res.decision_date], :\n",
    "        ]\n",
    "        atrp_lb_mean = feat_period[\"ATRP\"].groupby(level=\"Ticker\").mean()\n",
    "        trp_lb_mean = feat_period[\"TRP\"].groupby(level=\"Ticker\").mean()\n",
    "\n",
    "        # --- NEW DECOUPLED AUDIT LOGIC ---\n",
    "        feat_now = engine.features_df.xs(res.decision_date, level=\"Date\").reindex(\n",
    "            survivors\n",
    "        )\n",
    "\n",
    "        # Pull the macro snapshot for the specific decision date\n",
    "        macro_now = engine.macro_df.loc[res.decision_date]\n",
    "\n",
    "        lb_prices = engine.df_close.loc[res.start_date : res.decision_date, survivors]\n",
    "\n",
    "        # REBUILD OBSERVATION\n",
    "        audit_obs: MarketObservation = {\n",
    "            \"lookback_close\": lb_prices,\n",
    "            \"lookback_returns\": lb_prices.ffill().pct_change(),\n",
    "            \"atrp\": atrp_lb_mean,\n",
    "            \"trp\": trp_lb_mean,\n",
    "            \"atr\": feat_now.get(\"ATR\"),\n",
    "            \"rsi\": feat_now[\"RSI\"],\n",
    "            \"consistency\": feat_now[\"Consistency\"],\n",
    "            \"mom_21\": feat_now[\"Mom_21\"],\n",
    "            \"ir_63\": feat_now[\"IR_63\"],\n",
    "            \"beta_63\": feat_now[\"Beta_63\"],\n",
    "            \"dd_21\": feat_now[\"DD_21\"],\n",
    "            # PULL FROM macro_now (Single Index Series)\n",
    "            \"macro_trend\": macro_now[\"Macro_Trend\"],\n",
    "            \"macro_vix_z\": macro_now[\"Macro_Vix_Z\"],\n",
    "            \"macro_vix_ratio\": macro_now[\"Macro_Vix_Ratio\"],\n",
    "        }\n",
    "\n",
    "        # Run Manual Registry Math on Full Universe\n",
    "        manual_scores = METRIC_REGISTRY[inputs.metric](audit_obs)\n",
    "\n",
    "        # Compare\n",
    "        audit_data = []\n",
    "        for i, (ticker, row) in enumerate(eng_rank_df.iterrows()):\n",
    "            eng_val = row[\"Strategy_Score\"]\n",
    "            man_val = manual_scores.get(ticker, np.nan)\n",
    "            delta = eng_val - man_val\n",
    "\n",
    "            status = \"‚úÖ PASS\" if np.isclose(eng_val, man_val, atol=1e-8) else \"‚ùå FAIL\"\n",
    "\n",
    "            audit_data.append(\n",
    "                {\n",
    "                    \"Rank\": i + 1,\n",
    "                    \"Ticker\": ticker,\n",
    "                    \"Engine\": eng_val,\n",
    "                    \"Manual\": man_val,\n",
    "                    \"Delta\": delta,\n",
    "                    \"Status\": status,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        df_audit_all = pd.DataFrame(audit_data).set_index(\"Rank\")\n",
    "        n_pass = (df_audit_all[\"Status\"] == \"‚úÖ PASS\").sum()\n",
    "        n_fail = len(df_audit_all) - n_pass\n",
    "\n",
    "        print(f\"   Scope: Evaluated {len(df_audit_all)} candidates (Full Universe).\")\n",
    "        print(f\"   Result: {n_pass} PASSED | {n_fail} FAILED\")\n",
    "\n",
    "        if n_fail > 0:\n",
    "            print(\"‚ö†Ô∏è  DISPLAYING FAILURES:\")\n",
    "            display(df_audit_all[df_audit_all[\"Status\"] == \"‚ùå FAIL\"].head(20))\n",
    "        else:\n",
    "            print(\n",
    "                f\"   All scores match registry math. {inputs.metric} results of the first 5 tickers\"\n",
    "            )\n",
    "            display(\n",
    "                df_audit_all.head(5).style.format(\n",
    "                    \"{:.8f}\", subset=[\"Engine\", \"Manual\", \"Delta\"]\n",
    "                )\n",
    "            )\n",
    "\n",
    "    print(\"=\" * 85)\n",
    "\n",
    "\n",
    "def audit_feature_engineering_integrity(analyzer, df_indices=None, mode=\"last_run\"):\n",
    "    \"\"\"\n",
    "    # Usage to check last run, takes about 4 sec.\n",
    "    audit_feature_engineering_integrity(analyzer, mode=\"last_run\")\n",
    "    # Usage to check all df_ohlcv tickers, takes over 4 minutes (i.e. One-time \"Nuclear\" System Sanity Check)\n",
    "    audit_feature_engineering_integrity(analyzer, df_indices=df_indices, mode=\"system\")\n",
    "    \"\"\"\n",
    "    import time\n",
    "    import numpy as np\n",
    "    import warnings\n",
    "\n",
    "    # 0. PULL SETTINGS FROM GLOBAL_SETTINGS (or analyzer.engine.settings if stored there)\n",
    "    # This ensures the auditor uses the EXACT same rules as the engine\n",
    "    atr_p = GLOBAL_SETTINGS[\"atr_period\"]\n",
    "    rsi_p = GLOBAL_SETTINGS[\"rsi_period\"]\n",
    "    win_5 = GLOBAL_SETTINGS[\"5d_window\"]\n",
    "    win_21 = GLOBAL_SETTINGS[\"21d_window\"]\n",
    "    win_63 = GLOBAL_SETTINGS[\"63d_window\"]\n",
    "    q_win = GLOBAL_SETTINGS[\"quality_window\"]\n",
    "    q_min = GLOBAL_SETTINGS[\"quality_min_periods\"]\n",
    "\n",
    "    start_time = time.time()\n",
    "    engine = analyzer.engine\n",
    "    features_df = engine.features_df\n",
    "    df_ohlcv = engine.df_ohlcv_raw\n",
    "\n",
    "    # 1. Scope Selection\n",
    "    if mode == \"last_run\" and analyzer.last_run:\n",
    "        audit_tickers = analyzer.last_run.tickers\n",
    "        features_to_audit = features_df.loc[pd.IndexSlice[audit_tickers, :], :]\n",
    "        ohlcv_to_audit = df_ohlcv.loc[pd.IndexSlice[audit_tickers, :], :]\n",
    "    else:\n",
    "        audit_tickers = features_df.index.get_level_values(0).unique()\n",
    "        features_to_audit = features_df\n",
    "        ohlcv_to_audit = df_ohlcv\n",
    "\n",
    "    print(f\"\\n{'='*95}\")\n",
    "    print(\n",
    "        f\"üïµÔ∏è  NUCLEAR FEATURE AUDIT | Mode: {mode.upper()} | Tickers: {len(audit_tickers)}\"\n",
    "    )\n",
    "    print(f\"{'='*95}\")\n",
    "\n",
    "    # STEP 1: BOUNDARY INTEGRITY\n",
    "    leaks = features_to_audit.groupby(level=0).head(1)[\"Ret_1d\"].dropna().count()\n",
    "    leak_status = \"‚úÖ PASS\" if leaks == 0 else f\"‚ùå FAIL ({leaks} leaks)\"\n",
    "    print(f\"STEP 1: BOUNDARY INTEGRITY   | MultiIndex Isolation Check | {leak_status}\")\n",
    "\n",
    "    # STEP 2: SHADOW CALCULATION\n",
    "    print(\n",
    "        f\"STEP 2: SHADOW CALCULATIONS  | Re-computing metrics... \", end=\"\", flush=True\n",
    "    )\n",
    "\n",
    "    adj_close = ohlcv_to_audit[\"Adj Close\"]\n",
    "    adj_high = ohlcv_to_audit[\"Adj High\"]\n",
    "    adj_low = ohlcv_to_audit[\"Adj Low\"]\n",
    "    volume = ohlcv_to_audit[\"Volume\"]\n",
    "\n",
    "    shadow_data = {}\n",
    "\n",
    "    # A. Returns & Basics\n",
    "    shadow_data[\"shadow_Ret_1d\"] = adj_close.groupby(level=0).pct_change()\n",
    "    prev_close = adj_close.groupby(level=0).shift(1)\n",
    "    tr = pd.concat(\n",
    "        [\n",
    "            adj_high - adj_low,\n",
    "            (adj_high - prev_close).abs(),\n",
    "            (adj_low - prev_close).abs(),\n",
    "        ],\n",
    "        axis=1,\n",
    "    ).max(axis=1, skipna=False)\n",
    "\n",
    "    # B. Smoothing (ATR/RSI) - Use transform for speed and index matching\n",
    "    shadow_data[\"shadow_ATR\"] = tr.groupby(level=0).transform(\n",
    "        lambda x: x.ewm(alpha=1 / atr_p, adjust=False).mean()  # Replaced 14\n",
    "    )\n",
    "\n",
    "    shadow_data[\"shadow_ATRP\"] = shadow_data[\"shadow_ATR\"] / adj_close\n",
    "    shadow_data[\"shadow_TRP\"] = tr / adj_close\n",
    "\n",
    "    # Auditor Step 2B - Shadow RSI with correct Inf/NaN handling\n",
    "    delta = adj_close.groupby(level=0).diff()\n",
    "    up, down = delta.clip(lower=0), (-delta).clip(lower=0)\n",
    "\n",
    "    # Match Wilder's spec correctly:\n",
    "    roll_up = up.groupby(level=0).transform(\n",
    "        lambda x: x.ewm(alpha=1 / rsi_p, adjust=False).mean()  # Replaced 14\n",
    "    )\n",
    "    roll_down = down.groupby(level=0).transform(\n",
    "        lambda x: x.ewm(alpha=1 / rsi_p, adjust=False).mean()  # Replaced 14\n",
    "    )\n",
    "\n",
    "    # FIX: Allow division by zero (i.e. no down day) to create inf (correct RSI=100),\n",
    "    # inf‚Üí100, -inf‚Üí0, NaN‚Üí50\n",
    "    # then clean up remaining NaNs (initial periods/no movement)\n",
    "    # - Initial periods: Before the 14-day lookback is filled, the EWM mean is undefined ‚Üí NaN.\n",
    "    # - Flat prices: If price doesn't move (Avg Up = 0 and Avg Down = 0), RS is 0/0 ‚Üí NaN.\n",
    "    # - By convention, RSI is set to 50 (neutral) when there is no directional momentum.\n",
    "    rs = roll_up / roll_down  # Keep zero denominator ‚Üí inf\n",
    "    raw_rsi = 100 - (100 / (1 + rs))\n",
    "    shadow_data[\"shadow_RSI\"] = raw_rsi.replace({np.inf: 100, -np.inf: 0}).fillna(50)\n",
    "\n",
    "    # C. Momentum & Consistency\n",
    "    shadow_data[f\"shadow_Mom_{win_21}\"] = adj_close.groupby(level=0).pct_change(win_21)\n",
    "    pos_ret = (shadow_data[\"shadow_Ret_1d\"] > 0).astype(float)\n",
    "    shadow_data[\"shadow_Consistency\"] = pos_ret.groupby(level=0).transform(\n",
    "        lambda x: x.rolling(win_5).mean()\n",
    "    )\n",
    "\n",
    "    # D. Risk (Beta & IR)\n",
    "    if df_indices is not None:\n",
    "        try:\n",
    "            # USE THIS: Pull the single source of truth from the engine\n",
    "            mkt_ret = engine.macro_df[\"Mkt_Ret\"]\n",
    "            # Map it to the audit tickers\n",
    "            mkt_series = mkt_ret.reindex(\n",
    "                ohlcv_to_audit.index.get_level_values(1)\n",
    "            ).values\n",
    "            mkt_series = pd.Series(mkt_series, index=ohlcv_to_audit.index)\n",
    "\n",
    "            # Shadow Beta\n",
    "            s_ret = shadow_data[\"shadow_Ret_1d\"]\n",
    "            shadow_data[f\"shadow_Beta_{win_63}\"] = (\n",
    "                s_ret.groupby(level=0)\n",
    "                .transform(\n",
    "                    lambda x: x.rolling(win_63).cov(\n",
    "                        mkt_ret.reindex(x.index.get_level_values(1))\n",
    "                    )\n",
    "                    / mkt_ret.reindex(x.index.get_level_values(1)).rolling(win_63).var()\n",
    "                )\n",
    "                .fillna(1.0)\n",
    "            )\n",
    "\n",
    "            # Shadow IR\n",
    "            active_ret = s_ret - mkt_series\n",
    "            shadow_data[\"shadow_IR_63\"] = (\n",
    "                active_ret.groupby(level=0)\n",
    "                .transform(lambda x: x.rolling(win_63).mean() / x.rolling(win_63).std())\n",
    "                .fillna(0.0)\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" (Macro Shadow Error: {e}) \", end=\"\")\n",
    "\n",
    "    # E. Drawdown & Quality\n",
    "    roll_max_21 = adj_close.groupby(level=0).transform(\n",
    "        lambda x: x.rolling(win_21).max()\n",
    "    )\n",
    "    shadow_data[f\"shadow_DD_{win_21}\"] = (adj_close / roll_max_21 - 1).fillna(0.0)\n",
    "    stale_mask = ((volume == 0) | (adj_high == adj_low)).astype(int)\n",
    "\n",
    "    shadow_data[\"shadow_RollingStalePct\"] = stale_mask.groupby(level=0).transform(\n",
    "        lambda x: x.rolling(q_win, min_periods=q_min).mean()\n",
    "    )\n",
    "    dollar_vol = adj_close * volume\n",
    "    shadow_data[\"shadow_RollMedDollarVol\"] = dollar_vol.groupby(level=0).transform(\n",
    "        lambda x: x.rolling(q_win, min_periods=q_min).median()  # Replaced 252, 126\n",
    "    )\n",
    "\n",
    "    same_vol = (volume.groupby(level=0).diff() == 0).astype(int)\n",
    "    shadow_data[\"shadow_RollingSameVolCount\"] = same_vol.groupby(level=0).transform(\n",
    "        lambda x: x.rolling(q_win, min_periods=q_min).sum()  # Replaced 252, 126\n",
    "    )\n",
    "\n",
    "    # Build Final Shadow DF\n",
    "    audit_df = pd.DataFrame(shadow_data, index=ohlcv_to_audit.index)\n",
    "    print(f\"DONE ({time.time()-start_time:.2f}s)\")\n",
    "\n",
    "    # STEP 3: RECONCILIATION REPORT\n",
    "    print(f\"\\n{'Metric':<20} | {'Max Delta':<12} | {'Correlation':<12} | {'Status'}\")\n",
    "    print(\"-\" * 85)\n",
    "\n",
    "    cols_to_check = [\n",
    "        \"Ret_1d\",\n",
    "        \"ATR\",\n",
    "        \"ATRP\",\n",
    "        \"TRP\",\n",
    "        \"RSI\",\n",
    "        \"Mom_21\",\n",
    "        \"Consistency\",\n",
    "        \"Beta_63\",\n",
    "        \"IR_63\",\n",
    "        \"DD_21\",\n",
    "        \"RollingStalePct\",\n",
    "        \"RollMedDollarVol\",\n",
    "        \"RollingSameVolCount\",\n",
    "    ]\n",
    "\n",
    "    for col in cols_to_check:\n",
    "        sha_col = f\"shadow_{col}\"\n",
    "        if sha_col not in audit_df.columns:\n",
    "            continue\n",
    "\n",
    "        eng, sha = features_to_audit[col], audit_df[sha_col]\n",
    "        # Align and drop NaNs for comparison\n",
    "        mask = eng.notna() & sha.notna()\n",
    "        if not mask.any():\n",
    "            continue\n",
    "\n",
    "        e_v, s_v = eng[mask], sha[mask]\n",
    "\n",
    "        delta = (e_v - s_v).abs().max()\n",
    "\n",
    "        # Suppress the NumPy \"Subtract\" warning during correlation of constant series\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "            # If standard deviation is 0, correlation is undefined; if eng matches Shadow Calculation, we treat as 1.0\n",
    "            if e_v.std() == 0:\n",
    "                corr = 1.0 if delta < 1e-6 else 0.0\n",
    "            else:\n",
    "                corr = e_v.corr(s_v)\n",
    "\n",
    "        status = \"‚úÖ PASS\" if (delta < 1e-6 or corr > 0.99999) else \"‚ùå FAIL\"\n",
    "        print(f\"{col:<20} | {delta:>12.4e} | {corr:>12.6f} | {status}\")\n",
    "\n",
    "    vix_z = engine.macro_df[\"Macro_Vix_Z\"].abs().max()\n",
    "    print(\n",
    "        f\"{'Macro_Vix_Signals':<20} | {'N/A':<12} | {'N/A':<12} | {'‚úÖ LIVE' if vix_z > 0 else '‚ùå MISSING VIX, VIX3M'}\"\n",
    "    )\n",
    "    print(f\"{'='*95}\")\n",
    "\n",
    "\n",
    "def verify_macro_engine(df_ohlcv, df_indices, original_macro_df, settings):\n",
    "    \"\"\"\n",
    "    Independently verifies the macro_df calculation logic using GLOBAL_SETTINGS.\n",
    "    \"\"\"\n",
    "    print(f\"--- Macro Verification (Benchmark: {settings['benchmark_ticker']}) ---\")\n",
    "\n",
    "    # 1. Setup Skeleton\n",
    "    all_dates = df_ohlcv.index.get_level_values(\"Date\").unique().sort_values()\n",
    "    v_df = pd.DataFrame(index=all_dates)\n",
    "\n",
    "    # Constants from GLOBAL_SETTINGS\n",
    "    benchmark = settings[\"benchmark_ticker\"]\n",
    "    win_21 = settings[\"21d_window\"]\n",
    "    win_63 = settings[\"63d_window\"]\n",
    "    z_clip = settings[\"feature_zscore_clip\"]\n",
    "\n",
    "    # 2. Market Return & Trend Calculation\n",
    "    # Logic: Uses 200-day SMA for the trend anchor\n",
    "    if benchmark in df_ohlcv.index.get_level_values(\"Ticker\"):\n",
    "        mkt_close = (\n",
    "            df_ohlcv.xs(benchmark, level=\"Ticker\")[\"Adj Close\"]\n",
    "            .reindex(all_dates)\n",
    "            .ffill()\n",
    "        )\n",
    "        v_df[\"Mkt_Ret\"] = mkt_close.pct_change().fillna(0.0)\n",
    "        v_df[\"Macro_Trend\"] = (mkt_close / mkt_close.rolling(200).mean()) - 1.0\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Warning: {benchmark} not found in OHLCV. Defaulting to 0.0.\")\n",
    "        v_df[\"Mkt_Ret\"] = 0.0\n",
    "        v_df[\"Macro_Trend\"] = 0.0\n",
    "\n",
    "    # 3. Trend Velocity & Momentum logic\n",
    "    v_df[\"Macro_Trend_Vel\"] = v_df[\"Macro_Trend\"].diff(win_21)\n",
    "\n",
    "    # Z-Score of Velocity normalized by 63d rolling volatility of the Trend itself\n",
    "    v_df[\"Macro_Trend_Vel_Z\"] = (\n",
    "        v_df[\"Macro_Trend_Vel\"] / v_df[\"Macro_Trend\"].rolling(win_63).std()\n",
    "    ).clip(-z_clip, z_clip)\n",
    "\n",
    "    # Momentum: Sign agreement between level and direction\n",
    "    v_df[\"Macro_Trend_Mom\"] = (\n",
    "        np.sign(v_df[\"Macro_Trend\"])\n",
    "        * np.sign(v_df[\"Macro_Trend_Vel\"])\n",
    "        * np.abs(v_df[\"Macro_Trend_Vel\"])\n",
    "    ).fillna(0)\n",
    "\n",
    "    # 4. VIX Engine Logic\n",
    "    v_df[\"Macro_Vix_Z\"] = 0.0\n",
    "    v_df[\"Macro_Vix_Ratio\"] = 1.0\n",
    "\n",
    "    if df_indices is not None:\n",
    "        idx_names = df_indices.index.get_level_values(0).unique()\n",
    "        if \"^VIX\" in idx_names:\n",
    "            vix = df_indices.xs(\"^VIX\", level=0)[\"Adj Close\"].reindex(all_dates).ffill()\n",
    "            # VIX Z-score over 63 days\n",
    "            v_df[\"Macro_Vix_Z\"] = (\n",
    "                (vix - vix.rolling(63).mean()) / vix.rolling(63).std()\n",
    "            ).clip(-z_clip, z_clip)\n",
    "\n",
    "            if \"^VIX3M\" in idx_names:\n",
    "                vix3m = (\n",
    "                    df_indices.xs(\"^VIX3M\", level=0)[\"Adj Close\"]\n",
    "                    .reindex(all_dates)\n",
    "                    .ffill()\n",
    "                )\n",
    "                v_df[\"Macro_Vix_Ratio\"] = (vix / vix3m).fillna(1.0)\n",
    "\n",
    "    # Final cleanup to match original function\n",
    "    v_df.fillna(0.0, inplace=True)\n",
    "\n",
    "    # 5. Validation Loop\n",
    "    print(f\"\\nComparing verification vs original (Clip Threshold: {z_clip}):\")\n",
    "    match_all = True\n",
    "    for col in original_macro_df.columns:\n",
    "        if col not in v_df.columns:\n",
    "            print(f\"‚ùå Column '{col}' missing in verification code.\")\n",
    "            match_all = False\n",
    "            continue\n",
    "\n",
    "        # Use a tolerance for floating point math\n",
    "        diff = np.abs(original_macro_df[col] - v_df[col])\n",
    "        max_err = diff.max()\n",
    "\n",
    "        if max_err < 1e-9:\n",
    "            print(f\"‚úÖ {col:<20} | PASS (Max Diff: {max_err:.2e})\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è {col:<20} | FAIL (Max Diff: {max_err:.2e})\")\n",
    "            match_all = False\n",
    "\n",
    "    return v_df if not match_all else None\n",
    "\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a48017a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SECTION H: UTILITIES\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "def export_debug_to_csv(audit_pack, source_label=\"Audit\"):\n",
    "    \"\"\"\n",
    "    High-Transparency Exporter (Hardened Version).\n",
    "    Dumps the entire simulation state into a folder for manual Excel verification.\n",
    "    \"\"\"\n",
    "    if not audit_pack or not audit_pack[0]:\n",
    "        print(\"‚ùå Error: Audit Pack is empty. Run a simulation first.\")\n",
    "        return\n",
    "\n",
    "    data = audit_pack[0]\n",
    "    # Handle the fact that 'inputs' might be a key or a dataclass attribute\n",
    "    inputs = data.get(\"inputs\")\n",
    "\n",
    "    # 1. Folder Setup\n",
    "    date_str = inputs.start_date.strftime(\"%Y-%m-%d\")\n",
    "    strat = inputs.metric.replace(\" \", \"\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "    folder_name = f\"{source_label}_{strat}_{date_str}\"\n",
    "\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    print(f\"üìÇ [AUDIT EXPORT] Folder: ./{folder_name}/\")\n",
    "\n",
    "    def process_item(item, path_prefix=\"\"):\n",
    "        # A. Handle Nested Dicts\n",
    "        if isinstance(item, dict):\n",
    "            for k, v in item.items():\n",
    "                process_item(v, f\"{path_prefix}{k}_\" if path_prefix else f\"{k}_\")\n",
    "\n",
    "        # B. Handle DataFrames (Matrices - High Precision)\n",
    "        elif isinstance(item, pd.DataFrame):\n",
    "            fn = f\"Matrix_{path_prefix.strip('_')}.csv\"\n",
    "            item.to_csv(os.path.join(folder_name, fn), float_format=\"%.8f\")\n",
    "            print(f\"   ‚úÖ Matrix: {fn}\")\n",
    "\n",
    "        # C. Handle Series (Vectors)\n",
    "        elif isinstance(item, pd.Series):\n",
    "            fn = f\"Vector_{path_prefix.strip('_')}.csv\"\n",
    "            item.to_frame().to_csv(os.path.join(folder_name, fn), float_format=\"%.8f\")\n",
    "            print(f\"   ‚úÖ Vector: {fn}\")\n",
    "\n",
    "        # D. Handle Dataclasses (Metadata & Results)\n",
    "        elif is_dataclass(item):\n",
    "            class_name = item.__class__.__name__\n",
    "            fn = f\"Summary_{class_name}_{path_prefix.strip('_')}\".strip(\"_\") + \".csv\"\n",
    "\n",
    "            # --- THE FIX: Create a Safe Dictionary for Pandas ---\n",
    "            raw_dict = asdict(item)\n",
    "            summary_ready_dict = {}\n",
    "\n",
    "            for k, v in raw_dict.items():\n",
    "                # If it's a big data object, just note its existence in the summary\n",
    "                if isinstance(v, (pd.DataFrame, pd.Series)):\n",
    "                    summary_ready_dict[k] = f\"<{v.__class__.__name__} shape={v.shape}>\"\n",
    "                # If it's a list or dict (the crash cause), stringify it for Excel\n",
    "                elif isinstance(v, (list, dict)):\n",
    "                    summary_ready_dict[k] = str(v)\n",
    "                else:\n",
    "                    summary_ready_dict[k] = v\n",
    "\n",
    "            # Save the clean key-value summary\n",
    "            pd.DataFrame.from_dict(\n",
    "                summary_ready_dict, orient=\"index\", columns=[\"Value\"]\n",
    "            ).to_csv(os.path.join(folder_name, fn))\n",
    "            print(f\"   üìë Summary: {fn}\")\n",
    "\n",
    "            # E. RECURSION: Now find the actual DataFrames inside the dataclass\n",
    "            # We iterate the object attributes directly to avoid the 'asdict' list confusion\n",
    "            for k in item.__dataclass_fields__.keys():\n",
    "                val = getattr(item, k)\n",
    "                if isinstance(val, (pd.DataFrame, pd.Series, dict)):\n",
    "                    process_item(val, f\"{path_prefix}{k}_\")\n",
    "\n",
    "    # 3. Execute Extraction\n",
    "    process_item(data)\n",
    "    print(f\"\\n‚ú® Export Complete. Open ./{folder_name}/ to verify results.\")\n",
    "\n",
    "\n",
    "# def export_audit_to_excel(audit_pack, filename=\"Audit_Verification_Report.xlsx\"):\n",
    "#     \"\"\"\n",
    "#     Final Zero-Base Audit Export.\n",
    "#     Provides everything needed to reconstruct the Strategy results from raw candles.\n",
    "#     Usage: export_audit_to_excel(analyzer1.last_run)\n",
    "#     \"\"\"\n",
    "#     if audit_pack is None:\n",
    "#         return print(\"‚ùå Error: Audit Pack is empty.\")\n",
    "\n",
    "#     # Resolve full output path\n",
    "#     output_path = Path(OUTPUT_DIR) / filename\n",
    "\n",
    "#     # Ensure output directory exists\n",
    "#     output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#     # 1. Setup Core References\n",
    "#     debug = audit_pack.debug_data or {}\n",
    "#     inputs = debug.get(\"inputs_snapshot\")\n",
    "#     p_raw = debug.get(\"portfolio_raw_components\", {})\n",
    "#     b_raw = debug.get(\"benchmark_raw_components\", {})\n",
    "\n",
    "#     dec_date = audit_pack.decision_date\n",
    "#     bench_ticker = inputs.benchmark_ticker if inputs else \"Benchmark\"\n",
    "#     top_3_tickers = audit_pack.tickers[:3] if audit_pack.tickers else []\n",
    "\n",
    "#     print(f\"üìÇ [EXCEL AUDIT] Building full transparency report: {output_path}\")\n",
    "\n",
    "#     with pd.ExcelWriter(output_path, engine=\"openpyxl\") as writer:\n",
    "\n",
    "#         # --- SHEET 1: OVERVIEW (Settings & Results) ---\n",
    "#         meta = {**asdict(inputs)} if inputs else {}\n",
    "#         meta.update(audit_pack.perf_metrics or {})\n",
    "#         pd.DataFrame.from_dict(\n",
    "#             {k: str(v) for k, v in meta.items()}, orient=\"index\", columns=[\"Value\"]\n",
    "#         ).to_excel(writer, sheet_name=\"OVERVIEW\")\n",
    "\n",
    "#         # --- SHEET 2: DAILY_AUDIT (The Timeline + Period Labels) ---\n",
    "#         daily = {\n",
    "#             \"Port_Value\": audit_pack.portfolio_series,\n",
    "#             \"Port_ATRP\": audit_pack.portfolio_atrp_series,\n",
    "#             \"Port_TRP\": audit_pack.portfolio_trp_series,\n",
    "#             \"Bench_Value\": audit_pack.benchmark_series,\n",
    "#             \"Bench_ATRP\": audit_pack.benchmark_atrp_series,\n",
    "#             \"Bench_TRP\": audit_pack.benchmark_trp_series,\n",
    "#         }\n",
    "#         if audit_pack.portfolio_series is not None:\n",
    "#             daily[\"Port_Ret\"] = QuantUtils.compute_returns(audit_pack.portfolio_series)\n",
    "#         if audit_pack.benchmark_series is not None:\n",
    "#             daily[\"Bench_Ret\"] = QuantUtils.compute_returns(audit_pack.benchmark_series)\n",
    "\n",
    "#         df_daily = pd.concat({k: v for k, v in daily.items() if v is not None}, axis=1)\n",
    "\n",
    "#         # Add Period Label Column for Excel Range Selection\n",
    "#         df_daily[\"Period_Label\"] = np.where(\n",
    "#             df_daily.index <= dec_date, \"LOOKBACK\", \"HOLDING\"\n",
    "#         )\n",
    "#         df_daily.to_excel(writer, sheet_name=\"DAILY_AUDIT\")\n",
    "\n",
    "#         # --- SHEET 3: RAW_OHLCV_SAMPLES (Spot Check for 3 Tickers + Benchmark) ---\n",
    "#         ohlcv_list = []\n",
    "#         # Get Benchmark OHLCV\n",
    "#         if (b_ohlcv := b_raw.get(\"ohlcv_raw\")) is not None:\n",
    "#             b_temp = b_ohlcv.copy()\n",
    "#             b_temp[\"Ticker\"] = bench_ticker\n",
    "#             ohlcv_list.append(b_temp)\n",
    "#         # Get Top 3 Tickers OHLCV\n",
    "#         if (p_ohlcv := p_raw.get(\"ohlcv_raw\")) is not None:\n",
    "#             # Assuming ohlcv_raw index or column identifies ticker\n",
    "#             # If it's a MultiIndex (Date, Ticker), we filter. Otherwise, we assume tidy.\n",
    "#             if isinstance(p_ohlcv.index, pd.MultiIndex):\n",
    "#                 sample_p = p_ohlcv.query(\"Ticker in @top_3_tickers\")\n",
    "#                 ohlcv_list.append(sample_p.reset_index())\n",
    "#             else:\n",
    "#                 # Fallback: Filter by 'ticker' column if it exists\n",
    "#                 col_name = \"ticker\" if \"ticker\" in p_ohlcv.columns else \"Ticker\"\n",
    "#                 if col_name in p_ohlcv.columns:\n",
    "#                     ohlcv_list.append(p_ohlcv[p_ohlcv[col_name].isin(top_3_tickers)])\n",
    "\n",
    "#         if ohlcv_list:\n",
    "#             pd.concat(ohlcv_list).to_excel(\n",
    "#                 writer, sheet_name=\"RAW_OHLCV_SAMPLES\", index=False\n",
    "#             )\n",
    "\n",
    "#         # --- SHEET 4, 5, 6: MERGED MATRICES (Price, ATRP, TRP) ---\n",
    "#         for sheet_name, key in [\n",
    "#             (\"RAW_PRICES\", \"prices\"),\n",
    "#             (\"RAW_ATRP_DATA\", \"atrp\"),\n",
    "#             (\"RAW_TRP_DATA\", \"trp\"),\n",
    "#         ]:\n",
    "#             p_df, b_df = p_raw.get(key), b_raw.get(key)\n",
    "#             if p_df is not None and b_df is not None:\n",
    "#                 pd.concat(\n",
    "#                     [p_df, b_df.rename(columns={b_df.columns[0]: bench_ticker})], axis=1\n",
    "#                 ).to_excel(writer, sheet_name=sheet_name)\n",
    "\n",
    "#         # --- SHEET 7: RAW_DRIFTED_WEIGHTS ---\n",
    "#         if (p_prices := p_raw.get(\"prices\")) is not None:\n",
    "#             weights_ser = pd.Series(\n",
    "#                 audit_pack.initial_weights, index=audit_pack.tickers\n",
    "#             )\n",
    "#             norm_p = p_prices.div(p_prices.bfill().iloc[0])\n",
    "#             weighted = norm_p.mul(weights_ser, axis=1)\n",
    "#             drift_weights = weighted.div(weighted.sum(axis=1), axis=0)\n",
    "#             drift_weights.to_excel(writer, sheet_name=\"RAW_DRIFTED_WEIGHTS\")\n",
    "\n",
    "#         # --- SHEET 8: SURVIVAL_AUDIT (Layer 1 Filter Verification) ---\n",
    "#         if liq_audit := debug.get(\"audit_liquidity\", {}):\n",
    "#             if (snap := liq_audit.get(\"universe_snapshot\")) is not None:\n",
    "#                 snap.to_excel(writer, sheet_name=\"SURVIVAL_AUDIT\")\n",
    "\n",
    "#         # --- SHEET 9: FULL_RANKING ---\n",
    "#         if (df_rank := debug.get(\"full_universe_ranking\")) is not None:\n",
    "#             df_rank.to_excel(writer, sheet_name=\"FULL_RANKING\")\n",
    "\n",
    "#     print(f\"‚ú® Audit Report Complete: {output_path}\")\n",
    "#     return output_path\n",
    "\n",
    "\n",
    "def export_audit_to_excel(audit_pack, filename=\"Audit_Verification_Report.xlsx\"):\n",
    "    \"\"\"\n",
    "    Final Zero-Base Audit Export.\n",
    "    Provides everything needed to reconstruct the Strategy results from raw candles.\n",
    "    Usage: export_audit_to_excel(analyzer1.last_run)\n",
    "    \"\"\"\n",
    "    if audit_pack is None:\n",
    "        return print(\"‚ùå Error: Audit Pack is empty.\")\n",
    "\n",
    "    # Resolve full output path\n",
    "    output_path = Path(OUTPUT_DIR) / filename\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1. Setup Core References\n",
    "    debug = audit_pack.debug_data or {}\n",
    "    inputs = debug.get(\"inputs_snapshot\")\n",
    "    p_raw = debug.get(\"portfolio_raw_components\", {})\n",
    "    b_raw = debug.get(\"benchmark_raw_components\", {})\n",
    "\n",
    "    dec_date = audit_pack.decision_date\n",
    "    bench_ticker = inputs.benchmark_ticker if inputs else \"Benchmark\"\n",
    "    # CHANGED: Export all tickers, not just top 3\n",
    "    all_tickers = audit_pack.tickers if audit_pack.tickers else []\n",
    "\n",
    "    print(f\"üìÇ [EXCEL AUDIT] Building full transparency report: {output_path}\")\n",
    "\n",
    "    with pd.ExcelWriter(output_path, engine=\"openpyxl\") as writer:\n",
    "\n",
    "        # --- SHEET 1: OVERVIEW (Settings & Results) ---\n",
    "        meta = {**asdict(inputs)} if inputs else {}\n",
    "        meta.update(audit_pack.perf_metrics or {})\n",
    "        pd.DataFrame.from_dict(\n",
    "            {k: str(v) for k, v in meta.items()}, orient=\"index\", columns=[\"Value\"]\n",
    "        ).to_excel(writer, sheet_name=\"OVERVIEW\")\n",
    "\n",
    "        # --- SHEET 2: DAILY_AUDIT (The Timeline + Period Labels) ---\n",
    "        daily = {\n",
    "            \"Port_Value\": audit_pack.portfolio_series,\n",
    "            \"Port_ATRP\": audit_pack.portfolio_atrp_series,\n",
    "            \"Port_TRP\": audit_pack.portfolio_trp_series,\n",
    "            \"Bench_Value\": audit_pack.benchmark_series,\n",
    "            \"Bench_ATRP\": audit_pack.benchmark_atrp_series,\n",
    "            \"Bench_TRP\": audit_pack.benchmark_trp_series,\n",
    "        }\n",
    "        if audit_pack.portfolio_series is not None:\n",
    "            daily[\"Port_Ret\"] = QuantUtils.compute_returns(audit_pack.portfolio_series)\n",
    "        if audit_pack.benchmark_series is not None:\n",
    "            daily[\"Bench_Ret\"] = QuantUtils.compute_returns(audit_pack.benchmark_series)\n",
    "\n",
    "        df_daily = pd.concat({k: v for k, v in daily.items() if v is not None}, axis=1)\n",
    "\n",
    "        # Add Period Label Column for Excel Range Selection\n",
    "        df_daily[\"Period_Label\"] = np.where(\n",
    "            df_daily.index <= dec_date, \"LOOKBACK\", \"HOLDING\"\n",
    "        )\n",
    "        df_daily.to_excel(writer, sheet_name=\"DAILY_AUDIT\")\n",
    "\n",
    "        # --- SHEET 3: RAW_OHLCV_SAMPLES (Spot Check for ALL Tickers + Benchmark) ---\n",
    "        ohlcv_list = []\n",
    "        # Get Benchmark OHLCV\n",
    "        if (b_ohlcv := b_raw.get(\"ohlcv_raw\")) is not None:\n",
    "            b_temp = b_ohlcv.copy()\n",
    "            b_temp[\"Ticker\"] = bench_ticker\n",
    "            ohlcv_list.append(b_temp)\n",
    "        # Get ALL Tickers OHLCV (not just top 3)\n",
    "        if (p_ohlcv := p_raw.get(\"ohlcv_raw\")) is not None:\n",
    "            if isinstance(p_ohlcv.index, pd.MultiIndex):\n",
    "                # CHANGED: Use all_tickers instead of top_3_tickers\n",
    "                sample_p = p_ohlcv.query(\"Ticker in @all_tickers\")\n",
    "                ohlcv_list.append(sample_p.reset_index())\n",
    "            else:\n",
    "                # Fallback: Filter by 'ticker' column if it exists\n",
    "                col_name = \"ticker\" if \"ticker\" in p_ohlcv.columns else \"Ticker\"\n",
    "                if col_name in p_ohlcv.columns:\n",
    "                    # CHANGED: Use all_tickers instead of top_3_tickers\n",
    "                    ohlcv_list.append(p_ohlcv[p_ohlcv[col_name].isin(all_tickers)])\n",
    "\n",
    "        if ohlcv_list:\n",
    "            pd.concat(ohlcv_list).to_excel(\n",
    "                writer, sheet_name=\"RAW_OHLCV_SAMPLES\", index=False\n",
    "            )\n",
    "\n",
    "        # --- SHEET 4, 5, 6: MERGED MATRICES (Price, ATRP, TRP) ---\n",
    "        for sheet_name, key in [\n",
    "            (\"RAW_PRICES\", \"prices\"),\n",
    "            (\"RAW_ATRP_DATA\", \"atrp\"),\n",
    "            (\"RAW_TRP_DATA\", \"trp\"),\n",
    "        ]:\n",
    "            p_df, b_df = p_raw.get(key), b_raw.get(key)\n",
    "            if p_df is not None and b_df is not None:\n",
    "                pd.concat(\n",
    "                    [p_df, b_df.rename(columns={b_df.columns[0]: bench_ticker})], axis=1\n",
    "                ).to_excel(writer, sheet_name=sheet_name)\n",
    "\n",
    "        # --- SHEET 7: RAW_DRIFTED_WEIGHTS ---\n",
    "        if (p_prices := p_raw.get(\"prices\")) is not None:\n",
    "            weights_ser = pd.Series(\n",
    "                audit_pack.initial_weights, index=audit_pack.tickers\n",
    "            )\n",
    "            norm_p = p_prices.div(p_prices.bfill().iloc[0])\n",
    "            weighted = norm_p.mul(weights_ser, axis=1)\n",
    "            drift_weights = weighted.div(weighted.sum(axis=1), axis=0)\n",
    "            drift_weights.to_excel(writer, sheet_name=\"RAW_DRIFTED_WEIGHTS\")\n",
    "\n",
    "        # --- SHEET 8: SURVIVAL_AUDIT (Layer 1 Filter Verification) ---\n",
    "        if liq_audit := debug.get(\"audit_liquidity\", {}):\n",
    "            if (snap := liq_audit.get(\"universe_snapshot\")) is not None:\n",
    "                snap.to_excel(writer, sheet_name=\"SURVIVAL_AUDIT\")\n",
    "\n",
    "        # --- SHEET 9: FULL_RANKING ---\n",
    "        if (df_rank := debug.get(\"full_universe_ranking\")) is not None:\n",
    "            df_rank.to_excel(writer, sheet_name=\"FULL_RANKING\")\n",
    "\n",
    "    print(f\"‚ú® Audit Report Complete: {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "\n",
    "def export_last_run_tickers_data_to_csv(\n",
    "    analyzer, df_ohlcv, features_df, filename=\"all_tickers_stacked.csv\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Export the last run ticker data from a WalkForwardAnalyzer to a stacked CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    analyzer : WalkForwardAnalyzer\n",
    "        The analyzer containing last_run data\n",
    "    df_ohlcv : pd.DataFrame\n",
    "        OHLCV data for create_combined_dict\n",
    "    features_df : pd.DataFrame\n",
    "        Features data for create_combined_dict\n",
    "    filename : str\n",
    "        Output filename (saved to OUTPUT_DIR)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Path : Path to saved CSV file\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Access the result object from the analyzer\n",
    "    res = analyzer.last_run\n",
    "\n",
    "    if res is None:\n",
    "        raise ValueError(\n",
    "            \"‚ùå No results found in analyzer. Please click 'Run Simulation' first.\"\n",
    "        )\n",
    "\n",
    "    # 2. Extract attributes directly (No [0] needed)\n",
    "    benchmark = res.debug_data[\"inputs_snapshot\"].benchmark_ticker\n",
    "    tickers = res.tickers + [benchmark]\n",
    "    start_date = res.start_date\n",
    "    end_date = res.holding_end_date  # Note: I use end_date, not decision_date/buy_date\n",
    "\n",
    "    # 3. Generate the combined dict\n",
    "    combined = create_combined_dict(\n",
    "        df_ohlcv=df_ohlcv.copy(),\n",
    "        features_df=features_df,\n",
    "        tickers=tickers,\n",
    "        date_start=start_date,\n",
    "        date_end=end_date,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # 4. Print ticker data (optional ‚Äî remove if not needed)\n",
    "    for ticker in tickers:\n",
    "        with pd.option_context(\"display.float_format\", \"{:.8f}\".format):\n",
    "            print(f\"{ticker}:\\n{combined[ticker][start_date:end_date]}\\n\")\n",
    "\n",
    "    # 5. Save ticker data to CSV\n",
    "    file_path = filename\n",
    "\n",
    "    # Save first ticker with header\n",
    "    first_ticker = tickers[0]\n",
    "    df_first = combined[first_ticker][start_date:end_date].reset_index()\n",
    "    df_first[\"Ticker\"] = first_ticker\n",
    "\n",
    "    df_first.to_csv(file_path, header=True, index=False, lineterminator=\"\\n\")\n",
    "    print(f\"‚úì Saved {first_ticker} with header\")\n",
    "\n",
    "    # Append remaining tickers without header\n",
    "    for ticker in tickers[1:]:\n",
    "        df = combined[ticker][start_date:end_date].reset_index()\n",
    "        df[\"Ticker\"] = ticker\n",
    "\n",
    "        df.to_csv(file_path, header=False, index=False, lineterminator=\"\\n\", mode=\"a\")\n",
    "        print(f\"‚úì Appended {ticker}\")\n",
    "\n",
    "    print(f\"\\n‚úì Saved all tickers to: {file_path}\")\n",
    "\n",
    "    return file_path\n",
    "\n",
    "\n",
    "def print_nested(d, indent=0, width=4):\n",
    "    \"\"\"Pretty-print nested containers.\n",
    "    Leaves are rendered as two lines:  key\\\\nvalue .\"\"\"\n",
    "    spacing = \" \" * indent\n",
    "\n",
    "    def _kind(node):\n",
    "        if not isinstance(node, dict):\n",
    "            return None\n",
    "        return \"sep\" if all(isinstance(v, dict) for v in node.values()) else \"nest\"\n",
    "\n",
    "    if isinstance(d, dict):\n",
    "        for k, v in d.items():\n",
    "            kind = _kind(v)\n",
    "            tag = \"\" if kind is None else f\"  [{'SEP' if kind == 'sep' else 'NEST'}]\"\n",
    "            print(f\"{spacing}{k}{tag}\")\n",
    "            print_nested(v, indent + width, width)\n",
    "\n",
    "    elif isinstance(d, (list, tuple)):\n",
    "        for idx, item in enumerate(d):\n",
    "            print(f\"{spacing}[{idx}]\")\n",
    "            print_nested(item, indent + width, width)\n",
    "\n",
    "    else:  # leaf ‚Äì primitive value\n",
    "        print(f\"{spacing}{d}\")\n",
    "\n",
    "\n",
    "def get_ticker_OHLCV(\n",
    "    df_ohlcv: pd.DataFrame,\n",
    "    tickers: Union[str, List[str]],\n",
    "    date_start: str,\n",
    "    date_end: str,\n",
    "    return_format: str = \"dataframe\",\n",
    "    verbose: bool = True,\n",
    ") -> Union[pd.DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    Get OHLCV data for specified tickers within a date range.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_ohlcv : pd.DataFrame\n",
    "        DataFrame with MultiIndex of (ticker, date) and OHLCV columns\n",
    "    tickers : str or list of str\n",
    "        Ticker symbol(s) to retrieve\n",
    "    date_start : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    date_end : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    return_format : str, optional\n",
    "        Format to return data in. Options:\n",
    "        - 'dataframe': Single DataFrame with MultiIndex (default)\n",
    "        - 'dict': Dictionary with tickers as keys and DataFrames as values\n",
    "        - 'separate': List of separate DataFrames for each ticker\n",
    "    verbose : bool, optional\n",
    "        Whether to print summary information (default: True)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Union[pd.DataFrame, dict, list]\n",
    "        Filtered OHLCV data in specified format\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If input parameters are invalid\n",
    "    KeyError\n",
    "        If tickers not found in DataFrame\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> # Get data for single ticker\n",
    "    >>> vlo_data = get_ticker_OHLCV(df_ohlcv, 'VLO', '2025-08-13', '2025-09-04')\n",
    "\n",
    "    >>> # Get data for multiple tickers\n",
    "    >>> multi_data = get_ticker_OHLCV(df_ohlcv, ['VLO', 'JPST'], '2025-08-13', '2025-09-04')\n",
    "\n",
    "    >>> # Get data as dictionary\n",
    "    >>> data_dict = get_ticker_OHLCV(df_ohlcv, ['VLO', 'JPST'], '2025-08-13',\n",
    "    ...                              '2025-09-04', return_format='dict')\n",
    "    \"\"\"\n",
    "\n",
    "    # Input validation\n",
    "    if not isinstance(df_ohlcv, pd.DataFrame):\n",
    "        raise TypeError(\"df_ohlcv must be a pandas DataFrame\")\n",
    "\n",
    "    if not isinstance(df_ohlcv.index, pd.MultiIndex):\n",
    "        raise ValueError(\"DataFrame must have MultiIndex of (ticker, date)\")\n",
    "\n",
    "    if len(df_ohlcv.index.levels) != 2:\n",
    "        raise ValueError(\"MultiIndex must have exactly 2 levels: (ticker, date)\")\n",
    "\n",
    "    # Convert single ticker to list for consistent processing\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "    elif not isinstance(tickers, list):\n",
    "        raise TypeError(\"tickers must be a string or list of strings\")\n",
    "\n",
    "    # Convert dates to Timestamps\n",
    "    try:\n",
    "        start_date = pd.Timestamp(date_start)\n",
    "        end_date = pd.Timestamp(date_end)\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"Invalid date format. Use 'YYYY-MM-DD': {e}\")\n",
    "\n",
    "    if start_date > end_date:\n",
    "        raise ValueError(\"date_start must be before or equal to date_end\")\n",
    "\n",
    "    # Check if tickers exist in the DataFrame\n",
    "    available_tickers = df_ohlcv.index.get_level_values(0).unique()\n",
    "    missing_tickers = [t for t in tickers if t not in available_tickers]\n",
    "\n",
    "    if missing_tickers:\n",
    "        raise KeyError(f\"Ticker(s) not found in DataFrame: {missing_tickers}\")\n",
    "\n",
    "    # Filter the data using MultiIndex slicing\n",
    "    try:\n",
    "        filtered_data = df_ohlcv.loc[(tickers, slice(date_start, date_end)), :]\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error filtering data: {e}\")\n",
    "\n",
    "    # Handle empty results\n",
    "    if filtered_data.empty:\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"No data found for tickers {tickers} in date range {date_start} to {date_end}\"\n",
    "            )\n",
    "        return filtered_data\n",
    "\n",
    "    # Print summary if verbose\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"Data retrieved for {len(tickers)} ticker(s) from {date_start} to {date_end}\"\n",
    "        )\n",
    "        print(f\"Total rows: {len(filtered_data)}\")\n",
    "        print(\n",
    "            f\"Date range in data: {filtered_data.index.get_level_values(1).min()} to \"\n",
    "            f\"{filtered_data.index.get_level_values(1).max()}\"\n",
    "        )\n",
    "\n",
    "        # Print ticker-specific counts\n",
    "        ticker_counts = filtered_data.index.get_level_values(0).value_counts()\n",
    "        for ticker in tickers:\n",
    "            count = ticker_counts.get(ticker, 0)\n",
    "            if count > 0:\n",
    "                print(f\"  {ticker}: {count} rows\")\n",
    "            else:\n",
    "                print(f\"  {ticker}: No data in range\")\n",
    "\n",
    "    # Return in requested format\n",
    "    if return_format == \"dict\":\n",
    "        result = {}\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result[ticker] = filtered_data.xs(ticker, level=0).loc[\n",
    "                    date_start:date_end\n",
    "                ]\n",
    "            except KeyError:\n",
    "                result[ticker] = pd.DataFrame()\n",
    "        return result\n",
    "\n",
    "    elif return_format == \"separate\":\n",
    "        result = []\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result.append(\n",
    "                    filtered_data.xs(ticker, level=0).loc[date_start:date_end]\n",
    "                )\n",
    "            except KeyError:\n",
    "                result.append(pd.DataFrame())\n",
    "        return result\n",
    "\n",
    "    elif return_format == \"dataframe\":\n",
    "        return filtered_data\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Invalid return_format: {return_format}. \"\n",
    "            f\"Must be 'dataframe', 'dict', or 'separate'\"\n",
    "        )\n",
    "\n",
    "\n",
    "def get_ticker_features(\n",
    "    features_df: pd.DataFrame,\n",
    "    tickers: Union[str, List[str]],\n",
    "    date_start: str,\n",
    "    date_end: str,\n",
    "    return_format: str = \"dataframe\",\n",
    "    verbose: bool = True,\n",
    ") -> Union[pd.DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    Get features data for specified tickers within a date range.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    features_df : pd.DataFrame\n",
    "        DataFrame with MultiIndex of (ticker, date) and feature columns\n",
    "    tickers : str or list of str\n",
    "        Ticker symbol(s) to retrieve\n",
    "    date_start : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    date_end : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    return_format : str, optional\n",
    "        Format to return data in. Options:\n",
    "        - 'dataframe': Single DataFrame with MultiIndex (default)\n",
    "        - 'dict': Dictionary with tickers as keys and DataFrames as values\n",
    "        - 'separate': List of separate DataFrames for each ticker\n",
    "    verbose : bool, optional\n",
    "        Whether to print summary information (default: True)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Union[pd.DataFrame, dict, list]\n",
    "        Filtered features data in specified format\n",
    "    \"\"\"\n",
    "    # Convert single ticker to list for consistent processing\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "\n",
    "    # Filter the data using MultiIndex slicing\n",
    "    try:\n",
    "        filtered_data = features_df.loc[(tickers, slice(date_start, date_end)), :]\n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"Error filtering data: {e}\")\n",
    "        return pd.DataFrame() if return_format == \"dataframe\" else {}\n",
    "\n",
    "    # Handle empty results\n",
    "    if filtered_data.empty:\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"No data found for tickers {tickers} in date range {date_start} to {date_end}\"\n",
    "            )\n",
    "        return filtered_data\n",
    "\n",
    "    # Print summary if verbose\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"Features data retrieved for {len(tickers)} ticker(s) from {date_start} to {date_end}\"\n",
    "        )\n",
    "        print(f\"Total rows: {len(filtered_data)}\")\n",
    "        print(\n",
    "            f\"Date range in data: {filtered_data.index.get_level_values(1).min()} to \"\n",
    "            f\"{filtered_data.index.get_level_values(1).max()}\"\n",
    "        )\n",
    "        print(f\"Available features: {', '.join(filtered_data.columns.tolist())}\")\n",
    "\n",
    "        # Print ticker-specific counts\n",
    "        ticker_counts = filtered_data.index.get_level_values(0).value_counts()\n",
    "        for ticker in tickers:\n",
    "            count = ticker_counts.get(ticker, 0)\n",
    "            if count > 0:\n",
    "                print(f\"  {ticker}: {count} rows\")\n",
    "            else:\n",
    "                print(f\"  {ticker}: No data in range\")\n",
    "\n",
    "    # Return in requested format\n",
    "    if return_format == \"dict\":\n",
    "        result = {}\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result[ticker] = filtered_data.xs(ticker, level=0).loc[\n",
    "                    date_start:date_end\n",
    "                ]\n",
    "            except KeyError:\n",
    "                result[ticker] = pd.DataFrame()\n",
    "        return result\n",
    "\n",
    "    elif return_format == \"separate\":\n",
    "        result = []\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result.append(\n",
    "                    filtered_data.xs(ticker, level=0).loc[date_start:date_end]\n",
    "                )\n",
    "            except KeyError:\n",
    "                result.append(pd.DataFrame())\n",
    "        return result\n",
    "\n",
    "    elif return_format == \"dataframe\":\n",
    "        return filtered_data\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Invalid return_format: {return_format}. \"\n",
    "            f\"Must be 'dataframe', 'dict', or 'separate'\"\n",
    "        )\n",
    "\n",
    "\n",
    "def create_combined_dict(\n",
    "    df_ohlcv: pd.DataFrame,\n",
    "    features_df: pd.DataFrame,\n",
    "    tickers: Union[str, List[str]],\n",
    "    date_start: str,\n",
    "    date_end: str,\n",
    "    verbose: bool = True,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Create a combined dictionary with both OHLCV and features data for each ticker.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_ohlcv : pd.DataFrame\n",
    "        DataFrame with OHLCV data (MultiIndex: ticker, date)\n",
    "    features_df : pd.DataFrame\n",
    "        DataFrame with features data (MultiIndex: ticker, date)\n",
    "    tickers : str or list of str\n",
    "        Ticker symbol(s) to retrieve\n",
    "    date_start : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    date_end : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    verbose : bool, optional\n",
    "        Whether to print progress information (default: True)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with tickers as keys and combined DataFrames (OHLCV + features) as values\n",
    "    \"\"\"\n",
    "    # Convert single ticker to list\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Creating combined dictionary for {len(tickers)} ticker(s)\")\n",
    "        print(f\"Date range: {date_start} to {date_end}\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "    # Get OHLCV data as dictionary\n",
    "    ohlcv_dict = get_ticker_OHLCV(\n",
    "        df_ohlcv, tickers, date_start, date_end, return_format=\"dict\", verbose=verbose\n",
    "    )\n",
    "\n",
    "    # Get features data as dictionary\n",
    "    features_dict = get_ticker_features(\n",
    "        features_df,\n",
    "        tickers,\n",
    "        date_start,\n",
    "        date_end,\n",
    "        return_format=\"dict\",\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "    # Create combined_dict\n",
    "    combined_dict = {}\n",
    "\n",
    "    for ticker in tickers:\n",
    "        if verbose:\n",
    "            print(f\"\\nProcessing {ticker}...\")\n",
    "\n",
    "        # Check if ticker exists in both dictionaries\n",
    "        if ticker in ohlcv_dict and ticker in features_dict:\n",
    "            ohlcv_data = ohlcv_dict[ticker]\n",
    "            features_data = features_dict[ticker]\n",
    "\n",
    "            # Check if both dataframes have data\n",
    "            if not ohlcv_data.empty and not features_data.empty:\n",
    "                # Combine OHLCV and features data\n",
    "                # Note: Both dataframes have the same index (dates), so we can concatenate\n",
    "                combined_df = pd.concat([ohlcv_data, features_data], axis=1)\n",
    "\n",
    "                # Ensure proper index naming\n",
    "                combined_df.index.name = \"Date\"\n",
    "\n",
    "                # Store in combined_dict\n",
    "                combined_dict[ticker] = combined_df\n",
    "\n",
    "                if verbose:\n",
    "                    print(f\"  ‚úì Successfully combined data\")\n",
    "                    print(f\"  OHLCV shape: {ohlcv_data.shape}\")\n",
    "                    print(f\"  Features shape: {features_data.shape}\")\n",
    "                    print(f\"  Combined shape: {combined_df.shape}\")\n",
    "                    print(\n",
    "                        f\"  Date range: {combined_df.index.min()} to {combined_df.index.max()}\"\n",
    "                    )\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"  ‚úó Cannot combine: One or both dataframes are empty\")\n",
    "                    print(f\"    OHLCV empty: {ohlcv_data.empty}\")\n",
    "                    print(f\"    Features empty: {features_data.empty}\")\n",
    "                combined_dict[ticker] = pd.DataFrame()\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(f\"  ‚úó Ticker not found in both dictionaries\")\n",
    "                if ticker not in ohlcv_dict:\n",
    "                    print(f\"    Not in OHLCV data\")\n",
    "                if ticker not in features_dict:\n",
    "                    print(f\"    Not in features data\")\n",
    "            combined_dict[ticker] = pd.DataFrame()\n",
    "\n",
    "    # Print summary\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"SUMMARY\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Total tickers processed: {len(tickers)}\")\n",
    "\n",
    "        tickers_with_data = [\n",
    "            ticker for ticker, df in combined_dict.items() if not df.empty\n",
    "        ]\n",
    "        print(f\"Tickers with combined data: {len(tickers_with_data)}\")\n",
    "\n",
    "        if tickers_with_data:\n",
    "            print(\"\\nTicker details:\")\n",
    "            for ticker in tickers_with_data:\n",
    "                df = combined_dict[ticker]\n",
    "                print(f\"  {ticker}: {df.shape} - {df.index.min()} to {df.index.max()}\")\n",
    "                print(f\"    Columns: {len(df.columns)}\")\n",
    "\n",
    "        empty_tickers = [ticker for ticker, df in combined_dict.items() if df.empty]\n",
    "        if empty_tickers:\n",
    "            print(f\"\\nTickers with no data: {', '.join(empty_tickers)}\")\n",
    "\n",
    "    return combined_dict\n",
    "\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8f2f10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- üõ°Ô∏è Starting Final Integrity Audit ---\n",
      "‚úÖ Series Boundary: OK\n",
      "‚úÖ DataFrame Boundary: OK\n",
      "‚úÖ AUDIT PASSED: Mathematical boundaries are strictly enforced.\n",
      "\n",
      "--- üõ°Ô∏è Starting Feature Engineering Audit ---\n",
      "‚ö° Generating Decoupled Features (Benchmark: SPY)...\n",
      "Audit Values:\n",
      "[ nan 25.  17.5]\n",
      "‚úÖ FEATURE INTEGRITY PASSED: Wilder's ATR logic is strictly enforced.\n",
      "--- üõ°Ô∏è Starting Ranking Kernel Audit ---\n",
      "‚úÖ RANKING INTEGRITY PASSED: Volatility normalization is strictly enforced.\n",
      "\n",
      "--- üõ°Ô∏è Starting Volatility Alignment Audit ---\n",
      "‚úÖ Series Temporal Coupling: OK\n",
      "‚úÖ DataFrame Temporal Coupling: OK\n",
      "‚úÖ AUDIT PASSED: Reward and Risk are strictly synchronized.\n"
     ]
    }
   ],
   "source": [
    "# Auto-run the checks\n",
    "verify_math_integrity()\n",
    "\n",
    "verify_feature_engineering_integrity()\n",
    "\n",
    "verify_ranking_integrity()\n",
    "\n",
    "verify_vol_alignment_integrity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6d867e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_indices:|n                   Adj Open  Adj High  Adj Low  Adj Close  Volume\n",
      "Ticker Date                                                      \n",
      "^AXJO  1992-11-22   1455.00   1455.00  1455.00    1455.00       0\n",
      "       1992-11-23   1458.40   1458.40  1458.40    1458.40       0\n",
      "       1992-11-24   1467.90   1467.90  1467.90    1467.90       0\n",
      "       1992-11-25   1459.00   1459.00  1459.00    1459.00       0\n",
      "       1992-11-26   1458.90   1458.90  1458.90    1458.90       0\n",
      "...                     ...       ...      ...        ...     ...\n",
      "^VIX3M 2026-02-20     22.39     22.39    20.97      21.09       0\n",
      "       2026-02-23     21.25     22.52    21.13      22.14       0\n",
      "       2026-02-24     22.40     22.66    21.15      21.34       0\n",
      "       2026-02-25     20.82     20.92    20.34      20.36       0\n",
      "       2026-02-26     20.46     21.75    20.41      20.81       0\n",
      "\n",
      "[144597 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "data_path = r\"c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_indices.parquet\"\n",
    "\n",
    "df_indices = pd.read_parquet(data_path, engine=\"pyarrow\")\n",
    "print(f\"df_indices:|n{df_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf150180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['^AXJO',\n",
       " '^BSESN',\n",
       " '^DJI',\n",
       " '^FCHI',\n",
       " '^FTSE',\n",
       " '^GDAXI',\n",
       " '^GSPC',\n",
       " '^HSI',\n",
       " '^IXIC',\n",
       " '^N225',\n",
       " '^NYA',\n",
       " '^STOXX50E',\n",
       " '^VIX',\n",
       " '^VIX3M']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 144597 entries, ('^AXJO', Timestamp('1992-11-22 00:00:00')) to ('^VIX3M', Timestamp('2026-02-26 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   Adj Open   144597 non-null  float64\n",
      " 1   Adj High   144597 non-null  float64\n",
      " 2   Adj Low    144597 non-null  float64\n",
      " 3   Adj Close  144597 non-null  float64\n",
      " 4   Volume     144597 non-null  int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "_indices = df_indices.index.get_level_values(0).unique().tolist()\n",
    "display(_indices)\n",
    "df_indices.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "232740e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = (\n",
    "    r\"c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet\"\n",
    ")\n",
    "\n",
    "df_ohlcv = pd.read_parquet(data_path, engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "239275a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_ohlcv.head():\n",
      "                    Adj Open  Adj High  Adj Low  Adj Close    Volume\n",
      "Ticker Date                                                        \n",
      "A      1999-11-18   27.1966   29.8864  23.9091    26.3000  74849959\n",
      "       1999-11-19   25.6649   25.7023  23.7970    24.1333  18230872\n",
      "       1999-11-22   24.6936   26.3000  23.9465    26.3000   7871811\n",
      "       1999-11-23   25.4034   26.0759  23.9091    23.9091   7151080\n",
      "       1999-11-24   23.9838   25.0672  23.9091    24.5442   5795948\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 9487718 entries, ('A', Timestamp('1999-11-18 00:00:00')) to ('ZWS', Timestamp('2026-02-26 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   Adj Open   float64\n",
      " 1   Adj High   float64\n",
      " 2   Adj Low    float64\n",
      " 3   Adj Close  float64\n",
      " 4   Volume     int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 398.8+ MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"df_ohlcv.head():\\n {df_ohlcv.head()}\\n\")\n",
    "df_ohlcv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6e70338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing New Feature Engine...\n",
      "‚ö° Generating Decoupled Features (Benchmark: SPY)...\n",
      "‚úÖ Features Generated Successfully!\n",
      "\n",
      "--- TICKER FEATURES (Micro) ---\n",
      "Columns: ['ATR', 'ATRP', 'TRP', 'RSI', 'Mom_21', 'Consistency', 'IR_63', 'Beta_63', 'DD_21', 'Ret_1d', 'RollingStalePct', 'RollMedDollarVol', 'RollingSameVolCount']\n",
      "Sample Data:\n",
      "                    Mom_21   IR_63    ATRP\n",
      "Ticker Date                              \n",
      "A      2019-09-27  0.0922  0.0318  0.0195\n",
      "       2019-09-30  0.0862  0.0208  0.0189\n",
      "       2019-10-01  0.0547  0.0008  0.0201\n",
      "       2019-10-02  0.0440 -0.0324  0.0210\n",
      "       2019-10-03  0.0447 -0.0132  0.0207\n",
      "\n",
      "--- MACRO STATE (Shared) ---\n",
      "Columns: ['Mkt_Ret', 'Macro_Trend', 'Macro_Trend_Vel', 'Macro_Trend_Vel_Z', 'Macro_Trend_Mom', 'Macro_Vix_Z', 'Macro_Vix_Ratio']\n",
      "\n",
      "üîç Macro Check for 2019-10-03:\n",
      "Mkt_Ret              0.0000\n",
      "Macro_Trend          0.0000\n",
      "Macro_Trend_Vel      0.0000\n",
      "Macro_Trend_Vel_Z    0.0000\n",
      "Macro_Trend_Mom      0.0000\n",
      "Macro_Vix_Z         -1.3653\n",
      "Macro_Vix_Ratio      0.9120\n",
      "Name: 2019-10-03 00:00:00, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# === FIXED TEST HARNESS ===\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üß™ Testing New Feature Engine...\")\n",
    "\n",
    "    # 1. Create Dummy Index Data\n",
    "    dates = df_ohlcv.index.get_level_values(\"Date\").unique()\n",
    "    dummy_indices = []\n",
    "\n",
    "    for ticker in [\"^GSPC\", \"^VIX\", \"^VIX3M\"]:\n",
    "        temp = pd.DataFrame(\n",
    "            {\n",
    "                \"Adj Close\": (\n",
    "                    np.random.normal(100, 5, len(dates))\n",
    "                    if ticker == \"^GSPC\"\n",
    "                    else np.random.normal(20, 2, len(dates))\n",
    "                ),\n",
    "                \"Volume\": 1000,\n",
    "            },\n",
    "            index=dates,\n",
    "        )\n",
    "        temp[\"Ticker\"] = ticker\n",
    "        dummy_indices.append(temp.reset_index().set_index([\"Ticker\", \"Date\"]))\n",
    "\n",
    "    df_idx_test = pd.concat(dummy_indices)\n",
    "\n",
    "    # 2. Run Generation\n",
    "    try:\n",
    "        # FIX 1: Unpack the tuple into two variables\n",
    "        feat_df, mac_df = generate_features(\n",
    "            df_ohlcv.iloc[:5000], df_indices=df_idx_test\n",
    "        )\n",
    "\n",
    "        print(\"‚úÖ Features Generated Successfully!\")\n",
    "\n",
    "        # FIX 2: Check columns of the features_df (Ticker-specific)\n",
    "        print(\"\\n--- TICKER FEATURES (Micro) ---\")\n",
    "        print(\"Columns:\", feat_df.columns.tolist())\n",
    "        # Note: Macro_Vix_Z is no longer in feat_df (that's the point of the optimization!)\n",
    "        print(\"Sample Data:\\n\", feat_df[[\"Mom_21\", \"IR_63\", \"ATRP\"]].tail())\n",
    "\n",
    "        # FIX 3: Check the new Macro DataFrame\n",
    "        print(\"\\n--- MACRO STATE (Shared) ---\")\n",
    "        print(\"Columns:\", mac_df.columns.tolist())\n",
    "\n",
    "        # Check specific date alignment\n",
    "        last_date = feat_df.index.get_level_values(\"Date\")[-1]\n",
    "        print(f\"\\nüîç Macro Check for {last_date.date()}:\")\n",
    "        # We look up the date in the mac_df now\n",
    "        print(mac_df.loc[last_date])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d3a9824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Takes about 2.5 minutes to generate_features\n",
      "‚ö° Generating Decoupled Features (Benchmark: SPY)...\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# DATA PRE-COMPUTATION (The \"Fast-Track\" Setup)\n",
    "# ==============================================================================\n",
    "print(f\"Takes about 2.5 minutes to generate_features\")\n",
    "\n",
    "features_df, macro_df = generate_features(\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    df_indices=df_indices,\n",
    "    benchmark_ticker=GLOBAL_SETTINGS[\"benchmark_ticker\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eed07737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 9487718 entries, ('A', Timestamp('1999-11-18 00:00:00')) to ('ZWS', Timestamp('2026-02-26 00:00:00'))\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Dtype  \n",
      "---  ------               -----  \n",
      " 0   ATR                  float64\n",
      " 1   ATRP                 float64\n",
      " 2   TRP                  float64\n",
      " 3   RSI                  float64\n",
      " 4   Mom_21               float64\n",
      " 5   Consistency          float64\n",
      " 6   IR_63                float64\n",
      " 7   Beta_63              float64\n",
      " 8   DD_21                float64\n",
      " 9   Ret_1d               float64\n",
      " 10  RollingStalePct      float64\n",
      " 11  RollMedDollarVol     float64\n",
      " 12  RollingSameVolCount  float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 977.9+ MB\n",
      "features_df.info():\n",
      "None\n",
      "\n",
      "features_df.index.names:\n",
      "['Ticker', 'Date']\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 16146 entries, 1962-01-02 to 2026-02-26\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Mkt_Ret            16146 non-null  float64\n",
      " 1   Macro_Trend        16146 non-null  float64\n",
      " 2   Macro_Trend_Vel    16146 non-null  float64\n",
      " 3   Macro_Trend_Vel_Z  16146 non-null  float64\n",
      " 4   Macro_Trend_Mom    16146 non-null  float64\n",
      " 5   Macro_Vix_Z        16146 non-null  float64\n",
      " 6   Macro_Vix_Ratio    16146 non-null  float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 1.5 MB\n",
      "macro_df.info():\n",
      "None\n",
      "\n",
      "macro_df.index.names:\n",
      "['Date']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"features_df.info():\\n{features_df.info()}\\n\")\n",
    "print(f\"features_df.index.names:\\n{features_df.index.names}\\n\")\n",
    "print(f\"macro_df.info():\\n{macro_df.info()}\\n\")\n",
    "print(f\"macro_df.index.names:\\n{macro_df.index.names}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5f1e8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Macro Verification (Benchmark: SPY) ---\n",
      "\n",
      "Comparing verification vs original (Clip Threshold: 4.0):\n",
      "‚úÖ Mkt_Ret              | PASS (Max Diff: 0.00e+00)\n",
      "‚úÖ Macro_Trend          | PASS (Max Diff: 0.00e+00)\n",
      "‚úÖ Macro_Trend_Vel      | PASS (Max Diff: 0.00e+00)\n",
      "‚úÖ Macro_Trend_Vel_Z    | PASS (Max Diff: 0.00e+00)\n",
      "‚úÖ Macro_Trend_Mom      | PASS (Max Diff: 0.00e+00)\n",
      "‚úÖ Macro_Vix_Z          | PASS (Max Diff: 0.00e+00)\n",
      "‚úÖ Macro_Vix_Ratio      | PASS (Max Diff: 0.00e+00)\n"
     ]
    }
   ],
   "source": [
    "verify_macro_engine(df_ohlcv, df_indices, macro_df, GLOBAL_SETTINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e82d6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Generating Wide Matrices for Instant Backtesting... (takes about 1 minute to run)\n",
      "   - Unstacking ATRP...\n",
      "   - Unstacking TRP...\n",
      "‚úÖ Pre-computation Complete. Tickers: 1581, Days: 16146\n",
      "   Ready: df_close_wide, df_atrp_wide, df_trp_wide, and macro_df.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"üöÄ Generating Wide Matrices for Instant Backtesting... (takes about 1 minute to run)\"\n",
    ")\n",
    "\n",
    "# 1. Price Matrix\n",
    "df_close_wide = df_ohlcv[\"Adj Close\"].unstack(level=0)\n",
    "\n",
    "# 2. Volatility Matrices (Unstack and Align)\n",
    "# Using features_df (the first item from the tuple)\n",
    "print(\"   - Unstacking ATRP...\")\n",
    "df_atrp_wide = features_df[\"ATRP\"].unstack(level=0).reindex_like(df_close_wide)\n",
    "\n",
    "print(\"   - Unstacking TRP...\")\n",
    "df_trp_wide = features_df[\"TRP\"].unstack(level=0).reindex_like(df_close_wide)\n",
    "\n",
    "# 3. Handle Data Gaps (Sanitize the Wide Matrices)\n",
    "if GLOBAL_SETTINGS[\"handle_zeros_as_nan\"]:\n",
    "    df_close_wide = df_close_wide.replace(0, np.nan)\n",
    "\n",
    "# Forward fill up to the limit, then fill remaining with the \"Disaster Detection\" value\n",
    "df_close_wide = df_close_wide.ffill(limit=GLOBAL_SETTINGS[\"max_data_gap_ffill\"])\n",
    "df_close_wide = df_close_wide.fillna(GLOBAL_SETTINGS[\"nan_price_replacement\"])\n",
    "\n",
    "print(\n",
    "    f\"‚úÖ Pre-computation Complete. Tickers: {len(df_close_wide.columns)}, Days: {len(df_close_wide)}\"\n",
    ")\n",
    "print(\"   Ready: df_close_wide, df_atrp_wide, df_trp_wide, and macro_df.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2e95348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This ensures the 'master_engine' variable actually uses the code you just pasted above.\n",
    "master_engine = AlphaEngine(\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    features_df=features_df,\n",
    "    macro_df=macro_df,\n",
    "    df_close_wide=df_close_wide,\n",
    "    df_atrp_wide=df_atrp_wide,\n",
    "    df_trp_wide=df_trp_wide,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df84a930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "‚úì Added to path: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_RLVR\n",
      "NOTEBOOKS_RLVR_ROOT: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_RLVR\n",
      "\n",
      "OUTPUT_DIR: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_RLVR\\output\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Enable Autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def add_project_root_to_path():\n",
    "    \"\"\"Find notebooks_RLVR and add to sys.path.\"\"\"\n",
    "    current = Path.cwd()\n",
    "\n",
    "    # Search upward for notebooks_RLVR folder\n",
    "    for path in [current] + list(current.parents):\n",
    "        if path.name == \"notebooks_RLVR\":\n",
    "            sys.path.insert(0, str(path))\n",
    "            print(f\"‚úì Added to path: {path}\")\n",
    "            return path\n",
    "        # Also check if notebooks_RLVR exists as child (for running from stocks/)\n",
    "        candidate = path / \"notebooks_RLVR\"\n",
    "        if candidate.exists():\n",
    "            sys.path.insert(0, str(candidate))\n",
    "            print(f\"‚úì Added to path: {candidate}\")\n",
    "            return candidate\n",
    "\n",
    "    raise RuntimeError(\"Could not find notebooks_RLVR directory\")\n",
    "\n",
    "\n",
    "# Run once at notebook start\n",
    "add_project_root_to_path()\n",
    "\n",
    "\n",
    "# 2. Force reload cached modules (run this to refresh code changes)\n",
    "import importlib\n",
    "\n",
    "modules_to_reload = [\n",
    "    \"core.engine\",\n",
    "    \"core.contracts\",\n",
    "    \"core.settings\",\n",
    "    \"strategy.registry\",\n",
    "    \"core.quant\",\n",
    "    \"core.analyzer\",\n",
    "    \"core.paths\",\n",
    "]\n",
    "\n",
    "for mod in modules_to_reload:\n",
    "    if mod in sys.modules:\n",
    "        del sys.modules[mod]\n",
    "\n",
    "\n",
    "# 3. Standard imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display\n",
    "from dataclasses import fields, asdict, is_dataclass\n",
    "from typing import List, Union, Tuple \n",
    "\n",
    "\n",
    "# 4. Fresh imports (these will re-import from disk due to cache clearing above)\n",
    "from core.engine import AlphaEngine\n",
    "from core.contracts import MarketObservation, FilterPack\n",
    "from core.settings import GLOBAL_SETTINGS\n",
    "from strategy.registry import METRIC_REGISTRY\n",
    "from core.quant import QuantUtils\n",
    "from core.analyzer import create_walk_forward_analyzer\n",
    "from core.paths import OUTPUT_DIR\n",
    "\n",
    "\n",
    "# 5. Pandas display settings\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"display.max_colwidth\", 50)\n",
    "pd.set_option(\"display.precision\", 4)\n",
    "\n",
    "\n",
    "# 6. Instantiate engine (customize DataFrames as needed)\n",
    "master_engine = AlphaEngine(\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    features_df=features_df,\n",
    "    macro_df=macro_df,\n",
    "    df_close_wide=df_close_wide,\n",
    "    df_atrp_wide=df_atrp_wide,\n",
    "    df_trp_wide=df_trp_wide,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0c4cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Ready for Stage 1: Run Simulation for first filter.\n",
      "DEBUG: 937 stocks passed filters on 2025-12-10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b84c957ff3174575a54f545204fbf21b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>1. Timeline Configuration:</b> (Past <--- Decision ---> Future)'), HBox(children‚Ä¶"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# universe_subset=None means \"Scan the whole market\"\n",
    "analyzer1, stage1_pack = create_walk_forward_analyzer(\n",
    "    master_engine, universe_subset=None\n",
    ")\n",
    "\n",
    "print(\"üöÄ Ready for Stage 1: Run Simulation for first filter.\")\n",
    "analyzer1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0227cbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Ready for Stage 2: Run Simulation for 2nd filter.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d215a6191b054c718e735d382c8d0f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>1. Timeline Configuration:</b> (Past <--- Decision ---> Future)'), HBox(children‚Ä¶"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get decision date from last run\n",
    "decision_date_last_run = FilterPack(decision_date=analyzer1.last_run.decision_date)\n",
    "\n",
    "# 1. LAUNCH STAGE 2 (Cascade)\n",
    "# universe_subset=analyzer1.last_run.tickers means \"Scan the whole market\"\n",
    "analyzer2, stage1_pack = create_walk_forward_analyzer(\n",
    "    master_engine,\n",
    "    universe_subset=analyzer1.last_run.tickers,\n",
    "    # universe_subset=None,\n",
    "    filter_pack=decision_date_last_run,\n",
    ")\n",
    "\n",
    "print(\"üöÄ Ready for Stage 2: Run Simulation for 2nd filter.\")\n",
    "analyzer2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44eb1d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6ff2e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================\n",
      "üîç HIGH-TRANSPARENCY AUDIT MAP\n",
      "====================================================================\n",
      "[  0] üì¶ audit_pack (EngineOutput)\n",
      "[  1]   üìà portfolio_series (shape=(17,))\n",
      "[  2]   üìà benchmark_series (shape=(17,))\n",
      "[  3]   üßÆ normalized_plot_data (shape=(17, 10))\n",
      "[  4]   üìÇ tickers (len=10)\n",
      "[  5]     üìÑ index_0 (str)\n",
      "[  6]     üìÑ index_1 (str)\n",
      "[  7]     üìÑ index_2 (str)\n",
      "[  8]     üìÑ index_3 (str)\n",
      "[  9]     üìÑ index_4 (str)\n",
      "[ 10]     üìÑ index_5 (str)\n",
      "[ 11]     üìÑ index_6 (str)\n",
      "[ 12]     üìÑ index_7 (str)\n",
      "[ 13]     üìÑ index_8 (str)\n",
      "[ 14]     üìÑ index_9 (str)\n",
      "[ 15]   üìà initial_weights (shape=(10,))\n",
      "[ 16]   üìÇ perf_metrics (len=24)\n",
      "[ 17]     üî¢ full_p_gain (float)\n",
      "[ 18]     üî¢ full_p_sharpe (float)\n",
      "[ 19]     üî¢ full_p_sharpe_atrp (float)\n",
      "[ 20]     üî¢ full_p_sharpe_trp (float)\n",
      "[ 21]     üî¢ lookback_p_gain (float)\n",
      "[ 22]     üî¢ lookback_p_sharpe (float)\n",
      "[ 23]     üî¢ lookback_p_sharpe_atrp (float)\n",
      "[ 24]     üî¢ lookback_p_sharpe_trp (float)\n",
      "[ 25]     üî¢ holding_p_gain (float)\n",
      "[ 26]     üî¢ holding_p_sharpe (float)\n",
      "[ 27]     üî¢ holding_p_sharpe_atrp (float)\n",
      "[ 28]     üî¢ holding_p_sharpe_trp (float)\n",
      "[ 29]     üî¢ full_b_gain (float)\n",
      "[ 30]     üî¢ full_b_sharpe (float)\n",
      "[ 31]     üî¢ full_b_sharpe_atrp (float)\n",
      "[ 32]     üî¢ full_b_sharpe_trp (float)\n",
      "[ 33]     üî¢ lookback_b_gain (float)\n",
      "[ 34]     üî¢ lookback_b_sharpe (float)\n",
      "[ 35]     üî¢ lookback_b_sharpe_atrp (float)\n",
      "[ 36]     üî¢ lookback_b_sharpe_trp (float)\n",
      "[ 37]     üî¢ holding_b_gain (float)\n",
      "[ 38]     üî¢ holding_b_sharpe (float)\n",
      "[ 39]     üî¢ holding_b_sharpe_atrp (float)\n",
      "[ 40]     üî¢ holding_b_sharpe_trp (float)\n",
      "[ 41]   üßÆ results_df (shape=(10, 2))\n",
      "[ 42]   üìÖ start_date (Timestamp)\n",
      "[ 43]   üìÖ decision_date (Timestamp)\n",
      "[ 44]   üìÖ buy_date (Timestamp)\n",
      "[ 45]   üìÖ holding_end_date (Timestamp)\n",
      "[ 46]   üìà portfolio_atrp_series (shape=(17,))\n",
      "[ 47]   üìà benchmark_atrp_series (shape=(17,))\n",
      "[ 48]   üìà portfolio_trp_series (shape=(17,))\n",
      "[ 49]   üìà benchmark_trp_series (shape=(17,))\n",
      "[ 50]   üìÑ error_msg (NoneType)\n",
      "[ 51]   üìÇ debug_data (len=8)\n",
      "[ 52]     üìÇ audit_liquidity (len=3)\n",
      "[ 53]       üìÑ mode (str)\n",
      "[ 54]       üî¢ tickers_passed (int)\n",
      "[ 55]       üî¢ forced_list (bool)\n",
      "[ 56]     üßÆ full_universe_ranking (shape=(80, 4))\n",
      "[ 57]     üìÇ meta (len=4)\n",
      "[ 58]       üî¢ dropped_count (int)\n",
      "[ 59]       üìÇ dropped_tickers (len=0)\n",
      "[ 60]       üî¢ clean_count (int)\n",
      "[ 61]       üìÑ selection_range (str)\n",
      "[ 62]     üì¶ inputs_snapshot (EngineInput)\n",
      "[ 63]       üìÑ mode (str)\n",
      "[ 64]       üìÖ start_date (Timestamp)\n",
      "[ 65]       üî¢ lookback_period (int)\n",
      "[ 66]       üî¢ holding_period (int)\n",
      "[ 67]       üìÑ metric (str)\n",
      "[ 68]       üìÑ benchmark_ticker (str)\n",
      "[ 69]       üî¢ rank_start (int)\n",
      "[ 70]       üî¢ rank_end (int)\n",
      "[ 71]       üìÇ quality_thresholds (len=4)\n",
      "[ 72]         üî¢ min_median_dollar_volume (int)\n",
      "[ 73]         üî¢ min_liquidity_percentile (float)\n",
      "[ 74]         üî¢ max_stale_pct (float)\n",
      "[ 75]         üî¢ max_same_vol_count (int)\n",
      "[ 76]       üìÇ manual_tickers (len=0)\n",
      "[ 77]       üî¢ debug (bool)\n",
      "[ 78]       üìÇ universe_subset (len=80)\n",
      "[ 79]         üìÑ index_0 (str)\n",
      "[ 80]         üìÑ index_1 (str)\n",
      "[ 81]         üìÑ index_2 (str)\n",
      "[ 82]         üìÑ index_3 (str)\n",
      "[ 83]         üìÑ index_4 (str)\n",
      "[ 84]         üìÑ index_5 (str)\n",
      "[ 85]         üìÑ index_6 (str)\n",
      "[ 86]         üìÑ index_7 (str)\n",
      "[ 87]         üìÑ index_8 (str)\n",
      "[ 88]         üìÑ index_9 (str)\n",
      "[ 89]         üìÑ index_10 (str)\n",
      "[ 90]         üìÑ index_11 (str)\n",
      "[ 91]         üìÑ index_12 (str)\n",
      "[ 92]         üìÑ index_13 (str)\n",
      "[ 93]         üìÑ index_14 (str)\n",
      "[ 94]         üìÑ index_15 (str)\n",
      "[ 95]         üìÑ index_16 (str)\n",
      "[ 96]         üìÑ index_17 (str)\n",
      "[ 97]         üìÑ index_18 (str)\n",
      "[ 98]         üìÑ index_19 (str)\n",
      "[ 99]         üìÑ index_20 (str)\n",
      "[100]         üìÑ index_21 (str)\n",
      "[101]         üìÑ index_22 (str)\n",
      "[102]         üìÑ index_23 (str)\n",
      "[103]         üìÑ index_24 (str)\n",
      "[104]         üìÑ index_25 (str)\n",
      "[105]         üìÑ index_26 (str)\n",
      "[106]         üìÑ index_27 (str)\n",
      "[107]         üìÑ index_28 (str)\n",
      "[108]         üìÑ index_29 (str)\n",
      "[109]         üìÑ index_30 (str)\n",
      "[110]         üìÑ index_31 (str)\n",
      "[111]         üìÑ index_32 (str)\n",
      "[112]         üìÑ index_33 (str)\n",
      "[113]         üìÑ index_34 (str)\n",
      "[114]         üìÑ index_35 (str)\n",
      "[115]         üìÑ index_36 (str)\n",
      "[116]         üìÑ index_37 (str)\n",
      "[117]         üìÑ index_38 (str)\n",
      "[118]         üìÑ index_39 (str)\n",
      "[119]         üìÑ index_40 (str)\n",
      "[120]         üìÑ index_41 (str)\n",
      "[121]         üìÑ index_42 (str)\n",
      "[122]         üìÑ index_43 (str)\n",
      "[123]         üìÑ index_44 (str)\n",
      "[124]         üìÑ index_45 (str)\n",
      "[125]         üìÑ index_46 (str)\n",
      "[126]         üìÑ index_47 (str)\n",
      "[127]         üìÑ index_48 (str)\n",
      "[128]         üìÑ index_49 (str)\n",
      "[129]         üìÑ index_50 (str)\n",
      "[130]         üìÑ index_51 (str)\n",
      "[131]         üìÑ index_52 (str)\n",
      "[132]         üìÑ index_53 (str)\n",
      "[133]         üìÑ index_54 (str)\n",
      "[134]         üìÑ index_55 (str)\n",
      "[135]         üìÑ index_56 (str)\n",
      "[136]         üìÑ index_57 (str)\n",
      "[137]         üìÑ index_58 (str)\n",
      "[138]         üìÑ index_59 (str)\n",
      "[139]         üìÑ index_60 (str)\n",
      "[140]         üìÑ index_61 (str)\n",
      "[141]         üìÑ index_62 (str)\n",
      "[142]         üìÑ index_63 (str)\n",
      "[143]         üìÑ index_64 (str)\n",
      "[144]         üìÑ index_65 (str)\n",
      "[145]         üìÑ index_66 (str)\n",
      "[146]         üìÑ index_67 (str)\n",
      "[147]         üìÑ index_68 (str)\n",
      "[148]         üìÑ index_69 (str)\n",
      "[149]         üìÑ index_70 (str)\n",
      "[150]         üìÑ index_71 (str)\n",
      "[151]         üìÑ index_72 (str)\n",
      "[152]         üìÑ index_73 (str)\n",
      "[153]         üìÑ index_74 (str)\n",
      "[154]         üìÑ index_75 (str)\n",
      "[155]         üìÑ index_76 (str)\n",
      "[156]         üìÑ index_77 (str)\n",
      "[157]         üìÑ index_78 (str)\n",
      "[158]         üìÑ index_79 (str)\n",
      "[159]     üìÇ verification (len=2)\n",
      "[160]       üìÇ p (len=12)\n",
      "                  ‚ï∞‚îÄ‚îÄ full_val --> [See ID 1]\n",
      "[161]         üìà full_ret (shape=(17,))\n",
      "                  ‚ï∞‚îÄ‚îÄ full_atrp --> [See ID 46]\n",
      "                  ‚ï∞‚îÄ‚îÄ full_trp --> [See ID 48]\n",
      "[162]         üìà lookback_val (shape=(11,))\n",
      "[163]         üìà lookback_ret (shape=(11,))\n",
      "[164]         üìà lookback_atrp (shape=(11,))\n",
      "[165]         üìà lookback_trp (shape=(11,))\n",
      "[166]         üìà holding_val (shape=(6,))\n",
      "[167]         üìà holding_ret (shape=(6,))\n",
      "[168]         üìà holding_atrp (shape=(6,))\n",
      "[169]         üìà holding_trp (shape=(6,))\n",
      "[170]       üìÇ b (len=12)\n",
      "                  ‚ï∞‚îÄ‚îÄ full_val --> [See ID 2]\n",
      "[171]         üìà full_ret (shape=(17,))\n",
      "                  ‚ï∞‚îÄ‚îÄ full_atrp --> [See ID 47]\n",
      "                  ‚ï∞‚îÄ‚îÄ full_trp --> [See ID 49]\n",
      "[172]         üìà lookback_val (shape=(11,))\n",
      "[173]         üìà lookback_ret (shape=(11,))\n",
      "[174]         üìà lookback_atrp (shape=(11,))\n",
      "[175]         üìà lookback_trp (shape=(11,))\n",
      "[176]         üìà holding_val (shape=(6,))\n",
      "[177]         üìà holding_ret (shape=(6,))\n",
      "[178]         üìà holding_atrp (shape=(6,))\n",
      "[179]         üìà holding_trp (shape=(6,))\n",
      "[180]     üìÇ portfolio_raw_components (len=4)\n",
      "[181]       üßÆ prices (shape=(17, 10))\n",
      "[182]       üßÆ atrp (shape=(17, 10))\n",
      "[183]       üßÆ trp (shape=(17, 10))\n",
      "[184]       üßÆ ohlcv_raw (shape=(170, 5))\n",
      "[185]     üìÇ benchmark_raw_components (len=4)\n",
      "[186]       üßÆ prices (shape=(17, 1))\n",
      "[187]       üßÆ atrp (shape=(17, 1))\n",
      "[188]       üßÆ trp (shape=(17, 1))\n",
      "[189]       üßÆ ohlcv_raw (shape=(17, 5))\n",
      "              ‚ï∞‚îÄ‚îÄ selection_audit --> [See ID 56]\n",
      "[190]   üßÆ macro_df (shape=(16146, 7))\n"
     ]
    }
   ],
   "source": [
    "my_analyzer = analyzer2\n",
    "\n",
    "my_res = visualize_analyzer_structure(my_analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5f1fb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================================================================================\n",
      "***********************************************************************************************\n",
      "üïµÔ∏è  STARTING SHORT-FORM AUDIT: Price Gain @ 2026-02-18\n",
      "‚ö†Ô∏è  ASSUMPTION: Verification logic is independent, but trusts Engine source DataFrames\n",
      "   (engine.features_df, engine.df_close, and debug['portfolio_raw_components'])\n",
      "***********************************************************************************************\n",
      "===============================================================================================\n",
      "üïµÔ∏è  AUDIT: Price Gain @ 2026-02-18\n",
      "===============================================================================================\n",
      "LAYER 1: SURVIVAL  | Mode: CASCADE/SUBSET | ‚úÖ BYPASS\n",
      "LAYER 2: SELECTION | Strategy: Price Gain | Selection Match: ‚úÖ PASS\n",
      "LAYER 3: PERFORMANCE (Holding Period: 5 days)\n",
      "Metric               | Engine       | Manual       | Status\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Gain                 |     0.043951 |     0.043951 | ‚úÖ PASS\n",
      "Sharpe               |    23.768151 |    23.768151 | ‚úÖ PASS\n",
      "Sharpe (ATRP)        |     0.260284 |     0.260284 | ‚úÖ PASS\n",
      "Sharpe (TRP)         |     0.274655 |     0.274655 | ‚úÖ PASS\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "verify_analyzer_short(my_analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a23faaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= verify_analyzer_long (FINAL) ========= \n",
      "\n",
      "\n",
      "=====================================================================================\n",
      "üõ°Ô∏è  STARTING NUCLEAR AUDIT | 2026-02-18 | Price Gain\n",
      "=====================================================================================\n",
      "üìù 1. PERFORMANCE RECONCILIATION\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Period</th>\n",
       "      <th>Full</th>\n",
       "      <th>Holding</th>\n",
       "      <th>Lookback</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entity</th>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Benchmark</th>\n",
       "      <th>Gain</th>\n",
       "      <td>‚úÖ PASS</td>\n",
       "      <td>‚úÖ PASS</td>\n",
       "      <td>‚úÖ PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe</th>\n",
       "      <td>‚úÖ PASS</td>\n",
       "      <td>‚úÖ PASS</td>\n",
       "      <td>‚úÖ PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe (ATRP)</th>\n",
       "      <td>‚úÖ PASS</td>\n",
       "      <td>‚úÖ PASS</td>\n",
       "      <td>‚úÖ PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe (TRP)</th>\n",
       "      <td>‚úÖ PASS</td>\n",
       "      <td>‚úÖ PASS</td>\n",
       "      <td>‚úÖ PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Group</th>\n",
       "      <th>Gain</th>\n",
       "      <td>‚úÖ PASS</td>\n",
       "      <td>‚úÖ PASS</td>\n",
       "      <td>‚úÖ PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe</th>\n",
       "      <td>‚úÖ PASS</td>\n",
       "      <td>‚úÖ PASS</td>\n",
       "      <td>‚úÖ PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe (ATRP)</th>\n",
       "      <td>‚úÖ PASS</td>\n",
       "      <td>‚úÖ PASS</td>\n",
       "      <td>‚úÖ PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe (TRP)</th>\n",
       "      <td>‚úÖ PASS</td>\n",
       "      <td>‚úÖ PASS</td>\n",
       "      <td>‚úÖ PASS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Period                     Full Holding Lookback\n",
       "Entity    Metric                                \n",
       "Benchmark Gain           ‚úÖ PASS  ‚úÖ PASS   ‚úÖ PASS\n",
       "          Sharpe         ‚úÖ PASS  ‚úÖ PASS   ‚úÖ PASS\n",
       "          Sharpe (ATRP)  ‚úÖ PASS  ‚úÖ PASS   ‚úÖ PASS\n",
       "          Sharpe (TRP)   ‚úÖ PASS  ‚úÖ PASS   ‚úÖ PASS\n",
       "Group     Gain           ‚úÖ PASS  ‚úÖ PASS   ‚úÖ PASS\n",
       "          Sharpe         ‚úÖ PASS  ‚úÖ PASS   ‚úÖ PASS\n",
       "          Sharpe (ATRP)  ‚úÖ PASS  ‚úÖ PASS   ‚úÖ PASS\n",
       "          Sharpe (TRP)   ‚úÖ PASS  ‚úÖ PASS   ‚úÖ PASS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====================================================================================\n",
      "üìù 2. SURVIVAL AUDIT\n",
      "   Mode: CASCADE/SUBSET | Logic: Quality filters bypassed per design. | ‚úÖ BYPASS\n",
      "\n",
      "=====================================================================================\n",
      "üìù 3. UNIVERSAL SELECTION AUDIT | Strategy: Price Gain\n",
      "   Scope: Evaluated 80 candidates (Full Universe).\n",
      "   Result: 80 PASSED | 0 FAILED\n",
      "   All scores match registry math. Price Gain results of the first 5 tickers\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_9aac9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9aac9_level0_col0\" class=\"col_heading level0 col0\" >Ticker</th>\n",
       "      <th id=\"T_9aac9_level0_col1\" class=\"col_heading level0 col1\" >Engine</th>\n",
       "      <th id=\"T_9aac9_level0_col2\" class=\"col_heading level0 col2\" >Manual</th>\n",
       "      <th id=\"T_9aac9_level0_col3\" class=\"col_heading level0 col3\" >Delta</th>\n",
       "      <th id=\"T_9aac9_level0_col4\" class=\"col_heading level0 col4\" >Status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Rank</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9aac9_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_9aac9_row0_col0\" class=\"data row0 col0\" >AEM</td>\n",
       "      <td id=\"T_9aac9_row0_col1\" class=\"data row0 col1\" >0.11155361</td>\n",
       "      <td id=\"T_9aac9_row0_col2\" class=\"data row0 col2\" >0.11155361</td>\n",
       "      <td id=\"T_9aac9_row0_col3\" class=\"data row0 col3\" >0.00000000</td>\n",
       "      <td id=\"T_9aac9_row0_col4\" class=\"data row0 col4\" >‚úÖ PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9aac9_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "      <td id=\"T_9aac9_row1_col0\" class=\"data row1 col0\" >AG</td>\n",
       "      <td id=\"T_9aac9_row1_col1\" class=\"data row1 col1\" >0.02509092</td>\n",
       "      <td id=\"T_9aac9_row1_col2\" class=\"data row1 col2\" >0.02509092</td>\n",
       "      <td id=\"T_9aac9_row1_col3\" class=\"data row1 col3\" >0.00000000</td>\n",
       "      <td id=\"T_9aac9_row1_col4\" class=\"data row1 col4\" >‚úÖ PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9aac9_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "      <td id=\"T_9aac9_row2_col0\" class=\"data row2 col0\" >ASX</td>\n",
       "      <td id=\"T_9aac9_row2_col1\" class=\"data row2 col1\" >0.18541116</td>\n",
       "      <td id=\"T_9aac9_row2_col2\" class=\"data row2 col2\" >0.18541116</td>\n",
       "      <td id=\"T_9aac9_row2_col3\" class=\"data row2 col3\" >0.00000000</td>\n",
       "      <td id=\"T_9aac9_row2_col4\" class=\"data row2 col4\" >‚úÖ PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9aac9_level0_row3\" class=\"row_heading level0 row3\" >4</th>\n",
       "      <td id=\"T_9aac9_row3_col0\" class=\"data row3 col0\" >ATI</td>\n",
       "      <td id=\"T_9aac9_row3_col1\" class=\"data row3 col1\" >0.14637324</td>\n",
       "      <td id=\"T_9aac9_row3_col2\" class=\"data row3 col2\" >0.14637324</td>\n",
       "      <td id=\"T_9aac9_row3_col3\" class=\"data row3 col3\" >0.00000000</td>\n",
       "      <td id=\"T_9aac9_row3_col4\" class=\"data row3 col4\" >‚úÖ PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9aac9_level0_row4\" class=\"row_heading level0 row4\" >5</th>\n",
       "      <td id=\"T_9aac9_row4_col0\" class=\"data row4 col0\" >AU</td>\n",
       "      <td id=\"T_9aac9_row4_col1\" class=\"data row4 col1\" >0.07282379</td>\n",
       "      <td id=\"T_9aac9_row4_col2\" class=\"data row4 col2\" >0.07282379</td>\n",
       "      <td id=\"T_9aac9_row4_col3\" class=\"data row4 col3\" >0.00000000</td>\n",
       "      <td id=\"T_9aac9_row4_col4\" class=\"data row4 col4\" >‚úÖ PASS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x21f0e729690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "verify_analyzer_long(my_analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6869fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================================================================================\n",
      "üïµÔ∏è  NUCLEAR FEATURE AUDIT | Mode: LAST_RUN | Tickers: 10\n",
      "===============================================================================================\n",
      "STEP 1: BOUNDARY INTEGRITY   | MultiIndex Isolation Check | ‚úÖ PASS\n",
      "STEP 2: SHADOW CALCULATIONS  | Re-computing metrics... DONE (0.57s)\n",
      "\n",
      "Metric               | Max Delta    | Correlation  | Status\n",
      "-------------------------------------------------------------------------------------\n",
      "Ret_1d               |   0.0000e+00 |     1.000000 | ‚úÖ PASS\n",
      "ATR                  |   0.0000e+00 |     1.000000 | ‚úÖ PASS\n",
      "ATRP                 |   0.0000e+00 |     1.000000 | ‚úÖ PASS\n",
      "TRP                  |   0.0000e+00 |     1.000000 | ‚úÖ PASS\n",
      "RSI                  |   0.0000e+00 |     1.000000 | ‚úÖ PASS\n",
      "Mom_21               |   0.0000e+00 |     1.000000 | ‚úÖ PASS\n",
      "Consistency          |   0.0000e+00 |     1.000000 | ‚úÖ PASS\n",
      "DD_21                |   0.0000e+00 |     1.000000 | ‚úÖ PASS\n",
      "RollingStalePct      |   0.0000e+00 |     1.000000 | ‚úÖ PASS\n",
      "RollMedDollarVol     |   0.0000e+00 |     1.000000 | ‚úÖ PASS\n",
      "RollingSameVolCount  |   0.0000e+00 |     1.000000 | ‚úÖ PASS\n",
      "Macro_Vix_Signals    | N/A          | N/A          | ‚úÖ LIVE\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Takes 4 seconds to run, checks selected tickers from analyzer1\n",
    "audit_feature_engineering_integrity(my_analyzer, mode=\"last_run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65e41650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ [EXCEL AUDIT] Building full transparency report: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_RLVR\\output\\Audit_Verification_Report.xlsx\n",
      "‚ú® Audit Report Complete: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_RLVR\\output\\Audit_Verification_Report.xlsx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/ping/Files_win10/python/py311/stocks/notebooks_RLVR/output/Audit_Verification_Report.xlsx')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_name_excel = OUTPUT_DIR / \"Audit_Verification_Report.xlsx\"\n",
    "\n",
    "export_audit_to_excel(audit_pack=my_analyzer.last_run, filename=f_name_excel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbf136b",
   "metadata": {},
   "source": [
    "### Export Ticker's OHLCV and its Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7c8c4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating combined dictionary for 11 ticker(s)\n",
      "Date range: 2026-02-03 00:00:00 to 2026-02-26 00:00:00\n",
      "============================================================\n",
      "Data retrieved for 11 ticker(s) from 2026-02-03 00:00:00 to 2026-02-26 00:00:00\n",
      "Total rows: 187\n",
      "Date range in data: 2026-02-03 00:00:00 to 2026-02-26 00:00:00\n",
      "  IAG: 17 rows\n",
      "  AU: 17 rows\n",
      "  BUD: 17 rows\n",
      "  CAT: 17 rows\n",
      "  EWY: 17 rows\n",
      "  NEM: 17 rows\n",
      "  WBD: 17 rows\n",
      "  WWD: 17 rows\n",
      "  JNJ: 17 rows\n",
      "  GDX: 17 rows\n",
      "  SPY: 17 rows\n",
      "Features data retrieved for 11 ticker(s) from 2026-02-03 00:00:00 to 2026-02-26 00:00:00\n",
      "Total rows: 187\n",
      "Date range in data: 2026-02-03 00:00:00 to 2026-02-26 00:00:00\n",
      "Available features: ATR, ATRP, TRP, RSI, Mom_21, Consistency, IR_63, Beta_63, DD_21, Ret_1d, RollingStalePct, RollMedDollarVol, RollingSameVolCount\n",
      "  IAG: 17 rows\n",
      "  AU: 17 rows\n",
      "  BUD: 17 rows\n",
      "  CAT: 17 rows\n",
      "  EWY: 17 rows\n",
      "  NEM: 17 rows\n",
      "  WBD: 17 rows\n",
      "  WWD: 17 rows\n",
      "  JNJ: 17 rows\n",
      "  GDX: 17 rows\n",
      "  SPY: 17 rows\n",
      "\n",
      "Processing IAG...\n",
      "  ‚úì Successfully combined data\n",
      "  OHLCV shape: (17, 5)\n",
      "  Features shape: (17, 13)\n",
      "  Combined shape: (17, 18)\n",
      "  Date range: 2026-02-03 00:00:00 to 2026-02-26 00:00:00\n",
      "\n",
      "Processing AU...\n",
      "  ‚úì Successfully combined data\n",
      "  OHLCV shape: (17, 5)\n",
      "  Features shape: (17, 13)\n",
      "  Combined shape: (17, 18)\n",
      "  Date range: 2026-02-03 00:00:00 to 2026-02-26 00:00:00\n",
      "\n",
      "Processing BUD...\n",
      "  ‚úì Successfully combined data\n",
      "  OHLCV shape: (17, 5)\n",
      "  Features shape: (17, 13)\n",
      "  Combined shape: (17, 18)\n",
      "  Date range: 2026-02-03 00:00:00 to 2026-02-26 00:00:00\n",
      "\n",
      "Processing CAT...\n",
      "  ‚úì Successfully combined data\n",
      "  OHLCV shape: (17, 5)\n",
      "  Features shape: (17, 13)\n",
      "  Combined shape: (17, 18)\n",
      "  Date range: 2026-02-03 00:00:00 to 2026-02-26 00:00:00\n",
      "\n",
      "Processing EWY...\n",
      "  ‚úì Successfully combined data\n",
      "  OHLCV shape: (17, 5)\n",
      "  Features shape: (17, 13)\n",
      "  Combined shape: (17, 18)\n",
      "  Date range: 2026-02-03 00:00:00 to 2026-02-26 00:00:00\n",
      "\n",
      "Processing NEM...\n",
      "  ‚úì Successfully combined data\n",
      "  OHLCV shape: (17, 5)\n",
      "  Features shape: (17, 13)\n",
      "  Combined shape: (17, 18)\n",
      "  Date range: 2026-02-03 00:00:00 to 2026-02-26 00:00:00\n",
      "\n",
      "Processing WBD...\n",
      "  ‚úì Successfully combined data\n",
      "  OHLCV shape: (17, 5)\n",
      "  Features shape: (17, 13)\n",
      "  Combined shape: (17, 18)\n",
      "  Date range: 2026-02-03 00:00:00 to 2026-02-26 00:00:00\n",
      "\n",
      "Processing WWD...\n",
      "  ‚úì Successfully combined data\n",
      "  OHLCV shape: (17, 5)\n",
      "  Features shape: (17, 13)\n",
      "  Combined shape: (17, 18)\n",
      "  Date range: 2026-02-03 00:00:00 to 2026-02-26 00:00:00\n",
      "\n",
      "Processing JNJ...\n",
      "  ‚úì Successfully combined data\n",
      "  OHLCV shape: (17, 5)\n",
      "  Features shape: (17, 13)\n",
      "  Combined shape: (17, 18)\n",
      "  Date range: 2026-02-03 00:00:00 to 2026-02-26 00:00:00\n",
      "\n",
      "Processing GDX...\n",
      "  ‚úì Successfully combined data\n",
      "  OHLCV shape: (17, 5)\n",
      "  Features shape: (17, 13)\n",
      "  Combined shape: (17, 18)\n",
      "  Date range: 2026-02-03 00:00:00 to 2026-02-26 00:00:00\n",
      "\n",
      "Processing SPY...\n",
      "  ‚úì Successfully combined data\n",
      "  OHLCV shape: (17, 5)\n",
      "  Features shape: (17, 13)\n",
      "  Combined shape: (17, 18)\n",
      "  Date range: 2026-02-03 00:00:00 to 2026-02-26 00:00:00\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "Total tickers processed: 11\n",
      "Tickers with combined data: 11\n",
      "\n",
      "Ticker details:\n",
      "  IAG: (17, 18) - 2026-02-03 00:00:00 to 2026-02-26 00:00:00\n",
      "    Columns: 18\n",
      "  AU: (17, 18) - 2026-02-03 00:00:00 to 2026-02-26 00:00:00\n",
      "    Columns: 18\n",
      "  BUD: (17, 18) - 2026-02-03 00:00:00 to 2026-02-26 00:00:00\n",
      "    Columns: 18\n",
      "  CAT: (17, 18) - 2026-02-03 00:00:00 to 2026-02-26 00:00:00\n",
      "    Columns: 18\n",
      "  EWY: (17, 18) - 2026-02-03 00:00:00 to 2026-02-26 00:00:00\n",
      "    Columns: 18\n",
      "  NEM: (17, 18) - 2026-02-03 00:00:00 to 2026-02-26 00:00:00\n",
      "    Columns: 18\n",
      "  WBD: (17, 18) - 2026-02-03 00:00:00 to 2026-02-26 00:00:00\n",
      "    Columns: 18\n",
      "  WWD: (17, 18) - 2026-02-03 00:00:00 to 2026-02-26 00:00:00\n",
      "    Columns: 18\n",
      "  JNJ: (17, 18) - 2026-02-03 00:00:00 to 2026-02-26 00:00:00\n",
      "    Columns: 18\n",
      "  GDX: (17, 18) - 2026-02-03 00:00:00 to 2026-02-26 00:00:00\n",
      "    Columns: 18\n",
      "  SPY: (17, 18) - 2026-02-03 00:00:00 to 2026-02-26 00:00:00\n",
      "    Columns: 18\n",
      "IAG:\n",
      "              Adj Open    Adj High     Adj Low   Adj Close    Volume        ATR       ATRP        TRP         RSI     Mom_21  Consistency      IR_63    Beta_63       DD_21      Ret_1d  RollingStalePct   RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                                                            \n",
      "2026-02-03 19.30000000 19.56000000 18.66000000 19.56000000  12691000 1.20122277 0.06141221 0.07004090 55.66410609 0.20591862   0.60000000 0.22136666 1.09522313 -0.11211984  0.07531611       0.00000000 108162984.50000000           0.00000000\n",
      "2026-02-04 20.11000000 20.11000000 18.45000000 19.20000000  11592200 1.23399257 0.06427045 0.08645833 53.59112258 0.17647059   0.40000000 0.21817169 1.13740579 -0.12846119 -0.01840491       0.00000000 109000179.50000000           0.00000000\n",
      "2026-02-05 18.34000000 19.00000000 17.88000000 17.98000000   7042200 1.24013596 0.06897308 0.07341491 47.17887604 0.06833036   0.40000000 0.21139715 1.19820403 -0.18384022 -0.06354167       0.00000000 109659196.50000000           0.00000000\n",
      "2026-02-06 18.58000000 19.36000000 18.57000000 19.12000000   7633800 1.25012625 0.06538317 0.07217573 52.85535965 0.12603062   0.60000000 0.20023065 1.30051176 -0.13209260  0.06340378       0.00000000 109921209.00000000           0.00000000\n",
      "2026-02-09 19.48000000 21.32000000 19.43000000 21.28000000   9554400 1.31797437 0.06193489 0.10338346 61.33413396 0.24882629   0.60000000 0.22419855 1.47216057 -0.03404448  0.11297071       0.00000000 110367067.50000000           0.00000000\n",
      "2026-02-10 21.12000000 21.95000000 21.10000000 21.58000000   7991100 1.28454763 0.05952491 0.03938832 62.34700116 0.25392214   0.60000000 0.21249924 1.45890007 -0.02042669  0.01409774       0.00000000 110525850.00000000           0.00000000\n",
      "2026-02-11 22.10000000 22.50000000 21.54000000 22.49000000   8847200 1.26136566 0.05608562 0.04268564 65.31504758 0.26348315   0.80000000 0.21545731 1.37086556  0.00000000  0.04216867       0.00000000 110808795.00000000           0.00000000\n",
      "2026-02-12 21.99000000 22.31000000 20.14000000 20.16000000  11402900 1.33912526 0.06642486 0.11656746 53.65323092 0.15729047   0.80000000 0.16518755 1.76357752 -0.10360160 -0.10360160       0.00000000 111338716.00000000           0.00000000\n",
      "2026-02-13 20.58000000 21.89000000 20.51000000 21.63000000   6930700 1.36704488 0.06320134 0.07998151 58.66732597 0.21448624   0.80000000 0.17029730 1.76893980 -0.03823922  0.07291667       0.00000000 111634300.00000000           0.00000000\n",
      "2026-02-17 20.66000000 21.08000000 19.77000000 20.81000000   9488200 1.40225596 0.06738376 0.08938011 55.08714822 0.18440524   0.60000000 0.16534774 1.63217970 -0.07469987 -0.03791031       0.00000000 112190316.00000000           0.00000000\n",
      "2026-02-18 21.40000000 21.98000000 20.96000000 21.27000000   7544100 1.38566625 0.06514651 0.05500705 56.68407339 0.23878858   0.60000000 0.17281475 1.64011614 -0.05424633  0.02210476       0.00000000 112938434.00000000           0.00000000\n",
      "2026-02-19 21.20000000 22.49000000 21.15000000 22.37000000   8648500 1.38240437 0.06179725 0.05990165 60.31762344 0.12808875   0.60000000 0.19396879 1.56201828 -0.00533570  0.05171603       0.00000000 113178552.50000000           0.00000000\n",
      "2026-02-20 22.43000000 23.06000000 21.49000000 22.20000000  14402200 1.39580406 0.06287406 0.07072072 59.48710875 0.15264798   0.60000000 0.18028800 1.56131651 -0.01289462 -0.00759946       0.00000000 113473769.50000000           0.00000000\n",
      "2026-02-23 22.45000000 22.95000000 22.33000000 22.76000000   8484800 1.34967520 0.05930032 0.03295255 61.37383328 0.13572854   0.60000000 0.19422128 1.46414759  0.00000000  0.02522523       0.00000000 113848553.00000000           0.00000000\n",
      "2026-02-24 22.09000000 23.13000000 21.88000000 22.94000000   6135100 1.34255554 0.05852465 0.05448997 61.98663605 0.09498807   0.80000000 0.21536786 1.16756528  0.00000000  0.00790861       0.00000000 114214593.50000000           0.00000000\n",
      "2026-02-25 23.19000000 23.36000000 22.86000000 22.99000000   5887600 1.28237300 0.05577960 0.02174859 62.16619264 0.09476190   0.80000000 0.21376652 1.16442388  0.00000000  0.00217960       0.00000000 114490979.50000000           0.00000000\n",
      "2026-02-26 22.93000000 23.98000000 22.84000000 23.82000000   7933296 1.27220350 0.05340905 0.04785894 65.11218478 0.11673699   0.80000000 0.20620793 0.80932519  0.00000000  0.03610265       0.00000000 114544879.00000000           0.00000000\n",
      "\n",
      "AU:\n",
      "               Adj Open     Adj High      Adj Low    Adj Close   Volume        ATR       ATRP        TRP         RSI     Mom_21  Consistency      IR_63    Beta_63       DD_21      Ret_1d  RollingStalePct   RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                                                               \n",
      "2026-02-03 100.14000000 102.00000000  97.58000000 100.74000000  3534300 5.97869273 0.05934775 0.07097479 53.04635390 0.17686916   0.60000000 0.18392636 1.40494126 -0.12945040  0.06209805       0.00000000 158497386.35070002           0.00000000\n",
      "2026-02-04 105.26000000 105.30000000  96.01000000 100.87000000  4091300 6.21521467 0.06161609 0.09209874 53.16698391 0.14016051   0.60000000 0.19383097 1.41568662 -0.12832700  0.00129045       0.00000000 158836355.90885001           0.00000000\n",
      "2026-02-05  97.10000000 100.69000000  96.89000000  98.59000000  3048600 6.05555648 0.06142161 0.04036921 50.70647127 0.05263720   0.60000000 0.20841332 1.30929925 -0.14802973 -0.02260335       0.00000000 158962579.50485000           0.00000000\n",
      "2026-02-06 102.56000000 105.76000000 102.13000000 103.95000000  2733000 6.13515959 0.05902029 0.06897547 55.87623574 0.12087557   0.80000000 0.20316995 1.38622289 -0.10171103  0.05436657       0.00000000 159128912.73870000           0.00000000\n",
      "2026-02-09 103.65000000 107.96000000 103.62000000 107.19000000  2368500 6.00693391 0.05604006 0.04048885 58.69615233 0.17713595   0.80000000 0.20471850 1.46921950 -0.07371241  0.03116883       0.00000000 159340458.80675000           0.00000000\n",
      "2026-02-10 107.42000000 108.69000000 106.05000000 108.61000000  1876400 5.76643863 0.05309307 0.02430715 59.90556853 0.17734417   0.80000000 0.20207856 1.45843854 -0.06144141  0.01324750       0.00000000 159638109.21474999           0.00000000\n",
      "2026-02-11 111.33000000 112.30000000 107.75000000 112.27000000  1599400 5.67955015 0.05058832 0.04052730 62.91933895 0.16233565   0.80000000 0.19582142 1.27794907 -0.02981334  0.03369855       0.00000000 160211251.92500001           0.00000000\n",
      "2026-02-12 111.37000000 113.80000000 104.67000000 104.73000000  2256200 5.92601086 0.05658370 0.08717655 53.92638521 0.07239402   0.80000000 0.14420198 1.47950052 -0.09497062 -0.06715953       0.00000000 161456835.22500002           0.00000000\n",
      "2026-02-13 106.91000000 110.18000000 105.10000000 109.82000000  1630300 5.89201008 0.05365152 0.04962666 58.26317830 0.10360768   0.80000000 0.13582704 1.47766094 -0.05098514  0.04860116       0.00000000 162505567.50000000           0.00000000\n",
      "2026-02-17 104.75000000 107.07000000 103.18000000 106.17000000  2314500 5.94543793 0.05599923 0.06254121 54.31500671 0.07732116   0.60000000 0.13612991 1.29173042 -0.08252679 -0.03323620       0.00000000 164427098.22000000           0.00000000\n",
      "2026-02-18 106.37000000 110.33000000 105.63000000 108.35000000  1846600 5.85647808 0.05405148 0.04337794 56.22308131 0.09411290   0.60000000 0.15039546 1.30121272 -0.06368821  0.02053311       0.00000000 166285658.67704999           0.00000000\n",
      "2026-02-19 105.01000000 108.19000000 104.31000000 107.63000000  1740300 5.72672965 0.05320756 0.03753600 55.40009431 0.00739423   0.40000000 0.15376809 1.26715070 -0.06991013 -0.00664513       0.00000000 166569695.89295000           0.00000000\n",
      "2026-02-20 107.27000000 114.86000000 106.74000000 114.25000000  4937000 5.89767753 0.05162081 0.07107221 61.04607888 0.12717048   0.60000000 0.15947890 1.46809116 -0.01270308  0.06150701       0.00000000 168431947.72070000           0.00000000\n",
      "2026-02-23 115.86000000 121.92000000 115.86000000 121.12000000  3385000 6.02427199 0.04973804 0.06332563 65.87414023 0.17535177   0.60000000 0.17621716 1.22010750  0.00000000  0.06013129       0.00000000 170225548.00569999           0.00000000\n",
      "2026-02-24 117.60000000 125.82000000 117.12000000 124.70000000  3017800 6.21539542 0.04984279 0.06976744 68.09342369 0.17353661   0.80000000 0.19615892 1.11407181  0.00000000  0.02955746       0.00000000 170812594.95120001           0.00000000\n",
      "2026-02-25 126.59000000 128.54000000 124.34000000 124.50000000  2228000 6.07143860 0.04876658 0.03373494 67.82804252 0.15181793   0.60000000 0.19222102 1.09787200 -0.00160385 -0.00160385       0.00000000 172930951.23710001           0.00000000\n",
      "2026-02-26 122.56000000 126.27500000 120.44000000 126.07000000  2603776 6.05455013 0.04802530 0.04628381 68.85421088 0.15195541   0.80000000 0.18490985 0.92934308  0.00000000  0.01261044       0.00000000 174598910.37680000           0.00000000\n",
      "\n",
      "BUD:\n",
      "              Adj Open    Adj High     Adj Low   Adj Close   Volume        ATR       ATRP        TRP         RSI     Mom_21  Consistency      IR_63     Beta_63       DD_21      Ret_1d  RollingStalePct   RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                                                            \n",
      "2026-02-03 72.18000000 73.72000000 72.06000000 73.53000000  2029900 1.11020227 0.01509863 0.02257582 81.17709562 0.15413593   0.80000000 0.21320331  0.09372316  0.00000000  0.01490683       0.00000000 131097966.00000000           0.00000000\n",
      "2026-02-04 74.51000000 75.15000000 74.41000000 74.48000000  2362300 1.14661639 0.01539496 0.02175081 83.08900527 0.17717718   1.00000000 0.22955995  0.07729803  0.00000000  0.01291990       0.00000000 131277849.00000000           0.00000000\n",
      "2026-02-05 74.64000000 75.73000000 74.32000000 74.99000000  3218500 1.16542951 0.01554113 0.01880251 84.02699608 0.17631373   1.00000000 0.22570730  0.09621189  0.00000000  0.00684748       0.00000000 131322168.00000000           0.00000000\n",
      "2026-02-06 75.62000000 76.30000000 75.22000000 75.81000000  4768600 1.17575597 0.01550925 0.01728004 85.42663976 0.20066519   1.00000000 0.20101170  0.11717134  0.00000000  0.01093479       0.00000000 131428176.00000000           0.00000000\n",
      "2026-02-09 75.73000000 76.04000000 75.44000000 76.04000000  3037700 1.13463054 0.01492150 0.00789058 85.80242838 0.17599753   1.00000000 0.18609269  0.11190143  0.00000000  0.00303390       0.00000000 131428176.00000000           0.00000000\n",
      "2026-02-10 75.09000000 75.86000000 74.84000000 75.72000000  2191900 1.13929979 0.01504622 0.01584786 82.61069203 0.14936248   0.80000000 0.17769375  0.11786558 -0.00420831 -0.00420831       0.00000000 131562753.45750001           0.00000000\n",
      "2026-02-11 76.59000000 77.56000000 76.04000000 77.26000000  4336400 1.18934981 0.01539412 0.02381569 85.42130750 0.15762661   0.80000000 0.21949243  0.13170201  0.00000000  0.02033809       0.00000000 131691062.45750001           0.00000000\n",
      "2026-02-12 80.06000000 81.56000000 79.65000000 80.20000000  5624500 1.41153910 0.01760024 0.05361596 89.05750072 0.18132273   0.80000000 0.23637073 -0.04334370  0.00000000  0.03805333       0.00000000 132427876.00000000           0.00000000\n",
      "2026-02-13 80.12000000 80.69000000 79.00000000 80.39000000  3192300 1.43142917 0.01780606 0.02102252 89.24420820 0.16862916   0.80000000 0.24279205 -0.04255638  0.00000000  0.00236908       0.00000000 132427876.00000000           0.00000000\n",
      "2026-02-17 79.18000000 79.57000000 78.57000000 79.29000000  2317900 1.45918423 0.01840313 0.02295371 80.66309126 0.15381257   0.60000000 0.20620961 -0.06936289 -0.01368329 -0.01368329       0.00000000 132427876.00000000           0.00000000\n",
      "2026-02-18 78.78000000 79.96000000 78.40000000 78.89000000  2346100 1.46638535 0.01858772 0.01977437 77.73598898 0.15050314   0.60000000 0.20799147 -0.08348298 -0.01865904 -0.00504477       0.00000000 133235376.00000000           0.00000000\n",
      "2026-02-19 78.28000000 78.77000000 77.87000000 78.77000000  1597300 1.43450069 0.01821126 0.01294909 76.83518742 0.14341704   0.40000000 0.23196622 -0.17476831 -0.02015176 -0.00152111       0.00000000 133235376.00000000           0.00000000\n",
      "2026-02-20 78.54000000 79.00000000 78.20000000 78.52000000  2301400 1.38917921 0.01769204 0.01018849 74.88819697 0.13369910   0.20000000 0.22754383 -0.24800851 -0.02326160 -0.00317380       0.00000000 133587648.64800000           0.00000000\n",
      "2026-02-23 78.67000000 80.27000000 78.60000000 80.00000000  2176000 1.41495212 0.01768690 0.02187500 78.38080311 0.14843526   0.20000000 0.26798574 -0.27694802 -0.00485135  0.01884870       0.00000000 133851552.64800000           0.00000000\n",
      "2026-02-24 80.15000000 80.76000000 79.79000000 80.66000000  1820900 1.38316983 0.01714815 0.01202579 79.73442554 0.15426445   0.40000000 0.25270062 -0.30603454  0.00000000  0.00825000       0.00000000 134233971.50000000           0.00000000\n",
      "2026-02-25 79.13000000 79.38000000 78.32000000 78.59000000  3502600 1.45151484 0.01846946 0.02977478 65.81572355 0.13242075   0.40000000 0.18744044 -0.45651468 -0.02566328 -0.02566328       0.00000000 134233971.50000000           0.00000000\n",
      "2026-02-26 79.17000000 79.58000000 78.78000000 79.48000000  2274302 1.41854949 0.01784788 0.01245596 68.37211503 0.13138790   0.60000000 0.22297270 -0.47396904 -0.01462931  0.01132460       0.00000000 134233971.50000000           0.00000000\n",
      "\n",
      "CAT:\n",
      "               Adj Open     Adj High      Adj Low    Adj Close   Volume         ATR       ATRP        TRP         RSI     Mom_21  Consistency      IR_63    Beta_63       DD_21      Ret_1d  RollingStalePct    RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                                                                 \n",
      "2026-02-03 694.36000000 710.03000000 691.40000000 702.89000000  3524700 19.85719382 0.02825078 0.02720198 72.70097547 0.17734455   0.80000000 0.18367079 1.77011557  0.00000000  0.01733945       0.00000000 1104155258.95799994           0.00000000\n",
      "2026-02-04 707.00000000 723.16000000 675.00000000 691.82000000  7146700 21.87882283 0.03162502 0.06961348 67.76806980 0.12552915   0.60000000 0.18642477 1.79530972 -0.01574926 -0.01574926       0.00000000 1104155258.95799994           0.00000000\n",
      "2026-02-05 681.54000000 686.50000000 665.07000000 678.31000000  2792800 22.22676406 0.03276786 0.03943625 62.21949475 0.09116911   0.40000000 0.21183964 1.71434133 -0.03496991 -0.01952820       0.00000000 1104366823.92199993           0.00000000\n",
      "2026-02-06 692.57000000 727.40000000 690.52000000 726.20000000  3359700 24.14556662 0.03324920 0.06759846 71.21612355 0.22024170   0.60000000 0.21884638 1.86802138  0.00000000  0.07060194       0.00000000 1104646948.39400005           0.00000000\n",
      "2026-02-09 724.50000000 743.50000000 721.61000000 742.12000000  2496800 23.98445472 0.03231884 0.02949658 73.47719555 0.22318534   0.60000000 0.22302833 1.93717181  0.00000000  0.02192234       0.00000000 1109627201.10400009           0.00000000\n",
      "2026-02-10 742.75000000 752.00000000 737.67000000 742.37000000  4008700 23.29485081 0.03137903 0.01930304 73.51238315 0.20479796   0.60000000 0.23929413 1.93717856  0.00000000  0.00033687       0.00000000 1119877840.06449986           0.00000000\n",
      "2026-02-11 758.68000000 775.54000000 756.10000000 775.00000000  3926300 24.00021861 0.03096802 0.04280000 77.67546018 0.23348719   0.80000000 0.27077509 2.02404400  0.00000000  0.04395382       0.00000000 1125273881.30250001           0.00000000\n",
      "2026-02-12 776.69000000 789.81000000 756.01000000 758.29000000  4893400 24.70020300 0.03257356 0.04457398 71.47965087 0.19407474   0.80000000 0.27213535 2.01019524 -0.02156129 -0.02156129       0.00000000 1131567618.81299996           0.00000000\n",
      "2026-02-13 765.00000000 784.00000000 747.42000000 774.20000000  3232800 25.54875993 0.03300021 0.04724877 73.63593045 0.21489065   0.80000000 0.28113351 2.01255560 -0.00103226  0.02098142       0.00000000 1139508442.81699991           0.00000000\n",
      "2026-02-17 765.00000000 774.42000000 750.00000000 764.76000000  3450300 25.46813422 0.03330213 0.03193159 70.24251686 0.18444590   0.60000000 0.28537075 1.97519551 -0.01321290 -0.01219323       0.00000000 1139508442.81699991           0.00000000\n",
      "2026-02-18 765.11000000 772.70000000 750.38000000 751.97000000  2563700 25.24326749 0.03356951 0.02968204 65.81695863 0.16515851   0.40000000 0.26050342 1.92976192 -0.02971613 -0.01672420       0.00000000 1142437045.17950010           0.00000000\n",
      "2026-02-19 752.00000000 762.00000000 744.15000000 760.53000000  2908000 24.71517695 0.03249731 0.02347047 67.30179897 0.20910970   0.40000000 0.26719963 1.94893573 -0.01867097  0.01138343       0.00000000 1144169304.30599976           0.00000000\n",
      "2026-02-20 755.00000000 771.97000000 752.11000000 759.74000000  2095100 24.36837860 0.03207463 0.02614052 67.01248939 0.17719793   0.40000000 0.25994763 1.91628924 -0.01969032 -0.00103875       0.00000000 1148866975.07850003           0.00000000\n",
      "2026-02-23 758.95000000 767.98000000 752.78000000 756.47000000  2289600 23.71349441 0.03134757 0.02009333 65.75253737 0.16665381   0.20000000 0.25857621 1.87901467 -0.02390968 -0.00430410       0.00000000 1160346671.13000011           0.00000000\n",
      "2026-02-24 755.00000000 773.94000000 751.69000000 768.23000000  2615300 23.60895910 0.03073163 0.02896268 68.07711793 0.22599023   0.40000000 0.26345094 1.93699481 -0.00873548  0.01554589       0.00000000 1168482400.09999990           0.00000000\n",
      "2026-02-25 772.50000000 777.60000000 756.74000000 766.61000000  2606500 23.41260488 0.03054044 0.02721071 67.39844821 0.20551327   0.40000000 0.25493075 1.92703923 -0.01082581 -0.00210874       0.00000000 1174469179.75999975           0.00000000\n",
      "2026-02-26 770.61000000 770.61000000 728.40000000 752.93000000  3300387 24.75527596 0.03287859 0.05606099 61.79605211 0.17846019   0.20000000 0.24099692 2.02840712 -0.02847742 -0.01784480       0.00000000 1180328200.46000004           0.00000000\n",
      "\n",
      "EWY:\n",
      "               Adj Open     Adj High      Adj Low    Adj Close    Volume        ATR       ATRP        TRP         RSI     Mom_21  Consistency      IR_63    Beta_63       DD_21      Ret_1d  RollingStalePct   RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                                                                \n",
      "2026-02-03 126.11000000 126.15000000 122.57000000 124.32000000  12727800 2.93470165 0.02360603 0.04198842 74.06273564 0.21620035   0.40000000 0.24963995 1.52588464 -0.00987576  0.02803275       0.00000000 299586896.07340002           0.00000000\n",
      "2026-02-04 126.46000000 126.64000000 119.38000000 120.26000000  21545500 3.24365153 0.02697199 0.06036920 63.80926936 0.14719069   0.20000000 0.18973224 1.55400918 -0.04221090 -0.03265766       0.00000000 301278080.27869999           0.00000000\n",
      "2026-02-05 118.90000000 121.70000000 118.12000000 120.21000000  16250400 3.26767643 0.02718307 0.02978122 63.69232300 0.11708949   0.20000000 0.24835523 1.36488349 -0.04260911 -0.00041577       0.00000000 302692713.65570003           0.00000000\n",
      "2026-02-06 121.35000000 124.87000000 121.35000000 124.71000000  11990100 3.36712811 0.02699966 0.03736669 69.16900648 0.16518733   0.40000000 0.25928394 1.40275638 -0.00676967  0.03743449       0.00000000 304909136.93879998           0.00000000\n",
      "2026-02-09 123.98000000 126.41000000 123.50000000 126.05000000  10426600 3.33447610 0.02645360 0.02308608 70.59155850 0.18256872   0.60000000 0.29203471 1.33360506  0.00000000  0.01074493       0.00000000 308576605.00319999           0.00000000\n",
      "2026-02-10 125.46000000 125.56000000 123.81000000 124.45000000   7838600 3.25629924 0.02616552 0.01799920 66.63787721 0.14289650   0.40000000 0.30470586 1.34895483 -0.01269338 -0.01269338       0.00000000 312773178.93910003           0.00000000\n",
      "2026-02-11 127.68000000 130.73000000 126.33000000 130.60000000  12884200 3.47227786 0.02658712 0.04808576 72.91684153 0.19893510   0.60000000 0.31278905 1.26413272  0.00000000  0.04941744       0.00000000 316954717.24524999           0.00000000\n",
      "2026-02-12 133.33000000 134.30000000 129.61000000 130.80000000  16591800 3.55925802 0.02721145 0.03585627 73.09418697 0.21629161   0.80000000 0.33513520 1.20124766  0.00000000  0.00153139       0.00000000 319306562.26144999           0.00000000\n",
      "2026-02-13 131.69000000 134.32000000 128.33000000 133.97000000  16584300 3.73288244 0.02786357 0.04471150 75.79917211 0.22190806   0.80000000 0.34866670 1.20458765  0.00000000  0.02423547       0.00000000 320140856.46685004           0.00000000\n",
      "2026-02-17 132.32000000 132.99000000 129.65000000 130.68000000  16472200 3.77481941 0.02888598 0.03305785 68.14221317 0.17676722   0.60000000 0.31771954 1.16497013 -0.02455774 -0.02455774       0.00000000 321739707.54694998           0.00000000\n",
      "2026-02-18 131.38000000 134.14000000 130.61000000 132.93000000  12057700 3.75733231 0.02826550 0.02655533 70.34825346 0.18454821   0.80000000 0.32807741 1.17266917 -0.00776293  0.01721763       0.00000000 325386050.82980001           0.00000000\n",
      "2026-02-19 134.18000000 135.36000000 133.43000000 135.21000000  13191900 3.66252286 0.02708766 0.01797204 72.43153263 0.21843742   0.80000000 0.34750390 1.13808669  0.00000000  0.01715188       0.00000000 327565644.48319995           0.00000000\n",
      "2026-02-20 137.70000000 141.98000000 137.44000000 141.88000000  19435400 3.88448551 0.02737867 0.04771638 77.42781018 0.22669895   0.80000000 0.38154878 1.17662320  0.00000000  0.04933067       0.00000000 328718478.88845003           0.00000000\n",
      "2026-02-23 140.62000000 141.38000000 138.96000000 139.30000000  15725300 3.81559369 0.02739120 0.02096195 71.99278613 0.20096560   0.60000000 0.39059694 1.24219018 -0.01818438 -0.01818438       0.00000000 330495121.90525001           0.00000000\n",
      "2026-02-24 143.65000000 145.62000000 142.78000000 144.55000000  20212900 3.99447986 0.02763390 0.04372190 75.72665009 0.22531152   0.80000000 0.42088829 1.23387385  0.00000000  0.03768844       0.00000000 332443871.58449996           0.00000000\n",
      "2026-02-25 149.05000000 149.74000000 148.18000000 148.89000000  16893200 4.07987415 0.02740194 0.03485795 78.30193190 0.26909308   0.80000000 0.44105397 1.30074016  0.00000000  0.03002421       0.00000000 334045261.68919998           0.00000000\n",
      "2026-02-26 153.30500000 154.22000000 146.60000000 150.41000000  41834404 4.33274028 0.02880620 0.05066153 79.13679379 0.22583537   0.80000000 0.45807822 1.35249443  0.00000000  0.01020888       0.00000000 334703873.13584995           0.00000000\n",
      "\n",
      "NEM:\n",
      "               Adj Open     Adj High      Adj Low    Adj Close    Volume        ATR       ATRP        TRP         RSI      Mom_21  Consistency      IR_63    Beta_63       DD_21      Ret_1d  RollingStalePct   RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                                                                 \n",
      "2026-02-03 118.79000000 119.00000000 114.76000000 117.14000000  11195900 5.42566641 0.04631779 0.05250128 54.07211764  0.15728117   0.60000000 0.21869039 1.55665569 -0.11223948  0.03801506       0.00000000 706525837.21079993           0.00000000\n",
      "2026-02-04 120.77000000 120.77000000 113.51000000 116.85000000  10944800 5.55669024 0.04755405 0.06213094 53.68502917  0.12865836   0.40000000 0.21651667 1.55856215 -0.11443729 -0.00247567       0.00000000 707831726.05449998           0.00000000\n",
      "2026-02-05 113.32000000 115.33000000 108.05000000 108.53000000  15327100 5.78835522 0.05333415 0.08108357 43.96158336 -0.00613553   0.40000000 0.18891103 1.70605785 -0.17749147 -0.07120240       0.00000000 708692869.58109999           0.00000000\n",
      "2026-02-06 110.35000000 115.48000000 110.35000000 115.32000000  10814900 5.87132985 0.05091337 0.06026708 51.65699382  0.06767892   0.60000000 0.19417453 1.81398376 -0.12603259  0.06256335       0.00000000 716147458.94064999           0.00000000\n",
      "2026-02-09 116.66000000 121.11000000 116.24000000 120.73000000   7439100 5.86552057 0.04858379 0.04795825 56.75283360  0.12947890   0.60000000 0.20319783 1.93531840 -0.08503221  0.04691294       0.00000000 727433337.69075000           0.00000000\n",
      "2026-02-10 119.81000000 121.73000000 119.62000000 121.53000000   6718900 5.59726910 0.04605669 0.01736197 57.46681585  0.11505643   0.60000000 0.20310725 1.92915520 -0.07896931  0.00662636       0.00000000 732792345.43935001           0.00000000\n",
      "2026-02-11 125.00000000 125.20000000 121.40000000 124.60000000   6654700 5.46889274 0.04389160 0.03049759 60.18342247  0.10304533   0.80000000 0.19557892 1.81890827 -0.05570292  0.02526125       0.00000000 736460485.06655002           0.00000000\n",
      "2026-02-12 122.90000000 125.53000000 118.04000000 118.12000000   9289000 5.61325754 0.04752165 0.06341009 52.55347404  0.03044578   0.80000000 0.16408577 1.94244402 -0.10481243 -0.05200642       0.00000000 739128132.95840001           0.00000000\n",
      "2026-02-13 119.84000000 126.39000000 118.95000000 125.80000000   7623400 5.80302486 0.04612897 0.06573927 59.16167890  0.10205869   0.80000000 0.17599068 1.94937974 -0.04660856  0.06501863       0.00000000 741385305.31360006           0.00000000\n",
      "2026-02-17 121.70000000 123.64000000 118.10000000 122.31000000   8196400 5.93852309 0.04855305 0.06295479 55.38654595  0.07092199   0.60000000 0.16991649 1.88796683 -0.07305798 -0.02774245       0.00000000 744082301.34080005           0.00000000\n",
      "2026-02-18 125.11000000 127.34000000 123.45000000 124.69000000   7851500 5.87362858 0.04710585 0.04034004 57.38366552  0.09262180   0.60000000 0.18948611 1.89057808 -0.05502084  0.01945875       0.00000000 746110738.81970000           0.00000000\n",
      "2026-02-19 122.01000000 126.18000000 122.00000000 125.40000000   7854500 5.75265511 0.04587444 0.03333333 57.98786321  0.05431310   0.60000000 0.19322251 1.89815213 -0.04964002  0.00569412       0.00000000 750984525.79250002           0.00000000\n",
      "2026-02-20 122.35000000 125.63000000 118.67000000 122.13000000  12525400 5.83889403 0.04780884 0.05698845 54.17807667  0.02707930   0.60000000 0.17211778 1.81893660 -0.07442213 -0.02607656       0.00000000 755426428.46424997           0.00000000\n",
      "2026-02-23 123.36000000 126.23000000 122.00000000 124.25000000   9372000 5.72397303 0.04606819 0.03404427 56.18777839  0.02103706   0.60000000 0.18215778 1.71619021 -0.05835544  0.01735855       0.00000000 760852635.85249996           0.00000000\n",
      "2026-02-24 120.52000000 124.76000000 119.12000000 124.09000000   9641800 5.71797496 0.04607926 0.04545088 55.98819539 -0.00176977   0.60000000 0.20700029 1.45143748 -0.05956802 -0.00128773       0.00000000 760852635.85249996           0.00000000\n",
      "2026-02-25 124.95000000 126.97000000 123.16000000 124.85000000   7785600 5.58169103 0.04470718 0.03051662 56.77362774 -0.00849746   0.60000000 0.20134659 1.42766931 -0.05380826  0.00612459       0.00000000 760852635.85249996           0.00000000\n",
      "2026-02-26 123.74000000 127.93000000 122.65000000 127.47000000   5399682 5.56014167 0.04361922 0.04142151 59.45959129  0.00370079   0.60000000 0.20358046 1.32940090 -0.03395225  0.02098518       0.00000000 760852635.85249996           0.00000000\n",
      "\n",
      "WBD:\n",
      "              Adj Open    Adj High     Adj Low   Adj Close    Volume        ATR       ATRP        TRP         RSI      Mom_21  Consistency      IR_63    Beta_63       DD_21      Ret_1d  RollingStalePct   RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                                                             \n",
      "2026-02-03 27.51000000 27.62000000 27.02000000 27.19000000  17516100 0.54254864 0.01995398 0.02206694 39.43085690 -0.04629954   0.00000000 0.15090775 0.44594480 -0.05884389 -0.01199128       0.00000000 558134807.50000000           0.00000000\n",
      "2026-02-04 27.20000000 27.26000000 26.86000000 27.03000000  27564700 0.53236660 0.01969540 0.01479837 37.66968943 -0.05257624   0.00000000 0.15771002 0.46247419 -0.06438214 -0.00588452       0.00000000 560747712.00000000           0.00000000\n",
      "2026-02-05 27.06000000 27.12000000 26.61000000 26.76000000  29457400 0.53076898 0.01983442 0.01905830 34.84161291 -0.06006322   0.00000000 0.14053323 0.55106432 -0.07372793 -0.00998890       0.00000000 569489351.50000000           0.00000000\n",
      "2026-02-06 26.90000000 27.48000000 26.85000000 27.36000000  33623700 0.54428548 0.01989348 0.02631579 44.76549804 -0.04302204   0.20000000 0.14022784 0.59637961 -0.05295950  0.02242152       0.00000000 583639267.00000000           0.00000000\n",
      "2026-02-09 27.34000000 27.42000000 27.05000000 27.21000000  16493500 0.53183652 0.01954563 0.01359794 43.00219592 -0.03919492   0.20000000 0.13492803 0.54560337 -0.05815161 -0.00548246       0.00000000 583639267.00000000           0.00000000\n",
      "2026-02-10 27.68000000 27.97000000 27.45000000 27.80000000  35199000 0.54813391 0.01971705 0.02733813 51.15245615 -0.03772932   0.40000000 0.14515539 0.52617554 -0.03672904  0.02168320       0.00000000 591377616.00000000           0.00000000\n",
      "2026-02-11 28.01000000 28.28000000 27.83000000 27.99000000  22494800 0.54326720 0.01940933 0.01714898 53.46038497 -0.01443662   0.60000000 0.15240654 0.51463819 -0.03014553  0.00683453       0.00000000 594442308.00000000           0.00000000\n",
      "2026-02-12 28.13000000 28.18000000 27.61000000 28.11000000  24763600 0.54517669 0.01939440 0.02027748 54.90941659 -0.02598753   0.80000000 0.16673920 0.47539885 -0.01816277  0.00428725       0.00000000 596359263.00000000           0.00000000\n",
      "2026-02-13 28.07000000 28.18000000 27.90000000 27.99000000  13200900 0.52623550 0.01880084 0.01000357 53.12800900 -0.02235417   0.60000000 0.19987517 0.47995078 -0.02064381 -0.00426894       0.00000000 596359263.00000000           0.00000000\n",
      "2026-02-17 28.69000000 29.01000000 28.57000000 28.75000000  31951400 0.56150439 0.01953059 0.03547826 61.62046345  0.00912601   0.80000000 0.20751798 0.49868779  0.00000000  0.02715255       0.00000000 596787625.50000000           0.00000000\n",
      "2026-02-18 28.86000000 28.97000000 28.59000000 28.79000000  19347600 0.54853979 0.01905314 0.01319903 62.01059706  0.00734780   0.80000000 0.17636871 0.49750650  0.00000000  0.00139130       0.00000000 596787625.50000000           0.00000000\n",
      "2026-02-19 28.59000000 29.19000000 28.51000000 28.53000000  23920900 0.55792981 0.01955590 0.02383456 57.89128337  0.01026912   0.60000000 0.17353321 0.47303944 -0.00903091 -0.00903091       0.00000000 597155134.50000000           0.00000000\n",
      "2026-02-20 28.69000000 28.78000000 28.52000000 28.75000000  19879100 0.53664911 0.01866606 0.00904348 60.29476465  0.00771118   0.60000000 0.13883615 0.59837478 -0.00138937  0.00771118       0.00000000 597155134.50000000           0.00000000\n",
      "2026-02-23 28.82000000 28.99000000 28.74000000 28.92000000  13040200 0.51617417 0.01784835 0.00864454 62.09518551  0.01974612   0.80000000 0.18320251 0.59892212  0.00000000  0.00591304       0.00000000 597155134.50000000           0.00000000\n",
      "2026-02-24 29.00000000 29.20000000 28.93000000 29.15000000  27447500 0.49930459 0.01712880 0.00960549 64.44427418  0.01994402   0.80000000 0.17824107 0.58129036  0.00000000  0.00795297       0.00000000 598446125.00000000           0.00000000\n",
      "2026-02-25 29.04000000 29.10000000 28.85000000 28.90000000  22322700 0.48506854 0.01678438 0.01038062 60.08543262  0.02337110   0.60000000 0.15860126 0.52811392 -0.00857633 -0.00857633       0.00000000 602511136.50000000           0.00000000\n",
      "2026-02-26 28.77500000 29.00500000 28.76000000 28.80000000  15848836 0.46792079 0.01624725 0.00850694 58.38434063  0.02600641   0.60000000 0.19067880 0.65773954 -0.01200686 -0.00346021       0.00000000 602511136.50000000           0.00000000\n",
      "\n",
      "WWD:\n",
      "               Adj Open     Adj High      Adj Low    Adj Close   Volume         ATR       ATRP        TRP         RSI     Mom_21  Consistency      IR_63    Beta_63       DD_21      Ret_1d  RollingStalePct   RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                                                                \n",
      "2026-02-03 372.70600000 384.34600000 363.47300000 370.86700000  2400157 12.69351882 0.03422661 0.15467270 74.64895647 0.19401106   0.40000000 0.21160779 1.19814305  0.00000000  0.13420881       0.00000000 115385703.25950000           0.00000000\n",
      "2026-02-04 372.69600000 383.76700000 362.97400000 373.00600000  1287650 13.27205319 0.03558134 0.05574441 75.20218163 0.15902643   0.60000000 0.22009663 1.19408278  0.00000000  0.00576757       0.00000000 115385703.25950000           0.00000000\n",
      "2026-02-05 368.26900000 381.23900000 364.69200000 376.50300000  1079380 13.50597796 0.03587217 0.04394918 76.11970126 0.15596677   0.80000000 0.23176635 1.11356515  0.00000000  0.00937518       0.00000000 115385703.25950000           0.00000000\n",
      "2026-02-06 382.26800000 392.34000000 382.26800000 388.18300000   939466 13.67247954 0.03522174 0.04079777 78.92455681 0.20431425   1.00000000 0.23293121 1.12885091  0.00000000  0.03102233       0.00000000 115945641.71200001           0.00000000\n",
      "2026-02-09 396.54600000 402.98100000 390.09200000 392.46000000   844288 13.75287386 0.03504274 0.03770575 79.85752055 0.23039784   1.00000000 0.22657528 1.16939245  0.00000000  0.01101800       0.00000000 115945641.71200001           0.00000000\n",
      "2026-02-10 392.19000000 399.67400000 387.05400000 391.21100000   714482 13.67195429 0.03494778 0.03225881 78.76102399 0.21597193   0.80000000 0.22178645 1.17481553 -0.00318249 -0.00318249       0.00000000 115945641.71200001           0.00000000\n",
      "2026-02-11 391.40100000 396.90600000 386.68400000 389.29200000   797450 13.42552899 0.03448704 0.02625792 77.01140407 0.19497566   0.60000000 0.21649348 1.19876376 -0.00807216 -0.00490528       0.00000000 117536930.17900001           0.00000000\n",
      "2026-02-12 392.66000000 399.08400000 376.36300000 380.12000000   738202 14.08949120 0.03706590 0.05977323 69.10930223 0.15250393   0.40000000 0.21835425 1.25748167 -0.03144269 -0.02356072       0.00000000 119370107.00700000           0.00000000\n",
      "2026-02-13 380.69900000 384.68600000 375.80300000 379.08100000   662440 13.71759897 0.03618646 0.02343299 68.25490927 0.14532902   0.20000000 0.20607601 1.25396139 -0.03409010 -0.00273335       0.00000000 120381950.01749998           0.00000000\n",
      "2026-02-17 376.26300000 387.51400000 372.45600000 386.80400000   624709 13.81334190 0.03571148 0.03892928 71.11361539 0.15214193   0.20000000 0.23219532 1.13371510 -0.01441166  0.02037295       0.00000000 120777059.64750001           0.00000000\n",
      "2026-02-18 388.06300000 398.30500000 388.06300000 392.06000000   772630 13.64817463 0.03481144 0.02933480 72.90208985 0.17810738   0.40000000 0.24441893 1.13322087 -0.00101921  0.01358828       0.00000000 121153360.79700001           0.00000000\n",
      "2026-02-19 391.96000000 394.50000000 388.17000000 390.92000000   429800 13.12544787 0.03357579 0.01619257 71.86282081 0.19204006   0.40000000 0.23990229 1.14542540 -0.00392397 -0.00290772       0.00000000 122089406.59400001           0.00000000\n",
      "2026-02-20 390.92000000 397.02000000 390.74000000 394.03000000   276400 12.63648730 0.03206986 0.01593787 72.99389273 0.17569656   0.60000000 0.24045032 1.11636252  0.00000000  0.00795559       0.00000000 122089406.59400001           0.00000000\n",
      "2026-02-23 393.51000000 395.83000000 388.89000000 392.77000000   412500 12.22959535 0.03113679 0.01766937 71.73572086 0.18045370   0.60000000 0.24287327 1.11390675 -0.00319773 -0.00319773       0.00000000 123093240.34000000           0.00000000\n",
      "2026-02-24 393.04000000 396.72000000 389.05000000 394.76000000   299800 11.90390997 0.03015480 0.01942953 72.54074592 0.20812969   0.60000000 0.23365499 1.13921450  0.00000000  0.00506658       0.00000000 123093240.34000000           0.00000000\n",
      "2026-02-25 399.08000000 399.08000000 389.56000000 393.58000000   504200 11.73363069 0.02981257 0.02418822 71.24494244 0.18938684   0.40000000 0.22249244 1.09655369 -0.00298916 -0.00298916       0.00000000 123554165.09099999           0.00000000\n",
      "2026-02-26 393.02000000 394.96500000 383.06000000 387.74000000   561756 11.74587135 0.03029316 0.03070356 65.05152794 0.17796458   0.40000000 0.23039603 1.26664955 -0.01778296 -0.01483815       0.00000000 123766305.85600001           0.00000000\n",
      "\n",
      "JNJ:\n",
      "               Adj Open     Adj High      Adj Low    Adj Close    Volume        ATR       ATRP        TRP         RSI     Mom_21  Consistency      IR_63     Beta_63       DD_21      Ret_1d  RollingStalePct    RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                                                                  \n",
      "2026-02-03 230.27600000 233.95600000 229.26100000 231.86700000   9396287 3.83426179 0.01653647 0.02024868 82.26677142 0.12418183   0.60000000 0.25438836  0.00130500  0.00000000  0.01018168       0.00000000 1438628696.53100014           0.00000000\n",
      "2026-02-04 233.75700000 234.58300000 231.70800000 233.23000000   8687338 3.76574309 0.01614605 0.01232689 83.24803456 0.14761600   0.60000000 0.29170577  0.00694797  0.00000000  0.00587837       0.00000000 1441964207.15549994           0.00000000\n",
      "2026-02-05 233.75700000 238.31300000 233.74700000 236.53300000  10322083 3.85983287 0.01631837 0.02148960 85.36191041 0.16114321   0.80000000 0.30031136 -0.03550739  0.00000000  0.01416199       0.00000000 1441964207.15549994           0.00000000\n",
      "2026-02-06 237.69600000 239.66600000 236.72200000 238.72100000   8317985 3.80791623 0.01595132 0.01312411 86.57080163 0.15663322   1.00000000 0.29730918  0.00285575  0.00000000  0.00925029       0.00000000 1445500150.76399994           0.00000000\n",
      "2026-02-09 238.98000000 239.46700000 235.78700000 237.37800000   9428357 3.79877936 0.01600308 0.01550270 82.08950357 0.15985381   0.80000000 0.26419187 -0.00560813 -0.00562581 -0.00562581       0.00000000 1448627367.17400002           0.00000000\n",
      "2026-02-10 238.71100000 239.22800000 236.62200000 237.09000000   6759041 3.71358083 0.01566317 0.01099161 81.11975272 0.16615595   0.60000000 0.27029290 -0.00004475 -0.00683224 -0.00121325       0.00000000 1451363229.25500011           0.00000000\n",
      "2026-02-11 238.07400000 239.98400000 236.14500000 239.58600000   6840070 3.72253934 0.01553738 0.01602347 82.99471770 0.14848210   0.60000000 0.29114364 -0.02831529  0.00000000  0.01052765       0.00000000 1458617742.89150000           0.00000000\n",
      "2026-02-12 239.20800000 245.04700000 238.41300000 243.25700000  10308813 3.93050082 0.01615781 0.02727157 85.30598627 0.14463109   0.60000000 0.29340460 -0.09200433  0.00000000  0.01532226       0.00000000 1469608310.72850013           0.00000000\n",
      "2026-02-13 243.29700000 243.65500000 241.32700000 242.16300000  13339037 3.81603648 0.01575813 0.00961336 81.74047869 0.11393599   0.40000000 0.28314917 -0.09344631 -0.00449730 -0.00449730       0.00000000 1483843256.59299994           0.00000000\n",
      "2026-02-17 242.83900000 243.19700000 240.59100000 242.04300000  12770530 3.72960530 0.01540885 0.01076668 81.33888334 0.10820983   0.40000000 0.25839366 -0.09958306 -0.00499061 -0.00049553       0.00000000 1483843256.59299994           0.00000000\n",
      "2026-02-18 241.95400000 243.77400000 241.53600000 243.69500000   8172918 3.62306206 0.01486720 0.00918361 82.60585815 0.12041618   0.60000000 0.25607404 -0.09443090  0.00000000  0.00682523       0.00000000 1493531685.52500010           0.00000000\n",
      "2026-02-19 243.32600000 245.65400000 242.97800000 245.60400000   7594057 3.55541477 0.01447621 0.01089559 83.96100993 0.13152366   0.60000000 0.24120374 -0.05472425  0.00000000  0.00783356       0.00000000 1493531685.52500010           0.00000000\n",
      "2026-02-20 245.16700000 245.57500000 239.00900000 241.20800000  13637917 3.77252800 0.01564014 0.02734155 70.36587655 0.11229059   0.40000000 0.18916499 -0.10395836 -0.01789873 -0.01789873       0.00000000 1494553500.65399981           0.00000000\n",
      "2026-02-23 242.34200000 245.50500000 241.31700000 244.54000000   9673855 3.80999029 0.01558023 0.01757177 73.82541116 0.12517542   0.60000000 0.20384709 -0.14534549 -0.00433218  0.01381380       0.00000000 1497728582.32200003           0.00000000\n",
      "2026-02-24 245.35000000 247.25000000 244.54000000 246.28000000   7246300 3.73141955 0.01515113 0.01100374 75.43798122 0.12468946   0.80000000 0.18403010 -0.14985494  0.00000000  0.00711540       0.00000000 1497728582.32200003           0.00000000\n",
      "2026-02-25 244.86000000 247.25000000 243.72000000 245.17000000   7698200 3.71703244 0.01516104 0.01439817 72.37471999 0.11279554   0.60000000 0.17409690 -0.17322211 -0.00450707 -0.00450707       0.00000000 1497728582.32200003           0.00000000\n",
      "2026-02-26 245.11000000 245.47000000 242.02000000 243.47000000   5508368 3.69795870 0.01518856 0.01417012 67.83177201 0.09055645   0.40000000 0.17769672 -0.19789099 -0.01140978 -0.00693396       0.00000000 1494553500.65399981           0.00000000\n",
      "\n",
      "GDX:\n",
      "               Adj Open     Adj High      Adj Low    Adj Close    Volume        ATR       ATRP        TRP         RSI     Mom_21  Consistency      IR_63    Beta_63       DD_21      Ret_1d  RollingStalePct    RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                                                                 \n",
      "2026-02-03  99.79000000  99.99000000  95.66000000  98.22000000  43633800 4.88948539 0.04978095 0.05905111 51.70252705 0.14568996   0.40000000 0.18631329 1.38789275 -0.12428673  0.04278586       0.00000000 1274276947.85444999           0.00000000\n",
      "2026-02-04 101.01000000 101.12000000  94.94000000  98.70000000  30256800 4.98166500 0.05047280 0.06261398 52.35571587 0.11588468   0.40000000 0.19941481 1.38777276 -0.12000713  0.00488699       0.00000000 1288320996.10085011           0.00000000\n",
      "2026-02-05  94.54000000  97.20000000  92.28000000  92.44000000  39586600 5.08440321 0.05500220 0.06945045 43.99836467 0.00325591   0.40000000 0.18433149 1.47241740 -0.17582026 -0.06342452       0.00000000 1297940537.50880003           0.00000000\n",
      "2026-02-06  95.13000000  97.93000000  94.98000000  97.39000000  24807700 5.11337441 0.05250410 0.05637129 50.69981291 0.06951461   0.60000000 0.18561445 1.55634528 -0.13168688  0.05354825       0.00000000 1301112140.37039995           0.00000000\n",
      "2026-02-09  98.55000000 103.09000000  98.51000000 102.89000000  27057100 5.15527624 0.05010474 0.05539897 56.87486468 0.12398951   0.80000000 0.20347228 1.65106651 -0.08264979  0.05647397       0.00000000 1304557764.73239994           0.00000000\n",
      "2026-02-10 102.27000000 103.80000000 101.85000000 103.01000000  15407600 4.92632794 0.04782378 0.01893020 57.00141098 0.11289974   0.80000000 0.19295198 1.64892052 -0.08157989  0.00116629       0.00000000 1307278787.16170001           0.00000000\n",
      "2026-02-11 105.49000000 106.47000000 102.49000000 105.97000000  22624300 4.85873309 0.04585008 0.03755780 60.11076296 0.10708316   0.80000000 0.19172054 1.56866182 -0.05518902  0.02873507       0.00000000 1308367241.31130004           0.00000000\n",
      "2026-02-12 104.82000000 105.79000000  98.13000000  98.28000000  43435500 5.07168072 0.05160440 0.07977208 49.99571826 0.01876231   0.80000000 0.15110223 1.80552490 -0.12375178 -0.07256771       0.00000000 1311949350.94775009           0.00000000\n",
      "2026-02-13 100.92000000 104.14000000  99.53000000 103.94000000  31928300 5.12798924 0.04933605 0.05637868 55.88038717 0.07309519   0.80000000 0.16115564 1.81129961 -0.07328816  0.05759056       0.00000000 1316086606.39065003           0.00000000\n",
      "2026-02-17  99.86000000 101.19000000  97.41000000 100.25000000  26743000 5.22813287 0.05215095 0.06513716 51.61566281 0.03233447   0.60000000 0.14585860 1.78030168 -0.10618759 -0.03550125       0.00000000 1320520892.10555005           0.00000000\n",
      "2026-02-18 101.82000000 103.69000000 101.29000000 102.56000000  18924100 5.10040909 0.04973098 0.03354134 53.98331128 0.05471000   0.60000000 0.16099751 1.79152701 -0.08559201  0.02304239       0.00000000 1327068792.45225000           0.00000000\n",
      "2026-02-19 102.01000000 104.30000000 101.11000000 104.24000000  18466500 4.96395130 0.04762041 0.03060246 55.68185220 0.01420510   0.60000000 0.17401182 1.76311968 -0.07061341  0.01638066       0.00000000 1343881776.06360006           0.00000000\n",
      "2026-02-20 104.33000000 106.39000000 102.03000000 106.26000000  23441000 4.92081192 0.04630917 0.04103143 57.70343937 0.04906704   0.80000000 0.17143374 1.82179572 -0.05260342  0.01937836       0.00000000 1366553809.55935001           0.00000000\n",
      "2026-02-23 107.78000000 110.54000000 107.62000000 110.29000000  26609300 4.87503964 0.04420201 0.03880678 61.47872556 0.04868308   0.80000000 0.19004921 1.65111394 -0.01667261  0.03792584       0.00000000 1375625911.71535015           0.00000000\n",
      "2026-02-24 107.00000000 111.50000000 106.47000000 110.70000000  15635700 4.88610824 0.04413829 0.04543812 61.85178883 0.03438610   1.00000000 0.20512665 1.48692179 -0.01301712  0.00371747       0.00000000 1386059065.44990015           0.00000000\n",
      "2026-02-25 112.18000000 113.16000000 110.87000000 111.16000000  14632600 4.71281479 0.04239668 0.02213026 62.29301606 0.03423893   1.00000000 0.20316423 1.48541107 -0.00891583  0.00415537       0.00000000 1397715795.72485018           0.00000000\n",
      "2026-02-26 110.40000000 113.91500000 109.13000000 113.89000000  18252041 4.71797088 0.04142568 0.04201422 64.88854820 0.04208985   1.00000000 0.19758215 1.27409477  0.00000000  0.02455919       0.00000000 1410914062.26574993           0.00000000\n",
      "\n",
      "SPY:\n",
      "               Adj Open     Adj High      Adj Low    Adj Close     Volume        ATR       ATRP        TRP         RSI      Mom_21  Consistency      IR_63    Beta_63       DD_21      Ret_1d  RollingStalePct     RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                                                                    \n",
      "2026-02-03 696.21000000 696.96000000 684.03000000 689.53000000  107904600 6.97134078 0.01011028 0.01875190 50.44243826  0.00930954   0.20000000 0.00000000 1.00000000 -0.00856950 -0.00845544       0.00000000 43956891577.11999512           0.00000000\n",
      "2026-02-04 690.35000000 691.45000000 681.76000000 686.19000000  105204600 7.16553073 0.01044249 0.01412145 46.78048900 -0.00222474   0.20000000 0.00000000 1.00000000 -0.01337187 -0.00484388       0.00000000 44049811064.61650085           0.00000000\n",
      "2026-02-05 680.94000000 683.69000000 675.79000000 677.62000000  113610800 7.39656425 0.01091550 0.01534784 38.96419332 -0.02051141   0.20000000 0.00000000 1.00000000 -0.02569411 -0.01248925       0.00000000 44102835008.88049316           0.00000000\n",
      "2026-02-06 681.46000000 692.31000000 680.85000000 690.62000000   89127600 7.91752394 0.01146437 0.02127074 52.05169370  0.00150816   0.40000000 0.00000000 1.00000000 -0.00700226  0.01918479       0.00000000 44138530969.53399658           0.00000000\n",
      "2026-02-09 689.42000000 695.87000000 688.34000000 693.95000000   73885200 7.88984366 0.01136947 0.01085093 54.72946341  0.00643936   0.40000000 0.00000000 1.00000000 -0.00221427  0.00482175       0.00000000 44218482724.44799805           0.00000000\n",
      "2026-02-10 694.95000000 696.54000000 691.66000000 692.12000000   65185700 7.67485483 0.01108891 0.00705080 52.97844505 -0.00280951   0.40000000 0.00000000 1.00000000 -0.00484550 -0.00263708       0.00000000 44384321508.44799805           0.00000000\n",
      "2026-02-11 696.39000000 697.14000000 689.18000000 691.96000000   76353900 7.69522234 0.01112091 0.01150356 52.81932827 -0.00460326   0.40000000 0.00000000 1.00000000 -0.00507556 -0.00023117       0.00000000 44540441280.00000000           0.00000000\n",
      "2026-02-12 694.24000000 695.35000000 680.37000000 681.27000000  118829000 8.21556360 0.01205919 0.02198835 43.43329771 -0.01801750   0.40000000 0.00000000 1.00000000 -0.02044602 -0.01544887       0.00000000 44617251698.09950256           0.00000000\n",
      "2026-02-13 681.69000000 686.28000000 677.52000000 681.75000000   96267500 8.25445192 0.01210774 0.01284928 43.91522584 -0.01247175   0.40000000 0.00000000 1.00000000 -0.01975586  0.00070457       0.00000000 44630307874.65699768           0.00000000\n",
      "2026-02-17 680.14000000 684.94000000 675.78000000 682.85000000   81354700 8.31913392 0.01218296 0.01341437 45.07018255 -0.01356466   0.40000000 0.00000000 1.00000000 -0.01817424  0.00161349       0.00000000 44676101522.10499573           0.00000000\n",
      "2026-02-18 684.02000000 689.15000000 682.83000000 686.29000000   73570300 8.17633864 0.01191382 0.00920893 48.63270699 -0.00776393   0.60000000 0.00000000 1.00000000 -0.01322808  0.00503771       0.00000000 44863944733.27549744           0.00000000\n",
      "2026-02-19 683.84000000 686.18000000 681.55000000 684.48000000   58649400 7.93088588 0.01158673 0.00692496 46.90881913  0.01018330   0.60000000 0.00000000 1.00000000 -0.01583057 -0.00263737       0.00000000 44863944733.27549744           0.00000000\n",
      "2026-02-20 682.32000000 690.06000000 681.73000000 689.43000000  100034000 7.95939403 0.01154489 0.01208244 51.92748957  0.00587978   0.80000000 0.00000000 1.00000000 -0.00871328  0.00723177       0.00000000 45062725929.72799683           0.00000000\n",
      "2026-02-23 687.83000000 690.00000000 680.37000000 682.39000000   90558100 8.07872303 0.01183886 0.01411216 45.36010448 -0.00956486   0.60000000 0.00000000 1.00000000 -0.01883564 -0.01021133       0.00000000 45153244742.16500092           0.00000000\n",
      "2026-02-24 681.90000000 688.35000000 680.00000000 687.35000000   73798700 8.09809996 0.01178163 0.01214811 50.14424727 -0.00272768   0.60000000 0.00000000 1.00000000 -0.01170398  0.00726857       0.00000000 45153244742.16500092           0.00000000\n",
      "2026-02-25 690.18000000 693.68000000 690.10000000 693.15000000   56369500 7.97180710 0.01150084 0.00913222 55.09550046  0.00060630   0.60000000 0.00000000 1.00000000 -0.00336453  0.00843820       0.00000000 45153244742.16500092           0.00000000\n",
      "2026-02-26 693.28000000 693.30000000 684.36000000 689.30000000   67867592 8.04096374 0.01166541 0.01296968 51.44336682 -0.00890020   0.60000000 0.00000000 1.00000000 -0.00880044 -0.00555435       0.00000000 45214405694.44799805           0.00000000\n",
      "\n",
      "‚úì Saved IAG with header\n",
      "‚úì Appended AU\n",
      "‚úì Appended BUD\n",
      "‚úì Appended CAT\n",
      "‚úì Appended EWY\n",
      "‚úì Appended NEM\n",
      "‚úì Appended WBD\n",
      "‚úì Appended WWD\n",
      "‚úì Appended JNJ\n",
      "‚úì Appended GDX\n",
      "‚úì Appended SPY\n",
      "\n",
      "‚úì Saved all tickers to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_RLVR\\output\\all_tickers_data_stacked.csv\n"
     ]
    }
   ],
   "source": [
    "f_name_csv = OUTPUT_DIR / \"all_tickers_data_stacked.csv\"\n",
    "\n",
    "# Single call replaces your 3 cells\n",
    "file_path = export_last_run_tickers_data_to_csv(\n",
    "    analyzer=my_analyzer,\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    features_df=features_df,\n",
    "    filename=f_name_csv,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c160a5",
   "metadata": {},
   "source": [
    "### Audit features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa40b6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Takes 4 minutes to run, checks all tickers from my_analyzer\n",
    "# audit_feature_engineering_integrity(my_analyzer, df_indices=df_indices, mode=\"system\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf25a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
