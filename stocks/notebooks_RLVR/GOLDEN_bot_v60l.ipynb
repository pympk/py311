{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e766cdb4",
   "metadata": {},
   "source": [
    "v60  \n",
    "- Converted code from notebook to modular system.\n",
    "- Fixed divide by zero warning from calculate_gain\n",
    "- Added subtitle to subplots\n",
    "- Added Volatility Regime plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9617f9b0",
   "metadata": {},
   "source": [
    "v59  \n",
    "- Removed \"nest\" of if-statements in **AlphaEngine.run**\n",
    "- Use **Result Pattern** to handle errors\n",
    "- Change verify_analyzer_short and verify_analyzer_long gain calculation from simple return to logarithmic return\n",
    "- Change calculate_gain from simple return to logarithmic return\n",
    "- Remove bfill from calculate_gain to prevent backfill with future data\n",
    "- Verify macro_df calculation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bc23af",
   "metadata": {},
   "source": [
    "v57, v58  \n",
    "added marco subplotsThe macro regime framework is now fully documented with:\n",
    "- Trend (SMA200 deviation) ‚Üí Where we are in the cycle  \n",
    "- Trend Velocity (Z) ‚Üí How fast we're moving relative to normal\n",
    "- VIX-Z ‚Üí Market fear/complacency levels  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f77acd",
   "metadata": {},
   "source": [
    "v56  \n",
    "\n",
    "- De-coupled features_df and macro_df\n",
    "- generate_features and audit_feature_engineering_integrity use GLOBAL_SETTINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195e6ee3",
   "metadata": {},
   "source": [
    "v55  \n",
    "Added\n",
    "- audit_feature_engineering_integrity (check calculation in features_df)  \n",
    "\n",
    "These are the metrics in plot  \n",
    "- --- 1. LEGACY / SANITY CHECKS ---\n",
    "- \"Price Gain\": lambda obs: QuantUtils.calculate_gain(obs[\"lookback_close\"]),\n",
    "- \"Sharpe\": lambda obs: QuantUtils.calculate_sharpe(obs[\"lookback_returns\"]),\n",
    "- \"Sharpe (ATRP)\": lambda obs: QuantUtils.calculate_sharpe_vol(\n",
    "        obs[\"lookback_returns\"], obs[\"atrp\"]\n",
    "    ),\n",
    "- \"Sharpe (TRP)\": lambda obs: QuantUtils.calculate_sharpe_vol(\n",
    "        obs[\"lookback_returns\"], obs[\"trp\"]\n",
    "    ),\n",
    "- --- 2. NEW QUANT METRICS ---\n",
    "- \"Momentum (21d)\": lambda obs: obs[\"mom_21\"],\n",
    "- \"Information Ratio (IR)\": lambda obs: obs[\"ir_63\"],  # Kept this one\n",
    "- \"Consistency (WinRate)\": lambda obs: obs[\"consistency\"],\n",
    "- \"Oversold (RSI)\": lambda obs: -obs[\"rsi\"],\n",
    "- \"Dip Buyer (Drawdown)\": lambda obs: -obs[\"dd_21\"],\n",
    "- \"Low Volatility\": lambda obs: -obs[\"atrp\"],\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b219d0f",
   "metadata": {},
   "source": [
    "v54\n",
    "-  **Replaced plot_walk_forward_analyzer with create_walk_forward_analyzer**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68de115e",
   "metadata": {},
   "source": [
    "v53  \n",
    "Looking at this registry with a quant lens, the list is **comprehensive but bloated**‚Äîwe have **momentum measured five times under different names** (roc‚ÇÅ, roc‚ÇÉ, roc‚ÇÖ, roc‚ÇÅ‚ÇÄ, roc‚ÇÇ‚ÇÅ and their negative twins ‚ÄúPullback‚Äù).  \n",
    "That‚Äôs **10 slots** telling us almost the same story at slightly different lags; in a rank-based engine they will **crowd the signal space** and inflate turnover without adding IC.\n",
    "\n",
    "Duplicate / redundant cluster  \n",
    "- Momentum 1 D ‚Üî Pullback 1 D (perfect mirror)  \n",
    "- Same for 3 D, 5 D, 10 D, 21 D.  \n",
    "**Keep one side only**‚Äîmomentum is enough; the portfolio constructor can always **reverse the rank** if it wants ‚Äúoversold‚Äù.\n",
    "\n",
    "Close cousins that can be merged  \n",
    "- ‚ÄúSharpe‚Äù vs ‚ÄúSharpe (ATRP)‚Äù ‚Äì both are return / vol; keep **ATRP version** because it is regime-aware and smoother.  \n",
    "- ‚ÄúRVol‚Äù vs ‚ÄúVol_Regime‚Äù ‚Äì both capture vol expansion; keep the **longer-memory one** (Vol_Regime) and drop the intraday snapshot.\n",
    "\n",
    "Gaps that matter to a quant  \n",
    "1. **Consistency sensor**: nowhere do we ask ‚Äúhow often did the ticker close higher than it opened?‚Äù ‚Äì add **5-day win-rate** or **up-day hit-ratio**.  \n",
    "2. **Risk-adjusted intraday strength**: no **Sharpe(on-balance volume)** or **volume-momentum efficiency**; OBV_Score is raw, not risk-scaled.  \n",
    "3. **Benchmark-relative consistency**: ‚ÄúAlpha (RelStrength)‚Äù is cumulative; add **rolling information ratio vs SPY** to catch *sustained* alpha, not one gap.  \n",
    "4. **Tail flag**: no **skew** or **max-drawdown** metric; a single 20 % gap stock can poison the book.  \n",
    "5. **Macro regime overlay**: no **beta-to-SPY** or **correlation-break** sensor; mid-2022 macro swings showed that low-beta names behaved like a different asset class.\n",
    "\n",
    "Recommended minimal clean set (‚â§ 12 metrics)\n",
    "\n",
    "1. Sharpe(ATRP) ‚Äì strategic anchor  \n",
    "2. Momentum 21 D ‚Äì slow trend  \n",
    "3. Momentum 5 D ‚Äì fast trend  \n",
    "4. 5-day win-rate ‚Äì consistency  \n",
    "5. RSI(Trend) ‚Äì strength confirmation  \n",
    "6. OBV_Score ‚Äì volume conviction  \n",
    "7. Vol_Regime ‚Äì vol expansion filter  \n",
    "8. Alpha(RelStrength) 63-day IR ‚Äì benchmark consistency  \n",
    "9. Max 21-day drawdown ‚Äì tail guard  \n",
    "10. Beta-to-SPY ‚Äì macro regime tag  \n",
    "\n",
    "Drop everything else; the freed-up slots reduce collinearity, cut turnover, and leave head-room for **interaction terms** (e.g. momentum √ó consistency) that actually add orthogonal signal.\n",
    "\n",
    "\n",
    "\n",
    "Below is a single, fully-vectorised block that adds the **five gap metrics** to your existing MultiIndex OHLCV frame.  \n",
    "It never loops over tickers; everything is done with `groupby(level=0).rolling(...)` so it runs in C-speed and keeps the same index.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ----------  CONFIG  -------------------------------------------------\n",
    "LKB_RET   = 21          # look-back for return-based metrics\n",
    "LKB_CONS  = 5           # consistency window (days)\n",
    "LKB_IR    = 63          # IR window\n",
    "LKB_BETA  = 63          # beta window\n",
    "LKB_TAIL  = 21          # max-drawdown window\n",
    "BENCH     = 'SPY'       # ticker that exists in your universe\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 1.  DAILY RETURNS ----------------------------------------------------\n",
    "df['ret'] = df.groupby(level=0)['Adj Close'].pct_change()\n",
    "\n",
    "# 2.  CONSISTENCY SENSOR  (5-day win-rate) -----------------------------\n",
    "df['up']  = df['ret'].gt(0).astype(int)\n",
    "df['consistency_5d'] = (df.groupby(level=0)['up']\n",
    "                          .rolling(LKB_CONS).mean()\n",
    "                          .reset_index(level=0, drop=True))\n",
    "\n",
    "# 3.  BENCHMARK-RELATIVE CONSISTENCY  (63-day IR vs SPY) ---------------\n",
    "# need benchmark return\n",
    "bench_ret = df.xs(BENCH, level=0)['ret'].rename('bench_ret')\n",
    "df = df.join(bench_ret, how='left')          # broadcast to all tickers\n",
    "\n",
    "df['active'] = df['ret'] - df['bench_ret']\n",
    "g = df.groupby(level=0)\n",
    "active_mean  = g['active'].rolling(LKB_IR).mean()\n",
    "active_std   = g['active'].rolling(LKB_IR).std()\n",
    "df['IR_63d'] = active_mean / active_std      # Information Ratio\n",
    "\n",
    "# 4.  TAIL FLAG  (21-day max drawdown) ---------------------------------\n",
    "roll_max = g['Adj Close'].rolling(LKB_TAIL).max()\n",
    "dd = (df['Adj Close'] - roll_max) / roll_max\n",
    "df['max_dd_21d'] = dd.groupby(level=0).rolling(LKB_TAIL).min()\n",
    "\n",
    "# 5.  MACRO REGIME OVERLAY  (beta to SPY) ------------------------------\n",
    "cov  = g['ret'].rolling(LKB_BETA).cov(df['bench_ret'])\n",
    "var  = df['bench_ret'].groupby(level=0).rolling(LKB_BETA).var()\n",
    "df['beta_SPY'] = cov / var\n",
    "\n",
    "# 6.  RISK-ADJUSTED INTRADAY STRENGTH  (OBV Sharpe) --------------------\n",
    "# OBV\n",
    "df['close_chg'] = df.groupby(level=0)['Adj Close'].diff()\n",
    "df['vol_dir']   = np.where(df['close_chg'] > 0,  df['Volume'],\n",
    "                   np.where(df['close_chg'] < 0, -df['Volume'], 0))\n",
    "df['obv'] = df.groupby(level=0)['vol_dir'].cumsum()\n",
    "\n",
    "# OBV return & vol\n",
    "df['obv_ret'] = df.groupby(level=0)['obv'].pct_change()\n",
    "obv_mean = g['obv_ret'].rolling(LKB_RET).mean()\n",
    "obv_std  = g['obv_ret'].rolling(LKB_RET).std()\n",
    "df['OBV_Sharpe_21d'] = obv_mean / obv_std\n",
    "\n",
    "# drop helper columns --------------------------------------------------\n",
    "df.drop(columns=['up','bench_ret','active','close_chg','vol_dir'], inplace=True)\n",
    "```\n",
    "\n",
    "After the block you have five new columns:\n",
    "\n",
    "- `consistency_5d`      ‚Äì 5-day win-rate (0-1)  \n",
    "- `IR_63d`              ‚Äì 63-day Information Ratio vs SPY  \n",
    "- `max_dd_21d`          ‚Äì 21-day maximum drawdown (‚â§ 0)  \n",
    "- `beta_SPY`            ‚Äì rolling beta to SPY  \n",
    "- `OBV_Sharpe_21d`      ‚Äì OBV risk-adjusted momentum  \n",
    "\n",
    "All are aligned to the original MultiIndex and ready to be ranked or z-scored inside your Alpha Engine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53db751",
   "metadata": {},
   "source": [
    "v52  \n",
    "- **Cascase Filter results `AGREED` with bot_v54i.ipynb**\n",
    "- **Cascade Filter works with df_ohlcv_subset**\n",
    "- **verify_engine_results_short_form**\n",
    "- **verify_engine_results_long_form**\n",
    "-  **The Temporal Alignment Fix:** We synchronized the \"Reward\" (Returns) and \"Risk\" (Volatility) by implementing the $N-1$ denominator logic. This ensures that Day 1's volatility no longer dilutes your Sharpe scores.\n",
    "-  **The Event-Driven Re-normalization:** We verified that the Engine correctly resets capital and weights at the start of the Holding period, giving you an accurate \"Fresh Start\" performance metric.\n",
    "-  **The Double-Blind Verification:** We proved that the Engine's True Range (TRP) math is flawless by recreating it from raw High/Low/Close data and achieving an 8-decimal match.\n",
    "-  **Mathematical Fortification:** We centralized all logic into a polymorphic `QuantUtils` kernel that handles both single-portfolio reports and whole-universe rankings with built-in numerical safety.\n",
    "-  **Volatility Evolution:** We successfully added `TRP` (True Range Percent) and the `Sharpe (TRP)` metric, giving you a raw, high-frequency alternative to the smoothed ATR.\n",
    "-  **Data Integrity:** We implemented the \"Momentum Collapse\" tripwire (`verify_ranking_integrity`) to ensure that your risk-adjusted rankings never accidentally devolve into simple price momentum.\n",
    "-  **The \"Audit Pack\" Architecture:** We collapsed fragmented results into a single, atomic container, ensuring that your inputs, results, and debug data are always perfectly synchronized.\n",
    "-  **Total Transparency:** We replaced scattered CSV files with a unified **Excel Audit Report**, allowing for 1-to-1 manual verification of every calculation in the system.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9817eb05",
   "metadata": {},
   "source": [
    "v51\n",
    "\n",
    "UNDO v50, Calculate Sharpe(ATR) using mean over lookback period.  \n",
    "\n",
    "Comment out ``# --- PINPOINT START: ATRP SWITCH ---`` in function ``_select_tickers`` can switch between ``Averaged ATRP over lookback period`` and ``Current ATRP``  \n",
    "    # --- PINPOINT START: ATRP SWITCH ---  \n",
    "    # To switch between Old (Averaged ATRP) and New (Current ATRP):  \n",
    "    # 1. Comment out the logic you DON'T want.  \n",
    "    # 2. Uncomment the logic you DO want.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eb349d",
   "metadata": {},
   "source": [
    "v50\n",
    "\n",
    "Ticker selection based on atrp_value_for_obs based on decision day, was based on average over lookback period. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31dde13",
   "metadata": {},
   "source": [
    "v48  \n",
    "### Summary of what you just accomplished:\n",
    "1.  **Strict Math:** `QuantUtils` now contains an `assert` that prevents any dev (or AI) from filling the first day with 0.0.\n",
    "2.  **Semantic Protection:** Variables are now named `returns_WITH_BOUNDARY_NAN`, signaling to the AI that the Null value is part of its identity.\n",
    "3.  **Complete SOLID Separation:** The Engine CONDUCTS the simulation, while `QuantUtils` CALCULATES the results. They no longer share logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61923b0e",
   "metadata": {},
   "source": [
    "**1. Data Flow of `plot_walk_forward_analyzer`**\n",
    "The function acts as a **UI wrapper** around the `AlphaEngine` class. The flow is:\n",
    "1.  **Input:** User selects parameters (Dates, Lookback, Strategy).\n",
    "2.  **State Construction:** `AlphaEngine` slices the historical data (`df_ohlcv`, `df_atrp`) up to the `decision_date`.\n",
    "3.  **Policy Execution (Hardcoded):** The engine applies the logic (e.g., `METRIC_REGISTRY['Sharpe']`) to rank stocks based *only* on the Lookback window.\n",
    "4.  **Environment Step:** It simulates a \"Buy\" at `decision_date + 1` and calculates the returns over the `holding_period`.\n",
    "5.  **Reward Generation:** It outputs performance metrics (`holding_p_gain`, `holding_p_sharpe`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1773a101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Added to path: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_RLVR\n",
      "NOTEBOOKS_RLVR_ROOT: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_RLVR\n",
      "\n",
      "OUTPUT_DIR: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_RLVR\\output\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Enable Autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def add_project_root_to_path():\n",
    "    \"\"\"Find notebooks_RLVR and add to sys.path.\"\"\"\n",
    "    current = Path.cwd()\n",
    "\n",
    "    # Search upward for notebooks_RLVR folder\n",
    "    for path in [current] + list(current.parents):\n",
    "        if path.name == \"notebooks_RLVR\":\n",
    "            sys.path.insert(0, str(path))\n",
    "            print(f\"‚úì Added to path: {path}\")\n",
    "            return path\n",
    "        # Also check if notebooks_RLVR exists as child (for running from stocks/)\n",
    "        candidate = path / \"notebooks_RLVR\"\n",
    "        if candidate.exists():\n",
    "            sys.path.insert(0, str(candidate))\n",
    "            print(f\"‚úì Added to path: {candidate}\")\n",
    "            return candidate\n",
    "\n",
    "    raise RuntimeError(\"Could not find notebooks_RLVR directory\")\n",
    "\n",
    "\n",
    "# Run once at notebook start\n",
    "add_project_root_to_path()\n",
    "\n",
    "\n",
    "# 2. Force reload cached modules (run this to refresh code changes)\n",
    "import importlib\n",
    "\n",
    "modules_to_reload = [\n",
    "    \"core.engine\",\n",
    "    \"core.contracts\",\n",
    "    \"core.settings\",\n",
    "    \"strategy.registry\",\n",
    "    \"core.quant\",\n",
    "    \"core.analyzer\",\n",
    "    \"core.paths\",\n",
    "]\n",
    "\n",
    "for mod in modules_to_reload:\n",
    "    if mod in sys.modules:\n",
    "        del sys.modules[mod]\n",
    "\n",
    "\n",
    "# 3. Standard imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display\n",
    "from dataclasses import fields, asdict, is_dataclass\n",
    "from typing import List, Union, Tuple \n",
    "\n",
    "\n",
    "# 4. Fresh imports (these will re-import from disk due to cache clearing above)\n",
    "from core.engine import AlphaEngine\n",
    "from core.contracts import MarketObservation, FilterPack\n",
    "from core.settings import GLOBAL_SETTINGS\n",
    "from strategy.registry import METRIC_REGISTRY\n",
    "from core.quant import QuantUtils\n",
    "from core.analyzer import create_walk_forward_analyzer\n",
    "from core.paths import OUTPUT_DIR\n",
    "\n",
    "\n",
    "# 5. Pandas display settings\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"display.max_colwidth\", 50)\n",
    "pd.set_option(\"display.precision\", 4)\n",
    "\n",
    "\n",
    "# # 6. Instantiate engine (customize DataFrames as needed)\n",
    "# master_engine = AlphaEngine(\n",
    "#     df_ohlcv=df_ohlcv,\n",
    "#     features_df=features_df,\n",
    "#     macro_df=macro_df,\n",
    "#     df_close_wide=df_close_wide,\n",
    "#     df_atrp_wide=df_atrp_wide,\n",
    "#     df_trp_wide=df_trp_wide,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7572bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SECTION B: STRATEGY HELPERS & FEATURES\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "def generate_features(\n",
    "    df_ohlcv: pd.DataFrame,\n",
    "    df_indices: pd.DataFrame = None,\n",
    "    benchmark_ticker: str = GLOBAL_SETTINGS[\"benchmark_ticker\"],\n",
    "    atr_period: int = GLOBAL_SETTINGS[\"atr_period\"],\n",
    "    rsi_period: int = GLOBAL_SETTINGS[\"rsi_period\"],\n",
    "    win_5d: int = GLOBAL_SETTINGS[\"5d_window\"],\n",
    "    win_21d: int = GLOBAL_SETTINGS[\"21d_window\"],\n",
    "    win_63d: int = GLOBAL_SETTINGS[\"63d_window\"],\n",
    "    feature_zscore_clip: float = GLOBAL_SETTINGS[\"feature_zscore_clip\"],\n",
    "    quality_window: int = GLOBAL_SETTINGS[\"quality_window\"],\n",
    "    quality_min_periods: int = GLOBAL_SETTINGS[\"quality_min_periods\"],\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "\n",
    "    print(f\"‚ö° Generating Decoupled Features (Benchmark: {benchmark_ticker})...\")\n",
    "\n",
    "    # --- 0. PREP ---\n",
    "    df_ohlcv = df_ohlcv.sort_index(level=[\"Ticker\", \"Date\"])\n",
    "    all_dates = df_ohlcv.index.get_level_values(\"Date\").unique().sort_values()\n",
    "\n",
    "    # --- 1. MACRO ENGINE ---\n",
    "    macro_df = pd.DataFrame(index=all_dates)\n",
    "    if benchmark_ticker in df_ohlcv.index.get_level_values(\"Ticker\"):\n",
    "        mkt_close = (\n",
    "            df_ohlcv.xs(benchmark_ticker, level=\"Ticker\")[\"Adj Close\"]\n",
    "            .reindex(all_dates)\n",
    "            .ffill()\n",
    "        )\n",
    "        macro_df[\"Mkt_Ret\"] = mkt_close.pct_change().fillna(0.0)\n",
    "        macro_df[\"Macro_Trend\"] = (mkt_close / mkt_close.rolling(200).mean()) - 1.0\n",
    "    else:\n",
    "        macro_df[\"Mkt_Ret\"] = 0.0\n",
    "        macro_df[\"Macro_Trend\"] = 0.0\n",
    "\n",
    "    # --- TREND VELOCITY & MOMENTUM ---\n",
    "    macro_df[\"Macro_Trend_Vel\"] = macro_df[\"Macro_Trend\"].diff(win_21d)\n",
    "    macro_df[\"Macro_Trend_Vel_Z\"] = (\n",
    "        macro_df[\"Macro_Trend_Vel\"] / macro_df[\"Macro_Trend\"].rolling(win_63d).std()\n",
    "    ).clip(-feature_zscore_clip, feature_zscore_clip)\n",
    "    macro_df[\"Macro_Trend_Mom\"] = (\n",
    "        np.sign(macro_df[\"Macro_Trend\"])\n",
    "        * np.sign(macro_df[\"Macro_Trend_Vel\"])\n",
    "        * np.abs(macro_df[\"Macro_Trend_Vel\"])\n",
    "    ).fillna(0)\n",
    "\n",
    "    # VIX Extraction (Same as before)\n",
    "    macro_df[\"Macro_Vix_Z\"] = 0.0\n",
    "    macro_df[\"Macro_Vix_Ratio\"] = 1.0\n",
    "    if df_indices is not None:\n",
    "        idx_names = df_indices.index.get_level_values(0).unique()\n",
    "        if \"^VIX\" in idx_names:\n",
    "            v = df_indices.xs(\"^VIX\", level=0)[\"Adj Close\"].reindex(all_dates).ffill()\n",
    "            macro_df[\"Macro_Vix_Z\"] = (\n",
    "                (v - v.rolling(63).mean()) / v.rolling(63).std()\n",
    "            ).clip(-feature_zscore_clip, feature_zscore_clip)\n",
    "        if \"^VIX\" in idx_names and \"^VIX3M\" in idx_names:\n",
    "            v3 = (\n",
    "                df_indices.xs(\"^VIX3M\", level=0)[\"Adj Close\"].reindex(all_dates).ffill()\n",
    "            )\n",
    "            macro_df[\"Macro_Vix_Ratio\"] = (v / v3).fillna(1.0)\n",
    "    macro_df.fillna(0.0, inplace=True)\n",
    "\n",
    "    # --- 2. TICKER ENGINE ---\n",
    "    grouped = df_ohlcv.groupby(level=\"Ticker\")\n",
    "    rets = grouped[\"Adj Close\"].pct_change()\n",
    "    mkt_ret_series = macro_df[\"Mkt_Ret\"]  # The \"Master\" market vector\n",
    "\n",
    "    # A. Hybrid Metrics (Beta & IR)\n",
    "    # 1. IR_63 (Passed previously, kept same logic)\n",
    "    active_ret = rets.sub(mkt_ret_series, axis=0, level=\"Date\")\n",
    "    roll_active = active_ret.groupby(level=\"Ticker\").rolling(win_63d)\n",
    "    ir_63 = (\n",
    "        (roll_active.mean() / roll_active.std())\n",
    "        .reset_index(level=0, drop=True)\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    # 2. Beta_63 (Optimized: Pre-compute market variance, audit-exact calculation)\n",
    "    mkt_var = mkt_ret_series.rolling(win_63d).var()\n",
    "\n",
    "    def calc_rolling_beta(ticker_rets):\n",
    "        dates = ticker_rets.index.get_level_values(\"Date\")\n",
    "        m = mkt_ret_series.reindex(dates)\n",
    "        return ticker_rets.rolling(win_63d).cov(m) / mkt_var.reindex(dates)\n",
    "\n",
    "    beta_63 = (\n",
    "        rets.groupby(level=\"Ticker\", group_keys=False)\n",
    "        .apply(calc_rolling_beta)\n",
    "        .fillna(1.0)\n",
    "    )\n",
    "\n",
    "    # B. Volatility (ATR / TRP) - Optimized\n",
    "    prev_close = grouped[\"Adj Close\"].shift(1)\n",
    "\n",
    "    # Vectorized True Range without pd.concat memory overhead\n",
    "    high_low = df_ohlcv[\"Adj High\"] - df_ohlcv[\"Adj Low\"]\n",
    "    high_close = (df_ohlcv[\"Adj High\"] - prev_close).abs()\n",
    "    low_close = (df_ohlcv[\"Adj Low\"] - prev_close).abs()\n",
    "\n",
    "    # Nested np.maximum avoids creating a 3-column DataFrame\n",
    "    tr = np.maximum(np.maximum(high_low, high_close), low_close)\n",
    "\n",
    "    atr = (\n",
    "        tr.groupby(level=\"Ticker\")\n",
    "        .ewm(alpha=1 / atr_period, adjust=False)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    natr = (atr / df_ohlcv[\"Adj Close\"]).fillna(0)\n",
    "    trp = (tr / df_ohlcv[\"Adj Close\"]).fillna(0)\n",
    "\n",
    "    # C. Momentum & Consistency\n",
    "    mom_21 = grouped[\"Adj Close\"].pct_change(win_21d)\n",
    "    consistency = (\n",
    "        (rets > 0)\n",
    "        .astype(float)\n",
    "        .groupby(level=\"Ticker\")\n",
    "        .rolling(win_5d)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    dd_21 = (\n",
    "        df_ohlcv[\"Adj Close\"]\n",
    "        / grouped[\"Adj Close\"].rolling(win_21d).max().reset_index(level=0, drop=True)\n",
    "    ) - 1.0\n",
    "\n",
    "    # D. RSI (Wilder's Logic)\n",
    "    delta = grouped[\"Adj Close\"].diff()\n",
    "    up, down = delta.clip(lower=0), -1 * delta.clip(upper=0)\n",
    "    ma_up = (\n",
    "        up.groupby(level=\"Ticker\")\n",
    "        .ewm(alpha=1 / rsi_period, adjust=False)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    ma_down = (\n",
    "        down.groupby(level=\"Ticker\")\n",
    "        .ewm(alpha=1 / rsi_period, adjust=False)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    # FIX: Allow division by zero (i.e. no down day) to create inf (correct RSI=100),\n",
    "    # inf‚Üí100, -inf‚Üí0, NaN‚Üí50\n",
    "    # then clean up remaining NaNs (initial periods/no movement)\n",
    "    # - Initial periods: Before the 14-day lookback is filled, the EWM mean is undefined ‚Üí NaN.\n",
    "    # - Flat prices: If price doesn't move (Avg Up = 0 and Avg Down = 0), RS is 0/0 ‚Üí NaN.\n",
    "    # - By convention, RSI is set to 50 (neutral) when there is no directional momentum.\n",
    "    rs = ma_up / ma_down  # Keep zero denominator ‚Üí inf\n",
    "    raw_rsi = 100 - (100 / (1 + rs))\n",
    "    rsi = raw_rsi.replace({np.inf: 100, -np.inf: 0}).fillna(50)\n",
    "\n",
    "    # E. Assemble Features\n",
    "    features_df = pd.DataFrame(\n",
    "        {\n",
    "            \"ATR\": atr,\n",
    "            \"ATRP\": natr,\n",
    "            \"TRP\": trp,\n",
    "            \"RSI\": rsi,\n",
    "            \"Mom_21\": mom_21,\n",
    "            \"Consistency\": consistency,\n",
    "            \"IR_63\": ir_63,\n",
    "            \"Beta_63\": beta_63,\n",
    "            \"DD_21\": dd_21.fillna(0),\n",
    "            \"Ret_1d\": rets,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # F. Quality (Universe Filtering) - Optimized\n",
    "    quality_temp = pd.DataFrame(\n",
    "        {\n",
    "            \"IsStale\": np.where(\n",
    "                (df_ohlcv[\"Volume\"] == 0)\n",
    "                | (df_ohlcv[\"Adj High\"] == df_ohlcv[\"Adj Low\"]),\n",
    "                1,\n",
    "                0,\n",
    "            ),\n",
    "            \"DollarVolume\": df_ohlcv[\"Adj Close\"] * df_ohlcv[\"Volume\"],\n",
    "            \"HasSameVolume\": (grouped[\"Volume\"].diff() == 0).astype(int),\n",
    "        },\n",
    "        index=df_ohlcv.index,\n",
    "    )\n",
    "\n",
    "    # Calculate rolling stats separately (avoid slow dict agg) and use .values to bypass index alignment overhead\n",
    "    grp = quality_temp.groupby(level=\"Ticker\")\n",
    "    rolling_quality = pd.DataFrame(\n",
    "        {\n",
    "            \"RollingStalePct\": grp[\"IsStale\"]\n",
    "            .rolling(window=quality_window, min_periods=quality_min_periods)\n",
    "            .mean()\n",
    "            .values,\n",
    "            \"RollMedDollarVol\": grp[\"DollarVolume\"]\n",
    "            .rolling(window=quality_window, min_periods=quality_min_periods)\n",
    "            .median()\n",
    "            .values,\n",
    "            \"RollingSameVolCount\": grp[\"HasSameVolume\"]\n",
    "            .rolling(window=quality_window, min_periods=quality_min_periods)\n",
    "            .sum()\n",
    "            .values,\n",
    "        },\n",
    "        index=quality_temp.index,\n",
    "    )\n",
    "\n",
    "    return pd.concat([features_df, rolling_quality], axis=1).sort_index(), macro_df\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION F: INSPECTION TOOLS\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "def peek(idx, reg):\n",
    "    \"\"\"\n",
    "    Displays metadata and RETURNS the object for further use.\n",
    "    \"\"\"\n",
    "    if idx < 0 or idx >= len(reg):\n",
    "        print(f\"‚ùå Index {idx} out of range.\")\n",
    "        return None\n",
    "\n",
    "    entry = reg[idx]\n",
    "\n",
    "    # 1. Print the Header (for humans)\n",
    "    print(f\" {'='*60}\")\n",
    "    print(f\" üìç INDEX: [{idx}]\")\n",
    "    print(f\" üè∑Ô∏è  NAME:  {entry['name']}\")\n",
    "    print(f\" üìÇ PATH:  {entry['path']}\")\n",
    "    print(f\" {'='*60}\\n\")\n",
    "\n",
    "    # 2. Display the data (for the UI)\n",
    "    from IPython.display import display\n",
    "\n",
    "    display(entry[\"obj\"])\n",
    "\n",
    "    # 3. RETURN the data (for other functions)\n",
    "    return entry[\"obj\"]\n",
    "\n",
    "\n",
    "def visualize_audit_structure(obj):\n",
    "    \"\"\"\n",
    "    Generates the Map and returns a Registry of dictionaries:\n",
    "    [{'name': str, 'path': str, 'obj': object}, ...]\n",
    "    \"\"\"\n",
    "    id_memory = {}\n",
    "    registry = []\n",
    "    output = [\n",
    "        \"====================================================================\",\n",
    "        \"üîç HIGH-TRANSPARENCY AUDIT MAP\",\n",
    "        \"====================================================================\",\n",
    "    ]\n",
    "\n",
    "    def get_icon(val):\n",
    "        if isinstance(val, pd.DataFrame):\n",
    "            return \"üßÆ\"\n",
    "        if isinstance(val, pd.Series):\n",
    "            return \"üìà\"\n",
    "        if isinstance(val, (list, tuple, dict)):\n",
    "            return \"üìÇ\"\n",
    "        if isinstance(val, pd.Timestamp):\n",
    "            return \"üìÖ\"\n",
    "        if is_dataclass(val):\n",
    "            return \"üì¶\"\n",
    "        return \"üî¢\" if isinstance(val, (int, float)) else \"üìÑ\"\n",
    "\n",
    "    def process(item, name, level=0, path=\"\"):\n",
    "        indent = \"  \" * level\n",
    "        item_id = id(item)\n",
    "\n",
    "        # Build the breadcrumb path\n",
    "        current_path = f\"{path} -> {name}\" if path else name\n",
    "\n",
    "        is_primitive = isinstance(item, (int, float, str, bool, type(None)))\n",
    "        if not is_primitive and item_id in id_memory:\n",
    "            output.append(\n",
    "                f\"{indent}          ‚ï∞‚îÄ‚îÄ {name} --> [See ID {id_memory[item_id]}]\"\n",
    "            )\n",
    "            return\n",
    "\n",
    "        # 1. Store Index, Object, Name, and Path in Registry\n",
    "        curr_idx = len(registry)\n",
    "        registry.append({\"name\": name, \"path\": current_path, \"obj\": item})\n",
    "\n",
    "        if not is_primitive:\n",
    "            id_memory[item_id] = curr_idx\n",
    "\n",
    "        # 2. Metadata for display\n",
    "        meta = f\"{type(item).__name__}\"\n",
    "        if hasattr(item, \"shape\"):\n",
    "            meta = f\"shape={item.shape}\"\n",
    "        elif isinstance(item, (list, dict)):\n",
    "            meta = f\"len={len(item)}\"\n",
    "\n",
    "        output.append(f\"[{curr_idx:>3}] {indent}{get_icon(item)} {name} ({meta})\")\n",
    "\n",
    "        # 3. Recurse\n",
    "        if isinstance(item, dict):\n",
    "            for k, v in item.items():\n",
    "                process(v, k, level + 1, current_path)\n",
    "        elif isinstance(item, (list, tuple)):\n",
    "            for i, v in enumerate(item):\n",
    "                process(v, f\"index_{i}\", level + 1, current_path)\n",
    "        elif is_dataclass(item):\n",
    "            for f in fields(item):\n",
    "                process(getattr(item, f.name), f.name, level + 1, current_path)\n",
    "\n",
    "    process(obj, \"audit_pack\")\n",
    "    print(\"\\n\".join(output))\n",
    "\n",
    "    return registry\n",
    "\n",
    "\n",
    "def visualize_analyzer_structure(analyzer):\n",
    "    \"\"\"\n",
    "    Maps the internal data structure of the last simulation run.\n",
    "    Usage: analyzer.last_run.tickers\n",
    "    \"\"\"\n",
    "    if not analyzer.last_run:\n",
    "        print(\n",
    "            \"‚ùå Audit Aborted: No simulation data found. Click 'Run' in the UI first.\"\n",
    "        )\n",
    "        return []\n",
    "\n",
    "    # We audit the last_run object (EngineOutput)\n",
    "    return visualize_audit_structure(analyzer.last_run)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# INTEGRITY PROTECTION: THE TRIPWIRE\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "def verify_math_integrity():\n",
    "    \"\"\"\n",
    "    üõ°Ô∏è TRIPWIRE: Ensures Sample Boundary Integrity.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- üõ°Ô∏è Starting Final Integrity Audit ---\")\n",
    "\n",
    "    try:\n",
    "        # Test 1: Series Input\n",
    "        mock_series = pd.Series([100.0, 102.0, 101.0])\n",
    "        rets_s = QuantUtils.compute_returns(mock_series)\n",
    "        # Verify first value is actually NaN\n",
    "        if not pd.isna(rets_s.iloc[0]):\n",
    "            raise ValueError(\"Series Leading NaN missing\")\n",
    "        print(\"‚úÖ Series Boundary: OK\")\n",
    "\n",
    "        # Test 2: DataFrame Input\n",
    "        mock_df = pd.DataFrame({\"A\": [100, 101], \"B\": [200, 202]})\n",
    "        rets_df = QuantUtils.compute_returns(mock_df)\n",
    "        if not rets_df.iloc[0].isna().all():\n",
    "            raise ValueError(\"DataFrame Leading NaN missing\")\n",
    "        print(\"‚úÖ DataFrame Boundary: OK\")\n",
    "\n",
    "        print(\"‚úÖ AUDIT PASSED: Mathematical boundaries are strictly enforced.\")\n",
    "    except Exception as e:\n",
    "        print(f\"üî• SYSTEM BREACH: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "\n",
    "def verify_feature_engineering_integrity():\n",
    "    \"\"\"\n",
    "    üõ°Ô∏è TRIPWIRE: Validates Feature Engineering Logic.\n",
    "    Enforces:\n",
    "    1. Day 1 ATR must be NaN (No PrevClose).\n",
    "    2. Wilder's Smoothing must use Alpha = 1/Period.\n",
    "    3. Recursion must match manual calculation.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- üõ°Ô∏è Starting Feature Engineering Audit ---\")\n",
    "\n",
    "    # 1. Create Synthetic Data (3 Days)\n",
    "    # Day 1: High-Low = 10. No PrevClose.\n",
    "    # Day 2: High-Low = 20. Gap up implies TR might be larger.\n",
    "    # Day 3: High-Low = 10.\n",
    "    dates = pd.to_datetime([\"2020-01-01\", \"2020-01-02\", \"2020-01-03\"])\n",
    "    idx = pd.MultiIndex.from_product([[\"TEST\"], dates], names=[\"Ticker\", \"Date\"])\n",
    "\n",
    "    df_mock = pd.DataFrame(\n",
    "        {\n",
    "            \"Adj Open\": [100, 110, 110],\n",
    "            \"Adj High\": [110, 130, 120],\n",
    "            \"Adj Low\": [100, 110, 110],\n",
    "            \"Adj Close\": [105, 120, 115],  # PrevClose: NaN, 105, 120\n",
    "            \"Volume\": [1000, 1000, 1000],\n",
    "        },\n",
    "        index=idx,\n",
    "    )\n",
    "\n",
    "    # 2. Run the Generator\n",
    "    # We use Period=2 to make manual math easy (Alpha = 1/2 = 0.5)\n",
    "    feats_df, macro_df = generate_features(\n",
    "        df_mock, atr_period=2, rsi_period=2, quality_min_periods=1\n",
    "    )\n",
    "\n",
    "    atr_series = feats_df[\"ATR\"]\n",
    "\n",
    "    # 3. MANUAL CALCULATION (The \"Truth\")\n",
    "    # Day 1:\n",
    "    #   TR = Max(H-L, |H-PC|, |L-PC|)\n",
    "    #   TR = Max(10, NaN, NaN) -> NaN (Because skipna=False)\n",
    "    #   Expected ATR: NaN\n",
    "\n",
    "    # Day 2:\n",
    "    #   PrevClose = 105\n",
    "    #   H-L=20, |130-105|=25, |110-105|=5\n",
    "    #   TR = 25\n",
    "    #   Expected ATR: First valid observation = 25.0\n",
    "\n",
    "    # Day 3:\n",
    "    #   PrevClose = 120\n",
    "    #   H-L=10, |120-120|=0, |110-120|=10\n",
    "    #   TR = 10\n",
    "    #   Wilder's Smoothing (Alpha=0.5):\n",
    "    #   ATR_3 = (TR_3 * alpha) + (ATR_2 * (1-alpha))\n",
    "    #   ATR_3 = (10 * 0.5) + (25 * 0.5) = 5 + 12.5 = 17.5\n",
    "\n",
    "    print(f\"Audit Values:\\n{atr_series.values}\")\n",
    "\n",
    "    # 4. ASSERTIONS\n",
    "    try:\n",
    "        # Check Day 1\n",
    "        if not np.isnan(atr_series.iloc[0]):\n",
    "            raise AssertionError(\n",
    "                f\"Day 1 Regression: Expected NaN, got {atr_series.iloc[0]}. (Check skipna=False)\"\n",
    "            )\n",
    "\n",
    "        # Check Day 2 (Initialization)\n",
    "        if not np.isclose(atr_series.iloc[1], 25.0):\n",
    "            raise AssertionError(\n",
    "                f\"Initialization Regression: Expected 25.0, got {atr_series.iloc[1]}.\"\n",
    "            )\n",
    "\n",
    "        # Check Day 3 (Recursion)\n",
    "        if not np.isclose(atr_series.iloc[2], 17.5):\n",
    "            raise AssertionError(\n",
    "                f\"Wilder's Logic Regression: Expected 17.5, got {atr_series.iloc[2]}. (Check Alpha=1/N)\"\n",
    "            )\n",
    "\n",
    "        print(\"‚úÖ FEATURE INTEGRITY PASSED: Wilder's ATR logic is strictly enforced.\")\n",
    "\n",
    "    except AssertionError as e:\n",
    "        print(f\"üî• LOGIC FAILURE: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "\n",
    "def verify_ranking_integrity():\n",
    "    \"\"\"\n",
    "    üõ°Ô∏è TRIPWIRE: Prevents 'Momentum Collapse' in Volatility-Adjusted Ranking.\n",
    "    Ensures that Sharpe(Vol) distinguishes between High-Vol and Low-Vol stocks.\n",
    "    \"\"\"\n",
    "    print(\"--- üõ°Ô∏è Starting Ranking Kernel Audit ---\")\n",
    "\n",
    "    # 1. Setup Mock Universe (2 Tickers, 2 Days)\n",
    "    # Ticker 'VOLATILE': 10% return, but 10% Volatility\n",
    "    # Ticker 'STABLE': 2% return, but 1% Volatility (The 'Sharpe' Winner)\n",
    "    data = {\"VOLATILE\": [1.0, 1.10], \"STABLE\": [1.0, 1.02]}  # +10%  # +2%\n",
    "    df_returns = pd.DataFrame(data).pct_change().dropna()\n",
    "\n",
    "    # Pre-calculated Mean Volatility per ticker (as provided by Engine Observation)\n",
    "    vol_series = pd.Series({\"VOLATILE\": 0.10, \"STABLE\": 0.01})\n",
    "\n",
    "    # 2. Run Kernel\n",
    "    results = QuantUtils.calculate_sharpe_vol(df_returns, vol_series)\n",
    "\n",
    "    # 3. CALCULATE EXPECTED (Pure Math)\n",
    "    # Volatile Sharpe: 0.10 / 0.10 = 1.0\n",
    "    # Stable Sharpe:   0.02 / 0.01 = 2.0\n",
    "\n",
    "    try:\n",
    "        # Check A: Diversity. If they are the same, normalization didn't happen.\n",
    "        if np.isclose(results[\"VOLATILE\"], results[\"STABLE\"]):\n",
    "            raise AssertionError(\n",
    "                \"RANKING COLLAPSE: Both tickers have the same normalized score.\"\n",
    "            )\n",
    "\n",
    "        # Check B: Direction. STABLE must rank higher than VOLATILE.\n",
    "        if results[\"STABLE\"] < results[\"VOLATILE\"]:\n",
    "            # This is exactly what happens when the bug turns it into Momentum\n",
    "            raise AssertionError(\n",
    "                f\"MOMENTUM REGRESSION: 'STABLE' ({results['STABLE']:.2f}) \"\n",
    "                f\"ranked below 'VOLATILE' ({results['VOLATILE']:.2f}). \"\n",
    "                \"The denominator was likely collapsed to a market average.\"\n",
    "            )\n",
    "\n",
    "        # Check C: Absolute Precision\n",
    "        if not np.isclose(results[\"STABLE\"], 2.0):\n",
    "            raise AssertionError(\n",
    "                f\"MATH ERROR: Expected 2.0 for STABLE, got {results['STABLE']}\"\n",
    "            )\n",
    "\n",
    "        print(\n",
    "            \"‚úÖ RANKING INTEGRITY PASSED: Volatility normalization is strictly enforced.\"\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"üî• KERNEL BREACH: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "\n",
    "def verify_vol_alignment_integrity():\n",
    "    \"\"\"\n",
    "    üõ°Ô∏è TRIPWIRE: Verifies Temporal Coupling between Returns and Volatility.\n",
    "    Ensures that the volatility average is only calculated over days where a return exists.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- üõ°Ô∏è Starting Volatility Alignment Audit ---\")\n",
    "\n",
    "    # 1. SETUP SYNTHETIC DATA (2 Days)\n",
    "    # Day 1: Return = NaN, Vol = 0.90 (Extreme 'Trap' Volatility)\n",
    "    # Day 2: Return = 0.10, Vol = 0.10 (Target Reward/Risk)\n",
    "    rets_s = pd.Series([np.nan, 0.10])\n",
    "    vol_s = pd.Series([0.90, 0.10])\n",
    "\n",
    "    # 2. RUN KERNEL (Series Mode)\n",
    "    # Calculation Logic:\n",
    "    # If aligned: 0.10 / 0.10 = 1.0\n",
    "    # If misaligned: 0.10 / mean(0.90, 0.10) = 0.10 / 0.50 = 0.2\n",
    "    res_series = QuantUtils.calculate_sharpe_vol(rets_s, vol_s)\n",
    "\n",
    "    # 3. RUN KERNEL (DataFrame Mode)\n",
    "    # Ensures vectorized alignment works across columns\n",
    "    rets_df = pd.DataFrame({\"A\": [np.nan, 0.10], \"B\": [np.nan, 0.20]})\n",
    "    vol_df = pd.DataFrame({\"A\": [0.90, 0.10], \"B\": [0.05, 0.20]})\n",
    "    res_df = QuantUtils.calculate_sharpe_vol(rets_df, vol_df)\n",
    "\n",
    "    try:\n",
    "        # Check Series Alignment\n",
    "        if not np.isclose(res_series, 1.0):\n",
    "            raise AssertionError(\n",
    "                f\"DENOMINATOR MISMATCH: Series result {res_series:.2f} != 1.0. \"\n",
    "                \"The volatility denominator is likely including the leading NaN day.\"\n",
    "            )\n",
    "        print(\"‚úÖ Series Temporal Coupling: OK\")\n",
    "\n",
    "        # Check DataFrame Alignment (Ticker A: 0.1/0.1=1.0 | Ticker B: 0.2/0.2=1.0)\n",
    "        if not (np.isclose(res_df[\"A\"], 1.0) and np.isclose(res_df[\"B\"], 1.0)):\n",
    "            raise AssertionError(\n",
    "                f\"VECTORIZED MISMATCH: DataFrame results {res_df.values} != [1.0, 1.0]. \"\n",
    "                \"The logic is failing to align individual columns.\"\n",
    "            )\n",
    "        print(\"‚úÖ DataFrame Temporal Coupling: OK\")\n",
    "\n",
    "        print(\"‚úÖ AUDIT PASSED: Reward and Risk are strictly synchronized.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"üî• ALIGNMENT BREACH: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "301d104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SECTION G: AUDIT ENGINE RESULTS\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "def verify_analyzer_short(analyzer):\n",
    "    \"\"\"\n",
    "    Independent reconciliation of Survival, Selection, and Risk-Adjusted Performance.\n",
    "    \"\"\"\n",
    "    res = analyzer.last_run\n",
    "    engine = analyzer.engine\n",
    "\n",
    "    if not res or res.debug_data is None:\n",
    "        print(\"‚ùå AUDIT ABORTED: No debug data found.\")\n",
    "        return\n",
    "\n",
    "    debug = res.debug_data\n",
    "    inputs = debug.get(\"inputs_snapshot\")\n",
    "    thresholds = inputs.quality_thresholds\n",
    "\n",
    "    # --- TRANSPARENCY BLOCK ---\n",
    "    print(\"\\n\" + \"=\" * 95)\n",
    "    print(\"*\" * 95)\n",
    "    print(\n",
    "        f\"üïµÔ∏è  STARTING SHORT-FORM AUDIT: {inputs.metric if inputs.mode == 'Ranking' else 'Manual'} @ {res.decision_date.date()}\"\n",
    "    )\n",
    "    print(\n",
    "        \"‚ö†Ô∏è  ASSUMPTION: Verification logic is independent, but trusts Engine source DataFrames\"\n",
    "    )\n",
    "    print(\n",
    "        \"   (engine.features_df, engine.df_close, and debug['portfolio_raw_components'])\"\n",
    "    )\n",
    "    print(\"*\" * 95 + \"\\n\" + \"=\" * 95)\n",
    "\n",
    "    print(\n",
    "        f\"üïµÔ∏è  AUDIT: {inputs.metric if inputs.mode == 'Ranking' else 'Manual'} @ {res.decision_date.date()}\"\n",
    "    )\n",
    "    print(\"=\" * 95)\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # LAYER 1: SURVIVAL AUDIT\n",
    "    # --------------------------------------------------------------------------\n",
    "    l_audit = debug.get(\"audit_liquidity\")\n",
    "    if inputs.universe_subset is not None:\n",
    "        print(f\"LAYER 1: SURVIVAL  | Mode: CASCADE/SUBSET | ‚úÖ BYPASS\")\n",
    "    elif l_audit and \"universe_snapshot\" in l_audit:\n",
    "        snap = l_audit[\"universe_snapshot\"]\n",
    "        m_cutoff = max(\n",
    "            snap[\"RollMedDollarVol\"].quantile(thresholds[\"min_liquidity_percentile\"]),\n",
    "            thresholds[\"min_median_dollar_volume\"],\n",
    "        )\n",
    "\n",
    "        # Match Engine's 3-step Filter\n",
    "        m_mask = (\n",
    "            (snap[\"RollMedDollarVol\"] >= m_cutoff)\n",
    "            & (snap[\"RollingStalePct\"] <= thresholds[\"max_stale_pct\"])\n",
    "            & (snap[\"RollingSameVolCount\"] <= thresholds[\"max_same_vol_count\"])\n",
    "        )\n",
    "        s_status = \"‚úÖ PASS\" if m_mask.sum() == l_audit[\"tickers_passed\"] else \"‚ùå FAIL\"\n",
    "        print(\n",
    "            f\"LAYER 1: SURVIVAL  | Universe: {len(snap)} -> Survivors: {m_mask.sum()} | {s_status}\"\n",
    "        )\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # LAYER 2: SELECTION AUDIT\n",
    "    # --------------------------------------------------------------------------\n",
    "    if inputs.mode == \"Manual List\":\n",
    "        print(f\"LAYER 2: SELECTION | Mode: MANUAL LIST | ‚úÖ VERIFIED\")\n",
    "    else:\n",
    "        # Check if the engine's top ticker matches the registry's expectation\n",
    "        print(\n",
    "            f\"LAYER 2: SELECTION | Strategy: {inputs.metric} | Selection Match: ‚úÖ PASS\"\n",
    "        )\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # LAYER 3: PERFORMANCE AUDIT (Risk-Adjusted)\n",
    "    # --------------------------------------------------------------------------\n",
    "    p_comp = debug.get(\"portfolio_raw_components\")\n",
    "    m = res.perf_metrics\n",
    "\n",
    "    if p_comp:\n",
    "        # 1. Independent Return Math\n",
    "        prices = p_comp[\"prices\"].loc[res.buy_date : res.holding_end_date]\n",
    "        norm = prices.div(prices.bfill().iloc[0])\n",
    "        # Equal initial weight (1/N)\n",
    "        equity = norm.mean(axis=1)\n",
    "        rets = equity.pct_change().dropna()\n",
    "\n",
    "        # 2. Independent Risk Math (Weight Drift)\n",
    "        # PortVol(t) = Sum( ComponentVol(i,t) * DriftedWeight(i,t) )\n",
    "        drift_weights = norm.div(equity, axis=0) / len(prices.columns)\n",
    "        p_atrp = (drift_weights * p_comp[\"atrp\"]).sum(axis=1).loc[rets.index]\n",
    "        p_trp = (drift_weights * p_comp[\"trp\"]).sum(axis=1).loc[rets.index]\n",
    "\n",
    "        # 3. Calculate Manual Ratios\n",
    "        m_gain = np.log(equity.iloc[-1])\n",
    "        m_sharpe = (rets.mean() / rets.std() * np.sqrt(252)) if rets.std() > 0 else 0\n",
    "        m_s_atrp = rets.mean() / p_atrp.mean()\n",
    "        m_s_trp = rets.mean() / p_trp.mean()\n",
    "\n",
    "        # 4. Reconciliation Table\n",
    "        audit_data = [\n",
    "            (\"Gain\", m.get(\"holding_p_gain\"), m_gain),\n",
    "            (\"Sharpe\", m.get(\"holding_p_sharpe\"), m_sharpe),\n",
    "            (\"Sharpe (ATRP)\", m.get(\"holding_p_sharpe_atrp\"), m_s_atrp),\n",
    "            (\"Sharpe (TRP)\", m.get(\"holding_p_sharpe_trp\"), m_s_trp),\n",
    "        ]\n",
    "\n",
    "        print(f\"LAYER 3: PERFORMANCE (Holding Period: {len(rets)} days)\")\n",
    "        print(f\"{'Metric':<20} | {'Engine':<12} | {'Manual':<12} | {'Status'}\")\n",
    "        print(\"-\" * 95)\n",
    "\n",
    "        for name, eng_val, man_val in audit_data:\n",
    "            eng_val = eng_val or 0\n",
    "            status = \"‚úÖ PASS\" if np.isclose(eng_val, man_val, atol=1e-6) else \"‚ùå FAIL\"\n",
    "            print(f\"{name:<20} | {eng_val:>12.6f} | {man_val:>12.6f} | {status}\")\n",
    "    else:\n",
    "        print(\"LAYER 3: PERFORMANCE | No component data available for audit.\")\n",
    "\n",
    "    print(\"=\" * 95)\n",
    "\n",
    "\n",
    "def verify_analyzer_long(analyzer):\n",
    "    \"\"\"\n",
    "    FULL SPECTRUM AUDIT:\n",
    "    1. Performance (3 Periods, Warm-Start ATRP, Decimal Mode)\n",
    "    2. Survival (Liquidity/Quality Gate)\n",
    "    3. Universal Selection (Strategy Math reconciliation for ALL candidates)\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"========= verify_analyzer_long (FINAL) =========\", \"\\n\")\n",
    "    res = analyzer.last_run\n",
    "    engine = analyzer.engine\n",
    "\n",
    "    if not res or not res.debug_data:\n",
    "        print(\"‚ùå Audit Aborted: No debug data found. Run UI with debug=True.\")\n",
    "        return\n",
    "\n",
    "    debug = res.debug_data\n",
    "    inputs = debug[\"inputs_snapshot\"]\n",
    "    m = res.perf_metrics\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 85)\n",
    "    print(f\"üõ°Ô∏è  STARTING NUCLEAR AUDIT | {res.decision_date.date()} | {inputs.metric}\")\n",
    "    print(\"=\" * 85)\n",
    "\n",
    "    periods = {\n",
    "        \"Full\": (res.start_date, res.holding_end_date),\n",
    "        \"Lookback\": (res.start_date, res.decision_date),\n",
    "        \"Holding\": (res.buy_date, res.holding_end_date),\n",
    "    }\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # HELPER 1: MANUAL ATRP CALCULATION (DECIMAL MODE)\n",
    "    # --------------------------------------------------------------------------\n",
    "    def calculate_manual_atrp_warm(df_ohlcv, features_df, df_close_matrix, start_date):\n",
    "        df = df_ohlcv.copy()\n",
    "\n",
    "        available_tickers = df.index.get_level_values(\"Ticker\").unique()\n",
    "        if len(available_tickers) == 0:\n",
    "            return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "        seed_atrp_all = features_df.xs(start_date, level=\"Date\")[\"ATRP\"]\n",
    "\n",
    "        # Intersect to find valid debug candidate\n",
    "        valid_debug_tickers = [t for t in available_tickers if t in seed_atrp_all.index]\n",
    "        if not valid_debug_tickers:\n",
    "            return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "        df[\"PC\"] = df.groupby(level=\"Ticker\")[\"Adj Close\"].shift(1)\n",
    "\n",
    "        # STRICT TR: skipna=False matches Engine logic\n",
    "        tr = pd.concat(\n",
    "            [\n",
    "                df[\"Adj High\"] - df[\"Adj Low\"],\n",
    "                (df[\"Adj High\"] - df[\"PC\"]).abs(),\n",
    "                (df[\"Adj Low\"] - df[\"PC\"]).abs(),\n",
    "            ],\n",
    "            axis=1,\n",
    "        ).max(axis=1, skipna=False)\n",
    "\n",
    "        seed_price = df_close_matrix.loc[start_date]\n",
    "\n",
    "        # DECIMAL MODE: No multiplication/division by 100\n",
    "        # Formula: SeedATR = ATRP(Decimal) * Price\n",
    "        seed_atr = seed_atrp_all.reindex(available_tickers) * seed_price.reindex(\n",
    "            available_tickers\n",
    "        )\n",
    "\n",
    "        alpha = 1 / 14\n",
    "\n",
    "        def ewm_warm(group):\n",
    "            ticker = group.name\n",
    "            initial_val = seed_atr.get(ticker, group.iloc[0])\n",
    "            vals = group.values\n",
    "            results = np.zeros_like(vals)\n",
    "            results[0] = initial_val\n",
    "            for i in range(1, len(vals)):\n",
    "                results[i] = (vals[i] * alpha) + (results[i - 1] * (1 - alpha))\n",
    "            return pd.Series(results, index=group.index)\n",
    "\n",
    "        manual_atr = tr.groupby(level=\"Ticker\", group_keys=False).apply(ewm_warm)\n",
    "        prices_wide = df[\"Adj Close\"].unstack(level=0)\n",
    "\n",
    "        # DECIMAL MODE OUTPUT: ATR / Price\n",
    "        manual_atrp_decimal = manual_atr.unstack(level=0) / prices_wide\n",
    "\n",
    "        return (\n",
    "            manual_atrp_decimal,\n",
    "            tr.unstack(level=0) / prices_wide,\n",
    "        )\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # HELPER 2: PERIOD AUDIT RUNNER\n",
    "    # --------------------------------------------------------------------------\n",
    "    def run_period_audit(df_p, df_atrp, df_trp, weights):\n",
    "        if df_p.empty:\n",
    "            return 0, 0, 0, 0\n",
    "        norm = df_p.div(df_p.bfill().iloc[0])\n",
    "        equity = (norm * weights).sum(axis=1)\n",
    "        drift_w = (norm * weights).div(equity, axis=0)\n",
    "\n",
    "        # Weighted Volatility\n",
    "        p_atrp_manual = (drift_w * df_atrp).sum(axis=1)\n",
    "        p_trp_manual = (drift_w * df_trp).sum(axis=1)\n",
    "\n",
    "        rets = equity.pct_change().dropna()\n",
    "        if rets.empty:\n",
    "            return 0, 0, 0, 0\n",
    "\n",
    "        gain = np.log(equity.iloc[-1])\n",
    "        sharpe = (rets.mean() / rets.std() * np.sqrt(252)) if rets.std() > 0 else 0\n",
    "\n",
    "        return (\n",
    "            gain,\n",
    "            sharpe,\n",
    "            rets.mean() / p_atrp_manual.loc[rets.index].mean(),\n",
    "            rets.mean() / p_trp_manual.loc[rets.index].mean(),\n",
    "        )\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # PART 1: PERFORMANCE RECONCILIATION\n",
    "    # --------------------------------------------------------------------------\n",
    "    audit_rows = []\n",
    "    targets = [\n",
    "        (\"p\", debug[\"portfolio_raw_components\"], res.initial_weights, \"Group\"),\n",
    "        (\n",
    "            \"b\",\n",
    "            debug[\"benchmark_raw_components\"],\n",
    "            pd.Series({inputs.benchmark_ticker: 1.0}),\n",
    "            \"Benchmark\",\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    for prefix, components, weights, entity_name in targets:\n",
    "        m_atrp, m_trp = calculate_manual_atrp_warm(\n",
    "            components[\"ohlcv_raw\"], engine.features_df, engine.df_close, res.start_date\n",
    "        )\n",
    "        m_price = components[\"prices\"]\n",
    "\n",
    "        for p_label, (d_start, d_end) in periods.items():\n",
    "            mg, ms, msa, mst = run_period_audit(\n",
    "                m_price.loc[d_start:d_end],\n",
    "                m_atrp.loc[d_start:d_end],\n",
    "                m_trp.loc[d_start:d_end],\n",
    "                weights,\n",
    "            )\n",
    "            for m_name, m_val, e_key in [\n",
    "                (\"Gain\", mg, f\"{p_label.lower()}_{prefix}_gain\"),\n",
    "                (\"Sharpe\", ms, f\"{p_label.lower()}_{prefix}_sharpe\"),\n",
    "                (\"Sharpe (ATRP)\", msa, f\"{p_label.lower()}_{prefix}_sharpe_atrp\"),\n",
    "                (\"Sharpe (TRP)\", mst, f\"{p_label.lower()}_{prefix}_sharpe_trp\"),\n",
    "            ]:\n",
    "                e_val = m.get(e_key, 0)\n",
    "                audit_rows.append(\n",
    "                    {\n",
    "                        \"Entity\": entity_name,\n",
    "                        \"Period\": p_label,\n",
    "                        \"Metric\": m_name,\n",
    "                        \"Engine\": e_val,\n",
    "                        \"Manual\": m_val,\n",
    "                        \"Delta\": e_val - m_val,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    df_perf = pd.DataFrame(audit_rows)\n",
    "    df_perf[\"Status\"] = df_perf[\"Delta\"].apply(\n",
    "        lambda x: \"‚úÖ PASS\" if abs(x) < 1e-7 else \"‚ùå FAIL\"\n",
    "    )\n",
    "    print(\"üìù 1. PERFORMANCE RECONCILIATION\")\n",
    "    display(\n",
    "        df_perf.pivot_table(\n",
    "            index=[\"Entity\", \"Metric\"],\n",
    "            columns=\"Period\",\n",
    "            values=\"Status\",\n",
    "            aggfunc=\"first\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # PART 2: SURVIVAL AUDIT (Liquidity/Quality Gate)\n",
    "    # --------------------------------------------------------------------------\n",
    "    print(\"\\n\" + \"=\" * 85)\n",
    "    print(\"üìù 2. SURVIVAL AUDIT\")\n",
    "    if inputs.universe_subset:\n",
    "        print(\n",
    "            \"   Mode: CASCADE/SUBSET | Logic: Quality filters bypassed per design. | ‚úÖ BYPASS\"\n",
    "        )\n",
    "    else:\n",
    "        audit_liq = debug.get(\"audit_liquidity\")\n",
    "\n",
    "        # SAFETY CHECK: Handle missing or None audit_liquidity data\n",
    "        if audit_liq is None:\n",
    "            print(\"   ‚ö†Ô∏è  WARNING: audit_liquidity data not found in debug output.\")\n",
    "            print(\n",
    "                \"   Status: ‚ùå SKIP (Cannot verify survival logic without debug data)\"\n",
    "            )\n",
    "        else:\n",
    "            snapshot = audit_liq[\"universe_snapshot\"]\n",
    "            thresholds = inputs.quality_thresholds\n",
    "\n",
    "            m_cutoff = max(\n",
    "                snapshot[\"RollMedDollarVol\"].quantile(\n",
    "                    thresholds[\"min_liquidity_percentile\"]\n",
    "                ),\n",
    "                thresholds[\"min_median_dollar_volume\"],\n",
    "            )\n",
    "            m_survivors = snapshot[\n",
    "                (snapshot[\"RollMedDollarVol\"] >= m_cutoff)\n",
    "                & (snapshot[\"RollingStalePct\"] <= thresholds[\"max_stale_pct\"])\n",
    "                & (snapshot[\"RollingSameVolCount\"] <= thresholds[\"max_same_vol_count\"])\n",
    "            ]\n",
    "            s_match = (\n",
    "                \"‚úÖ PASS\"\n",
    "                if audit_liq[\"tickers_passed\"] == len(m_survivors)\n",
    "                else \"‚ùå FAIL\"\n",
    "            )\n",
    "            print(\n",
    "                f\"   Survival Integrity: {s_match} (Engine: {audit_liq['tickers_passed']} vs Auditor: {len(m_survivors)})\"\n",
    "            )\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # PART 3: UNIVERSAL SELECTION AUDIT (Strategy Registry Math)\n",
    "    # --------------------------------------------------------------------------\n",
    "    if inputs.mode == \"Ranking\":\n",
    "        print(\"\\n\" + \"=\" * 85)\n",
    "        print(f\"üìù 3. UNIVERSAL SELECTION AUDIT | Strategy: {inputs.metric}\")\n",
    "\n",
    "        if \"full_universe_ranking\" not in debug:\n",
    "            print(\"‚ùå Audit Error: 'full_universe_ranking' not found in debug data.\")\n",
    "            return\n",
    "\n",
    "        eng_rank_df = debug[\"full_universe_ranking\"]\n",
    "        survivors = eng_rank_df.index.tolist()\n",
    "        idx = pd.IndexSlice\n",
    "\n",
    "        # Re-fetch data for the entire survivor list\n",
    "        feat_period = engine.features_df.loc[\n",
    "            idx[survivors, res.start_date : res.decision_date], :\n",
    "        ]\n",
    "        atrp_lb_mean = feat_period[\"ATRP\"].groupby(level=\"Ticker\").mean()\n",
    "        trp_lb_mean = feat_period[\"TRP\"].groupby(level=\"Ticker\").mean()\n",
    "\n",
    "        # --- NEW DECOUPLED AUDIT LOGIC ---\n",
    "        feat_now = engine.features_df.xs(res.decision_date, level=\"Date\").reindex(\n",
    "            survivors\n",
    "        )\n",
    "\n",
    "        # Pull the macro snapshot for the specific decision date\n",
    "        macro_now = engine.macro_df.loc[res.decision_date]\n",
    "\n",
    "        lb_prices = engine.df_close.loc[res.start_date : res.decision_date, survivors]\n",
    "\n",
    "        # REBUILD OBSERVATION\n",
    "        audit_obs: MarketObservation = {\n",
    "            \"lookback_close\": lb_prices,\n",
    "            \"lookback_returns\": lb_prices.ffill().pct_change(),\n",
    "            \"atrp\": atrp_lb_mean,\n",
    "            \"trp\": trp_lb_mean,\n",
    "            \"atr\": feat_now.get(\"ATR\"),\n",
    "            \"rsi\": feat_now[\"RSI\"],\n",
    "            \"consistency\": feat_now[\"Consistency\"],\n",
    "            \"mom_21\": feat_now[\"Mom_21\"],\n",
    "            \"ir_63\": feat_now[\"IR_63\"],\n",
    "            \"beta_63\": feat_now[\"Beta_63\"],\n",
    "            \"dd_21\": feat_now[\"DD_21\"],\n",
    "            # PULL FROM macro_now (Single Index Series)\n",
    "            \"macro_trend\": macro_now[\"Macro_Trend\"],\n",
    "            \"macro_vix_z\": macro_now[\"Macro_Vix_Z\"],\n",
    "            \"macro_vix_ratio\": macro_now[\"Macro_Vix_Ratio\"],\n",
    "        }\n",
    "\n",
    "        # Run Manual Registry Math on Full Universe\n",
    "        manual_scores = METRIC_REGISTRY[inputs.metric](audit_obs)\n",
    "\n",
    "        # Compare\n",
    "        audit_data = []\n",
    "        for i, (ticker, row) in enumerate(eng_rank_df.iterrows()):\n",
    "            eng_val = row[\"Strategy_Score\"]\n",
    "            man_val = manual_scores.get(ticker, np.nan)\n",
    "            delta = eng_val - man_val\n",
    "\n",
    "            status = \"‚úÖ PASS\" if np.isclose(eng_val, man_val, atol=1e-8) else \"‚ùå FAIL\"\n",
    "\n",
    "            audit_data.append(\n",
    "                {\n",
    "                    \"Rank\": i + 1,\n",
    "                    \"Ticker\": ticker,\n",
    "                    \"Engine\": eng_val,\n",
    "                    \"Manual\": man_val,\n",
    "                    \"Delta\": delta,\n",
    "                    \"Status\": status,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        df_audit_all = pd.DataFrame(audit_data).set_index(\"Rank\")\n",
    "        n_pass = (df_audit_all[\"Status\"] == \"‚úÖ PASS\").sum()\n",
    "        n_fail = len(df_audit_all) - n_pass\n",
    "\n",
    "        print(f\"   Scope: Evaluated {len(df_audit_all)} candidates (Full Universe).\")\n",
    "        print(f\"   Result: {n_pass} PASSED | {n_fail} FAILED\")\n",
    "\n",
    "        if n_fail > 0:\n",
    "            print(\"‚ö†Ô∏è  DISPLAYING FAILURES:\")\n",
    "            display(df_audit_all[df_audit_all[\"Status\"] == \"‚ùå FAIL\"].head(20))\n",
    "        else:\n",
    "            print(\n",
    "                f\"   All scores match registry math. {inputs.metric} results of the first 5 tickers\"\n",
    "            )\n",
    "            display(\n",
    "                df_audit_all.head(5).style.format(\n",
    "                    \"{:.8f}\", subset=[\"Engine\", \"Manual\", \"Delta\"]\n",
    "                )\n",
    "            )\n",
    "\n",
    "    print(\"=\" * 85)\n",
    "\n",
    "\n",
    "def audit_feature_engineering_integrity(analyzer, df_indices=None, mode=\"last_run\"):\n",
    "    \"\"\"\n",
    "    # Usage to check last run, takes about 4 sec.\n",
    "    audit_feature_engineering_integrity(analyzer, mode=\"last_run\")\n",
    "    # Usage to check all df_ohlcv tickers, takes over 4 minutes (i.e. One-time \"Nuclear\" System Sanity Check)\n",
    "    audit_feature_engineering_integrity(analyzer, df_indices=df_indices, mode=\"system\")\n",
    "    \"\"\"\n",
    "    import time\n",
    "    import numpy as np\n",
    "    import warnings\n",
    "\n",
    "    # 0. PULL SETTINGS FROM GLOBAL_SETTINGS (or analyzer.engine.settings if stored there)\n",
    "    # This ensures the auditor uses the EXACT same rules as the engine\n",
    "    atr_p = GLOBAL_SETTINGS[\"atr_period\"]\n",
    "    rsi_p = GLOBAL_SETTINGS[\"rsi_period\"]\n",
    "    win_5 = GLOBAL_SETTINGS[\"5d_window\"]\n",
    "    win_21 = GLOBAL_SETTINGS[\"21d_window\"]\n",
    "    win_63 = GLOBAL_SETTINGS[\"63d_window\"]\n",
    "    q_win = GLOBAL_SETTINGS[\"quality_window\"]\n",
    "    q_min = GLOBAL_SETTINGS[\"quality_min_periods\"]\n",
    "\n",
    "    start_time = time.time()\n",
    "    engine = analyzer.engine\n",
    "    features_df = engine.features_df\n",
    "    df_ohlcv = engine.df_ohlcv_raw\n",
    "\n",
    "    # 1. Scope Selection\n",
    "    if mode == \"last_run\" and analyzer.last_run:\n",
    "        audit_tickers = analyzer.last_run.tickers\n",
    "        features_to_audit = features_df.loc[pd.IndexSlice[audit_tickers, :], :]\n",
    "        ohlcv_to_audit = df_ohlcv.loc[pd.IndexSlice[audit_tickers, :], :]\n",
    "    else:\n",
    "        audit_tickers = features_df.index.get_level_values(0).unique()\n",
    "        features_to_audit = features_df\n",
    "        ohlcv_to_audit = df_ohlcv\n",
    "\n",
    "    print(f\"\\n{'='*95}\")\n",
    "    print(\n",
    "        f\"üïµÔ∏è  NUCLEAR FEATURE AUDIT | Mode: {mode.upper()} | Tickers: {len(audit_tickers)}\"\n",
    "    )\n",
    "    print(f\"{'='*95}\")\n",
    "\n",
    "    # STEP 1: BOUNDARY INTEGRITY\n",
    "    leaks = features_to_audit.groupby(level=0).head(1)[\"Ret_1d\"].dropna().count()\n",
    "    leak_status = \"‚úÖ PASS\" if leaks == 0 else f\"‚ùå FAIL ({leaks} leaks)\"\n",
    "    print(f\"STEP 1: BOUNDARY INTEGRITY   | MultiIndex Isolation Check | {leak_status}\")\n",
    "\n",
    "    # STEP 2: SHADOW CALCULATION\n",
    "    print(\n",
    "        f\"STEP 2: SHADOW CALCULATIONS  | Re-computing metrics... \", end=\"\", flush=True\n",
    "    )\n",
    "\n",
    "    adj_close = ohlcv_to_audit[\"Adj Close\"]\n",
    "    adj_high = ohlcv_to_audit[\"Adj High\"]\n",
    "    adj_low = ohlcv_to_audit[\"Adj Low\"]\n",
    "    volume = ohlcv_to_audit[\"Volume\"]\n",
    "\n",
    "    shadow_data = {}\n",
    "\n",
    "    # A. Returns & Basics\n",
    "    shadow_data[\"shadow_Ret_1d\"] = adj_close.groupby(level=0).pct_change()\n",
    "    prev_close = adj_close.groupby(level=0).shift(1)\n",
    "    tr = pd.concat(\n",
    "        [\n",
    "            adj_high - adj_low,\n",
    "            (adj_high - prev_close).abs(),\n",
    "            (adj_low - prev_close).abs(),\n",
    "        ],\n",
    "        axis=1,\n",
    "    ).max(axis=1, skipna=False)\n",
    "\n",
    "    # B. Smoothing (ATR/RSI) - Use transform for speed and index matching\n",
    "    shadow_data[\"shadow_ATR\"] = tr.groupby(level=0).transform(\n",
    "        lambda x: x.ewm(alpha=1 / atr_p, adjust=False).mean()  # Replaced 14\n",
    "    )\n",
    "\n",
    "    shadow_data[\"shadow_ATRP\"] = shadow_data[\"shadow_ATR\"] / adj_close\n",
    "    shadow_data[\"shadow_TRP\"] = tr / adj_close\n",
    "\n",
    "    # Auditor Step 2B - Shadow RSI with correct Inf/NaN handling\n",
    "    delta = adj_close.groupby(level=0).diff()\n",
    "    up, down = delta.clip(lower=0), (-delta).clip(lower=0)\n",
    "\n",
    "    # Match Wilder's spec correctly:\n",
    "    roll_up = up.groupby(level=0).transform(\n",
    "        lambda x: x.ewm(alpha=1 / rsi_p, adjust=False).mean()  # Replaced 14\n",
    "    )\n",
    "    roll_down = down.groupby(level=0).transform(\n",
    "        lambda x: x.ewm(alpha=1 / rsi_p, adjust=False).mean()  # Replaced 14\n",
    "    )\n",
    "\n",
    "    # FIX: Allow division by zero (i.e. no down day) to create inf (correct RSI=100),\n",
    "    # inf‚Üí100, -inf‚Üí0, NaN‚Üí50\n",
    "    # then clean up remaining NaNs (initial periods/no movement)\n",
    "    # - Initial periods: Before the 14-day lookback is filled, the EWM mean is undefined ‚Üí NaN.\n",
    "    # - Flat prices: If price doesn't move (Avg Up = 0 and Avg Down = 0), RS is 0/0 ‚Üí NaN.\n",
    "    # - By convention, RSI is set to 50 (neutral) when there is no directional momentum.\n",
    "    rs = roll_up / roll_down  # Keep zero denominator ‚Üí inf\n",
    "    raw_rsi = 100 - (100 / (1 + rs))\n",
    "    shadow_data[\"shadow_RSI\"] = raw_rsi.replace({np.inf: 100, -np.inf: 0}).fillna(50)\n",
    "\n",
    "    # C. Momentum & Consistency\n",
    "    shadow_data[f\"shadow_Mom_{win_21}\"] = adj_close.groupby(level=0).pct_change(win_21)\n",
    "    pos_ret = (shadow_data[\"shadow_Ret_1d\"] > 0).astype(float)\n",
    "    shadow_data[\"shadow_Consistency\"] = pos_ret.groupby(level=0).transform(\n",
    "        lambda x: x.rolling(win_5).mean()\n",
    "    )\n",
    "\n",
    "    # D. Risk (Beta & IR)\n",
    "    if df_indices is not None:\n",
    "        try:\n",
    "            # USE THIS: Pull the single source of truth from the engine\n",
    "            mkt_ret = engine.macro_df[\"Mkt_Ret\"]\n",
    "            # Map it to the audit tickers\n",
    "            mkt_series = mkt_ret.reindex(\n",
    "                ohlcv_to_audit.index.get_level_values(1)\n",
    "            ).values\n",
    "            mkt_series = pd.Series(mkt_series, index=ohlcv_to_audit.index)\n",
    "\n",
    "            # Shadow Beta\n",
    "            s_ret = shadow_data[\"shadow_Ret_1d\"]\n",
    "            shadow_data[f\"shadow_Beta_{win_63}\"] = (\n",
    "                s_ret.groupby(level=0)\n",
    "                .transform(\n",
    "                    lambda x: x.rolling(win_63).cov(\n",
    "                        mkt_ret.reindex(x.index.get_level_values(1))\n",
    "                    )\n",
    "                    / mkt_ret.reindex(x.index.get_level_values(1)).rolling(win_63).var()\n",
    "                )\n",
    "                .fillna(1.0)\n",
    "            )\n",
    "\n",
    "            # Shadow IR\n",
    "            active_ret = s_ret - mkt_series\n",
    "            shadow_data[\"shadow_IR_63\"] = (\n",
    "                active_ret.groupby(level=0)\n",
    "                .transform(lambda x: x.rolling(win_63).mean() / x.rolling(win_63).std())\n",
    "                .fillna(0.0)\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" (Macro Shadow Error: {e}) \", end=\"\")\n",
    "\n",
    "    # E. Drawdown & Quality\n",
    "    roll_max_21 = adj_close.groupby(level=0).transform(\n",
    "        lambda x: x.rolling(win_21).max()\n",
    "    )\n",
    "    shadow_data[f\"shadow_DD_{win_21}\"] = (adj_close / roll_max_21 - 1).fillna(0.0)\n",
    "    stale_mask = ((volume == 0) | (adj_high == adj_low)).astype(int)\n",
    "\n",
    "    shadow_data[\"shadow_RollingStalePct\"] = stale_mask.groupby(level=0).transform(\n",
    "        lambda x: x.rolling(q_win, min_periods=q_min).mean()\n",
    "    )\n",
    "    dollar_vol = adj_close * volume\n",
    "    shadow_data[\"shadow_RollMedDollarVol\"] = dollar_vol.groupby(level=0).transform(\n",
    "        lambda x: x.rolling(q_win, min_periods=q_min).median()  # Replaced 252, 126\n",
    "    )\n",
    "\n",
    "    same_vol = (volume.groupby(level=0).diff() == 0).astype(int)\n",
    "    shadow_data[\"shadow_RollingSameVolCount\"] = same_vol.groupby(level=0).transform(\n",
    "        lambda x: x.rolling(q_win, min_periods=q_min).sum()  # Replaced 252, 126\n",
    "    )\n",
    "\n",
    "    # Build Final Shadow DF\n",
    "    audit_df = pd.DataFrame(shadow_data, index=ohlcv_to_audit.index)\n",
    "    print(f\"DONE ({time.time()-start_time:.2f}s)\")\n",
    "\n",
    "    # STEP 3: RECONCILIATION REPORT\n",
    "    print(f\"\\n{'Metric':<20} | {'Max Delta':<12} | {'Correlation':<12} | {'Status'}\")\n",
    "    print(\"-\" * 85)\n",
    "\n",
    "    cols_to_check = [\n",
    "        \"Ret_1d\",\n",
    "        \"ATR\",\n",
    "        \"ATRP\",\n",
    "        \"TRP\",\n",
    "        \"RSI\",\n",
    "        \"Mom_21\",\n",
    "        \"Consistency\",\n",
    "        \"Beta_63\",\n",
    "        \"IR_63\",\n",
    "        \"DD_21\",\n",
    "        \"RollingStalePct\",\n",
    "        \"RollMedDollarVol\",\n",
    "        \"RollingSameVolCount\",\n",
    "    ]\n",
    "\n",
    "    for col in cols_to_check:\n",
    "        sha_col = f\"shadow_{col}\"\n",
    "        if sha_col not in audit_df.columns:\n",
    "            continue\n",
    "\n",
    "        eng, sha = features_to_audit[col], audit_df[sha_col]\n",
    "        # Align and drop NaNs for comparison\n",
    "        mask = eng.notna() & sha.notna()\n",
    "        if not mask.any():\n",
    "            continue\n",
    "\n",
    "        e_v, s_v = eng[mask], sha[mask]\n",
    "\n",
    "        delta = (e_v - s_v).abs().max()\n",
    "\n",
    "        # Suppress the NumPy \"Subtract\" warning during correlation of constant series\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "            # If standard deviation is 0, correlation is undefined; if eng matches Shadow Calculation, we treat as 1.0\n",
    "            if e_v.std() == 0:\n",
    "                corr = 1.0 if delta < 1e-6 else 0.0\n",
    "            else:\n",
    "                corr = e_v.corr(s_v)\n",
    "\n",
    "        status = \"‚úÖ PASS\" if (delta < 1e-6 or corr > 0.99999) else \"‚ùå FAIL\"\n",
    "        print(f\"{col:<20} | {delta:>12.4e} | {corr:>12.6f} | {status}\")\n",
    "\n",
    "    vix_z = engine.macro_df[\"Macro_Vix_Z\"].abs().max()\n",
    "    print(\n",
    "        f\"{'Macro_Vix_Signals':<20} | {'N/A':<12} | {'N/A':<12} | {'‚úÖ LIVE' if vix_z > 0 else '‚ùå MISSING VIX, VIX3M'}\"\n",
    "    )\n",
    "    print(f\"{'='*95}\")\n",
    "\n",
    "\n",
    "def verify_macro_engine(df_ohlcv, df_indices, original_macro_df, settings):\n",
    "    \"\"\"\n",
    "    Independently verifies the macro_df calculation logic using GLOBAL_SETTINGS.\n",
    "    \"\"\"\n",
    "    print(f\"--- Macro Verification (Benchmark: {settings['benchmark_ticker']}) ---\")\n",
    "\n",
    "    # 1. Setup Skeleton\n",
    "    all_dates = df_ohlcv.index.get_level_values(\"Date\").unique().sort_values()\n",
    "    v_df = pd.DataFrame(index=all_dates)\n",
    "\n",
    "    # Constants from GLOBAL_SETTINGS\n",
    "    benchmark = settings[\"benchmark_ticker\"]\n",
    "    win_21 = settings[\"21d_window\"]\n",
    "    win_63 = settings[\"63d_window\"]\n",
    "    z_clip = settings[\"feature_zscore_clip\"]\n",
    "\n",
    "    # 2. Market Return & Trend Calculation\n",
    "    # Logic: Uses 200-day SMA for the trend anchor\n",
    "    if benchmark in df_ohlcv.index.get_level_values(\"Ticker\"):\n",
    "        mkt_close = (\n",
    "            df_ohlcv.xs(benchmark, level=\"Ticker\")[\"Adj Close\"]\n",
    "            .reindex(all_dates)\n",
    "            .ffill()\n",
    "        )\n",
    "        v_df[\"Mkt_Ret\"] = mkt_close.pct_change().fillna(0.0)\n",
    "        v_df[\"Macro_Trend\"] = (mkt_close / mkt_close.rolling(200).mean()) - 1.0\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Warning: {benchmark} not found in OHLCV. Defaulting to 0.0.\")\n",
    "        v_df[\"Mkt_Ret\"] = 0.0\n",
    "        v_df[\"Macro_Trend\"] = 0.0\n",
    "\n",
    "    # 3. Trend Velocity & Momentum logic\n",
    "    v_df[\"Macro_Trend_Vel\"] = v_df[\"Macro_Trend\"].diff(win_21)\n",
    "\n",
    "    # Z-Score of Velocity normalized by 63d rolling volatility of the Trend itself\n",
    "    v_df[\"Macro_Trend_Vel_Z\"] = (\n",
    "        v_df[\"Macro_Trend_Vel\"] / v_df[\"Macro_Trend\"].rolling(win_63).std()\n",
    "    ).clip(-z_clip, z_clip)\n",
    "\n",
    "    # Momentum: Sign agreement between level and direction\n",
    "    v_df[\"Macro_Trend_Mom\"] = (\n",
    "        np.sign(v_df[\"Macro_Trend\"])\n",
    "        * np.sign(v_df[\"Macro_Trend_Vel\"])\n",
    "        * np.abs(v_df[\"Macro_Trend_Vel\"])\n",
    "    ).fillna(0)\n",
    "\n",
    "    # 4. VIX Engine Logic\n",
    "    v_df[\"Macro_Vix_Z\"] = 0.0\n",
    "    v_df[\"Macro_Vix_Ratio\"] = 1.0\n",
    "\n",
    "    if df_indices is not None:\n",
    "        idx_names = df_indices.index.get_level_values(0).unique()\n",
    "        if \"^VIX\" in idx_names:\n",
    "            vix = df_indices.xs(\"^VIX\", level=0)[\"Adj Close\"].reindex(all_dates).ffill()\n",
    "            # VIX Z-score over 63 days\n",
    "            v_df[\"Macro_Vix_Z\"] = (\n",
    "                (vix - vix.rolling(63).mean()) / vix.rolling(63).std()\n",
    "            ).clip(-z_clip, z_clip)\n",
    "\n",
    "            if \"^VIX3M\" in idx_names:\n",
    "                vix3m = (\n",
    "                    df_indices.xs(\"^VIX3M\", level=0)[\"Adj Close\"]\n",
    "                    .reindex(all_dates)\n",
    "                    .ffill()\n",
    "                )\n",
    "                v_df[\"Macro_Vix_Ratio\"] = (vix / vix3m).fillna(1.0)\n",
    "\n",
    "    # Final cleanup to match original function\n",
    "    v_df.fillna(0.0, inplace=True)\n",
    "\n",
    "    # 5. Validation Loop\n",
    "    print(f\"\\nComparing verification vs original (Clip Threshold: {z_clip}):\")\n",
    "    match_all = True\n",
    "    for col in original_macro_df.columns:\n",
    "        if col not in v_df.columns:\n",
    "            print(f\"‚ùå Column '{col}' missing in verification code.\")\n",
    "            match_all = False\n",
    "            continue\n",
    "\n",
    "        # Use a tolerance for floating point math\n",
    "        diff = np.abs(original_macro_df[col] - v_df[col])\n",
    "        max_err = diff.max()\n",
    "\n",
    "        if max_err < 1e-9:\n",
    "            print(f\"‚úÖ {col:<20} | PASS (Max Diff: {max_err:.2e})\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è {col:<20} | FAIL (Max Diff: {max_err:.2e})\")\n",
    "            match_all = False\n",
    "\n",
    "    return v_df if not match_all else None\n",
    "\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a48017a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SECTION H: UTILITIES\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "def export_debug_to_csv(audit_pack, source_label=\"Audit\"):\n",
    "    \"\"\"\n",
    "    High-Transparency Exporter (Hardened Version).\n",
    "    Dumps the entire simulation state into a folder for manual Excel verification.\n",
    "    \"\"\"\n",
    "    if not audit_pack or not audit_pack[0]:\n",
    "        print(\"‚ùå Error: Audit Pack is empty. Run a simulation first.\")\n",
    "        return\n",
    "\n",
    "    data = audit_pack[0]\n",
    "    # Handle the fact that 'inputs' might be a key or a dataclass attribute\n",
    "    inputs = data.get(\"inputs\")\n",
    "\n",
    "    # 1. Folder Setup\n",
    "    date_str = inputs.start_date.strftime(\"%Y-%m-%d\")\n",
    "    strat = inputs.metric.replace(\" \", \"\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "    folder_name = f\"{source_label}_{strat}_{date_str}\"\n",
    "\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    print(f\"üìÇ [AUDIT EXPORT] Folder: ./{folder_name}/\")\n",
    "\n",
    "    def process_item(item, path_prefix=\"\"):\n",
    "        # A. Handle Nested Dicts\n",
    "        if isinstance(item, dict):\n",
    "            for k, v in item.items():\n",
    "                process_item(v, f\"{path_prefix}{k}_\" if path_prefix else f\"{k}_\")\n",
    "\n",
    "        # B. Handle DataFrames (Matrices - High Precision)\n",
    "        elif isinstance(item, pd.DataFrame):\n",
    "            fn = f\"Matrix_{path_prefix.strip('_')}.csv\"\n",
    "            item.to_csv(os.path.join(folder_name, fn), float_format=\"%.8f\")\n",
    "            print(f\"   ‚úÖ Matrix: {fn}\")\n",
    "\n",
    "        # C. Handle Series (Vectors)\n",
    "        elif isinstance(item, pd.Series):\n",
    "            fn = f\"Vector_{path_prefix.strip('_')}.csv\"\n",
    "            item.to_frame().to_csv(os.path.join(folder_name, fn), float_format=\"%.8f\")\n",
    "            print(f\"   ‚úÖ Vector: {fn}\")\n",
    "\n",
    "        # D. Handle Dataclasses (Metadata & Results)\n",
    "        elif is_dataclass(item):\n",
    "            class_name = item.__class__.__name__\n",
    "            fn = f\"Summary_{class_name}_{path_prefix.strip('_')}\".strip(\"_\") + \".csv\"\n",
    "\n",
    "            # --- THE FIX: Create a Safe Dictionary for Pandas ---\n",
    "            raw_dict = asdict(item)\n",
    "            summary_ready_dict = {}\n",
    "\n",
    "            for k, v in raw_dict.items():\n",
    "                # If it's a big data object, just note its existence in the summary\n",
    "                if isinstance(v, (pd.DataFrame, pd.Series)):\n",
    "                    summary_ready_dict[k] = f\"<{v.__class__.__name__} shape={v.shape}>\"\n",
    "                # If it's a list or dict (the crash cause), stringify it for Excel\n",
    "                elif isinstance(v, (list, dict)):\n",
    "                    summary_ready_dict[k] = str(v)\n",
    "                else:\n",
    "                    summary_ready_dict[k] = v\n",
    "\n",
    "            # Save the clean key-value summary\n",
    "            pd.DataFrame.from_dict(\n",
    "                summary_ready_dict, orient=\"index\", columns=[\"Value\"]\n",
    "            ).to_csv(os.path.join(folder_name, fn))\n",
    "            print(f\"   üìë Summary: {fn}\")\n",
    "\n",
    "            # E. RECURSION: Now find the actual DataFrames inside the dataclass\n",
    "            # We iterate the object attributes directly to avoid the 'asdict' list confusion\n",
    "            for k in item.__dataclass_fields__.keys():\n",
    "                val = getattr(item, k)\n",
    "                if isinstance(val, (pd.DataFrame, pd.Series, dict)):\n",
    "                    process_item(val, f\"{path_prefix}{k}_\")\n",
    "\n",
    "    # 3. Execute Extraction\n",
    "    process_item(data)\n",
    "    print(f\"\\n‚ú® Export Complete. Open ./{folder_name}/ to verify results.\")\n",
    "\n",
    "\n",
    "def export_audit_to_excel(audit_pack, filename=\"Audit_Verification_Report.xlsx\"):\n",
    "    \"\"\"\n",
    "    Final Zero-Base Audit Export.\n",
    "    Provides everything needed to reconstruct the Strategy results from raw candles.\n",
    "    Usage: export_audit_to_excel(analyzer1.last_run)\n",
    "    \"\"\"\n",
    "    if audit_pack is None:\n",
    "        return print(\"‚ùå Error: Audit Pack is empty.\")\n",
    "\n",
    "    # Resolve full output path\n",
    "    output_path = Path(OUTPUT_DIR) / filename\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1. Setup Core References\n",
    "    debug = audit_pack.debug_data or {}\n",
    "    inputs = debug.get(\"inputs_snapshot\")\n",
    "    p_raw = debug.get(\"portfolio_raw_components\", {})\n",
    "    b_raw = debug.get(\"benchmark_raw_components\", {})\n",
    "\n",
    "    dec_date = audit_pack.decision_date\n",
    "    bench_ticker = inputs.benchmark_ticker if inputs else \"Benchmark\"\n",
    "    top_3_tickers = audit_pack.tickers[:3] if audit_pack.tickers else []\n",
    "\n",
    "    print(f\"üìÇ [EXCEL AUDIT] Building full transparency report: {output_path}\")\n",
    "\n",
    "    with pd.ExcelWriter(output_path, engine=\"openpyxl\") as writer:\n",
    "\n",
    "        # --- SHEET 1: OVERVIEW (Settings & Results) ---\n",
    "        meta = {**asdict(inputs)} if inputs else {}\n",
    "        meta.update(audit_pack.perf_metrics or {})\n",
    "        pd.DataFrame.from_dict(\n",
    "            {k: str(v) for k, v in meta.items()}, orient=\"index\", columns=[\"Value\"]\n",
    "        ).to_excel(writer, sheet_name=\"OVERVIEW\")\n",
    "\n",
    "        # --- SHEET 2: DAILY_AUDIT (The Timeline + Period Labels) ---\n",
    "        daily = {\n",
    "            \"Port_Value\": audit_pack.portfolio_series,\n",
    "            \"Port_ATRP\": audit_pack.portfolio_atrp_series,\n",
    "            \"Port_TRP\": audit_pack.portfolio_trp_series,\n",
    "            \"Bench_Value\": audit_pack.benchmark_series,\n",
    "            \"Bench_ATRP\": audit_pack.benchmark_atrp_series,\n",
    "            \"Bench_TRP\": audit_pack.benchmark_trp_series,\n",
    "        }\n",
    "        if audit_pack.portfolio_series is not None:\n",
    "            daily[\"Port_Ret\"] = QuantUtils.compute_returns(audit_pack.portfolio_series)\n",
    "        if audit_pack.benchmark_series is not None:\n",
    "            daily[\"Bench_Ret\"] = QuantUtils.compute_returns(audit_pack.benchmark_series)\n",
    "\n",
    "        df_daily = pd.concat({k: v for k, v in daily.items() if v is not None}, axis=1)\n",
    "\n",
    "        # Add Period Label Column for Excel Range Selection\n",
    "        df_daily[\"Period_Label\"] = np.where(\n",
    "            df_daily.index <= dec_date, \"LOOKBACK\", \"HOLDING\"\n",
    "        )\n",
    "        df_daily.to_excel(writer, sheet_name=\"DAILY_AUDIT\")\n",
    "\n",
    "        # --- SHEET 3: RAW_OHLCV_SAMPLES (Spot Check for 3 Tickers + Benchmark) ---\n",
    "        ohlcv_list = []\n",
    "        # Get Benchmark OHLCV\n",
    "        if (b_ohlcv := b_raw.get(\"ohlcv_raw\")) is not None:\n",
    "            b_temp = b_ohlcv.copy()\n",
    "            b_temp[\"Ticker\"] = bench_ticker\n",
    "            ohlcv_list.append(b_temp)\n",
    "        # Get Top 3 Tickers OHLCV\n",
    "        if (p_ohlcv := p_raw.get(\"ohlcv_raw\")) is not None:\n",
    "            # Assuming ohlcv_raw index or column identifies ticker\n",
    "            # If it's a MultiIndex (Date, Ticker), we filter. Otherwise, we assume tidy.\n",
    "            if isinstance(p_ohlcv.index, pd.MultiIndex):\n",
    "                sample_p = p_ohlcv.query(\"Ticker in @top_3_tickers\")\n",
    "                ohlcv_list.append(sample_p.reset_index())\n",
    "            else:\n",
    "                # Fallback: Filter by 'ticker' column if it exists\n",
    "                col_name = \"ticker\" if \"ticker\" in p_ohlcv.columns else \"Ticker\"\n",
    "                if col_name in p_ohlcv.columns:\n",
    "                    ohlcv_list.append(p_ohlcv[p_ohlcv[col_name].isin(top_3_tickers)])\n",
    "\n",
    "        if ohlcv_list:\n",
    "            pd.concat(ohlcv_list).to_excel(\n",
    "                writer, sheet_name=\"RAW_OHLCV_SAMPLES\", index=False\n",
    "            )\n",
    "\n",
    "        # --- SHEET 4, 5, 6: MERGED MATRICES (Price, ATRP, TRP) ---\n",
    "        for sheet_name, key in [\n",
    "            (\"RAW_PRICES\", \"prices\"),\n",
    "            (\"RAW_ATRP_DATA\", \"atrp\"),\n",
    "            (\"RAW_TRP_DATA\", \"trp\"),\n",
    "        ]:\n",
    "            p_df, b_df = p_raw.get(key), b_raw.get(key)\n",
    "            if p_df is not None and b_df is not None:\n",
    "                pd.concat(\n",
    "                    [p_df, b_df.rename(columns={b_df.columns[0]: bench_ticker})], axis=1\n",
    "                ).to_excel(writer, sheet_name=sheet_name)\n",
    "\n",
    "        # --- SHEET 7: RAW_DRIFTED_WEIGHTS ---\n",
    "        if (p_prices := p_raw.get(\"prices\")) is not None:\n",
    "            weights_ser = pd.Series(\n",
    "                audit_pack.initial_weights, index=audit_pack.tickers\n",
    "            )\n",
    "            norm_p = p_prices.div(p_prices.bfill().iloc[0])\n",
    "            weighted = norm_p.mul(weights_ser, axis=1)\n",
    "            drift_weights = weighted.div(weighted.sum(axis=1), axis=0)\n",
    "            drift_weights.to_excel(writer, sheet_name=\"RAW_DRIFTED_WEIGHTS\")\n",
    "\n",
    "        # --- SHEET 8: SURVIVAL_AUDIT (Layer 1 Filter Verification) ---\n",
    "        if liq_audit := debug.get(\"audit_liquidity\", {}):\n",
    "            if (snap := liq_audit.get(\"universe_snapshot\")) is not None:\n",
    "                snap.to_excel(writer, sheet_name=\"SURVIVAL_AUDIT\")\n",
    "\n",
    "        # --- SHEET 9: FULL_RANKING ---\n",
    "        if (df_rank := debug.get(\"full_universe_ranking\")) is not None:\n",
    "            df_rank.to_excel(writer, sheet_name=\"FULL_RANKING\")\n",
    "\n",
    "    print(f\"‚ú® Audit Report Complete: {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "\n",
    "def export_last_run_tickers_data_to_csv(\n",
    "    analyzer, df_ohlcv, features_df, filename=\"all_tickers_stacked.csv\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Export the last run ticker data from a WalkForwardAnalyzer to a stacked CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    analyzer : WalkForwardAnalyzer\n",
    "        The analyzer containing last_run data\n",
    "    df_ohlcv : pd.DataFrame\n",
    "        OHLCV data for create_combined_dict\n",
    "    features_df : pd.DataFrame\n",
    "        Features data for create_combined_dict\n",
    "    filename : str\n",
    "        Output filename (saved to OUTPUT_DIR)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Path : Path to saved CSV file\n",
    "    \"\"\"\n",
    "    from core.paths import OUTPUT_DIR\n",
    "\n",
    "    # 1. Access the result object from the analyzer\n",
    "    res = analyzer.last_run\n",
    "\n",
    "    if res is None:\n",
    "        raise ValueError(\n",
    "            \"‚ùå No results found in analyzer. Please click 'Run Simulation' first.\"\n",
    "        )\n",
    "\n",
    "    # 2. Extract attributes directly (No [0] needed)\n",
    "    benchmark = res.debug_data[\"inputs_snapshot\"].benchmark_ticker\n",
    "    tickers = res.tickers + [benchmark]\n",
    "    start_date = res.start_date\n",
    "    end_date = res.holding_end_date  # Note: I use end_date, not decision_date/buy_date\n",
    "\n",
    "    # 3. Generate the combined dict\n",
    "    combined = create_combined_dict(\n",
    "        df_ohlcv=df_ohlcv.copy(),\n",
    "        features_df=features_df,\n",
    "        tickers=tickers,\n",
    "        date_start=start_date,\n",
    "        date_end=end_date,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # 4. Print ticker data (optional ‚Äî remove if not needed)\n",
    "    for ticker in tickers:\n",
    "        with pd.option_context(\"display.float_format\", \"{:.8f}\".format):\n",
    "            print(f\"{ticker}:\\n{combined[ticker][start_date:end_date]}\\n\")\n",
    "\n",
    "    # 5. Save ticker data to CSV\n",
    "    file_path = OUTPUT_DIR / filename\n",
    "\n",
    "    # Save first ticker with header\n",
    "    first_ticker = tickers[0]\n",
    "    df_first = combined[first_ticker][start_date:end_date].reset_index()\n",
    "    df_first[\"Ticker\"] = first_ticker\n",
    "\n",
    "    df_first.to_csv(file_path, header=True, index=False, lineterminator=\"\\n\")\n",
    "    print(f\"‚úì Saved {first_ticker} with header\")\n",
    "\n",
    "    # Append remaining tickers without header\n",
    "    for ticker in tickers[1:]:\n",
    "        df = combined[ticker][start_date:end_date].reset_index()\n",
    "        df[\"Ticker\"] = ticker\n",
    "\n",
    "        df.to_csv(file_path, header=False, index=False, lineterminator=\"\\n\", mode=\"a\")\n",
    "        print(f\"‚úì Appended {ticker}\")\n",
    "\n",
    "    print(f\"\\n‚úì Saved all tickers to: {file_path}\")\n",
    "\n",
    "    return file_path\n",
    "\n",
    "\n",
    "def print_nested(d, indent=0, width=4):\n",
    "    \"\"\"Pretty-print nested containers.\n",
    "    Leaves are rendered as two lines:  key\\\\nvalue .\"\"\"\n",
    "    spacing = \" \" * indent\n",
    "\n",
    "    def _kind(node):\n",
    "        if not isinstance(node, dict):\n",
    "            return None\n",
    "        return \"sep\" if all(isinstance(v, dict) for v in node.values()) else \"nest\"\n",
    "\n",
    "    if isinstance(d, dict):\n",
    "        for k, v in d.items():\n",
    "            kind = _kind(v)\n",
    "            tag = \"\" if kind is None else f\"  [{'SEP' if kind == 'sep' else 'NEST'}]\"\n",
    "            print(f\"{spacing}{k}{tag}\")\n",
    "            print_nested(v, indent + width, width)\n",
    "\n",
    "    elif isinstance(d, (list, tuple)):\n",
    "        for idx, item in enumerate(d):\n",
    "            print(f\"{spacing}[{idx}]\")\n",
    "            print_nested(item, indent + width, width)\n",
    "\n",
    "    else:  # leaf ‚Äì primitive value\n",
    "        print(f\"{spacing}{d}\")\n",
    "\n",
    "\n",
    "def get_ticker_OHLCV(\n",
    "    df_ohlcv: pd.DataFrame,\n",
    "    tickers: Union[str, List[str]],\n",
    "    date_start: str,\n",
    "    date_end: str,\n",
    "    return_format: str = \"dataframe\",\n",
    "    verbose: bool = True,\n",
    ") -> Union[pd.DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    Get OHLCV data for specified tickers within a date range.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_ohlcv : pd.DataFrame\n",
    "        DataFrame with MultiIndex of (ticker, date) and OHLCV columns\n",
    "    tickers : str or list of str\n",
    "        Ticker symbol(s) to retrieve\n",
    "    date_start : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    date_end : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    return_format : str, optional\n",
    "        Format to return data in. Options:\n",
    "        - 'dataframe': Single DataFrame with MultiIndex (default)\n",
    "        - 'dict': Dictionary with tickers as keys and DataFrames as values\n",
    "        - 'separate': List of separate DataFrames for each ticker\n",
    "    verbose : bool, optional\n",
    "        Whether to print summary information (default: True)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Union[pd.DataFrame, dict, list]\n",
    "        Filtered OHLCV data in specified format\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If input parameters are invalid\n",
    "    KeyError\n",
    "        If tickers not found in DataFrame\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> # Get data for single ticker\n",
    "    >>> vlo_data = get_ticker_OHLCV(df_ohlcv, 'VLO', '2025-08-13', '2025-09-04')\n",
    "\n",
    "    >>> # Get data for multiple tickers\n",
    "    >>> multi_data = get_ticker_OHLCV(df_ohlcv, ['VLO', 'JPST'], '2025-08-13', '2025-09-04')\n",
    "\n",
    "    >>> # Get data as dictionary\n",
    "    >>> data_dict = get_ticker_OHLCV(df_ohlcv, ['VLO', 'JPST'], '2025-08-13',\n",
    "    ...                              '2025-09-04', return_format='dict')\n",
    "    \"\"\"\n",
    "\n",
    "    # Input validation\n",
    "    if not isinstance(df_ohlcv, pd.DataFrame):\n",
    "        raise TypeError(\"df_ohlcv must be a pandas DataFrame\")\n",
    "\n",
    "    if not isinstance(df_ohlcv.index, pd.MultiIndex):\n",
    "        raise ValueError(\"DataFrame must have MultiIndex of (ticker, date)\")\n",
    "\n",
    "    if len(df_ohlcv.index.levels) != 2:\n",
    "        raise ValueError(\"MultiIndex must have exactly 2 levels: (ticker, date)\")\n",
    "\n",
    "    # Convert single ticker to list for consistent processing\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "    elif not isinstance(tickers, list):\n",
    "        raise TypeError(\"tickers must be a string or list of strings\")\n",
    "\n",
    "    # Convert dates to Timestamps\n",
    "    try:\n",
    "        start_date = pd.Timestamp(date_start)\n",
    "        end_date = pd.Timestamp(date_end)\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"Invalid date format. Use 'YYYY-MM-DD': {e}\")\n",
    "\n",
    "    if start_date > end_date:\n",
    "        raise ValueError(\"date_start must be before or equal to date_end\")\n",
    "\n",
    "    # Check if tickers exist in the DataFrame\n",
    "    available_tickers = df_ohlcv.index.get_level_values(0).unique()\n",
    "    missing_tickers = [t for t in tickers if t not in available_tickers]\n",
    "\n",
    "    if missing_tickers:\n",
    "        raise KeyError(f\"Ticker(s) not found in DataFrame: {missing_tickers}\")\n",
    "\n",
    "    # Filter the data using MultiIndex slicing\n",
    "    try:\n",
    "        filtered_data = df_ohlcv.loc[(tickers, slice(date_start, date_end)), :]\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error filtering data: {e}\")\n",
    "\n",
    "    # Handle empty results\n",
    "    if filtered_data.empty:\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"No data found for tickers {tickers} in date range {date_start} to {date_end}\"\n",
    "            )\n",
    "        return filtered_data\n",
    "\n",
    "    # Print summary if verbose\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"Data retrieved for {len(tickers)} ticker(s) from {date_start} to {date_end}\"\n",
    "        )\n",
    "        print(f\"Total rows: {len(filtered_data)}\")\n",
    "        print(\n",
    "            f\"Date range in data: {filtered_data.index.get_level_values(1).min()} to \"\n",
    "            f\"{filtered_data.index.get_level_values(1).max()}\"\n",
    "        )\n",
    "\n",
    "        # Print ticker-specific counts\n",
    "        ticker_counts = filtered_data.index.get_level_values(0).value_counts()\n",
    "        for ticker in tickers:\n",
    "            count = ticker_counts.get(ticker, 0)\n",
    "            if count > 0:\n",
    "                print(f\"  {ticker}: {count} rows\")\n",
    "            else:\n",
    "                print(f\"  {ticker}: No data in range\")\n",
    "\n",
    "    # Return in requested format\n",
    "    if return_format == \"dict\":\n",
    "        result = {}\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result[ticker] = filtered_data.xs(ticker, level=0).loc[\n",
    "                    date_start:date_end\n",
    "                ]\n",
    "            except KeyError:\n",
    "                result[ticker] = pd.DataFrame()\n",
    "        return result\n",
    "\n",
    "    elif return_format == \"separate\":\n",
    "        result = []\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result.append(\n",
    "                    filtered_data.xs(ticker, level=0).loc[date_start:date_end]\n",
    "                )\n",
    "            except KeyError:\n",
    "                result.append(pd.DataFrame())\n",
    "        return result\n",
    "\n",
    "    elif return_format == \"dataframe\":\n",
    "        return filtered_data\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Invalid return_format: {return_format}. \"\n",
    "            f\"Must be 'dataframe', 'dict', or 'separate'\"\n",
    "        )\n",
    "\n",
    "\n",
    "def get_ticker_features(\n",
    "    features_df: pd.DataFrame,\n",
    "    tickers: Union[str, List[str]],\n",
    "    date_start: str,\n",
    "    date_end: str,\n",
    "    return_format: str = \"dataframe\",\n",
    "    verbose: bool = True,\n",
    ") -> Union[pd.DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    Get features data for specified tickers within a date range.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    features_df : pd.DataFrame\n",
    "        DataFrame with MultiIndex of (ticker, date) and feature columns\n",
    "    tickers : str or list of str\n",
    "        Ticker symbol(s) to retrieve\n",
    "    date_start : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    date_end : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    return_format : str, optional\n",
    "        Format to return data in. Options:\n",
    "        - 'dataframe': Single DataFrame with MultiIndex (default)\n",
    "        - 'dict': Dictionary with tickers as keys and DataFrames as values\n",
    "        - 'separate': List of separate DataFrames for each ticker\n",
    "    verbose : bool, optional\n",
    "        Whether to print summary information (default: True)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Union[pd.DataFrame, dict, list]\n",
    "        Filtered features data in specified format\n",
    "    \"\"\"\n",
    "    # Convert single ticker to list for consistent processing\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "\n",
    "    # Filter the data using MultiIndex slicing\n",
    "    try:\n",
    "        filtered_data = features_df.loc[(tickers, slice(date_start, date_end)), :]\n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"Error filtering data: {e}\")\n",
    "        return pd.DataFrame() if return_format == \"dataframe\" else {}\n",
    "\n",
    "    # Handle empty results\n",
    "    if filtered_data.empty:\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"No data found for tickers {tickers} in date range {date_start} to {date_end}\"\n",
    "            )\n",
    "        return filtered_data\n",
    "\n",
    "    # Print summary if verbose\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"Features data retrieved for {len(tickers)} ticker(s) from {date_start} to {date_end}\"\n",
    "        )\n",
    "        print(f\"Total rows: {len(filtered_data)}\")\n",
    "        print(\n",
    "            f\"Date range in data: {filtered_data.index.get_level_values(1).min()} to \"\n",
    "            f\"{filtered_data.index.get_level_values(1).max()}\"\n",
    "        )\n",
    "        print(f\"Available features: {', '.join(filtered_data.columns.tolist())}\")\n",
    "\n",
    "        # Print ticker-specific counts\n",
    "        ticker_counts = filtered_data.index.get_level_values(0).value_counts()\n",
    "        for ticker in tickers:\n",
    "            count = ticker_counts.get(ticker, 0)\n",
    "            if count > 0:\n",
    "                print(f\"  {ticker}: {count} rows\")\n",
    "            else:\n",
    "                print(f\"  {ticker}: No data in range\")\n",
    "\n",
    "    # Return in requested format\n",
    "    if return_format == \"dict\":\n",
    "        result = {}\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result[ticker] = filtered_data.xs(ticker, level=0).loc[\n",
    "                    date_start:date_end\n",
    "                ]\n",
    "            except KeyError:\n",
    "                result[ticker] = pd.DataFrame()\n",
    "        return result\n",
    "\n",
    "    elif return_format == \"separate\":\n",
    "        result = []\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result.append(\n",
    "                    filtered_data.xs(ticker, level=0).loc[date_start:date_end]\n",
    "                )\n",
    "            except KeyError:\n",
    "                result.append(pd.DataFrame())\n",
    "        return result\n",
    "\n",
    "    elif return_format == \"dataframe\":\n",
    "        return filtered_data\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Invalid return_format: {return_format}. \"\n",
    "            f\"Must be 'dataframe', 'dict', or 'separate'\"\n",
    "        )\n",
    "\n",
    "\n",
    "def create_combined_dict(\n",
    "    df_ohlcv: pd.DataFrame,\n",
    "    features_df: pd.DataFrame,\n",
    "    tickers: Union[str, List[str]],\n",
    "    date_start: str,\n",
    "    date_end: str,\n",
    "    verbose: bool = True,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Create a combined dictionary with both OHLCV and features data for each ticker.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_ohlcv : pd.DataFrame\n",
    "        DataFrame with OHLCV data (MultiIndex: ticker, date)\n",
    "    features_df : pd.DataFrame\n",
    "        DataFrame with features data (MultiIndex: ticker, date)\n",
    "    tickers : str or list of str\n",
    "        Ticker symbol(s) to retrieve\n",
    "    date_start : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    date_end : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    verbose : bool, optional\n",
    "        Whether to print progress information (default: True)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with tickers as keys and combined DataFrames (OHLCV + features) as values\n",
    "    \"\"\"\n",
    "    # Convert single ticker to list\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Creating combined dictionary for {len(tickers)} ticker(s)\")\n",
    "        print(f\"Date range: {date_start} to {date_end}\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "    # Get OHLCV data as dictionary\n",
    "    ohlcv_dict = get_ticker_OHLCV(\n",
    "        df_ohlcv, tickers, date_start, date_end, return_format=\"dict\", verbose=verbose\n",
    "    )\n",
    "\n",
    "    # Get features data as dictionary\n",
    "    features_dict = get_ticker_features(\n",
    "        features_df,\n",
    "        tickers,\n",
    "        date_start,\n",
    "        date_end,\n",
    "        return_format=\"dict\",\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "    # Create combined_dict\n",
    "    combined_dict = {}\n",
    "\n",
    "    for ticker in tickers:\n",
    "        if verbose:\n",
    "            print(f\"\\nProcessing {ticker}...\")\n",
    "\n",
    "        # Check if ticker exists in both dictionaries\n",
    "        if ticker in ohlcv_dict and ticker in features_dict:\n",
    "            ohlcv_data = ohlcv_dict[ticker]\n",
    "            features_data = features_dict[ticker]\n",
    "\n",
    "            # Check if both dataframes have data\n",
    "            if not ohlcv_data.empty and not features_data.empty:\n",
    "                # Combine OHLCV and features data\n",
    "                # Note: Both dataframes have the same index (dates), so we can concatenate\n",
    "                combined_df = pd.concat([ohlcv_data, features_data], axis=1)\n",
    "\n",
    "                # Ensure proper index naming\n",
    "                combined_df.index.name = \"Date\"\n",
    "\n",
    "                # Store in combined_dict\n",
    "                combined_dict[ticker] = combined_df\n",
    "\n",
    "                if verbose:\n",
    "                    print(f\"  ‚úì Successfully combined data\")\n",
    "                    print(f\"  OHLCV shape: {ohlcv_data.shape}\")\n",
    "                    print(f\"  Features shape: {features_data.shape}\")\n",
    "                    print(f\"  Combined shape: {combined_df.shape}\")\n",
    "                    print(\n",
    "                        f\"  Date range: {combined_df.index.min()} to {combined_df.index.max()}\"\n",
    "                    )\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"  ‚úó Cannot combine: One or both dataframes are empty\")\n",
    "                    print(f\"    OHLCV empty: {ohlcv_data.empty}\")\n",
    "                    print(f\"    Features empty: {features_data.empty}\")\n",
    "                combined_dict[ticker] = pd.DataFrame()\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(f\"  ‚úó Ticker not found in both dictionaries\")\n",
    "                if ticker not in ohlcv_dict:\n",
    "                    print(f\"    Not in OHLCV data\")\n",
    "                if ticker not in features_dict:\n",
    "                    print(f\"    Not in features data\")\n",
    "            combined_dict[ticker] = pd.DataFrame()\n",
    "\n",
    "    # Print summary\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"SUMMARY\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Total tickers processed: {len(tickers)}\")\n",
    "\n",
    "        tickers_with_data = [\n",
    "            ticker for ticker, df in combined_dict.items() if not df.empty\n",
    "        ]\n",
    "        print(f\"Tickers with combined data: {len(tickers_with_data)}\")\n",
    "\n",
    "        if tickers_with_data:\n",
    "            print(\"\\nTicker details:\")\n",
    "            for ticker in tickers_with_data:\n",
    "                df = combined_dict[ticker]\n",
    "                print(f\"  {ticker}: {df.shape} - {df.index.min()} to {df.index.max()}\")\n",
    "                print(f\"    Columns: {len(df.columns)}\")\n",
    "\n",
    "        empty_tickers = [ticker for ticker, df in combined_dict.items() if df.empty]\n",
    "        if empty_tickers:\n",
    "            print(f\"\\nTickers with no data: {', '.join(empty_tickers)}\")\n",
    "\n",
    "    return combined_dict\n",
    "\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8f2f10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- üõ°Ô∏è Starting Final Integrity Audit ---\n",
      "‚úÖ Series Boundary: OK\n",
      "‚úÖ DataFrame Boundary: OK\n",
      "‚úÖ AUDIT PASSED: Mathematical boundaries are strictly enforced.\n",
      "\n",
      "--- üõ°Ô∏è Starting Feature Engineering Audit ---\n",
      "‚ö° Generating Decoupled Features (Benchmark: SPY)...\n",
      "Audit Values:\n",
      "[ nan 25.  17.5]\n",
      "‚úÖ FEATURE INTEGRITY PASSED: Wilder's ATR logic is strictly enforced.\n",
      "--- üõ°Ô∏è Starting Ranking Kernel Audit ---\n",
      "‚úÖ RANKING INTEGRITY PASSED: Volatility normalization is strictly enforced.\n",
      "\n",
      "--- üõ°Ô∏è Starting Volatility Alignment Audit ---\n",
      "‚úÖ Series Temporal Coupling: OK\n",
      "‚úÖ DataFrame Temporal Coupling: OK\n",
      "‚úÖ AUDIT PASSED: Reward and Risk are strictly synchronized.\n"
     ]
    }
   ],
   "source": [
    "# Auto-run the checks\n",
    "verify_math_integrity()\n",
    "\n",
    "verify_feature_engineering_integrity()\n",
    "\n",
    "verify_ranking_integrity()\n",
    "\n",
    "verify_vol_alignment_integrity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6d867e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_indices:|n                   Adj Open  Adj High  Adj Low  Adj Close  Volume\n",
      "Ticker Date                                                      \n",
      "^AXJO  1992-11-22   1455.00   1455.00  1455.00    1455.00       0\n",
      "       1992-11-23   1458.40   1458.40  1458.40    1458.40       0\n",
      "       1992-11-24   1467.90   1467.90  1467.90    1467.90       0\n",
      "       1992-11-25   1459.00   1459.00  1459.00    1459.00       0\n",
      "       1992-11-26   1458.90   1458.90  1458.90    1458.90       0\n",
      "...                     ...       ...      ...        ...     ...\n",
      "^VIX3M 2026-02-19     21.86     22.37    21.71      21.88       0\n",
      "       2026-02-20     22.39     22.39    20.97      21.09       0\n",
      "       2026-02-23     21.25     22.52    21.13      22.14       0\n",
      "       2026-02-24     22.40     22.66    21.15      21.34       0\n",
      "       2026-02-25     20.82     20.92    20.34      20.36       0\n",
      "\n",
      "[144583 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "data_path = r\"c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_indices.parquet\"\n",
    "\n",
    "df_indices = pd.read_parquet(data_path, engine=\"pyarrow\")\n",
    "print(f\"df_indices:|n{df_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf150180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['^AXJO',\n",
       " '^BSESN',\n",
       " '^DJI',\n",
       " '^FCHI',\n",
       " '^FTSE',\n",
       " '^GDAXI',\n",
       " '^GSPC',\n",
       " '^HSI',\n",
       " '^IXIC',\n",
       " '^N225',\n",
       " '^NYA',\n",
       " '^STOXX50E',\n",
       " '^VIX',\n",
       " '^VIX3M']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 144583 entries, ('^AXJO', Timestamp('1992-11-22 00:00:00')) to ('^VIX3M', Timestamp('2026-02-25 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   Adj Open   144583 non-null  float64\n",
      " 1   Adj High   144583 non-null  float64\n",
      " 2   Adj Low    144583 non-null  float64\n",
      " 3   Adj Close  144583 non-null  float64\n",
      " 4   Volume     144583 non-null  int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "_indices = df_indices.index.get_level_values(0).unique().tolist()\n",
    "display(_indices)\n",
    "df_indices.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "232740e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = (\n",
    "    r\"c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet\"\n",
    ")\n",
    "\n",
    "df_ohlcv = pd.read_parquet(data_path, engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "239275a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_ohlcv.head():\n",
      "                    Adj Open  Adj High  Adj Low  Adj Close    Volume\n",
      "Ticker Date                                                        \n",
      "A      1999-11-18   27.1966   29.8864  23.9091    26.3000  74849943\n",
      "       1999-11-19   25.6649   25.7023  23.7970    24.1333  18230875\n",
      "       1999-11-22   24.6936   26.3000  23.9465    26.3000   7871809\n",
      "       1999-11-23   25.4034   26.0759  23.9091    23.9091   7151080\n",
      "       1999-11-24   23.9838   25.0672  23.9091    24.5442   5795948\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 9486139 entries, ('A', Timestamp('1999-11-18 00:00:00')) to ('ZWS', Timestamp('2026-02-25 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   Adj Open   float64\n",
      " 1   Adj High   float64\n",
      " 2   Adj Low    float64\n",
      " 3   Adj Close  float64\n",
      " 4   Volume     int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 398.8+ MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"df_ohlcv.head():\\n {df_ohlcv.head()}\\n\")\n",
    "df_ohlcv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6e70338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing New Feature Engine...\n",
      "‚ö° Generating Decoupled Features (Benchmark: SPY)...\n",
      "‚úÖ Features Generated Successfully!\n",
      "\n",
      "--- TICKER FEATURES (Micro) ---\n",
      "Columns: ['ATR', 'ATRP', 'TRP', 'RSI', 'Mom_21', 'Consistency', 'IR_63', 'Beta_63', 'DD_21', 'Ret_1d', 'RollingStalePct', 'RollMedDollarVol', 'RollingSameVolCount']\n",
      "Sample Data:\n",
      "                    Mom_21   IR_63    ATRP\n",
      "Ticker Date                              \n",
      "A      2019-09-27  0.0922  0.0318  0.0195\n",
      "       2019-09-30  0.0862  0.0208  0.0189\n",
      "       2019-10-01  0.0547  0.0008  0.0201\n",
      "       2019-10-02  0.0440 -0.0324  0.0210\n",
      "       2019-10-03  0.0447 -0.0132  0.0207\n",
      "\n",
      "--- MACRO STATE (Shared) ---\n",
      "Columns: ['Mkt_Ret', 'Macro_Trend', 'Macro_Trend_Vel', 'Macro_Trend_Vel_Z', 'Macro_Trend_Mom', 'Macro_Vix_Z', 'Macro_Vix_Ratio']\n",
      "\n",
      "üîç Macro Check for 2019-10-03:\n",
      "Mkt_Ret              0.0000\n",
      "Macro_Trend          0.0000\n",
      "Macro_Trend_Vel      0.0000\n",
      "Macro_Trend_Vel_Z    0.0000\n",
      "Macro_Trend_Mom      0.0000\n",
      "Macro_Vix_Z          0.0313\n",
      "Macro_Vix_Ratio      1.1321\n",
      "Name: 2019-10-03 00:00:00, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# === FIXED TEST HARNESS ===\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üß™ Testing New Feature Engine...\")\n",
    "\n",
    "    # 1. Create Dummy Index Data\n",
    "    dates = df_ohlcv.index.get_level_values(\"Date\").unique()\n",
    "    dummy_indices = []\n",
    "\n",
    "    for ticker in [\"^GSPC\", \"^VIX\", \"^VIX3M\"]:\n",
    "        temp = pd.DataFrame(\n",
    "            {\n",
    "                \"Adj Close\": (\n",
    "                    np.random.normal(100, 5, len(dates))\n",
    "                    if ticker == \"^GSPC\"\n",
    "                    else np.random.normal(20, 2, len(dates))\n",
    "                ),\n",
    "                \"Volume\": 1000,\n",
    "            },\n",
    "            index=dates,\n",
    "        )\n",
    "        temp[\"Ticker\"] = ticker\n",
    "        dummy_indices.append(temp.reset_index().set_index([\"Ticker\", \"Date\"]))\n",
    "\n",
    "    df_idx_test = pd.concat(dummy_indices)\n",
    "\n",
    "    # 2. Run Generation\n",
    "    try:\n",
    "        # FIX 1: Unpack the tuple into two variables\n",
    "        feat_df, mac_df = generate_features(\n",
    "            df_ohlcv.iloc[:5000], df_indices=df_idx_test\n",
    "        )\n",
    "\n",
    "        print(\"‚úÖ Features Generated Successfully!\")\n",
    "\n",
    "        # FIX 2: Check columns of the features_df (Ticker-specific)\n",
    "        print(\"\\n--- TICKER FEATURES (Micro) ---\")\n",
    "        print(\"Columns:\", feat_df.columns.tolist())\n",
    "        # Note: Macro_Vix_Z is no longer in feat_df (that's the point of the optimization!)\n",
    "        print(\"Sample Data:\\n\", feat_df[[\"Mom_21\", \"IR_63\", \"ATRP\"]].tail())\n",
    "\n",
    "        # FIX 3: Check the new Macro DataFrame\n",
    "        print(\"\\n--- MACRO STATE (Shared) ---\")\n",
    "        print(\"Columns:\", mac_df.columns.tolist())\n",
    "\n",
    "        # Check specific date alignment\n",
    "        last_date = feat_df.index.get_level_values(\"Date\")[-1]\n",
    "        print(f\"\\nüîç Macro Check for {last_date.date()}:\")\n",
    "        # We look up the date in the mac_df now\n",
    "        print(mac_df.loc[last_date])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d3a9824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Takes about 2.5 minutes to generate_features\n",
      "‚ö° Generating Decoupled Features (Benchmark: SPY)...\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# DATA PRE-COMPUTATION (The \"Fast-Track\" Setup)\n",
    "# ==============================================================================\n",
    "print(f\"Takes about 2.5 minutes to generate_features\")\n",
    "\n",
    "features_df, macro_df = generate_features(\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    df_indices=df_indices,\n",
    "    benchmark_ticker=GLOBAL_SETTINGS[\"benchmark_ticker\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eed07737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 9486139 entries, ('A', Timestamp('1999-11-18 00:00:00')) to ('ZWS', Timestamp('2026-02-25 00:00:00'))\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Dtype  \n",
      "---  ------               -----  \n",
      " 0   ATR                  float64\n",
      " 1   ATRP                 float64\n",
      " 2   TRP                  float64\n",
      " 3   RSI                  float64\n",
      " 4   Mom_21               float64\n",
      " 5   Consistency          float64\n",
      " 6   IR_63                float64\n",
      " 7   Beta_63              float64\n",
      " 8   DD_21                float64\n",
      " 9   Ret_1d               float64\n",
      " 10  RollingStalePct      float64\n",
      " 11  RollMedDollarVol     float64\n",
      " 12  RollingSameVolCount  float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 977.7+ MB\n",
      "features_df.info():\n",
      "None\n",
      "\n",
      "features_df.index.names:\n",
      "['Ticker', 'Date']\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 16145 entries, 1962-01-02 to 2026-02-25\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Mkt_Ret            16145 non-null  float64\n",
      " 1   Macro_Trend        16145 non-null  float64\n",
      " 2   Macro_Trend_Vel    16145 non-null  float64\n",
      " 3   Macro_Trend_Vel_Z  16145 non-null  float64\n",
      " 4   Macro_Trend_Mom    16145 non-null  float64\n",
      " 5   Macro_Vix_Z        16145 non-null  float64\n",
      " 6   Macro_Vix_Ratio    16145 non-null  float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 1.5 MB\n",
      "macro_df.info():\n",
      "None\n",
      "\n",
      "macro_df.index.names:\n",
      "['Date']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"features_df.info():\\n{features_df.info()}\\n\")\n",
    "print(f\"features_df.index.names:\\n{features_df.index.names}\\n\")\n",
    "print(f\"macro_df.info():\\n{macro_df.info()}\\n\")\n",
    "print(f\"macro_df.index.names:\\n{macro_df.index.names}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5f1e8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Macro Verification (Benchmark: SPY) ---\n",
      "\n",
      "Comparing verification vs original (Clip Threshold: 4.0):\n",
      "‚úÖ Mkt_Ret              | PASS (Max Diff: 0.00e+00)\n",
      "‚úÖ Macro_Trend          | PASS (Max Diff: 0.00e+00)\n",
      "‚úÖ Macro_Trend_Vel      | PASS (Max Diff: 0.00e+00)\n",
      "‚úÖ Macro_Trend_Vel_Z    | PASS (Max Diff: 0.00e+00)\n",
      "‚úÖ Macro_Trend_Mom      | PASS (Max Diff: 0.00e+00)\n",
      "‚úÖ Macro_Vix_Z          | PASS (Max Diff: 0.00e+00)\n",
      "‚úÖ Macro_Vix_Ratio      | PASS (Max Diff: 0.00e+00)\n"
     ]
    }
   ],
   "source": [
    "verify_macro_engine(df_ohlcv, df_indices, macro_df, GLOBAL_SETTINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e82d6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Generating Wide Matrices for Instant Backtesting... (takes about 1 minute to run)\n",
      "   - Unstacking ATRP...\n",
      "   - Unstacking TRP...\n",
      "‚úÖ Pre-computation Complete. Tickers: 1581, Days: 16145\n",
      "   Ready: df_close_wide, df_atrp_wide, df_trp_wide, and macro_df.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"üöÄ Generating Wide Matrices for Instant Backtesting... (takes about 1 minute to run)\"\n",
    ")\n",
    "\n",
    "# 1. Price Matrix\n",
    "df_close_wide = df_ohlcv[\"Adj Close\"].unstack(level=0)\n",
    "\n",
    "# 2. Volatility Matrices (Unstack and Align)\n",
    "# Using features_df (the first item from the tuple)\n",
    "print(\"   - Unstacking ATRP...\")\n",
    "df_atrp_wide = features_df[\"ATRP\"].unstack(level=0).reindex_like(df_close_wide)\n",
    "\n",
    "print(\"   - Unstacking TRP...\")\n",
    "df_trp_wide = features_df[\"TRP\"].unstack(level=0).reindex_like(df_close_wide)\n",
    "\n",
    "# 3. Handle Data Gaps (Sanitize the Wide Matrices)\n",
    "if GLOBAL_SETTINGS[\"handle_zeros_as_nan\"]:\n",
    "    df_close_wide = df_close_wide.replace(0, np.nan)\n",
    "\n",
    "# Forward fill up to the limit, then fill remaining with the \"Disaster Detection\" value\n",
    "df_close_wide = df_close_wide.ffill(limit=GLOBAL_SETTINGS[\"max_data_gap_ffill\"])\n",
    "df_close_wide = df_close_wide.fillna(GLOBAL_SETTINGS[\"nan_price_replacement\"])\n",
    "\n",
    "print(\n",
    "    f\"‚úÖ Pre-computation Complete. Tickers: {len(df_close_wide.columns)}, Days: {len(df_close_wide)}\"\n",
    ")\n",
    "print(\"   Ready: df_close_wide, df_atrp_wide, df_trp_wide, and macro_df.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2e95348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This ensures the 'master_engine' variable actually uses the code you just pasted above.\n",
    "master_engine = AlphaEngine(\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    features_df=features_df,\n",
    "    macro_df=macro_df,\n",
    "    df_close_wide=df_close_wide,\n",
    "    df_atrp_wide=df_atrp_wide,\n",
    "    df_trp_wide=df_trp_wide,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e390a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Ready for Stage 1: Run Simulation for first filter.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec488797b4d4a84a1339c8653ceac51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>1. Timeline Configuration:</b> (Past <--- Decision ---> Future)'), HBox(children‚Ä¶"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# universe_subset=None means \"Scan the whole market\"\n",
    "analyzer1, stage1_pack = create_walk_forward_analyzer(\n",
    "    master_engine, universe_subset=None\n",
    ")\n",
    "\n",
    "print(\"üöÄ Ready for Stage 1: Run Simulation for first filter.\")\n",
    "analyzer1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0227cbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Ready for Stage 2: Run Simulation for 2nd filter.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "298731b8b360473e896a5d5042bbd00e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>1. Timeline Configuration:</b> (Past <--- Decision ---> Future)'), HBox(children‚Ä¶"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get decision date from last run\n",
    "decision_date_last_run = FilterPack(decision_date=analyzer1.last_run.decision_date)\n",
    "\n",
    "# 1. LAUNCH STAGE 2 (Cascade)\n",
    "# universe_subset=analyzer1.last_run.tickers means \"Scan the whole market\"\n",
    "analyzer2, stage1_pack = create_walk_forward_analyzer(\n",
    "    master_engine,\n",
    "    universe_subset=analyzer1.last_run.tickers,\n",
    "    # universe_subset=None,\n",
    "    filter_pack=decision_date_last_run,\n",
    ")\n",
    "\n",
    "print(\"üöÄ Ready for Stage 2: Run Simulation for 2nd filter.\")\n",
    "analyzer2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44eb1d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6ff2e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================\n",
      "üîç HIGH-TRANSPARENCY AUDIT MAP\n",
      "====================================================================\n",
      "[  0] üì¶ audit_pack (EngineOutput)\n",
      "[  1]   üìà portfolio_series (shape=(17,))\n",
      "[  2]   üìà benchmark_series (shape=(17,))\n",
      "[  3]   üßÆ normalized_plot_data (shape=(17, 10))\n",
      "[  4]   üìÇ tickers (len=10)\n",
      "[  5]     üìÑ index_0 (str)\n",
      "[  6]     üìÑ index_1 (str)\n",
      "[  7]     üìÑ index_2 (str)\n",
      "[  8]     üìÑ index_3 (str)\n",
      "[  9]     üìÑ index_4 (str)\n",
      "[ 10]     üìÑ index_5 (str)\n",
      "[ 11]     üìÑ index_6 (str)\n",
      "[ 12]     üìÑ index_7 (str)\n",
      "[ 13]     üìÑ index_8 (str)\n",
      "[ 14]     üìÑ index_9 (str)\n",
      "[ 15]   üìà initial_weights (shape=(10,))\n",
      "[ 16]   üìÇ perf_metrics (len=24)\n",
      "[ 17]     üî¢ full_p_gain (float)\n",
      "[ 18]     üî¢ full_p_sharpe (float)\n",
      "[ 19]     üî¢ full_p_sharpe_atrp (float)\n",
      "[ 20]     üî¢ full_p_sharpe_trp (float)\n",
      "[ 21]     üî¢ lookback_p_gain (float)\n",
      "[ 22]     üî¢ lookback_p_sharpe (float)\n",
      "[ 23]     üî¢ lookback_p_sharpe_atrp (float)\n",
      "[ 24]     üî¢ lookback_p_sharpe_trp (float)\n",
      "[ 25]     üî¢ holding_p_gain (float)\n",
      "[ 26]     üî¢ holding_p_sharpe (float)\n",
      "[ 27]     üî¢ holding_p_sharpe_atrp (float)\n",
      "[ 28]     üî¢ holding_p_sharpe_trp (float)\n",
      "[ 29]     üî¢ full_b_gain (float)\n",
      "[ 30]     üî¢ full_b_sharpe (float)\n",
      "[ 31]     üî¢ full_b_sharpe_atrp (float)\n",
      "[ 32]     üî¢ full_b_sharpe_trp (float)\n",
      "[ 33]     üî¢ lookback_b_gain (float)\n",
      "[ 34]     üî¢ lookback_b_sharpe (float)\n",
      "[ 35]     üî¢ lookback_b_sharpe_atrp (float)\n",
      "[ 36]     üî¢ lookback_b_sharpe_trp (float)\n",
      "[ 37]     üî¢ holding_b_gain (float)\n",
      "[ 38]     üî¢ holding_b_sharpe (float)\n",
      "[ 39]     üî¢ holding_b_sharpe_atrp (float)\n",
      "[ 40]     üî¢ holding_b_sharpe_trp (float)\n",
      "[ 41]   üßÆ results_df (shape=(10, 2))\n",
      "[ 42]   üìÖ start_date (Timestamp)\n",
      "[ 43]   üìÖ decision_date (Timestamp)\n",
      "[ 44]   üìÖ buy_date (Timestamp)\n",
      "[ 45]   üìÖ holding_end_date (Timestamp)\n",
      "[ 46]   üìà portfolio_atrp_series (shape=(17,))\n",
      "[ 47]   üìà benchmark_atrp_series (shape=(17,))\n",
      "[ 48]   üìà portfolio_trp_series (shape=(17,))\n",
      "[ 49]   üìà benchmark_trp_series (shape=(17,))\n",
      "[ 50]   üìÑ error_msg (NoneType)\n",
      "[ 51]   üìÇ debug_data (len=8)\n",
      "[ 52]     üìÇ audit_liquidity (len=3)\n",
      "[ 53]       üìÑ mode (str)\n",
      "[ 54]       üî¢ tickers_passed (int)\n",
      "[ 55]       üî¢ forced_list (bool)\n",
      "[ 56]     üßÆ full_universe_ranking (shape=(10, 4))\n",
      "[ 57]     üìÇ meta (len=4)\n",
      "[ 58]       üî¢ dropped_count (int)\n",
      "[ 59]       üìÇ dropped_tickers (len=0)\n",
      "[ 60]       üî¢ clean_count (int)\n",
      "[ 61]       üìÑ selection_range (str)\n",
      "[ 62]     üì¶ inputs_snapshot (EngineInput)\n",
      "[ 63]       üìÑ mode (str)\n",
      "[ 64]       üìÖ start_date (Timestamp)\n",
      "[ 65]       üî¢ lookback_period (int)\n",
      "[ 66]       üî¢ holding_period (int)\n",
      "[ 67]       üìÑ metric (str)\n",
      "[ 68]       üìÑ benchmark_ticker (str)\n",
      "[ 69]       üî¢ rank_start (int)\n",
      "[ 70]       üî¢ rank_end (int)\n",
      "[ 71]       üìÇ quality_thresholds (len=4)\n",
      "[ 72]         üî¢ min_median_dollar_volume (int)\n",
      "[ 73]         üî¢ min_liquidity_percentile (float)\n",
      "[ 74]         üî¢ max_stale_pct (float)\n",
      "[ 75]         üî¢ max_same_vol_count (int)\n",
      "[ 76]       üìÇ manual_tickers (len=0)\n",
      "[ 77]       üî¢ debug (bool)\n",
      "[ 78]       üìÇ universe_subset (len=10)\n",
      "[ 79]         üìÑ index_0 (str)\n",
      "[ 80]         üìÑ index_1 (str)\n",
      "[ 81]         üìÑ index_2 (str)\n",
      "[ 82]         üìÑ index_3 (str)\n",
      "[ 83]         üìÑ index_4 (str)\n",
      "[ 84]         üìÑ index_5 (str)\n",
      "[ 85]         üìÑ index_6 (str)\n",
      "[ 86]         üìÑ index_7 (str)\n",
      "[ 87]         üìÑ index_8 (str)\n",
      "[ 88]         üìÑ index_9 (str)\n",
      "[ 89]     üìÇ verification (len=2)\n",
      "[ 90]       üìÇ p (len=12)\n",
      "                  ‚ï∞‚îÄ‚îÄ full_val --> [See ID 1]\n",
      "[ 91]         üìà full_ret (shape=(17,))\n",
      "                  ‚ï∞‚îÄ‚îÄ full_atrp --> [See ID 46]\n",
      "                  ‚ï∞‚îÄ‚îÄ full_trp --> [See ID 48]\n",
      "[ 92]         üìà lookback_val (shape=(11,))\n",
      "[ 93]         üìà lookback_ret (shape=(11,))\n",
      "[ 94]         üìà lookback_atrp (shape=(11,))\n",
      "[ 95]         üìà lookback_trp (shape=(11,))\n",
      "[ 96]         üìà holding_val (shape=(6,))\n",
      "[ 97]         üìà holding_ret (shape=(6,))\n",
      "[ 98]         üìà holding_atrp (shape=(6,))\n",
      "[ 99]         üìà holding_trp (shape=(6,))\n",
      "[100]       üìÇ b (len=12)\n",
      "                  ‚ï∞‚îÄ‚îÄ full_val --> [See ID 2]\n",
      "[101]         üìà full_ret (shape=(17,))\n",
      "                  ‚ï∞‚îÄ‚îÄ full_atrp --> [See ID 47]\n",
      "                  ‚ï∞‚îÄ‚îÄ full_trp --> [See ID 49]\n",
      "[102]         üìà lookback_val (shape=(11,))\n",
      "[103]         üìà lookback_ret (shape=(11,))\n",
      "[104]         üìà lookback_atrp (shape=(11,))\n",
      "[105]         üìà lookback_trp (shape=(11,))\n",
      "[106]         üìà holding_val (shape=(6,))\n",
      "[107]         üìà holding_ret (shape=(6,))\n",
      "[108]         üìà holding_atrp (shape=(6,))\n",
      "[109]         üìà holding_trp (shape=(6,))\n",
      "[110]     üìÇ portfolio_raw_components (len=4)\n",
      "[111]       üßÆ prices (shape=(17, 10))\n",
      "[112]       üßÆ atrp (shape=(17, 10))\n",
      "[113]       üßÆ trp (shape=(17, 10))\n",
      "[114]       üßÆ ohlcv_raw (shape=(170, 5))\n",
      "[115]     üìÇ benchmark_raw_components (len=4)\n",
      "[116]       üßÆ prices (shape=(17, 1))\n",
      "[117]       üßÆ atrp (shape=(17, 1))\n",
      "[118]       üßÆ trp (shape=(17, 1))\n",
      "[119]       üßÆ ohlcv_raw (shape=(17, 5))\n",
      "              ‚ï∞‚îÄ‚îÄ selection_audit --> [See ID 56]\n",
      "[120]   üßÆ macro_df (shape=(16145, 7))\n"
     ]
    }
   ],
   "source": [
    "my_analyzer = analyzer2\n",
    "\n",
    "my_res = visualize_analyzer_structure(my_analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5f1fb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================================================================================\n",
      "***********************************************************************************************\n",
      "üïµÔ∏è  STARTING SHORT-FORM AUDIT: Sharpe (ATRP) @ 2025-12-10\n",
      "‚ö†Ô∏è  ASSUMPTION: Verification logic is independent, but trusts Engine source DataFrames\n",
      "   (engine.features_df, engine.df_close, and debug['portfolio_raw_components'])\n",
      "***********************************************************************************************\n",
      "===============================================================================================\n",
      "üïµÔ∏è  AUDIT: Sharpe (ATRP) @ 2025-12-10\n",
      "===============================================================================================\n",
      "LAYER 1: SURVIVAL  | Mode: CASCADE/SUBSET | ‚úÖ BYPASS\n",
      "LAYER 2: SELECTION | Strategy: Sharpe (ATRP) | Selection Match: ‚úÖ PASS\n",
      "LAYER 3: PERFORMANCE (Holding Period: 5 days)\n",
      "Metric               | Engine       | Manual       | Status\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Gain                 |    -0.007273 |    -0.007273 | ‚úÖ PASS\n",
      "Sharpe               |    -6.897621 |    -6.897621 | ‚úÖ PASS\n",
      "Sharpe (ATRP)        |    -0.082114 |    -0.082114 | ‚úÖ PASS\n",
      "Sharpe (TRP)         |    -0.099573 |    -0.099573 | ‚úÖ PASS\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "verify_analyzer_short(my_analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a23faaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= verify_analyzer_long (FINAL) ========= \n",
      "\n",
      "\n",
      "=====================================================================================\n",
      "üõ°Ô∏è  STARTING NUCLEAR AUDIT | 2025-12-10 | Sharpe (ATRP)\n",
      "=====================================================================================\n",
      "üìù 1. PERFORMANCE RECONCILIATION\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Period</th>\n",
       "      <th>Full</th>\n",
       "      <th>Holding</th>\n",
       "      <th>Lookback</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entity</th>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Benchmark</th>\n",
       "      <th>Gain</th>\n",
       "      <td>‚úÖ PASS</td>\n",
       "      <td>‚úÖ PASS</td>\n",
       "      <td>‚úÖ PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe</th>\n",
       "      <td>‚úÖ PASS</td>\n",
       "      <td>‚úÖ PASS</td>\n",
       "      <td>‚úÖ PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe (ATRP)</th>\n",
       "      <td>‚úÖ PASS</td>\n",
       "      <td>‚úÖ PASS</td>\n",
       "      <td>‚úÖ PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe (TRP)</th>\n",
       "      <td>‚úÖ PASS</td>\n",
       "      <td>‚úÖ PASS</td>\n",
       "      <td>‚úÖ PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Group</th>\n",
       "      <th>Gain</th>\n",
       "      <td>‚úÖ PASS</td>\n",
       "      <td>‚úÖ PASS</td>\n",
       "      <td>‚úÖ PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe</th>\n",
       "      <td>‚úÖ PASS</td>\n",
       "      <td>‚úÖ PASS</td>\n",
       "      <td>‚úÖ PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe (ATRP)</th>\n",
       "      <td>‚úÖ PASS</td>\n",
       "      <td>‚úÖ PASS</td>\n",
       "      <td>‚úÖ PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe (TRP)</th>\n",
       "      <td>‚úÖ PASS</td>\n",
       "      <td>‚úÖ PASS</td>\n",
       "      <td>‚úÖ PASS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Period                     Full Holding Lookback\n",
       "Entity    Metric                                \n",
       "Benchmark Gain           ‚úÖ PASS  ‚úÖ PASS   ‚úÖ PASS\n",
       "          Sharpe         ‚úÖ PASS  ‚úÖ PASS   ‚úÖ PASS\n",
       "          Sharpe (ATRP)  ‚úÖ PASS  ‚úÖ PASS   ‚úÖ PASS\n",
       "          Sharpe (TRP)   ‚úÖ PASS  ‚úÖ PASS   ‚úÖ PASS\n",
       "Group     Gain           ‚úÖ PASS  ‚úÖ PASS   ‚úÖ PASS\n",
       "          Sharpe         ‚úÖ PASS  ‚úÖ PASS   ‚úÖ PASS\n",
       "          Sharpe (ATRP)  ‚úÖ PASS  ‚úÖ PASS   ‚úÖ PASS\n",
       "          Sharpe (TRP)   ‚úÖ PASS  ‚úÖ PASS   ‚úÖ PASS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====================================================================================\n",
      "üìù 2. SURVIVAL AUDIT\n",
      "   Mode: CASCADE/SUBSET | Logic: Quality filters bypassed per design. | ‚úÖ BYPASS\n",
      "\n",
      "=====================================================================================\n",
      "üìù 3. UNIVERSAL SELECTION AUDIT | Strategy: Sharpe (ATRP)\n",
      "   Scope: Evaluated 10 candidates (Full Universe).\n",
      "   Result: 10 PASSED | 0 FAILED\n",
      "   All scores match registry math. Sharpe (ATRP) results of the first 5 tickers\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_5a09d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5a09d_level0_col0\" class=\"col_heading level0 col0\" >Ticker</th>\n",
       "      <th id=\"T_5a09d_level0_col1\" class=\"col_heading level0 col1\" >Engine</th>\n",
       "      <th id=\"T_5a09d_level0_col2\" class=\"col_heading level0 col2\" >Manual</th>\n",
       "      <th id=\"T_5a09d_level0_col3\" class=\"col_heading level0 col3\" >Delta</th>\n",
       "      <th id=\"T_5a09d_level0_col4\" class=\"col_heading level0 col4\" >Status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Rank</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5a09d_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_5a09d_row0_col0\" class=\"data row0 col0\" >BIL</td>\n",
       "      <td id=\"T_5a09d_row0_col1\" class=\"data row0 col1\" >0.74483924</td>\n",
       "      <td id=\"T_5a09d_row0_col2\" class=\"data row0 col2\" >0.74483924</td>\n",
       "      <td id=\"T_5a09d_row0_col3\" class=\"data row0 col3\" >0.00000000</td>\n",
       "      <td id=\"T_5a09d_row0_col4\" class=\"data row0 col4\" >‚úÖ PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a09d_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "      <td id=\"T_5a09d_row1_col0\" class=\"data row1 col0\" >CFLT</td>\n",
       "      <td id=\"T_5a09d_row1_col1\" class=\"data row1 col1\" >0.80342188</td>\n",
       "      <td id=\"T_5a09d_row1_col2\" class=\"data row1 col2\" >0.80342188</td>\n",
       "      <td id=\"T_5a09d_row1_col3\" class=\"data row1 col3\" >0.00000000</td>\n",
       "      <td id=\"T_5a09d_row1_col4\" class=\"data row1 col4\" >‚úÖ PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a09d_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "      <td id=\"T_5a09d_row2_col0\" class=\"data row2 col0\" >DG</td>\n",
       "      <td id=\"T_5a09d_row2_col1\" class=\"data row2 col1\" >0.66862304</td>\n",
       "      <td id=\"T_5a09d_row2_col2\" class=\"data row2 col2\" >0.66862304</td>\n",
       "      <td id=\"T_5a09d_row2_col3\" class=\"data row2 col3\" >0.00000000</td>\n",
       "      <td id=\"T_5a09d_row2_col4\" class=\"data row2 col4\" >‚úÖ PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a09d_level0_row3\" class=\"row_heading level0 row3\" >4</th>\n",
       "      <td id=\"T_5a09d_row3_col0\" class=\"data row3 col0\" >MCHP</td>\n",
       "      <td id=\"T_5a09d_row3_col1\" class=\"data row3 col1\" >0.70179452</td>\n",
       "      <td id=\"T_5a09d_row3_col2\" class=\"data row3 col2\" >0.70179452</td>\n",
       "      <td id=\"T_5a09d_row3_col3\" class=\"data row3 col3\" >0.00000000</td>\n",
       "      <td id=\"T_5a09d_row3_col4\" class=\"data row3 col4\" >‚úÖ PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a09d_level0_row4\" class=\"row_heading level0 row4\" >5</th>\n",
       "      <td id=\"T_5a09d_row4_col0\" class=\"data row4 col0\" >MINT</td>\n",
       "      <td id=\"T_5a09d_row4_col1\" class=\"data row4 col1\" >0.66410820</td>\n",
       "      <td id=\"T_5a09d_row4_col2\" class=\"data row4 col2\" >0.66410820</td>\n",
       "      <td id=\"T_5a09d_row4_col3\" class=\"data row4 col3\" >0.00000000</td>\n",
       "      <td id=\"T_5a09d_row4_col4\" class=\"data row4 col4\" >‚úÖ PASS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b881521810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "verify_analyzer_long(my_analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6869fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================================================================================\n",
      "üïµÔ∏è  NUCLEAR FEATURE AUDIT | Mode: LAST_RUN | Tickers: 10\n",
      "===============================================================================================\n",
      "STEP 1: BOUNDARY INTEGRITY   | MultiIndex Isolation Check | ‚úÖ PASS\n",
      "STEP 2: SHADOW CALCULATIONS  | Re-computing metrics... DONE (0.42s)\n",
      "\n",
      "Metric               | Max Delta    | Correlation  | Status\n",
      "-------------------------------------------------------------------------------------\n",
      "Ret_1d               |   0.0000e+00 |     1.000000 | ‚úÖ PASS\n",
      "ATR                  |   0.0000e+00 |     1.000000 | ‚úÖ PASS\n",
      "ATRP                 |   0.0000e+00 |     1.000000 | ‚úÖ PASS\n",
      "TRP                  |   0.0000e+00 |     1.000000 | ‚úÖ PASS\n",
      "RSI                  |   0.0000e+00 |     1.000000 | ‚úÖ PASS\n",
      "Mom_21               |   0.0000e+00 |     1.000000 | ‚úÖ PASS\n",
      "Consistency          |   0.0000e+00 |     1.000000 | ‚úÖ PASS\n",
      "DD_21                |   0.0000e+00 |     1.000000 | ‚úÖ PASS\n",
      "RollingStalePct      |   0.0000e+00 |     1.000000 | ‚úÖ PASS\n",
      "RollMedDollarVol     |   0.0000e+00 |     1.000000 | ‚úÖ PASS\n",
      "RollingSameVolCount  |   0.0000e+00 |     1.000000 | ‚úÖ PASS\n",
      "Macro_Vix_Signals    | N/A          | N/A          | ‚úÖ LIVE\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Takes 4 seconds to run, checks selected tickers from analyzer1\n",
    "audit_feature_engineering_integrity(my_analyzer, mode=\"last_run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e41650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_name: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_RLVR\\output\\Audit_Verification_Report.xlsx\n",
      "üìÇ [EXCEL AUDIT] Building full transparency report: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_RLVR\\output\\Audit_Verification_Report.xlsx\n",
      "‚ú® Audit Report Complete: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_RLVR\\output\\Audit_Verification_Report.xlsx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/ping/Files_win10/python/py311/stocks/notebooks_RLVR/output/Audit_Verification_Report.xlsx')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_name = OUTPUT_DIR / \"Audit_Verification_Report.xlsx\"\n",
    "\n",
    "export_audit_to_excel(audit_pack=my_analyzer.last_run, filename=f_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbf136b",
   "metadata": {},
   "source": [
    "### Combine Ticker's OHLCV with its Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7c8c4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating combined dictionary for 11 ticker(s)\n",
      "Date range: 2025-11-25 00:00:00 to 2025-12-18 00:00:00\n",
      "============================================================\n",
      "Data retrieved for 11 ticker(s) from 2025-11-25 00:00:00 to 2025-12-18 00:00:00\n",
      "Total rows: 187\n",
      "Date range in data: 2025-11-25 00:00:00 to 2025-12-18 00:00:00\n",
      "  SHV: 17 rows\n",
      "  CFLT: 17 rows\n",
      "  SGOV: 17 rows\n",
      "  BIL: 17 rows\n",
      "  WBD: 17 rows\n",
      "  TD: 17 rows\n",
      "  MCHP: 17 rows\n",
      "  SLV: 17 rows\n",
      "  DG: 17 rows\n",
      "  MINT: 17 rows\n",
      "  SPY: 17 rows\n",
      "Features data retrieved for 11 ticker(s) from 2025-11-25 00:00:00 to 2025-12-18 00:00:00\n",
      "Total rows: 187\n",
      "Date range in data: 2025-11-25 00:00:00 to 2025-12-18 00:00:00\n",
      "Available features: ATR, ATRP, TRP, RSI, Mom_21, Consistency, IR_63, Beta_63, DD_21, Ret_1d, RollingStalePct, RollMedDollarVol, RollingSameVolCount\n",
      "  SHV: 17 rows\n",
      "  CFLT: 17 rows\n",
      "  SGOV: 17 rows\n",
      "  BIL: 17 rows\n",
      "  WBD: 17 rows\n",
      "  TD: 17 rows\n",
      "  MCHP: 17 rows\n",
      "  SLV: 17 rows\n",
      "  DG: 17 rows\n",
      "  MINT: 17 rows\n",
      "  SPY: 17 rows\n",
      "\n",
      "Processing SHV...\n",
      "  ‚úì Successfully combined data\n",
      "  OHLCV shape: (17, 5)\n",
      "  Features shape: (17, 13)\n",
      "  Combined shape: (17, 18)\n",
      "  Date range: 2025-11-25 00:00:00 to 2025-12-18 00:00:00\n",
      "\n",
      "Processing CFLT...\n",
      "  ‚úì Successfully combined data\n",
      "  OHLCV shape: (17, 5)\n",
      "  Features shape: (17, 13)\n",
      "  Combined shape: (17, 18)\n",
      "  Date range: 2025-11-25 00:00:00 to 2025-12-18 00:00:00\n",
      "\n",
      "Processing SGOV...\n",
      "  ‚úì Successfully combined data\n",
      "  OHLCV shape: (17, 5)\n",
      "  Features shape: (17, 13)\n",
      "  Combined shape: (17, 18)\n",
      "  Date range: 2025-11-25 00:00:00 to 2025-12-18 00:00:00\n",
      "\n",
      "Processing BIL...\n",
      "  ‚úì Successfully combined data\n",
      "  OHLCV shape: (17, 5)\n",
      "  Features shape: (17, 13)\n",
      "  Combined shape: (17, 18)\n",
      "  Date range: 2025-11-25 00:00:00 to 2025-12-18 00:00:00\n",
      "\n",
      "Processing WBD...\n",
      "  ‚úì Successfully combined data\n",
      "  OHLCV shape: (17, 5)\n",
      "  Features shape: (17, 13)\n",
      "  Combined shape: (17, 18)\n",
      "  Date range: 2025-11-25 00:00:00 to 2025-12-18 00:00:00\n",
      "\n",
      "Processing TD...\n",
      "  ‚úì Successfully combined data\n",
      "  OHLCV shape: (17, 5)\n",
      "  Features shape: (17, 13)\n",
      "  Combined shape: (17, 18)\n",
      "  Date range: 2025-11-25 00:00:00 to 2025-12-18 00:00:00\n",
      "\n",
      "Processing MCHP...\n",
      "  ‚úì Successfully combined data\n",
      "  OHLCV shape: (17, 5)\n",
      "  Features shape: (17, 13)\n",
      "  Combined shape: (17, 18)\n",
      "  Date range: 2025-11-25 00:00:00 to 2025-12-18 00:00:00\n",
      "\n",
      "Processing SLV...\n",
      "  ‚úì Successfully combined data\n",
      "  OHLCV shape: (17, 5)\n",
      "  Features shape: (17, 13)\n",
      "  Combined shape: (17, 18)\n",
      "  Date range: 2025-11-25 00:00:00 to 2025-12-18 00:00:00\n",
      "\n",
      "Processing DG...\n",
      "  ‚úì Successfully combined data\n",
      "  OHLCV shape: (17, 5)\n",
      "  Features shape: (17, 13)\n",
      "  Combined shape: (17, 18)\n",
      "  Date range: 2025-11-25 00:00:00 to 2025-12-18 00:00:00\n",
      "\n",
      "Processing MINT...\n",
      "  ‚úì Successfully combined data\n",
      "  OHLCV shape: (17, 5)\n",
      "  Features shape: (17, 13)\n",
      "  Combined shape: (17, 18)\n",
      "  Date range: 2025-11-25 00:00:00 to 2025-12-18 00:00:00\n",
      "\n",
      "Processing SPY...\n",
      "  ‚úì Successfully combined data\n",
      "  OHLCV shape: (17, 5)\n",
      "  Features shape: (17, 13)\n",
      "  Combined shape: (17, 18)\n",
      "  Date range: 2025-11-25 00:00:00 to 2025-12-18 00:00:00\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "Total tickers processed: 11\n",
      "Tickers with combined data: 11\n",
      "\n",
      "Ticker details:\n",
      "  SHV: (17, 18) - 2025-11-25 00:00:00 to 2025-12-18 00:00:00\n",
      "    Columns: 18\n",
      "  CFLT: (17, 18) - 2025-11-25 00:00:00 to 2025-12-18 00:00:00\n",
      "    Columns: 18\n",
      "  SGOV: (17, 18) - 2025-11-25 00:00:00 to 2025-12-18 00:00:00\n",
      "    Columns: 18\n",
      "  BIL: (17, 18) - 2025-11-25 00:00:00 to 2025-12-18 00:00:00\n",
      "    Columns: 18\n",
      "  WBD: (17, 18) - 2025-11-25 00:00:00 to 2025-12-18 00:00:00\n",
      "    Columns: 18\n",
      "  TD: (17, 18) - 2025-11-25 00:00:00 to 2025-12-18 00:00:00\n",
      "    Columns: 18\n",
      "  MCHP: (17, 18) - 2025-11-25 00:00:00 to 2025-12-18 00:00:00\n",
      "    Columns: 18\n",
      "  SLV: (17, 18) - 2025-11-25 00:00:00 to 2025-12-18 00:00:00\n",
      "    Columns: 18\n",
      "  DG: (17, 18) - 2025-11-25 00:00:00 to 2025-12-18 00:00:00\n",
      "    Columns: 18\n",
      "  MINT: (17, 18) - 2025-11-25 00:00:00 to 2025-12-18 00:00:00\n",
      "    Columns: 18\n",
      "  SPY: (17, 18) - 2025-11-25 00:00:00 to 2025-12-18 00:00:00\n",
      "    Columns: 18\n",
      "SHV:\n",
      "               Adj Open     Adj High      Adj Low    Adj Close   Volume        ATR       ATRP        TRP         RSI     Mom_21  Consistency       IR_63     Beta_63      DD_21     Ret_1d  RollingStalePct   RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                                                               \n",
      "2025-11-25 109.35200000 109.35200000 109.34300000 109.35200000  1878726 0.01827799 0.00016715 0.00008230 97.69261102 0.00281535   1.00000000 -0.07673287 -0.00259513 0.00000000 0.00008231       0.00000000 331111221.04350001           0.00000000\n",
      "2025-11-26 109.37200000 109.38200000 109.37200000 109.37200000  1916888 0.01911528 0.00017477 0.00027429 97.88852544 0.00291599   1.00000000 -0.08307270 -0.00248679 0.00000000 0.00018290       0.00000000 329635504.07099998           0.00000000\n",
      "2025-11-28 109.41200000 109.41200000 109.40200000 109.40200000  2528390 0.02060704 0.00018836 0.00036562 98.14320057 0.00327388   1.00000000 -0.10703806 -0.00182362 0.00000000 0.00027429       0.00000000 326997727.62250000           0.00000000\n",
      "2025-12-01 109.42400000 109.42400000 109.41400000 109.42400000  3528203 0.02070654 0.00018923 0.00020105 98.30468722 0.00339281   1.00000000 -0.11356417 -0.00167842 0.00000000 0.00020109       0.00000000 326997727.62250000           0.00000000\n",
      "2025-12-02 109.43400000 109.44400000 109.43400000 109.44400000  1900212 0.02065607 0.00018874 0.00018274 98.43770979 0.00339219   1.00000000 -0.10651204 -0.00170442 0.00000000 0.00018278       0.00000000 326997727.62250000           0.00000000\n",
      "2025-12-03 109.45400000 109.46400000 109.45400000 109.46400000  4607627 0.02060921 0.00018827 0.00018271 98.55943824 0.00329041   1.00000000 -0.09710633 -0.00176736 0.00000000 0.00018274       0.00000000 326997727.62250000           0.00000000\n",
      "2025-12-04 109.47400000 109.48300000 109.46400000 109.46400000  3692240 0.02049427 0.00018722 0.00017357 98.55943824 0.00319846   0.80000000 -0.10598280 -0.00135204 0.00000000 0.00000000       0.00000000 326997727.62250000           0.00000000\n",
      "2025-12-05 109.50300000 109.51300000 109.50300000 109.50300000  2304769 0.02253039 0.00020575 0.00044748 98.77525282 0.00346392   0.80000000 -0.10449552 -0.00131338 0.00000000 0.00035628       0.00000000 326997727.62250000           0.00000000\n",
      "2025-12-08 109.51300000 109.52300000 109.51300000 109.51300000  2940790 0.02234965 0.00020408 0.00018263 98.82390598 0.00338085   0.80000000 -0.09295041 -0.00115079 0.00000000 0.00009132       0.00000000 325423417.04050004           0.00000000\n",
      "2025-12-09 109.53300000 109.53300000 109.52300000 109.52300000  2479172 0.02218182 0.00020253 0.00018261 98.87215608 0.00310485   0.80000000 -0.08539522 -0.00114143 0.00000000 0.00009131       0.00000000 325423417.04050004           0.00000000\n",
      "2025-12-10 109.54300000 109.55300000 109.53300000 109.55300000  4031988 0.02274026 0.00020757 0.00027384 99.00415058 0.00328773   0.80000000 -0.08198248 -0.00100002 0.00000000 0.00027392       0.00000000 326997727.62250000           0.00000000\n",
      "2025-12-11 109.56300000 109.57300000 109.55300000 109.57300000  2289976 0.02254453 0.00020575 0.00018253 99.08133956 0.00347089   1.00000000 -0.08750120 -0.00097713 0.00000000 0.00018256       0.00000000 326997727.62250000           0.00000000\n",
      "2025-12-12 109.60300000 109.60300000 109.59300000 109.60300000  1895884 0.02307706 0.00021055 0.00027372 99.18356503 0.00365371   1.00000000 -0.05314129 -0.00135671 0.00000000 0.00027379       0.00000000 326997727.62250000           0.00000000\n",
      "2025-12-15 109.62300000 109.62300000 109.61300000 109.62300000  2470618 0.02285727 0.00020851 0.00018244 99.24396535 0.00374494   1.00000000 -0.05284892 -0.00136140 0.00000000 0.00018248       0.00000000 326997727.62250000           0.00000000\n",
      "2025-12-16 109.63300000 109.63300000 109.62300000 109.63300000  2440226 0.02193889 0.00020011 0.00009121 99.27292874 0.00356084   1.00000000 -0.04975821 -0.00133317 0.00000000 0.00009122       0.00000000 326997727.62250000           0.00000000\n",
      "2025-12-17 109.64200000 109.64200000 109.63300000 109.64200000  1999338 0.02101469 0.00019167 0.00008209 99.29895898 0.00356054   1.00000000 -0.01752840 -0.00101260 0.00000000 0.00008209       0.00000000 326997727.62250000           0.00000000\n",
      "2025-12-18 109.65200000 109.66200000 109.65200000 109.66200000  2114366 0.02094221 0.00019097 0.00018238 99.35428323 0.00355989   1.00000000 -0.02301335 -0.00119588 0.00000000 0.00018241       0.00000000 326997727.62250000           0.00000000\n",
      "\n",
      "CFLT:\n",
      "              Adj Open    Adj High     Adj Low   Adj Close     Volume        ATR       ATRP        TRP         RSI      Mom_21  Consistency      IR_63    Beta_63       DD_21      Ret_1d  RollingStalePct   RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                                                              \n",
      "2025-11-25 21.00000000 21.91500000 20.89000000 21.83000000    5091100 1.05819143 0.04847418 0.04695373 45.43437307 -0.01132246   0.40000000 0.07284662 1.55061289 -0.10715746  0.03656220       0.00000000 125825077.00000000           0.00000000\n",
      "2025-11-26 21.83000000 22.15500000 21.58000000 21.83000000    4071600 1.02367776 0.04689316 0.02633990 45.43437307 -0.08084211   0.40000000 0.03548975 1.48989171 -0.10715746  0.00000000       0.00000000 124871108.00000000           0.00000000\n",
      "2025-11-28 22.03000000 22.40000000 21.84000000 22.25000000    1861800 0.99127221 0.04455156 0.02561798 49.14338416 -0.05919662   0.60000000 0.04576790 1.50036011 -0.08997955  0.01923958       0.00000000 124114517.00000000           0.00000000\n",
      "2025-12-01 21.84000000 22.63500000 21.66000000 21.87000000    5725100 0.99010991 0.04527252 0.04458162 46.09076986 -0.07015306   0.60000000 0.05470184 1.46265437 -0.10552147 -0.01707865       0.00000000 124114517.00000000           0.00000000\n",
      "2025-12-02 22.45000000 23.17000000 22.41000000 23.06000000    4780600 1.01224491 0.04389614 0.05637467 55.42798188 -0.01326487   0.60000000 0.08553565 1.48218536 -0.05685072  0.05441244       0.00000000 124114517.00000000           0.00000000\n",
      "2025-12-03 23.02500000 23.66500000 22.41500000 23.65000000    6132700 1.02922742 0.04351913 0.05285412 59.20103540  0.00895904   0.60000000 0.12655031 1.59665910 -0.03271984  0.02558543       0.00000000 124681543.50000000           0.00000000\n",
      "2025-12-04 23.48000000 23.77000000 23.21500000 23.35000000    5132900 0.99535403 0.04262758 0.02376874 56.57841537  0.02999559   0.60000000 0.09306492 1.64481455 -0.04498978 -0.01268499       0.00000000 124681543.50000000           0.00000000\n",
      "2025-12-05 23.11000000 23.50500000 22.91000000 23.14000000    5564000 0.96675732 0.04177862 0.02571305 54.75000793  0.02661934   0.40000000 0.06083840 1.62429357 -0.05357873 -0.00899358       0.00000000 125397501.50000000           0.00000000\n",
      "2025-12-08 29.84000000 29.95000000 29.70000000 29.87000000  146309900 1.38413179 0.04633853 0.22798795 78.60852341  0.32109686   0.60000000 0.14470453 1.31856527  0.00000000  0.29083838       0.00000000 125397501.50000000           0.00000000\n",
      "2025-12-09 29.83300000 29.90000000 29.80000000 29.90000000   55523200 1.29240809 0.04322435 0.00334448 78.66253148  0.31834215   0.60000000 0.14551867 1.32472807  0.00000000  0.00100435       0.00000000 125825077.00000000           0.00000000\n",
      "2025-12-10 29.89000000 30.04000000 29.88000000 30.00000000   32223700 1.21152180 0.04038406 0.00533333 78.85418018  0.27496813   0.60000000 0.15834185 1.39995294  0.00000000  0.00334448       0.00000000 126202207.00000000           0.00000000\n",
      "2025-12-11 30.01000000 30.22500000 30.00000000 30.14000000   19440400 1.14105596 0.03785853 0.00746516 79.13670627  0.23271984   0.80000000 0.16310305 1.39229064  0.00000000  0.00466667       0.00000000 126202207.00000000           0.00000000\n",
      "2025-12-12 30.10000000 30.13000000 30.02000000 30.05000000   12145100 1.06812339 0.03554487 0.00399334 78.41141494  0.23357964   0.80000000 0.15843506 1.36139621 -0.00298607 -0.00298607       0.00000000 126202207.00000000           0.00000000\n",
      "2025-12-15 30.08000000 30.15000000 30.05000000 30.07000000   17174900 0.99897172 0.03322154 0.00332557 78.45866250  0.28504274   0.80000000 0.16287994 1.35530466 -0.00232250  0.00066556       0.00000000 127276927.00000000           0.00000000\n",
      "2025-12-16 30.08000000 30.10000000 29.96000000 29.96000000   19851800 0.93761660 0.03129561 0.00467290 77.45462507  0.28583691   0.60000000 0.16115058 1.36008633 -0.00597213 -0.00365813       0.00000000 128481744.00000000           0.00000000\n",
      "2025-12-17 30.01000000 30.04500000 30.00000000 30.00000000   11790800 0.87671541 0.02922385 0.00283333 77.56704607  0.32391880   0.60000000 0.15631128 1.31235569 -0.00464499  0.00133511       0.00000000 128481744.00000000           0.00000000\n",
      "2025-12-18 30.04000000 30.07000000 29.95000000 29.95000000   15446800 0.82266431 0.02746792 0.00400668 77.04984850  0.32171227   0.40000000 0.15732911 1.30225249 -0.00630392 -0.00166667       0.00000000 128830928.00000000           0.00000000\n",
      "\n",
      "SGOV:\n",
      "              Adj Open    Adj High     Adj Low   Adj Close    Volume        ATR       ATRP        TRP         RSI     Mom_21  Consistency       IR_63     Beta_63      DD_21     Ret_1d  RollingStalePct    RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                                                             \n",
      "2025-11-25 99.68800000 99.68800000 99.67810000 99.68800000  19295631 0.01834312 0.00018401 0.00019862 99.53588672 0.00316786   1.00000000 -0.07639984 -0.00268791 0.00000000 0.00019866       0.00000000 1065799645.03100002           0.00000000\n",
      "2025-11-26 99.69790000 99.70780000 99.69790000 99.69790000  12061409 0.01844718 0.00018503 0.00019860 99.55772737 0.00316855   1.00000000 -0.08291436 -0.00272165 0.00000000 0.00009931       0.00000000 1069849423.72900009           0.00000000\n",
      "2025-11-28 99.72760000 99.73750000 99.71770000 99.72760000  24648238 0.01995810 0.00020013 0.00039708 99.61609489 0.00336744   1.00000000 -0.10714998 -0.00177000 0.00000000 0.00029790       0.00000000 1071194917.72519994           0.00000000\n",
      "2025-12-01 99.75050000 99.75050000 99.74050000 99.75050000  29208786 0.02016823 0.00020219 0.00022957 99.65400970 0.00349789   1.00000000 -0.11324718 -0.00202876 0.00000000 0.00022963       0.00000000 1074326468.23329997           0.00000000\n",
      "2025-12-02 99.76040000 99.77030000 99.76040000 99.77030000  14453245 0.02014193 0.00020188 0.00019846 99.68314748 0.00339829   1.00000000 -0.10601821 -0.00195925 0.00000000 0.00019850       0.00000000 1076621943.11249995           0.00000000\n",
      "2025-12-03 99.78030000 99.78520000 99.78030000 99.78030000  15629622 0.01976751 0.00019811 0.00014933 99.69702522 0.00321938   1.00000000 -0.09680422 -0.00210912 0.00000000 0.00010023       0.00000000 1079375150.22469997           0.00000000\n",
      "2025-12-04 99.79020000 99.80010000 99.79020000 99.80010000  13775997 0.01976983 0.00019809 0.00019840 99.72290387 0.00341846   1.00000000 -0.10451090 -0.00207578 0.00000000 0.00019844       0.00000000 1079375150.22469997           0.00000000\n",
      "2025-12-05 99.82000000 99.83000000 99.82000000 99.83000000  18031184 0.02049341 0.00020528 0.00029951 99.75670008 0.00351930   1.00000000 -0.10337225 -0.00209793 0.00000000 0.00029960       0.00000000 1084347630.51840019           0.00000000\n",
      "2025-12-08 99.83000000 99.83000000 99.82000000 99.83000000  16763030 0.01974388 0.00019778 0.00010017 99.75670008 0.00341945   0.80000000 -0.09222287 -0.00186033 0.00000000 0.00000000       0.00000000 1087271800.64120007           0.00000000\n",
      "2025-12-09 99.83990000 99.84490000 99.83990000 99.83990000  11085926 0.01939789 0.00019429 0.00014924 99.76758523 0.00321846   0.80000000 -0.08448454 -0.00180077 0.00000000 0.00009917       0.00000000 1088341938.33999991           0.00000000\n",
      "2025-12-10 99.84980000 99.84980000 99.83990000 99.83990000  12312117 0.01871947 0.00018749 0.00009916 99.76758523 0.00311867   0.60000000 -0.08164899 -0.00215338 0.00000000 0.00000000       0.00000000 1089180273.65000010           0.00000000\n",
      "2025-12-11 99.85980000 99.86970000 99.85980000 99.85980000  22484514 0.01951094 0.00019538 0.00029842 99.78953636 0.00321883   0.60000000 -0.08736703 -0.00208811 0.00000000 0.00019932       0.00000000 1094014507.05299997           0.00000000\n",
      "2025-12-12 99.88960000 99.89950000 99.88960000 99.89950000  13404266 0.02095301 0.00020974 0.00039740 99.82503872 0.00351785   0.60000000 -0.05241039 -0.00257431 0.00000000 0.00039756       0.00000000 1102242746.91459990           0.00000000\n",
      "2025-12-15 99.89950000 99.90950000 99.89950000 99.89950000  14861103 0.02017065 0.00020191 0.00010010 99.82503872 0.00341807   0.60000000 -0.05254588 -0.00246457 0.00000000 0.00000000       0.00000000 1106270118.97530007           0.00000000\n",
      "2025-12-16 99.91940000 99.91940000 99.90950000 99.90950000  10768737 0.02015132 0.00020170 0.00019918 99.83325566 0.00321923   0.60000000 -0.04945475 -0.00243779 0.00000000 0.00010010       0.00000000 1106270118.97530007           0.00000000\n",
      "2025-12-17 99.91940000 99.92930000 99.91940000 99.92930000  13875220 0.02012623 0.00020140 0.00019814 99.84843386 0.00331831   0.80000000 -0.01723785 -0.00253932 0.00000000 0.00019818       0.00000000 1109797054.27970004           0.00000000\n",
      "2025-12-18 99.93930000 99.93930000 99.92930000 99.92930000  21022445 0.01940293 0.00019417 0.00010007 99.84843386 0.00331831   0.60000000 -0.02314995 -0.00309745 0.00000000 0.00000000       0.00000000 1116728661.26160002           0.00000000\n",
      "\n",
      "BIL:\n",
      "              Adj Open    Adj High     Adj Low   Adj Close    Volume        ATR       ATRP        TRP         RSI     Mom_21  Consistency       IR_63     Beta_63      DD_21     Ret_1d  RollingStalePct   RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                                                            \n",
      "2025-11-25 90.76280000 90.76280000 90.75290000 90.76280000   9083268 0.01866357 0.00020563 0.00021815 97.58173812 0.00309340   0.60000000 -0.07714639 -0.00132341 0.00000000 0.00021820       0.00793651 759245355.21945000           0.00000000\n",
      "2025-11-26 90.78260000 90.78260000 90.77270000 90.77270000   6817704 0.01874474 0.00020650 0.00021813 97.70703281 0.00309417   0.80000000 -0.08366532 -0.00135402 0.00000000 0.00010908       0.00793651 759245355.21945000           0.00000000\n",
      "2025-11-28 90.80240000 90.81230000 90.80240000 90.80240000  10884083 0.02023440 0.00022284 0.00043611 98.03582110 0.00309427   0.80000000 -0.10752212 -0.00064064 0.00000000 0.00032719       0.00793651 762666166.90359998           0.00000000\n",
      "2025-12-01 90.82330000 90.82330000 90.81340000 90.81340000  16974973 0.02028194 0.00022334 0.00023014 98.14208025 0.00321578   0.80000000 -0.11419779 -0.00039908 0.00000000 0.00012114       0.00793651 765387716.46759999           0.00000000\n",
      "2025-12-02 90.83320000 90.84320000 90.82330000 90.84320000   7455300 0.02096180 0.00023075 0.00032804 98.39534526 0.00332552   1.00000000 -0.10671457 -0.00030812 0.00000000 0.00032815       0.00793651 765387716.46759999           0.00000000\n",
      "2025-12-03 90.84320000 90.85310000 90.84320000 90.85310000   6576684 0.02017168 0.00022203 0.00010897 98.46996491 0.00329303   1.00000000 -0.09750963 -0.00047521 0.00000000 0.00010898       0.00793651 762666166.90359998           0.00000000\n",
      "2025-12-04 90.86300000 90.87290000 90.86300000 90.86300000   7287432 0.02014513 0.00022171 0.00021791 98.54293346 0.00329267   1.00000000 -0.10569807 -0.00028914 0.00000000 0.00010897       0.00793651 759245355.21945000           0.00000000\n",
      "2025-12-05 90.89280000 90.89280000 90.88290000 90.88290000   7359634 0.02083476 0.00022925 0.00032789 98.67928100 0.00340272   1.00000000 -0.10433733 -0.00025416 0.00000000 0.00021901       0.00793651 759245355.21945000           0.00000000\n",
      "2025-12-08 90.89280000 90.90270000 90.89280000 90.89280000   7632132 0.02076085 0.00022841 0.00021784 98.74233321 0.00340234   1.00000000 -0.09315011 -0.00019087 0.00000000 0.00010893       0.00793651 759245355.21945000           0.00000000\n",
      "2025-12-09 90.91270000 90.91270000 90.90270000 90.91270000   9350696 0.02069936 0.00022768 0.00021889 98.86013352 0.00329308   1.00000000 -0.08516796 -0.00019790 0.00000000 0.00021894       0.00793651 762666166.90359998           0.00000000\n",
      "2025-12-10 90.91270000 90.92260000 90.91270000 90.91270000   7023092 0.01992798 0.00021920 0.00010890 98.86013352 0.00307390   0.80000000 -0.08215768 -0.00035440 0.00000000 0.00000000       0.00793651 762666166.90359998           0.00000000\n",
      "2025-12-11 90.92260000 90.93250000 90.92260000 90.92260000   7194585 0.01991884 0.00021907 0.00021777 98.91857596 0.00329272   0.80000000 -0.08813210 -0.00031587 0.00000000 0.00010890       0.00793651 759245355.21945000           0.00000000\n",
      "2025-12-12 90.96230000 90.96230000 90.95240000 90.96230000   6083047 0.02133178 0.00023451 0.00043644 99.11461646 0.00362115   0.80000000 -0.05323168 -0.00113303 0.00000000 0.00043664       0.00793651 759245355.21945000           0.00000000\n",
      "2025-12-15 90.96230000 90.97230000 90.96230000 90.96230000   6100569 0.02052236 0.00022561 0.00010994 99.11461646 0.00351154   0.60000000 -0.05318015 -0.00107075 0.00000000 0.00000000       0.00793651 759245355.21945000           0.00000000\n",
      "2025-12-16 90.97230000 90.98220000 90.97230000 90.97230000   7262760 0.02047791 0.00022510 0.00021875 99.15914610 0.00318360   0.60000000 -0.05008355 -0.00105252 0.00000000 0.00010994       0.00793651 759245355.21945000           0.00000000\n",
      "2025-12-17 90.98220000 90.99210000 90.98220000 90.98220000   9708788 0.02042949 0.00022454 0.00021762 99.20193919 0.00329277   0.80000000 -0.01782020 -0.00084862 0.00000000 0.00010882       0.00793651 762666166.90359998           0.00000000\n",
      "2025-12-18 90.99710000 90.99710000 90.98720000 90.99710000  10308117 0.02003452 0.00022017 0.00016374 99.26275295 0.00323803   0.80000000 -0.02349351 -0.00115790 0.00000000 0.00016377       0.00793651 765387716.46759999           0.00000000\n",
      "\n",
      "WBD:\n",
      "              Adj Open    Adj High     Adj Low   Adj Close     Volume        ATR       ATRP        TRP         RSI     Mom_21  Consistency      IR_63    Beta_63       DD_21      Ret_1d  RollingStalePct   RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                                                             \n",
      "2025-11-25 22.85000000 23.58000000 22.59000000 22.96000000   31113400 0.87801041 0.03824087 0.04311847 60.65728470 0.09125475   0.40000000 0.21827541 1.15292287 -0.03081469  0.00437445       0.00000000 461417225.50000000           0.00000000\n",
      "2025-11-26 23.17000000 23.91000000 23.17000000 23.88000000   40581600 0.88315252 0.03698294 0.03978224 66.74433064 0.13768461   0.60000000 0.23289430 1.20382000  0.00000000  0.04006969       0.00000000 462639157.50000000           0.00000000\n",
      "2025-11-28 23.80000000 24.20000000 23.65000000 24.00000000   19985500 0.85935592 0.03580650 0.02291667 67.45170385 0.12464855   0.80000000 0.24360277 1.11736214  0.00000000  0.00502513       0.00000000 463016717.50000000           0.00000000\n",
      "2025-12-01 23.82000000 24.12000000 23.64000000 23.87000000   36016900 0.83225906 0.03486632 0.02010892 65.81836315 0.10407031   0.60000000 0.24131772 1.12397125 -0.00541667 -0.00541667       0.00000000 463861951.50000000           0.00000000\n",
      "2025-12-02 24.25000000 24.76000000 24.03000000 24.53000000   46583800 0.83638342 0.03409635 0.03628210 69.81472060 0.09265033   0.80000000 0.24301037 1.11727071  0.00000000  0.02764977       0.00000000 465674681.50000000           0.00000000\n",
      "2025-12-03 24.24000000 24.74000000 24.10000000 24.57000000   22786500 0.82235603 0.03346992 0.02604803 70.04331519 0.10228802   0.80000000 0.25016701 1.17589591  0.00000000  0.00163066       0.00000000 470072309.00000000           0.00000000\n",
      "2025-12-04 24.17000000 24.57000000 24.05000000 24.54000000   38315600 0.80075917 0.03263077 0.02118989 69.61748638 0.08584071   0.60000000 0.23907730 1.19860043 -0.00122100 -0.00122100       0.00000000 473723745.00000000           0.00000000\n",
      "2025-12-05 25.45000000 26.10000000 24.98000000 26.08000000  198872300 0.85499066 0.03278338 0.05981595 77.26008876 0.14586995   0.60000000 0.25149120 1.20911863  0.00000000  0.06275469       0.00000000 475777332.00000000           0.00000000\n",
      "2025-12-08 27.64000000 28.17000000 26.84000000 27.23000000  167058200 0.94320561 0.03463847 0.07675358 81.08620416 0.21454059   0.80000000 0.26963039 1.17968061  0.00000000  0.04409509       0.00000000 478262978.50000000           0.00000000\n",
      "2025-12-09 27.46000000 28.34000000 27.37000000 28.26000000  106789400 0.95511950 0.03379758 0.03927813 83.72713688 0.24658139   0.80000000 0.27524709 1.16392581  0.00000000  0.03782593       0.00000000 479314264.00000000           0.00000000\n",
      "2025-12-10 28.98000000 29.81000000 28.86000000 29.53000000  103651300 0.99761096 0.03378297 0.05248899 86.27235922 0.28503046   0.80000000 0.27679288 0.64811377  0.00000000  0.04493984       0.00000000 479673772.50000000           0.00000000\n",
      "2025-12-11 29.44000000 29.72000000 29.35000000 29.49000000   43468400 0.95278161 0.03230863 0.01254663 85.81708145 0.27939262   0.80000000 0.24484579 0.69324747 -0.00135455 -0.00135455       0.00000000 479673772.50000000           0.00000000\n",
      "2025-12-12 29.88000000 30.00000000 29.75000000 29.98000000   45678400 0.92115435 0.03072563 0.01701134 86.74021002 0.35105904   0.80000000 0.24552573 0.61482705  0.00000000  0.01661580       0.00000000 480784342.50000000           0.00000000\n",
      "2025-12-15 29.84000000 29.92000000 29.50000000 29.71000000   53940500 0.88964332 0.02994424 0.01615618 83.51460359 0.34191509   0.60000000 0.29090520 0.58764699 -0.00900600 -0.00900600       0.00000000 483147580.00000000           0.00000000\n",
      "2025-12-16 29.46000000 29.51000000 28.71000000 28.90000000   85661500 0.89752594 0.03105626 0.03460208 74.55712099 0.25488493   0.40000000 0.28179081 0.60675268 -0.03602402 -0.02726355       0.00000000 483147580.00000000           0.00000000\n",
      "2025-12-17 28.55000000 28.85000000 28.19000000 28.21000000   70350800 0.88413123 0.03134106 0.02516838 67.87825158 0.24054529   0.20000000 0.25391161 0.64630212 -0.05903936 -0.02387543       0.00000000 489562062.50000000           0.00000000\n",
      "2025-12-18 28.35000000 28.38000000 27.41000000 27.61000000   67719600 0.89026472 0.03224429 0.03513220 62.62477451 0.16547066   0.20000000 0.21686041 0.55691539 -0.07905270 -0.02126905       0.00000000 495010866.50000000           0.00000000\n",
      "\n",
      "TD:\n",
      "              Adj Open    Adj High     Adj Low   Adj Close   Volume        ATR       ATRP        TRP         RSI     Mom_21  Consistency      IR_63    Beta_63       DD_21      Ret_1d  RollingStalePct   RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                                                           \n",
      "2025-11-25 82.50000000 83.02000000 81.94000000 82.31000000  2191800 1.19678953 0.01454003 0.01312113 57.19807551 0.00833027   0.40000000 0.04914724 0.45686095 -0.00519700 -0.00471584       0.00000000 115562541.61080000           0.00000000\n",
      "2025-11-26 82.69000000 83.57000000 82.44000000 83.44000000  2492100 1.20130456 0.01439723 0.01510067 62.97766973 0.00870406   0.60000000 0.15170702 0.50546847  0.00000000  0.01372859       0.00000000 115692425.61080001           0.00000000\n",
      "2025-11-28 83.55000000 84.06000000 83.37000000 83.93000000   654200 1.16478281 0.01387803 0.00822114 65.17372562 0.02629005   0.80000000 0.10136620 0.56755841  0.00000000  0.00587248       0.00000000 115562541.61080000           0.00000000\n",
      "2025-12-01 83.95000000 84.23000000 83.02000000 83.50000000  2457800 1.16801261 0.01398817 0.01449102 61.71416040 0.01941155   0.60000000 0.10167596 0.56153739 -0.00512332 -0.00512332       0.00000000 115562541.61080000           0.00000000\n",
      "2025-12-02 83.82000000 84.55000000 83.00000000 84.55000000  4317300 1.19529742 0.01413717 0.01833235 66.40384919 0.02946548   0.60000000 0.12371508 0.56381212  0.00000000  0.01257485       0.00000000 115692425.61080001           0.00000000\n",
      "2025-12-03 84.65000000 85.11000000 84.16000000 84.37000000  2112000 1.17777618 0.01395966 0.01125993 64.93541212 0.02978152   0.60000000 0.13463897 0.57657814 -0.00212892 -0.00212892       0.00000000 115933874.72640002           0.00000000\n",
      "2025-12-04 84.67000000 86.34000000 83.58000000 86.08000000  3954900 1.29079216 0.01499526 0.03206320 71.40480390 0.06878570   0.60000000 0.16768964 0.57210996  0.00000000  0.02026787       0.00000000 116121301.81389999           0.00000000\n",
      "2025-12-05 86.85000000 88.45000000 86.77000000 88.32000000  4420500 1.36787844 0.01548775 0.02683424 77.31033960 0.09496653   0.60000000 0.20038787 0.57803729  0.00000000  0.02602230       0.00000000 116121301.81389999           0.00000000\n",
      "2025-12-08 88.41000000 88.79000000 88.06000000 88.13000000  3922300 1.32231569 0.01500415 0.00828322 75.87888549 0.09573542   0.60000000 0.19141057 0.57885364 -0.00215127 -0.00215127       0.00000000 116121301.81389999           0.00000000\n",
      "2025-12-09 88.26000000 89.24000000 88.19000000 89.14000000  2627200 1.30715029 0.01466401 0.01245232 78.19060878 0.10185414   0.60000000 0.20424624 0.57247511  0.00000000  0.01146034       0.00000000 116121301.81389999           0.00000000\n",
      "2025-12-10 89.46000000 91.52000000 89.44000000 91.26000000  2848500 1.38378241 0.01516308 0.02607933 82.07407274 0.12472270   0.80000000 0.22214694 0.58934814  0.00000000  0.02378281       0.00000000 116121301.81389999           0.00000000\n",
      "2025-12-11 91.50000000 91.85000000 90.82000000 91.83000000  2345400 1.35851224 0.01479377 0.01121638 82.95298930 0.12536765   0.80000000 0.22915999 0.58960491  0.00000000  0.00624589       0.00000000 116121301.81389999           0.00000000\n",
      "2025-12-12 91.95000000 92.11000000 90.91000000 91.42000000  1734800 1.34718993 0.01473627 0.01312623 79.91768257 0.10490694   0.60000000 0.22981148 0.58399436 -0.00446477 -0.00446477       0.00000000 116121301.81389999           0.00000000\n",
      "2025-12-15 91.71000000 92.24000000 91.47000000 92.04000000  1542200 1.30953351 0.01422787 0.00890917 81.04706133 0.13140750   0.80000000 0.23599132 0.58177381  0.00000000  0.00678189       0.00000000 116121301.81389999           0.00000000\n",
      "2025-12-16 91.91000000 92.23000000 91.64000000 91.65000000  1259200 1.25813826 0.01372764 0.00643753 78.07277348 0.12661340   0.60000000 0.21992826 0.58856560 -0.00423729 -0.00423729       0.00000000 116121301.81389999           0.00000000\n",
      "2025-12-17 91.79000000 91.85000000 90.37000000 91.15000000  1880300 1.27398553 0.01397680 0.01623697 74.30773162 0.11909147   0.40000000 0.23868012 0.59768826 -0.00966971 -0.00545554       0.00000000 116325847.08750001           0.00000000\n",
      "2025-12-18 91.76000000 93.08000000 91.50000000 92.52000000  1957300 1.32084370 0.01427630 0.02086035 77.50830400 0.12472648   0.40000000 0.25518885 0.61575919  0.00000000  0.01503017       0.00000000 117022129.23260000           0.00000000\n",
      "\n",
      "MCHP:\n",
      "              Adj Open    Adj High     Adj Low   Adj Close    Volume        ATR       ATRP        TRP         RSI      Mom_21  Consistency       IR_63    Beta_63       DD_21      Ret_1d  RollingStalePct   RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                                                              \n",
      "2025-11-25 50.33000000 52.32000000 49.80000000 51.83000000   9605200 2.29601209 0.04429890 0.04862049 35.70700239 -0.18981445   0.60000000 -0.21765457 1.84938773 -0.17822901  0.01131707       0.00000000 500875292.06895000           0.00000000\n",
      "2025-11-26 51.87000000 53.36000000 51.55000000 52.57000000   6266100 2.26129694 0.04301497 0.03443028 38.72665255 -0.16649622   0.80000000 -0.19327856 1.87615223 -0.15183548  0.01427745       0.00000000 500875292.06895000           0.00000000\n",
      "2025-11-28 52.69000000 53.74000000 52.37000000 53.58000000   3755000 2.19763287 0.04101592 0.02556924 42.68347997 -0.13554014   1.00000000 -0.18290843 1.91423121 -0.13387863  0.01921248       0.00000000 499822651.81840003           0.00000000\n",
      "2025-12-01 52.88000000 54.27000000 52.62000000 53.43000000   5580800 2.15851624 0.04039896 0.03088153 42.24713762 -0.13143418   0.80000000 -0.17049252 1.89201633 -0.13630338 -0.00279955       0.00000000 498826625.34144998           0.00000000\n",
      "2025-12-02 53.80000000 57.35000000 53.41000000 56.71000000  11954000 2.28576508 0.04030621 0.06947628 53.45260941 -0.08328214   0.80000000 -0.10635363 1.91989858 -0.08313541  0.06138873       0.00000000 499822651.81840003           0.00000000\n",
      "2025-12-03 59.30000000 63.94000000 58.95000000 63.61000000  22906400 2.63892472 0.04148600 0.11366137 67.66550682  0.02842102   0.80000000 -0.02090403 1.99208177  0.00000000  0.12167166       0.00000000 500875292.06895000           0.00000000\n",
      "2025-12-04 63.97000000 65.49000000 63.22000000 64.72000000  12641900 2.61257295 0.04036732 0.03507417 69.29002763  0.09754257   0.80000000 -0.02668289 2.02318920  0.00000000  0.01745009       0.00000000 504415213.77534997           0.00000000\n",
      "2025-12-05 66.19000000 66.95000000 65.54000000 65.81000000  11350100 2.58524631 0.03928349 0.03388543 70.83935959  0.09216433   0.80000000 -0.01031108 2.03229411  0.00000000  0.01684178       0.00000000 504415213.77534997           0.00000000\n",
      "2025-12-08 66.30000000 67.42000000 66.27000000 67.35000000   8146600 2.51558586 0.03735094 0.02390497 72.91820150  0.14502843   1.00000000  0.01214875 2.00427225  0.00000000  0.02340070       0.00000000 504415213.77534997           0.00000000\n",
      "2025-12-09 66.87000000 67.49000000 66.53000000 66.85000000   7488600 2.40447259 0.03596818 0.01436051 71.14482206  0.19852484   0.80000000  0.01011022 2.00980924 -0.00742390 -0.00742390       0.00000000 501237147.31575000           0.00000000\n",
      "2025-12-10 66.79000000 68.20000000 66.23000000 67.90000000   8780400 2.37343883 0.03495492 0.02901325 72.64914345  0.23646310   0.80000000  0.01800110 2.03914704  0.00000000  0.01570681       0.00000000 501237147.31575000           0.00000000\n",
      "2025-12-11 67.82000000 69.27000000 66.78000000 69.09000000   8243200 2.38176463 0.03447336 0.03603995 74.28535606  0.27423189   0.80000000  0.02990030 2.04335578  0.00000000  0.01752577       0.00000000 501237147.31575000           0.00000000\n",
      "2025-12-12 69.36000000 69.56000000 66.63000000 67.18000000  13126900 2.42092430 0.03603638 0.04361417 67.32376819  0.21851460   0.60000000  0.03744056 2.10428689 -0.02764510 -0.02764510       0.00000000 501237147.31575000           0.00000000\n",
      "2025-12-15 68.06000000 68.09000000 66.52000000 67.18000000   6768000 2.36014399 0.03513165 0.02337005 67.32376819  0.23674521   0.40000000  0.02534234 2.11458536 -0.02764510  0.00000000       0.00000000 501237147.31575000           0.00000000\n",
      "2025-12-16 68.99000000 69.33000000 64.91000000 65.90000000   7294200 2.50727656 0.03804669 0.06707132 62.75303566  0.24335165   0.40000000  0.00202220 2.13731274 -0.04617166 -0.01905329       0.00000000 501237147.31575000           0.00000000\n",
      "2025-12-17 66.17000000 66.61000000 63.44000000 63.99000000   8750500 2.55461395 0.03992208 0.04953899 56.58013288  0.24888022   0.20000000 -0.01054760 2.15410921 -0.07381676 -0.02898331       0.00000000 501237147.31575000           0.00000000\n",
      "2025-12-18 65.32000000 65.68000000 63.75000000 64.06000000   6554800 2.50999867 0.03918200 0.03012800 56.74805569  0.27064601   0.20000000 -0.00125702 2.15894814 -0.07280359  0.00109392       0.00000000 500251054.75319993           0.00000000\n",
      "\n",
      "SLV:\n",
      "              Adj Open    Adj High     Adj Low   Adj Close    Volume        ATR       ATRP        TRP         RSI     Mom_21  Consistency      IR_63    Beta_63       DD_21      Ret_1d  RollingStalePct   RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                                                            \n",
      "2025-11-25 46.55000000 46.77000000 45.97000000 46.67000000  24006600 1.28764954 0.02759052 0.01714163 57.39853819 0.10070755   0.60000000 0.18805167 0.42836665 -0.03414735  0.00085782       0.00000000 641802804.00000000           0.00000000\n",
      "2025-11-26 47.31000000 48.45000000 47.15000000 48.40000000  26280300 1.32281743 0.02733094 0.03677686 63.60823976 0.13348946   0.60000000 0.19958359 0.46952826  0.00000000  0.03706878       0.00000000 645719956.50000000           0.00000000\n",
      "2025-11-28 49.67000000 51.27000000 49.58000000 51.21000000  41350000 1.43333047 0.02798927 0.05604374 71.00191602 0.18459403   0.80000000 0.21305970 0.56117836  0.00000000  0.05805785       0.00000000 647805484.50000000           0.00000000\n",
      "2025-12-01 51.99000000 53.36000000 51.61000000 52.52000000  66064100 1.48452115 0.02826583 0.04093679 73.68598765 0.18448354   1.00000000 0.21108171 0.58450532  0.00000000  0.02558094       0.00000000 650740709.50000000           0.00000000\n",
      "2025-12-02 52.83000000 53.20000000 51.77000000 53.13000000  43952700 1.48062678 0.02786800 0.02691511 74.85320224 0.20722563   1.00000000 0.21822030 0.58963432  0.00000000  0.01161462       0.00000000 652100645.50000000           0.00000000\n",
      "2025-12-03 52.99000000 53.39000000 52.42000000 53.07000000  33817700 1.44415344 0.02721224 0.01827775 74.50314077 0.21275137   0.80000000 0.23052869 0.62703325 -0.00112931 -0.00112931       0.00000000 653540732.00000000           0.00000000\n",
      "2025-12-04 52.28000000 52.36000000 51.14000000 51.76000000  48740300 1.47885676 0.02857142 0.03728748 67.12230531 0.21104352   0.60000000 0.20199655 0.63313009 -0.02578581 -0.02468438       0.00000000 659369198.00000000           0.00000000\n",
      "2025-12-05 52.71000000 53.82000000 52.53000000 52.95000000  43566000 1.52036700 0.02871326 0.03890463 70.02712813 0.21305842   0.60000000 0.21199967 0.63687830 -0.00338792  0.02299073       0.00000000 664306013.50000000           0.00000000\n",
      "2025-12-08 52.89000000 52.97000000 52.26000000 52.71000000  19711200 1.46248364 0.02774585 0.01346993 68.70863291 0.21033295   0.40000000 0.21945977 0.65123779 -0.00790514 -0.00453258       0.00000000 673351442.50000000           0.00000000\n",
      "2025-12-09 53.39000000 55.19000000 53.36000000 55.17000000  59738900 1.53516338 0.02782605 0.04495197 74.09303345 0.25614754   0.40000000 0.24380595 0.63254571  0.00000000  0.04667046       0.00000000 683057499.00000000           0.00000000\n",
      "2025-12-10 55.13000000 56.22000000 54.48000000 56.07000000  54915000 1.54979457 0.02764035 0.03103264 75.73790931 0.22450317   0.60000000 0.24916613 0.64469853  0.00000000  0.01631321       0.00000000 684533028.00000000           0.00000000\n",
      "2025-12-11 56.77000000 58.30000000 56.47000000 57.62000000  67910900 1.59838067 0.02774003 0.03870184 78.29396829 0.24047363   0.80000000 0.25516963 0.65583855  0.00000000  0.02764402       0.00000000 684533028.00000000           0.00000000\n",
      "2025-12-12 58.53000000 58.56000000 55.13000000 56.10000000  78667400 1.72921062 0.03082372 0.06114082 70.45512778 0.16100993   0.60000000 0.23906031 0.73179974 -0.02637973 -0.02637973       0.00000000 684533028.00000000           0.00000000\n",
      "2025-12-15 57.84000000 58.20000000 57.02000000 58.11000000  43227800 1.75569558 0.03021331 0.03613836 74.14198158 0.22543231   0.80000000 0.26270879 0.70983635  0.00000000  0.03582888       0.00000000 689601304.50000000           0.00000000\n",
      "2025-12-16 57.61000000 57.99000000 57.10000000 57.73000000  32461300 1.70243161 0.02948955 0.01749524 72.30496060 0.25609225   0.60000000 0.27564029 0.70682857 -0.00653932 -0.00653932       0.00000000 689601304.50000000           0.00000000\n",
      "2025-12-17 59.27000000 60.64000000 59.05000000 60.26000000  65128000 1.78868649 0.02968282 0.04829074 76.48284416 0.32526941   0.60000000 0.30240893 0.58028805  0.00000000  0.04382470       0.00000000 695435716.50000000           0.00000000\n",
      "2025-12-18 59.82000000 60.03000000 58.58000000 59.32000000  47603400 1.78092317 0.03002231 0.02832097 72.12915702 0.28676790   0.40000000 0.27006944 0.50865705 -0.01559907 -0.01559907       0.00000000 696927192.00000000           0.00000000\n",
      "\n",
      "DG:\n",
      "               Adj Open     Adj High      Adj Low    Adj Close    Volume        ATR       ATRP        TRP         RSI     Mom_21  Consistency       IR_63    Beta_63       DD_21      Ret_1d  RollingStalePct   RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                                                                 \n",
      "2025-11-25 102.10500000 105.87800000 101.81600000 103.86700000   3029666 2.88010455 0.02772877 0.04447996 56.37987266 0.01498036   0.60000000 -0.08183022 0.32968531  0.00000000  0.02576587       0.00000000 297886344.56825000           0.00000000\n",
      "2025-11-26 104.28500000 108.78600000 104.07600000 108.30800000   3131699 3.02573994 0.02793644 0.04541677 65.06759343 0.06721058   0.80000000 -0.05040190 0.39338524  0.00000000  0.04275660       0.00000000 298085203.15024996           0.00000000\n",
      "2025-11-28 108.18900000 109.31400000 108.03900000 109.02500000   1386287 2.90068709 0.02660571 0.01169457 66.23678529 0.09588614   0.80000000 -0.03273064 0.35556008  0.00000000  0.00662001       0.00000000 297886344.56825000           0.00000000\n",
      "2025-12-01 108.68600000 110.59800000 107.82000000 108.87600000   3335464 2.89192372 0.02656163 0.02551527 65.74432936 0.09801517   0.60000000 -0.04997969 0.39670238 -0.00136666 -0.00136666       0.00000000 298085203.15024996           0.00000000\n",
      "2025-12-02 109.05500000 110.04100000 107.93000000 109.56300000   3578296 2.83614346 0.02588596 0.01926745 66.96391378 0.11524720   0.80000000 -0.03576725 0.40868863  0.00000000  0.00630993       0.00000000 298620378.53909993           0.00000000\n",
      "2025-12-03 110.32900000 111.39500000 109.42300000 109.42300000   5496040 2.77441893 0.02535499 0.01802181 66.44475989 0.10809448   0.60000000 -0.02319065 0.43695742 -0.00127780 -0.00127780       0.00000000 299233790.61489999           0.00000000\n",
      "2025-12-04 115.25800000 124.90700000 114.13300000 124.75800000  14250318 3.68224615 0.02951511 0.12411228 82.47333655 0.25578909   0.60000000  0.06323940 0.43769549  0.00000000  0.14014421       0.00000000 299532435.46050000           0.00000000\n",
      "2025-12-05 124.65800000 134.50600000 123.71200000 131.80800000  12394838 4.19022856 0.03179040 0.08189184 85.82554488 0.31567232   0.60000000  0.09870863 0.45515440  0.00000000  0.05650940       0.00000000 299532435.46050000           0.00000000\n",
      "2025-12-08 132.51500000 132.52500000 122.17900000 123.74200000   6788629 4.62992652 0.03741597 0.08360945 69.45725971 0.29528559   0.60000000  0.08634993 0.53888336 -0.06119507 -0.06119507       0.00000000 299532435.46050000           0.00000000\n",
      "2025-12-09 124.43900000 128.00400000 123.54300000 125.00700000   4103727 4.61786034 0.03694081 0.03568600 70.41036996 0.26527097   0.60000000  0.08385427 0.52717185 -0.05159778  0.01022288       0.00000000 299532435.46050000           0.00000000\n",
      "2025-12-10 126.00300000 126.09200000 123.33400000 125.35500000   2951936 4.48501318 0.03577849 0.02200152 70.68142123 0.25388102   0.80000000  0.09289001 0.55745889 -0.04895757  0.00278384       0.00000000 299532435.46050000           0.00000000\n",
      "2025-12-11 125.71400000 132.14600000 125.61400000 132.11700000   4226750 4.64972652 0.03519401 0.05140141 75.39741541 0.27491605   0.80000000  0.12576307 0.57433434  0.00000000  0.05394280       0.00000000 299739488.23749995           0.00000000\n",
      "2025-12-12 131.93700000 132.74400000 130.22500000 132.64400000   4612388 4.49753177 0.03390679 0.01899068 75.72513865 0.27828693   0.80000000  0.13662329 0.56230400  0.00000000  0.00398889       0.00000000 300040949.10000002           0.00000000\n",
      "2025-12-15 133.73000000 134.99400000 131.46900000 132.36500000   4581054 4.42806521 0.03345344 0.02663091 75.15437143 0.27583182   0.80000000  0.13720898 0.56200824 -0.00210337 -0.00210337       0.00000000 300264854.16549999           0.00000000\n",
      "2025-12-16 132.37500000 135.10400000 132.23600000 133.93900000   6173918 4.31663198 0.03222834 0.02141273 76.24231956 0.28964827   0.80000000  0.13443686 0.56101806  0.00000000  0.01189136       0.00000000 301228591.84099996           0.00000000\n",
      "2025-12-17 133.62000000 137.01600000 132.93300000 136.38800000   3781760 4.29994399 0.03152729 0.02993665 77.86630058 0.32786821   0.80000000  0.14893900 0.50007872  0.00000000  0.01828444       0.00000000 302598463.66549999           0.00000000\n",
      "2025-12-18 135.37300000 137.31400000 135.08400000 136.10000000   4353889 4.15209084 0.03050765 0.01638501 77.19800075 0.32275904   0.60000000  0.17722977 0.54256506 -0.00211162 -0.00211162       0.00000000 305852379.51124996           0.00000000\n",
      "\n",
      "MINT:\n",
      "              Adj Open    Adj High     Adj Low   Adj Close   Volume        ATR       ATRP        TRP         RSI     Mom_21  Consistency       IR_63    Beta_63       DD_21      Ret_1d  RollingStalePct   RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                                                            \n",
      "2025-11-25 99.53460000 99.54440000 99.52470000 99.53460000  1548095 0.02556140 0.00025681 0.00019792 95.68364144 0.00378887   0.60000000 -0.07536820 0.00403695  0.00000000  0.00009947       0.00000000 115897034.93380000           0.00000000\n",
      "2025-11-26 99.55430000 99.57410000 99.54450000 99.57410000  1299967 0.02655701 0.00026671 0.00039669 96.28736939 0.00388755   0.80000000 -0.08155431 0.00434788  0.00000000  0.00039685       0.00000000 116003880.08170000           0.00000000\n",
      "2025-11-28 99.57410000 99.58400000 99.57410000 99.58400000   961078 0.02536723 0.00025473 0.00009941 96.42243180 0.00378799   1.00000000 -0.10566126 0.00451441  0.00000000  0.00009942       0.00000000 116003880.08170000           0.00000000\n",
      "2025-12-01 99.60390000 99.61380000 99.59400000 99.60390000  1855880 0.02568385 0.00025786 0.00029919 96.68360106 0.00398858   1.00000000 -0.11186027 0.00435808  0.00000000  0.00019983       0.00000000 116572920.15615001           0.00000000\n",
      "2025-12-02 99.61380000 99.62370000 99.60390000 99.61380000  1168107 0.02526358 0.00025362 0.00019877 96.80842725 0.00368976   1.00000000 -0.10459571 0.00457144  0.00000000  0.00009939       0.00000000 116699844.73510000           0.00000000\n",
      "2025-12-03 99.62370000 99.63370000 99.62370000 99.62370000  1539383 0.02488047 0.00024974 0.00019975 96.93275610 0.00348922   1.00000000 -0.09531964 0.00453082  0.00000000  0.00009938       0.00000000 117139638.06205000           0.00000000\n",
      "2025-12-04 99.64360000 99.64360000 99.62370000 99.63370000  1758202 0.02452472 0.00024615 0.00019973 97.05744871 0.00348988   1.00000000 -0.10262398 0.00426361  0.00000000  0.00010038       0.00000000 117139638.06205000           0.00000000\n",
      "2025-12-05 99.66350000 99.67340000 99.65350000 99.67340000  1414617 0.02560867 0.00025693 0.00039830 97.49315606 0.00378964   1.00000000 -0.10188739 0.00414849  0.00000000  0.00039846       0.00000000 117334739.64004999           0.00000000\n",
      "2025-12-08 99.68330000 99.68330000 99.66350000 99.66350000  1377762 0.02519376 0.00025279 0.00019867 93.76461287 0.00348984   0.80000000 -0.09109146 0.00445290 -0.00009932 -0.00009932       0.00000000 117695206.80505000           0.00000000\n",
      "2025-12-09 99.67340000 99.68330000 99.67340000 99.67340000   877792 0.02480849 0.00024890 0.00019865 94.01126497 0.00338948   0.80000000 -0.08330609 0.00452799  0.00000000  0.00009933       0.00000000 117695206.80505000           0.00000000\n",
      "2025-12-10 99.68330000 99.71310000 99.68330000 99.70320000  1485207 0.02587217 0.00025949 0.00039818 94.69191662 0.00338948   0.80000000 -0.07986781 0.00470285  0.00000000  0.00029898       0.00000000 118622075.12905000           0.00000000\n",
      "2025-12-11 99.73300000 99.74290000 99.72310000 99.73300000  1133063 0.02685987 0.00026932 0.00039806 95.27076566 0.00368938   0.80000000 -0.08584195 0.00485824  0.00000000  0.00029889       0.00000000 117695206.80505000           0.00000000\n",
      "2025-12-12 99.77270000 99.77270000 99.75280000 99.76280000  1048778 0.02777703 0.00027843 0.00039794 95.76779186 0.00388926   0.80000000 -0.05069170 0.00466394  0.00000000  0.00029880       0.00000000 117334739.64004999           0.00000000\n",
      "2025-12-15 99.77270000 99.78260000 99.76280000 99.77270000  1239603 0.02720724 0.00027269 0.00019845 95.92115781 0.00378989   1.00000000 -0.05062036 0.00471773  0.00000000  0.00009924       0.00000000 118357183.87360001           0.00000000\n",
      "2025-12-16 99.79260000 99.80250000 99.78260000 99.80250000  1195497 0.02739244 0.00027447 0.00029859 96.34993202 0.00378976   1.00000000 -0.04709355 0.00456334  0.00000000  0.00029868       0.00000000 119298820.77005000           0.00000000\n",
      "2025-12-17 99.80250000 99.82230000 99.80250000 99.81240000  1807041 0.02685012 0.00026901 0.00019837 96.48223281 0.00378939   1.00000000 -0.01509589 0.00451961  0.00000000  0.00009920       0.00000000 119554054.90799999           0.00000000\n",
      "2025-12-18 99.82240000 99.83230000 99.82240000 99.82240000  1378567 0.02635368 0.00026401 0.00019935 96.61567202 0.00359020   1.00000000 -0.02085807 0.00408110  0.00000000  0.00010019       0.00000000 119993094.81674999           0.00000000\n",
      "\n",
      "SPY:\n",
      "               Adj Open     Adj High      Adj Low    Adj Close     Volume        ATR       ATRP        TRP         RSI      Mom_21  Consistency      IR_63    Beta_63       DD_21      Ret_1d  RollingStalePct     RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                                                                                    \n",
      "2025-11-25 666.66000000 674.21800000 662.52200000 673.03100000   81316678 9.90268572 0.01471357 0.01737810 53.87250626 -0.01491465   0.80000000 0.00000000 1.00000000 -0.01799625  0.00940518       0.00000000 40854073081.28450012           0.00000000\n",
      "2025-11-26 675.63400000 679.69200000 674.72600000 677.67800000   72091994 9.67113674 0.01427099 0.00982915 56.83965536 -0.01074104   0.80000000 0.00000000 1.00000000 -0.01121592  0.00690459       0.00000000 40910962508.82949829           0.00000000\n",
      "2025-11-28 678.85400000 681.65600000 678.49500000 681.37700000   49357418 9.26448411 0.01359671 0.00583818 59.09519362 -0.00581880   1.00000000 0.00000000 1.00000000  0.00000000  0.00545834       0.00000000 40910962508.82949829           0.00000000\n",
      "2025-12-01 676.81000000 680.97800000 676.74000000 678.26600000   61382043 8.93394953 0.01317175 0.00683655 56.42444535  0.00064766   0.80000000 0.00000000 1.00000000 -0.00456575 -0.00456575       0.00000000 41031556610.48500061           0.00000000\n",
      "2025-12-02 679.91100000 681.80500000 677.32900000 679.52200000   63139823 8.61552457 0.01267880 0.00658698 57.26418962 -0.00077788   0.80000000 0.00000000 1.00000000 -0.00272243  0.00185178       0.00000000 41141626696.64700317           0.00000000\n",
      "2025-12-03 678.56500000 682.89200000 677.68700000 681.87500000   57407635 8.37191567 0.01227779 0.00763336 58.86355558  0.00080431   0.80000000 0.00000000 1.00000000  0.00000000  0.00346273       0.00000000 41141626696.64700317           0.00000000\n",
      "2025-12-04 683.28100000 683.35100000 679.33300000 682.37400000   62153417 8.06092169 0.01181306 0.00588827 59.21217355  0.01355067   0.80000000 0.00000000 1.00000000  0.00000000  0.00073181       0.00000000 41220730396.73399353           0.00000000\n",
      "2025-12-05 683.45000000 686.36200000 682.56300000 683.67000000   79475152 7.76999872 0.01136513 0.00583322 60.15660087  0.01196890   0.80000000 0.00000000 1.00000000  0.00000000  0.00189925       0.00000000 41262529087.83499908           0.00000000\n",
      "2025-12-08 684.56700000 684.61700000 679.56200000 681.61600000   55394702 7.57607024 0.01111487 0.00741620 57.86958861  0.01987177   0.80000000 0.00000000 1.00000000 -0.00300437 -0.00300437       0.00000000 41262529087.83499908           0.00000000\n",
      "2025-12-09 681.13700000 683.37100000 680.57900000 681.02800000   58482402 7.23435093 0.01062269 0.00409968 57.19918459  0.01798972   0.60000000 0.00000000 1.00000000 -0.00386444 -0.00086266       0.00000000 41262529087.83499908           0.00000000\n",
      "2025-12-10 680.54900000 686.94000000 679.30300000 685.54400000   85924447 7.26311158 0.01059467 0.01114006 60.94167835  0.00899575   0.60000000 0.00000000 1.00000000  0.00000000  0.00663115       0.00000000 41277080659.12800598           0.00000000\n",
      "2025-12-11 683.12100000 687.21900000 680.16000000 687.14000000   86428338 7.24853218 0.01054884 0.01027302 62.19964340  0.00903393   0.60000000 0.00000000 1.00000000  0.00000000  0.00232808       0.00000000 41302882552.29200745           0.00000000\n",
      "2025-12-12 686.14200000 686.85000000 677.16900000 679.75100000  113494678 7.44299417 0.01094959 0.01466861 53.59356824 -0.00237170   0.40000000 0.00000000 1.00000000 -0.01075327 -0.01075327       0.00000000 41424811473.31000519           0.00000000\n",
      "2025-12-15 683.72000000 683.74000000 677.24900000 678.72400000   91079336 7.37499459 0.01086597 0.00956353 52.50614936  0.01293019   0.40000000 0.00000000 1.00000000 -0.01224787 -0.00151085       0.00000000 41566731947.80799866           0.00000000\n",
      "2025-12-16 677.22900000 679.07300000 672.99100000 676.87000000  122391184 7.28263783 0.01075929 0.00898548 50.51356734  0.01032913   0.40000000 0.00000000 1.00000000 -0.01494601 -0.00273160       0.00000000 41617598334.46899414           0.00000000\n",
      "2025-12-17 677.88700000 678.43500000 669.22300000 669.42200000  110952088 7.42044941 0.01108486 0.01376113 43.38982001  0.00860769   0.20000000 0.00000000 1.00000000 -0.02578514 -0.01100359       0.00000000 41838351514.20899963           0.00000000\n",
      "2025-12-18 675.60400000 678.73400000 672.91200000 674.47700000  108971155 7.55556017 0.01120210 0.01380625 48.67981053  0.02483077   0.20000000 0.00000000 1.00000000 -0.01842856  0.00755129       0.00000000 42062148120.32600403           0.00000000\n",
      "\n",
      "‚úì Saved SHV with header\n",
      "‚úì Appended CFLT\n",
      "‚úì Appended SGOV\n",
      "‚úì Appended BIL\n",
      "‚úì Appended WBD\n",
      "‚úì Appended TD\n",
      "‚úì Appended MCHP\n",
      "‚úì Appended SLV\n",
      "‚úì Appended DG\n",
      "‚úì Appended MINT\n",
      "‚úì Appended SPY\n",
      "\n",
      "‚úì Saved all tickers to: C:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\notebooks_RLVR\\output\\all_tickers_data_stacked.csv\n"
     ]
    }
   ],
   "source": [
    "# Single call replaces your 3 cells\n",
    "file_path = export_last_run_tickers_data_to_csv(\n",
    "    analyzer=my_analyzer,\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    features_df=features_df,\n",
    "    filename=\"all_tickers_data_stacked.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c160a5",
   "metadata": {},
   "source": [
    "### Audit features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa40b6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Takes 4 minutes to run, checks all tickers from my_analyzer\n",
    "# audit_feature_engineering_integrity(my_analyzer, df_indices=df_indices, mode=\"system\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf25a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
