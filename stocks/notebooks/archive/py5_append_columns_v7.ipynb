{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create \"ATR/Price %\" in df_finviz\n",
    "#### Calculate \"Perf 3D %\" in df_Perf_3D_pct\n",
    "#### Merge columns of df_finviz and df_Perf_3D_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process_files.py\n",
    "from config import DATE_STR, DOWNLOAD_DIR, DEST_DIR\n",
    "from pathlib import Path  # Better path handling\n",
    "\n",
    "print(f\"DATE_STR: {DATE_STR}\")\n",
    "print(f\"DOWNLOAD_DIR: {DOWNLOAD_DIR}\")\n",
    "print(f\"DEST_DIR: {DEST_DIR}\\n\")\n",
    "\n",
    "# Build paths\n",
    "# ohlcv_path = Path(DEST_DIR) / f'{DATE_STR}_df_OHLCV_clean_stocks_etfs.parquet'\n",
    "ohlcv_path = Path(DEST_DIR) / f'df_OHLCV_clean_stocks_etfs.parquet'\n",
    "source_path = Path(DEST_DIR) / f'{DATE_STR}_df_finviz_n_ratios_stocks_etfs.parquet'\n",
    "dest_path = Path(DEST_DIR) / f'{DATE_STR}_df_finviz_merged_stocks_etfs.parquet'\n",
    "tickers_path = Path(DEST_DIR) / f'{DATE_STR}_df_common_tickers_stocks_etfs.parquet'\n",
    "\n",
    "print(f\"ohlcv_path: {ohlcv_path}\")\n",
    "print(f\"source_path: {source_path}\")\n",
    "print(f\"dest_path: {dest_path}\")\n",
    "print(f\"tickers_path: {tickers_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set pandas display options to show more columns and rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.max_rows', None)       # Limit to 10 rows for readability\n",
    "pd.set_option('display.width', None)        # Let the display adjust to the window\n",
    "pd.set_option('display.width', 2000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the parquet file into a DataFrame\n",
    "df_finviz = pd.read_parquet(source_path)\n",
    "\n",
    "# Display basic information about the DataFrame\n",
    "print(f\"df_finviz.shape: {df_finviz.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df_finviz.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ATR/Price ratio and format it as percentage\n",
    "df_finviz['ATR/Price %'] = (df_finviz['ATR'] / df_finviz['Price']) * 100\n",
    "\n",
    "# Display the first few rows of the new column\n",
    "print(\"\\nFirst few rows of ATR/Price column:\")\n",
    "display(df_finviz[['ATR', 'Price', 'ATR/Price %']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common_tickers = pd.read_parquet(tickers_path)\n",
    "tickers = df_common_tickers.index.to_list()\n",
    "\n",
    "print(f'len(tickers): {len(tickers)}')\n",
    "print(f'tickers[0:5]: {tickers[0:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  # Import numpy\n",
    "\n",
    "# 1. Load Data\n",
    "df_OHLCV = pd.read_parquet(ohlcv_path)\n",
    "print(\"df_OHLCV Info:\")\n",
    "display(df_OHLCV.info())\n",
    "\n",
    "\n",
    "# 2. Prepare Adjusted Close Data\n",
    "df_adj_close = df_OHLCV[['Adj Close']].unstack(level=0)\n",
    "df_adj_close.columns = df_adj_close.columns.get_level_values(1)\n",
    "df_adj_close = df_adj_close.sort_index(axis=0)\n",
    "\n",
    "print(f'Before filter, len(df_adj_close.columns): {len(df_adj_close.columns)}\\n')\n",
    "df_adj_close = df_adj_close[tickers]\n",
    "print(f'After filter, len(df_adj_close.columns): {len(df_adj_close.columns)}\\n')\n",
    "print(\"df_adj_close Info:\")\n",
    "print(df_adj_close.info())\n",
    "print(\"df_adj_close Tail:\")\n",
    "display(df_adj_close.tail())\n",
    "\n",
    "\n",
    "# 4. Calculate Returns\n",
    "df_returns = df_adj_close.pct_change(periods=3) * 100\n",
    "df_Perf_3D_pct = df_returns.tail(1)\n",
    "\n",
    "\n",
    "# 5. Display Returns\n",
    "pd.options.display.float_format = '{:.5f}'.format\n",
    "print(\"df_Perf_3D_pct:\")\n",
    "display(df_Perf_3D_pct)\n",
    "print(\"df_Perf_3D_pct Info:\")\n",
    "df_Perf_3D_pct.info()\n",
    "print(df_Perf_3D_pct.info())  # Print is redundant, info is already displayed above\n",
    "print(\"df_Perf_3D_pct Head:\")\n",
    "print(df_Perf_3D_pct.head(2))\n",
    "\n",
    "\n",
    "# 6. Define Merge Function\n",
    "def merge_dataframes(df, df_Perf_3D_pct):\n",
    "    \"\"\"\n",
    "    Merges data from df_Perf_3D_pct into df, aligning based on tickers.\n",
    "    Renames the added column to \"Perf 3D %\".\n",
    "\n",
    "    Assumptions:\n",
    "      - df_Perf_3D_pct has columns representing tickers.\n",
    "      - df has an index representing tickers.\n",
    "    \"\"\"\n",
    "    # Transpose df_Perf_3D_pct so that tickers become the index.\n",
    "    df_Perf_3D_pct_transposed = df_Perf_3D_pct.T\n",
    "    df_Perf_3D_pct_transposed.index.name = 'Ticker'\n",
    "\n",
    "    # Ensure that the main dataframe's index also has a name if it doesn't\n",
    "    if df.index.name is None:\n",
    "        df.index.name = 'Ticker'\n",
    "\n",
    "    # Merge the two dataframes based on the index (which represents the tickers)\n",
    "    df_merged = df.merge(df_Perf_3D_pct_transposed, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    # Rename the added column, using the *last* column name\n",
    "    if df_merged.shape[1] > df.shape[1]:  # Check if new columns were actually added\n",
    "        last_col = df_merged.columns[-1]  # Get the last column name which is what we need to rename\n",
    "        df_merged = df_merged.rename(columns={last_col: 'Perf 3D %'})\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "\n",
    "# 7. Merge Dataframes\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "df_merged = merge_dataframes(df_finviz, df_Perf_3D_pct)\n",
    "print(\"df_merged Head:\")\n",
    "print(df_merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def find_duplicate_columns(df):\n",
    "  \"\"\"\n",
    "  Finds and returns a list of duplicate column names in a Pandas DataFrame.\n",
    "\n",
    "  Args:\n",
    "    df: The Pandas DataFrame to check.\n",
    "\n",
    "  Returns:\n",
    "    A list of column names that are duplicates (excluding the first occurrence).\n",
    "    Returns an empty list if no duplicate columns are found.\n",
    "  \"\"\"\n",
    "\n",
    "  duplicate_columns = []\n",
    "  seen_columns = set()  # Keep track of columns we've already encountered\n",
    "\n",
    "  for col in df.columns:\n",
    "    if col in seen_columns:\n",
    "      duplicate_columns.append(col)\n",
    "    else:\n",
    "      seen_columns.add(col)\n",
    "\n",
    "  return duplicate_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_cols = find_duplicate_columns(df_merged)\n",
    "\n",
    "if duplicate_cols:\n",
    "    print(\"Duplicate columns found:\")\n",
    "    for col in duplicate_cols:\n",
    "        print(f\"- {col}\")\n",
    "    raise ValueError(\"Duplicate columns found\") # Raise the error\n",
    "else:\n",
    "    print(\"No duplicate columns found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_merged.columns.to_list())\n",
    "print(f\"len(df_merged.columns): {len(df_merged.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_order = ['No.', 'Company', 'Index', 'Sector', 'Industry', 'Country', 'Exchange',\n",
    "                    'Info', 'MktCap AUM, M', 'Rank',\n",
    "                    'Market Cap, M', 'P/E', 'Fwd P/E', 'PEG', 'P/S', 'P/B', 'P/C', 'P/FCF', \n",
    "                    'Book/sh', 'Cash/sh', 'Dividend %', 'Dividend TTM', 'Dividend Ex Date', \n",
    "                    'Payout Ratio %', 'EPS', 'EPS next Q', 'EPS this Y %', 'EPS next Y %', \n",
    "                    'EPS past 5Y %', 'EPS next 5Y %', 'Sales past 5Y %', 'Sales Q/Q %', \n",
    "                    'EPS Q/Q %', 'EPS YoY TTM %', 'Sales YoY TTM %', 'Sales, M', 'Income, M', \n",
    "                    'EPS Surprise %', 'Revenue Surprise %', 'Outstanding, M', \n",
    "                    'Float, M', 'Float %', 'Insider Own %', 'Insider Trans %', 'Inst Own %', \n",
    "                    'Inst Trans %', 'Short Float %', 'Short Ratio', 'Short Interest, M', \n",
    "                    # 'ROA %', 'ROE %', 'ROI %', 'Curr R', 'Quick R', 'LTDebt/Eq', 'Debt/Eq', \n",
    "                    'ROA %', 'ROE %', 'ROIC %', 'Curr R', 'Quick R', 'LTDebt/Eq', 'Debt/Eq',                     \n",
    "                    'Gross M %', 'Oper M %', 'Profit M %', 'Perf 3D %', 'Perf Week %', 'Perf Month %', \n",
    "                    'Perf Quart %', 'Perf Half %', 'Perf Year %', 'Perf YTD %', 'Beta', 'ATR','ATR/Price %',\n",
    "                    'Volatility W %', 'Volatility M %', 'SMA20 %', 'SMA50 %', 'SMA200 %', \n",
    "                    '50D High %', '50D Low %', '52W High %', '52W Low %', '52W Range', \n",
    "                    'All-Time High %', 'All-Time Low %', 'RSI', 'Earnings', 'IPO Date', \n",
    "                    'Optionable', 'Shortable', 'Employees', 'Change from Open %', 'Gap %', \n",
    "                    'Recom', 'Avg Volume, M', 'Rel Volume', 'Volume', 'Target Price', \n",
    "                    'Prev Close', 'Open', 'High', 'Low', 'Price', 'Change %', 'Single Category', \n",
    "                    'Asset Type', 'Expense %', 'Holdings', 'AUM, M', 'Flows 1M, M', 'Flows% 1M', \n",
    "                    'Flows 3M, M', 'Flows% 3M', 'Flows YTD, M', 'Flows% YTD', 'Return% 1Y', \n",
    "                    'Return% 3Y', 'Return% 5Y', 'Tags', 'Sharpe 3d', 'Sortino 3d', 'Omega 3d', \n",
    "                    'Sharpe 5d', 'Sortino 5d', 'Omega 5d', 'Sharpe 10d', 'Sortino 10d', 'Omega 10d', \n",
    "                    'Sharpe 15d', 'Sortino 15d', 'Omega 15d', 'Sharpe 30d', 'Sortino 30d', 'Omega 30d', \n",
    "                    'Sharpe 60d', 'Sortino 60d', 'Omega 60d', 'Sharpe 120d', 'Sortino 120d', \n",
    "                    'Omega 120d', 'Sharpe 250d', 'Sortino 250d', 'Omega 250d',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'len(new_column_order): {len(new_column_order)}')\n",
    "print(f'len(df_merged.columns.to_list()): {len(df_merged.columns.to_list())}')\n",
    "missing_columns = [col for col in df_merged.columns.to_list() if col not in new_column_order]\n",
    "# missing_columns = [col for col in new_column_order if col not in df_merged.columns.to_list()]\n",
    "print(f'missing_columns: {missing_columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindex the DataFrame with the new column order\n",
    "df_merged = df_merged.reindex(columns=new_column_order)\n",
    "\n",
    "print(\"reindexed df_merged Head:\")\n",
    "print(df_merged.head(), df_merged.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_parquet(dest_path, engine='pyarrow', compression='zstd')\n",
    "print(f\"Merged dataframe saved to {dest_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'df_merged shape: {df_merged.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.columns.to_list()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
