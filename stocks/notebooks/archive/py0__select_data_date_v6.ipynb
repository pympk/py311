{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing Orchestrator\n",
    "\n",
    "This notebook orchestrates a data processing workflow by preparing a configuration file and running an external analysis script (`run_sequence.py`) for one or more dates.\n",
    "\n",
    "**Workflow:**\n",
    "\n",
    "1.  **Prerequisites:**\n",
    "    *   The `Yloader` application has been run to download OHLCV data.\n",
    "    *   A `finviz` data generation process has created `.parquet` files (e.g., `df_finviz_YYYY-MM-DD.parquet`) in the `Downloads` directory.\n",
    "2.  **Find Data:** The notebook scans the `Downloads` directory for recent Finviz data files.\n",
    "3.  **Select Date(s):** It extracts all available dates from the filenames and selects a subset for processing based on user configuration (e.g., only the latest date).\n",
    "4.  **Configure & Run:** For each selected date, it generates a `config.py` file and executes the `run_sequence.py` script.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and Configuration\n",
    "\n",
    "**This is the only cell you need to modify.** Adjust the variables below to match your environment and desired processing scope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# --- Project and Path Configuration ---\n",
    "\n",
    "# Autodetect the project's root directory.\n",
    "# Assumes this notebook is in `root/notebooks/` or the `root/` directory.\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "ROOT_DIR = NOTEBOOK_DIR.parent if NOTEBOOK_DIR.name == 'notebooks' else NOTEBOOK_DIR\n",
    "\n",
    "# Add the project's root directory to the Python path so we can import 'config'\n",
    "if str(ROOT_DIR) not in sys.path:\n",
    "    sys.path.append(str(ROOT_DIR))\n",
    "\n",
    "# Add the project's source directory to the Python path\n",
    "SRC_DIR = ROOT_DIR / 'src'\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.append(str(SRC_DIR))\n",
    "    \n",
    "# Import the custom utility module now that the path is set\n",
    "import utils\n",
    "from config import ANNUAL_RISK_FREE_RATE, TRADING_DAYS_PER_YEAR\n",
    "\n",
    "# --- Data File Configuration ---\n",
    "DOWNLOADS_DIR = Path.home() / \"Downloads\"\n",
    "DATA_FILE_PREFIX = 'df_finviz'  # Prefix for files like 'df_finviz_2024-01-15.parquet'\n",
    "DATA_FILE_EXTENSION = 'parquet'\n",
    "DATA_FILES_TO_SCAN = 100  # How many recent files to check for dates\n",
    "\n",
    "# --- Analysis Run Configuration ---\n",
    "\n",
    "# Define which dates to process using a slice.\n",
    "# Examples:\n",
    "#   slice(-1, None, None) -> Processes only the most recent date.\n",
    "#   slice(None)           -> Processes ALL found dates.\n",
    "#   slice(-5, None, None) -> Processes the 5 most recent dates.\n",
    "#   slice(0, 5, None)     -> Processes the 5 oldest dates.\n",
    "DATE_SLICE = slice(-1, None, None)  # Defaults to getting the last item\n",
    "\n",
    "# --- config.py Generation Parameters ---\n",
    "# These values will be written into the config.py file for each run.\n",
    "DEST_DIR = ROOT_DIR / 'data' # Destination directory for processed data\n",
    "ANNUAL_RISK_FREE_RATE = 0.04\n",
    "TRADING_DAYS_PER_YEAR = 252\n",
    "DAILY_RISK_FREE_RATE = ANNUAL_RISK_FREE_RATE / TRADING_DAYS_PER_YEAR\n",
    "\n",
    "# --- Verification ---\n",
    "print(f\"Project Root Directory: {ROOT_DIR}\")\n",
    "print(f\"Source Directory: {SRC_DIR}\")\n",
    "print(f\"Scanning for data files in: {DOWNLOADS_DIR}\")\n",
    "# print(f\"Date selection rule: {DATE_SLICE}\")\n",
    "\n",
    "# Set pandas display options for better readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Enable auto-reloading of external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Find Recent Data Files\n",
    "\n",
    "This step searches the configured directory for data files that match the specified prefix and extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Execute Step 1 ---\n",
    "print(\"--- Step 1: Finding recent data files ---\")\n",
    "\n",
    "# Use the utility function to get a list of recent filenames.\n",
    "# NOTE: We pass `directory_name=DOWNLOADS_DIR.name` to match the expected\n",
    "# function signature in the existing `utils.py` module.\n",
    "found_files = utils.get_recent_files_in_directory(\n",
    "    prefix=DATA_FILE_PREFIX,\n",
    "    extension=DATA_FILE_EXTENSION,\n",
    "    count=DATA_FILES_TO_SCAN,\n",
    "    directory_name=DOWNLOADS_DIR.name  # Corrected argument\n",
    ")\n",
    "\n",
    "if found_files:\n",
    "    print(f\"Found {len(found_files)} potential data file(s).\")\n",
    "    # Display the first 5 found files for brevity\n",
    "    for i, filename in enumerate(found_files[:20]):\n",
    "        # print(f\"  {i+1}. {filename}\")\n",
    "        print(f\"  {i}. {filename}\")        \n",
    "    if len(found_files) > 20:\n",
    "        print(\"  ...\")\n",
    "else:\n",
    "    print(f\"No files matching '{DATA_FILE_PREFIX}*.{DATA_FILE_EXTENSION}' found in '{DOWNLOADS_DIR}'.\")\n",
    "    # Initialize as empty list to prevent errors in the next step\n",
    "    found_files = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Extract and Select Dates for Processing\n",
    "\n",
    "This step extracts dates from the found filenames, sorts them, and then selects the dates to be processed based on the `DATE_SLICE` configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List\n",
    "\n",
    "def extract_and_sort_dates(filenames: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extracts unique date strings (YYYY-MM-DD) from filenames and sorts them.\n",
    "\n",
    "    Args:\n",
    "        filenames: A list of filenames.\n",
    "\n",
    "    Returns:\n",
    "        A sorted list of unique date strings.\n",
    "    \"\"\"\n",
    "    date_pattern = re.compile(r'\\d{4}-\\d{2}-\\d{2}')\n",
    "    \n",
    "    # Use a set comprehension for a concise way to find all unique matches\n",
    "    all_dates = {\n",
    "        match.group(0)\n",
    "        for filename in filenames\n",
    "        if (match := date_pattern.search(filename))\n",
    "    }\n",
    "    \n",
    "    # sorted() works directly on sets\n",
    "    return sorted(all_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_in_columns(items: List[str], num_columns: int = 5):\n",
    "    \"\"\"\n",
    "    Prints a list of strings in a numbered, multi-column format.\n",
    "\n",
    "    Args:\n",
    "        items: The list of strings to print.\n",
    "        num_columns: The number of columns to display.\n",
    "    \"\"\"\n",
    "    if not items:\n",
    "        print(\"No items to display.\")\n",
    "        return\n",
    "\n",
    "    # Iterate through the items in chunks the size of num_columns\n",
    "    for i in range(0, len(items), num_columns):\n",
    "        # Get the slice of items for the current row\n",
    "        row_slice = items[i : i + num_columns]\n",
    "        \n",
    "        row_items = []\n",
    "        for j, item in enumerate(row_slice):\n",
    "            # The original index of the item in the full list\n",
    "            original_index = i + j\n",
    "            \n",
    "            # Format the label (e.g., \"  0.\") to a fixed width for alignment\n",
    "            label = f\"  {original_index}.\"\n",
    "            \n",
    "            # Combine the fixed-width label with the item string\n",
    "            row_items.append(f\"{label:<8}{item}\")\n",
    "            \n",
    "        # Join the formatted items for the row and print\n",
    "        print(\"  \".join(row_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Extract the data\n",
    "available_dates = extract_and_sort_dates(found_files)\n",
    "\n",
    "# 2. Display the data\n",
    "print(f\"Extracted {len(available_dates)} unique dates from filenames:\")\n",
    "print_in_columns(available_dates, num_columns=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "def parse_str_to_slice(slice_str: str) -> Optional[slice]:\n",
    "    \"\"\"\n",
    "    Parses a string like \"start:stop:step\" into a slice object.\n",
    "    Returns None if the format is invalid.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Split the string by colons to get the slice parts\n",
    "        parts = slice_str.split(':')\n",
    "        if len(parts) > 3:\n",
    "            return None # Invalid format, too many colons\n",
    "\n",
    "        # Create a function to convert a string part to an integer or None\n",
    "        to_int_or_none = lambda s: int(s) if s.strip() else None\n",
    "\n",
    "        # Unpack parts and convert them\n",
    "        start = to_int_or_none(parts[0]) if len(parts) > 0 else None\n",
    "        stop = to_int_or_none(parts[1]) if len(parts) > 1 else None\n",
    "        step = to_int_or_none(parts[2]) if len(parts) > 2 else None\n",
    "        \n",
    "        return slice(start, stop, step)\n",
    "    except (ValueError, IndexError):\n",
    "        # Catches errors from non-integer parts or bad format\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_for_slice_update(variable_name: str, current_value: slice) -> slice:\n",
    "    \"\"\"\n",
    "    Displays a slice's current value and prompts the user to keep or change it.\n",
    "    Loops until a valid slice format is entered.\n",
    "\n",
    "    Args:\n",
    "        variable_name: The name of the variable (e.g., \"DATE_SLICE\").\n",
    "        current_value: The current slice object.\n",
    "\n",
    "    Returns:\n",
    "        The updated (or original) slice object.\n",
    "    \"\"\"\n",
    "    # Format the current slice object into a user-friendly string\n",
    "    s = current_value\n",
    "    current_value_str = f\"{s.start or ''}:{s.stop or ''}\"\n",
    "    if s.step is not None:\n",
    "        current_value_str += f\":{s.step}\"\n",
    "\n",
    "    # --- Start the user prompt loop ---\n",
    "    while True:\n",
    "        prompt = (\n",
    "            f\"\\n-> The current {variable_name} is: '{current_value_str}'\\n\"\n",
    "            f\"   Enter a new slice (e.g., ':10', '-5:', '::-1') or press ENTER to continue: \"\n",
    "        )\n",
    "        user_input = input(prompt).strip()\n",
    "\n",
    "        # Case 1: User presses ENTER to keep the current value\n",
    "        if not user_input:\n",
    "            print(f\"   Continuing with the current value.\")\n",
    "            return current_value\n",
    "\n",
    "        # Case 2: User enters a new value, try to parse it\n",
    "        new_slice = parse_str_to_slice(user_input)\n",
    "        \n",
    "        if new_slice is not None:\n",
    "            print(f\"   {variable_name} updated.\")\n",
    "            return new_slice\n",
    "        else:\n",
    "            # Case 3: The input was invalid, inform the user and loop again\n",
    "            print(f\"   Error: Invalid slice format '{user_input}'. Please try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Call the function to allow the user to modify the slice\n",
    "DATE_SLICE = prompt_for_slice_update(\"DATE_SLICE\", DATE_SLICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Continue execution with the (potentially new) value ---\n",
    "print(\"\\nContinuing script execution...\")\n",
    "print(f\"The script will now proceed using DATE_SLICE = '{DATE_SLICE}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Select the dates to process based on the configured slice\n",
    "dates_to_process = available_dates[DATE_SLICE]\n",
    "print(f\"Selected {len(dates_to_process)} date(s) to process:\")\n",
    "print(f'dates_to_process:\\n{dates_to_process}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Generate Configuration and Run Analysis for Each Selected Date\n",
    "\n",
    "This is the main execution step. It iterates through the list of selected dates. For each date, it generates a fresh `config.py` and runs the `run_sequence.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_config_file(date_str: str, config_path: Path):\n",
    "    \"\"\"\n",
    "    Creates a config.py file with dynamic paths and parameters.\n",
    "    It pulls configuration from the global variables set in the setup cell.\n",
    "\n",
    "    Args:\n",
    "        date_str (str): The date to be written into the config file.\n",
    "        config_path (Path): The path where the config.py file will be saved.\n",
    "    \"\"\"\n",
    "    # Use repr() to get a string representation of the path, which correctly\n",
    "    # handles backslashes on Windows (e.g., 'C:\\\\Users\\\\...')\n",
    "    config_content = f\"\"\"# config.py\n",
    "# This file is auto-generated by a notebook. DO NOT EDIT MANUALLY.\n",
    "\n",
    "# --- File path configuration ---\n",
    "DATE_STR = '{date_str}'\n",
    "DOWNLOAD_DIR = {repr(str(DOWNLOADS_DIR))}\n",
    "DEST_DIR = {repr(str(DEST_DIR))}\n",
    "\n",
    "# --- Analysis Parameters ---\n",
    "ANNUAL_RISK_FREE_RATE = {ANNUAL_RISK_FREE_RATE}\n",
    "TRADING_DAYS_PER_YEAR = {TRADING_DAYS_PER_YEAR}\n",
    "DAILY_RISK_FREE_RATE = {DAILY_RISK_FREE_RATE}\n",
    "\"\"\"\n",
    "    \n",
    "    with open(config_path, 'w') as f:\n",
    "        f.write(config_content)\n",
    "\n",
    "# --- Execute Step 3 ---\n",
    "print(\"\\n--- Step 3: Starting processing sequence ---\")\n",
    "\n",
    "if not dates_to_process:\n",
    "    print(\"No dates to process. Halting execution.\")\n",
    "else:\n",
    "    for date_str in dates_to_process:\n",
    "        print(f\"\\n{'='*20} PROCESSING DATE: {date_str} {'='*20}\")\n",
    "        \n",
    "        # Define the path for the config file (in the project root)\n",
    "        config_file_path = ROOT_DIR / 'config.py'\n",
    "        \n",
    "        # 1. Create the config.py file for the current date\n",
    "        create_config_file(date_str, config_file_path)\n",
    "        print(f\"Successfully created config file: {config_file_path}\")\n",
    "\n",
    "        # 2. Run the external processing script\n",
    "        print(f\"Executing run_sequence.py for {date_str}...\")\n",
    "        %run -i {ROOT_DIR / 'run_sequence.py'}\n",
    "        print(f\"--- Finished processing for {date_str} ---\")\n",
    "\n",
    "    print(f\"\\n{'='*20} WORKFLOW COMPLETE {'='*20}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
