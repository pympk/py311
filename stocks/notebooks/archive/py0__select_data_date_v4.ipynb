{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing Orchestrator\n",
    "\n",
    "This notebook orchestrates a data processing workflow by preparing a configuration file and running an external analysis script (`run_sequence.py`) for one or more dates.\n",
    "\n",
    "**Workflow:**\n",
    "\n",
    "1.  **Prerequisites:**\n",
    "    *   The `Yloader` application has been run to download OHLCV data.\n",
    "    *   A `finviz` data generation process has created `.parquet` files (e.g., `df_finviz_YYYY-MM-DD.parquet`) in the `Downloads` directory.\n",
    "2.  **Find Data:** The notebook scans the `Downloads` directory for recent Finviz data files.\n",
    "3.  **Select Date(s):** It extracts all available dates from the filenames and selects a subset for processing based on user configuration (e.g., only the latest date).\n",
    "4.  **Configure & Run:** For each selected date, it generates a `config.py` file and executes the `run_sequence.py` script.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and Configuration\n",
    "\n",
    "**This is the only cell you need to modify.** Adjust the variables below to match your environment and desired processing scope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Root Directory: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\n",
      "Source Directory: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\src\n",
      "Scanning for data files in: C:\\Users\\ping\\Downloads\n",
      "Date selection rule: slice(-2, None, None)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# --- Project and Path Configuration ---\n",
    "\n",
    "# Autodetect the project's root directory.\n",
    "# Assumes this notebook is in `root/notebooks/` or the `root/` directory.\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "ROOT_DIR = NOTEBOOK_DIR.parent if NOTEBOOK_DIR.name == 'notebooks' else NOTEBOOK_DIR\n",
    "\n",
    "# Add the project's source directory to the Python path\n",
    "SRC_DIR = ROOT_DIR / 'src'\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.append(str(SRC_DIR))\n",
    "    \n",
    "# Import the custom utility module now that the path is set\n",
    "import utils\n",
    "\n",
    "# --- Data File Configuration ---\n",
    "DOWNLOADS_DIR = Path.home() / \"Downloads\"\n",
    "DATA_FILE_PREFIX = 'df_finviz'  # Prefix for files like 'df_finviz_2024-01-15.parquet'\n",
    "DATA_FILE_EXTENSION = 'parquet'\n",
    "DATA_FILES_TO_SCAN = 100  # How many recent files to check for dates\n",
    "\n",
    "# --- Analysis Run Configuration ---\n",
    "\n",
    "# Define which dates to process using a slice.\n",
    "# Examples:\n",
    "#   slice(-1, None, None) -> Processes only the most recent date.\n",
    "#   slice(None)           -> Processes ALL found dates.\n",
    "#   slice(-5, None, None) -> Processes the 5 most recent dates.\n",
    "#   slice(0, 5, None)     -> Processes the 5 oldest dates.\n",
    "DATE_SLICE = slice(-2, None, None)\n",
    "\n",
    "# --- config.py Generation Parameters ---\n",
    "# These values will be written into the config.py file for each run.\n",
    "DEST_DIR = ROOT_DIR / 'data' # Destination directory for processed data\n",
    "ANNUAL_RISK_FREE_RATE = 0.04\n",
    "TRADING_DAYS_YEAR = 252\n",
    "\n",
    "# --- Verification ---\n",
    "print(f\"Project Root Directory: {ROOT_DIR}\")\n",
    "print(f\"Source Directory: {SRC_DIR}\")\n",
    "print(f\"Scanning for data files in: {DOWNLOADS_DIR}\")\n",
    "print(f\"Date selection rule: {DATE_SLICE}\")\n",
    "\n",
    "# Set pandas display options for better readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Enable auto-reloading of external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Find Recent Data Files\n",
    "\n",
    "This step searches the configured directory for data files that match the specified prefix and extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Finding recent data files ---\n",
      "target_dir: C:\\Users\\ping\\Downloads\n",
      "Found 35 potential data file(s).\n",
      "  1. df_finviz_2025-06-13_stocks_etfs.parquet\n",
      "  2. df_finviz_2025-06-12_stocks_etfs.parquet\n",
      "  3. df_finviz_2025-06-11_stocks_etfs.parquet\n",
      "  4. df_finviz_2025-06-10_stocks_etfs.parquet\n",
      "  5. df_finviz_2025-06-09_stocks_etfs.parquet\n",
      "  ...\n"
     ]
    }
   ],
   "source": [
    "# --- Execute Step 1 ---\n",
    "print(\"--- Step 1: Finding recent data files ---\")\n",
    "\n",
    "# Use the utility function to get a list of recent filenames.\n",
    "# NOTE: We pass `directory_name=DOWNLOADS_DIR.name` to match the expected\n",
    "# function signature in the existing `utils.py` module.\n",
    "found_files = utils.get_recent_files_in_directory(\n",
    "    prefix=DATA_FILE_PREFIX,\n",
    "    extension=DATA_FILE_EXTENSION,\n",
    "    count=DATA_FILES_TO_SCAN,\n",
    "    directory_name=DOWNLOADS_DIR.name  # Corrected argument\n",
    ")\n",
    "\n",
    "if found_files:\n",
    "    print(f\"Found {len(found_files)} potential data file(s).\")\n",
    "    # Display the first 5 found files for brevity\n",
    "    for i, filename in enumerate(found_files[:5]):\n",
    "        print(f\"  {i+1}. {filename}\")\n",
    "    if len(found_files) > 5:\n",
    "        print(\"  ...\")\n",
    "else:\n",
    "    print(f\"No files matching '{DATA_FILE_PREFIX}*.{DATA_FILE_EXTENSION}' found in '{DOWNLOADS_DIR}'.\")\n",
    "    # Initialize as empty list to prevent errors in the next step\n",
    "    found_files = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Extract and Select Dates for Processing\n",
    "\n",
    "This step extracts dates from the found filenames, sorts them, and then selects the dates to be processed based on the `DATE_SLICE` configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 2: Extracting and selecting dates ---\n",
      "Found 35 unique dates.\n",
      "Date range: 2025-04-25 to 2025-06-13\n",
      "\n",
      "Selected 2 date(s) for processing:\n",
      "  - 2025-06-12\n",
      "  - 2025-06-13\n"
     ]
    }
   ],
   "source": [
    "def extract_and_sort_dates_from_files(filenames: list[str]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Extracts date strings (YYYY-MM-DD) from a list of filenames using a\n",
    "    regular expression, removes duplicates, and sorts them chronologically.\n",
    "\n",
    "    Args:\n",
    "        filenames: A list of filenames.\n",
    "\n",
    "    Returns:\n",
    "        A sorted list of unique date strings.\n",
    "    \"\"\"\n",
    "    dates = set()\n",
    "    date_pattern = re.compile(r'\\d{4}-\\d{2}-\\d{2}')\n",
    "    \n",
    "    for filename in filenames:\n",
    "        match = date_pattern.search(filename)\n",
    "        if match:\n",
    "            dates.add(match.group(0))\n",
    "            \n",
    "    return sorted(list(dates))\n",
    "\n",
    "# --- Execute Step 2 ---\n",
    "print(\"\\n--- Step 2: Extracting and selecting dates ---\")\n",
    "\n",
    "# 1. Extract all available dates from the filenames\n",
    "available_dates = extract_and_sort_dates_from_files(found_files)\n",
    "print(f\"Found {len(available_dates)} unique dates.\")\n",
    "if available_dates:\n",
    "    print(f\"Date range: {available_dates[0]} to {available_dates[-1]}\")\n",
    "\n",
    "# 2. Select the dates to process based on the configured slice\n",
    "dates_to_process = available_dates[DATE_SLICE]\n",
    "\n",
    "if dates_to_process:\n",
    "    print(f\"\\nSelected {len(dates_to_process)} date(s) for processing:\")\n",
    "    for d in dates_to_process:\n",
    "        print(f\"  - {d}\")\n",
    "else:\n",
    "    print(\"\\nNo dates were selected for processing based on the current configuration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Generate Configuration and Run Analysis for Each Selected Date\n",
    "\n",
    "This is the main execution step. It iterates through the list of selected dates. For each date, it generates a fresh `config.py` and runs the `run_sequence.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 3: Starting processing sequence ---\n",
      "\n",
      "==================== PROCESSING DATE: 2025-06-12 ====================\n",
      "Successfully created config file: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\config.py\n",
      "Executing run_sequence.py for 2025-06-12...\n",
      "Starting notebook execution sequence...\n",
      "\n",
      "--- Running py0_get_yloader_OHLCV_data_v1.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\jupyter nbconvert --to notebook --execute --output executed\\executed_py0_get_yloader_OHLCV_data_v1.ipynb py0_get_yloader_OHLCV_data_v1.ipynb\n",
      "Successfully executed py0_get_yloader_OHLCV_data_v1.ipynb\n",
      "Output saved to: executed\\executed_py0_get_yloader_OHLCV_data_v1.ipynb\n",
      "\n",
      "--- Running py1_clean_df_finviz_v14.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\jupyter nbconvert --to notebook --execute --output executed\\executed_py1_clean_df_finviz_v14.ipynb py1_clean_df_finviz_v14.ipynb\n",
      "Successfully executed py1_clean_df_finviz_v14.ipynb\n",
      "Output saved to: executed\\executed_py1_clean_df_finviz_v14.ipynb\n",
      "\n",
      "--- Running py2_clean_df_OHLCV_v10.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\jupyter nbconvert --to notebook --execute --output executed\\executed_py2_clean_df_OHLCV_v10.ipynb py2_clean_df_OHLCV_v10.ipynb\n",
      "Successfully executed py2_clean_df_OHLCV_v10.ipynb\n",
      "Output saved to: executed\\executed_py2_clean_df_OHLCV_v10.ipynb\n",
      "\n",
      "--- Running py2_save_df_adj_close_v1.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\jupyter nbconvert --to notebook --execute --output executed\\executed_py2_save_df_adj_close_v1.ipynb py2_save_df_adj_close_v1.ipynb\n",
      "Successfully executed py2_save_df_adj_close_v1.ipynb\n",
      "Output saved to: executed\\executed_py2_save_df_adj_close_v1.ipynb\n",
      "\n",
      "--- Running py3_calc_perf_ratios_v16.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\jupyter nbconvert --to notebook --execute --output executed\\executed_py3_calc_perf_ratios_v16.ipynb py3_calc_perf_ratios_v16.ipynb\n",
      "Successfully executed py3_calc_perf_ratios_v16.ipynb\n",
      "Output saved to: executed\\executed_py3_calc_perf_ratios_v16.ipynb\n",
      "\n",
      "--- All notebooks executed successfully! ---\n",
      "--- Finished processing for 2025-06-12 ---\n",
      "\n",
      "==================== PROCESSING DATE: 2025-06-13 ====================\n",
      "Successfully created config file: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\config.py\n",
      "Executing run_sequence.py for 2025-06-13...\n",
      "Starting notebook execution sequence...\n",
      "\n",
      "--- Running py0_get_yloader_OHLCV_data_v1.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\jupyter nbconvert --to notebook --execute --output executed\\executed_py0_get_yloader_OHLCV_data_v1.ipynb py0_get_yloader_OHLCV_data_v1.ipynb\n",
      "Successfully executed py0_get_yloader_OHLCV_data_v1.ipynb\n",
      "Output saved to: executed\\executed_py0_get_yloader_OHLCV_data_v1.ipynb\n",
      "\n",
      "--- Running py1_clean_df_finviz_v14.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\jupyter nbconvert --to notebook --execute --output executed\\executed_py1_clean_df_finviz_v14.ipynb py1_clean_df_finviz_v14.ipynb\n",
      "Successfully executed py1_clean_df_finviz_v14.ipynb\n",
      "Output saved to: executed\\executed_py1_clean_df_finviz_v14.ipynb\n",
      "\n",
      "--- Running py2_clean_df_OHLCV_v10.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\jupyter nbconvert --to notebook --execute --output executed\\executed_py2_clean_df_OHLCV_v10.ipynb py2_clean_df_OHLCV_v10.ipynb\n",
      "Successfully executed py2_clean_df_OHLCV_v10.ipynb\n",
      "Output saved to: executed\\executed_py2_clean_df_OHLCV_v10.ipynb\n",
      "\n",
      "--- Running py2_save_df_adj_close_v1.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\jupyter nbconvert --to notebook --execute --output executed\\executed_py2_save_df_adj_close_v1.ipynb py2_save_df_adj_close_v1.ipynb\n",
      "Successfully executed py2_save_df_adj_close_v1.ipynb\n",
      "Output saved to: executed\\executed_py2_save_df_adj_close_v1.ipynb\n",
      "\n",
      "--- Running py3_calc_perf_ratios_v16.ipynb ---\n",
      "\n",
      "Running command: c:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Scripts\\jupyter nbconvert --to notebook --execute --output executed\\executed_py3_calc_perf_ratios_v16.ipynb py3_calc_perf_ratios_v16.ipynb\n",
      "Successfully executed py3_calc_perf_ratios_v16.ipynb\n",
      "Output saved to: executed\\executed_py3_calc_perf_ratios_v16.ipynb\n",
      "\n",
      "--- All notebooks executed successfully! ---\n",
      "--- Finished processing for 2025-06-13 ---\n",
      "\n",
      "==================== WORKFLOW COMPLETE ====================\n"
     ]
    }
   ],
   "source": [
    "def create_config_file(date_str: str, config_path: Path):\n",
    "    \"\"\"\n",
    "    Creates a config.py file with dynamic paths and parameters.\n",
    "    It pulls configuration from the global variables set in the setup cell.\n",
    "\n",
    "    Args:\n",
    "        date_str (str): The date to be written into the config file.\n",
    "        config_path (Path): The path where the config.py file will be saved.\n",
    "    \"\"\"\n",
    "    # Use repr() to get a string representation of the path, which correctly\n",
    "    # handles backslashes on Windows (e.g., 'C:\\\\Users\\\\...')\n",
    "    config_content = f\"\"\"# config.py\n",
    "# This file is auto-generated by a notebook. DO NOT EDIT MANUALLY.\n",
    "\n",
    "# --- File path configuration ---\n",
    "DATE_STR = '{date_str}'\n",
    "DOWNLOAD_DIR = {repr(str(DOWNLOADS_DIR))}\n",
    "DEST_DIR = {repr(str(DEST_DIR))}\n",
    "\n",
    "# --- Analysis Parameters ---\n",
    "ANNUAL_RISK_FREE_RATE = {ANNUAL_RISK_FREE_RATE}\n",
    "TRADING_DAYS_YEAR = {TRADING_DAYS_YEAR}\n",
    "\"\"\"\n",
    "    \n",
    "    with open(config_path, 'w') as f:\n",
    "        f.write(config_content)\n",
    "\n",
    "# --- Execute Step 3 ---\n",
    "print(\"\\n--- Step 3: Starting processing sequence ---\")\n",
    "\n",
    "if not dates_to_process:\n",
    "    print(\"No dates to process. Halting execution.\")\n",
    "else:\n",
    "    for date_str in dates_to_process:\n",
    "        print(f\"\\n{'='*20} PROCESSING DATE: {date_str} {'='*20}\")\n",
    "        \n",
    "        # Define the path for the config file (in the project root)\n",
    "        config_file_path = ROOT_DIR / 'config.py'\n",
    "        \n",
    "        # 1. Create the config.py file for the current date\n",
    "        create_config_file(date_str, config_file_path)\n",
    "        print(f\"Successfully created config file: {config_file_path}\")\n",
    "\n",
    "        # 2. Run the external processing script\n",
    "        print(f\"Executing run_sequence.py for {date_str}...\")\n",
    "        %run -i {ROOT_DIR / 'run_sequence.py'}\n",
    "        print(f\"--- Finished processing for {date_str} ---\")\n",
    "\n",
    "    print(f\"\\n{'='*20} WORKFLOW COMPLETE {'='*20}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
