{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HplHE-XnwHFz"
   },
   "source": [
    "===== TURN ON POWERTOY AWAKE to KEEP CONNECTION ALIVE =====\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0BAeKmVzAEwE"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzjWU0MyA8cT"
   },
   "source": [
    "===== SET download_to_PC and end_index ====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "LnCnXVOGAzi8"
   },
   "outputs": [],
   "source": [
    "# symbols: The string (or sequence) to slice.\n",
    "# start_index: Optional. The starting index of the slice. If None, defaults to 0.\n",
    "# end_index: Optional. The ending index of the slice (exclusive). If None, defaults to the end of the string.\n",
    "# step_value: Optional. The step value for the slice. If None, defaults to 1.\n",
    "\n",
    "# True download to PC, False download to Google Drive\n",
    "download_to_PC = True  # True download to PC\n",
    "# download_to_PC = False  # True download to Google Drive\n",
    "\n",
    "# Download all if end_iddex = None\n",
    "end_index = None\n",
    "end_index = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BWX6sLNsmsCr",
    "outputId": "a3dabbf1-e196-482a-c2c8-63da3a538257"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slice of symbols: symbols[slice(None, 3, None)]\n"
     ]
    }
   ],
   "source": [
    "start_index = None\n",
    "\n",
    "step_value = None\n",
    "slice_obj = slice(start_index, end_index, step_value)  # Create a slice object\n",
    "\n",
    "print(f'slice of symbols: symbols[{slice_obj}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K2xUTYT3wHF4"
   },
   "outputs": [],
   "source": [
    "! pip install fake-useragent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "HTCD6Lo1wHF4"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "selector = '.styled-table-new'\n",
    "ua = UserAgent()  # Initialize UserAgent\n",
    "\n",
    "def download_table(url, selector):\n",
    "    \"\"\"\n",
    "    Downloads table data from a Yahoo Finance page with rate limiting.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Add a User-Agent header to mimic a browser\n",
    "        # headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}  # Example User-Agent\n",
    "        new_user_agent = ua.random\n",
    "        headers = {\"User-Agent\": new_user_agent}\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        table_body = soup.select_one(selector)\n",
    "\n",
    "        if table_body is None:\n",
    "            print(f\"Error: Table body not found using selector: {selector}\")\n",
    "            return None\n",
    "\n",
    "        rows = table_body.find_all('tr')\n",
    "        if not rows:\n",
    "            print(\"Error: No rows found in the table.\")\n",
    "            return None\n",
    "\n",
    "        # Extract headers from the first row (th elements)\n",
    "        headers_list = [th.text.strip() for th in rows[0].find_all('th')]\n",
    "\n",
    "        data = []\n",
    "        for row in rows:\n",
    "            cells = row.find_all('td')\n",
    "            row_data = [cell.text.strip() for cell in cells]\n",
    "            if row_data:  # Only append if the row has data\n",
    "                data.append(row_data)\n",
    "\n",
    "        if not data:\n",
    "            print(\"Error: No data found in the table rows.\")\n",
    "            return None\n",
    "\n",
    "        df = pd.DataFrame(data, columns=headers_list)\n",
    "        return df\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error during request: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7WcYi3BecotV"
   },
   "outputs": [],
   "source": [
    "# all_stocks_and_etfs_columns\n",
    "# https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&r=721&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RpuXvF2ncotV"
   },
   "outputs": [],
   "source": [
    "# all_etf_columns_sorted_by_AUM\n",
    "# https://finviz.com/screener.ashx?v=152&ft=4&o=-e.assetsundermanagement&c=0,1,2,3,4,5,129,75,14,130,131,31,84,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,70,80,83,60,61,63,64,67,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AgZUn7phcotW"
   },
   "outputs": [],
   "source": [
    "# all_stock_columns_sorted_by_market_cap\n",
    "# https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xyyiAJcecotX"
   },
   "outputs": [],
   "source": [
    "# remove duplicate Dividend with $ value in column 75, kept Dividend with value in % \n",
    "url_all_columns = '0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "xilLYhetMk-y"
   },
   "outputs": [],
   "source": [
    "url_mktcap ='https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c='\n",
    "# url_mktcap_all_columns = '0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66'\n",
    "url_mktcap_rows = ['&r=1', '&r=21', '&r=41', '&r=61', '&r=81', '&r=101', '&r=121', '&r=141', '&r=161', '&r=181', '&r=201', '&r=221', '&r=241', '&r=261', '&r=281', '&r=301', '&r=321', '&r=341', '&r=361', '&r=381', '&r=401', '&r=421', '&r=441', '&r=461', '&r=481', '&r=501', '&r=521', '&r=541', '&r=561', '&r=581', '&r=601', '&r=621', '&r=641', '&r=661', '&r=681', '&r=701', '&r=721', '&r=741', '&r=761', '&r=781', '&r=801', '&r=821', '&r=841', '&r=861', '&r=881', '&r=901', '&r=921', '&r=941', '&r=961', '&r=981', '&r=1001', '&r=1021','&r=1041','&r=1061','&r=1081','&r=1101','&r=1121','&r=1141',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "p4mC2RrCcotY"
   },
   "outputs": [],
   "source": [
    "url_etfs ='https://finviz.com/screener.ashx?v=152&ft=4&o=-e.assetsundermanagement&c='\n",
    "# url_etfs_all_columns = '0,1,2,3,4,5,129,75,14,130,131,31,84,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,70,80,83,60,61,63,64,67,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105'\n",
    "url_etfs_rows = ['&r=1', '&r=21', '&r=41', '&r=61', '&r=81', '&r=101', '&r=121', '&r=141', '&r=161', '&r=181', '&r=201', '&r=221', '&r=241', '&r=261', '&r=281', '&r=301', '&r=321', '&r=341', '&r=361', '&r=381']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BYhnaEoxwHF6",
    "outputId": "def62974-d424-427e-e6b1-f8e8257a0f65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of urls: 58\n",
      "First 3 urls:\n",
      "['https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=1', 'https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=21', 'https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=41']\n"
     ]
    }
   ],
   "source": [
    "urls_mktcap = []\n",
    "\n",
    "for _rows in url_mktcap_rows:\n",
    "    # _url = url_mktcap + url_mktcap_all_columns + _rows\n",
    "    _url = url_mktcap + url_all_columns + _rows\n",
    "    urls_mktcap.append(_url)\n",
    "\n",
    "print(f'Total number of urls: {len(urls_mktcap)}')\n",
    "print(f'First 3 urls:\\n{urls_mktcap[0:3]}')  # Print the length of the list of url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "WJ38HN3UcotZ",
    "outputId": "515f4104-1d5d-41bc-ca5b-5b8b3af952ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of urls: 20\n",
      "First 3 urls:\n",
      "['https://finviz.com/screener.ashx?v=152&ft=4&o=-e.assetsundermanagement&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=1', 'https://finviz.com/screener.ashx?v=152&ft=4&o=-e.assetsundermanagement&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=21', 'https://finviz.com/screener.ashx?v=152&ft=4&o=-e.assetsundermanagement&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=41']\n"
     ]
    }
   ],
   "source": [
    "urls_etfs = []\n",
    "\n",
    "for _rows in url_etfs_rows:\n",
    "    # _url = url_etfs + url_etfs_all_columns + _rows\n",
    "    _url = url_etfs + url_all_columns + _rows\n",
    "    urls_etfs.append(_url)\n",
    "\n",
    "print(f'Total number of urls: {len(urls_etfs)}')\n",
    "print(f'First 3 urls:\\n{urls_etfs[0:3]}')  # Print the length of the list of url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JWfH7PLrwHF7",
    "outputId": "23b628b5-cf9d-4b51-9f38-c55e3044c1d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(shuffled_urls): 78\n",
      "shuffled_urls[0:10]\n",
      "https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=881\n",
      "https://finviz.com/screener.ashx?v=152&ft=4&o=-e.assetsundermanagement&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=141\n",
      "https://finviz.com/screener.ashx?v=152&ft=4&o=-e.assetsundermanagement&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=321\n",
      "https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=801\n",
      "https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=901\n",
      "https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=41\n",
      "https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=1121\n",
      "https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=361\n",
      "https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=1061\n",
      "https://finviz.com/screener.ashx?v=152&ft=4&o=-e.assetsundermanagement&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=221\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "urls =  urls_mktcap + urls_etfs\n",
    "shuffled_urls = random.sample(urls, len(urls))\n",
    "print(f'len(shuffled_urls): {len(shuffled_urls)}')\n",
    "print(f'shuffled_urls[0:10]')\n",
    "for url in shuffled_urls[0:10]:\n",
    "    print(f'{url}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WyA3q6n9wHF7"
   },
   "outputs": [],
   "source": [
    "# test_urls = [\n",
    "#   'https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,3,4,6,14,42,43,44,45,46,47,48,49,50,51,52,53,54,57,58,59,67,65,66,103,100,109,120,121,122&r=1',\n",
    "#   'https://finviz.com/screener.ashx?v=152&ft=4&o=-e.assetsundermanagement&c=0,1,2,3,4,6,14,42,43,44,45,46,47,48,49,50,51,52,53,54,57,58,59,67,65,66,103,100,109,120,121,122&r=101',\n",
    "#   'https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,3,4,6,14,42,43,44,45,46,47,48,49,50,51,52,53,54,57,58,59,67,65,66,103,100,109,120,121,122&r=601',\n",
    "#   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "sp4KYbgEcotc",
    "outputId": "15d64caf-c84a-4d1a-bc03-b104917b3d5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=881. Sleeping for 3.76 seconds.  Processed 1 / 78 urls\n",
      "Downloading https://finviz.com/screener.ashx?v=152&ft=4&o=-e.assetsundermanagement&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=141. Sleeping for 2.84 seconds.  Processed 2 / 78 urls\n",
      "Downloading https://finviz.com/screener.ashx?v=152&ft=4&o=-e.assetsundermanagement&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=321. Sleeping for 4.06 seconds.  Processed 3 / 78 urls\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "total_urls_to_download = len(shuffled_urls)\n",
    "\n",
    "df = pd.DataFrame()  # Initialized an empty DataFrame\n",
    "processed_count = 0\n",
    "\n",
    "# for url in test_urls:\n",
    "# for url in shuffled_urls[0:3]:\n",
    "for url in shuffled_urls[slice_obj]:\n",
    "    # Introduce a delay between requests (adjust as needed)\n",
    "    delay_seconds = random.uniform(2, 4.5)  # Sleep between 2 and 5 seconds\n",
    "    # print(f\"Downloading {symbol}. Sleeping for {delay_seconds:.2f} seconds...\")\n",
    "    processed_count += 1\n",
    "    print(f\"Downloading {url}. Sleeping for {delay_seconds:.2f} seconds.  Processed {processed_count} / {total_urls_to_download} urls\")\n",
    "    time.sleep(delay_seconds)\n",
    "\n",
    "    df_temp = download_table(url, selector)\n",
    "\n",
    "    if df_temp is not None:\n",
    "        df = pd.concat([df, df_temp], ignore_index=True)\n",
    "    else:\n",
    "        print(f\"Failed to download data for {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&              c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=881'\n",
    "'https://finviz.com/screener.ashx?v=152&ft=4&o=-e.assetsundermanagement&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=141'\n",
    "'https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&r=881&        c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,   14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60 entries, 0 to 59\n",
      "Columns: 112 entries, No. to Tags\n",
      "dtypes: object(112)\n",
      "memory usage: 52.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "TJt8zyFewHF8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_finviz_filename: df_finviz_2025-05-06_stocks.parquet\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "\n",
    "pst = pytz.timezone('America/Los_Angeles')  # or 'US/Pacific'\n",
    "current_date_pst = datetime.datetime.now(pst).strftime('%Y-%m-%d')\n",
    "\n",
    "# Save the DataFrame as a Parquet file\n",
    "df_finviz_filename = f\"df_finviz_{current_date_pst}_stocks.parquet\"\n",
    "\n",
    "print(f\"df_finviz_filename: {df_finviz_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate Dividend columns\n",
    "# Step 1: Deduplicate column names by appending suffixes to duplicates\n",
    "cols = []\n",
    "count = {}\n",
    "for column in df.columns:\n",
    "    if column in count:\n",
    "        count[column] += 1\n",
    "        cols.append(f\"{column}_{count[column]}\")\n",
    "    else:\n",
    "        count[column] = 0\n",
    "        cols.append(column)\n",
    "df.columns = cols\n",
    "\n",
    "# Step 2: Identify which 'Dividend' column has values ending with '%'\n",
    "dividend_cols = [col for col in df.columns if col.startswith('Dividend_') or col == 'Dividend']\n",
    "\n",
    "keep_col = None\n",
    "for col in dividend_cols:\n",
    "    # Check if any non-null value ends with '%'\n",
    "    if df[col].apply(lambda x: str(x).endswith('%') if pd.notnull(x) else False).any():\n",
    "        keep_col = col\n",
    "        break\n",
    "\n",
    "# Step 3: Drop the other Dividend column(s)\n",
    "if keep_col:\n",
    "    drop_cols = [col for col in dividend_cols if col != keep_col]\n",
    "    df = df.drop(columns=drop_cols)\n",
    "    # Optionally rename kept column back to 'Dividend' if it was altered\n",
    "    if keep_col != 'Dividend':\n",
    "        df = df.rename(columns={keep_col: 'Dividend'})\n",
    "else:\n",
    "    raise ValueError(\"No Dividend column with '%' values found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "3agEKFzAMX95"
   },
   "outputs": [],
   "source": [
    "import pyarrow\n",
    "\n",
    "df.to_parquet(df_finviz_filename, engine='pyarrow', compression='zstd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "aw1Sw3G-W419"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   No. Ticker                             Company    Index                  Sector                        Industry Country Exchange Market Cap     P/E Fwd P/E   PEG   P/S   P/B     P/C  P/FCF Book/sh Cash/sh Dividend Dividend TTM Dividend Ex Date Payout Ratio    EPS EPS next Q EPS this Y EPS next Y EPS past 5Y EPS next 5Y Sales past 5Y Sales Q/Q    EPS Q/Q EPS YoY TTM Sales YoY TTM   Sales    Income EPS Surprise Revenue Surprise Outstanding    Float Float % Insider Own Insider Trans Inst Own Inst Trans Short Float Short Ratio Short Interest     ROA     ROE     ROI Curr R Quick R LTDebt/Eq Debt/Eq Gross M  Oper M Profit M Perf Week Perf Month Perf Quart Perf Half Perf Year Perf YTD  Beta   ATR Volatility W Volatility M   SMA20    SMA50   SMA200 50D High 50D Low 52W High 52W Low        52W Range All-Time High All-Time Low    RSI  Earnings   IPO Date Optionable Shortable Employees Change from Open     Gap Recom Avg Volume Rel Volume     Volume Target Price Prev Close    Open    High     Low   Price  Change Single Category Asset Type Expense Holdings AUM Flows 1M Flows% 1M Flows 3M Flows% 3M Flows YTD Flows% YTD Return% 1Y Return% 3Y Return% 5Y Tags\n",
      "0  881    WIX                         Wix.com Ltd        -              Technology       Software - Infrastructure  Israel     NASD      9.14B   70.58   18.83  3.78  5.19     -    8.25  19.05   -1.40   19.89        -            -                -        0.00%   2.33       1.63     14.23%     19.44%           -      18.66%        18.58%    14.04%   1483.60%     327.43%        12.74%   1.76B   138.32M       21.61%           -0.27%      56.11M   53.48M  95.31%       3.93%         0.00%   82.75%     -1.81%       3.48%        2.16          1.86M   7.44%       -  47.64%   0.84    0.84         -       -  67.93%   5.69%    7.86%    -3.44%      9.41%    -27.83%    -1.79%    37.31%  -23.50%  1.39  7.69        3.50%        5.33%   1.62%   -3.51%  -11.07%  -20.88%  15.29%  -33.58%  38.38%  118.61 - 247.11       -54.67%     1049.37%  48.35  May 21/b  11/6/2013        Yes       Yes      5283            0.41%  -1.78%  1.54    863.81K       0.70    605,339       238.29     166.43  163.46  168.12  161.68  164.13  -1.38%               -          -       -        -   -        -         -        -         -         -          -          -          -          -    -\n",
      "1  882   FYBR  Frontier Communications Parent Inc        -  Communication Services                Telecom Services     USA     NASD      9.13B       -       -     -  1.53  1.87   15.25      -   19.49    2.39        -            -                -            -  -1.55      -0.20     16.10%     20.48%      53.04%      28.77%        -5.85%     3.35%  -6505.00%   -1514.85%         3.69%   5.99B  -387.00M      -20.37%            0.34%     250.23M  220.86M  88.26%      11.74%       -71.83%   76.87%     -4.83%       3.07%        2.30          6.78M  -1.88%  -7.64%  -2.34%   0.42    0.42      2.39    2.39  36.67%   7.77%   -6.47%     0.66%      2.41%      1.87%     2.16%    52.08%    5.19%  1.01  0.18        0.42%        0.62%   1.05%    1.49%    6.29%   -0.19%   3.36%   -6.91%  49.41%    24.43 - 39.21        -6.91%      213.30%  70.48  Apr 29/a   5/4/2021        Yes       Yes     13000           -0.05%  -0.05%  3.17      2.95M       0.41  1,199,895        38.50      36.54   36.52   36.53   36.45   36.50  -0.11%               -          -       -        -   -        -         -        -         -         -          -          -          -          -    -\n",
      "2  883    SWK          Stanley Black & Decker Inc  S&P 500             Industrials             Tools & Accessories     USA     NYSE      9.12B   25.05   10.38  1.57  0.60  1.03   26.18  11.93   57.16    2.25    5.33%         3.27         6/3/2025      172.28%   2.35       0.50      1.03%     29.04%     -20.90%      15.98%         3.91%    -3.23%    361.22%     575.89%        -3.04%  15.24B   357.20M       14.57%            1.46%     154.69M  154.19M  99.68%       0.34%        -0.40%   91.86%      4.39%       5.53%        3.29          8.53M   1.54%   4.03%   2.63%   1.10    0.36      0.54    0.76  30.06%   8.64%    2.34%    -3.72%     -6.20%    -31.94%   -36.54%   -30.60%  -26.54%  1.16  3.00        3.81%        5.61%  -0.88%  -17.83%  -32.88%  -34.65%   9.40%  -46.81%   9.40%   53.91 - 110.88       -73.79%      807.38%  39.11  Apr 30/b  6/15/1966        Yes       Yes     48500           -0.15%  -1.68%  2.70      2.59M       0.81  2,089,725        80.21      60.08   59.07   59.76   58.68   58.98  -1.83%               -          -       -        -   -        -         -        -         -         -          -          -          -          -    -\n",
      "3  884    OGE                     Oge Energy Corp        -               Utilities  Utilities - Regulated Electric     USA     NYSE      9.11B   18.78   18.63  3.24  2.91  1.97  338.82      -   22.93    0.13    3.74%         1.68         4/7/2025       76.55%   2.41       0.57      4.06%      6.61%       0.30%       5.80%        10.10%    25.28%    235.06%      21.90%        15.56%   3.14B   485.60M       36.26%            6.88%     201.30M  200.34M  99.52%       0.49%        -1.17%   72.90%      4.61%       2.23%        3.30          4.47M   3.61%  10.72%   4.99%   0.73    0.35      1.11    1.28  45.29%  25.66%   15.48%    -0.96%      3.69%      6.84%    13.20%    29.27%    9.75%  0.62  1.01        2.30%        2.62%   1.30%    0.95%    7.67%   -3.50%  10.96%   -3.50%  32.37%    34.20 - 46.91        -3.50%      934.74%  53.63  Apr 30/b  9/27/1950        Yes       Yes      2291            0.60%  -0.31%  2.71      1.35M       0.88  1,191,735        45.56      45.14   45.00   45.57   45.00   45.27   0.29%               -          -       -        -   -        -         -        -         -         -          -          -          -          -    -\n",
      "4  885   SARO                    StandardAero Inc        -             Industrials             Aerospace & Defense     USA     NYSE      9.11B  854.23   23.57     -  1.74  3.84   88.85      -    7.10    0.31        -            -                -        0.00%   0.03       0.18   2029.25%     35.74%           -           -        14.66%    21.75%   -220.15%     130.41%        14.77%   5.24B    10.98M     -129.20%            3.24%     334.46M  152.04M  45.46%      54.54%       -16.48%   39.66%    137.64%       3.78%        2.26          5.75M       -       -   0.23%   1.95    1.29      1.00    1.02  12.58%   8.53%    0.21%     1.19%     17.81%      0.74%    -5.55%         -   10.06%     -  0.98        2.39%        4.35%   5.63%    1.75%   -0.78%   -9.14%  27.87%  -20.74%  27.87%    21.31 - 34.38       -20.74%       27.87%  55.95  May 12/a  10/2/2024        Yes       Yes      7700           -0.80%  -0.69%  1.78      2.54M       0.43  1,097,078        33.00      27.66   27.47   27.76   27.18   27.25  -1.48%               -          -       -        -   -        -         -        -         -         -          -          -          -          -    -\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.width', 3000) \n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60 entries, 0 to 59\n",
      "Columns: 111 entries, No. to Tags\n",
      "dtypes: object(111)\n",
      "memory usage: 52.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R6_jh9e9WE_8"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "file_path = '/content/drive/MyDrive/stocks/df_finviz_tickers.pkl'  # Run in Colab\n",
    "file_path = 'df_finviz_tickers.pkl'  # Run in VSCode\n",
    "\n",
    "df_tickers = df[['Ticker']]\n",
    "\n",
    "# Save the DataFrame to a pickle file in the specified location\n",
    "df_tickers.to_pickle(file_path)\n",
    "print(f\"{len(df_tickers)} tickers saved to: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(zip_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "if download_to_PC:\n",
    "  # Download the ZIP file (only 1 prompt)\n",
    "  if os.path.exists(zip_filename):\n",
    "      files.download(zip_filename)\n",
    "      print(f\"File '{zip_filename}' dowloaded to PC\")\n",
    "  else:\n",
    "      print(f\"Error: Zip file not created: {zip_filename}\")\n",
    "\n",
    "else:\n",
    "  destination_path = '/content/drive/MyDrive/stocks/'\n",
    "\n",
    "  # Construct the full path to the destination file\n",
    "  destination_file = os.path.join(destination_path, zip_filename)\n",
    "\n",
    "  # Use shutil.copy2 to preserve metadata (like timestamps)\n",
    "  try:\n",
    "      shutil.copy2(zip_filename, destination_file)\n",
    "      print(f\"File '{zip_filename}' downloaded to '{destination_file}'\")\n",
    "  except FileNotFoundError:\n",
    "      print(f\"Error: The file '{zip_filename}' was not found.\")\n",
    "  except Exception as e:\n",
    "      print(f\"An error occurred during the copy operation: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78db6cfhuLqT"
   },
   "outputs": [],
   "source": [
    "# ======================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5VcTdIE3uLqT"
   },
   "outputs": [],
   "source": [
    "# symbols: The string (or sequence) to slice.\n",
    "# start_index: Optional. The starting index of the slice. If None, defaults to 0.\n",
    "# end_index: Optional. The ending index of the slice (exclusive). If None, defaults to the end of the string.\n",
    "# step_value: Optional. The step value for the slice. If None, defaults to 1.\n",
    "\n",
    "# start_index = None\n",
    "# end_index = None\n",
    "# end_index = 3\n",
    "\n",
    "step_value = None\n",
    "slice_obj = slice(start_index, end_index, step_value)  # Create a slice object\n",
    "\n",
    "print(f'slice of symbols: symbols[{slice_obj}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Block 1: Setup and Imports (for yfinance approach)\n",
    "# !pip install yfinance pandas fake_useragent openpyxl\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# For User-Agent rotation if needed with yfinance (though often not required)\n",
    "from fake_useragent import UserAgent\n",
    "ua = UserAgent()\n",
    "\n",
    "# --- Code related to loading symbols (your existing code) ---\n",
    "# Assuming this file exists in your Colab's Google Drive\n",
    "file_path = '/content/drive/MyDrive/stocks/df_finviz_tickers.pkl'\n",
    "\n",
    "# Ensure Google Drive is mounted if running in Colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    loaded_df = pd.read_pickle(file_path)\n",
    "    symbols = loaded_df['Ticker'].tolist()\n",
    "    print(f\"Loaded {len(symbols)} symbols. First 5: {symbols[:5]}\")\n",
    "else:\n",
    "    print(f\"Error: File not found at {file_path}. Using sample symbols.\")\n",
    "    symbols = [\"AAPL\", \"MSFT\", \"GOOG\", \"HPE\", \"AMZN\"] # Sample symbols if file not found\n",
    "\n",
    "# --- Define slice_obj and col_names (as they were used in your original code) ---\n",
    "# Example: Process the first 5 symbols\n",
    "slice_obj = slice(0, 5) # Or whatever slice you need\n",
    "# Standard column names from Yahoo Finance history\n",
    "col_names = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Dividends', 'Stock Splits']\n",
    "\n",
    "\n",
    "# --- Main Loop using yfinance ---\n",
    "symbols_to_download = symbols[slice_obj]\n",
    "total_symbols_to_download = len(symbols_to_download)\n",
    "processed_count = 0\n",
    "all_data_frames = [] # List to hold individual DataFrames\n",
    "\n",
    "print(f'Symbols to download: symbols[{slice_obj}] (Total: {total_symbols_to_download})')\n",
    "\n",
    "for symbol in symbols_to_download:\n",
    "    delay_seconds = random.uniform(1, 3) # yfinance is more efficient, can use shorter delays\n",
    "    processed_count += 1\n",
    "    print(f\"Downloading {symbol}. Sleeping for {delay_seconds:.2f} seconds. Processed {processed_count}/{total_symbols_to_download} symbols.\")\n",
    "    time.sleep(delay_seconds)\n",
    "\n",
    "    try:\n",
    "        ticker = yf.Ticker(symbol)\n",
    "        # Set a user agent for the session yfinance uses\n",
    "        # This can sometimes help if default yfinance requests are blocked\n",
    "        ticker.session.headers.update({'User-Agent': ua.random})\n",
    "\n",
    "        # Fetch historical market data\n",
    "        # You can specify period (e.g., \"1y\", \"5d\", \"max\") or start/end dates\n",
    "        hist_df = ticker.history(period=\"1y\") # Example: 1 year of data\n",
    "\n",
    "        if hist_df.empty:\n",
    "            print(f\"No data returned for {symbol}. It might be delisted or an invalid ticker.\")\n",
    "            continue\n",
    "\n",
    "        # yfinance returns 'Date' as index. 'Dividends' and 'Stock Splits' are also columns.\n",
    "        # We want to ensure our col_names are reflected or adjusted.\n",
    "        # For MultiIndex:\n",
    "        hist_df.index.name = 'Date' # Ensure the index is named 'Date'\n",
    "        # Create MultiIndex\n",
    "        current_symbol_df = pd.concat({symbol: hist_df}, names=['Symbol'])\n",
    "        all_data_frames.append(current_symbol_df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download or process data for {symbol} using yfinance: {e}\")\n",
    "        # yfinance sometimes prints more detailed errors itself\n",
    "\n",
    "# Combine all DataFrames\n",
    "if all_data_frames:\n",
    "    final_df = pd.concat(all_data_frames)\n",
    "    print(\"\\n--- Final Combined DataFrame (first 10 rows) ---\")\n",
    "    print(final_df.head(10))\n",
    "    # You can now save final_df to a file, e.g., final_df.to_csv('yahoo_finance_data.csv')\n",
    "else:\n",
    "    print(\"No data was successfully downloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aZmvZTdHuLqT"
   },
   "outputs": [],
   "source": [
    "from fake_useragent import UserAgent\n",
    "\n",
    "ua = UserAgent()  # Initialize UserAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NAuxwFy7uLqU"
   },
   "outputs": [],
   "source": [
    "# selector = \"#nimbus-app > section > section > section > article > div.container > div.table-container.yf-1jecxey > table > tbody\"\n",
    "selector = \"#nimbus-app > section > section > section > article > div.container > div.table-container.yf-1jecxey\"\n",
    "col_names = ['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hVZTyrX6uLqU"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def read_stock_symbols(dir_path, symbols_stocks_file, symbols_ETFs_file):\n",
    "    \"\"\"\n",
    "    Reads stock and ETF symbols from text files in the specified directory and returns them in two separate lists.\n",
    "\n",
    "    Args:\n",
    "        dir_path (str): The directory path where the symbol files are located.\n",
    "        symbols_stocks_file (str): The name of the file containing stock symbols.\n",
    "        symbols_ETFs_file (str): The name of the file containing ETF symbols.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two lists: (stock_symbols, etf_symbols).  Returns ([], [])\n",
    "               if any error occurs during file reading.\n",
    "    \"\"\"\n",
    "\n",
    "    stock_symbols = []\n",
    "    etf_symbols = []\n",
    "\n",
    "    try:\n",
    "        # Read stock symbols\n",
    "        with open(os.path.join(dir_path, symbols_stocks_file), 'r') as f:\n",
    "            stock_symbols = [line.strip() for line in f]\n",
    "\n",
    "        # Read ETF symbols\n",
    "        with open(os.path.join(dir_path, symbols_ETFs_file), 'r') as f:\n",
    "            etf_symbols = [line.strip() for line in f]\n",
    "\n",
    "        return stock_symbols, etf_symbols\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: One or more files not found in directory: {dir_path}\")\n",
    "        return [], []\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I79YQzfFuLqV"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random  # For a bit of randomness in the sleep time\n",
    "\n",
    "def download_yahoo_finance_table(url, selector):\n",
    "    \"\"\"\n",
    "    Downloads table data from a Yahoo Finance page with rate limiting.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Add a User-Agent header to mimic a browser\n",
    "        # headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}  # Example User-Agent\n",
    "        new_user_agent = ua.random\n",
    "        headers = {\"User-Agent\": new_user_agent}\n",
    "\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        table_body = soup.select_one(selector)\n",
    "\n",
    "        if table_body is None:\n",
    "            print(f\"Error: Table body not found using selector: {selector}\")\n",
    "            return None\n",
    "\n",
    "        rows = table_body.find_all('tr')\n",
    "        if not rows:\n",
    "            print(\"Error: No rows found in the table.\")\n",
    "            return None\n",
    "\n",
    "        # Extract headers from the first row (th elements)\n",
    "        headers_list = [th.text.strip() for th in rows[0].find_all('th')]\n",
    "\n",
    "        data = []\n",
    "        for row in rows:\n",
    "            cells = row.find_all('td')\n",
    "            row_data = [cell.text.strip() for cell in cells]\n",
    "            if row_data:  # Only append if the row has data\n",
    "                data.append(row_data)\n",
    "\n",
    "        if not data:\n",
    "            print(\"Error: No data found in the table rows.\")\n",
    "            return None\n",
    "\n",
    "        df = pd.DataFrame(data, columns=headers_list)\n",
    "        return df\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error during request: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NkcX6TakuLqV"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "\n",
    "def get_current_pst_time():\n",
    "  \"\"\"\n",
    "  Returns the current time in Pacific Standard Time (PST).\n",
    "\n",
    "  Returns:\n",
    "    A string representing the current time in PST, formatted as\n",
    "    \"YYYY-MM-DD HH:MM:SS\".\n",
    "  \"\"\"\n",
    "\n",
    "  pst_timezone = pytz.timezone('America/Los_Angeles')  # Get the PST timezone\n",
    "  pst_now = datetime.datetime.now(pst_timezone)  # Get the current time in PST\n",
    "\n",
    "  return pst_now.strftime(\"%Y-%m-%d %H:%M:%S\")  # Format the time as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gInEy7rtuLqV"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def convert_df_data_types(df):\n",
    "    \"\"\"\n",
    "    Cleans and converts a Pandas DataFrame with a MultiIndex to the specified data types.\n",
    "\n",
    "    Args:\n",
    "        df: The input Pandas DataFrame.  Assumes a MultiIndex with stock ticker (str) and date (str).\n",
    "            Assumes columns 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume' as objects.\n",
    "\n",
    "    Returns:\n",
    "        A Pandas DataFrame with the correct data types.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the second level of the MultiIndex to datetime\n",
    "    try:\n",
    "        df.index = pd.MultiIndex.from_tuples([(i[0], pd.to_datetime(i[1])) for i in df.index], names=df.index.names)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error converting MultiIndex to datetime: {e}\")\n",
    "        return df  # Or handle the error differently, e.g., raise it\n",
    "\n",
    "    # Convert columns to appropriate data types\n",
    "    columns_to_convert = ['Open', 'High', 'Low', 'Close', 'Adj Close']\n",
    "    for col in columns_to_convert:\n",
    "        try:\n",
    "            # Remove commas *before* attempting conversion. CRITICAL.\n",
    "            df[col] = df[col].str.replace(',', '', regex=False)  # Remove commas first\n",
    "            df[col] = df[col].astype(float)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error converting column '{col}' to float: {e}\")\n",
    "            return df #skip this column and return the original df\n",
    "\n",
    "    try:\n",
    "        # Handle '-' values in 'Volume' BEFORE removing commas\n",
    "        df['Volume'] = df['Volume'].replace('-', np.nan)\n",
    "        df['Volume'] = df['Volume'].str.replace(',', '', regex=False).astype(float).astype('Int64') # Use Int64 to store NaN\n",
    "    except ValueError as e:\n",
    "        print(f\"Error converting column 'Volume' to int64: {e}\")\n",
    "        return df\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OHvVY-VhuLqV"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def adjust_prices(df):\n",
    "    \"\"\"\n",
    "    Adjusts Open, High, Low, and Close prices using Adj Close to account for splits and dividends.\n",
    "\n",
    "    Args:\n",
    "        df: Pandas DataFrame with 'Open', 'High', 'Low', 'Close', and 'Adj Close' columns.\n",
    "            Assumes MultiIndex with stock ticker and datetime.\n",
    "\n",
    "    Returns:\n",
    "        Pandas DataFrame with adjusted 'Open', 'High', and 'Low' prices.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the adjustment ratio\n",
    "    df['adjustment_ratio'] = df['Adj Close'] / df['Close']\n",
    "\n",
    "    # Adjust Open, High, and Low prices\n",
    "    df['Adj Open'] = df['Open'] * df['adjustment_ratio']\n",
    "    df['Adj High'] = df['High'] * df['adjustment_ratio']\n",
    "    df['Adj Low'] = df['Low'] * df['adjustment_ratio']\n",
    "\n",
    "\n",
    "    # Optionally, drop the adjustment_ratio column if you don't need it\n",
    "    df = df.drop('adjustment_ratio', axis=1)  # axis=1 to drop the column\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example Usage (assuming 'df' is your cleaned DataFrame)\n",
    "# df_adjusted = adjust_prices(df.copy())  # Create a copy\n",
    "# print(df_adjusted.head())\n",
    "# print(df_adjusted.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bnDeGAN7uLqW"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "file_path = '/content/drive/MyDrive/stocks/df_finviz_tickers.pkl'  # Run in Colab\n",
    "\n",
    "loaded_df = pd.read_pickle(file_path)\n",
    "symbols = loaded_df['Ticker'].tolist()\n",
    "print(f\"symbols (len = {len(symbols)}):\")\n",
    "print(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5xZ2jju1uLqW"
   },
   "outputs": [],
   "source": [
    "symbols_to_download = symbols[slice_obj]\n",
    "\n",
    "# symbols_to_download = slice_string(symbols, symbol_start, symbol_end, symbol_step)  # Adjust the slice as needed\n",
    "total_symbols_to_download = len(symbols_to_download)\n",
    "processed_count = 0\n",
    "\n",
    "print(f'symbols_to_download: symbols[{slice_obj}]')\n",
    "print(f'total_symbols_to_download: {total_symbols_to_download}')\n",
    "print(f'processed_count: {processed_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q52YTHcquLqW"
   },
   "outputs": [],
   "source": [
    "current_pst_time = get_current_pst_time()\n",
    "print(f\"Start OHLCV download at PST time: {current_pst_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Ro6O4nGuLqW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame()  # Initialized an empty DataFrame\n",
    "\n",
    "for symbol in symbols_to_download:\n",
    "    url = f\"https://finance.yahoo.com/quote/{symbol}/history/\"\n",
    "    # Introduce a delay between requests (adjust as needed)\n",
    "    delay_seconds = random.uniform(2, 4.5)  # Sleep between 2 and 5 seconds\n",
    "    # print(f\"Downloading {symbol}. Sleeping for {delay_seconds:.2f} seconds...\")\n",
    "    processed_count += 1\n",
    "    print(f\"Downloading {symbol}. Sleeping for {delay_seconds:.2f} seconds.  Processed {processed_count} / {total_symbols_to_download} symbols.\")\n",
    "    time.sleep(delay_seconds)\n",
    "\n",
    "    df_temp = download_yahoo_finance_table(url, selector)\n",
    "\n",
    "    if df_temp is not None:\n",
    "        df_temp.columns = col_names # Ensure the columns are what is expected\n",
    "\n",
    "        df_temp.set_index('Date', inplace=True) # Set Date as Index\n",
    "        # Create MultiIndex\n",
    "        df_temp.index = pd.MultiIndex.from_product([[symbol], df_temp.index], names=['Symbol', 'Date'])\n",
    "\n",
    "        df = pd.concat([df, df_temp])  # Append to the combined DataFrame\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to download data for {symbol}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ekzZn5ahuLqW"
   },
   "outputs": [],
   "source": [
    "current_pst_time = get_current_pst_time()\n",
    "print(f\"End OHLCV download at PST time: {current_pst_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nW2J6txeuLqX"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5elcgkAsuLqX"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ed0R2tQduLqX"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "\n",
    "pst = pytz.timezone('America/Los_Angeles')  # or 'US/Pacific'\n",
    "current_date_pst = datetime.datetime.now(pst).strftime('%Y-%m-%d')\n",
    "\n",
    "df_OHLCV_filename = f\"df_OHLCV_{current_date_pst}_stocks.parquet\"\n",
    "\n",
    "print(f\"df_OHLCV_filename: {df_OHLCV_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5cWwmLvyuLqc"
   },
   "outputs": [],
   "source": [
    "# Drop rows with any NaN values\n",
    "df_dropna = df.dropna()\n",
    "df_dropna.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gqENdn0huLqc"
   },
   "outputs": [],
   "source": [
    "df_converted = convert_df_data_types(df_dropna.copy())  # Create a copy to avoid modifying the original\n",
    "df_converted.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iEi6efHUuLqd"
   },
   "outputs": [],
   "source": [
    "df_adjusted = adjust_prices(df_converted.copy())  # Create a copy\n",
    "df_adjusted.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vWQqc08yqnfk"
   },
   "outputs": [],
   "source": [
    "df_adjusted.to_parquet(df_OHLCV_filename, engine='pyarrow', compression='zstd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bb6tONh4uLqd"
   },
   "outputs": [],
   "source": [
    "df_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zvZEbfwqiS0Z"
   },
   "outputs": [],
   "source": [
    "# Create a ZIP file\n",
    "zip_filename = current_date_pst + '_finviz_OHLCV.zip'\n",
    "zip_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2SjosRxFlcwW"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "# from google.colab import files\n",
    "\n",
    "# Example: List of files to download\n",
    "file_list = [df_finviz_filename, df_OHLCV_filename]\n",
    "\n",
    "# Check if files exist before adding to the zip archive\n",
    "with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
    "    for file in file_list:\n",
    "        if os.path.exists(file):\n",
    "            zipf.write(file)\n",
    "        else:\n",
    "            print(f\"Warning: File not found: {file}. Skipping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XvKKrhq-7UGk"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "if download_to_PC:\n",
    "  # Download the ZIP file (only 1 prompt)\n",
    "  if os.path.exists(zip_filename):\n",
    "      files.download(zip_filename)\n",
    "      print(f\"File '{zip_filename}' dowloaded to PC\")\n",
    "  else:\n",
    "      print(f\"Error: Zip file not created: {zip_filename}\")\n",
    "\n",
    "else:\n",
    "  destination_path = '/content/drive/MyDrive/stocks/'\n",
    "\n",
    "  # Construct the full path to the destination file\n",
    "  destination_file = os.path.join(destination_path, zip_filename)\n",
    "\n",
    "  # Use shutil.copy2 to preserve metadata (like timestamps)\n",
    "  try:\n",
    "      shutil.copy2(zip_filename, destination_file)\n",
    "      print(f\"File '{zip_filename}' downloaded to '{destination_file}'\")\n",
    "  except FileNotFoundError:\n",
    "      print(f\"Error: The file '{zip_filename}' was not found.\")\n",
    "  except Exception as e:\n",
    "      print(f\"An error occurred during the copy operation: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8gD4Ira3CdUo"
   },
   "outputs": [],
   "source": [
    "# # prompt: calculate the daily return of each ticker in df_adjusted. note the date index in df_adjusted is in reverse order\n",
    "\n",
    "# # THIS CALCULATAION IS CORRECT --- Calculate daily returns, handling the reversed date index\n",
    "# df_returns = df_adjusted['Adj Close'].pct_change(periods=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XjbtUIlQf9SQ"
   },
   "outputs": [],
   "source": [
    "# # prompt: cp: cannot stat 'zip_filename.zip': No such file or directory\n",
    "\n",
    "# import os\n",
    "# import zipfile\n",
    "# from google.colab import files\n",
    "\n",
    "# # Example: List of files to download\n",
    "# file_list = [df_finviz_filename, df_OHLCV_filename]\n",
    "\n",
    "# # Check if files exist before adding to the zip archive\n",
    "# with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
    "#     for file in file_list:\n",
    "#         if os.path.exists(file):\n",
    "#             zipf.write(file)\n",
    "#         else:\n",
    "#             print(f\"Warning: File not found: {file}. Skipping.\")\n",
    "\n",
    "# # Download the ZIP file (only 1 prompt)\n",
    "# if os.path.exists(zip_filename):\n",
    "#     files.download(zip_filename)\n",
    "# else:\n",
    "#     print(f\"Error: Zip file not created: {zip_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cMk4EaASg5ze"
   },
   "outputs": [],
   "source": [
    "# # prompt: copy zipeFile from above cell to /content/drive/MyDrive/stocks/\n",
    "\n",
    "# import shutil\n",
    "# import os\n",
    "\n",
    "# # Assuming zip_filename is defined in the previous code cell\n",
    "# # and contains the name of the created zip file.\n",
    "# # Example: zip_filename = '2024-07-27_finviz_OHLCV.zip'\n",
    "\n",
    "# destination_path = '/content/drive/MyDrive/stocks/'\n",
    "\n",
    "# # Construct the full path to the destination file\n",
    "# destination_file = os.path.join(destination_path, zip_filename)\n",
    "\n",
    "# # Use shutil.copy2 to preserve metadata (like timestamps)\n",
    "# try:\n",
    "#     shutil.copy2(zip_filename, destination_file)\n",
    "#     print(f\"File '{zip_filename}' copied to '{destination_file}'\")\n",
    "# except FileNotFoundError:\n",
    "#     print(f\"Error: The file '{zip_filename}' was not found.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"An error occurred during the copy operation: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1c-CzVo5tGFmNmvnIhfHMJTDBqd0fwr_x",
     "timestamp": 1745777515985
    }
   ]
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
