{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backtest Results: Analysis and Visualization (v2)\n",
    "\n",
    "This notebook loads the master results file and performs in-depth analysis and visualization, correctly distinguishing between different strategy parameter sets.\n",
    "\n",
    "**Workflow:**\n",
    "1.  **Setup:** Configure paths and define the columns that identify a unique strategy.\n",
    "2.  **Load Data:** Load the master backtest results file.\n",
    "3.  **Aggregate Analysis:** Calculate performance metrics by grouping on **unique strategy parameters** to ensure a correct, apples-to-apples comparison.\n",
    "4.  **Visualize Evolving Sharpe:** Plot the evolving Sharpe ratio for the best-performing strategy run.\n",
    "5.  **Visualize Equity Curve:** Plot the cumulative return (equity curve) for the best-performing strategy run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Project Path Setup ---\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "ROOT_DIR = NOTEBOOK_DIR.parent if NOTEBOOK_DIR.name == 'notebooks' else NOTEBOOK_DIR\n",
    "if str(ROOT_DIR) not in sys.path:\n",
    "    sys.path.append(str(ROOT_DIR))\n",
    "SRC_DIR = ROOT_DIR / 'src'\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.append(str(SRC_DIR))\n",
    "\n",
    "# --- Local Imports ---\n",
    "import utils\n",
    "# from stocks.notebooks.config_obsolete import ANNUAL_RISK_FREE_RATE, TRADING_DAYS_PER_YEAR\n",
    "from config import ANNUAL_RISK_FREE_RATE, DAILY_RISK_FREE_RATE, TRADING_DAYS_PER_YEAR\n",
    "\n",
    "# --- Analysis Parameters ---\n",
    "# ANNUAL_RISK_FREE_RATE = 0.04\n",
    "# TRADING_DAYS_PER_YEAR = 252\n",
    "MIN_PERIODS_FOR_SHARPE = 10\n",
    "BENCHMARK_TICKER = \"VGT\" # <--- ADD THIS LINE \n",
    "\n",
    "# --- !! CRITICAL: Define columns that identify a unique strategy run !! ---\n",
    "STRATEGY_ID_COLS = [\n",
    "    'n_select_requested',\n",
    "    'filter_min_price',\n",
    "    'filter_min_avg_volume_m',\n",
    "    'score_weight_rsi', # Add/remove any parameters you tune\n",
    "]\n",
    "\n",
    "# --- File Path Construction ---\n",
    "BACKTEST_DIR = ROOT_DIR / 'output' / 'backtest_results'\n",
    "SOURCE_PATH = BACKTEST_DIR / 'backtest_master_results.parquet'\n",
    "DATA_DIR = ROOT_DIR / 'data'\n",
    "\n",
    "# --- Notebook Setup ---\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', 1500)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# --- Verification ---\n",
    "print(f\"Source file for analysis: {SOURCE_PATH}\")\n",
    "print(f\"Identifying unique strategies by: {STRATEGY_ID_COLS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load Backtest Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"--- Step 1: Loading data from {SOURCE_PATH.name} ---\")\n",
    "\n",
    "try:\n",
    "    df_results = pd.read_parquet(SOURCE_PATH)\n",
    "    # Ensure date column is in datetime format for analysis\n",
    "    df_results['actual_selection_date_used'] = pd.to_datetime(df_results['actual_selection_date_used'])\n",
    "    print(f\"✅ Successfully loaded and prepared data for {len(df_results)} backtest runs.\")\n",
    "    # print(df_results)\n",
    "    # print(df_results.head(24))    \n",
    "    display(df_results.head(3))\n",
    "    display(df_results.tail(3))\n",
    "    # display(df_results)         \n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ ERROR: Source file not found at {SOURCE_PATH}. Halting execution.\")\n",
    "    df_results = None          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ?? lateest_date should be max + 5 more dats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the full date range of our entire backtest period\n",
    "earliest_date = df_results['actual_selection_date_used'].min()\n",
    "latest_date = df_results['actual_selection_date_used'].max() + pd.offsets.BDay(0)\n",
    "\n",
    "print(f\"Earliest 'actual_selection_date_used' in backtest: {earliest_date}\")\n",
    "print(f\"Latest 'actual_selection_date_used' in backtest:   {latest_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load Price Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df_prices = pd.read_parquet(DATA_DIR / 'df_adj_close.parquet')\n",
    "\n",
    "# Sort the DataFrame by its index, modifying it in place.\n",
    "_df_prices.sort_index(inplace=True)\n",
    "\n",
    "# --- Step 4: Use .loc with the new, extended end date ---\n",
    "# df_prices = _df_prices.loc[earliest_date:latest_date]\n",
    "df_prices = _df_prices.loc[earliest_date::]\n",
    "print(f\"Loaded price data with {len(_df_prices)} rows and {len(_df_prices.columns)} columns.\")\n",
    "print(f\"df_prices data:\")\n",
    "display(df_prices.head(3))\n",
    "display(df_prices.tail(3))\n",
    "\n",
    "benchmark_price_series = df_prices[BENCHMARK_TICKER]\n",
    "print(f'benchmark_price_series {BENCHMARK_TICKER} prices:')\n",
    "display(benchmark_price_series.head(3))\n",
    "display(benchmark_price_series.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "print(f'len(benchmark_price_series): {len(benchmark_price_series)}')\n",
    "print(f'benchmark_price_series:\\n{benchmark_price_series}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df_results.groupby(STRATEGY_ID_COLS + ['scheme'])\n",
    "print(\"Analyzing each unique strategy run...\")\n",
    "for group_name, group_df in grouped:\n",
    "\n",
    "    # --- START: DIAGNOSTIC CODE TO FIND DUPLICATES ---\n",
    "    # This block will check for and print any duplicate selection dates within this group.\n",
    "    \n",
    "    # Get the counts of each unique date in the 'actual_selection_date_used' column\n",
    "    date_counts = group_df['actual_selection_date_used'].value_counts()\n",
    "    \n",
    "    # Filter to find only those dates that appear more than once\n",
    "    duplicates = date_counts[date_counts > 1]\n",
    "    \n",
    "    # If the 'duplicates' Series is not empty, print the findings\n",
    "    if not duplicates.empty:\n",
    "        print(f\"\\n---> Found duplicate selection dates in group: {group_name}\")\n",
    "        print(\"     Date(s) and their counts:\")\n",
    "        print(duplicates)\n",
    "        print(\"-\" * 40)\n",
    "    else:\n",
    "        print(f\"\\n---> No duplicate selection dates found in group: {group_name}\")    \n",
    "    # --- END: DIAGNOSTIC CODE ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Aggregate Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'mean_bench_100: {mean_bench_100:.6f}')\n",
    "print(f'\\nstd_bench_100: {std_bench_100:.6f}')\n",
    "print(f'\\nbenchmark_buy_and_hold_sharpe: {benchmark_buy_and_hold_sharpe:.6f}')\n",
    "print(f'\\nbenchmark_returns_100 ({len(benchmark_returns_100)}):\\n{benchmark_returns_100}')\n",
    "print(f'\\nbenchmark_full_range ({len(benchmark_full_range)}):\\n{benchmark_full_range}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_results is not None and df_prices is not None:\n",
    "    print(\"\\n--- Step 2: Aggregate Performance Analysis (Corrected for 2-Day Cycle & vs. Benchmark) ---\")\n",
    "    \n",
    "    # --- Part A: Calculate Benchmark Performance First ---\n",
    "    print(f\"Calculating benchmark performance for '{BENCHMARK_TICKER}'...\")\n",
    "    \n",
    "    # Get the full date range of our entire backtest period\n",
    "    min_date = df_results['actual_selection_date_used'].min()\n",
    "    max_date = df_results['actual_selection_date_used'].max() + pd.DateOffset(days=2)\n",
    "\n",
    "    # benchmark_full_range = pd.date_range(start=min_date, end=max_date, freq='B')\n",
    "    # --- THIS IS THE FIX ---\n",
    "    # Create the benchmark timeline using ONLY the actual trading days from df_prices.\n",
    "    # This automatically handles all holidays and non-trading days correctly.\n",
    "    benchmark_full_range = df_prices.index[(df_prices.index >= min_date) & (df_prices.index <= max_date)]\n",
    "    # --- END FIX ---    \n",
    "\n",
    "###################\n",
    "    print(f'min_date: {min_date}, max_date: {max_date},\\nbenchmark_full_range ({len(benchmark_full_range)}):\\n{benchmark_full_range}')\n",
    "###################\n",
    "\n",
    "    \n",
    "#++++ CHECKED OK +++++++++++++++++++++++++\n",
    "    # Benchmark 1: Buy and Hold (100% invested)\n",
    "    benchmark_returns_100 = df_prices[BENCHMARK_TICKER].pct_change().reindex(benchmark_full_range)    \n",
    "    mean_bench_100 = benchmark_returns_100.mean()\n",
    "    std_bench_100 = benchmark_returns_100.std()\n",
    "    benchmark_buy_and_hold_sharpe = (mean_bench_100 * TRADING_DAYS_PER_YEAR - ANNUAL_RISK_FREE_RATE) / (std_bench_100 * np.sqrt(TRADING_DAYS_PER_YEAR))\n",
    "#++++ CHECKED OK +++++++++++++++++++++++++\n",
    "\n",
    "    # --- FIX STARTS HERE ---\n",
    "    # Benchmark 2: Timed (50% cash, mimicking the strategy)\n",
    "    # First, get only the UNIQUE selection dates to avoid duplicate index issues.\n",
    "    unique_selection_dates = df_results['actual_selection_date_used'].unique()\n",
    "    \n",
    "    selection_indices = df_prices.index.get_indexer(unique_selection_dates, method='ffill')\n",
    "\n",
    "###################\n",
    "    selection_indices_no_ffill = df_prices.index.get_indexer(unique_selection_dates)\n",
    "    \n",
    "    print(f'unique_selection_dates ({len(unique_selection_dates)}):\\n{unique_selection_dates}')\n",
    "    print(f'selection_indices ({len(selection_indices)}):\\n{selection_indices}')\n",
    "    print(f'selection_indices_no_ffill ({len(selection_indices_no_ffill)}):\\n{selection_indices_no_ffill}')\n",
    "###################\n",
    "\n",
    "    # --- ROBUSTNESS FIX: Ensure we don't try to trade past the end of our price data ---\n",
    "    # Create a boolean mask to identify which indices are valid for a T+2 trade.\n",
    "    # An index is valid only if its position + 2 is still within the bounds of df_prices.\n",
    "    valid_trade_mask = (selection_indices + 2) < len(df_prices)\n",
    "\n",
    "    # Apply this mask to get only the indices where a T+2 trade is possible\n",
    "    valid_selection_indices = selection_indices[valid_trade_mask]\n",
    "    # --- END ROBUSTNESS FIX ---\n",
    "\n",
    "    # Now, use the filtered 'valid_selection_indices' for all subsequent calculations\n",
    "    buy_prices_bench = df_prices[BENCHMARK_TICKER].iloc[valid_selection_indices + 1]\n",
    "    sell_prices_bench = df_prices[BENCHMARK_TICKER].iloc[valid_selection_indices + 2]\n",
    "\n",
    "    # Important: We must also filter the corresponding sell dates\n",
    "    sell_dates_bench = df_prices.index[valid_selection_indices + 2]\n",
    "\n",
    "    # The rest of the calculation proceeds safely\n",
    "    trade_returns_bench = (sell_prices_bench.values - buy_prices_bench.values) / buy_prices_bench.values\n",
    "\n",
    "    timed_benchmark_series = pd.Series(trade_returns_bench, index=sell_dates_bench).reindex(benchmark_full_range).fillna(0)\n",
    "    # --- FIX ENDS HERE ---\n",
    "\n",
    "    mean_bench_50 = timed_benchmark_series.mean()\n",
    "    std_bench_50 = timed_benchmark_series.std()\n",
    "    benchmark_timed_sharpe = (mean_bench_50 * TRADING_DAYS_PER_YEAR - ANNUAL_RISK_FREE_RATE) / (std_bench_50 * np.sqrt(TRADING_DAYS_PER_YEAR))\n",
    "\n",
    "\n",
    "    # --- Part B: Calculate Strategy Performance (Corrected Logic) ---\n",
    "    summary_records = []\n",
    "    grouped = df_results.groupby(STRATEGY_ID_COLS + ['scheme'])\n",
    "    # daily_risk_free_rate = ANNUAL_RISK_FREE_RATE / TRADING_DAYS_PER_YEAR\n",
    "    daily_risk_free_rate = DAILY_RISK_FREE_RATE   \n",
    "\n",
    "    print(\"Analyzing each unique strategy run...\")\n",
    "    for group_name, group_df in grouped:\n",
    "\n",
    "\n",
    "\n",
    "        # --- START: DIAGNOSTIC CODE TO FIND DUPLICATES ---\n",
    "        # This block will check for and print any duplicate selection dates within this group.\n",
    "        \n",
    "        # Get the counts of each unique date in the 'actual_selection_date_used' column\n",
    "        date_counts = group_df['actual_selection_date_used'].value_counts()\n",
    "        \n",
    "        # Filter to find only those dates that appear more than once\n",
    "        duplicates = date_counts[date_counts > 1]\n",
    "        \n",
    "        # If the 'duplicates' Series is not empty, print the findings\n",
    "        if not duplicates.empty:\n",
    "            print(f\"\\n---> Found duplicate selection dates in group: {group_name}\")\n",
    "            print(\"     Date(s) and their counts:\")\n",
    "            print(duplicates)\n",
    "            print(\"-\" * 40)\n",
    "        # --- END: DIAGNOSTIC CODE ---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # --- Correctly find the T+2 TRADING DAY for the sell date ---\n",
    "        selection_indices_strat = df_prices.index.get_indexer(group_df['actual_selection_date_used'], method='ffill')\n",
    "\n",
    "\n",
    "###############\n",
    "        print(f'selection_indices_strat ({len(selection_indices_strat)}):\\n{selection_indices_strat}')\n",
    "###############\n",
    "\n",
    "\n",
    "        # sell_dates_strat = df_prices.index[selection_indices_strat + 2]\n",
    "        # trade_returns = pd.Series(group_df['portfolio_return'].values, index=sell_dates_strat)\n",
    "\n",
    "        # --- ROBUSTNESS FIX: Add the same mask logic here ---\n",
    "        # Create a mask to find which trades are actually possible (not too close to the end)\n",
    "        valid_trade_mask = (selection_indices_strat + 2) < len(df_prices)\n",
    "        \n",
    "        # Apply the mask to get only the valid integer positions\n",
    "        valid_indices = selection_indices_strat[valid_trade_mask]\n",
    "\n",
    "        # CRUCIAL: Also apply the mask to the group_df itself to keep data aligned!\n",
    "        valid_group_df = group_df[valid_trade_mask]\n",
    "        # --- END FIX ---\n",
    "        \n",
    "        # Now, use the filtered \"valid\" data for all calculations\n",
    "        # If there are no valid trades left in this group after filtering, skip it.\n",
    "        if valid_group_df.empty:\n",
    "            continue # or handle as you see fit\n",
    "\n",
    "        # Use valid_indices to get the correct sell dates\n",
    "        sell_dates_strat = df_prices.index[valid_indices + 2]\n",
    "        \n",
    "        # Use valid_group_df to get the corresponding portfolio returns\n",
    "        trade_returns = pd.Series(valid_group_df['portfolio_return'].values, index=sell_dates_strat)\n",
    "\n",
    "        # Create the continuous timeline with zero-fill for cash days\n",
    "        start_date = trade_returns.index.min()\n",
    "        end_date = trade_returns.index.max()\n",
    "\n",
    "\n",
    "        # full_date_range = pd.date_range(start=start_date, end=end_date, freq='B')\n",
    "        # --- THIS IS THE SECOND FIX ---\n",
    "        # Create the strategy's timeline using ONLY the actual trading days from df_prices.\n",
    "        full_date_range = df_prices.index[(df_prices.index >= start_date) & (df_prices.index <= end_date)]\n",
    "        # --- END FIX ---\n",
    "\n",
    "\n",
    "\n",
    "########################\n",
    "        print(f'start_date: {start_date}, end_date: {end_date}')\n",
    "        print(f'full_date_range ({len(full_date_range)}):\\n {full_date_range}')\n",
    "        print(f'trade_returns ({len(trade_returns)}):\\n{trade_returns}')\n",
    "########################\n",
    "\n",
    "        daily_return_series = trade_returns.reindex(full_date_range).fillna(0)\n",
    "        mean_return = daily_return_series.mean()\n",
    "        std_dev_return = daily_return_series.std()\n",
    "        \n",
    "        if std_dev_return > 1e-9:\n",
    "            sharpe_ratio = (mean_return - daily_risk_free_rate) / std_dev_return\n",
    "        else:\n",
    "            sharpe_ratio = np.nan\n",
    "        annualized_sharpe = sharpe_ratio * np.sqrt(TRADING_DAYS_PER_YEAR)\n",
    "        \n",
    "        record = dict(zip(STRATEGY_ID_COLS + ['scheme'], group_name))\n",
    "        record['Num Trade Days'] = len(group_df)\n",
    "        record['Annualized Sharpe (adj. for cash)'] = annualized_sharpe\n",
    "        summary_records.append(record)\n",
    "\n",
    "    # --- Part C: Combine and Display Final Summary ---\n",
    "    df_summary = pd.DataFrame(summary_records).set_index(STRATEGY_ID_COLS + ['scheme'])\n",
    "    df_summary = df_summary.sort_values(by='Annualized Sharpe (adj. for cash)', ascending=False)\n",
    "    \n",
    "    # Create benchmark DataFrame to append\n",
    "    benchmark_data = {\n",
    "        'Num Trade Days': ['N/A', 'N/A'],\n",
    "        'Annualized Sharpe (adj. for cash)': [benchmark_buy_and_hold_sharpe, benchmark_timed_sharpe]\n",
    "    }\n",
    "    # Adjusting the benchmark index to match the columns in df_summary\n",
    "    # We create a list of tuples for the MultiIndex\n",
    "    benchmark_index_tuples = [\n",
    "        tuple(['BENCHMARK', BENCHMARK_TICKER, 'Buy & Hold'] + ['N/A'] * (len(df_summary.index.names) - 3)),\n",
    "        tuple(['BENCHMARK', BENCHMARK_TICKER, 'Timed'] + ['N/A'] * (len(df_summary.index.names) - 3))\n",
    "    ]\n",
    "    benchmark_index = pd.MultiIndex.from_tuples(benchmark_index_tuples, names=df_summary.index.names)\n",
    "    df_benchmark = pd.DataFrame(benchmark_data, index=benchmark_index)\n",
    "\n",
    "    df_final_summary = pd.concat([df_summary, df_benchmark])\n",
    "\n",
    "    print(f\"\\nAnalysis complete. Comparison vs. '{BENCHMARK_TICKER}'\")\n",
    "    display(df_final_summary)\n",
    "\n",
    "else:\n",
    "    print(\"Skipping analysis because data or price files failed to load.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if df_results is not None and df_prices is not None:\n",
    "#     print(\"\\n--- Step 2: Aggregate Performance Analysis (Corrected for 2-Day Cycle & vs. Benchmark) ---\")\n",
    "    \n",
    "#     # --- Part A: Calculate Benchmark Performance First ---\n",
    "#     print(f\"Calculating benchmark performance for '{BENCHMARK_TICKER}'...\")\n",
    "    \n",
    "#     # Get the full date range of our entire backtest period\n",
    "#     min_date = df_results['actual_selection_date_used'].min()\n",
    "#     max_date = df_results['actual_selection_date_used'].max() + pd.DateOffset(days=2)\n",
    "#     benchmark_full_range = pd.date_range(start=min_date, end=max_date, freq='B')\n",
    "    \n",
    "#     # Benchmark 1: Buy and Hold (100% invested)\n",
    "#     benchmark_returns_100 = df_prices[BENCHMARK_TICKER].pct_change().reindex(benchmark_full_range).fillna(0)\n",
    "#     mean_bench_100 = benchmark_returns_100.mean()\n",
    "#     std_bench_100 = benchmark_returns_100.std()\n",
    "#     benchmark_buy_and_hold_sharpe = (mean_bench_100 * TRADING_DAYS_PER_YEAR - ANNUAL_RISK_FREE_RATE) / (std_bench_100 * np.sqrt(TRADING_DAYS_PER_YEAR))\n",
    "\n",
    "#     # --- FIX STARTS HERE ---\n",
    "#     # Benchmark 2: Timed (50% cash, mimicking the strategy)\n",
    "#     # First, get only the UNIQUE selection dates to avoid duplicate index issues.\n",
    "#     unique_selection_dates = df_results['actual_selection_date_used'].unique()\n",
    "    \n",
    "#     selection_indices = df_prices.index.get_indexer(unique_selection_dates, method='ffill')\n",
    "\n",
    "#     # --- ROBUSTNESS FIX: Ensure we don't try to trade past the end of our price data ---\n",
    "#     # Create a boolean mask to identify which indices are valid for a T+2 trade.\n",
    "#     # An index is valid only if its position + 2 is still within the bounds of df_prices.\n",
    "#     valid_trade_mask = (selection_indices + 2) < len(df_prices)\n",
    "\n",
    "#     # Apply this mask to get only the indices where a T+2 trade is possible\n",
    "#     valid_selection_indices = selection_indices[valid_trade_mask]\n",
    "#     # --- END ROBUSTNESS FIX ---\n",
    "\n",
    "#     # Now, use the filtered 'valid_selection_indices' for all subsequent calculations\n",
    "#     buy_prices_bench = df_prices[BENCHMARK_TICKER].iloc[valid_selection_indices + 1]\n",
    "#     sell_prices_bench = df_prices[BENCHMARK_TICKER].iloc[valid_selection_indices + 2]\n",
    "\n",
    "#     # Important: We must also filter the corresponding sell dates\n",
    "#     sell_dates_bench = df_prices.index[valid_selection_indices + 2]\n",
    "\n",
    "#     # The rest of the calculation proceeds safely\n",
    "#     trade_returns_bench = (sell_prices_bench.values - buy_prices_bench.values) / buy_prices_bench.values\n",
    "\n",
    "#     timed_benchmark_series = pd.Series(trade_returns_bench, index=sell_dates_bench).reindex(benchmark_full_range).fillna(0)\n",
    "#     # --- FIX ENDS HERE ---\n",
    "\n",
    "#     mean_bench_50 = timed_benchmark_series.mean()\n",
    "#     std_bench_50 = timed_benchmark_series.std()\n",
    "#     benchmark_timed_sharpe = (mean_bench_50 * TRADING_DAYS_PER_YEAR - ANNUAL_RISK_FREE_RATE) / (std_bench_50 * np.sqrt(TRADING_DAYS_PER_YEAR))\n",
    "\n",
    "\n",
    "#     # --- Part B: Calculate Strategy Performance (Corrected Logic) ---\n",
    "#     summary_records = []\n",
    "#     grouped = df_results.groupby(STRATEGY_ID_COLS + ['scheme'])\n",
    "#     # daily_risk_free_rate = ANNUAL_RISK_FREE_RATE / TRADING_DAYS_PER_YEAR\n",
    "#     daily_risk_free_rate = DAILY_RISK_FREE_RATE   \n",
    "\n",
    "#     print(\"Analyzing each unique strategy run...\")\n",
    "#     for group_name, group_df in grouped:\n",
    "        \n",
    "#         # --- Correctly find the T+2 TRADING DAY for the sell date ---\n",
    "#         selection_indices_strat = df_prices.index.get_indexer(group_df['actual_selection_date_used'], method='ffill')\n",
    "#         # sell_dates_strat = df_prices.index[selection_indices_strat + 2]\n",
    "#         # trade_returns = pd.Series(group_df['portfolio_return'].values, index=sell_dates_strat)\n",
    "\n",
    "#         # --- ROBUSTNESS FIX: Add the same mask logic here ---\n",
    "#         # Create a mask to find which trades are actually possible (not too close to the end)\n",
    "#         valid_trade_mask = (selection_indices_strat + 2) < len(df_prices)\n",
    "        \n",
    "#         # Apply the mask to get only the valid integer positions\n",
    "#         valid_indices = selection_indices_strat[valid_trade_mask]\n",
    "\n",
    "#         # CRUCIAL: Also apply the mask to the group_df itself to keep data aligned!\n",
    "#         valid_group_df = group_df[valid_trade_mask]\n",
    "#         # --- END FIX ---\n",
    "        \n",
    "#         # Now, use the filtered \"valid\" data for all calculations\n",
    "#         # If there are no valid trades left in this group after filtering, skip it.\n",
    "#         if valid_group_df.empty:\n",
    "#             continue # or handle as you see fit\n",
    "\n",
    "#         # Use valid_indices to get the correct sell dates\n",
    "#         sell_dates_strat = df_prices.index[valid_indices + 2]\n",
    "        \n",
    "#         # Use valid_group_df to get the corresponding portfolio returns\n",
    "#         trade_returns = pd.Series(valid_group_df['portfolio_return'].values, index=sell_dates_strat)\n",
    "\n",
    "#         # Create the continuous timeline with zero-fill for cash days\n",
    "#         start_date = trade_returns.index.min()\n",
    "#         end_date = trade_returns.index.max()\n",
    "#         full_date_range = pd.date_range(start=start_date, end=end_date, freq='B')\n",
    "#         daily_return_series = trade_returns.reindex(full_date_range).fillna(0)\n",
    "#         mean_return = daily_return_series.mean()\n",
    "#         std_dev_return = daily_return_series.std()\n",
    "        \n",
    "#         if std_dev_return > 1e-9:\n",
    "#             sharpe_ratio = (mean_return - daily_risk_free_rate) / std_dev_return\n",
    "#         else:\n",
    "#             sharpe_ratio = np.nan\n",
    "#         annualized_sharpe = sharpe_ratio * np.sqrt(TRADING_DAYS_PER_YEAR)\n",
    "        \n",
    "#         record = dict(zip(STRATEGY_ID_COLS + ['scheme'], group_name))\n",
    "#         record['Num Trade Days'] = len(group_df)\n",
    "#         record['Annualized Sharpe (adj. for cash)'] = annualized_sharpe\n",
    "#         summary_records.append(record)\n",
    "\n",
    "#     # --- Part C: Combine and Display Final Summary ---\n",
    "#     df_summary = pd.DataFrame(summary_records).set_index(STRATEGY_ID_COLS + ['scheme'])\n",
    "#     df_summary = df_summary.sort_values(by='Annualized Sharpe (adj. for cash)', ascending=False)\n",
    "    \n",
    "#     # Create benchmark DataFrame to append\n",
    "#     benchmark_data = {\n",
    "#         'Num Trade Days': ['N/A', 'N/A'],\n",
    "#         'Annualized Sharpe (adj. for cash)': [benchmark_buy_and_hold_sharpe, benchmark_timed_sharpe]\n",
    "#     }\n",
    "#     # Adjusting the benchmark index to match the columns in df_summary\n",
    "#     # We create a list of tuples for the MultiIndex\n",
    "#     benchmark_index_tuples = [\n",
    "#         tuple(['BENCHMARK', BENCHMARK_TICKER, 'Buy & Hold'] + ['N/A'] * (len(df_summary.index.names) - 3)),\n",
    "#         tuple(['BENCHMARK', BENCHMARK_TICKER, 'Timed'] + ['N/A'] * (len(df_summary.index.names) - 3))\n",
    "#     ]\n",
    "#     benchmark_index = pd.MultiIndex.from_tuples(benchmark_index_tuples, names=df_summary.index.names)\n",
    "#     df_benchmark = pd.DataFrame(benchmark_data, index=benchmark_index)\n",
    "\n",
    "#     df_final_summary = pd.concat([df_summary, df_benchmark])\n",
    "\n",
    "#     print(f\"\\nAnalysis complete. Comparison vs. '{BENCHMARK_TICKER}'\")\n",
    "#     display(df_final_summary)\n",
    "\n",
    "# else:\n",
    "#     print(\"Skipping analysis because data or price files failed to load.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming 'grouped_for_demo' is your groupby object from before\n",
    "# group_names = list(grouped_for_demo.groups.keys())\n",
    "\n",
    "# # # Print the list of available group names\n",
    "# # print(\"Available group names:\")\n",
    "# # for i, name in enumerate(group_names):\n",
    "#     # print(f\"{i}  - {name}\")\n",
    "\n",
    "# # Use .get_group() to retrieve the DataFrame for just that group\n",
    "# specific_group_df = grouped_for_demo.get_group(group_names[1])\n",
    "\n",
    "# # Now you can work with this specific DataFrame\n",
    "# print(f\"\\nDataFrame for group: {group_names[1]}\")\n",
    "# print(specific_group_df)\n",
    "\n",
    "# group_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This cell demonstrates the CORRECTED DateOffset logic and adds a benchmark comparison.\n",
    "\n",
    "# if 'df_results' in locals() and 'df_prices' in locals():\n",
    "    \n",
    "#     # --- 1. Isolate a small sample to demonstrate with ---\n",
    "#     grouped_for_demo = df_results.groupby(STRATEGY_ID_COLS + ['scheme'])\n",
    "#     group_name, sample_group_df = next(iter(grouped_for_demo))\n",
    "    \n",
    "#     print(f\"--- Demonstrating with a sample group: {group_name} ---\")\n",
    "    \n",
    "#     # --- 2. Get the integer positions of the selection dates ---\n",
    "#     selection_dates = sample_group_df['actual_selection_date_used']\n",
    "#     selection_indices = df_prices.index.get_indexer(selection_dates, method='ffill')\n",
    "    \n",
    "#     # --- ROBUSTNESS FIX: Filter out trades that are too close to the end ---\n",
    "#     # Create a mask to identify which indices are valid for a T+2 trade.\n",
    "#     valid_trade_mask = (selection_indices + 2) < len(df_prices)\n",
    "\n",
    "#     # Apply this mask to all data sources that need to be aligned\n",
    "#     valid_indices = selection_indices[valid_trade_mask]\n",
    "#     valid_selection_dates = selection_dates[valid_trade_mask]\n",
    "#     valid_sample_group_df = sample_group_df[valid_trade_mask]\n",
    "#     # --- END FIX ---\n",
    "    \n",
    "#     # If all trades in this sample were filtered out, print a message and stop.\n",
    "#     if valid_sample_group_df.empty:\n",
    "#         print(\"\\nNOTE: The selected sample group contained no trades that could be completed (all were too close to the end of the price data).\")\n",
    "#     else:\n",
    "#         # --- 3. Calculate Benchmark Return using ONLY the valid indices ---\n",
    "#         buy_prices_bench = df_prices[BENCHMARK_TICKER].iloc[valid_indices + 1]\n",
    "#         sell_prices_bench = df_prices[BENCHMARK_TICKER].iloc[valid_indices + 2]\n",
    "#         benchmark_trade_returns = (sell_prices_bench.values - buy_prices_bench.values) / buy_prices_bench.values\n",
    "\n",
    "#         # --- 4. Create the comprehensive \"before and after\" DataFrame using filtered data ---\n",
    "#         demo_df = pd.DataFrame({\n",
    "#             'A_Selection_Date': valid_selection_dates.values,\n",
    "#             'B_Incorrect_Sell_Date (Calendar)': (valid_selection_dates + pd.DateOffset(days=2)).values,\n",
    "#             'C_Correct_Sell_Date (Trading)': df_prices.index[valid_indices + 2],\n",
    "#             'D_Portfolio_Return': valid_sample_group_df['portfolio_return'].values,\n",
    "#             'E_Benchmark_Return': benchmark_trade_returns\n",
    "#         })\n",
    "\n",
    "#         print(\"\\n--- Side-by-Side Performance for Individual Trades ---\")\n",
    "#         display(demo_df)\n",
    "        \n",
    "#         print(\"\\nEXPLANATION:\")\n",
    "#         print(\" - Column 'C' shows the correct sell date, skipping weekends.\")\n",
    "#         print(\" - Column 'D' is your strategy's return for the T+1 to T+2 period.\")\n",
    "#         print(f\" - Column 'E' is the '{BENCHMARK_TICKER}' return for the exact same period, allowing for a direct comparison.\")\n",
    "\n",
    "# else:\n",
    "#     print(\"Please run the data loading cells first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###########\n",
    "# selection_date_bench = df_prices[BENCHMARK_TICKER].iloc[selection_indices + 0]\n",
    "\n",
    "# # Define your start and end dates\n",
    "# start_date = '2025-04-25'\n",
    "# end_date = '2025-06-20'\n",
    "\n",
    "# # Convert the index to a list and sort it in one step\n",
    "# df_prices_index = df_prices.loc[start_date:end_date].index \\\n",
    "#     .sort_values() \\\n",
    "#     .strftime('%Y-%m-%d') \\\n",
    "#     .tolist()\n",
    "\n",
    "# # Use .loc to select all rows between these dates (inclusive)\n",
    "# # selected_df = df.loc[start_date:end_date]\n",
    "\n",
    "# # The 'selected_df' now contains only the data for that period\n",
    "# # print(selected_df)\n",
    "\n",
    "\n",
    "# print(f'\\nselection_date_bench:\\n{selection_date_bench}')\n",
    "# print(f'\\nbuy_prices_bench:\\n{buy_prices_bench}')\n",
    "# print(f'\\nsell_prices_bench:\\n{sell_prices_bench}')\n",
    "# print(f'\\ndf_prices_index:\\n')\n",
    "# for date in df_prices_index:\n",
    "#     print(date)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_prices_index = df_prices.index.sort_values().strftime('%Y-%m-%d').to_list()\n",
    "# df_prices_index\n",
    "\n",
    "# sell_dates_strat_index = sell_dates_strat.sort_values().strftime('%Y-%m-%d').to_list()\n",
    "# sell_dates_strat_index\n",
    "\n",
    "# trade_returns\n",
    "\n",
    "# daily_return_series\n",
    "\n",
    "# group_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'df_prices.index:\\n{df_prices.index}')\n",
    "# print(f'selection_indices_strat:\\n{selection_indices_strat}')\n",
    "# print(f'sell_dates_strat:\\n{sell_dates_strat}')\n",
    "# print(f'trade_returns:\\n{trade_returns}')        \n",
    "# print(f'daily_return_series:\\n{daily_return_series}')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "# buy_prices_bench\n",
    "# sell_prices_bench\n",
    "# print(df_prices[BENCHMARK_TICKER])  \n",
    "# benchmark_trade_returns\n",
    "# benchmark_trade_returns.tolist()\n",
    "# benchmark_prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df_summary\n",
    "# strategy_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This interactive cell allows the user to select and plot the equity curves\n",
    "# for any combination of strategy runs against the benchmark.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "if 'df_summary' in locals() and not df_summary.empty and 'df_prices' in locals():\n",
    "\n",
    "    # --- 1. Prepare the list of strategies for the widget ---\n",
    "    # We need a user-friendly name for each strategy and a way to map it back\n",
    "    # to the MultiIndex tuple used for filtering.\n",
    "    strategy_map = {}\n",
    "    for strategy_params in df_summary.index:\n",
    "        params_dict = dict(zip(df_summary.index.names, strategy_params))\n",
    "        # Create a concise, readable label\n",
    "        params_list = [f\"{k.split('_')[-1]}={v}\" for k, v in params_dict.items() if k not in ['scheme', 'n_select_requested']]\n",
    "        label_params = f\"n={params_dict.get('n_select_requested', 'N/A')}, {', '.join(params_list)}\"\n",
    "        strategy_label = f\"#{len(strategy_map)+1} - Scheme: {params_dict['scheme']} ({label_params})\"\n",
    "        strategy_map[strategy_label] = strategy_params\n",
    "\n",
    "    # --- 2. Create the Interactive Selection Widget ---\n",
    "    strategy_selector = widgets.SelectMultiple(\n",
    "        options=strategy_map.keys(),\n",
    "        value=[list(strategy_map.keys())[0]],  # Default to selecting the top strategy\n",
    "        description='Strategies',\n",
    "        disabled=False,\n",
    "        layout={'height': '250px', 'width': '95%'} # Make the widget easy to use\n",
    "    )\n",
    "\n",
    "    # --- 3. Create the function that will be called by the widget ---\n",
    "    def plot_selected_strategies(selected_labels):\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def plot_selected_strategies(selected_labels):\n",
    "        if not selected_labels:\n",
    "            print(\"Please select at least one strategy to plot.\")\n",
    "            return\n",
    "\n",
    "        print(f\"Plotting {len(selected_labels)} selected strategies vs. Benchmark...\")\n",
    "\n",
    "        # --- Determine the overall date range for the plot ---\n",
    "        selected_indices_tuples = [strategy_map[label] for label in selected_labels]\n",
    "        \n",
    "        # Correctly create a boolean mask for filtering df_results\n",
    "        mask = df_results.set_index(df_summary.index.names).index.isin(selected_indices_tuples)\n",
    "        all_relevant_runs = df_results[mask]\n",
    "        \n",
    "        if all_relevant_runs.empty:\n",
    "            print(\"No data found for the selected strategies.\")\n",
    "            return\n",
    "            \n",
    "        first_selection_date = all_relevant_runs['actual_selection_date_used'].min()\n",
    "        last_selection_date = all_relevant_runs['actual_selection_date_used'].max()\n",
    "        \n",
    "        # --- ROBUSTNESS FIX 1: Ensure the plot's date range is valid ---\n",
    "        start_loc = df_prices.index.get_indexer([first_selection_date], method='ffill')[0] + 1\n",
    "        \n",
    "        # Calculate the desired end position, but don't let it go out of bounds\n",
    "        desired_end_loc = df_prices.index.get_indexer([last_selection_date], method='ffill')[0] + 2\n",
    "        max_valid_loc = len(df_prices) - 1 # The highest valid index is len-1\n",
    "        end_loc = min(desired_end_loc, max_valid_loc)\n",
    "        \n",
    "        # Get the date range safely\n",
    "        correct_date_range = df_prices.index[start_loc:end_loc+1] # Slice up to and including end_loc\n",
    "        # --- END FIX 1 ---\n",
    "\n",
    "        # --- Setup the Plot ---\n",
    "        plt.style.use('seaborn-v0_8-darkgrid')\n",
    "        fig, ax = plt.subplots(figsize=(15, 8))\n",
    "        \n",
    "        # --- Loop Through Selected Strategies, Calculate, and Plot ---\n",
    "        for label in selected_labels:\n",
    "            strategy_params = strategy_map[label]\n",
    "            \n",
    "            # Create a boolean mask to filter for the current strategy group\n",
    "            group_mask = (df_results[df_summary.index.names] == pd.Series(strategy_params, index=df_summary.index.names)).all(axis=1)\n",
    "            df_strategy = df_results[group_mask]\n",
    "            \n",
    "            if df_strategy.empty:\n",
    "                continue\n",
    "\n",
    "            selection_indices = df_prices.index.get_indexer(df_strategy['actual_selection_date_used'], method='ffill')\n",
    "            \n",
    "            # --- ROBUSTNESS FIX 2: Apply the valid_trade_mask inside the loop ---\n",
    "            valid_trade_mask = (selection_indices + 2) < len(df_prices)\n",
    "            valid_indices = selection_indices[valid_trade_mask]\n",
    "            valid_group_df = df_strategy[valid_trade_mask]\n",
    "            \n",
    "            if valid_group_df.empty:\n",
    "                continue # Skip this strategy if it has no valid trades to plot\n",
    "                \n",
    "            sell_dates = df_prices.index[valid_indices + 2]\n",
    "            trade_returns = pd.Series(valid_group_df['portfolio_return'].values, index=sell_dates)\n",
    "            # --- END FIX 2 ---\n",
    "            \n",
    "            strategy_daily_returns = trade_returns.reindex(correct_date_range).fillna(0)\n",
    "            strategy_equity_curve = (1 + strategy_daily_returns).cumprod()\n",
    "\n",
    "            ax.plot(strategy_equity_curve.index, strategy_equity_curve.values, \n",
    "                    label=label, linewidth=2.0)\n",
    "\n",
    "        # --- Plot the Benchmark Curve ---\n",
    "        benchmark_prices = df_prices.loc[correct_date_range, BENCHMARK_TICKER]\n",
    "        benchmark_equity_curve = benchmark_prices / benchmark_prices.iloc[0]\n",
    "        ax.plot(benchmark_equity_curve.index, benchmark_equity_curve.values, \n",
    "                label=f\"Buy & Hold '{BENCHMARK_TICKER}'\", linewidth=1.5, color='black', linestyle='--', zorder=1)\n",
    "\n",
    "        # --- Finalize the Plot ---\n",
    "        ax.set_title(f\"Selected Strategies vs. Benchmark: Growth of $1\", fontsize=16)\n",
    "        ax.set_xlabel(\"Date\")\n",
    "        ax.set_ylabel(\"Equity Curve (1 = breakeven)\")\n",
    "        ax.legend(fontsize=9, loc='upper left')\n",
    "        ax.grid(True, which='both', linestyle=':', linewidth=0.6)\n",
    "        fig.autofmt_xdate()\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    # --- 4. Display the widget and link it to the plotting function ---\n",
    "    print(\"✅ Interactive Plotting Cell Ready\")\n",
    "    print(\"Use Ctrl+Click (or Cmd+Click on Mac) to select multiple strategies, or Shift+Click for a range.\")\n",
    "    \n",
    "    widgets.interact(plot_selected_strategies, selected_labels=strategy_selector)\n",
    "\n",
    "else:\n",
    "    print(\"Please run the analysis in 'Step 2' first to generate the 'df_summary' table.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# plot_selected_strategies('#1 - Scheme: IV (n=10, price=10.0, m=2.0, rsi=0.35)')\n",
    "# plot_selected_strategies([1,2])\n",
    "# plot_selected_strategies('Scheme: IV (n=10, price=10.0, m=2.0, rsi=0.35)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the 'portfolio_return' column FIRST, then apply aggregations\n",
    "df_summary = grouped['portfolio_return'].agg(['mean', 'std', 'count']).sort_values(by='mean', ascending=False)\n",
    "\n",
    "print(\"Aggregate statistics for each unique strategy run:\")\n",
    "display(df_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell the aggregation functions to automatically ignore non-numeric columns\n",
    "df_summary_all_numeric = grouped.agg(\n",
    "    mean=('portfolio_return', lambda x: x.mean(numeric_only=True)),\n",
    "    std=('portfolio_return', lambda x: x.std(numeric_only=True)),\n",
    "    count=('portfolio_return', 'count')\n",
    ").sort_values(by='mean', ascending=False)\n",
    "\n",
    "\n",
    "# A simpler way if you just want to run the functions on all applicable columns\n",
    "df_summary_all_numeric = grouped.mean(numeric_only=True)\n",
    "\n",
    "print(\"Mean of all numeric columns for each unique strategy run:\")\n",
    "display(df_summary_all_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Visualize Evolving Sharpe for Top Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_summary' in locals() and not df_summary.empty:\n",
    "    print(\"\\n--- Step 3: Plotting Evolving Sharpe Ratio for the Top Strategy Run ---\")\n",
    "    \n",
    "    # Get the parameters of the best strategy from our summary table\n",
    "    top_strategy_params = df_summary.index[0]\n",
    "    \n",
    "    # Create a filter mask to select only the data for this specific run\n",
    "    strategy_filter_mask = (df_results[STRATEGY_ID_COLS + ['scheme']] == top_strategy_params).all(axis=1)\n",
    "    df_top_strategy = df_results[strategy_filter_mask]\n",
    "\n",
    "    # Call the utility function\n",
    "    utils.plot_evolving_annualized_sharpe(\n",
    "        df=df_top_strategy, # Pass only the filtered data for the best strategy\n",
    "        date_col='actual_selection_date_used',\n",
    "        return_col='portfolio_return',\n",
    "        scheme_col='scheme',\n",
    "        annual_risk_free_rate=ANNUAL_RISK_FREE_RATE,\n",
    "        trading_days_per_year=TRADING_DAYS_PER_YEAR,\n",
    "        min_periods_for_sharpe=MIN_PERIODS_FOR_SHARPE\n",
    "    )\n",
    "else:\n",
    "    print(\"Skipping visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below Cells are for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the names of all the groups pandas created\n",
    "print(\"Available group names:\")\n",
    "print(list(grouped.groups.keys())[0:5]) # Print the first 5 group names\n",
    "print(list(grouped.groups.values())[0:5]) # Print the first 5 group names\n",
    "\n",
    "\n",
    "# Now, pick one of those names to inspect\n",
    "# The name will be a tuple, e.g., (10, 10.0, 2.0, 0.35, 'EW')\n",
    "a_specific_group_name = list(grouped.groups.keys())[0] \n",
    "\n",
    "print(f\"\\n--- Data for the specific group: {a_specific_group_name} ---\")\n",
    "display(grouped.get_group(a_specific_group_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
