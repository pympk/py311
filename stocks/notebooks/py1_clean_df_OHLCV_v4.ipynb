{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# from pathlib import Path\n",
    "\n",
    "# # Notebook cell\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# # Get root directory (assuming notebook is in root/notebooks/)\n",
    "# NOTEBOOK_DIR = Path.cwd()\n",
    "# ROOT_DIR = NOTEBOOK_DIR.parent if NOTEBOOK_DIR.name == 'notebooks' else NOTEBOOK_DIR\n",
    "\n",
    "# # Add src directory to Python path\n",
    "# sys.path.append(str(ROOT_DIR / 'src'))\n",
    "\n",
    "# # Verify path\n",
    "# print(f\"Python will look in these locations:\\n{sys.path}\")\n",
    "\n",
    "\n",
    "# # --- Execute the processor ---\n",
    "# import utils\n",
    "\n",
    "\n",
    "# SOURCE_PATH, DEST_PATH = utils.main_processor(\n",
    "#     data_dir='..\\data',  # search project ..\\data    \n",
    "#     downloads_dir=None,  # None searchs Downloads dir, '' omits search\n",
    "#     downloads_limit=50,  # search the first 10 files\n",
    "#     clean_name_override=None,  # override filename\n",
    "#     start_file_pattern='df_OHLCV_', # search for files starting with 'df_'\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_str: 2025-04-01\n",
      "DOWNLOAD_DIR: C:\\Users\\ping\\Downloads\n",
      "DEST_DIR: ..\\data\n",
      "\n",
      "source_path: C:\\Users\\ping\\Downloads\\df_OHLCV_2025-04-01.parquet\n",
      "dest_path: ..\\data\\df_OHLCV_2025-04-01_clean.parquet\n"
     ]
    }
   ],
   "source": [
    "# process_files.py\n",
    "from config import date_str, DOWNLOAD_DIR, DEST_DIR\n",
    "from pathlib import Path  # Better path handling\n",
    "\n",
    "print(f\"date_str: {date_str}\")\n",
    "print(f\"DOWNLOAD_DIR: {DOWNLOAD_DIR}\")\n",
    "print(f\"DEST_DIR: {DEST_DIR}\\n\")\n",
    "\n",
    "# Build paths\n",
    "source_path = Path(DOWNLOAD_DIR) / f'df_OHLCV_{date_str}.parquet'\n",
    "dest_path = Path(DEST_DIR) / f'df_OHLCV_{date_str}_clean.parquet'\n",
    "\n",
    "print(f\"source_path: {source_path}\")\n",
    "print(f\"dest_path: {dest_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Raw Data Overview]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Open</th>\n",
       "      <th>Adj High</th>\n",
       "      <th>Adj Low</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Symbol</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">TBIL</th>\n",
       "      <th>2025-04-01</th>\n",
       "      <td>49.84</td>\n",
       "      <td>49.85</td>\n",
       "      <td>49.83</td>\n",
       "      <td>49.84</td>\n",
       "      <td>49.84</td>\n",
       "      <td>3609452</td>\n",
       "      <td>49.84</td>\n",
       "      <td>49.85</td>\n",
       "      <td>49.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-31</th>\n",
       "      <td>50.00</td>\n",
       "      <td>50.01</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.01</td>\n",
       "      <td>50.01</td>\n",
       "      <td>3381800</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.01</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-28</th>\n",
       "      <td>50.00</td>\n",
       "      <td>50.01</td>\n",
       "      <td>49.99</td>\n",
       "      <td>49.99</td>\n",
       "      <td>49.99</td>\n",
       "      <td>2638500</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.01</td>\n",
       "      <td>49.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-27</th>\n",
       "      <td>49.98</td>\n",
       "      <td>49.99</td>\n",
       "      <td>49.98</td>\n",
       "      <td>49.99</td>\n",
       "      <td>49.99</td>\n",
       "      <td>2561300</td>\n",
       "      <td>49.98</td>\n",
       "      <td>49.99</td>\n",
       "      <td>49.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-26</th>\n",
       "      <td>49.97</td>\n",
       "      <td>49.98</td>\n",
       "      <td>49.97</td>\n",
       "      <td>49.98</td>\n",
       "      <td>49.98</td>\n",
       "      <td>1540200</td>\n",
       "      <td>49.97</td>\n",
       "      <td>49.98</td>\n",
       "      <td>49.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Open   High    Low  Close  Adj Close   Volume  Adj Open  \\\n",
       "Symbol Date                                                                   \n",
       "TBIL   2025-04-01  49.84  49.85  49.83  49.84      49.84  3609452     49.84   \n",
       "       2025-03-31  50.00  50.01  50.00  50.01      50.01  3381800     50.00   \n",
       "       2025-03-28  50.00  50.01  49.99  49.99      49.99  2638500     50.00   \n",
       "       2025-03-27  49.98  49.99  49.98  49.99      49.99  2561300     49.98   \n",
       "       2025-03-26  49.97  49.98  49.97  49.98      49.98  1540200     49.97   \n",
       "\n",
       "                   Adj High  Adj Low  \n",
       "Symbol Date                           \n",
       "TBIL   2025-04-01     49.85    49.83  \n",
       "       2025-03-31     50.01    50.00  \n",
       "       2025-03-28     50.01    49.99  \n",
       "       2025-03-27     49.99    49.98  \n",
       "       2025-03-26     49.98    49.97  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 389418 entries, ('TBIL', Timestamp('2025-04-01 00:00:00')) to ('IEI', Timestamp('2024-04-02 00:00:00'))\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   Open       389418 non-null  float64\n",
      " 1   High       389418 non-null  float64\n",
      " 2   Low        389418 non-null  float64\n",
      " 3   Close      389418 non-null  float64\n",
      " 4   Adj Close  389418 non-null  float64\n",
      " 5   Volume     389397 non-null  Int64  \n",
      " 6   Adj Open   389418 non-null  float64\n",
      " 7   Adj High   389418 non-null  float64\n",
      " 8   Adj Low    389418 non-null  float64\n",
      "dtypes: Int64(1), float64(8)\n",
      "memory usage: 28.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# --- Data Loading & Initial Inspection ---\n",
    "import pandas as pd\n",
    "\n",
    "# # Load raw data from pickle file\n",
    "# df = pd.read_pickle(source_path)\n",
    "\n",
    "df = pd.read_parquet(source_path, engine='pyarrow')\n",
    "\n",
    "# Display initial data structure\n",
    "print(\"[Raw Data Overview]\")\n",
    "display(df.head())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Original number of symbols: 1559\n",
      "Number of symbols after filtering: 1540\n",
      "Number of symbols filtered out: 19\n",
      "\n",
      "First 10 symbols that were filtered out:\n",
      "['BTC', 'VIK', 'WAY', 'TTAN', 'SAIL', 'VG', 'ZK', 'STRK', 'SFD', 'LTM']\n",
      "\n",
      "Example of dates for first filtered out symbol:\n",
      "\n",
      "Dates for BTC:\n",
      "DatetimeIndex(['2025-04-01', '2025-03-31', '2025-03-28', '2025-03-27',\n",
      "               '2025-03-26', '2025-03-25', '2025-03-24', '2025-03-21',\n",
      "               '2025-03-20', '2025-03-19',\n",
      "               ...\n",
      "               '2024-08-13', '2024-08-12', '2024-08-09', '2024-08-08',\n",
      "               '2024-08-07', '2024-08-06', '2024-08-05', '2024-08-02',\n",
      "               '2024-08-01', '2024-07-31'],\n",
      "              dtype='datetime64[ns]', name='Date', length=168, freq=None)\n",
      "\n",
      "Filtered DataFrame info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 386540 entries, ('TBIL', Timestamp('2025-04-01 00:00:00')) to ('IEI', Timestamp('2024-04-02 00:00:00'))\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   Open       386540 non-null  float64\n",
      " 1   High       386540 non-null  float64\n",
      " 2   Low        386540 non-null  float64\n",
      " 3   Close      386540 non-null  float64\n",
      " 4   Adj Close  386540 non-null  float64\n",
      " 5   Volume     386524 non-null  Int64  \n",
      " 6   Adj Open   386540 non-null  float64\n",
      " 7   Adj High   386540 non-null  float64\n",
      " 8   Adj Low    386540 non-null  float64\n",
      "dtypes: Int64(1), float64(8)\n",
      "memory usage: 28.4+ MB\n",
      "None\n",
      "\n",
      "[Cleaning Report]\n",
      "Removed 2 symbols with missing data: ['FER', 'FSEC']\n",
      "\n",
      "[Cleaned Data Structure]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 386038 entries, ('TBIL', Timestamp('2025-04-01 00:00:00')) to ('IEI', Timestamp('2024-04-02 00:00:00'))\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   Open       386038 non-null  float64\n",
      " 1   High       386038 non-null  float64\n",
      " 2   Low        386038 non-null  float64\n",
      " 3   Close      386038 non-null  float64\n",
      " 4   Adj Close  386038 non-null  float64\n",
      " 5   Volume     386038 non-null  Int64  \n",
      " 6   Adj Open   386038 non-null  float64\n",
      " 7   Adj High   386038 non-null  float64\n",
      " 8   Adj Low    386038 non-null  float64\n",
      "dtypes: Int64(1), float64(8)\n",
      "memory usage: 28.4+ MB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Notebook cell\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Get root directory (assuming notebook is in root/notebooks/)\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "ROOT_DIR = NOTEBOOK_DIR.parent if NOTEBOOK_DIR.name == 'notebooks' else NOTEBOOK_DIR\n",
    "\n",
    "# Add src directory to Python path\n",
    "sys.path.append(str(ROOT_DIR / 'src'))\n",
    "\n",
    "\n",
    "# --- Data Filtering & Cleaning ---\n",
    "import utils  # Custom utility functions\n",
    "\n",
    "# 1. Align dates across all symbols using SPY as reference\n",
    "df = utils.filter_df_dates_to_reference_symbol(df=df, reference_symbol='SPY')\n",
    "\n",
    "# 2. Remove symbols with missing data points\n",
    "df_clean, missing_symbols = utils.filter_symbols_with_missing_values(df)\n",
    "\n",
    "# Display cleaning results\n",
    "print(\"\\n[Cleaning Report]\")\n",
    "print(f\"Removed {len(missing_symbols)} symbols with missing data: {missing_symbols}\")\n",
    "print(\"\\n[Cleaned Data Structure]\")\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Save Successful] Cleaned data saved to:\n",
      "..\\data\\df_OHLCV_2025-04-01_clean.parquet\n"
     ]
    }
   ],
   "source": [
    "# --- Save Cleaned Data ---\n",
    "# # Save processed data to pickle file\n",
    "# df_clean.to_pickle(dest_path)\n",
    "\n",
    "# Using PyArrow (default, recommended for most cases)\n",
    "df_clean.to_parquet(dest_path, engine='pyarrow')\n",
    "print(f\"\\n[Save Successful] Cleaned data saved to:\\n{dest_path}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
