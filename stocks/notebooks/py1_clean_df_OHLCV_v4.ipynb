{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# from pathlib import Path\n",
    "\n",
    "# # Notebook cell\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# # Get root directory (assuming notebook is in root/notebooks/)\n",
    "# NOTEBOOK_DIR = Path.cwd()\n",
    "# ROOT_DIR = NOTEBOOK_DIR.parent if NOTEBOOK_DIR.name == 'notebooks' else NOTEBOOK_DIR\n",
    "\n",
    "# # Add src directory to Python path\n",
    "# sys.path.append(str(ROOT_DIR / 'src'))\n",
    "\n",
    "# # Verify path\n",
    "# print(f\"Python will look in these locations:\\n{sys.path}\")\n",
    "\n",
    "\n",
    "# # --- Execute the processor ---\n",
    "# import utils\n",
    "\n",
    "\n",
    "# SOURCE_PATH, DEST_PATH = utils.main_processor(\n",
    "#     data_dir='..\\data',  # search project ..\\data    \n",
    "#     downloads_dir=None,  # None searchs Downloads dir, '' omits search\n",
    "#     downloads_limit=50,  # search the first 10 files\n",
    "#     clean_name_override=None,  # override filename\n",
    "#     start_file_pattern='df_OHLCV_', # search for files starting with 'df_'\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_str: 2025-03-14\n",
      "DOWNLOAD_DIR: C:\\Users\\ping\\Downloads\n",
      "DEST_DIR: ..\\data\n",
      "\n",
      "source_path: C:\\Users\\ping\\Downloads\\df_OHLCV_2025-03-14.pkl\n",
      "dest_path: ..\\data\\df_OHLCV_2025-03-14_clean.pkl\n"
     ]
    }
   ],
   "source": [
    "# process_files.py\n",
    "from config import date_str, DOWNLOAD_DIR, DEST_DIR\n",
    "from pathlib import Path  # Better path handling\n",
    "\n",
    "print(f\"date_str: {date_str}\")\n",
    "print(f\"DOWNLOAD_DIR: {DOWNLOAD_DIR}\")\n",
    "print(f\"DEST_DIR: {DEST_DIR}\\n\")\n",
    "\n",
    "# Build paths\n",
    "source_path = Path(DOWNLOAD_DIR) / f'df_OHLCV_{date_str}.pkl'\n",
    "dest_path = Path(DEST_DIR) / f'df_OHLCV_{date_str}_clean.pkl'\n",
    "\n",
    "print(f\"source_path: {source_path}\")\n",
    "print(f\"dest_path: {dest_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Raw Data Overview]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Open</th>\n",
       "      <th>Adj High</th>\n",
       "      <th>Adj Low</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Symbol</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">UBS</th>\n",
       "      <th>2025-03-14</th>\n",
       "      <td>32.25</td>\n",
       "      <td>32.85</td>\n",
       "      <td>32.19</td>\n",
       "      <td>32.73</td>\n",
       "      <td>32.73</td>\n",
       "      <td>7312500</td>\n",
       "      <td>32.25</td>\n",
       "      <td>32.85</td>\n",
       "      <td>32.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-13</th>\n",
       "      <td>31.85</td>\n",
       "      <td>31.90</td>\n",
       "      <td>31.56</td>\n",
       "      <td>31.71</td>\n",
       "      <td>31.71</td>\n",
       "      <td>1876700</td>\n",
       "      <td>31.85</td>\n",
       "      <td>31.90</td>\n",
       "      <td>31.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-12</th>\n",
       "      <td>31.96</td>\n",
       "      <td>32.03</td>\n",
       "      <td>31.64</td>\n",
       "      <td>31.94</td>\n",
       "      <td>31.94</td>\n",
       "      <td>3057200</td>\n",
       "      <td>31.96</td>\n",
       "      <td>32.03</td>\n",
       "      <td>31.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-11</th>\n",
       "      <td>31.68</td>\n",
       "      <td>31.81</td>\n",
       "      <td>31.02</td>\n",
       "      <td>31.38</td>\n",
       "      <td>31.38</td>\n",
       "      <td>6007500</td>\n",
       "      <td>31.68</td>\n",
       "      <td>31.81</td>\n",
       "      <td>31.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-10</th>\n",
       "      <td>32.74</td>\n",
       "      <td>32.86</td>\n",
       "      <td>31.65</td>\n",
       "      <td>31.88</td>\n",
       "      <td>31.88</td>\n",
       "      <td>7367000</td>\n",
       "      <td>32.74</td>\n",
       "      <td>32.86</td>\n",
       "      <td>31.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Open   High    Low  Close  Adj Close   Volume  Adj Open  \\\n",
       "Symbol Date                                                                   \n",
       "UBS    2025-03-14  32.25  32.85  32.19  32.73      32.73  7312500     32.25   \n",
       "       2025-03-13  31.85  31.90  31.56  31.71      31.71  1876700     31.85   \n",
       "       2025-03-12  31.96  32.03  31.64  31.94      31.94  3057200     31.96   \n",
       "       2025-03-11  31.68  31.81  31.02  31.38      31.38  6007500     31.68   \n",
       "       2025-03-10  32.74  32.86  31.65  31.88      31.88  7367000     32.74   \n",
       "\n",
       "                   Adj High  Adj Low  \n",
       "Symbol Date                           \n",
       "UBS    2025-03-14     32.85    32.19  \n",
       "       2025-03-13     31.90    31.56  \n",
       "       2025-03-12     32.03    31.64  \n",
       "       2025-03-11     31.81    31.02  \n",
       "       2025-03-10     32.86    31.65  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 348198 entries, ('UBS', Timestamp('2025-03-14 00:00:00')) to ('SARO', Timestamp('2024-10-02 00:00:00'))\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   Open       348198 non-null  float64\n",
      " 1   High       348198 non-null  float64\n",
      " 2   Low        348198 non-null  float64\n",
      " 3   Close      348198 non-null  float64\n",
      " 4   Adj Close  348198 non-null  float64\n",
      " 5   Volume     348168 non-null  Int64  \n",
      " 6   Adj Open   348198 non-null  float64\n",
      " 7   Adj High   348198 non-null  float64\n",
      " 8   Adj Low    348198 non-null  float64\n",
      "dtypes: Int64(1), float64(8)\n",
      "memory usage: 25.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# --- Data Loading & Initial Inspection ---\n",
    "import pandas as pd\n",
    "\n",
    "# Load raw data from pickle file\n",
    "df = pd.read_pickle(source_path)\n",
    "\n",
    "# Display initial data structure\n",
    "print(\"[Raw Data Overview]\")\n",
    "display(df.head())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Original number of symbols: 1399\n",
      "Number of symbols after filtering: 1380\n",
      "Number of symbols filtered out: 19\n",
      "\n",
      "First 10 symbols that were filtered out:\n",
      "['ZK', 'SAIL', 'LTM', 'TTAN', 'TEM', 'SOLV', 'BTC', 'ULS', 'STRK', 'SW']\n",
      "\n",
      "Example of dates for first filtered out symbol:\n",
      "\n",
      "Dates for ZK:\n",
      "DatetimeIndex(['2025-03-14', '2025-03-13', '2025-03-12', '2025-03-11',\n",
      "               '2025-03-10', '2025-03-07', '2025-03-06', '2025-03-05',\n",
      "               '2025-03-04', '2025-03-03',\n",
      "               ...\n",
      "               '2024-05-23', '2024-05-22', '2024-05-21', '2024-05-20',\n",
      "               '2024-05-17', '2024-05-16', '2024-05-15', '2024-05-14',\n",
      "               '2024-05-13', '2024-05-10'],\n",
      "              dtype='datetime64[ns]', name='Date', length=211, freq=None)\n",
      "\n",
      "Filtered DataFrame info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 345000 entries, ('UBS', Timestamp('2025-03-14 00:00:00')) to ('PCVX', Timestamp('2024-03-15 00:00:00'))\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   Open       345000 non-null  float64\n",
      " 1   High       345000 non-null  float64\n",
      " 2   Low        345000 non-null  float64\n",
      " 3   Close      345000 non-null  float64\n",
      " 4   Adj Close  345000 non-null  float64\n",
      " 5   Volume     344975 non-null  Int64  \n",
      " 6   Adj Open   345000 non-null  float64\n",
      " 7   Adj High   345000 non-null  float64\n",
      " 8   Adj Low    345000 non-null  float64\n",
      "dtypes: Int64(1), float64(8)\n",
      "memory usage: 25.4+ MB\n",
      "None\n",
      "\n",
      "[Cleaning Report]\n",
      "Removed 1 symbols with missing data: ['FER']\n",
      "\n",
      "[Cleaned Data Structure]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 344750 entries, ('UBS', Timestamp('2025-03-14 00:00:00')) to ('PCVX', Timestamp('2024-03-15 00:00:00'))\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   Open       344750 non-null  float64\n",
      " 1   High       344750 non-null  float64\n",
      " 2   Low        344750 non-null  float64\n",
      " 3   Close      344750 non-null  float64\n",
      " 4   Adj Close  344750 non-null  float64\n",
      " 5   Volume     344750 non-null  Int64  \n",
      " 6   Adj Open   344750 non-null  float64\n",
      " 7   Adj High   344750 non-null  float64\n",
      " 8   Adj Low    344750 non-null  float64\n",
      "dtypes: Int64(1), float64(8)\n",
      "memory usage: 25.4+ MB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Notebook cell\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Get root directory (assuming notebook is in root/notebooks/)\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "ROOT_DIR = NOTEBOOK_DIR.parent if NOTEBOOK_DIR.name == 'notebooks' else NOTEBOOK_DIR\n",
    "\n",
    "# Add src directory to Python path\n",
    "sys.path.append(str(ROOT_DIR / 'src'))\n",
    "\n",
    "\n",
    "# --- Data Filtering & Cleaning ---\n",
    "import utils  # Custom utility functions\n",
    "\n",
    "# 1. Align dates across all symbols using SPY as reference\n",
    "df = utils.filter_df_dates_to_reference_symbol(df=df, reference_symbol='SPY')\n",
    "\n",
    "# 2. Remove symbols with missing data points\n",
    "df_clean, missing_symbols = utils.filter_symbols_with_missing_values(df)\n",
    "\n",
    "# Display cleaning results\n",
    "print(\"\\n[Cleaning Report]\")\n",
    "print(f\"Removed {len(missing_symbols)} symbols with missing data: {missing_symbols}\")\n",
    "print(\"\\n[Cleaned Data Structure]\")\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Save Successful] Cleaned data saved to:\n",
      "..\\data\\df_OHLCV_2025-03-14_clean.pkl\n"
     ]
    }
   ],
   "source": [
    "# --- Save Cleaned Data ---\n",
    "# Save processed data to pickle file\n",
    "df_clean.to_pickle(dest_path)\n",
    "print(f\"\\n[Save Successful] Cleaned data saved to:\\n{dest_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
