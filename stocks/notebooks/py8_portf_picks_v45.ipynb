{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Notebook cell\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Get root directory (assuming notebook is in root/notebooks/)\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "ROOT_DIR = NOTEBOOK_DIR.parent if NOTEBOOK_DIR.name == 'notebooks' else NOTEBOOK_DIR\n",
    "\n",
    "# Add src directory to Python path\n",
    "sys.path.append(str(ROOT_DIR / 'src'))\n",
    "\n",
    "# Verify path\n",
    "print(f\"Python will look in these locations:\\n{sys.path}\")\n",
    "\n",
    "\n",
    "# --- Execute the processor ---\n",
    "import utils\n",
    "from config import date_str, DOWNLOAD_DIR, DEST_DIR\n",
    "\n",
    "print(f'date_str: {date_str}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override date_str for testing\n",
    "# date_str = '2025-04-14'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Set pandas display options to show more columns and rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "# pd.set_option('display.max_rows', 10)       # Limit to 10 rows for readability\n",
    "pd.set_option('display.width', 1000)        # Let the display adjust to the window\n",
    "# pd.set_option('display.max_colwidth', None) # Show full content of each cell\n",
    "pd.set_option('display.max_rows', 200)\n",
    "# pd.set_option('display.width', 120)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zscore_df = pd.read_parquet(f'..\\data\\{date_str}_zscore_df.parquet', engine='pyarrow')\n",
    "cluster_stats_df = pd.read_parquet(f'..\\data\\{date_str}_cluster_stats_df.parquet', engine='pyarrow')\n",
    "detailed_clusters_df = pd.read_parquet(f'..\\data\\{date_str}_detailed_clusters_df.parquet', engine='pyarrow')\n",
    "df_data = pd.read_parquet(f'..\\data\\{date_str}_df_finviz_merged.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np # Will be used if we need to handle potential infinite values if any\n",
    "\n",
    "# --- IMPORTANT ---\n",
    "# Ensure your DataFrame is named df_data and contains the columns used below.\n",
    "# Example: (replace this with your actual data loading)\n",
    "# df_data = pd.read_csv('your_market_data.csv')\n",
    "\n",
    "# --- Data Cleaning (Optional but Recommended) ---\n",
    "# Replace potential infinite values with NaN\n",
    "df_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "# Use a copy to avoid modifying original if needed later\n",
    "df_plot = df_data.copy()\n",
    "\n",
    "# --- Font Size Definitions ---\n",
    "SCALE_FONTSIZE = 1.2  # Scale factor for font sizes\n",
    "TITLE_FONTSIZE = 18 * SCALE_FONTSIZE\n",
    "AXIS_LABEL_FONTSIZE = 14 * SCALE_FONTSIZE\n",
    "TICK_LABEL_FONTSIZE = 12 * SCALE_FONTSIZE\n",
    "LEGEND_FONTSIZE = 12 * SCALE_FONTSIZE\n",
    "SUPTITLE_FONTSIZE = 22 * SCALE_FONTSIZE\n",
    "\n",
    "# --- Visualization ---\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid') # Use a visually appealing style\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 14)) # Increased figure size slightly for larger text\n",
    "fig.suptitle('Visualizing Market Bifurcation Indicators (Larger Text)', fontsize=SUPTITLE_FONTSIZE, y=1.03) # Adjusted y position slightly\n",
    "\n",
    "# 1. Histogram of Yearly Performance ('Perf Year %')\n",
    "sns.histplot(data=df_plot, x='Perf Year %', kde=True, ax=axes[0, 0], bins=50)\n",
    "axes[0, 0].set_title('Distribution of Yearly Performance (%)', fontsize=TITLE_FONTSIZE)\n",
    "axes[0, 0].set_xlabel('Perf Year %', fontsize=AXIS_LABEL_FONTSIZE)\n",
    "axes[0, 0].set_ylabel('Frequency', fontsize=AXIS_LABEL_FONTSIZE) # Added y-axis label\n",
    "axes[0, 0].tick_params(axis='both', which='major', labelsize=TICK_LABEL_FONTSIZE)\n",
    "median_val = df_plot['Perf Year %'].median()\n",
    "mean_val = df_plot['Perf Year %'].mean()\n",
    "axes[0, 0].axvline(median_val, color='red', linestyle='--', label=f'Median: {median_val:.2f}%')\n",
    "axes[0, 0].axvline(mean_val, color='orange', linestyle=':', label=f'Mean: {mean_val:.2f}%')\n",
    "axes[0, 0].legend(fontsize=LEGEND_FONTSIZE)\n",
    "\n",
    "# 2. Histogram of Normalized Volatility ('ATR/Price %')\n",
    "sns.histplot(data=df_plot, x='ATR/Price %', kde=True, ax=axes[0, 1], bins=50)\n",
    "axes[0, 1].set_title('Distribution of Normalized Daily Volatility (ATR/Price %)', fontsize=TITLE_FONTSIZE)\n",
    "axes[0, 1].set_xlabel('ATR/Price %', fontsize=AXIS_LABEL_FONTSIZE)\n",
    "axes[0, 1].set_ylabel('Frequency', fontsize=AXIS_LABEL_FONTSIZE) # Added y-axis label\n",
    "axes[0, 1].tick_params(axis='both', which='major', labelsize=TICK_LABEL_FONTSIZE)\n",
    "median_val = df_plot['ATR/Price %'].median()\n",
    "mean_val = df_plot['ATR/Price %'].mean()\n",
    "axes[0, 1].axvline(median_val, color='red', linestyle='--', label=f'Median: {median_val:.2f}%')\n",
    "axes[0, 1].axvline(mean_val, color='orange', linestyle=':', label=f'Mean: {mean_val:.2f}%')\n",
    "axes[0, 1].legend(fontsize=LEGEND_FONTSIZE)\n",
    "\n",
    "# 3. Scatter Plot: Yearly Performance vs. Normalized Volatility\n",
    "sns.scatterplot(data=df_plot, x='ATR/Price %', y='Perf Year %', ax=axes[1, 0], alpha=0.5, s=25) # Slightly larger points\n",
    "axes[1, 0].set_title('Yearly Performance vs. Daily Volatility', fontsize=TITLE_FONTSIZE)\n",
    "axes[1, 0].set_xlabel('ATR/Price % (Daily Volatility)', fontsize=AXIS_LABEL_FONTSIZE)\n",
    "axes[1, 0].set_ylabel('Perf Year %', fontsize=AXIS_LABEL_FONTSIZE)\n",
    "axes[1, 0].tick_params(axis='both', which='major', labelsize=TICK_LABEL_FONTSIZE)\n",
    "\n",
    "# 4. Scatter Plot: Yearly Performance vs. Distance from 200-Day MA\n",
    "sns.scatterplot(data=df_plot, x='SMA200 %', y='Perf Year %', ax=axes[1, 1], alpha=0.5, s=25) # Slightly larger points\n",
    "axes[1, 1].set_title('Yearly Performance vs. Position Relative to 200-Day MA', fontsize=TITLE_FONTSIZE)\n",
    "axes[1, 1].set_xlabel('Price vs SMA200 (%)', fontsize=AXIS_LABEL_FONTSIZE)\n",
    "axes[1, 1].set_ylabel('Perf Year %', fontsize=AXIS_LABEL_FONTSIZE)\n",
    "axes[1, 1].tick_params(axis='both', which='major', labelsize=TICK_LABEL_FONTSIZE)\n",
    "axes[1, 1].axvline(0, color='grey', linestyle='--') # Line at 0% (on the SMA200)\n",
    "axes[1, 1].axhline(0, color='grey', linestyle='--') # Line at 0% Perf Year\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.97]) # Adjust layout slightly for suptitle\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_clusters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd # Assuming pandas is used \n",
    "\n",
    "# def select_stocks_from_clusters(cluster_stats_df, detailed_clusters_df,\n",
    "#                                 select_top_n_clusters=3, max_selection_per_cluster=5,\n",
    "#                                 min_cluster_size=5, penalty_IntraCluster_Corr=0.3,\n",
    "#                                 date_str=date_str,\n",
    "#                                 min_raw_score=None, # <-- Added argument\n",
    "#                                 min_risk_adj_score=None): # <-- Added argument\n",
    "#     \"\"\"\n",
    "#     Pipeline to select stocks from better performing clusters, with optional score thresholds.\n",
    "\n",
    "#     Parameters:\n",
    "#     - cluster_stats_df: DataFrame with cluster statistics.\n",
    "#     - detailed_clusters_df: DataFrame with detailed cluster information including\n",
    "#                             'Ticker', 'Cluster_ID', 'Raw_Score', 'Risk_Adj_Score', etc.\n",
    "#     - select_top_n_clusters: int, Number of top clusters to select (default=3).\n",
    "#     - max_selection_per_cluster: int, Max number of stocks to select from each cluster (default=5).\n",
    "#     - min_cluster_size: int, Minimum size for a cluster to be considered (default=5).\n",
    "#     - penalty_IntraCluster_Corr: float, Penalty weight for intra-cluster correlation in\n",
    "#                                      composite score (default=0.3).\n",
    "#     - date_str: str, Date string for tracking/parameter storage.\n",
    "#     - min_raw_score: float, optional (default=None)\n",
    "#         Minimum Raw_Score required for a stock to be considered for selection.\n",
    "#         If None, no threshold is applied based on Raw_Score.\n",
    "#     - min_risk_adj_score: float, optional (default=None)\n",
    "#         Minimum Risk_Adj_Score required for a stock to be considered for selection.\n",
    "#         If None, no threshold is applied based on Risk_Adj_Score.\n",
    "\n",
    "#     Returns:\n",
    "#     - dict: A dictionary containing:\n",
    "#         - 'selected_top_n_cluster_ids': List of top selected cluster IDs.\n",
    "#         - 'selected_stocks': DataFrame of selected stocks.\n",
    "#         - 'cluster_performance': DataFrame of selected cluster metrics.\n",
    "#         - 'parameters': Dictionary of the input parameters used.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Store input parameters\n",
    "#     parameters = {\n",
    "#         'date_str': date_str,\n",
    "#         'select_top_n_clusters': select_top_n_clusters,\n",
    "#         'max_selection_per_cluster': max_selection_per_cluster,\n",
    "#         'min_cluster_size': min_cluster_size,\n",
    "#         'min_raw_score': min_raw_score,         # <-- Stored parameter\n",
    "#         'min_risk_adj_score': min_risk_adj_score, # <-- Stored parameter\n",
    "#         'penalty_IntraCluster_Corr': penalty_IntraCluster_Corr,\n",
    "#     }\n",
    "    \n",
    "#     # ===== 1. Filter and Rank Clusters =====\n",
    "#     qualified_clusters = cluster_stats_df[cluster_stats_df['Size'] >= min_cluster_size].copy()\n",
    "#     if qualified_clusters.empty:\n",
    "#         print(f\"Warning: No clusters met the minimum size criteria ({min_cluster_size}).\")\n",
    "#         return {\n",
    "#             'selected_stocks': pd.DataFrame(),\n",
    "#             'cluster_performance': pd.DataFrame(),\n",
    "#             'parameters': parameters\n",
    "#         }\n",
    "\n",
    "#     qualified_clusters['Composite_Cluster_Score'] = (\n",
    "#         (1 - penalty_IntraCluster_Corr) * qualified_clusters['Avg_Raw_Score'] +\n",
    "#         penalty_IntraCluster_Corr * (1 - qualified_clusters['Avg_IntraCluster_Corr'])\n",
    "#     )\n",
    "#     ranked_clusters = qualified_clusters.sort_values('Composite_Cluster_Score', ascending=False)\n",
    "#     selected_clusters = ranked_clusters.head(select_top_n_clusters)\n",
    "#     cluster_ids = selected_clusters['Cluster_ID'].tolist()\n",
    "\n",
    "#     if not cluster_ids:\n",
    "#         print(\"Warning: No clusters were selected based on ranking.\")\n",
    "#         return {\n",
    "#             'selected_stocks': pd.DataFrame(),\n",
    "#             'cluster_performance': selected_clusters, # Return empty selected clusters df\n",
    "#             'parameters': parameters\n",
    "#         }\n",
    "\n",
    "\n",
    "#     # ===== 2. Select Stocks from Each Cluster =====\n",
    "#     selected_stocks_list = []\n",
    "#     for cluster_id in cluster_ids:\n",
    "#         # Get all stocks for the current cluster\n",
    "#         cluster_stocks = detailed_clusters_df[detailed_clusters_df['Cluster_ID'] == cluster_id].copy()\n",
    "\n",
    "#         # ===> Apply Threshold Filters <===\n",
    "#         if min_raw_score is not None:\n",
    "#             cluster_stocks = cluster_stocks[cluster_stocks['Raw_Score'] >= min_raw_score]\n",
    "#         if min_risk_adj_score is not None:\n",
    "#             cluster_stocks = cluster_stocks[cluster_stocks['Risk_Adj_Score'] >= min_risk_adj_score]\n",
    "#         # ===> End of Added Filters <===\n",
    "\n",
    "#         # Proceed only if stocks remain after filtering\n",
    "#         if len(cluster_stocks) > 0:\n",
    "#             # Sort remaining stocks by Risk_Adj_Score and select top N\n",
    "#             top_stocks = cluster_stocks.sort_values('Risk_Adj_Score', ascending=False).head(max_selection_per_cluster)\n",
    "\n",
    "#             # Add cluster-level metrics to the selected stock rows\n",
    "#             cluster_metrics = selected_clusters[selected_clusters['Cluster_ID'] == cluster_id].iloc[0]\n",
    "#             for col in ['Composite_Cluster_Score', 'Avg_IntraCluster_Corr', 'Avg_Volatility',\n",
    "#                       'Avg_Raw_Score', 'Avg_Risk_Adj_Score', 'Size']: # Added Size for context\n",
    "#                 # Use .get() for safety if a column might be missing\n",
    "#                 top_stocks[f'Cluster_{col}'] = cluster_metrics.get(col, None)\n",
    "#             selected_stocks_list.append(top_stocks)\n",
    "\n",
    "#     # Consolidate selected stocks\n",
    "#     if selected_stocks_list:\n",
    "#         selected_stocks = pd.concat(selected_stocks_list)\n",
    "#         # Recalculate weights based on the final selection\n",
    "#         if selected_stocks['Risk_Adj_Score'].sum() != 0:\n",
    "#              selected_stocks['Weight'] = (selected_stocks['Risk_Adj_Score'] /\n",
    "#                                           selected_stocks['Risk_Adj_Score'].sum())\n",
    "#         else:\n",
    "#              # Handle case where all selected scores are zero (unlikely but possible)\n",
    "#              selected_stocks['Weight'] = 1 / len(selected_stocks) if len(selected_stocks) > 0 else 0\n",
    "\n",
    "#         selected_stocks = selected_stocks.sort_values(['Cluster_ID', 'Risk_Adj_Score'],\n",
    "#                                                     ascending=[True, False])\n",
    "#     else:\n",
    "#         selected_stocks = pd.DataFrame()\n",
    "#         print(\"Warning: No stocks met selection criteria (including score thresholds if applied).\")\n",
    "\n",
    "\n",
    "#     # ===== 3. Prepare Enhanced Output Reports =====\n",
    "#     cluster_performance = selected_clusters.copy()\n",
    "#     # Calculate how many stocks were actually selected per cluster after filtering\n",
    "#     cluster_performance['Stocks_Selected'] = cluster_performance['Cluster_ID'].apply(\n",
    "#         lambda x: len(selected_stocks[selected_stocks['Cluster_ID'] == x]) if not selected_stocks.empty else 0)\n",
    "\n",
    "#     if not selected_stocks.empty:\n",
    "#          # Ensure Avg_IntraCluster_Corr exists before calculating diversification\n",
    "#         if 'Avg_IntraCluster_Corr' in cluster_performance.columns:\n",
    "#              cluster_performance['Intra_Cluster_Diversification'] = 1 - cluster_performance['Avg_IntraCluster_Corr']\n",
    "#         else:\n",
    "#              cluster_performance['Intra_Cluster_Diversification'] = pd.NA # Or None\n",
    "#     else:\n",
    "#       # Handle case where selected_stocks is empty\n",
    "#         cluster_performance['Intra_Cluster_Diversification'] = pd.NA # Or None\n",
    "\n",
    "#     # ===> Package results and parameters\n",
    "#     results_bundle = {\n",
    "#         'selected_top_n_cluster_ids': cluster_ids,\n",
    "#         'selected_stocks': selected_stocks,\n",
    "#         'cluster_performance': cluster_performance,\n",
    "#         'parameters': parameters\n",
    "#     }\n",
    "\n",
    "#     return results_bundle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from typing import Dict, Any\n",
    "\n",
    "# def print_stock_selection_report(output: Dict[str, Any]) -> None:\n",
    "#     \"\"\"\n",
    "#     Prints a detailed report summarizing the results of the stock selection process,\n",
    "#     extracting all necessary information from the output dictionary.\n",
    "\n",
    "#     Args:\n",
    "#         output (Dict[str, Any]): The dictionary returned by the\n",
    "#                                  select_stocks_from_clusters function, containing:\n",
    "#                                  - 'selected_stocks': DataFrame of selected stocks.\n",
    "#                                  - 'cluster_performance': DataFrame of selected cluster metrics.\n",
    "#                                 #  - 'parameters': Dictionary of the input parameters used.\n",
    "#                                 #  - 'cluster_stats_df': Original cluster stats DataFrame.\n",
    "#                                 #  - 'detailed_clusters_df': Original detailed clusters DataFrame.\n",
    "#     Returns:\n",
    "#         None: This function prints output to the console.\n",
    "#     \"\"\"\n",
    "#     # Extract data from the output dictionary using .get() for safety\n",
    "#     selected_stocks = output.get('selected_stocks', pd.DataFrame())\n",
    "#     cluster_performance = output.get('cluster_performance', pd.DataFrame())\n",
    "#     used_params = output.get('parameters', {})\n",
    "#     # Extract the input DataFrames needed for the report\n",
    "#     # cluster_stats_df = output.get('input_cluster_stats_df') # Might be None\n",
    "#     cluster_stats_df = output.get('cluster_stats_df') # Might be None\n",
    "#     # detailed_clusters_df = output.get('input_detailed_clusters_df') # Might be None\n",
    "#     detailed_clusters_df = output.get('detailed_clusters_df') # Might be None\n",
    "\n",
    "#     # --- Start of Original Code Block (adapted) ---\n",
    "\n",
    "#     print(\"\\n=== CLUSTER SELECTION CRITERIA ===\")\n",
    "#     print(\"* Using Composite_Cluster_Score (balancing Raw Score and diversification) for cluster ranking.\")\n",
    "#     print(\"* Using Risk_Adj_Score for stock selection within clusters.\")\n",
    "\n",
    "#     num_selected_clusters = len(cluster_performance) if not cluster_performance.empty else 0\n",
    "#     # Use the extracted cluster_stats_df\n",
    "#     total_clusters = len(cluster_stats_df) if cluster_stats_df is not None and not cluster_stats_df.empty else 'N/A'\n",
    "\n",
    "#     print(f\"* Selected top {num_selected_clusters} clusters from {total_clusters} total initial clusters.\") # Adjusted wording slightly\n",
    "#     print(f\"* Selection Criteria:\")\n",
    "#     if used_params:\n",
    "#         for key, value in used_params.items():\n",
    "#             # Avoid printing the large input dataframes stored in parameters if they were added there too\n",
    "#             if not isinstance(value, pd.DataFrame):\n",
    "#                  print(f\"    {key}: {value}\")\n",
    "#     else:\n",
    "#         print(\"    Parameters not available.\")\n",
    "\n",
    "\n",
    "#     if not cluster_performance.empty:\n",
    "#         print(\"\\n=== SELECTED CLUSTERS (RANKED BY COMPOSITE SCORE) ===\")\n",
    "#         display_cols_exist = [col for col in [\n",
    "#                                 'Cluster_ID', 'Size', 'Avg_Raw_Score', 'Avg_Risk_Adj_Score',\n",
    "#                                 'Avg_IntraCluster_Corr', 'Avg_Volatility', 'Composite_Cluster_Score',\n",
    "#                                 'Stocks_Selected', 'Intra_Cluster_Diversification']\n",
    "#                               if col in cluster_performance.columns]\n",
    "#         print(cluster_performance[display_cols_exist].sort_values('Composite_Cluster_Score', ascending=False).to_string(index=False))\n",
    "\n",
    "#         # Print top 8 stocks by Raw_Score for each selected cluster\n",
    "#         # Check if detailed_clusters_df was successfully extracted\n",
    "#         if detailed_clusters_df is not None and not detailed_clusters_df.empty:\n",
    "#             print(\"\\n=== TOP STOCKS BY RAW SCORE PER SELECTED CLUSTER ===\")\n",
    "#             print(\"\"\"* Volatility is the standard deviation of daily returns over the past 250 trading days (example context).\n",
    "# * Note: The stocks below are shown ranked by Raw_Score for analysis,\n",
    "# *       but actual selection within the cluster was based on Risk_Adj_Score.\"\"\")\n",
    "\n",
    "#             for cluster_id in cluster_performance['Cluster_ID']:\n",
    "#                  cluster_stocks = detailed_clusters_df[detailed_clusters_df['Cluster_ID'] == cluster_id]\n",
    "#                  if not cluster_stocks.empty:\n",
    "#                     required_cols = ['Ticker', 'Raw_Score', 'Risk_Adj_Score', 'Volatility']\n",
    "#                     if all(col in cluster_stocks.columns for col in required_cols):\n",
    "#                         top_raw = cluster_stocks.nlargest(8, 'Raw_Score')[required_cols]\n",
    "\n",
    "#                         print(f\"\\nCluster {cluster_id} - Top 8 by Raw Score:\")\n",
    "#                         print(top_raw.to_string(index=False))\n",
    "#                         cluster_avg_raw = cluster_performance.loc[cluster_performance['Cluster_ID'] == cluster_id, 'Avg_Raw_Score'].values\n",
    "#                         cluster_avg_risk = cluster_performance.loc[cluster_performance['Cluster_ID'] == cluster_id, 'Avg_Risk_Adj_Score'].values\n",
    "#                         if len(cluster_avg_raw) > 0: print(f\"Cluster Avg Raw Score: {cluster_avg_raw[0]:.2f}\")\n",
    "#                         if len(cluster_avg_risk) > 0: print(f\"Cluster Avg Risk Adj Score: {cluster_avg_risk[0]:.2f}\")\n",
    "#                     else:\n",
    "#                         print(f\"\\nCluster {cluster_id} - Missing required columns in detailed_clusters_df to show top stocks.\")\n",
    "#                  else:\n",
    "#                      print(f\"\\nCluster {cluster_id} - No stocks found in detailed_clusters_df for this cluster.\")\n",
    "#         else:\n",
    "#             print(\"\\n=== TOP STOCKS BY RAW SCORE PER SELECTED CLUSTER ===\")\n",
    "#             print(\"Skipping - Detailed cluster information ('input_detailed_clusters_df') not found in the output dictionary.\")\n",
    "\n",
    "#     else:\n",
    "#         print(\"\\n=== SELECTED CLUSTERS ===\")\n",
    "#         print(\"No clusters were selected based on the criteria.\")\n",
    "\n",
    "\n",
    "#     print(f\"\\n=== FINAL SELECTED STOCKS (FILTERED & WEIGHTED) ===\")\n",
    "#     if not selected_stocks.empty:\n",
    "#         print(\"* Stocks actually selected based on Risk_Adj_Score (and optional thresholds) within each cluster.\")\n",
    "#         print(\"* Position weights assigned based on Risk_Adj_Score within the final selected portfolio.\")\n",
    "\n",
    "#         desired_cols = ['Cluster_ID', 'Ticker', 'Raw_Score', 'Risk_Adj_Score',\n",
    "#                         'Volatility', 'Weight',\n",
    "#                         'Cluster_Avg_Raw_Score', 'Cluster_Avg_Risk_Adj_Score']\n",
    "#         available_cols = [col for col in desired_cols if col in selected_stocks.columns]\n",
    "#         print(selected_stocks[available_cols].sort_values(['Cluster_ID', 'Risk_Adj_Score'],\n",
    "#                                                         ascending=[True, False]).to_string(index=False))\n",
    "\n",
    "#         print(\"\\n=== PORTFOLIO SUMMARY ===\")\n",
    "#         print(f\"Total Stocks Selected: {len(selected_stocks)}\")\n",
    "#         print(f\"Average Raw Score: {selected_stocks.get('Raw_Score', pd.Series(dtype=float)).mean():.2f}\")\n",
    "#         print(f\"Average Risk-Adjusted Score: {selected_stocks.get('Risk_Adj_Score', pd.Series(dtype=float)).mean():.2f}\")\n",
    "#         print(f\"Average Volatility: {selected_stocks.get('Volatility', pd.Series(dtype=float)).mean():.2f}\")\n",
    "#         print(f\"Total Weight (should be close to 1.0): {selected_stocks.get('Weight', pd.Series(dtype=float)).sum():.4f}\")\n",
    "#         print(\"\\nCluster Distribution:\")\n",
    "#         print(selected_stocks['Cluster_ID'].value_counts().to_string())\n",
    "#     else:\n",
    "#         print(\"No stocks were selected after applying all filters and criteria.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fixed Parameters ---\n",
    "select_top_n_clusters = 10\n",
    "max_selection_per_cluster = 2\n",
    "min_cluster_size = 3  # prevent extreme high risk adj scores\n",
    "penalty_IntraCluster_Corr = 0\n",
    "min_raw_score = 2.0 \n",
    "min_risk_adj_score = 100.0 \n",
    "\n",
    "output = utils.select_stocks_from_clusters(\n",
    "    cluster_stats_df=cluster_stats_df,\n",
    "    detailed_clusters_df=detailed_clusters_df,\n",
    "    select_top_n_clusters=select_top_n_clusters,\n",
    "    max_selection_per_cluster=max_selection_per_cluster,\n",
    "    min_cluster_size=min_cluster_size,\n",
    "    penalty_IntraCluster_Corr=penalty_IntraCluster_Corr,\n",
    "    min_raw_score=min_raw_score,\n",
    "    min_risk_adj_score=min_risk_adj_score,\n",
    "    date_str=date_str # Pass the date\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Import pandas if you're expecting DataFrames/Series\n",
    "\n",
    "print(\"--- Printing Keys and Values in output dictionary ---\")\n",
    "for key, value in output.items():\n",
    "    print(f\"Key: {key}\")\n",
    "    if isinstance(value, (pd.DataFrame, pd.Series)):\n",
    "        print(f\"Value (first 5 rows/elements):\\n{value.head()}\\n\")\n",
    "    elif isinstance(value, dict):\n",
    "        print(f\"Value (is a dictionary):\\n{value}\\n\")\n",
    "    else:\n",
    "        print(f\"Value:\\n{value}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_top_n_cluster_ids= output['selected_top_n_cluster_ids']\n",
    "print(f'selected_top_{select_top_n_clusters}_cluster_ids: {selected_top_n_cluster_ids}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io # Needed for capturing string output if needed\n",
    "\n",
    "print(f'====== Clusters picked by select_stocks_from_clusters ======')\n",
    "\n",
    "# --- Parameters ---\n",
    "num_clusters_to_process = 10\n",
    "n_rows_per_cluster = 5\n",
    "sort_column = 'Risk_Adj_Score'\n",
    "ascending_sort = False\n",
    "# --- End Parameters ---\n",
    "\n",
    "\n",
    "# 1. Select only the first 'num_clusters_to_process' from the full list\n",
    "if num_clusters_to_process <= 0:\n",
    "    print(\"Number of clusters to process must be positive.\")\n",
    "    clusters_to_process = []\n",
    "elif num_clusters_to_process >= len(selected_top_n_cluster_ids):\n",
    "     print(f\"Processing all {len(selected_top_n_cluster_ids)} clusters from the list.\")\n",
    "     clusters_to_process = selected_top_n_cluster_ids\n",
    "else:\n",
    "    clusters_to_process = selected_top_n_cluster_ids[:num_clusters_to_process]\n",
    "    print(f\"Processing the first {num_clusters_to_process} clusters: {clusters_to_process}\")\n",
    "\n",
    "\n",
    "# Proceed only if there are clusters to process\n",
    "if clusters_to_process:\n",
    "\n",
    "    # 2. Filter the DataFrame\n",
    "    filtered_df = detailed_clusters_df[\n",
    "        detailed_clusters_df['Cluster_ID'].isin(clusters_to_process)\n",
    "    ].copy()\n",
    "\n",
    "    if filtered_df.empty:\n",
    "        print(f\"\\nNo rows found for the selected Cluster_IDs: {clusters_to_process}\")\n",
    "    else:\n",
    "        # 3. Convert to ordered categorical\n",
    "        filtered_df['Cluster_ID'] = pd.Categorical(\n",
    "            filtered_df['Cluster_ID'],\n",
    "            categories=clusters_to_process,\n",
    "            ordered=True\n",
    "        )\n",
    "\n",
    "        # --- Method 1: Sort then Head ---\n",
    "        # print(\"\\n--- Method 1: Sort then Head ---\")\n",
    "        sorted_df = filtered_df.sort_values(\n",
    "            by=['Cluster_ID', sort_column],\n",
    "            ascending=[True, ascending_sort]\n",
    "        )\n",
    "        top_n_per_cluster_df = sorted_df.groupby(\n",
    "            'Cluster_ID',\n",
    "            observed=True,\n",
    "            group_keys=False\n",
    "        ).head(n_rows_per_cluster)\n",
    "\n",
    "        print(f\"\\nTop {n_rows_per_cluster} Rows per Cluster (for first {num_clusters_to_process} clusters: {clusters_to_process})\")\n",
    "        print(f\"Sorted by '{sort_column}' (Ascending={ascending_sort}) within each cluster\")\n",
    "\n",
    "        # --- REVISED PRINTING SECTION V2: Format Once, Print Line-by-Line ---\n",
    "        if top_n_per_cluster_df.empty:\n",
    "            print(\"No data to display after filtering and selection.\")\n",
    "        else:\n",
    "            # 1. Get the entire formatted string WITH index\n",
    "            # Use index=True so we can potentially match rows if needed,\n",
    "            # but primarily to let pandas calculate all column widths correctly.\n",
    "            full_output_string = top_n_per_cluster_df.to_string(index=True)\n",
    "\n",
    "            # 2. Split into lines\n",
    "            lines = full_output_string.splitlines() # Use splitlines() to handle different line endings\n",
    "\n",
    "            # 3. Print the header line\n",
    "            print(lines[0])\n",
    "\n",
    "            last_cluster_id = None\n",
    "            # 4. Iterate through the *DataFrame rows* alongside the formatted lines\n",
    "            # We use range(len(...)) to easily access the corresponding line index\n",
    "            for i in range(len(top_n_per_cluster_df)):\n",
    "                # Get the actual Cluster_ID from the DataFrame row\n",
    "                current_cluster_id = top_n_per_cluster_df.iloc[i]['Cluster_ID']\n",
    "\n",
    "                # Check if cluster ID has changed\n",
    "                if last_cluster_id is not None and current_cluster_id != last_cluster_id:\n",
    "                    print(f'-'*83) # Print separator\n",
    "\n",
    "                # Print the corresponding pre-formatted line (data starts at lines[1])\n",
    "                print(lines[i + 1])\n",
    "\n",
    "                # Update the tracker\n",
    "                last_cluster_id = current_cluster_id\n",
    "        # --- END REVISED PRINTING SECTION V2 ---\n",
    "\n",
    "else:\n",
    "     print(\"\\nNo clusters selected for processing based on 'num_clusters_to_process'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def plot_cluster_statistics(cluster_stats_df, selected_cluster_ids, highlight_color='green', figsize=(12, 16)):\n",
    "    \"\"\"\n",
    "    Generates and displays a 5-panel plot visualizing various cluster statistics.\n",
    "\n",
    "    Args:\n",
    "        cluster_stats_df (pd.DataFrame): DataFrame containing cluster statistics.\n",
    "                                         Must include columns: 'Cluster_ID',\n",
    "                                         'Avg_Risk_Adj_Score', 'Avg_Raw_Score',\n",
    "                                         'Avg_IntraCluster_Corr', 'Avg_Volatility', 'Size'.\n",
    "        selected_cluster_ids (list or set): A collection of Cluster_IDs to highlight\n",
    "                                            on the plots.\n",
    "        highlight_color (str, optional): The color used to highlight the bars\n",
    "                                         corresponding to selected_cluster_ids.\n",
    "                                         Defaults to 'green'.\n",
    "        figsize (tuple, optional): The figure size for the plot.\n",
    "                                   Defaults to (12, 16).\n",
    "    \"\"\"\n",
    "    # Ensure Cluster_ID is suitable for indexing/lookup if it's not already\n",
    "    # (e.g., if it came from clustering that starts at 1 instead of 0)\n",
    "    # This assumes cluster IDs are sequential integers starting near 0.\n",
    "    cluster_ids = cluster_stats_df['Cluster_ID'].values\n",
    "\n",
    "    # --- Define constants and styles inside the function ---\n",
    "    HIGHLIGHT_COLOR = highlight_color\n",
    "    major_grid_style = {'color': 'lightgray', 'linestyle': '--', 'linewidth': 0.6}\n",
    "    minor_x_grid_style = {'color': 'gray', 'linestyle': '-', 'linewidth': 0.8}\n",
    "\n",
    "    # --- Define nested helper functions ---\n",
    "    def create_bars(ax, x, y, color, highlight_ids):\n",
    "        \"\"\"Creates bars, highlighting specific IDs.\"\"\"\n",
    "        # Ensure highlight_ids is a set for efficient lookup\n",
    "        highlight_set = set(highlight_ids)\n",
    "        bar_colors = [HIGHLIGHT_COLOR if cl_id in highlight_set else color for cl_id in x]\n",
    "        bars = ax.bar(x, y, color=bar_colors, width=0.8)\n",
    "        return bars\n",
    "\n",
    "    def configure_axis(ax, title, ylabel, show_xlabel=True):\n",
    "        \"\"\"Applies common configuration to an axis.\"\"\"\n",
    "        ax.set_title(title)\n",
    "        ax.set_ylabel(ylabel)\n",
    "        if show_xlabel:\n",
    "             ax.set_xlabel('Cluster_ID')\n",
    "\n",
    "        # Gridlines\n",
    "        ax.yaxis.grid(True, **major_grid_style)\n",
    "        ax.xaxis.grid(True, which='major', **major_grid_style)\n",
    "        ax.xaxis.set_minor_locator(mticker.MultipleLocator(5))\n",
    "        ax.xaxis.grid(True, which='minor', **minor_x_grid_style)\n",
    "        ax.tick_params(axis='x', which='minor', bottom=False)\n",
    "\n",
    "    # --- Create Figure and Axes ---\n",
    "    fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(5, 1, figsize=figsize)\n",
    "    fig.suptitle('Cluster Statistics Analysis', fontsize=16)\n",
    "\n",
    "    # --- Plotting ---\n",
    "\n",
    "    # Plot 1: Average Risk-Adjusted Score\n",
    "    create_bars(ax1, cluster_ids, cluster_stats_df['Avg_Risk_Adj_Score'],\n",
    "                'skyblue', selected_cluster_ids)\n",
    "    configure_axis(ax1, 'Average Risk-Adjusted Scores by Cluster', 'Average Risk-Adj Score')\n",
    "\n",
    "    # Plot 2: Average Raw Score\n",
    "    create_bars(ax2, cluster_ids, cluster_stats_df['Avg_Raw_Score'],\n",
    "                'lightgreen', selected_cluster_ids)\n",
    "    configure_axis(ax2, 'Average Raw Scores by Cluster', 'Average Raw Score')\n",
    "\n",
    "    # Plot 3: Average Correlation\n",
    "    create_bars(ax3, cluster_ids, cluster_stats_df['Avg_IntraCluster_Corr'],\n",
    "                'salmon', selected_cluster_ids)\n",
    "    configure_axis(ax3, 'Average Intra-Cluster Correlation', 'Average Correlation')\n",
    "\n",
    "    # Plot 4: Average Volatility\n",
    "    create_bars(ax4, cluster_ids, cluster_stats_df['Avg_Volatility'],\n",
    "                'gold', selected_cluster_ids)\n",
    "    configure_axis(ax4, 'Average Intra-Cluster Volatility', 'Average Volatility')\n",
    "\n",
    "    # Plot 5: Cluster Size\n",
    "    create_bars(ax5, cluster_ids, cluster_stats_df['Size'],\n",
    "                'orchid', selected_cluster_ids)\n",
    "    configure_axis(ax5, 'Cluster Sizes', 'Number of Members')\n",
    "\n",
    "    # --- Final Adjustments ---\n",
    "    num_clusters = len(cluster_ids)\n",
    "    # Adjust major ticks based on number of clusters for better readability\n",
    "    if num_clusters <= 20:\n",
    "        tick_step = 2\n",
    "    elif num_clusters <= 50:\n",
    "        tick_step = 5\n",
    "    else:\n",
    "        tick_step = 10 # Default for 60+\n",
    "\n",
    "    major_ticks = np.arange(min(cluster_ids), max(cluster_ids) + 1, tick_step)\n",
    "\n",
    "    # Apply x-axis limits and consistent major ticks to all axes\n",
    "    min_id = min(cluster_ids)\n",
    "    max_id = max(cluster_ids)\n",
    "    for ax in [ax1, ax2, ax3, ax4, ax5]:\n",
    "        ax.set_xlim(min_id - 0.5, max_id + 0.5)\n",
    "        ax.set_xticks(major_ticks)\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.96]) # Adjust rect for suptitle\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_stocks = output['selected_stocks']\n",
    "# selected_stocks = output['selected_stocks']\n",
    "selected_cluster_ids = selected_stocks['Cluster_ID'].unique()\n",
    "\n",
    "plot_cluster_statistics(cluster_stats_df, selected_cluster_ids, highlight_color='green', figsize=(12, 14))\n",
    "\n",
    "# You can also change the highlight color or figure size:\n",
    "# plot_cluster_statistics(cluster_stats_df, final_cluster_ids, highlight_color='red', figsize=(10, 14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.print_stock_selection_report(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
