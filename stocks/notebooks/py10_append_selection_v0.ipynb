{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_str: 2025-04-07\n",
      "SELECTED_STOCK_PATH: ../picks/2025-04-07_selected_stocks.parquet\n"
     ]
    }
   ],
   "source": [
    "# process_files.py\n",
    "from config import date_str, DOWNLOAD_DIR, DEST_DIR\n",
    "from pathlib import Path  # Better path handling\n",
    "\n",
    "# Build paths\n",
    "SELECTED_STOCK_PATH =f'../picks/{date_str}_selected_stocks.parquet'\n",
    "print(f'date_str: {date_str}')\n",
    "print(f'SELECTED_STOCK_PATH: {SELECTED_STOCK_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set pandas display options to show more columns and rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "# pd.set_option('display.max_rows', 10)       # Limit to 10 rows for readability\n",
    "pd.set_option('display.width', 1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected_stocks_n_weights (<class 'pandas.core.series.Series'>):\n",
      "Ticker\n",
      "BSCP    0.297630\n",
      "SHY     0.237228\n",
      "VGSH    0.233309\n",
      "SPTS    0.180986\n",
      "DG      0.013357\n",
      "UNH     0.013155\n",
      "BJ      0.010322\n",
      "CNC     0.007357\n",
      "KR      0.006657\n",
      "Name: Weight, dtype: float64\n",
      "\n",
      "selected_stocks_n_weights.index.name: Ticker\n",
      "\n",
      "date_str: 2025-04-07\n"
     ]
    }
   ],
   "source": [
    "selected_stocks = pd.read_parquet(SELECTED_STOCK_PATH)\n",
    "selected_stocks_n_weights = selected_stocks['Weight'].copy()\n",
    "\n",
    "print(f'selected_stocks_n_weights ({type(selected_stocks_n_weights)}):\\n{selected_stocks_n_weights}')\n",
    "print(f'\\nselected_stocks_n_weights.index.name: {selected_stocks_n_weights.index.name}')\n",
    "print(f'\\ndate_str: {date_str}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- process_daily_selections function remains the same ---\n",
    "def process_daily_selections(selected_stocks_n_weights: pd.Series, date_str: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Converts the daily stock selections Series into a standardized DataFrame format.\n",
    "    (Code is identical to the previous version)\n",
    "    \"\"\"\n",
    "    if not isinstance(selected_stocks_n_weights, pd.Series):\n",
    "        raise TypeError(\"selected_stocks_n_weights must be a pandas Series.\")\n",
    "\n",
    "    ticker_col_name = selected_stocks_n_weights.index.name if selected_stocks_n_weights.index.name else 'Ticker'\n",
    "    selected_stocks_n_weights.index.name = ticker_col_name\n",
    "\n",
    "    weight_col_name = selected_stocks_n_weights.name if selected_stocks_n_weights.name else 'Weight'\n",
    "\n",
    "    daily_df = selected_stocks_n_weights.reset_index()\n",
    "\n",
    "    rename_dict = {ticker_col_name: 'Ticker'}\n",
    "    if weight_col_name in daily_df.columns:\n",
    "         rename_dict[weight_col_name] = 'Weight'\n",
    "    elif 0 in daily_df.columns and len(daily_df.columns) == 2:\n",
    "         rename_dict[0] = 'Weight'\n",
    "    else:\n",
    "         print(f\"Warning: Could not automatically identify weight column. Columns found: {daily_df.columns}. Assuming the second column is Weight.\")\n",
    "         if len(daily_df.columns) > 1:\n",
    "             rename_dict[daily_df.columns[1]] = 'Weight'\n",
    "\n",
    "    daily_df = daily_df.rename(columns=rename_dict)\n",
    "    daily_df['Date'] = date_str\n",
    "    daily_df = daily_df[['Date', 'Ticker', 'Weight']]\n",
    "    return daily_df\n",
    "\n",
    "# --- update_tracking_file function remains the same ---\n",
    "def update_tracking_file(daily_data_df: pd.DataFrame, filename: str = \"stock_selections_history.csv\"):\n",
    "    \"\"\"\n",
    "    Loads historical selections, appends new daily data, and saves back to CSV.\n",
    "    Handles empty history file explicitly to avoid concat FutureWarning.\n",
    "    Saves data sorted chronologically by Date, then Ticker.\n",
    "    (Code is identical to the previous version)\n",
    "\n",
    "    Args:\n",
    "        daily_data_df: DataFrame containing the selections for the current day\n",
    "                       (should have columns 'Date', 'Ticker', 'Weight').\n",
    "        filename: The name of the CSV file to load from and save to.\n",
    "\n",
    "    Returns:\n",
    "        The updated DataFrame containing all historical and new selections\n",
    "        (sorted chronologically by Date, then Ticker).\n",
    "    \"\"\"\n",
    "    history_exists = os.path.exists(filename)\n",
    "    all_selections_df = pd.DataFrame(columns=['Date', 'Ticker', 'Weight']) # Initialize empty\n",
    "\n",
    "    if history_exists:\n",
    "        try:\n",
    "            all_selections_df = pd.read_csv(filename, parse_dates=['Date'])\n",
    "            print(f\"Loaded existing data from {filename}\")\n",
    "            if not all(col in all_selections_df.columns for col in ['Date', 'Ticker', 'Weight']):\n",
    "                 print(\"Warning: Loaded file missing expected columns. Treating as empty.\")\n",
    "                 all_selections_df = pd.DataFrame(columns=['Date', 'Ticker', 'Weight'])\n",
    "            elif all_selections_df.empty:\n",
    "                 print(f\"History file {filename} was empty.\")\n",
    "        except pd.errors.EmptyDataError:\n",
    "             print(f\"History file {filename} is empty. Starting fresh.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not load or parse {filename}. Error: {e}. Starting fresh.\")\n",
    "    else:\n",
    "        print(f\"History file {filename} not found. Creating a new one.\")\n",
    "\n",
    "    if all_selections_df.empty:\n",
    "        updated_df = daily_data_df.copy()\n",
    "        print(\"History was empty, using only new data.\")\n",
    "    else:\n",
    "        updated_df = pd.concat([all_selections_df, daily_data_df], ignore_index=True)\n",
    "        print(\"Appended new data to existing history.\")\n",
    "\n",
    "    try:\n",
    "        updated_df['Date'] = pd.to_datetime(updated_df['Date'])\n",
    "        updated_df['Weight'] = pd.to_numeric(updated_df['Weight'], errors='coerce')\n",
    "        updated_df['Ticker'] = updated_df['Ticker'].astype(str)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Error during data type conversion. Error: {e}\")\n",
    "\n",
    "    updated_df = updated_df.drop_duplicates(subset=['Date', 'Ticker'], keep='last')\n",
    "\n",
    "    # Sort data chronologically for saving\n",
    "    updated_df = updated_df.sort_values(by=['Date', 'Ticker']).reset_index(drop=True)\n",
    "    print(\"Data sorted chronologically (Date, Ticker) for saving.\")\n",
    "\n",
    "    try:\n",
    "        updated_df.to_csv(filename, index=False, date_format='%Y-%m-%d')\n",
    "        print(f\"Successfully updated and saved data to {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Could not save data to {filename}. Error: {e}\")\n",
    "\n",
    "    return updated_df # Return the chronologically sorted data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing data from stock_selections_history.csv\n",
      "Appended new data to existing history.\n",
      "Data sorted chronologically (Date, Ticker) for saving.\n",
      "Successfully updated and saved data to stock_selections_history.csv\n",
      "--------------------\n",
      "Current Full History DataFrame (Displayed with custom sort: Newest Date -> High Weight -> Ticker):\n",
      "         Date Ticker    Weight\n",
      "0  2025-04-07   BSCP  0.297630\n",
      "1  2025-04-07    SHY  0.237228\n",
      "2  2025-04-07   VGSH  0.233309\n",
      "3  2025-04-07   SPTS  0.180986\n",
      "4  2025-04-07     DG  0.013357\n",
      "5  2025-04-07    UNH  0.013155\n",
      "6  2025-04-07     BJ  0.010322\n",
      "7  2025-04-07    CNC  0.007357\n",
      "8  2025-04-07     KR  0.006657\n",
      "9  2025-04-04   FTSM  0.265842\n",
      "10 2025-04-04   JPST  0.152138\n",
      "11 2025-04-04   PULS  0.151988\n",
      "12 2025-04-04   SPTS  0.139178\n",
      "13 2025-04-04   VGSH  0.116990\n",
      "14 2025-04-04    BSV  0.088944\n",
      "15 2025-04-04    BLV  0.039118\n",
      "16 2025-04-04    TLH  0.023623\n",
      "17 2025-04-04   SPTL  0.022180\n",
      "18 2025-04-03    COR  0.141221\n",
      "19 2025-04-03    RSG  0.130864\n",
      "20 2025-04-03    MCK  0.128317\n",
      "21 2025-04-03    BRO  0.118636\n",
      "22 2025-04-03     WM  0.108731\n",
      "23 2025-04-03    HCA  0.106292\n",
      "24 2025-04-03    WCN  0.104093\n",
      "25 2025-04-03    MMC  0.089283\n",
      "26 2025-04-03   CCEP  0.072562\n",
      "27 2025-04-02   PHYS  0.180349\n",
      "28 2025-04-02     AM  0.117444\n",
      "29 2025-04-02    IGF  0.113616\n",
      "30 2025-04-02    GLD  0.106635\n",
      "31 2025-04-02    IAU  0.106491\n",
      "32 2025-04-02    OGE  0.104957\n",
      "33 2025-04-02    ATO  0.093588\n",
      "34 2025-04-02     NI  0.091604\n",
      "35 2025-04-02    EXE  0.085315\n",
      "36 2025-04-01   PHYS  0.182657\n",
      "37 2025-04-01    COR  0.166637\n",
      "38 2025-04-01    MCK  0.143199\n",
      "39 2025-04-01    IAU  0.111437\n",
      "40 2025-04-01   GLDM  0.111249\n",
      "41 2025-04-01    BRO  0.097893\n",
      "42 2025-04-01    MMC  0.097198\n",
      "43 2025-04-01   VRSN  0.089730\n"
     ]
    }
   ],
   "source": [
    "daily_df = process_daily_selections(selected_stocks_n_weights, date_str)\n",
    "# update_tracking_file returns the full data, sorted chronologically\n",
    "all_data_updated = update_tracking_file(daily_df, filename=\"stock_selections_history.csv\")\n",
    "\n",
    "print(\"-\" * 20)\n",
    "# --- MODIFICATION FOR DISPLAY ---\n",
    "print(\"Current Full History DataFrame (Displayed with custom sort: Newest Date -> High Weight -> Ticker):\")\n",
    "# Sort again just for this display\n",
    "display_sorted_df = all_data_updated.sort_values(\n",
    "    by=['Date', 'Weight', 'Ticker'],\n",
    "    ascending=[False, False, True] # Date descending, Weight descending, Ticker ascending\n",
    ").reset_index(drop=True)\n",
    "print(display_sorted_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
