{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HplHE-XnwHFz"
      },
      "source": [
        "===== TURN ON POWERTOY AWAKE to KEEP CONNECTION ALIVE =====\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BAeKmVzAEwE",
        "outputId": "f44a0603-6d25-4e13-8c15-85138e5fcd52"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzjWU0MyA8cT"
      },
      "source": [
        "===== SET download_to_PC and end_index ====="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LnCnXVOGAzi8"
      },
      "outputs": [],
      "source": [
        "# symbols: The string (or sequence) to slice.\n",
        "# start_index: Optional. The starting index of the slice. If None, defaults to 0.\n",
        "# end_index: Optional. The ending index of the slice (exclusive). If None, defaults to the end of the string.\n",
        "# step_value: Optional. The step value for the slice. If None, defaults to 1.\n",
        "\n",
        "# True download to PC, False download to Google Drive\n",
        "download_to_PC = True  # True download to PC\n",
        "# download_to_PC = False  # True download to Google Drive\n",
        "\n",
        "# Download all if end_iddex = None\n",
        "end_index = None\n",
        "end_index = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWX6sLNsmsCr",
        "outputId": "a3dabbf1-e196-482a-c2c8-63da3a538257"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "slice of symbols: symbols[slice(None, 3, None)]\n"
          ]
        }
      ],
      "source": [
        "start_index = None\n",
        "\n",
        "step_value = None\n",
        "slice_obj = slice(start_index, end_index, step_value)  # Create a slice object\n",
        "\n",
        "print(f'slice of symbols: symbols[{slice_obj}]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2xUTYT3wHF4",
        "outputId": "c1bccc50-3c35-44ef-835e-7144c72c090d"
      },
      "outputs": [],
      "source": [
        "! pip install fake-useragent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HTCD6Lo1wHF4"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from fake_useragent import UserAgent\n",
        "\n",
        "selector = '.styled-table-new'\n",
        "ua = UserAgent()  # Initialize UserAgent\n",
        "\n",
        "def download_table(url, selector):\n",
        "    \"\"\"\n",
        "    Downloads table data from a Yahoo Finance page with rate limiting.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Add a User-Agent header to mimic a browser\n",
        "        # headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}  # Example User-Agent\n",
        "        new_user_agent = ua.random\n",
        "        headers = {\"User-Agent\": new_user_agent}\n",
        "        response = requests.get(url, headers=headers)\n",
        "        response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        table_body = soup.select_one(selector)\n",
        "\n",
        "        if table_body is None:\n",
        "            print(f\"Error: Table body not found using selector: {selector}\")\n",
        "            return None\n",
        "\n",
        "        rows = table_body.find_all('tr')\n",
        "        if not rows:\n",
        "            print(\"Error: No rows found in the table.\")\n",
        "            return None\n",
        "\n",
        "        # Extract headers from the first row (th elements)\n",
        "        headers_list = [th.text.strip() for th in rows[0].find_all('th')]\n",
        "\n",
        "        data = []\n",
        "        for row in rows:\n",
        "            cells = row.find_all('td')\n",
        "            row_data = [cell.text.strip() for cell in cells]\n",
        "            if row_data:  # Only append if the row has data\n",
        "                data.append(row_data)\n",
        "\n",
        "        if not data:\n",
        "            print(\"Error: No data found in the table rows.\")\n",
        "            return None\n",
        "\n",
        "        df = pd.DataFrame(data, columns=headers_list)\n",
        "        return df\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error during request: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# all_stocks_and_etfs_columns\n",
        "# https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&r=721&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# all_etf_columns_sorted_by_AUM\n",
        "# https://finviz.com/screener.ashx?v=152&ft=4&o=-e.assetsundermanagement&c=0,1,2,3,4,5,129,75,14,130,131,31,84,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,70,80,83,60,61,63,64,67,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# all_stock_columns_sorted_by_market_cap\n",
        "# https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# url_all_columns = '0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105'\n",
        "# Dropped Dividend column 75, because 'Dividend' and 'Dividend %' used the same column name Dividend\n",
        "# and will cause an duplication column name error when trying to save the DataFrame\n",
        "url_all_columns = '0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,   14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xilLYhetMk-y"
      },
      "outputs": [],
      "source": [
        "url_mktcap ='https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c='\n",
        "# url_mktcap_all_columns = '0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66'\n",
        "url_mktcap_rows = ['&r=1', '&r=21', '&r=41', '&r=61', '&r=81', '&r=101', '&r=121', '&r=141', '&r=161', '&r=181', '&r=201', '&r=221', '&r=241', '&r=261', '&r=281', '&r=301', '&r=321', '&r=341', '&r=361', '&r=381', '&r=401', '&r=421', '&r=441', '&r=461', '&r=481', '&r=501', '&r=521', '&r=541', '&r=561', '&r=581', '&r=601', '&r=621', '&r=641', '&r=661', '&r=681', '&r=701', '&r=721', '&r=741', '&r=761', '&r=781', '&r=801', '&r=821', '&r=841', '&r=861', '&r=881', '&r=901', '&r=921', '&r=941', '&r=961', '&r=981', '&r=1001', '&r=1021','&r=1041','&r=1061','&r=1081','&r=1101','&r=1121','&r=1141',]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "url_etfs ='https://finviz.com/screener.ashx?v=152&ft=4&o=-e.assetsundermanagement&c='\n",
        "# url_etfs_all_columns = '0,1,2,3,4,5,129,75,14,130,131,31,84,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,70,80,83,60,61,63,64,67,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105'\n",
        "url_etfs_rows = ['&r=1', '&r=21', '&r=41', '&r=61', '&r=81', '&r=101', '&r=121', '&r=141', '&r=161', '&r=181', '&r=201', '&r=221', '&r=241', '&r=261', '&r=281', '&r=301', '&r=321', '&r=341', '&r=361', '&r=381']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYhnaEoxwHF6",
        "outputId": "def62974-d424-427e-e6b1-f8e8257a0f65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of urls: 58\n",
            "First 3 urls:\n",
            "['https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=1', 'https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=21', 'https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=41']\n"
          ]
        }
      ],
      "source": [
        "urls_mktcap = []\n",
        "\n",
        "for _rows in url_mktcap_rows:\n",
        "    # _url = url_mktcap + url_mktcap_all_columns + _rows\n",
        "    _url = url_mktcap + url_all_columns + _rows    \n",
        "    urls_mktcap.append(_url)\n",
        "\n",
        "print(f'Total number of urls: {len(urls_mktcap)}')\n",
        "print(f'First 3 urls:\\n{urls_mktcap[0:3]}')  # Print the length of the list of url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of urls: 20\n",
            "First 3 urls:\n",
            "['https://finviz.com/screener.ashx?v=152&ft=4&o=-e.assetsundermanagement&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=1', 'https://finviz.com/screener.ashx?v=152&ft=4&o=-e.assetsundermanagement&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=21', 'https://finviz.com/screener.ashx?v=152&ft=4&o=-e.assetsundermanagement&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=41']\n"
          ]
        }
      ],
      "source": [
        "urls_etfs = []\n",
        "\n",
        "for _rows in url_etfs_rows:\n",
        "    # _url = url_etfs + url_etfs_all_columns + _rows\n",
        "    _url = url_etfs + url_all_columns + _rows    \n",
        "    urls_etfs.append(_url)\n",
        "\n",
        "print(f'Total number of urls: {len(urls_etfs)}')\n",
        "print(f'First 3 urls:\\n{urls_etfs[0:3]}')  # Print the length of the list of url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWfH7PLrwHF7",
        "outputId": "23b628b5-cf9d-4b51-9f38-c55e3044c1d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len(shuffled_urls): 78\n",
            "shuffled_urls[0:10]\n",
            "https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=761\n",
            "https://finviz.com/screener.ashx?v=152&ft=4&o=-e.assetsundermanagement&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=81\n",
            "https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=1101\n",
            "https://finviz.com/screener.ashx?v=152&ft=4&o=-e.assetsundermanagement&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=321\n",
            "https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=601\n",
            "https://finviz.com/screener.ashx?v=152&ft=4&o=-e.assetsundermanagement&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=281\n",
            "https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=501\n",
            "https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=221\n",
            "https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=1001\n",
            "https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=841\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "urls =  urls_mktcap + urls_etfs\n",
        "shuffled_urls = random.sample(urls, len(urls))\n",
        "print(f'len(shuffled_urls): {len(shuffled_urls)}')\n",
        "print(f'shuffled_urls[0:10]')\n",
        "for url in shuffled_urls[0:10]:\n",
        "    print(f'{url}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyA3q6n9wHF7"
      },
      "outputs": [],
      "source": [
        "# test_urls = [\n",
        "#   'https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,3,4,6,14,42,43,44,45,46,47,48,49,50,51,52,53,54,57,58,59,67,65,66,103,100,109,120,121,122&r=1',\n",
        "#   'https://finviz.com/screener.ashx?v=152&ft=4&o=-e.assetsundermanagement&c=0,1,2,3,4,6,14,42,43,44,45,46,47,48,49,50,51,52,53,54,57,58,59,67,65,66,103,100,109,120,121,122&r=101',\n",
        "#   'https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,3,4,6,14,42,43,44,45,46,47,48,49,50,51,52,53,54,57,58,59,67,65,66,103,100,109,120,121,122&r=601',\n",
        "#   ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=761. Sleeping for 2.77 seconds.  Processed 1 / 78 urls\n",
            "Downloading https://finviz.com/screener.ashx?v=152&ft=4&o=-e.assetsundermanagement&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=81. Sleeping for 3.24 seconds.  Processed 2 / 78 urls\n",
            "Downloading https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,79,3,4,5,129,6,7,8,9,10,11,12,13,73,74,75,14,130,131,15,16,77,17,18,19,20,21,23,22,132,133,82,78,127,128,24,25,85,26,27,28,29,30,31,84,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,134,125,126,59,68,70,80,83,76,60,61,62,63,64,67,69,81,86,87,88,65,66,103,100,107,108,109,112,113,114,115,116,117,120,121,122,105&r=1101. Sleeping for 2.09 seconds.  Processed 3 / 78 urls\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "\n",
        "total_urls_to_download = len(shuffled_urls)\n",
        "\n",
        "df = pd.DataFrame()  # Initialized an empty DataFrame\n",
        "processed_count = 0\n",
        "\n",
        "# for url in test_urls:\n",
        "# for url in shuffled_urls[0:3]:\n",
        "for url in shuffled_urls[slice_obj]:\n",
        "    # Introduce a delay between requests (adjust as needed)\n",
        "    delay_seconds = random.uniform(2, 4.5)  # Sleep between 2 and 5 seconds\n",
        "    # print(f\"Downloading {symbol}. Sleeping for {delay_seconds:.2f} seconds...\")\n",
        "    processed_count += 1\n",
        "    print(f\"Downloading {url}. Sleeping for {delay_seconds:.2f} seconds.  Processed {processed_count} / {total_urls_to_download} urls\")\n",
        "    time.sleep(delay_seconds)\n",
        "\n",
        "    df_temp = download_table(url, selector)\n",
        "\n",
        "    if df_temp is not None:\n",
        "        df = pd.concat([df, df_temp], ignore_index=True)\n",
        "    else:\n",
        "        print(f\"Failed to download data for {url}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJt8zyFewHF8",
        "outputId": "85e82614-71d3-4a4c-924d-5c4fadf07117"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import pytz\n",
        "\n",
        "pst = pytz.timezone('America/Los_Angeles')  # or 'US/Pacific'\n",
        "current_date_pst = datetime.datetime.now(pst).strftime('%Y-%m-%d')\n",
        "\n",
        "# Save the DataFrame as a Parquet file\n",
        "df_finviz_filename = f\"df_finviz_{current_date_pst}_stocks.parquet\"\n",
        "\n",
        "print(f\"df_finviz_filename: {df_finviz_filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3agEKFzAMX95"
      },
      "outputs": [],
      "source": [
        "import pyarrow\n",
        "\n",
        "df.to_parquet(df_finviz_filename, engine='pyarrow', compression='zstd')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "aw1Sw3G-W419",
        "outputId": "060d3759-bed9-45d5-dac7-0c10d83117d9"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQtYfIR5F9y4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6_jh9e9WE_8",
        "outputId": "da0f981d-319d-4def-aa25-7c5f971cc9b8"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/drive/MyDrive/stocks/df_finviz_tickers.pkl'  # Run in Colab\n",
        "\n",
        "df_tickers = df[['Ticker']]\n",
        "\n",
        "# Save the DataFrame to a pickle file in the specified location\n",
        "df_tickers.to_pickle(file_path)\n",
        "print(f\"{len(df_tickers)} tickers saved to: {file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78db6cfhuLqT"
      },
      "outputs": [],
      "source": [
        "# ======================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VcTdIE3uLqT",
        "outputId": "60b577c5-8caa-4f2b-e785-535cc9c083d9"
      },
      "outputs": [],
      "source": [
        "# symbols: The string (or sequence) to slice.\n",
        "# start_index: Optional. The starting index of the slice. If None, defaults to 0.\n",
        "# end_index: Optional. The ending index of the slice (exclusive). If None, defaults to the end of the string.\n",
        "# step_value: Optional. The step value for the slice. If None, defaults to 1.\n",
        "\n",
        "# start_index = None\n",
        "# end_index = None\n",
        "# end_index = 3\n",
        "\n",
        "step_value = None\n",
        "slice_obj = slice(start_index, end_index, step_value)  # Create a slice object\n",
        "\n",
        "print(f'slice of symbols: symbols[{slice_obj}]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZmvZTdHuLqT"
      },
      "outputs": [],
      "source": [
        "from fake_useragent import UserAgent\n",
        "\n",
        "ua = UserAgent()  # Initialize UserAgent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAuxwFy7uLqU"
      },
      "outputs": [],
      "source": [
        "# selector = \"#nimbus-app > section > section > section > article > div.container > div.table-container.yf-1jecxey > table > tbody\"\n",
        "selector = \"#nimbus-app > section > section > section > article > div.container > div.table-container.yf-1jecxey\"\n",
        "col_names = ['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVZTyrX6uLqU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def read_stock_symbols(dir_path, symbols_stocks_file, symbols_ETFs_file):\n",
        "    \"\"\"\n",
        "    Reads stock and ETF symbols from text files in the specified directory and returns them in two separate lists.\n",
        "\n",
        "    Args:\n",
        "        dir_path (str): The directory path where the symbol files are located.\n",
        "        symbols_stocks_file (str): The name of the file containing stock symbols.\n",
        "        symbols_ETFs_file (str): The name of the file containing ETF symbols.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing two lists: (stock_symbols, etf_symbols).  Returns ([], [])\n",
        "               if any error occurs during file reading.\n",
        "    \"\"\"\n",
        "\n",
        "    stock_symbols = []\n",
        "    etf_symbols = []\n",
        "\n",
        "    try:\n",
        "        # Read stock symbols\n",
        "        with open(os.path.join(dir_path, symbols_stocks_file), 'r') as f:\n",
        "            stock_symbols = [line.strip() for line in f]\n",
        "\n",
        "        # Read ETF symbols\n",
        "        with open(os.path.join(dir_path, symbols_ETFs_file), 'r') as f:\n",
        "            etf_symbols = [line.strip() for line in f]\n",
        "\n",
        "        return stock_symbols, etf_symbols\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: One or more files not found in directory: {dir_path}\")\n",
        "        return [], []\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return [], []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I79YQzfFuLqV"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import random  # For a bit of randomness in the sleep time\n",
        "\n",
        "def download_yahoo_finance_table(url, selector):\n",
        "    \"\"\"\n",
        "    Downloads table data from a Yahoo Finance page with rate limiting.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Add a User-Agent header to mimic a browser\n",
        "        # headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}  # Example User-Agent\n",
        "        new_user_agent = ua.random\n",
        "        headers = {\"User-Agent\": new_user_agent}\n",
        "\n",
        "        response = requests.get(url, headers=headers)\n",
        "        response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
        "\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        table_body = soup.select_one(selector)\n",
        "\n",
        "        if table_body is None:\n",
        "            print(f\"Error: Table body not found using selector: {selector}\")\n",
        "            return None\n",
        "\n",
        "        rows = table_body.find_all('tr')\n",
        "        if not rows:\n",
        "            print(\"Error: No rows found in the table.\")\n",
        "            return None\n",
        "\n",
        "        # Extract headers from the first row (th elements)\n",
        "        headers_list = [th.text.strip() for th in rows[0].find_all('th')]\n",
        "\n",
        "        data = []\n",
        "        for row in rows:\n",
        "            cells = row.find_all('td')\n",
        "            row_data = [cell.text.strip() for cell in cells]\n",
        "            if row_data:  # Only append if the row has data\n",
        "                data.append(row_data)\n",
        "\n",
        "        if not data:\n",
        "            print(\"Error: No data found in the table rows.\")\n",
        "            return None\n",
        "\n",
        "        df = pd.DataFrame(data, columns=headers_list)\n",
        "        return df\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error during request: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkcX6TakuLqV"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import pytz\n",
        "\n",
        "def get_current_pst_time():\n",
        "  \"\"\"\n",
        "  Returns the current time in Pacific Standard Time (PST).\n",
        "\n",
        "  Returns:\n",
        "    A string representing the current time in PST, formatted as\n",
        "    \"YYYY-MM-DD HH:MM:SS\".\n",
        "  \"\"\"\n",
        "\n",
        "  pst_timezone = pytz.timezone('America/Los_Angeles')  # Get the PST timezone\n",
        "  pst_now = datetime.datetime.now(pst_timezone)  # Get the current time in PST\n",
        "\n",
        "  return pst_now.strftime(\"%Y-%m-%d %H:%M:%S\")  # Format the time as a string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gInEy7rtuLqV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def convert_df_data_types(df):\n",
        "    \"\"\"\n",
        "    Cleans and converts a Pandas DataFrame with a MultiIndex to the specified data types.\n",
        "\n",
        "    Args:\n",
        "        df: The input Pandas DataFrame.  Assumes a MultiIndex with stock ticker (str) and date (str).\n",
        "            Assumes columns 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume' as objects.\n",
        "\n",
        "    Returns:\n",
        "        A Pandas DataFrame with the correct data types.\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert the second level of the MultiIndex to datetime\n",
        "    try:\n",
        "        df.index = pd.MultiIndex.from_tuples([(i[0], pd.to_datetime(i[1])) for i in df.index], names=df.index.names)\n",
        "    except ValueError as e:\n",
        "        print(f\"Error converting MultiIndex to datetime: {e}\")\n",
        "        return df  # Or handle the error differently, e.g., raise it\n",
        "\n",
        "    # Convert columns to appropriate data types\n",
        "    columns_to_convert = ['Open', 'High', 'Low', 'Close', 'Adj Close']\n",
        "    for col in columns_to_convert:\n",
        "        try:\n",
        "            # Remove commas *before* attempting conversion. CRITICAL.\n",
        "            df[col] = df[col].str.replace(',', '', regex=False)  # Remove commas first\n",
        "            df[col] = df[col].astype(float)\n",
        "        except ValueError as e:\n",
        "            print(f\"Error converting column '{col}' to float: {e}\")\n",
        "            return df #skip this column and return the original df\n",
        "\n",
        "    try:\n",
        "        # Handle '-' values in 'Volume' BEFORE removing commas\n",
        "        df['Volume'] = df['Volume'].replace('-', np.nan)\n",
        "        df['Volume'] = df['Volume'].str.replace(',', '', regex=False).astype(float).astype('Int64') # Use Int64 to store NaN\n",
        "    except ValueError as e:\n",
        "        print(f\"Error converting column 'Volume' to int64: {e}\")\n",
        "        return df\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHvVY-VhuLqV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def adjust_prices(df):\n",
        "    \"\"\"\n",
        "    Adjusts Open, High, Low, and Close prices using Adj Close to account for splits and dividends.\n",
        "\n",
        "    Args:\n",
        "        df: Pandas DataFrame with 'Open', 'High', 'Low', 'Close', and 'Adj Close' columns.\n",
        "            Assumes MultiIndex with stock ticker and datetime.\n",
        "\n",
        "    Returns:\n",
        "        Pandas DataFrame with adjusted 'Open', 'High', and 'Low' prices.\n",
        "    \"\"\"\n",
        "\n",
        "    # Calculate the adjustment ratio\n",
        "    df['adjustment_ratio'] = df['Adj Close'] / df['Close']\n",
        "\n",
        "    # Adjust Open, High, and Low prices\n",
        "    df['Adj Open'] = df['Open'] * df['adjustment_ratio']\n",
        "    df['Adj High'] = df['High'] * df['adjustment_ratio']\n",
        "    df['Adj Low'] = df['Low'] * df['adjustment_ratio']\n",
        "\n",
        "\n",
        "    # Optionally, drop the adjustment_ratio column if you don't need it\n",
        "    df = df.drop('adjustment_ratio', axis=1)  # axis=1 to drop the column\n",
        "\n",
        "    return df\n",
        "\n",
        "# Example Usage (assuming 'df' is your cleaned DataFrame)\n",
        "# df_adjusted = adjust_prices(df.copy())  # Create a copy\n",
        "# print(df_adjusted.head())\n",
        "# print(df_adjusted.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnDeGAN7uLqW",
        "outputId": "1deb74c5-846a-4821-c4e7-e729ce192b56"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/drive/MyDrive/stocks/df_finviz_tickers.pkl'  # Run in Colab\n",
        "\n",
        "loaded_df = pd.read_pickle(file_path)\n",
        "symbols = loaded_df['Ticker'].tolist()\n",
        "print(f\"symbols (len = {len(symbols)}):\")\n",
        "print(symbols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xZ2jju1uLqW",
        "outputId": "2fa49162-9c71-4e46-ddfd-9380cb78286b"
      },
      "outputs": [],
      "source": [
        "symbols_to_download = symbols[slice_obj]\n",
        "\n",
        "# symbols_to_download = slice_string(symbols, symbol_start, symbol_end, symbol_step)  # Adjust the slice as needed\n",
        "total_symbols_to_download = len(symbols_to_download)\n",
        "processed_count = 0\n",
        "\n",
        "print(f'symbols_to_download: symbols[{slice_obj}]')\n",
        "print(f'total_symbols_to_download: {total_symbols_to_download}')\n",
        "print(f'processed_count: {processed_count}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q52YTHcquLqW",
        "outputId": "8d6f2ed7-93d5-434b-9f30-41bd70131e75"
      },
      "outputs": [],
      "source": [
        "current_pst_time = get_current_pst_time()\n",
        "print(f\"Start OHLCV download at PST time: {current_pst_time}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ro6O4nGuLqW",
        "outputId": "12efff59-ff2e-457a-d256-ea6de4ac3749"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame()  # Initialized an empty DataFrame\n",
        "\n",
        "for symbol in symbols_to_download:\n",
        "    url = f\"https://finance.yahoo.com/quote/{symbol}/history/\"\n",
        "    # Introduce a delay between requests (adjust as needed)\n",
        "    delay_seconds = random.uniform(2, 4.5)  # Sleep between 2 and 5 seconds\n",
        "    # print(f\"Downloading {symbol}. Sleeping for {delay_seconds:.2f} seconds...\")\n",
        "    processed_count += 1\n",
        "    print(f\"Downloading {symbol}. Sleeping for {delay_seconds:.2f} seconds.  Processed {processed_count} / {total_symbols_to_download} symbols.\")\n",
        "    time.sleep(delay_seconds)\n",
        "\n",
        "    df_temp = download_yahoo_finance_table(url, selector)\n",
        "\n",
        "    if df_temp is not None:\n",
        "        df_temp.columns = col_names # Ensure the columns are what is expected\n",
        "\n",
        "        df_temp.set_index('Date', inplace=True) # Set Date as Index\n",
        "        # Create MultiIndex\n",
        "        df_temp.index = pd.MultiIndex.from_product([[symbol], df_temp.index], names=['Symbol', 'Date'])\n",
        "\n",
        "        df = pd.concat([df, df_temp])  # Append to the combined DataFrame\n",
        "\n",
        "    else:\n",
        "        print(f\"Failed to download data for {symbol}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekzZn5ahuLqW",
        "outputId": "4c5795b8-f5b3-465b-f3e9-dd29d890c374"
      },
      "outputs": [],
      "source": [
        "current_pst_time = get_current_pst_time()\n",
        "print(f\"End OHLCV download at PST time: {current_pst_time}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "nW2J6txeuLqX",
        "outputId": "24ffccdc-2684-4dbf-b833-28b4692a5ae4"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5elcgkAsuLqX",
        "outputId": "baebf554-f284-4d71-8243-4e87520193e9"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ed0R2tQduLqX",
        "outputId": "9640ec47-b270-4806-f7d7-3e30a5b19692"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import pytz\n",
        "\n",
        "pst = pytz.timezone('America/Los_Angeles')  # or 'US/Pacific'\n",
        "current_date_pst = datetime.datetime.now(pst).strftime('%Y-%m-%d')\n",
        "\n",
        "df_OHLCV_filename = f\"df_OHLCV_{current_date_pst}_stocks.parquet\"\n",
        "\n",
        "print(f\"df_OHLCV_filename: {df_OHLCV_filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cWwmLvyuLqc",
        "outputId": "f4158e8c-cfce-4a78-d466-9d6ca38abd93"
      },
      "outputs": [],
      "source": [
        "# Drop rows with any NaN values\n",
        "df_dropna = df.dropna()\n",
        "df_dropna.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqENdn0huLqc",
        "outputId": "284e96d9-edc1-4afa-b3aa-ed5f594a63f4"
      },
      "outputs": [],
      "source": [
        "df_converted = convert_df_data_types(df_dropna.copy())  # Create a copy to avoid modifying the original\n",
        "df_converted.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEi6efHUuLqd",
        "outputId": "cc2cf2c2-f752-437d-bd3d-7d038fe905ba"
      },
      "outputs": [],
      "source": [
        "df_adjusted = adjust_prices(df_converted.copy())  # Create a copy\n",
        "df_adjusted.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWQqc08yqnfk"
      },
      "outputs": [],
      "source": [
        "df_adjusted.to_parquet(df_OHLCV_filename, engine='pyarrow', compression='zstd')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "bb6tONh4uLqd",
        "outputId": "4d9ea177-3458-496b-980c-9dbe0d67b390"
      },
      "outputs": [],
      "source": [
        "df_adjusted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "zvZEbfwqiS0Z",
        "outputId": "5803e72f-9bcf-46d5-e600-9c8724e8bb7d"
      },
      "outputs": [],
      "source": [
        "# Create a ZIP file\n",
        "zip_filename = current_date_pst + '_finviz_OHLCV.zip'\n",
        "zip_filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SjosRxFlcwW"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "# from google.colab import files\n",
        "\n",
        "# Example: List of files to download\n",
        "file_list = [df_finviz_filename, df_OHLCV_filename]\n",
        "\n",
        "# Check if files exist before adding to the zip archive\n",
        "with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "    for file in file_list:\n",
        "        if os.path.exists(file):\n",
        "            zipf.write(file)\n",
        "        else:\n",
        "            print(f\"Warning: File not found: {file}. Skipping.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XvKKrhq-7UGk",
        "outputId": "dafe8cae-03f6-42d1-bf2f-c98fe7365e2b"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "if download_to_PC:\n",
        "  # Download the ZIP file (only 1 prompt)\n",
        "  if os.path.exists(zip_filename):\n",
        "      files.download(zip_filename)\n",
        "      print(f\"File '{zip_filename}' dowloaded to PC\")\n",
        "  else:\n",
        "      print(f\"Error: Zip file not created: {zip_filename}\")\n",
        "\n",
        "else:\n",
        "  destination_path = '/content/drive/MyDrive/stocks/'\n",
        "\n",
        "  # Construct the full path to the destination file\n",
        "  destination_file = os.path.join(destination_path, zip_filename)\n",
        "\n",
        "  # Use shutil.copy2 to preserve metadata (like timestamps)\n",
        "  try:\n",
        "      shutil.copy2(zip_filename, destination_file)\n",
        "      print(f\"File '{zip_filename}' downloaded to '{destination_file}'\")\n",
        "  except FileNotFoundError:\n",
        "      print(f\"Error: The file '{zip_filename}' was not found.\")\n",
        "  except Exception as e:\n",
        "      print(f\"An error occurred during the copy operation: {e}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gD4Ira3CdUo"
      },
      "outputs": [],
      "source": [
        "# # prompt: calculate the daily return of each ticker in df_adjusted. note the date index in df_adjusted is in reverse order\n",
        "\n",
        "# # THIS CALCULATAION IS CORRECT --- Calculate daily returns, handling the reversed date index\n",
        "# df_returns = df_adjusted['Adj Close'].pct_change(periods=-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjbtUIlQf9SQ"
      },
      "outputs": [],
      "source": [
        "# # prompt: cp: cannot stat 'zip_filename.zip': No such file or directory\n",
        "\n",
        "# import os\n",
        "# import zipfile\n",
        "# from google.colab import files\n",
        "\n",
        "# # Example: List of files to download\n",
        "# file_list = [df_finviz_filename, df_OHLCV_filename]\n",
        "\n",
        "# # Check if files exist before adding to the zip archive\n",
        "# with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "#     for file in file_list:\n",
        "#         if os.path.exists(file):\n",
        "#             zipf.write(file)\n",
        "#         else:\n",
        "#             print(f\"Warning: File not found: {file}. Skipping.\")\n",
        "\n",
        "# # Download the ZIP file (only 1 prompt)\n",
        "# if os.path.exists(zip_filename):\n",
        "#     files.download(zip_filename)\n",
        "# else:\n",
        "#     print(f\"Error: Zip file not created: {zip_filename}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMk4EaASg5ze"
      },
      "outputs": [],
      "source": [
        "# # prompt: copy zipeFile from above cell to /content/drive/MyDrive/stocks/\n",
        "\n",
        "# import shutil\n",
        "# import os\n",
        "\n",
        "# # Assuming zip_filename is defined in the previous code cell\n",
        "# # and contains the name of the created zip file.\n",
        "# # Example: zip_filename = '2024-07-27_finviz_OHLCV.zip'\n",
        "\n",
        "# destination_path = '/content/drive/MyDrive/stocks/'\n",
        "\n",
        "# # Construct the full path to the destination file\n",
        "# destination_file = os.path.join(destination_path, zip_filename)\n",
        "\n",
        "# # Use shutil.copy2 to preserve metadata (like timestamps)\n",
        "# try:\n",
        "#     shutil.copy2(zip_filename, destination_file)\n",
        "#     print(f\"File '{zip_filename}' copied to '{destination_file}'\")\n",
        "# except FileNotFoundError:\n",
        "#     print(f\"Error: The file '{zip_filename}' was not found.\")\n",
        "# except Exception as e:\n",
        "#     print(f\"An error occurred during the copy operation: {e}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
