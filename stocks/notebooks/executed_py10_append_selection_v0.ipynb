{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T02:33:37.123145Z",
     "iopub.status.busy": "2025-04-10T02:33:37.122148Z",
     "iopub.status.idle": "2025-04-10T02:33:37.145562Z",
     "shell.execute_reply": "2025-04-10T02:33:37.143542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_str: 2025-04-09\n",
      "SELECTED_STOCK_PATH: ../picks/2025-04-09_selected_stocks.parquet\n"
     ]
    }
   ],
   "source": [
    "# process_files.py\n",
    "from config import date_str, DOWNLOAD_DIR, DEST_DIR\n",
    "from pathlib import Path  # Better path handling\n",
    "\n",
    "# Build paths\n",
    "SELECTED_STOCK_PATH =f'../picks/{date_str}_selected_stocks.parquet'\n",
    "print(f'date_str: {date_str}')\n",
    "print(f'SELECTED_STOCK_PATH: {SELECTED_STOCK_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T02:33:37.243591Z",
     "iopub.status.busy": "2025-04-10T02:33:37.242602Z",
     "iopub.status.idle": "2025-04-10T02:33:38.684351Z",
     "shell.execute_reply": "2025-04-10T02:33:38.682339Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set pandas display options to show more columns and rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "# pd.set_option('display.max_rows', 10)       # Limit to 10 rows for readability\n",
    "pd.set_option('display.width', 1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T02:33:38.691354Z",
     "iopub.status.busy": "2025-04-10T02:33:38.690354Z",
     "iopub.status.idle": "2025-04-10T02:33:38.801744Z",
     "shell.execute_reply": "2025-04-10T02:33:38.799721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected_stocks_n_weights (<class 'pandas.core.series.Series'>):\n",
      "Ticker\n",
      "PAAA    0.311288\n",
      "JAAA    0.179193\n",
      "UNH     0.172340\n",
      "FLOT    0.067708\n",
      "NOC     0.064434\n",
      "KGC     0.055596\n",
      "HMY     0.051966\n",
      "HCA     0.049134\n",
      "LMT     0.048342\n",
      "Name: Weight, dtype: float64\n",
      "\n",
      "selected_stocks_n_weights.index.name: Ticker\n",
      "\n",
      "date_str: 2025-04-09\n"
     ]
    }
   ],
   "source": [
    "selected_stocks = pd.read_parquet(SELECTED_STOCK_PATH)\n",
    "selected_stocks_n_weights = selected_stocks['Weight'].copy()\n",
    "\n",
    "print(f'selected_stocks_n_weights ({type(selected_stocks_n_weights)}):\\n{selected_stocks_n_weights}')\n",
    "print(f'\\nselected_stocks_n_weights.index.name: {selected_stocks_n_weights.index.name}')\n",
    "print(f'\\ndate_str: {date_str}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T02:33:38.809743Z",
     "iopub.status.busy": "2025-04-10T02:33:38.808743Z",
     "iopub.status.idle": "2025-04-10T02:33:38.843635Z",
     "shell.execute_reply": "2025-04-10T02:33:38.841623Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- process_daily_selections function remains the same ---\n",
    "def process_daily_selections(selected_stocks_n_weights: pd.Series, date_str: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Converts the daily stock selections Series into a standardized DataFrame format.\n",
    "    (Code is identical to the previous version)\n",
    "    \"\"\"\n",
    "    if not isinstance(selected_stocks_n_weights, pd.Series):\n",
    "        raise TypeError(\"selected_stocks_n_weights must be a pandas Series.\")\n",
    "\n",
    "    ticker_col_name = selected_stocks_n_weights.index.name if selected_stocks_n_weights.index.name else 'Ticker'\n",
    "    selected_stocks_n_weights.index.name = ticker_col_name\n",
    "\n",
    "    weight_col_name = selected_stocks_n_weights.name if selected_stocks_n_weights.name else 'Weight'\n",
    "\n",
    "    daily_df = selected_stocks_n_weights.reset_index()\n",
    "\n",
    "    rename_dict = {ticker_col_name: 'Ticker'}\n",
    "    if weight_col_name in daily_df.columns:\n",
    "         rename_dict[weight_col_name] = 'Weight'\n",
    "    elif 0 in daily_df.columns and len(daily_df.columns) == 2:\n",
    "         rename_dict[0] = 'Weight'\n",
    "    else:\n",
    "         print(f\"Warning: Could not automatically identify weight column. Columns found: {daily_df.columns}. Assuming the second column is Weight.\")\n",
    "         if len(daily_df.columns) > 1:\n",
    "             rename_dict[daily_df.columns[1]] = 'Weight'\n",
    "\n",
    "    daily_df = daily_df.rename(columns=rename_dict)\n",
    "    daily_df['Date'] = date_str\n",
    "    daily_df = daily_df[['Date', 'Ticker', 'Weight']]\n",
    "    return daily_df\n",
    "\n",
    "# --- update_tracking_file function remains the same ---\n",
    "def update_tracking_file(daily_data_df: pd.DataFrame, filename: str = \"stock_selections_history.csv\"):\n",
    "    \"\"\"\n",
    "    Loads historical selections, appends new daily data, and saves back to CSV.\n",
    "    Handles empty history file explicitly to avoid concat FutureWarning.\n",
    "    Saves data sorted chronologically by Date, then Ticker.\n",
    "    (Code is identical to the previous version)\n",
    "\n",
    "    Args:\n",
    "        daily_data_df: DataFrame containing the selections for the current day\n",
    "                       (should have columns 'Date', 'Ticker', 'Weight').\n",
    "        filename: The name of the CSV file to load from and save to.\n",
    "\n",
    "    Returns:\n",
    "        The updated DataFrame containing all historical and new selections\n",
    "        (sorted chronologically by Date, then Ticker).\n",
    "    \"\"\"\n",
    "    history_exists = os.path.exists(filename)\n",
    "    all_selections_df = pd.DataFrame(columns=['Date', 'Ticker', 'Weight']) # Initialize empty\n",
    "\n",
    "    if history_exists:\n",
    "        try:\n",
    "            all_selections_df = pd.read_csv(filename, parse_dates=['Date'])\n",
    "            print(f\"Loaded existing data from {filename}\")\n",
    "            if not all(col in all_selections_df.columns for col in ['Date', 'Ticker', 'Weight']):\n",
    "                 print(\"Warning: Loaded file missing expected columns. Treating as empty.\")\n",
    "                 all_selections_df = pd.DataFrame(columns=['Date', 'Ticker', 'Weight'])\n",
    "            elif all_selections_df.empty:\n",
    "                 print(f\"History file {filename} was empty.\")\n",
    "        except pd.errors.EmptyDataError:\n",
    "             print(f\"History file {filename} is empty. Starting fresh.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not load or parse {filename}. Error: {e}. Starting fresh.\")\n",
    "    else:\n",
    "        print(f\"History file {filename} not found. Creating a new one.\")\n",
    "\n",
    "    if all_selections_df.empty:\n",
    "        updated_df = daily_data_df.copy()\n",
    "        print(\"History was empty, using only new data.\")\n",
    "    else:\n",
    "        updated_df = pd.concat([all_selections_df, daily_data_df], ignore_index=True)\n",
    "        print(\"Appended new data to existing history.\")\n",
    "\n",
    "    try:\n",
    "        updated_df['Date'] = pd.to_datetime(updated_df['Date'])\n",
    "        updated_df['Weight'] = pd.to_numeric(updated_df['Weight'], errors='coerce')\n",
    "        updated_df['Ticker'] = updated_df['Ticker'].astype(str)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Error during data type conversion. Error: {e}\")\n",
    "\n",
    "    updated_df = updated_df.drop_duplicates(subset=['Date', 'Ticker'], keep='last')\n",
    "\n",
    "    # Sort data chronologically for saving\n",
    "    updated_df = updated_df.sort_values(by=['Date', 'Ticker']).reset_index(drop=True)\n",
    "    print(\"Data sorted chronologically (Date, Ticker) for saving.\")\n",
    "\n",
    "    try:\n",
    "        updated_df.to_csv(filename, index=False, date_format='%Y-%m-%d')\n",
    "        print(f\"Successfully updated and saved data to {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Could not save data to {filename}. Error: {e}\")\n",
    "\n",
    "    return updated_df # Return the chronologically sorted data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T02:33:38.849649Z",
     "iopub.status.busy": "2025-04-10T02:33:38.849649Z",
     "iopub.status.idle": "2025-04-10T02:33:38.915202Z",
     "shell.execute_reply": "2025-04-10T02:33:38.913210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing data from stock_selections_history.csv\n",
      "Appended new data to existing history.\n",
      "Data sorted chronologically (Date, Ticker) for saving.\n",
      "Successfully updated and saved data to stock_selections_history.csv\n",
      "--------------------\n",
      "Current Full History DataFrame (Displayed with custom sort: Newest Date -> High Weight -> Ticker):\n",
      "         Date Ticker    Weight\n",
      "0  2025-04-09   PAAA  0.311288\n",
      "1  2025-04-09   JAAA  0.179193\n",
      "2  2025-04-09    UNH  0.172340\n",
      "3  2025-04-09   FLOT  0.067708\n",
      "4  2025-04-09    NOC  0.064434\n",
      "..        ...    ...       ...\n",
      "57 2025-04-01    IAU  0.111437\n",
      "58 2025-04-01   GLDM  0.111249\n",
      "59 2025-04-01    BRO  0.097893\n",
      "60 2025-04-01    MMC  0.097198\n",
      "61 2025-04-01   VRSN  0.089730\n",
      "\n",
      "[62 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "daily_df = process_daily_selections(selected_stocks_n_weights, date_str)\n",
    "# update_tracking_file returns the full data, sorted chronologically\n",
    "all_data_updated = update_tracking_file(daily_df, filename=\"stock_selections_history.csv\")\n",
    "\n",
    "print(\"-\" * 20)\n",
    "# --- MODIFICATION FOR DISPLAY ---\n",
    "print(\"Current Full History DataFrame (Displayed with custom sort: Newest Date -> High Weight -> Ticker):\")\n",
    "# Sort again just for this display\n",
    "display_sorted_df = all_data_updated.sort_values(\n",
    "    by=['Date', 'Weight', 'Ticker'],\n",
    "    ascending=[False, False, True] # Date descending, Weight descending, Ticker ascending\n",
    ").reset_index(drop=True)\n",
    "print(display_sorted_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
