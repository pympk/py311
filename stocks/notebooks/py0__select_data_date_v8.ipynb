{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Orchestrator\n",
    "\n",
    "This notebook finds available Finviz data, allows the user to select which date(s) to process, and then executes the main processing pipeline (`run_sequence.py`) for each selected date.\n",
    "\n",
    "**Workflow:**\n",
    "1.  **Setup:** Configure paths and define the default date selection rule.\n",
    "2.  **Find Data Files:** Scan the `Downloads` directory for recent Finviz data files.\n",
    "3.  **Select Dates:** Extract available dates and apply the default selection rule.\n",
    "4.  **(Optional) Refine Selection:** Interactively prompt the user to override the default date selection.\n",
    "5.  **Execute Pipeline:** For each selected date, generate a `config.py` file and run the external processing script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# --- Project Path Setup ---\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "ROOT_DIR = NOTEBOOK_DIR.parent if NOTEBOOK_DIR.name == 'notebooks' else NOTEBOOK_DIR\n",
    "SRC_DIR = ROOT_DIR / 'src'\n",
    "if str(ROOT_DIR) not in sys.path: sys.path.append(str(ROOT_DIR))\n",
    "if str(SRC_DIR) not in sys.path: sys.path.append(str(SRC_DIR))\n",
    "import utils\n",
    "\n",
    "# --- Data File Configuration ---\n",
    "DOWNLOADS_DIR = Path.home() / \"Downloads\"\n",
    "DATA_FILE_PREFIX = 'df_finviz'\n",
    "DATA_FILE_EXTENSION = 'parquet'\n",
    "DATA_FILES_TO_SCAN = 100\n",
    "\n",
    "# --- Analysis Run Configuration ---\n",
    "# Default rule for selecting which dates to process.\n",
    "# slice(-1, None, None) -> Processes only the most recent date.\n",
    "DATE_SLICE = slice(-1, None, None)\n",
    "\n",
    "# --- config.py Generation Parameters ---\n",
    "DEST_DIR = ROOT_DIR / 'data'\n",
    "ANNUAL_RISK_FREE_RATE = 0.04\n",
    "TRADING_DAYS_PER_YEAR = 252\n",
    "\n",
    "# --- Notebook Setup ---\n",
    "pd.set_option('display.max_columns', None); pd.set_option('display.width', 1000)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# --- Verification ---\n",
    "print(f\"Project Root Directory: {ROOT_DIR}\")\n",
    "print(f\"Scanning for data files in: {DOWNLOADS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Find and Display Available Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Step 1: Finding recent data files ---\")\n",
    "\n",
    "# We assume get_recent_files_in_directory is in utils and now accepts a Path object.\n",
    "# If it's not yet refactored, the old call would work too.\n",
    "found_files = utils.get_recent_files_in_directory(\n",
    "    directory_path=DOWNLOADS_DIR,\n",
    "    prefix=DATA_FILE_PREFIX,\n",
    "    extension=DATA_FILE_EXTENSION,\n",
    "    count=DATA_FILES_TO_SCAN\n",
    ")\n",
    "\n",
    "if not found_files:\n",
    "    print(f\"No files matching '{DATA_FILE_PREFIX}*.{DATA_FILE_EXTENSION}' found.\")\n",
    "    available_dates = []\n",
    "else:\n",
    "    # Extract dates and display them neatly\n",
    "    available_dates = utils.extract_and_sort_dates_from_filenames(found_files)\n",
    "    print(f\"\\nFound {len(available_dates)} unique dates available for processing:\")\n",
    "    utils.print_list_in_columns(available_dates, num_columns=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Select Dates for Processing (Default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if available_dates:\n",
    "    # Apply the default slice defined in the setup cell\n",
    "    dates_to_process = available_dates[DATE_SLICE]\n",
    "    print(f\"\\n--- Step 2: Applying default selection rule ---\")\n",
    "    print(f\"Default rule '{DATE_SLICE}' selected {len(dates_to_process)} date(s):\")\n",
    "    print(dates_to_process)\n",
    "else:\n",
    "    dates_to_process = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: (OPTIONAL) Interactively Refine Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if available_dates:\n",
    "    # Call the interactive utility function\n",
    "    NEW_DATE_SLICE = utils.prompt_for_slice_update(\"DATE_SLICE\", DATE_SLICE)\n",
    "    \n",
    "    # If the slice was changed, update the list of dates to process\n",
    "    if NEW_DATE_SLICE != DATE_SLICE:\n",
    "        DATE_SLICE = NEW_DATE_SLICE\n",
    "        dates_to_process = available_dates[DATE_SLICE]\n",
    "        print(f\"\\nUpdated selection. Now processing {len(dates_to_process)} date(s):\")\n",
    "        print(dates_to_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Execute Pipeline\n",
    "\n",
    "This cell iterates through the final list of selected dates, generates the `config.py` file for each, and executes the `run_sequence.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Step 4: Starting processing sequence ---\")\n",
    "\n",
    "if not dates_to_process:\n",
    "    print(\"No dates to process. Halting execution.\")\n",
    "else:\n",
    "    for date_str in dates_to_process:\n",
    "        print(f\"\\n{'='*20} PROCESSING DATE: {date_str} {'='*20}\")\n",
    "        \n",
    "        # 1. Create the config.py file for the current date\n",
    "        utils.create_pipeline_config_file(\n",
    "            config_path=ROOT_DIR / 'config.py',\n",
    "            date_str=date_str,\n",
    "            downloads_dir=DOWNLOADS_DIR,\n",
    "            dest_dir=DEST_DIR,\n",
    "            annual_risk_free_rate=ANNUAL_RISK_FREE_RATE,\n",
    "            trading_days_per_year=TRADING_DAYS_PER_YEAR\n",
    "        )\n",
    "\n",
    "        # 2. Run the external processing script\n",
    "        print(f\"Executing run_sequence_v2.py for {date_str}...\")\n",
    "        %run -i {ROOT_DIR / 'run_sequence_v2.py'}        \n",
    "        \n",
    "        \n",
    "        print(f\"--- Finished processing for {date_str} ---\")\n",
    "\n",
    "    print(f\"\\n{'='*25} ALL PROCESSING COMPLETE {'='*25}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
