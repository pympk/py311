{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from scipy import stats\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def analyze_rank_series(ranks: np.ndarray):\n",
    "#     \"\"\"\n",
    "#     Performs linear regression on a rank series and calculates metrics\n",
    "#     to quantify its steadiness and volatility.\n",
    "\n",
    "#     Args:\n",
    "#         ranks (np.ndarray): A 1D array of ranks.\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary containing key metrics about the series.\n",
    "#     \"\"\"\n",
    "#     if len(ranks) < 2:\n",
    "#         return None # Not enough data to perform regression\n",
    "\n",
    "#     # Create the time-step variable (x-axis)\n",
    "#     time_steps = np.arange(len(ranks))\n",
    "\n",
    "#     # --- Perform Linear Regression using SciPy (fast and efficient) ---\n",
    "#     slope, intercept, r_value, p_value, std_err = stats.linregress(time_steps, ranks)\n",
    "    \n",
    "#     # --- Calculate Key Metrics ---\n",
    "    \n",
    "#     # 1. R-squared: The primary measure of \"steadiness\" or linearity\n",
    "#     r_squared = r_value**2\n",
    "\n",
    "#     # 2. Predicted values and residuals\n",
    "#     predicted_ranks = intercept + slope * time_steps\n",
    "#     residuals = ranks - predicted_ranks\n",
    "\n",
    "#     # 3. Maximum Absolute Residual: The single biggest jump from the trend\n",
    "#     max_abs_residual = np.max(np.abs(residuals))\n",
    "\n",
    "#     # 4. Standard Deviation of Returns: The primary measure of \"jumpiness\"\n",
    "#     # Use pandas for a convenient way to calculate percentage change\n",
    "#     returns = pd.Series(ranks).pct_change().dropna()\n",
    "#     std_dev_returns = returns.std()\n",
    "    \n",
    "#     # 5. Create a combined penalty score (example)\n",
    "#     # A higher score means more penalty (less desirable series)\n",
    "#     # We use (1 - r_squared) because a high r_squared is good.\n",
    "#     # We add a small epsilon to avoid division by zero if std_dev is 0.\n",
    "#     penalty_score = (1 - r_squared) * (std_dev_returns + 1e-9)\n",
    "\n",
    "#     return {\n",
    "#         \"slope\": slope,\n",
    "#         \"intercept\": intercept,\n",
    "#         \"r_squared\": r_squared,\n",
    "#         \"std_dev_returns\": std_dev_returns,\n",
    "#         \"max_abs_residual\": max_abs_residual,\n",
    "#         \"penalty_score\": penalty_score,\n",
    "#         \"predicted_ranks\": predicted_ranks # For plotting\n",
    "#     }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# # The 'analyze_rank_series' function is assumed to be defined as you provided\n",
    "# # from scipy import stats # This would be needed by analyze_rank_series\n",
    "\n",
    "# def calculate_rank_metrics(df_rank_history, tickers_list, lookback_days=20, recent_days=4):\n",
    "#     \"\"\"\n",
    "#     Calculates a comprehensive set of rank metrics for a given list of tickers.\n",
    "\n",
    "#     This function does NOT filter tickers based on performance criteria. It processes\n",
    "#     every ticker provided in the tickers_list and returns its calculated metrics,\n",
    "#     making it suitable for generating features for analysis or other models.\n",
    "\n",
    "#     Args:\n",
    "#         df_rank_history (pd.DataFrame): DataFrame with tickers as index and dates as columns.\n",
    "#         tickers_list (list): A list of ticker symbols to calculate metrics for.\n",
    "#         lookback_days (int): The number of days for the \"lookback\" period.\n",
    "#         recent_days (int): The number of days for the \"recent\" period.\n",
    "\n",
    "#     Returns:\n",
    "#         list: A list of dictionaries, where each dictionary contains the calculated\n",
    "#               rank metrics for one ticker. Tickers with insufficient data in the\n",
    "#               specified period are skipped.\n",
    "#     \"\"\"\n",
    "#     # --- Guard Clause & Date Setup ---\n",
    "#     total_days_needed = lookback_days + recent_days\n",
    "#     if len(df_rank_history.columns) < total_days_needed:\n",
    "#         print(f\"Error: Not enough data. Need {total_days_needed} days, have {len(df_rank_history.columns)}.\")\n",
    "#         return []\n",
    "\n",
    "#     all_dates = df_rank_history.columns\n",
    "#     last_date = all_dates[-1]\n",
    "#     recent_period_start_date = all_dates[-recent_days]\n",
    "#     lookback_period_end_date = all_dates[-(recent_days + 1)]\n",
    "#     lookback_period_start_date = all_dates[-(recent_days + lookback_days)]\n",
    "    \n",
    "#     lookback_dates = df_rank_history.loc[:, lookback_period_start_date:lookback_period_end_date].columns\n",
    "#     recent_dates = df_rank_history.loc[:, recent_period_start_date:last_date].columns\n",
    "    \n",
    "#     all_ticker_metrics = []\n",
    "\n",
    "#     print(f\"Calculating metrics for {len(tickers_list)} tickers...\")\n",
    "\n",
    "#     # --- Calculation Loop ---\n",
    "#     for ticker in tickers_list:\n",
    "#         # Skip if ticker is not in the dataframe index\n",
    "#         if ticker not in df_rank_history.index:\n",
    "#             continue\n",
    "\n",
    "#         lookback_ranks = df_rank_history.loc[ticker, lookback_dates].dropna()\n",
    "#         recent_ranks = df_rank_history.loc[ticker, recent_dates].dropna()\n",
    "        \n",
    "#         # Skip if there's not enough data for this specific ticker in the required periods\n",
    "#         if len(lookback_ranks) < lookback_days or len(recent_ranks) < recent_days:\n",
    "#             continue\n",
    "            \n",
    "#         # --- Perform all calculations without any filtering 'if' statements ---\n",
    "        \n",
    "#         # MODIFICATION: Use analyze_rank_series to calculate slope, r_squared, and penalty_score.\n",
    "#         analysis_results = analyze_rank_series(lookback_ranks.values)\n",
    "        \n",
    "#         # The analyze_rank_series function returns None if there's not enough data,\n",
    "#         # so we add a check here just in case.\n",
    "#         if not analysis_results:\n",
    "#             continue\n",
    "            \n",
    "#         slope = analysis_results['slope']\n",
    "#         r_squared = analysis_results['r_squared']\n",
    "#         penalty_score = analysis_results['penalty_score']\n",
    "        \n",
    "#         all_ranks_in_period = pd.concat([lookback_ranks, recent_ranks])\n",
    "\n",
    "#         # Key reference points\n",
    "#         current_rank = int(recent_ranks.iloc[-1])\n",
    "#         rank_at_start_of_recent = int(recent_ranks.iloc[0])\n",
    "#         recent_bottom_rank = int(recent_ranks.max()) # Worst rank in recent period\n",
    "#         total_peak_rank = int(all_ranks_in_period.min()) # Best rank over the whole period\n",
    "        \n",
    "#         # This dictionary holds all calculated metrics for one ticker\n",
    "#         metrics_dict = {\n",
    "#             'ticker': ticker,\n",
    "#             'lookback_slope': round(slope, 2),\n",
    "#             'r_squared': round(r_squared, 4),      # Added r_squared\n",
    "#             'penalty_score': round(penalty_score, 4), # Added penalty_score\n",
    "            \n",
    "#             # Key Ranks\n",
    "#             'current': current_rank,\n",
    "#             'recent_start': rank_at_start_of_recent,\n",
    "#             'lookback_start': int(lookback_ranks.iloc[0]),\n",
    "#             'lookback_end': int(lookback_ranks.iloc[-1]),\n",
    "\n",
    "#             # Best/Worst Ranks by Period\n",
    "#             'best_lookback': int(lookback_ranks.min()),\n",
    "#             'worst_lookback': int(lookback_ranks.max()),\n",
    "#             'best_recent': int(recent_ranks.min()),\n",
    "#             'worst_recent': recent_bottom_rank, # Same value, more descriptive name\n",
    "#             'best_total': total_peak_rank,\n",
    "#             'worst_total': int(all_ranks_in_period.max()),\n",
    "\n",
    "#             # Derived Metrics (using clearer names)\n",
    "#             'current_to_total_peak': current_rank - total_peak_rank,\n",
    "#             'current_to_recent_start': current_rank - rank_at_start_of_recent,\n",
    "#             'recent_bottom_to_recent_start': recent_bottom_rank - rank_at_start_of_recent,\n",
    "#             'recent_bottom_to_current': recent_bottom_rank - current_rank,\n",
    "#         }\n",
    "#         all_ticker_metrics.append(metrics_dict)\n",
    "\n",
    "#     return all_ticker_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Role of Each Metric in Your Strategy\n",
    "\n",
    "First, let's assign a clear purpose to each metric from an investor's point of view:\n",
    "\n",
    "1.  **Slope (The Growth Factor):** This is your **reward** metric. It quantifies the magnitude of the trend. A higher slope means faster price appreciation. A negative slope means the stock is losing value.\n",
    "    *   **Purpose:** To identify stocks that are actually growing.\n",
    "\n",
    "2.  **R-Squared (The Reliability Filter):** This is your **confidence** metric. It tells you if the slope is statistically meaningful or just a result of random noise. A high R-squared means the price movement is very trend-like and predictable.\n",
    "    *   **Purpose:** To filter out erratic, unpredictable stocks where the \"trend\" isn't trustworthy.\n",
    "\n",
    "3.  **Penalty Score (The Quality & Risk Factor):** This is your primary **selection** metric. It combines trend reliability (`1 - R²`) with path volatility (`std_dev_returns`). A lower score is better, indicating a smooth, linear, and low-volatility journey.\n",
    "    *   **Purpose:** To rank the \"good\" stocks and find the highest quality, most stable performers.\n",
    "\n",
    "---\n",
    "\n",
    "### Recommended Strategy: The Tiered Filtering & Ranking Funnel\n",
    "\n",
    "This is the most robust and logical approach. It works like a funnel, progressively narrowing the universe of stocks to find the best candidates.\n",
    "\n",
    "#### Step 1: The Viability Filter (using `Slope`)\n",
    "\n",
    "**Action:** Discard any stock where `Slope <= 0`.\n",
    "\n",
    "**Reasoning:** Your goal is to find \"steady price *gains*.\" The most basic requirement is that the stock's trend is positive. This is a simple, non-negotiable first pass to eliminate all assets that are flat or in a downtrend over your analysis period. You might even set a minimum threshold, like `Slope > 0.1`, to ensure you're only looking at stocks with meaningful upward momentum.\n",
    "\n",
    "#### Step 2: The Reliability Filter (using `R-Squared`)\n",
    "\n",
    "**Action:** From the remaining stocks, discard any where `R-Squared` is below a certain threshold. A good starting point is **`R-Squared < 0.70`**.\n",
    "\n",
    "**Reasoning:** A high slope is meaningless if the trend is not reliable. A stock that jumps +20% one week and falls -19% the next might have a positive slope, but its movement is chaotic. By filtering for a high R-squared, you are ensuring that the growth (slope) is consistent and not just a statistical accident. This step removes the \"trap\" stocks that look good on slope alone but are far too unpredictable.\n",
    "\n",
    "#### Step 3: The Quality Ranking (using `Penalty Score`)\n",
    "\n",
    "**Action:** Take the final pool of stocks that have passed both filters and **rank them by `Penalty Score` from lowest to highest.**\n",
    "\n",
    "**Reasoning:** You now have a list of stocks that are both *growing* (Step 1) and have a *reliable trend* (Step 2). The final step is to select the *best* among them based on your core philosophy: favoring steady, smooth gains. The `Penalty Score` was specifically designed for this. A lower penalty score signifies a smoother, more linear path with less volatility. The stocks at the top of this ranked list are your prime candidates.\n",
    "\n",
    "**Final Selection:** Choose the top N stocks (e.g., top 5, 10, or 20) from this final ranked list to build your portfolio.\n",
    "\n",
    "### Conceptual Example\n",
    "\n",
    "Imagine you analyze four stocks:\n",
    "\n",
    "| Stock | Slope | R-Squared | Penalty Score | Decision Process |\n",
    "| :---- | :---- | :-------- | :------------ | :-------------------------------------------------------------------------------- |\n",
    "| **A** | 1.5   | 0.95      | 0.2           | **Passes all filters.** High growth, reliable, and very smooth. **Top Candidate.**     |\n",
    "| **B** | 2.0   | 0.55      | 1.8           | Passes Step 1 (high slope), but **FAILS Step 2** (R² is too low). It's an erratic gambler's stock, not a steady gainer. **Discard.** |\n",
    "| **C** | 0.8   | 0.98      | 0.1           | **Passes all filters.** Moderate growth, but extremely reliable and smooth. Ranks higher than Stock A in the final ranking due to its lower penalty score. A great \"safe\" pick. |\n",
    "| **D** | -0.5  | 0.90      | 0.4           | **FAILS Step 1.** Even though it's a very smooth and predictable trend, it's going down. **Discard immediately.** |\n",
    "\n",
    "In this scenario, after the filtering and ranking, your final list would be:\n",
    "1.  **Stock C** (Penalty Score: 0.1)\n",
    "2.  **Stock A** (Penalty Score: 0.2)\n",
    "\n",
    "---\n",
    "\n",
    "### Alternative Strategy: The \"Steadiness-Adjusted Growth\" Score\n",
    "\n",
    "If you want to combine everything into a single number, you can create a ratio. This is for investors who are willing to accept a bit more volatility in exchange for a significantly higher growth rate.\n",
    "\n",
    "**Action:** For all stocks that pass the initial filters (`Slope > 0` and `R-Squared > 0.7`), calculate a new score:\n",
    "\n",
    "`SAG_Score = Slope / Penalty_Score` (Steadiness-Adjusted Growth)\n",
    "\n",
    "Then, rank the stocks from **highest to lowest** `SAG_Score`.\n",
    "\n",
    "**Reasoning:** This score rewards stocks with a high slope (high reward) and a low penalty score (low risk/high quality). It directly creates a \"bang for your buck\" metric. A stock with a massive slope could overcome a slightly higher penalty score. This is a more aggressive approach than the primary strategy but is an excellent way to balance growth and quality.\n",
    "\n",
    "### Final Recommendation\n",
    "\n",
    "For your stated goal, the **Tiered Filtering & Ranking Funnel is the superior strategy.** It is more robust, methodologically sound, and directly aligned with your philosophy. It ensures you never compromise on the foundational principles of positive growth and trend reliability before optimizing for smoothness.\n",
    "\n",
    "Start with that strategy. Once you are comfortable with it, you can experiment with the `SAG_Score` as a secondary way to view your top candidates and see if it reveals any high-growth opportunities you might have otherwise overlooked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank-Based Candidate Analysis\n",
    "\n",
    "This notebook identifies promising stock tickers based on their historical rank performance.\n",
    "\n",
    "**Workflow:**\n",
    "\n",
    "1.  **Load Data:** It finds the latest comprehensive Finviz data file and all recent daily rank files.\n",
    "2.  **Build Rank History:** It compiles the daily files into a single time-series DataFrame (`df_rank_history`) where each row is a ticker and each column is a date.\n",
    "3.  **Calculate Metrics:** It processes the entire rank history to compute a rich set of performance metrics (slope, peak rank, etc.) for *every ticker*. This creates a master `df_all_tickers_metrics` DataFrame.\n",
    "4.  **Filter & Sort Candidates:** The master metrics are filtered according to user-defined criteria (e.g., \"Reversal\" pattern) to find a small list of top candidates.\n",
    "5.  **Analyze & Visualize:** The top candidates are enhanced with price data, sorted, and plotted. A separate analysis is also performed on a pre-defined portfolio of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and Configuration\n",
    "\n",
    "This cell contains all imports and user-configurable parameters for the analysis pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Path Configuration ---\n",
      "✅ Project Root: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\n",
      "✅ Data Dir:     c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\n",
      "✅ Source Dir:   c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\src\n",
      "\n",
      "--- Module Verification ---\n",
      "✅ Successfully imported 'utils' and 'plotting_utils'.\n",
      "\n",
      "--- Analysis Configuration ---\n",
      "\n",
      "--- Analysis Configuration ---\n",
      "Period Parameters (for calculation):\n",
      "{'lookback_days': 40, 'recent_days': 8}\n",
      "\n",
      "Metric Filters (for selection):\n",
      "{'min_lookback_improvement': 0,\n",
      " 'current_rank_bracket_start': 1,\n",
      " 'current_rank_bracket_end': 1000,\n",
      " 'min_recent_bottom_to_recent_start': 0,\n",
      " 'min_recent_bottom_to_current': 0}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "import inspect  # <--- ADD THIS LINE\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# --- 1. PANDAS & IPYTHON OPTIONS ---\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 3000)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# --- 2. PROJECT PATH CONFIGURATION ---\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "ROOT_DIR = NOTEBOOK_DIR.parent.parent  # Adjust if your notebook is in a 'notebooks' subdirectory\n",
    "DATA_DIR = ROOT_DIR / 'data'\n",
    "SRC_DIR = ROOT_DIR / 'src'\n",
    "\n",
    "# Add 'src' to the Python path to import custom modules\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.append(str(SRC_DIR))\n",
    "\n",
    "# --- 3. IMPORT CUSTOM MODULES ---\n",
    "import utils\n",
    "import plotting_utils\n",
    "\n",
    "# --- 4. ANALYSIS & FILTERING CONFIGURATION ---\n",
    "\n",
    "# File searching parameters\n",
    "FILE_PREFIX = '202'  # e.g., '2024'\n",
    "FILE_CONTAINS_PATTERN = 'df_finviz_merged_stocks_etfs'\n",
    "HISTORY_FILE_COUNT = 100 # Number of recent daily files to build rank history\n",
    "\n",
    "############################################\n",
    "# # Parameters defining the time windows for metric calculation\n",
    "PERIOD_PARAMS = {\n",
    "    'lookback_days': 40,\n",
    "    'recent_days': 8,\n",
    "}\n",
    "\n",
    "############################################\n",
    "\n",
    "# This is not use for filtering, it's use to calculate metrics in SORT_ORDER\n",
    "# Parameters for filtering the calculated metrics to find candidates\n",
    "METRIC_FILTERS = {\n",
    "    'min_lookback_improvement': 0,\n",
    "    'current_rank_bracket_start': 1,\n",
    "    'current_rank_bracket_end': 1000,\n",
    "    # --- Select ONE mode by commenting out the others ---\n",
    "    # 'Reversal' Mode\n",
    "    'min_recent_bottom_to_recent_start': 0,\n",
    "    'min_recent_bottom_to_current': 0,    \n",
    "    # 'Dip' Mode\n",
    "    # 'min_current_to_recent_start': 10,\n",
    "}\n",
    "\n",
    "# Sorting is the filter to select the top tickers\n",
    "# Sorting order for final candidate list (column_name: ascending_boolean)\n",
    "SORT_ORDER = {\n",
    "    'lookback_slope': True,             # Lower is better (steeper improving trend)    \n",
    "    'current_to_total_peak': True,      # Lower is better (closer to all-time best rank)\n",
    "    'Change/(ATR/Price)': False,        # Higher is better (strong upside price and low volatility)   \n",
    "    'Change %': False,                  # Higher is better (stronger daily performance)    \n",
    "    'recent_bottom_to_current': False,  # Higher is better (stronger bounce from recent low)\n",
    "}\n",
    "\n",
    "\n",
    "# List of tickers for a separate, focused portfolio analysis\n",
    "PORTFOLIO_TICKERS = [\n",
    "    \"JOBY\", \"SYM\", \"RKLB\", \"MSTR\", \"ORCL\",\n",
    "    \"SHOP\", \"COIN\", \"VGT\", \"AVAV\", \"META\",\n",
    "    \"NVDA\",\n",
    "    # ####### Change/(ATR/Price) > 1.5\n",
    "    \"DELL\", \"FUTU\", \"VST\",\n",
    "    #########\n",
    "     \"U\", \"IONQ\",\n",
    "    \"RBLX\",\n",
    "    # ####### Kimi pick\n",
    "    \"ASTS\", \"NET\", \"ANET\", \"CCJ\",\n",
    "]\n",
    "\n",
    "CANDIDATES_TO_PLOT = 100\n",
    "\n",
    "# --- 5. VERIFICATION ---\n",
    "print(\"--- Path Configuration ---\")\n",
    "print(f\"✅ Project Root: {ROOT_DIR}\")\n",
    "print(f\"✅ Data Dir:     {DATA_DIR}\")\n",
    "print(f\"✅ Source Dir:   {SRC_DIR}\")\n",
    "assert all([ROOT_DIR.exists(), DATA_DIR.exists(), SRC_DIR.exists()]), \"A key directory was not found!\"\n",
    "\n",
    "print(\"\\n--- Module Verification ---\")\n",
    "print(f\"✅ Successfully imported 'utils' and 'plotting_utils'.\")\n",
    "\n",
    "print(\"\\n--- Analysis Configuration ---\")\n",
    "print(\"\\n--- Analysis Configuration ---\")\n",
    "print(\"Period Parameters (for calculation):\")\n",
    "pprint.pprint(PERIOD_PARAMS)\n",
    "print(\"\\nMetric Filters (for selection):\")\n",
    "pprint.pprint(METRIC_FILTERS, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load Latest Merged Finviz Data\n",
    "\n",
    "Find and load the single most recent `df_finviz_merged` file. This DataFrame contains supplementary data like `Price` and `ATR/Price %` that will be used to enhance our final analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Loading latest consolidated Finviz data ---\n",
      "Info: Index is unnamed. Assuming it contains tickers and assigning the name 'Ticker'.\n",
      "✅ Successfully loaded: 2025-09-08_df_finviz_merged_stocks_etfs.parquet\n",
      "Shape: (1525, 139)\n",
      "        No.                Company               Index      Sector                   Industry Country Exchange                                   Info  MktCap AUM, M  Rank  Market Cap, M    P/E  Fwd P/E   PEG    P/S    P/B    P/C  P/FCF  Book/sh  Cash/sh  Dividend %  Dividend TTM Dividend Ex Date  Payout Ratio %    EPS  EPS next Q  EPS this Y %  EPS next Y %  EPS past 5Y %  EPS next 5Y %  Sales past 5Y %  Sales Q/Q %  EPS Q/Q %  EPS YoY TTM %  Sales YoY TTM %  Sales, M  Income, M  EPS Surprise %  Revenue Surprise %  Outstanding, M  Float, M  Float %  Insider Own %  Insider Trans %  Inst Own %  Inst Trans %  Short Float %  Short Ratio  Short Interest, M  ROA %   ROE %  ROIC %  Curr R  Quick R  LTDebt/Eq  Debt/Eq  Gross M %  Oper M %  Profit M %  Perf 3D %  Perf Week %  Perf Month %  Perf Quart %  Perf Half %  Perf Year %  Perf YTD %  Beta   ATR  ATR/Price %  Volatility W %  Volatility M %  SMA20 %  SMA50 %  SMA200 %  50D High %  50D Low %  52W High %  52W Low %        52W Range  All-Time High %  All-Time Low %    RSI  Earnings    IPO Date Optionable Shortable  Employees  Change from Open %  Gap %  Recom  Avg Volume, M  Rel Volume     Volume  Target Price  Prev Close    Open    High     Low   Price  Change % Single Category Asset Type  Expense %  Holdings  AUM, M  Flows 1M, M  Flows% 1M  Flows 3M, M  Flows% 3M  Flows YTD, M  Flows% YTD  Return% 1Y  Return% 3Y  Return% 5Y Tags  Sharpe 3d  Sortino 3d  Omega 3d  Sharpe 5d  Sortino 5d  Omega 5d  Sharpe 10d  Sortino 10d  Omega 10d  Sharpe 15d  Sortino 15d  Omega 15d  Sharpe 30d  Sortino 30d  Omega 30d  Sharpe 60d  Sortino 60d  Omega 60d  Sharpe 120d  Sortino 120d  Omega 120d  Sharpe 250d  Sortino 250d  Omega 250d\n",
      "Ticker                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
      "NVDA      1            NVIDIA Corp  DJIA, NDX, S&P 500  Technology             Semiconductors     USA     NASD             Technology, Semiconductors      4089930.0     1      4089930.0  47.90    26.50  1.38  24.75  40.92  72.02  56.79     4.11     2.34        0.02          0.04        9/11/2025            1.16   3.51        1.24           NaN           NaN            NaN            NaN              NaN        55.60      61.23          64.54            71.55  165220.0    86600.0            4.13                1.51         24350.0   23400.0    96.13           4.09            -0.78       67.71          1.73           0.88         1.18             205.24  76.65  109.42   78.42    4.21     3.60       0.10     0.11      69.85     58.09       52.41  -1.353886        -3.37         -6.89         18.76        49.36        58.47       25.33  2.13  4.93     2.929119            2.36            2.62    -4.94    -2.48     20.78       -8.77      11.10       -8.77      94.31   86.62 - 184.48            -8.77       504829.97  39.44  Aug 27/a   1/22/1999        Yes       Yes    36000.0                0.44   0.33   1.39         174.08        0.93  161246256        215.51      167.02  167.57  170.96  167.35  168.31      0.77                                   NaN       NaN     NaN          NaN        NaN          NaN        NaN           NaN         NaN         NaN         NaN         NaN    -  -6.338270   -8.101796  0.278235  -3.642461   -4.312080  0.477349   -7.336899    -7.295211   0.267894   -5.257204    -5.577762   0.395843   -1.721513    -2.198637   0.749477    2.360177     3.727562   1.470507     1.848615      3.129862    1.434194     1.094629      1.589970    1.218367\n",
      "MSFT      2  Microsoft Corporation  DJIA, NDX, S&P 500  Technology  Software - Infrastructure     USA     NASD  Technology, Software - Infrastructure      3703200.0     2      3703200.0  36.52    27.23  2.18  13.14  10.78  39.16  51.71    46.20    12.72        0.70          3.32        8/21/2025           24.34  13.64        3.65           NaN           NaN            NaN            NaN              NaN        18.10      23.77          15.50            14.93  281720.0   101830.0            8.16                3.40          7430.0    7320.0    98.51           1.48            -0.26       73.31         -0.34           0.77         2.79              56.18  18.00   33.28   22.93    1.35     1.35       0.29     0.33      68.82     45.62       36.15  -1.414861        -1.68         -4.35          5.91        26.67        21.84       18.20  1.03  8.21     1.647933            1.83            1.47    -2.31    -2.26     12.11      -10.31       1.94      -10.31      44.49  344.79 - 555.45           -10.31       625161.69  40.65  Jul 30/a   3/13/1986        Yes       Yes   228000.0               -0.02   0.67   1.20          20.13        0.83   16712336        625.17      495.00  498.32  501.20  495.03  498.20      0.65                                   NaN       NaN     NaN          NaN        NaN          NaN        NaN           NaN         NaN         NaN         NaN         NaN    -  -6.800664   -8.469855  0.245445  -3.718816   -4.344779  0.452609   -2.185947    -2.563666   0.668963   -4.480328    -4.901284   0.463799   -1.265122    -1.915896   0.797289    0.911130     1.478945   1.172717     2.086204      4.139461    1.547944     0.827185      1.290481    1.173620\n",
      "AAPL      3              Apple Inc  DJIA, NDX, S&P 500  Technology       Consumer Electronics     USA     NASD       Technology, Consumer Electronics      3530230.0     3      3530230.0  36.16    29.88  4.18   8.64  53.69  63.75  36.70     4.43     3.73        0.43          1.02        8/11/2025           16.11   6.58        1.76           NaN           NaN            NaN            NaN              NaN         9.63      12.19           0.15             5.97  408620.0    99280.0            9.18                4.99         14860.0   14820.0    99.79           0.10            -2.09       64.55          1.15           0.86         2.33             127.08  29.94  149.81   66.96    0.87     0.83       1.25     1.54      46.68     31.87       24.30  -0.247411         2.47          8.11         16.65        -0.50         7.71       -5.01  1.08  4.40     1.849672            1.55            1.81     2.71     8.55      7.41       -1.43      19.38       -8.54      40.58  169.21 - 260.10            -8.54       373831.05  66.87  Jul 31/a  12/12/1980        Yes       Yes   164000.0               -0.61  -0.15   2.00          54.46        0.90   48770609        240.23      239.69  239.34  240.15  236.34  237.88     -0.76                                   NaN       NaN     NaN          NaN        NaN          NaN        NaN           NaN         NaN         NaN         NaN         NaN    - -12.895793  -11.973822  0.000000   6.891229   35.966894  5.248006    5.683748    18.204160   3.192558    2.422689     4.958322   1.574473    3.280415     7.622640   1.832658    3.328277     7.070242   1.856286     0.702957      1.108295    1.160638     0.281524      0.417362    1.057819\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Step 1: Loading latest consolidated Finviz data ---\")\n",
    "\n",
    "# Find the most recent file matching the pattern\n",
    "# This function is now understood to return List[str] (filenames), not List[Path].\n",
    "latest_finviz_filepaths = utils.get_recent_files(\n",
    "    directory_path=DATA_DIR,\n",
    "    extension='parquet',\n",
    "    prefix=FILE_PREFIX,\n",
    "    contains_pattern=FILE_CONTAINS_PATTERN,\n",
    "    count=1\n",
    ")\n",
    "\n",
    "if not latest_finviz_filepaths:\n",
    "    raise FileNotFoundError(f\"No files found in '{DATA_DIR}' with prefix '{FILE_PREFIX}' and pattern '{FILE_CONTAINS_PATTERN}'\")\n",
    "\n",
    "# Get the filename string from the list\n",
    "latest_filename = latest_finviz_filepaths[0]\n",
    "\n",
    "# Manually construct the full path before loading\n",
    "full_file_path = DATA_DIR / latest_filename\n",
    "df_finviz_latest = pd.read_parquet(full_file_path, engine='pyarrow')\n",
    "\n",
    "\n",
    "# --- Robust Index Setting (this logic remains correct) ---\n",
    "if df_finviz_latest.index.name == 'Ticker':\n",
    "    print(\"Info: 'Ticker' is already the index. No action needed.\")\n",
    "elif 'Ticker' in df_finviz_latest.columns:\n",
    "    print(\"Info: 'Ticker' column found. Setting it as the DataFrame index.\")\n",
    "    df_finviz_latest.set_index('Ticker', inplace=True)\n",
    "elif 'ticker' in df_finviz_latest.columns:\n",
    "    print(\"Info: 'ticker' column found. Renaming and setting as index.\")\n",
    "    df_finviz_latest.rename(columns={'ticker': 'Ticker'}, inplace=True)\n",
    "    df_finviz_latest.set_index('Ticker', inplace=True)\n",
    "elif df_finviz_latest.index.name is None:\n",
    "    print(\"Info: Index is unnamed. Assuming it contains tickers and assigning the name 'Ticker'.\")\n",
    "    df_finviz_latest.index.name = 'Ticker'\n",
    "else:\n",
    "    print(\"ERROR: Loaded DataFrame has an unexpected format.\")\n",
    "    print(f\"Columns: {df_finviz_latest.columns.tolist()}\")\n",
    "    print(f\"Index Name: '{df_finviz_latest.index.name}'\")\n",
    "    raise ValueError(\"Could not find a 'Ticker' column or a usable index to proceed.\")\n",
    "\n",
    "\n",
    "# Correct the print statement to work with the filename string\n",
    "print(f\"✅ Successfully loaded: {latest_filename}\")\n",
    "print(f\"Shape: {df_finviz_latest.shape}\")\n",
    "print(df_finviz_latest.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Build Rank History Matrix\n",
    "\n",
    "Load the last `N` daily data files to construct a comprehensive rank history DataFrame. This matrix is the primary input for all subsequent trend and performance calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 2: Building rank history from the latest 100 files ---\n",
      "✅ Rank history matrix created successfully.\n",
      "Shape: (1663, 92) (Tickers, Days)\n",
      "Date Range: 2025-04-25 to 2025-09-08\n"
     ]
    }
   ],
   "source": [
    "print(f\"--- Step 2: Building rank history from the latest {HISTORY_FILE_COUNT} files ---\")\n",
    "\n",
    "# Get a list of all recent daily files\n",
    "daily_files_list = utils.get_recent_files(\n",
    "    directory_path=DATA_DIR,\n",
    "    extension='parquet',\n",
    "    prefix=FILE_PREFIX,\n",
    "    contains_pattern=FILE_CONTAINS_PATTERN,\n",
    "    count=HISTORY_FILE_COUNT\n",
    ")\n",
    "\n",
    "# Use the utility function to create the rank history dataframe\n",
    "# Assumes 'create_rank_history_df' is now in utils.py\n",
    "df_rank_history = utils.create_rank_history_df(daily_files_list, DATA_DIR)\n",
    "\n",
    "print(f\"✅ Rank history matrix created successfully.\")\n",
    "print(f\"Shape: {df_rank_history.shape} (Tickers, Days)\")\n",
    "print(f\"Date Range: {df_rank_history.columns.min().strftime('%Y-%m-%d')} to {df_rank_history.columns.max().strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original shape: (1663, 92)\n",
      "\n",
      "DataFrame after removing rows with any NaN values:\n",
      "       2025-04-25  2025-04-28  2025-04-29  2025-04-30  2025-05-01  2025-05-02  2025-05-05  2025-05-06  2025-05-07  2025-05-08  2025-05-09  2025-05-12  2025-05-13  2025-05-14  2025-05-15  2025-05-16  2025-05-19  2025-05-20  2025-05-21  2025-05-22  2025-05-23  2025-05-27  2025-05-28  2025-05-29  2025-05-30  2025-06-02  2025-06-03  2025-06-04  2025-06-05  2025-06-06  2025-06-09  2025-06-10  2025-06-11  2025-06-12  2025-06-13  2025-06-16  2025-06-17  2025-06-18  2025-06-19  2025-06-20  2025-06-23  2025-06-24  2025-06-25  2025-06-26  2025-06-27  2025-06-30  2025-07-01  2025-07-02  2025-07-03  2025-07-07  2025-07-08  2025-07-09  2025-07-10  2025-07-11  2025-07-14  2025-07-15  2025-07-16  2025-07-17  2025-07-18  2025-07-21  2025-07-22  2025-07-23  2025-07-24  2025-07-25  2025-07-28  2025-07-29  2025-07-30  2025-07-31  2025-08-01  2025-08-04  2025-08-05  2025-08-06  2025-08-07  2025-08-08  2025-08-11  2025-08-12  2025-08-13  2025-08-14  2025-08-15  2025-08-18  2025-08-19  2025-08-21  2025-08-22  2025-08-25  2025-08-26  2025-08-28  2025-08-29  2025-09-02  2025-09-03  2025-09-04  2025-09-05  2025-09-08\n",
      "NVDA          3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         1.0         1.0         2.0         2.0         2.0         1.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0\n",
      "MSFT          2.0         2.0         2.0         2.0         2.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         2.0         2.0         1.0         1.0         1.0         2.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         1.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0\n",
      "AAPL          1.0         1.0         1.0         1.0         1.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         2.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0         3.0\n",
      "GOOGL         5.0         5.0         6.0         6.0         5.0         6.0         5.0         5.0         5.0         6.0         6.0         6.0         6.0         6.0         6.0         5.0         6.0         5.0         6.0         5.0         6.0         5.0         5.0         6.0         6.0         6.0         6.0         5.0         6.0         5.0         6.0         5.0         5.0         5.0         5.0         5.0         6.0         5.0         6.0         6.0         5.0         6.0         5.0         6.0         5.0         6.0         5.0         6.0         5.0         5.0         6.0         6.0         6.0         6.0         6.0         5.0         5.0         6.0         5.0         6.0         5.0         6.0         5.0         5.0         5.0         5.0         6.0         6.0         4.0         4.0         4.0         5.0         4.0         4.0         4.0         5.0         5.0         5.0         5.0         5.0         5.0         4.0         4.0         5.0         5.0         4.0         4.0         5.0         4.0         4.0         5.0         4.0\n",
      "GOOG          6.0         6.0         5.0         5.0         6.0         5.0         4.0         4.0         6.0         5.0         5.0         5.0         5.0         5.0         5.0         6.0         5.0         6.0         5.0         6.0         5.0         6.0         6.0         5.0         5.0         5.0         5.0         6.0         5.0         6.0         5.0         6.0         6.0         6.0         6.0         6.0         5.0         6.0         5.0         5.0         6.0         5.0         6.0         5.0         6.0         5.0         6.0         5.0         6.0         6.0         5.0         5.0         5.0         5.0         5.0         6.0         6.0         5.0         6.0         5.0         6.0         5.0         6.0         6.0         6.0         6.0         5.0         5.0         5.0         5.0         5.0         4.0         5.0         5.0         5.0         4.0         4.0         6.0         4.0         6.0         4.0         5.0         5.0         4.0         4.0         5.0         5.0         4.0         5.0         5.0         4.0         5.0\n",
      "...           ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...\n",
      "REET       1507.0      1508.0      1486.0      1507.0      1506.0      1505.0      1505.0      1505.0      1505.0      1505.0      1508.0      1508.0      1508.0      1513.0      1515.0      1513.0      1513.0      1514.0      1494.0      1517.0      1518.0      1514.0      1516.0      1514.0      1514.0      1513.0      1511.0      1515.0      1516.0      1512.0      1513.0      1515.0      1514.0      1514.0      1514.0      1514.0      1518.0      1497.0      1516.0      1516.0      1519.0      1509.0      1512.0      1514.0      1512.0      1509.0      1524.0      1524.0      1526.0      1525.0      1527.0      1527.0      1528.0      1528.0      1528.0      1528.0      1530.0      1528.0      1531.0      1531.0      1529.0      1529.0      1528.0      1530.0      1532.0      1533.0      1531.0      1533.0      1533.0      1533.0      1533.0      1532.0      1532.0      1534.0      1534.0      1536.0      1537.0      1539.0      1541.0      1538.0      1541.0      1534.0      1534.0      1537.0      1537.0      1539.0      1544.0      1544.0      1548.0      1549.0      1546.0      1546.0\n",
      "IXJ        1506.0      1507.0      1487.0      1506.0      1505.0      1509.0      1508.0      1508.0      1511.0      1510.0      1510.0      1510.0      1511.0      1517.0      1523.0      1521.0      1517.0      1515.0      1496.0      1519.0      1519.0      1516.0      1517.0      1523.0      1526.0      1525.0      1525.0      1528.0      1527.0      1527.0      1526.0      1530.0      1526.0      1528.0      1525.0      1525.0      1531.0      1511.0      1534.0      1534.0      1532.0      1531.0      1534.0      1533.0      1533.0      1535.0      1535.0      1533.0      1535.0      1536.0      1538.0      1536.0      1534.0      1534.0      1536.0      1538.0      1541.0      1541.0      1546.0      1546.0      1549.0      1546.0      1541.0      1540.0      1540.0      1546.0      1547.0      1548.0      1551.0      1546.0      1545.0      1549.0      1551.0      1552.0      1554.0      1553.0      1555.0      1554.0      1551.0      1548.0      1548.0      1544.0      1546.0      1546.0      1551.0      1551.0      1550.0      1550.0      1547.0      1548.0      1548.0      1549.0\n",
      "DON        1524.0      1525.0      1505.0      1526.0      1525.0      1526.0      1523.0      1526.0      1526.0      1527.0      1527.0      1526.0      1524.0      1525.0      1527.0      1527.0      1526.0      1528.0      1510.0      1532.0      1533.0      1531.0      1531.0      1531.0      1531.0      1531.0      1531.0      1532.0      1532.0      1533.0      1533.0      1535.0      1535.0      1535.0      1535.0      1535.0      1536.0      1516.0      1537.0      1537.0      1536.0      1534.0      1535.0      1537.0      1535.0      1540.0      1539.0      1536.0      1536.0      1535.0      1534.0      1535.0      1536.0      1536.0      1539.0      1539.0      1542.0      1543.0      1543.0      1543.0      1544.0      1543.0      1545.0      1546.0      1548.0      1548.0      1548.0      1551.0      1548.0      1547.0      1547.0      1546.0      1548.0      1548.0      1548.0      1549.0      1550.0      1549.0      1550.0      1550.0      1552.0      1550.0      1550.0      1545.0      1550.0      1549.0      1551.0      1551.0      1550.0      1551.0      1550.0      1552.0\n",
      "FV         1530.0      1531.0      1513.0      1531.0      1531.0      1530.0      1530.0      1529.0      1532.0      1531.0      1530.0      1532.0      1528.0      1529.0      1529.0      1530.0      1530.0      1530.0      1512.0      1534.0      1534.0      1532.0      1534.0      1535.0      1534.0      1533.0      1533.0      1533.0      1533.0      1535.0      1534.0      1536.0      1536.0      1537.0      1538.0      1538.0      1539.0      1520.0      1542.0      1542.0      1542.0      1539.0      1539.0      1543.0      1542.0      1541.0      1541.0      1541.0      1542.0      1542.0      1542.0      1542.0      1543.0      1542.0      1544.0      1544.0      1544.0      1545.0      1545.0      1545.0      1545.0      1545.0      1547.0      1547.0      1547.0      1550.0      1551.0      1550.0      1546.0      1548.0      1546.0      1548.0      1547.0      1551.0      1551.0      1551.0      1551.0      1553.0      1553.0      1553.0      1553.0      1554.0      1555.0      1554.0      1554.0      1555.0      1555.0      1555.0      1555.0      1556.0      1559.0      1559.0\n",
      "IYR        1551.0      1551.0      1533.0      1554.0      1545.0      1548.0      1554.0      1547.0      1548.0      1546.0      1532.0      1531.0      1525.0      1532.0      1538.0      1534.0      1537.0      1538.0      1521.0      1554.0      1557.0      1559.0      1544.0      1546.0      1539.0      1541.0      1540.0      1543.0      1539.0      1541.0      1537.0      1533.0      1530.0      1525.0      1526.0      1527.0      1530.0      1510.0      1530.0      1530.0      1530.0      1529.0      1529.0      1534.0      1532.0      1530.0      1525.0      1526.0      1534.0      1538.0      1544.0      1544.0      1542.0      1535.0      1534.0      1536.0      1546.0      1546.0      1549.0      1550.0      1548.0      1539.0      1540.0      1542.0      1543.0      1540.0      1539.0      1544.0      1543.0      1541.0      1541.0      1541.0      1545.0      1553.0      1553.0      1545.0      1535.0      1533.0      1539.0      1539.0      1536.0      1549.0      1553.0      1551.0      1552.0      1553.0      1554.0      1553.0      1558.0      1560.0      1560.0      1560.0\n",
      "\n",
      "[713 rows x 92 columns]\n",
      "\n",
      "New shape: (713, 92)\n"
     ]
    }
   ],
   "source": [
    "# 2. Print the original shape\n",
    "# df_rank_history.shape returns a tuple (number_of_rows, number_of_columns)\n",
    "print(\"\\nOriginal shape:\", df_rank_history.shape)\n",
    "\n",
    "# 3. Remove all rows with any NaN values\n",
    "# The dropna() method returns a new DataFrame by default\n",
    "df_rank_history_cleaned = df_rank_history.dropna()\n",
    "\n",
    "# 4. Print the new shape and the cleaned DataFrame\n",
    "print(\"\\nDataFrame after removing rows with any NaN values:\")\n",
    "print(df_rank_history_cleaned)\n",
    "\n",
    "print(\"\\nNew shape:\", df_rank_history_cleaned.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Calculate Metrics for All Tickers\n",
    "\n",
    "Process the rank history matrix to compute performance metrics for **every ticker**. This creates a master metrics DataFrame that serves as a single source of truth for all subsequent filtering and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 3: Calculating performance metrics for all tickers ---\n",
      "Calculating metrics for 1663 tickers...\n",
      "✅ Calculated metrics for 805 tickers.\n",
      "\n",
      "DataFrame head, now including 'r_squared' and 'penalty_score':\n",
      "        lookback_slope  r_squared  penalty_score  current  recent_start  lookback_start  lookback_end  best_lookback  worst_lookback  best_recent  worst_recent  best_total  worst_total  current_to_total_peak  current_to_recent_start  recent_bottom_to_recent_start  recent_bottom_to_current\n",
      "Ticker                                                                                                                                                                                                                                                                                           \n",
      "NVDA              0.00     0.0000         0.0000        1             1               1             1              1               1            1             1           1            1                      0                        0                              0                         0\n",
      "MSFT              0.00     0.0000         0.0000        2             2               2             2              2               2            2             2           2            2                      0                        0                              0                         0\n",
      "AAPL              0.00     0.0000         0.0000        3             3               3             3              3               3            3             3           3            3                      0                        0                              0                         0\n",
      "GOOGL            -0.03     0.3136         0.1009        4             5               5             5              4               6            4             5           4            6                      0                       -1                              0                         1\n",
      "GOOG             -0.03     0.2144         0.1508        5             4               6             4              4               6            4             5           4            6                      1                        1                              1                         0\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Step 3: Calculating performance metrics for all tickers ---\")\n",
    "\n",
    "# This call remains the same. It correctly passes the arguments to the new function.\n",
    "all_metrics_data = utils.calculate_rank_metrics( # Assuming it's in the same file, or use utils.\n",
    "    df_rank_history,\n",
    "    tickers_list=df_rank_history.index.tolist(),\n",
    "    **PERIOD_PARAMS\n",
    ")\n",
    "\n",
    "# Convert the list of dicts into a DataFrame.\n",
    "# The new 'r_squared' and 'penalty_score' keys will automatically become columns.\n",
    "df_all_tickers_metrics = pd.DataFrame(all_metrics_data)\n",
    "if not df_all_tickers_metrics.empty:\n",
    "    df_all_tickers_metrics.set_index('ticker', inplace=True)\n",
    "    df_all_tickers_metrics.index.name = 'Ticker'\n",
    "\n",
    "print(f\"✅ Calculated metrics for {len(df_all_tickers_metrics)} tickers.\")\n",
    "print(\"\\nDataFrame head, now including 'r_squared' and 'penalty_score':\")\n",
    "# display(df_all_tickers_metrics.head()) # Use display() in a notebook, or print()\n",
    "print(df_all_tickers_metrics.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Filter for 'Reversal' Candidates\n",
    "\n",
    "Apply the predefined filtering rules from the configuration cell to the master metrics DataFrame to identify a list of promising candidates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 4: Filtering metrics to find candidates ---\n",
      "METRIC_FILTERS\n",
      "{'current_rank_bracket_end': 1000,\n",
      " 'current_rank_bracket_start': 1,\n",
      " 'min_lookback_improvement': 0,\n",
      " 'min_recent_bottom_to_current': 0,\n",
      " 'min_recent_bottom_to_recent_start': 0}\n",
      "Filtering in 'Reversal' mode...\n",
      "✅ Found 300 candidates matching the criteria.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lookback_slope</th>\n",
       "      <th>r_squared</th>\n",
       "      <th>penalty_score</th>\n",
       "      <th>current</th>\n",
       "      <th>recent_start</th>\n",
       "      <th>lookback_start</th>\n",
       "      <th>lookback_end</th>\n",
       "      <th>best_lookback</th>\n",
       "      <th>worst_lookback</th>\n",
       "      <th>best_recent</th>\n",
       "      <th>worst_recent</th>\n",
       "      <th>best_total</th>\n",
       "      <th>worst_total</th>\n",
       "      <th>current_to_total_peak</th>\n",
       "      <th>current_to_recent_start</th>\n",
       "      <th>recent_bottom_to_recent_start</th>\n",
       "      <th>recent_bottom_to_current</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BG</th>\n",
       "      <td>-7.45</td>\n",
       "      <td>0.6678</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>779</td>\n",
       "      <td>768</td>\n",
       "      <td>1014</td>\n",
       "      <td>742</td>\n",
       "      <td>742</td>\n",
       "      <td>1069</td>\n",
       "      <td>768</td>\n",
       "      <td>804</td>\n",
       "      <td>742</td>\n",
       "      <td>1069</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COOP</th>\n",
       "      <td>-5.24</td>\n",
       "      <td>0.7874</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>900</td>\n",
       "      <td>954</td>\n",
       "      <td>1096</td>\n",
       "      <td>939</td>\n",
       "      <td>921</td>\n",
       "      <td>1120</td>\n",
       "      <td>900</td>\n",
       "      <td>998</td>\n",
       "      <td>900</td>\n",
       "      <td>1120</td>\n",
       "      <td>0</td>\n",
       "      <td>-54</td>\n",
       "      <td>44</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHRW</th>\n",
       "      <td>-4.29</td>\n",
       "      <td>0.8162</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>848</td>\n",
       "      <td>840</td>\n",
       "      <td>982</td>\n",
       "      <td>831</td>\n",
       "      <td>831</td>\n",
       "      <td>987</td>\n",
       "      <td>830</td>\n",
       "      <td>851</td>\n",
       "      <td>830</td>\n",
       "      <td>987</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CX</th>\n",
       "      <td>-3.99</td>\n",
       "      <td>0.8843</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>868</td>\n",
       "      <td>898</td>\n",
       "      <td>1050</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>1050</td>\n",
       "      <td>868</td>\n",
       "      <td>898</td>\n",
       "      <td>868</td>\n",
       "      <td>1050</td>\n",
       "      <td>0</td>\n",
       "      <td>-30</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INCY</th>\n",
       "      <td>-3.96</td>\n",
       "      <td>0.8196</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>777</td>\n",
       "      <td>789</td>\n",
       "      <td>886</td>\n",
       "      <td>771</td>\n",
       "      <td>761</td>\n",
       "      <td>905</td>\n",
       "      <td>767</td>\n",
       "      <td>798</td>\n",
       "      <td>761</td>\n",
       "      <td>905</td>\n",
       "      <td>16</td>\n",
       "      <td>-12</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BWXT</th>\n",
       "      <td>-3.72</td>\n",
       "      <td>0.6305</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>845</td>\n",
       "      <td>826</td>\n",
       "      <td>893</td>\n",
       "      <td>832</td>\n",
       "      <td>769</td>\n",
       "      <td>931</td>\n",
       "      <td>826</td>\n",
       "      <td>851</td>\n",
       "      <td>769</td>\n",
       "      <td>931</td>\n",
       "      <td>76</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFI</th>\n",
       "      <td>-3.65</td>\n",
       "      <td>0.7210</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>483</td>\n",
       "      <td>502</td>\n",
       "      <td>651</td>\n",
       "      <td>505</td>\n",
       "      <td>505</td>\n",
       "      <td>651</td>\n",
       "      <td>483</td>\n",
       "      <td>522</td>\n",
       "      <td>483</td>\n",
       "      <td>651</td>\n",
       "      <td>0</td>\n",
       "      <td>-19</td>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNN</th>\n",
       "      <td>-3.29</td>\n",
       "      <td>0.7246</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>784</td>\n",
       "      <td>799</td>\n",
       "      <td>888</td>\n",
       "      <td>789</td>\n",
       "      <td>789</td>\n",
       "      <td>904</td>\n",
       "      <td>784</td>\n",
       "      <td>803</td>\n",
       "      <td>784</td>\n",
       "      <td>904</td>\n",
       "      <td>0</td>\n",
       "      <td>-15</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KGC</th>\n",
       "      <td>-3.09</td>\n",
       "      <td>0.7487</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>542</td>\n",
       "      <td>584</td>\n",
       "      <td>714</td>\n",
       "      <td>589</td>\n",
       "      <td>589</td>\n",
       "      <td>714</td>\n",
       "      <td>542</td>\n",
       "      <td>592</td>\n",
       "      <td>542</td>\n",
       "      <td>714</td>\n",
       "      <td>0</td>\n",
       "      <td>-42</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TER</th>\n",
       "      <td>-3.08</td>\n",
       "      <td>0.7128</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>721</td>\n",
       "      <td>715</td>\n",
       "      <td>828</td>\n",
       "      <td>713</td>\n",
       "      <td>713</td>\n",
       "      <td>849</td>\n",
       "      <td>707</td>\n",
       "      <td>721</td>\n",
       "      <td>707</td>\n",
       "      <td>849</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CIEN</th>\n",
       "      <td>-2.73</td>\n",
       "      <td>0.6417</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>782</td>\n",
       "      <td>925</td>\n",
       "      <td>972</td>\n",
       "      <td>918</td>\n",
       "      <td>880</td>\n",
       "      <td>1017</td>\n",
       "      <td>782</td>\n",
       "      <td>925</td>\n",
       "      <td>782</td>\n",
       "      <td>1017</td>\n",
       "      <td>0</td>\n",
       "      <td>-143</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OHI</th>\n",
       "      <td>-2.68</td>\n",
       "      <td>0.9046</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>941</td>\n",
       "      <td>950</td>\n",
       "      <td>1024</td>\n",
       "      <td>935</td>\n",
       "      <td>932</td>\n",
       "      <td>1042</td>\n",
       "      <td>941</td>\n",
       "      <td>958</td>\n",
       "      <td>932</td>\n",
       "      <td>1042</td>\n",
       "      <td>9</td>\n",
       "      <td>-9</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EBAY</th>\n",
       "      <td>-2.58</td>\n",
       "      <td>0.8863</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>386</td>\n",
       "      <td>377</td>\n",
       "      <td>450</td>\n",
       "      <td>363</td>\n",
       "      <td>356</td>\n",
       "      <td>450</td>\n",
       "      <td>377</td>\n",
       "      <td>394</td>\n",
       "      <td>356</td>\n",
       "      <td>450</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLY</th>\n",
       "      <td>-2.51</td>\n",
       "      <td>0.8499</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>876</td>\n",
       "      <td>899</td>\n",
       "      <td>964</td>\n",
       "      <td>888</td>\n",
       "      <td>884</td>\n",
       "      <td>986</td>\n",
       "      <td>876</td>\n",
       "      <td>904</td>\n",
       "      <td>876</td>\n",
       "      <td>986</td>\n",
       "      <td>0</td>\n",
       "      <td>-23</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AU</th>\n",
       "      <td>-2.40</td>\n",
       "      <td>0.7236</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>495</td>\n",
       "      <td>530</td>\n",
       "      <td>612</td>\n",
       "      <td>525</td>\n",
       "      <td>506</td>\n",
       "      <td>612</td>\n",
       "      <td>495</td>\n",
       "      <td>536</td>\n",
       "      <td>495</td>\n",
       "      <td>612</td>\n",
       "      <td>0</td>\n",
       "      <td>-35</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FSLR</th>\n",
       "      <td>-2.37</td>\n",
       "      <td>0.6566</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>655</td>\n",
       "      <td>663</td>\n",
       "      <td>766</td>\n",
       "      <td>647</td>\n",
       "      <td>602</td>\n",
       "      <td>766</td>\n",
       "      <td>650</td>\n",
       "      <td>673</td>\n",
       "      <td>602</td>\n",
       "      <td>766</td>\n",
       "      <td>53</td>\n",
       "      <td>-8</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALLE</th>\n",
       "      <td>-2.27</td>\n",
       "      <td>0.7736</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>850</td>\n",
       "      <td>847</td>\n",
       "      <td>930</td>\n",
       "      <td>848</td>\n",
       "      <td>844</td>\n",
       "      <td>931</td>\n",
       "      <td>847</td>\n",
       "      <td>862</td>\n",
       "      <td>844</td>\n",
       "      <td>931</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WDC</th>\n",
       "      <td>-2.22</td>\n",
       "      <td>0.7942</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>478</td>\n",
       "      <td>534</td>\n",
       "      <td>613</td>\n",
       "      <td>523</td>\n",
       "      <td>523</td>\n",
       "      <td>615</td>\n",
       "      <td>478</td>\n",
       "      <td>536</td>\n",
       "      <td>478</td>\n",
       "      <td>615</td>\n",
       "      <td>0</td>\n",
       "      <td>-56</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VTRS</th>\n",
       "      <td>-2.21</td>\n",
       "      <td>0.4465</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>977</td>\n",
       "      <td>964</td>\n",
       "      <td>1030</td>\n",
       "      <td>945</td>\n",
       "      <td>934</td>\n",
       "      <td>1060</td>\n",
       "      <td>958</td>\n",
       "      <td>980</td>\n",
       "      <td>934</td>\n",
       "      <td>1060</td>\n",
       "      <td>43</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZG</th>\n",
       "      <td>-2.12</td>\n",
       "      <td>0.8174</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>660</td>\n",
       "      <td>672</td>\n",
       "      <td>753</td>\n",
       "      <td>671</td>\n",
       "      <td>664</td>\n",
       "      <td>757</td>\n",
       "      <td>660</td>\n",
       "      <td>697</td>\n",
       "      <td>660</td>\n",
       "      <td>757</td>\n",
       "      <td>0</td>\n",
       "      <td>-12</td>\n",
       "      <td>25</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lookback_slope  r_squared  penalty_score  current  recent_start  lookback_start  lookback_end  best_lookback  worst_lookback  best_recent  worst_recent  best_total  worst_total  current_to_total_peak  current_to_recent_start  recent_bottom_to_recent_start  recent_bottom_to_current\n",
       "Ticker                                                                                                                                                                                                                                                                                           \n",
       "BG               -7.45     0.6678         0.0130      779           768            1014           742            742            1069          768           804         742         1069                     37                       11                             36                        25\n",
       "COOP             -5.24     0.7874         0.0050      900           954            1096           939            921            1120          900           998         900         1120                      0                      -54                             44                        98\n",
       "CHRW             -4.29     0.8162         0.0035      848           840             982           831            831             987          830           851         830          987                     18                        8                             11                         3\n",
       "CX               -3.99     0.8843         0.0012      868           898            1050           891            891            1050          868           898         868         1050                      0                      -30                              0                        30\n",
       "INCY             -3.96     0.8196         0.0027      777           789             886           771            761             905          767           798         761          905                     16                      -12                              9                        21\n",
       "BWXT             -3.72     0.6305         0.0075      845           826             893           832            769             931          826           851         769          931                     76                       19                             25                         6\n",
       "GFI              -3.65     0.7210         0.0066      483           502             651           505            505             651          483           522         483          651                      0                      -19                             20                        39\n",
       "SNN              -3.29     0.7246         0.0044      784           799             888           789            789             904          784           803         784          904                      0                      -15                              4                        19\n",
       "KGC              -3.09     0.7487         0.0054      542           584             714           589            589             714          542           592         542          714                      0                      -42                              8                        50\n",
       "TER              -3.08     0.7128         0.0061      721           715             828           713            713             849          707           721         707          849                     14                        6                              6                         0\n",
       "CIEN             -2.73     0.6417         0.0049      782           925             972           918            880            1017          782           925         782         1017                      0                     -143                              0                       143\n",
       "OHI              -2.68     0.9046         0.0010      941           950            1024           935            932            1042          941           958         932         1042                      9                       -9                              8                        17\n",
       "EBAY             -2.58     0.8863         0.0024      386           377             450           363            356             450          377           394         356          450                     30                        9                             17                         8\n",
       "NLY              -2.51     0.8499         0.0016      876           899             964           888            884             986          876           904         876          986                      0                      -23                              5                        28\n",
       "AU               -2.40     0.7236         0.0062      495           530             612           525            506             612          495           536         495          612                      0                      -35                              6                        41\n",
       "FSLR             -2.37     0.6566         0.0104      655           663             766           647            602             766          650           673         602          766                     53                       -8                             10                        18\n",
       "ALLE             -2.27     0.7736         0.0024      850           847             930           848            844             931          847           862         844          931                      6                        3                             15                        12\n",
       "WDC              -2.22     0.7942         0.0040      478           534             613           523            523             615          478           536         478          615                      0                      -56                              2                        58\n",
       "VTRS             -2.21     0.4465         0.0069      977           964            1030           945            934            1060          958           980         934         1060                     43                       13                             16                         3\n",
       "ZG               -2.12     0.8174         0.0029      660           672             753           671            664             757          660           697         660          757                      0                      -12                             25                        37"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"--- Step 4: Filtering metrics to find candidates ---\")\n",
    "print(\"METRIC_FILTERS\")\n",
    "pprint.pprint(METRIC_FILTERS)\n",
    "\n",
    "# Use the utility function, passing only the relevant filter arguments.\n",
    "# This is now much cleaner than the previous version.\n",
    "df_filtered_candidates = utils.filter_rank_metrics(\n",
    "    df_all_tickers_metrics,\n",
    "    **METRIC_FILTERS\n",
    ")\n",
    "\n",
    "print(f\"✅ Found {len(df_filtered_candidates)} candidates matching the criteria.\")\n",
    "display(df_filtered_candidates.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Enhance, Sort, and Select Top Candidates\n",
    "\n",
    "Enrich the filtered candidates with the latest price data, sort them according to the specified rules, and select the top N for visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 5: Applying the Tiered Filtering & Ranking Funnel ---\n",
      "Starting with 300 initial candidates.\n",
      "-> 300 candidates remain after Slope Filter (lookback_slope < 100).\n",
      "-> 300 candidates remain after R-Squared Filter (r_squared > -10).\n",
      "\n",
      "==================================================\n",
      "      FINAL CANDIDATE REPORT (TIERED FUNNEL)\n",
      "==================================================\n",
      "\n",
      "Funnel Filter Parameters:\n",
      "  - Minimum Slope: 100\n",
      "  - Minimum R-Squared: -10\n",
      "\n",
      "Applied Metric Filters (from earlier steps):\n",
      "{'min_lookback_improvement': 0,\n",
      " 'current_rank_bracket_start': 1,\n",
      " 'current_rank_bracket_end': 1000,\n",
      " 'min_recent_bottom_to_recent_start': 0,\n",
      " 'min_recent_bottom_to_current': 0}\n",
      "\n",
      "Sorting Order (Primary: Penalty Score):\n",
      "{'lookback_slope': True,\n",
      " 'r_squared': False,\n",
      " 'penalty_score': True,\n",
      " 'Change/(ATR/Price)': False}\n",
      "\n",
      "Number of Tickers selected for plotting: : 300\n",
      "\n",
      "Tickers selected for plotting: ['BG', 'COOP', 'CHRW', 'CX', 'INCY', 'BWXT', 'GFI', 'SNN', 'KGC', 'TER', 'CIEN', 'OHI', 'EBAY', 'NLY', 'AU', 'FSLR', 'ALLE', 'WDC', 'VTRS', 'ZG', 'PTC', 'SNPS', 'HUM', 'ICLR', 'LECO', 'SGI', 'DB', 'PHM', 'CG', 'DHI', 'IDXX', 'EXPE', 'SJM', 'IBKR', 'GMAB', 'UAL', 'GDX', 'CMI', 'FN', 'TPR', 'J', 'CRH', 'XLU', 'LEN', 'NEM', 'RYAAY', 'B', 'ZBH', 'NOC', 'TEL', 'CBRE', 'BBVA', 'BF-B', 'MANH', 'IQV', 'ADM', 'ROST', 'ANET', 'LDOS', 'DLTR', 'FE', 'FFIV', 'ETR', 'CYBR', 'MPWR', 'DAL', 'WDS', 'URI', 'ULTA', 'RMD', 'CNA', 'AEG', 'FNF', 'ORLY', 'FAST', 'LNT', 'EA', 'SPLG', 'AZO', 'NI', 'WYNN', 'CSGP', 'BCS', 'MSI', 'BKR', 'BK', 'VIV', 'XEL', 'POOL', 'BCE', 'EIX', 'PPL', 'BR', 'SPEM', 'RDVY', 'GRMN', 'ACM', 'LYG', 'IEI', 'IWY', 'BTI', 'VMC', 'SRE', 'TSCO', 'SPSM', 'LOGI', 'LYV', 'BP', 'VOD', 'AEP', 'PUK', 'STX', 'SLV', 'EVRG', 'HYG', 'MGK', 'NSC', 'DEO', 'CDNS', 'CNP', 'D', 'MO', 'SPHQ', 'EFV', 'HPQ', 'TROW', 'TRMB', 'UBS', 'WPM', 'UTHR', 'WEC', 'AMX', 'BIV', 'AWK', 'SWK', 'IYW', 'LHX', 'CSX', 'LOW', 'ERIE', 'SMFG', 'SAN', 'WTW', 'WPC', 'HMC', 'GPN', 'SCHG', 'DTE', 'EL', 'E', 'TMO', 'ITOT', 'VT', 'RIO', 'FNDF', 'SPDW', 'PODD', 'XLK', 'IVW', 'OEF', 'OC', 'VEU', 'XLI', 'FBND', 'NDAQ', 'GM', 'MNST', 'AMD', 'APTV', 'SPYG', 'AON', 'NUE', 'XLP', 'SCHB', 'EEM', 'PEP', 'AZN', 'VYM', 'BX', 'ECL', 'RJF', 'VONV', 'SSNC', 'IMO', 'GEN', 'STE', 'CVX', 'CMS', 'AEE', 'RF', 'USIG', 'SLB', 'ENB', 'IUSG', 'TM', 'VO', 'REGN', 'CCL', 'MUFG', 'IUSB', 'BHP', 'ING', 'EXC', 'ESLT', 'IAU', 'EFA', 'IXUS', 'FNDX', 'TEF', 'OMC', 'BIIB', 'RTX', 'FERG', 'GILD', 'SCHA', 'SCHX', 'VXUS', 'CAT', 'VTIP', 'IJR', 'VV', 'DGRO', 'IEF', 'SPYV', 'EW', 'MDT', 'MCD', 'SONY', 'IGIB', 'CVS', 'IWF', 'VGT', 'TCOM', 'BLK', 'VZ', 'SHW', 'SCHD', 'HSBC', 'CINF', 'GSK', 'CFG', 'XLF', 'TS', 'MBB', 'SCHF', 'APD', 'IEFA', 'IEMG', 'NKE', 'VB', 'VOT', 'VONG', 'PAG', 'TMUS', 'BNDX', 'DHR', 'SPMD', 'MRK', 'IWB', 'DGRW', 'L', 'GE', 'STT', 'ACGL', 'T', 'COP', 'KKR', 'WBD', 'ABBV', 'MINT', 'ORCL', 'IWD', 'SNY', 'BA', 'TSLA', 'EXPD', 'VOO', 'IVV', 'RSP', 'ED', 'GOOGL', 'GOOG', 'QQQ', 'MS', 'LIN', 'VWO', 'IVE', 'NWS', 'WMT', 'VTI', 'JNJ', 'HD', 'VTV', 'BND', 'MMM', 'VGK', 'NVS', 'SCHV', 'VNQ', 'SCHM']\n"
     ]
    }
   ],
   "source": [
    "# Assuming the following columns have been calculated earlier for each stock\n",
    "# and are present in df_filtered_candidates:\n",
    "# - 'slope': The slope of the regression line (higher is better).\n",
    "# - 'r_squared': The R-squared value (higher is better).\n",
    "# - 'penalty_score': The combined penalty score (lower is better).\n",
    "\n",
    "print(\"--- Step 5: Applying the Tiered Filtering & Ranking Funnel ---\")\n",
    "\n",
    "# --- Funnel Strategy Parameters (you can tune these) ---\n",
    "# SLOPE_THRESHOLD = -1.0      # Viability: Trend must be meaningfully positive.\n",
    "# R_SQUARED_THRESHOLD = 0.75  # Reliability: Trend must be consistent and not random.\n",
    "SLOPE_THRESHOLD = 100      # Viability: Trend must be meaningfully positive.\n",
    "R_SQUARED_THRESHOLD = -10  # Reliability: Trend must be consistent and not random.\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# ### MODIFICATION START: Replaced the original sorting logic with the funnel ###\n",
    "# ==============================================================================\n",
    "\n",
    "# --- Step 1: The Viability Filter (using Slope) ---\n",
    "print(f\"Starting with {len(df_filtered_candidates)} initial candidates.\")\n",
    "df_funnel_step1 = df_filtered_candidates[df_filtered_candidates['lookback_slope'] < SLOPE_THRESHOLD]\n",
    "print(f\"-> {len(df_funnel_step1)} candidates remain after Slope Filter (lookback_slope < {SLOPE_THRESHOLD}).\")\n",
    "\n",
    "\n",
    "# --- Step 2: The Reliability Filter (using R-Squared) ---\n",
    "df_funnel_step2 = df_funnel_step1[df_funnel_step1['r_squared'] > R_SQUARED_THRESHOLD]\n",
    "print(f\"-> {len(df_funnel_step2)} candidates remain after R-Squared Filter (r_squared > {R_SQUARED_THRESHOLD}).\")\n",
    "df_funnel_candidates = df_funnel_step2\n",
    "\n",
    "# --- Step 3: Enhance, Calculate, and Rank the High-Quality Candidates ---\n",
    "# Join with latest Finviz data to add Price, MktCap, etc.\n",
    "cols_to_add = ['Price', 'Change %', 'MktCap AUM, M', 'ATR/Price %', 'Rel Volume']\n",
    "# Use .loc to avoid potential SettingWithCopyWarning\n",
    "df_candidates_enhanced = df_funnel_candidates.join(df_finviz_latest[cols_to_add])\n",
    "\n",
    "# Calculate the new 'Change/(ATR/Price)' metric\n",
    "df_candidates_enhanced['Change/(ATR/Price)'] = np.where(\n",
    "    df_candidates_enhanced['ATR/Price %'] != 0,\n",
    "    df_candidates_enhanced['Change %'] / df_candidates_enhanced['ATR/Price %'],\n",
    "    0\n",
    ")\n",
    "\n",
    "# --- Define the NEW Sorting Order based on the Funnel Philosophy ---\n",
    "# The primary sort is now by 'penalty_score'. Other metrics act as tie-breakers.\n",
    "# This replaces your original SORT_ORDER.\n",
    "SORT_ORDER_FUNNEL = {\n",
    "    'lookback_slope': True,             # Lower is better (steeper improving trend) - PRIMARY SORT    \n",
    "    'r_squared': False,                 # Higher is better (stronger growth) - TIE BREAKER 1    \n",
    "    'penalty_score': True,              # Lower is better (smoother, more linear trend) - TIE BREAKER 2\n",
    "    'Change/(ATR/Price)': False,        # Higher is better (strong recent momentum) - TIE BREAKER 3  \n",
    "}\n",
    "\n",
    "sort_keys = list(SORT_ORDER_FUNNEL.keys())\n",
    "sort_ascending = list(SORT_ORDER_FUNNEL.values())\n",
    "\n",
    "# Apply the new sorting logic\n",
    "df_sorted_candidates = df_candidates_enhanced.sort_values(by=sort_keys, ascending=sort_ascending)\n",
    "\n",
    "# ==============================================================================\n",
    "# ### MODIFICATION END ###\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "# --- Define and Apply Final Column Order (your existing logic is great here) ---\n",
    "leading_cols = [\n",
    "    'MktCap AUM, M', 'Price', 'Change %', 'ATR/Price %', 'Change/(ATR/Price)', 'Rel Volume',\n",
    "    'lookback_slope', 'r_squared', 'penalty_score' # Add our key metrics to the front\n",
    "]\n",
    "priority_cols = list(dict.fromkeys(leading_cols + sort_keys))\n",
    "remaining_cols = [c for c in df_sorted_candidates.columns if c not in priority_cols]\n",
    "final_col_order = priority_cols + remaining_cols\n",
    "df_sorted_candidates = df_sorted_candidates[final_col_order]\n",
    "\n",
    "\n",
    "# --- Select Top Candidates for Plotting ---\n",
    "\n",
    "####################################\n",
    "# tickers_to_plot = df_sorted_candidates.head(CANDIDATES_TO_PLOT).index.tolist()\n",
    "tickers_to_plot = df_sorted_candidates.index.tolist()\n",
    "####################################\n",
    "\n",
    "\n",
    "# --- Display Final Results with Context ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"      FINAL CANDIDATE REPORT (TIERED FUNNEL)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nFunnel Filter Parameters:\")\n",
    "print(f\"  - Minimum Slope: {SLOPE_THRESHOLD}\")\n",
    "print(f\"  - Minimum R-Squared: {R_SQUARED_THRESHOLD}\")\n",
    "\n",
    "print(\"\\nApplied Metric Filters (from earlier steps):\")\n",
    "pprint.pprint(METRIC_FILTERS, sort_dicts=False)\n",
    "\n",
    "print(\"\\nSorting Order (Primary: Penalty Score):\")\n",
    "pprint.pprint(SORT_ORDER_FUNNEL, sort_dicts=False)\n",
    "\n",
    "# print(f\"\\nDisplaying Top {CANDIDATES_TO_PLOT} Candidates from Funnel:\")\n",
    "# display(df_sorted_candidates.head(CANDIDATES_TO_PLOT))\n",
    "\n",
    "print(f\"\\nNumber of Tickers selected for plotting: : {len(tickers_to_plot)}\")\n",
    "print(f\"\\nTickers selected for plotting: {tickers_to_plot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['META'], dtype='object', name='Ticker')] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# tickers_to_view = ['NVDA', 'META', 'MSFT', 'B', 'GOOG', 'AVGO']\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# tickers_to_view = ['LYG', 'IEI']\u001b[39;00m\n\u001b[32m      3\u001b[39m tickers_to_view = [\u001b[33m'\u001b[39m\u001b[33mMETA\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mdf_sorted_candidates\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtickers_to_view\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# df_sorted_candidates\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1189\u001b[39m maybe_callable = com.apply_if_callable(key, \u001b[38;5;28mself\u001b[39m.obj)\n\u001b[32m   1190\u001b[39m maybe_callable = \u001b[38;5;28mself\u001b[39m._check_deprecated_callable_usage(key, maybe_callable)\n\u001b[32m-> \u001b[39m\u001b[32m1191\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1420\u001b[39m, in \u001b[36m_LocIndexer._getitem_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1417\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[33m\"\u001b[39m\u001b[33mndim\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key.ndim > \u001b[32m1\u001b[39m:\n\u001b[32m   1418\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot index with multidimensional key\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1420\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1422\u001b[39m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[32m   1423\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1360\u001b[39m, in \u001b[36m_LocIndexer._getitem_iterable\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1357\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_key(key, axis)\n\u001b[32m   1359\u001b[39m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1360\u001b[39m keyarr, indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1361\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj._reindex_with_indexers(\n\u001b[32m   1362\u001b[39m     {axis: [keyarr, indexer]}, copy=\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1363\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1558\u001b[39m, in \u001b[36m_LocIndexer._get_listlike_indexer\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1555\u001b[39m ax = \u001b[38;5;28mself\u001b[39m.obj._get_axis(axis)\n\u001b[32m   1556\u001b[39m axis_name = \u001b[38;5;28mself\u001b[39m.obj._get_axis_name(axis)\n\u001b[32m-> \u001b[39m\u001b[32m1558\u001b[39m keyarr, indexer = \u001b[43max\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1560\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6198\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6200\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6202\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6204\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6247\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[32m   6248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m nmissing == \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[32m-> \u001b[39m\u001b[32m6249\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6251\u001b[39m     not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m   6252\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"None of [Index(['META'], dtype='object', name='Ticker')] are in the [index]\""
     ]
    }
   ],
   "source": [
    "# tickers_to_view = ['NVDA', 'META', 'MSFT', 'B', 'GOOG', 'AVGO']\n",
    "# tickers_to_view = ['LYG', 'IEI']\n",
    "tickers_to_view = ['META']\n",
    "df_sorted_candidates.loc[tickers_to_view]\n",
    "# df_sorted_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Step 5: Enhancing and sorting final candidates ---\")\n",
    "\n",
    "# Join with latest Finviz data to add Price, MktCap, etc.\n",
    "cols_to_add = ['Price', 'Change %', 'MktCap AUM, M', 'ATR/Price %', 'Rel Volume']\n",
    "df_candidates_enhanced = df_filtered_candidates.join(df_finviz_latest[cols_to_add])\n",
    "\n",
    "# --- Calculate New Metrics ---\n",
    "# Create a normalized change metric by dividing the daily change by its recent volatility (ATR).\n",
    "# This gives a sense of how significant the day's move is relative to its own behavior.\n",
    "df_candidates_enhanced['Change/(ATR/Price)'] = np.where(\n",
    "    df_candidates_enhanced['ATR/Price %'] != 0,\n",
    "    df_candidates_enhanced['Change %'] / df_candidates_enhanced['ATR/Price %'],\n",
    "    0  # Assign 0 if ATR/Price % is 0 to avoid division errors\n",
    ")\n",
    "\n",
    "# Sort the candidates based on the rules in the SORT_ORDER dictionary\n",
    "sort_keys = list(SORT_ORDER.keys())\n",
    "sort_ascending = list(SORT_ORDER.values())\n",
    "df_sorted_candidates = df_candidates_enhanced.sort_values(by=sort_keys, ascending=sort_ascending)\n",
    "\n",
    "# --- Define and Apply Final Column Order ---\n",
    "# Define the columns that should always appear first, including our new metric.\n",
    "leading_cols = [\n",
    "    'MktCap AUM, M', 'Price', 'Change %', 'ATR/Price %', 'Change/(ATR/Price)', 'Rel Volume', 'current',\n",
    "]\n",
    "\n",
    "# Combine the leading columns with the sort keys for the master order.\n",
    "priority_cols = list(dict.fromkeys(leading_cols + sort_keys))\n",
    "remaining_cols = [c for c in df_sorted_candidates.columns if c not in priority_cols]\n",
    "final_col_order = priority_cols + remaining_cols\n",
    "df_sorted_candidates = df_sorted_candidates[final_col_order]\n",
    "\n",
    "# --- Select Top Candidates for Plotting ---\n",
    "tickers_to_plot = df_sorted_candidates.head(CANDIDATES_TO_PLOT).index.tolist()\n",
    "\n",
    "# --- Display Final Results with Context ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"      FINAL CANDIDATE REPORT\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nPeriod Parameters (for calculation):\")\n",
    "pprint.pprint(PERIOD_PARAMS)\n",
    "\n",
    "print(\"\\nApplied Metric Filters:\")\n",
    "pprint.pprint(METRIC_FILTERS, sort_dicts=False)\n",
    "\n",
    "print(\"\\nSorting Order:\")\n",
    "pprint.pprint(SORT_ORDER, sort_dicts=False)\n",
    "\n",
    "print(f\"\\nDisplaying Top {CANDIDATES_TO_PLOT} Candidates:\")\n",
    "display(df_sorted_candidates.head(CANDIDATES_TO_PLOT))\n",
    "\n",
    "print(f\"\\nTickers selected for plotting: {tickers_to_plot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'df_finviz_latest.info():\\n{df_finviz_latest.info()}')\n",
    "# print(f'\\ndf_finviz_latest.columns:\\n{df_finviz_latest.columns}')\n",
    "print(f'\\ndf_finviz_latest.columns:\\n{list(df_finviz_latest.columns)}')\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "#     # 'display.max_rows' controls the truncation of the Index/Series representation\n",
    "#     # 'display.max_columns' is good to include for printing the full DataFrame\n",
    "#     print(f'\\ndf_finviz_latest.columns:\\n{df_finviz_latest.columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Sort the DataFrame by the index using the desired order ---\n",
    "# Use .loc with the list of valid, ordered tickers\n",
    "# df_finviz_latest_sorted = df_finviz_latest.loc[valid_tickers_in_order_unique]\n",
    "df_finviz_tickers_to_plot = df_finviz_latest.loc[tickers_to_plot]\n",
    "print(f'df_finviz_tickers_to_plot:\\n{df_finviz_tickers_to_plot}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Visualize Top Candidates\n",
    "\n",
    "Plot the rank history for the top candidates to visually verify their performance and trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Step 6: Plotting rank history for top candidates ---\")\n",
    "\n",
    "if tickers_to_plot:\n",
    "    plot_days = PERIOD_PARAMS['lookback_days'] + PERIOD_PARAMS['recent_days'] + 10\n",
    "    # Combine both dictionaries for complete context in the plot's annotation\n",
    "    full_criteria_for_plot = {**PERIOD_PARAMS, **METRIC_FILTERS}\n",
    "    \n",
    "    plotting_utils.plot_rank_with_criteria(\n",
    "        df_rank_history=df_rank_history.iloc[:, -plot_days:],\n",
    "        ticker_list=tickers_to_plot,\n",
    "        title_suffix=\"Top Filtered Candidates\",\n",
    "        filter_criteria=full_criteria_for_plot, # Pass the combined dict\n",
    "        width=1150,\n",
    "        height=700,\n",
    "    )\n",
    "else:\n",
    "    print(\"No candidates found to plot.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_sorted_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Analyze Pre-defined Portfolio\n",
    "\n",
    "Perform a detailed analysis on a specific list of tickers. This step correctly uses the master `df_all_tickers_metrics` DataFrame to ensure all portfolio tickers are included, regardless of filter outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted_candidates.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Step 7: Analyzing the pre-defined portfolio ---\")\n",
    "\n",
    "# Correctly filter the *master* metrics dataframe for the portfolio tickers\n",
    "df_portfolio_analysis  = df_sorted_candidates[df_sorted_candidates.index.isin(PORTFOLIO_TICKERS)].copy()\n",
    "\n",
    "# Calculate portfolio weights, only if the dataframe is not empty\n",
    "if not df_portfolio_analysis.empty:\n",
    "    total_aum = df_portfolio_analysis['MktCap AUM, M'].sum()\n",
    "    inv_atr = 1 / df_portfolio_analysis['ATR/Price %']\n",
    "    total_inv_atr = inv_atr.sum()\n",
    "\n",
    "    df_portfolio_analysis['MktCap AUM Weight'] = df_portfolio_analysis['MktCap AUM, M'] / total_aum\n",
    "    df_portfolio_analysis['ATR/Price INV Weight'] = (inv_atr / total_inv_atr)\n",
    "\n",
    "    total_portf = df_portfolio_analysis['MktCap AUM Weight'].sum() + df_portfolio_analysis['ATR/Price INV Weight'].sum()\n",
    "    df_portfolio_analysis['Portf Weight'] = (df_portfolio_analysis['MktCap AUM Weight'] + df_portfolio_analysis['ATR/Price INV Weight']) / total_portf\n",
    "\n",
    "    # --- Define and Apply Final Column Order ---\n",
    "    # The new columns to be inserted\n",
    "    new_cols = ['MktCap AUM Weight', 'ATR/Price INV Weight', 'Portf Weight']\n",
    "\n",
    "    # Convert the original column Index to a list for easy manipulation\n",
    "    original_cols = list(df_sorted_candidates.columns)\n",
    "\n",
    "    # Find the index of the column to insert after\n",
    "    try:\n",
    "        # Find the integer position of the 'current' column\n",
    "        insert_index = original_cols.index('current') + 1 \n",
    "    except ValueError:\n",
    "        # Handle the case where 'current' isn't in the columns, perhaps append to the end\n",
    "        print(\"Warning: 'current' column not found. Appending new columns to the end.\")\n",
    "        insert_index = len(original_cols)\n",
    "\n",
    "    # Reconstruct the list with the new columns inserted\n",
    "    PORTFOLIO_COLUMN_ORDER = original_cols[:insert_index] + new_cols + original_cols[insert_index:]\n",
    "\n",
    "    # Filter the desired order to only include columns that actually exist in the DataFrame\n",
    "    # This makes the code robust against missing data columns.\n",
    "    final_portfolio_cols = [c for c in PORTFOLIO_COLUMN_ORDER if c in df_portfolio_analysis.columns]\n",
    "    df_portfolio_analysis = df_portfolio_analysis[final_portfolio_cols]\n",
    "\n",
    "print(f\"✅ Portfolio analysis complete for {len(df_portfolio_analysis)} tickers.\")\n",
    "print(\"Portfolio metrics, sorted by final portfolio weight:\")\n",
    "print(df_portfolio_analysis.sort_values(by='Portf Weight', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Visualize Portfolio\n",
    "\n",
    "Plot the rank history for the tickers in the pre-defined portfolio to compare their recent performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Step 8: Plotting rank history for the portfolio ---\")\n",
    "\n",
    "if PORTFOLIO_TICKERS:\n",
    "    plot_days = PERIOD_PARAMS['lookback_days'] + PERIOD_PARAMS['recent_days'] + 10\n",
    "    # Combine both dictionaries for complete context in the plot's annotation\n",
    "    full_criteria_for_plot = {**PERIOD_PARAMS, **METRIC_FILTERS}\n",
    "    \n",
    "    plotting_utils.plot_rank_with_criteria(\n",
    "        df_rank_history=df_rank_history.iloc[:, -plot_days:],\n",
    "        ticker_list=PORTFOLIO_TICKERS,\n",
    "        title_suffix=\"Pre-defined Portfolio\",\n",
    "        filter_criteria=full_criteria_for_plot, # Pass the combined dict\n",
    "        width=1150,\n",
    "        height=700,\n",
    "    )\n",
    "else:\n",
    "    print(\"Portfolio ticker list is empty. Nothing to plot.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
