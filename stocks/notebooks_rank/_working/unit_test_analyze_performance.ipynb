{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3ddca6c",
   "metadata": {},
   "source": [
    "### Jupyter Notebook: Testing `analyze_performance`\n",
    "\n",
    "#### Cell 1: Setup - Function Definition and Imports\n",
    "\n",
    "First, let's define the function we're going to test and import pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fd98d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. The 'analyze_performance' function is defined.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# def analyze_performance(trade_results):\n",
    "#     \"\"\"\n",
    "#     Calculates performance metrics from a DataFrame of trades.\n",
    "#     (This is the function we are testing)\n",
    "#     \"\"\"\n",
    "#     if trade_results.empty:\n",
    "#         return {'num_trades': 0, 'win_rate': 0, 'avg_return': 0, 'total_return': 0}\n",
    "    \n",
    "#     win_rate = (trade_results['return'] > 0).mean()\n",
    "#     total_return = (1 + trade_results['return']).prod() - 1\n",
    "#     avg_return = trade_results['return'].mean()\n",
    "    \n",
    "#     return {\n",
    "#         'num_trades': len(trade_results),\n",
    "#         'win_rate': win_rate,\n",
    "#         'avg_return': avg_return,\n",
    "#         'total_return': total_return\n",
    "#     }\n",
    "\n",
    "def analyze_performance(trade_results):\n",
    "    \"\"\"\n",
    "    Calculates performance metrics from a DataFrame of trades.\n",
    "    \n",
    "    Returns a dictionary of key metrics.\n",
    "    \"\"\"\n",
    "    if trade_results.empty:\n",
    "        return {'num_trades': 0, 'win_rate': 0, 'avg_return': 0, 'total_return': 0}\n",
    "    \n",
    "    win_rate = (trade_results['return'] > 0).mean()\n",
    "    total_return = (1 + trade_results['return']).prod() - 1\n",
    "    avg_return = trade_results['return'].mean()\n",
    "    \n",
    "    return {\n",
    "        'num_trades': len(trade_results),\n",
    "        'win_rate': win_rate,\n",
    "        'avg_return': avg_return,\n",
    "        'total_return': total_return\n",
    "    }\n",
    "\n",
    "print(\"Setup complete. The 'analyze_performance' function is defined.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbae3f6",
   "metadata": {},
   "source": [
    "#### Cell 2: Test 1 - The Edge Case (No Trades)\n",
    "\n",
    "The first and most important test is to ensure the function behaves correctly when there are no trades to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad3d3ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test 1: Handling an Empty DataFrame (No Trades) ---\n",
      "\n",
      "Input DataFrame:\n",
      "Empty DataFrame\n",
      "Columns: [return]\n",
      "Index: []\n",
      "\n",
      "Actual Results from function:\n",
      "{'num_trades': 0, 'win_rate': 0, 'avg_return': 0, 'total_return': 0}\n",
      "\n",
      "[SUCCESS]: The function correctly handled an empty input.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Test 1: Handling an Empty DataFrame (No Trades) ---\")\n",
    "\n",
    "# Arrange: Create an empty DataFrame with the expected 'return' column\n",
    "empty_trades = pd.DataFrame({'return': []})\n",
    "\n",
    "print(\"\\nInput DataFrame:\")\n",
    "print(empty_trades)\n",
    "\n",
    "# Act: Call the function with the empty DataFrame\n",
    "actual_results = analyze_performance(empty_trades)\n",
    "\n",
    "print(\"\\nActual Results from function:\")\n",
    "print(actual_results)\n",
    "\n",
    "# Assert: Define what we expect and check if the result matches\n",
    "expected_results = {'num_trades': 0, 'win_rate': 0, 'avg_return': 0, 'total_return': 0}\n",
    "\n",
    "try:\n",
    "    assert actual_results == expected_results\n",
    "    print(\"\\n[SUCCESS]: The function correctly handled an empty input.\")\n",
    "except AssertionError:\n",
    "    print(\"\\n[FAILURE]: The function did not return the expected dictionary of zeros for an empty input.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9e70aa",
   "metadata": {},
   "source": [
    "#### Cell 3: Test 2 - A Mix of Winning and Losing Trades\n",
    "\n",
    "Now, we'll test the core calculations. We'll create a small, predictable set of trades where we can easily calculate the correct metrics by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c202db52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test 2: Calculating Metrics for a Mix of Trades ---\n",
      "\n",
      "Input DataFrame:\n",
      "  ticker  return\n",
      "0      A    0.10\n",
      "1      B   -0.05\n",
      "2      C    0.20\n",
      "3      D   -0.02\n",
      "\n",
      "Actual Results from function:\n",
      "  num_trades: 4\n",
      "  win_rate: 0.50000\n",
      "  avg_return: 0.05750\n",
      "  total_return: 0.22892\n",
      "\n",
      "Verification Checks:\n",
      "  - num_trades: PASSED (4.00000 is close to 4.00000)\n",
      "  - win_rate: PASSED (0.50000 is close to 0.50000)\n",
      "  - avg_return: PASSED (0.05750 is close to 0.05750)\n",
      "  - total_return: PASSED (0.22892 is close to 0.22892)\n",
      "\n",
      "[SUCCESS]: All performance metrics were calculated correctly.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Test 2: Calculating Metrics for a Mix of Trades ---\")\n",
    "\n",
    "# Arrange: Create a sample DataFrame of trades\n",
    "# Let's use simple numbers for easy verification.\n",
    "sample_trades = pd.DataFrame({\n",
    "    'ticker': ['A', 'B', 'C', 'D'],\n",
    "    'return': [0.10, -0.05, 0.20, -0.02]  # Two wins, two losses\n",
    "})\n",
    "\n",
    "print(\"\\nInput DataFrame:\")\n",
    "print(sample_trades)\n",
    "\n",
    "# --- Manual Calculation for Verification ---\n",
    "# num_trades = 4\n",
    "# win_rate = 2 wins / 4 trades = 0.5\n",
    "# avg_return = (0.10 - 0.05 + 0.20 - 0.02) / 4 = 0.23 / 4 = 0.0575\n",
    "# total_return = (1.10 * 0.95 * 1.20 * 0.98) - 1 = 1.22892 - 1 = 0.22892\n",
    "\n",
    "# Act: Call the function with our sample trades\n",
    "actual_results = analyze_performance(sample_trades)\n",
    "\n",
    "print(\"\\nActual Results from function:\")\n",
    "# We round the floating point numbers for cleaner printing\n",
    "for key, value in actual_results.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.5f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "        \n",
    "# Assert: Define the expected results and check each one\n",
    "expected_results = {\n",
    "    'num_trades': 4,\n",
    "    'win_rate': 0.5,\n",
    "    'avg_return': 0.0575,\n",
    "    'total_return': 0.22892\n",
    "}\n",
    "\n",
    "print(\"\\nVerification Checks:\")\n",
    "all_passed = True\n",
    "for key, expected_value in expected_results.items():\n",
    "    actual_value = actual_results[key]\n",
    "    # Use np.isclose for safe floating point comparison\n",
    "    if np.isclose(actual_value, expected_value):\n",
    "        print(f\"  - {key}: PASSED ({actual_value:.5f} is close to {expected_value:.5f})\")\n",
    "    else:\n",
    "        print(f\"  - {key}: FAILED (Expected {expected_value:.5f}, but got {actual_value:.5f})\")\n",
    "        all_passed = False\n",
    "\n",
    "if all_passed:\n",
    "    print(\"\\n[SUCCESS]: All performance metrics were calculated correctly.\")\n",
    "else:\n",
    "    print(\"\\n[FAILURE]: One or more metrics were not calculated correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467d53a2",
   "metadata": {},
   "source": [
    "### By running these two cells, you can be very confident that your `analyze_performance` function is working exactly as intended, both for the normal case and the critical edge case of having no trades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "709ae1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected_results:\n",
      "{'num_trades': 4, 'win_rate': 0.5, 'avg_return': 0.0575, 'total_return': 0.22892}\n",
      "\n",
      "actual_results:\n",
      "{'num_trades': 4, 'win_rate': 0.5, 'avg_return': 0.0575, 'total_return': 0.2289199999999998}\n"
     ]
    }
   ],
   "source": [
    "print(f'expected_results:\\n{expected_results}')\n",
    "print(f'\\nactual_results:\\n{actual_results}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
