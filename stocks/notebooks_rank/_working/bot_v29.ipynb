{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9ae2708",
   "metadata": {},
   "source": [
    "# Here is the refactored solution. I have separated the concerns into three distinct layers:\n",
    "1.  **The Data Contract:** explicit `dataclasses` defining exactly what goes in and comes out.\n",
    "2.  **The Engine:** A purely mathematical class (`AlphaEngine`) containing the logic, with no widget/plotting dependencies.\n",
    "3.  **The UI:** A cleaned-up dashboard function that simply sends inputs to the Engine and visualizes the Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc79d79",
   "metadata": {},
   "source": [
    "### Following is the reverse chronological fix log (most recent entry is at the top )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68b1a41",
   "metadata": {},
   "source": [
    "```\n",
    "To see the full dataframe of all tickers (both those that passed and those that failed) for a specific date, we need to capture a snapshot of the universe inside the `_get_eligible_universe` method.\n",
    "\n",
    "I have updated the **`AlphaEngine`** class below.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30d1f60",
   "metadata": {},
   "source": [
    "```\n",
    "To verify that the relative percentile logic is working, we can modify the `AlphaEngine` to report exactly **how the cutoff was calculated** for the specific start date.\n",
    "\n",
    "We want to see evidence that:\n",
    "1.  In earlier years (e.g., 2005), the volume cutoff is lower (e.g., $200k).\n",
    "2.  In later years (e.g., 2024), the volume cutoff is higher (e.g., $5M).\n",
    "\n",
    "Here is the updated `AlphaEngine` and `UI` code. I have added a **\"Audit Log\"** feature. When you run the tool, it will now print exactly what the Dollar Volume Threshold was for that specific day.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50de4e99",
   "metadata": {},
   "source": [
    "```\n",
    "The best way to solve this is to switch from a **Fixed Dollar Threshold** (e.g., \"$1 Million\") to a **Relative Percentile Threshold** (e.g., \"Top 50% of the market\").\n",
    "\n",
    "In 2004, a stock trading $200k might have been in the top 50% of liquid stocks. In 2024, that same $200k is illiquid garbage. Using a percentile automatically adjusts for inflation and market growth over time.\n",
    "\n",
    "Here is how to modify your code to support this.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e8a3b9",
   "metadata": {},
   "source": [
    "```\n",
    "To fix this, we need to pass the **actual** calculated start date (the trading day the engine \"snapped\" to) back from the `AlphaEngine` to the UI. Then, the UI can compare the *Requested Date* vs. the *Actual Date* and display the warning message if they differ.\n",
    "\n",
    "Here is the plan:\n",
    "1.  **Update `EngineOutput`**: Add a `start_date` field to the dataclass.\n",
    "2.  **Update `AlphaEngine.run`**: Populate this new field with `safe_start_date`.\n",
    "3.  **Update `plot_walk_forward_analyzer`**: Add logic to compare the user's input date with the engine's returned date and print the \"Info\" message if they are different.\n",
    "\n",
    "Here is the updated code (Sections C, D, and E have changed):\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb918f61",
   "metadata": {},
   "source": [
    "```\n",
    "I have updated the `AlphaEngine.run` method. specifically inside the `if inputs.mode == 'Manual List':` block. It now iterates through every manual ticker and performs two checks:\n",
    "1.  **Existence**: Is the ticker in the database?\n",
    "2.  **Availability**: Does the ticker have a valid price on the specific `Start Date`?\n",
    "\n",
    "If any ticker fails, it compiles a specific error message explaining why (e.g., \"No price data on start date\") and aborts the calculation immediately.  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b728a8",
   "metadata": {},
   "source": [
    "```\n",
    "The `snapshot_df` contains **every single feature** calculated by your `generate_features` function for that specific day, plus the new audit columns we added.\n",
    "\n",
    "Here is exactly what is inside that DataFrame:\n",
    "\n",
    "### 1. The Core Features (from `generate_features`)\n",
    "*   **`TR`**: True Range\n",
    "*   **`ATR`**: Average True Range\n",
    "*   **`ATRP`**: Average True Range Percent (Volatility)\n",
    "*   **`RollingStalePct`**: How often the price didn't move or volume was 0.\n",
    "*   **`RollMedDollarVol`**: Median Daily Dollar Volume (Liquidity).\n",
    "*   **`RollingSameVolCount`**: Data quality check for repeated volume numbers.\n",
    "\n",
    "### 2. The Audit Columns (Added during filtering)\n",
    "*   **`Calculated_Cutoff`**: The specific dollar amount required to pass on that day.\n",
    "*   **`Passed_Vol_Check`**: `True` if the ticker met the liquidity requirement.\n",
    "*   **`Passed_Final`**: `True` if it passed **all** checks (Liquidity + Stale + Quality).\n",
    "\n",
    "=========================================\n",
    "\n",
    "Here are the formulas translated directly into the Python `pandas` code used in your `generate_features` function.\n",
    "\n",
    "I have simplified the code slightly to assume a single ticker context (removing the `groupby` wrapper) so you can see the raw math clearly.\n",
    "\n",
    "### 1. True Range (TR)\n",
    "Calculates the maximum of the three price differences.\n",
    "\n",
    "prev_close = df_ohlcv['Adj Close'].shift(1)\n",
    "\n",
    "# The three components\n",
    "diff1 = df_ohlcv['Adj High'] - df_ohlcv['Adj Low']\n",
    "diff2 = (df_ohlcv['Adj High'] - prev_close).abs()\n",
    "diff3 = (df_ohlcv['Adj Low'] - prev_close).abs()\n",
    "\n",
    "# Taking the max of the three\n",
    "tr = pd.concat([diff1, diff2, diff3], axis=1).max(axis=1)\n",
    "\n",
    "### 2. Average True Range (ATR)\n",
    "Uses an Exponential Weighted Mean (EWM) with a specific alpha smoothing factor.\n",
    "\n",
    "# N = atr_period (e.g., 14)\n",
    "# alpha = 1 / N\n",
    "atr = tr.ewm(alpha=1/14, adjust=False).mean()\n",
    "\n",
    "### 3. ATR Percent (ATRP)\n",
    "Simple division to normalize volatility.\n",
    "\n",
    "atrp = atr / df_ohlcv['Adj Close']\n",
    "\n",
    "### 4. Rolling Stale Percentage\n",
    "Checks if volume is 0 OR if High equals Low (price didn't move), then averages that 1 or 0 signal over the window.\n",
    "\n",
    "# 1. Define the Stale Signal (1 for stale, 0 for active)\n",
    "is_stale = np.where(\n",
    "    (df_ohlcv['Volume'] == 0) | (df_ohlcv['Adj High'] == df_ohlcv['Adj Low']), \n",
    "    1,  \n",
    "    0\n",
    ")\n",
    "\n",
    "# 2. Calculate average over window (W=252)\n",
    "rolling_stale_pct = pd.Series(is_stale).rolling(window=252).mean()\n",
    "\n",
    "### 5. Rolling Median Dollar Volume\n",
    "Calculates raw dollar volume, then finds the median over the window.\n",
    "\n",
    "# 1. Calculate Daily Dollar Volume\n",
    "dollar_volume = df_ohlcv['Adj Close'] * df_ohlcv['Volume']\n",
    "\n",
    "# 2. Get Median over window (W=252)\n",
    "roll_med_dollar_vol = dollar_volume.rolling(window=252).median()\n",
    "\n",
    "### 6. Rolling Same Volume Count\n",
    "Checks if today's volume is exactly the same as yesterday's (a sign of bad data), then sums those occurrences.\n",
    "\n",
    "# 1. Check if Volume(t) - Volume(t-1) equals 0\n",
    "# .diff() calculates current row minus previous row\n",
    "has_same_volume = (df_ohlcv['Volume'].diff() == 0).astype(int)\n",
    "\n",
    "# 2. Sum the errors over window (W=252)\n",
    "rolling_same_vol_count = has_same_volume.rolling(window=252).sum()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb417c7",
   "metadata": {},
   "source": [
    "================================  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6250617f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 9657171 entries, ('A', Timestamp('1999-11-18 00:00:00')) to ('ZWS', Timestamp('2025-12-03 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   Adj Open   float64\n",
      " 1   Adj High   float64\n",
      " 2   Adj Low    float64\n",
      " 3   Adj Close  float64\n",
      " 4   Volume     int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 405.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_ohlcv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1110f2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets\n",
    "import pprint\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Optional, Any, Union\n",
    "from collections import Counter\n",
    "from datetime import datetime, date\n",
    "\n",
    "# pd.set_option('display.max_rows', None)  display all rows\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "pd.set_option('display.precision', 4)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION A: CORE HELPER FUNCTIONS & FEATURE GENERATION\n",
    "# (Unchanged from previous version)\n",
    "# ==============================================================================\n",
    "# ... (Keep generate_features, calculate_gain, calculate_sharpe, \n",
    "#      calculate_sharpe_atr, calculate_buy_and_hold_performance as is) ...\n",
    "\n",
    "def generate_features(df_ohlcv: pd.DataFrame, atr_period: int = 14, quality_window: int = 252, quality_min_periods: int = 126) -> pd.DataFrame:\n",
    "    # (Same as before)\n",
    "    if not df_ohlcv.index.is_monotonic_increasing: df_ohlcv = df_ohlcv.sort_index()\n",
    "    grouped = df_ohlcv.groupby(level='Ticker')\n",
    "    prev_close = grouped['Adj Close'].shift(1)\n",
    "    tr = pd.concat([df_ohlcv['Adj High'] - df_ohlcv['Adj Low'], abs(df_ohlcv['Adj High'] - prev_close), abs(df_ohlcv['Adj Low'] - prev_close)], axis=1).max(axis=1, skipna=False)\n",
    "    atr = tr.groupby(level='Ticker').transform(lambda x: x.ewm(alpha=1/atr_period, adjust=False).mean())\n",
    "    atrp = (atr / df_ohlcv['Adj Close']).replace([np.inf, -np.inf], np.nan)\n",
    "    indicator_df = pd.DataFrame({'TR': tr, 'ATR': atr, 'ATRP': atrp})\n",
    "    quality_temp_df = pd.DataFrame({'IsStale': np.where((df_ohlcv['Volume'] == 0) | (df_ohlcv['Adj High'] == df_ohlcv['Adj Low']), 1, 0), 'DollarVolume': df_ohlcv['Adj Close'] * df_ohlcv['Volume'], 'HasSameVolume': (grouped['Volume'].diff() == 0).astype(int)}, index=df_ohlcv.index)\n",
    "    rolling_result = quality_temp_df.groupby(level='Ticker').rolling(window=quality_window, min_periods=quality_min_periods).agg({'IsStale': 'mean', 'DollarVolume': 'median', 'HasSameVolume': 'sum'}).rename(columns={'IsStale': 'RollingStalePct', 'DollarVolume': 'RollMedDollarVol', 'HasSameVolume': 'RollingSameVolCount'}).reset_index(level=0, drop=True)\n",
    "    return pd.concat([indicator_df, rolling_result], axis=1)\n",
    "\n",
    "def calculate_gain(price_series): \n",
    "    if price_series.dropna().shape[0] < 2: return np.nan\n",
    "    return (price_series.ffill().iloc[-1] / price_series.bfill().iloc[0]) - 1\n",
    "\n",
    "def calculate_sharpe(return_series):\n",
    "    if return_series.dropna().shape[0] < 2: return np.nan\n",
    "    std = return_series.std()\n",
    "    return (return_series.mean() / std * np.sqrt(252)) if std > 0 else 0.0\n",
    "\n",
    "def calculate_sharpe_atr(return_series, atrp_series):\n",
    "    if return_series.dropna().shape[0] < 2 or atrp_series.dropna().empty: return np.nan\n",
    "    mean_atrp = atrp_series.mean()\n",
    "    return (return_series.mean() / mean_atrp) if mean_atrp > 0 else 0.0\n",
    "\n",
    "def calculate_buy_and_hold_performance(df_close, features_df, tickers, start_date, end_date):\n",
    "    if not tickers: return pd.Series(dtype=float), pd.Series(dtype=float), pd.Series(dtype=float)\n",
    "    ticker_counts = Counter(tickers)\n",
    "    initial_weights = pd.Series({t: c / len(tickers) for t, c in ticker_counts.items()})\n",
    "    prices_raw = df_close[initial_weights.index.tolist()].loc[start_date:end_date]\n",
    "    if prices_raw.dropna(how='all').empty: return pd.Series(dtype=float), pd.Series(dtype=float), pd.Series(dtype=float)\n",
    "    prices_norm = prices_raw.div(prices_raw.bfill().iloc[0])\n",
    "    weighted_growth = prices_norm.mul(initial_weights, axis='columns')\n",
    "    value_series = weighted_growth.sum(axis=1)\n",
    "    return_series = value_series.pct_change()\n",
    "    full_idx = pd.MultiIndex.from_product([initial_weights.index.tolist(), return_series.index], names=['Ticker', 'Date'])\n",
    "    feat_subset = features_df.reindex(full_idx)['ATRP'].unstack(level='Ticker')\n",
    "    atrp_series = (weighted_growth.div(value_series, axis='index').align(feat_subset, join='inner', axis=1)[0] * weighted_growth.div(value_series, axis='index').align(feat_subset, join='inner', axis=1)[1]).sum(axis=1)\n",
    "    return value_series, return_series, atrp_series\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION B: METRIC REGISTRY\n",
    "# ==============================================================================\n",
    "\n",
    "def metric_price(d): return calculate_gain(d['calc_close'])\n",
    "def metric_sharpe(d): \n",
    "    r = d['daily_returns']\n",
    "    return (r.mean() / r.std() * np.sqrt(252)).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "def metric_sharpe_atr(d):\n",
    "    return (d['daily_returns'].mean() / d['atrp']).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "METRIC_REGISTRY = {\n",
    "    'Price': metric_price,\n",
    "    'Sharpe': metric_sharpe,\n",
    "    'Sharpe (ATR)': metric_sharpe_atr,\n",
    "}\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION C: DATA CONTRACTS (The API)\n",
    "# Updated EngineOutput to include actual start_date\n",
    "# ==============================================================================\n",
    "\n",
    "@dataclass\n",
    "class EngineInput:\n",
    "    mode: str\n",
    "    start_date: pd.Timestamp\n",
    "    calc_period: int\n",
    "    fwd_period: int\n",
    "    metric: str\n",
    "    benchmark_ticker: str\n",
    "    rank_start: int = 1\n",
    "    rank_end: int = 10\n",
    "    quality_thresholds: Dict[str, float] = field(default_factory=lambda: {'min_median_dollar_volume': 1_000_000, 'max_stale_pct': 0.05, 'max_same_vol_count': 10})\n",
    "    manual_tickers: List[str] = field(default_factory=list)\n",
    "    debug: bool = False\n",
    "\n",
    "@dataclass\n",
    "class EngineOutput:\n",
    "    portfolio_series: pd.Series\n",
    "    benchmark_series: pd.Series\n",
    "    normalized_plot_data: pd.DataFrame\n",
    "    tickers: List[str]\n",
    "    initial_weights: pd.Series\n",
    "    perf_metrics: Dict[str, float]\n",
    "    results_df: pd.DataFrame\n",
    "    start_date: pd.Timestamp # <--- NEW FIELD: The actual trading start date used\n",
    "    calc_end_date: pd.Timestamp\n",
    "    viz_end_date: pd.Timestamp\n",
    "    error_msg: Optional[str] = None\n",
    "    debug_data: Optional[Dict[str, Any]] = None\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION D: THE ALPHA ENGINE (The \"Brain\")\n",
    "# This version saves a sorted dataframe called `universe_snapshot` into the debug data. It adds columns showing exactly which tickers passed or failed the specific thresholds.\n",
    "# ==============================================================================\n",
    "\n",
    "class AlphaEngine:\n",
    "    def __init__(self, df_ohlcv: pd.DataFrame, master_ticker: str = 'SPY'):\n",
    "        print(\"--- âš™ï¸ Initializing AlphaEngine ---\")\n",
    "        self.features_df = generate_features(df_ohlcv)\n",
    "        print(\"Optimizing data structures...\")\n",
    "        self.df_close = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "        \n",
    "        if master_ticker not in self.df_close.columns:\n",
    "            master_ticker = self.df_close.columns[0]\n",
    "            print(f\"Warning: Master ticker not found. Using {master_ticker}\")\n",
    "            \n",
    "        self.trading_calendar = self.df_close[master_ticker].dropna().index.unique().sort_values()\n",
    "        print(\"âœ… AlphaEngine Ready.\")\n",
    "\n",
    "    def run(self, inputs: EngineInput) -> EngineOutput:\n",
    "        # --- A. Validate Dates ---\n",
    "        try:\n",
    "            start_idx = self.trading_calendar.searchsorted(inputs.start_date)\n",
    "            if start_idx < 0: start_idx = 0\n",
    "        except Exception:\n",
    "            return self._error_result(\"Invalid Start Date\")\n",
    "\n",
    "        desired_end_idx = start_idx + inputs.calc_period + inputs.fwd_period\n",
    "        if desired_end_idx >= len(self.trading_calendar):\n",
    "            return self._error_result(f\"Date range exceeds history.\")\n",
    "\n",
    "        safe_start_date = self.trading_calendar[start_idx]\n",
    "        safe_calc_end_date = self.trading_calendar[start_idx + inputs.calc_period]\n",
    "        safe_viz_end_date = self.trading_calendar[start_idx + inputs.calc_period + inputs.fwd_period]\n",
    "\n",
    "        # --- B. Select Tickers ---\n",
    "        tickers_to_trade = []\n",
    "        results_table = pd.DataFrame()\n",
    "        debug_dict = {}\n",
    "        audit_info = {} \n",
    "\n",
    "        if inputs.mode == 'Manual List':\n",
    "            validation_errors = []\n",
    "            valid_tickers = []\n",
    "            for t in inputs.manual_tickers:\n",
    "                if t not in self.df_close.columns:\n",
    "                    validation_errors.append(f\"âŒ {t}: Ticker not found.\")\n",
    "                    continue\n",
    "                if pd.isna(self.df_close.at[safe_start_date, t]):\n",
    "                    validation_errors.append(f\"âš ï¸ {t}: No price data on start date.\")\n",
    "                    continue\n",
    "                valid_tickers.append(t)\n",
    "            \n",
    "            if validation_errors: return self._error_result(\"\\n\".join(validation_errors))\n",
    "            if not valid_tickers: return self._error_result(\"No valid tickers.\")\n",
    "            tickers_to_trade = valid_tickers\n",
    "            results_table = pd.DataFrame(index=valid_tickers)\n",
    "            \n",
    "        else: # Ranking Mode\n",
    "            eligible_tickers = self._get_eligible_universe(safe_start_date, inputs.quality_thresholds, audit_info)\n",
    "            debug_dict['audit_liquidity'] = audit_info \n",
    "            \n",
    "            if not eligible_tickers: return self._error_result(\"No tickers passed quality filters.\")\n",
    "            \n",
    "            calc_close = self.df_close.loc[safe_start_date:safe_calc_end_date, eligible_tickers]\n",
    "            idx_product = pd.MultiIndex.from_product([eligible_tickers, calc_close.index], names=['Ticker', 'Date'])\n",
    "            feat_slice = self.features_df.reindex(idx_product).dropna(how='all')\n",
    "            atrp_mean = feat_slice.groupby(level='Ticker')['ATRP'].mean()\n",
    "            \n",
    "            ingredients = { 'calc_close': calc_close, 'daily_returns': calc_close.pct_change(), 'atrp': atrp_mean }\n",
    "            if inputs.metric not in METRIC_REGISTRY: return self._error_result(f\"Metric '{inputs.metric}' not found.\")\n",
    "            metric_vals = METRIC_REGISTRY[inputs.metric](ingredients)\n",
    "            sorted_tickers = metric_vals.sort_values(ascending=False)\n",
    "            \n",
    "            start_r = max(0, inputs.rank_start - 1)\n",
    "            end_r = inputs.rank_end\n",
    "            tickers_to_trade = sorted_tickers.iloc[start_r:end_r].index.tolist()\n",
    "            if not tickers_to_trade: return self._error_result(\"No tickers generated from ranking.\")\n",
    "\n",
    "            results_table = pd.DataFrame({\n",
    "                'Rank': range(inputs.rank_start, inputs.rank_start + len(tickers_to_trade)),\n",
    "                'Ticker': tickers_to_trade,\n",
    "                'Metric Value': sorted_tickers.loc[tickers_to_trade].values\n",
    "            }).set_index('Ticker')\n",
    "\n",
    "        # --- C. Performance Calculations ---\n",
    "        p_val, p_ret, p_atrp = calculate_buy_and_hold_performance(self.df_close, self.features_df, tickers_to_trade, safe_start_date, safe_viz_end_date)\n",
    "        b_val, b_ret, b_atrp = calculate_buy_and_hold_performance(self.df_close, self.features_df, [inputs.benchmark_ticker], safe_start_date, safe_viz_end_date)\n",
    "\n",
    "        # --- D. Final Metrics ---\n",
    "        plot_data = self.df_close[list(set(tickers_to_trade))].loc[safe_start_date:safe_viz_end_date]\n",
    "        if not plot_data.empty: plot_data = plot_data / plot_data.bfill().iloc[0]\n",
    "        calc_end_ts = safe_calc_end_date\n",
    "        metrics = {}\n",
    "        get_gain = lambda s: (s.iloc[-1] / s.iloc[0]) - 1 if len(s) > 0 else 0\n",
    "\n",
    "        metrics['full_p_gain'] = get_gain(p_val)\n",
    "        metrics['calc_p_gain'] = get_gain(p_val.loc[:calc_end_ts])\n",
    "        metrics['fwd_p_gain'] = get_gain(p_val.loc[calc_end_ts:])\n",
    "        metrics['full_p_sharpe_atr'] = calculate_sharpe_atr(p_ret, p_atrp)\n",
    "        metrics['calc_p_sharpe_atr'] = calculate_sharpe_atr(p_ret.loc[:calc_end_ts], p_atrp.loc[p_ret.loc[:calc_end_ts].index])\n",
    "        metrics['fwd_p_sharpe_atr'] = calculate_sharpe_atr(p_ret.loc[calc_end_ts:].iloc[1:], p_atrp.loc[p_ret.loc[calc_end_ts:].iloc[1:].index])\n",
    "        \n",
    "        if not b_ret.empty:\n",
    "            metrics['full_b_gain'] = get_gain(b_val)\n",
    "            metrics['calc_b_gain'] = get_gain(b_val.loc[:calc_end_ts])\n",
    "            metrics['fwd_b_gain'] = get_gain(b_val.loc[calc_end_ts:])\n",
    "            metrics['full_b_sharpe_atr'] = calculate_sharpe_atr(b_ret, b_atrp)\n",
    "            metrics['calc_b_sharpe_atr'] = calculate_sharpe_atr(b_ret.loc[:calc_end_ts], b_atrp.loc[b_ret.loc[:calc_end_ts].index])\n",
    "            metrics['fwd_b_sharpe_atr'] = calculate_sharpe_atr(b_ret.loc[calc_end_ts:].iloc[1:], b_atrp.loc[b_ret.loc[calc_end_ts:].iloc[1:].index])\n",
    "\n",
    "        if not plot_data.empty: results_table['Fwd Gain'] = (plot_data.iloc[-1] / plot_data.loc[calc_end_ts]) - 1\n",
    "        ticker_counts = Counter(tickers_to_trade)\n",
    "        weights = pd.Series({t: c/len(tickers_to_trade) for t, c in ticker_counts.items()})\n",
    "\n",
    "        if inputs.debug:\n",
    "            trace_df = plot_data.copy()\n",
    "            trace_df.columns = [f'Norm_Price_{c}' for c in trace_df.columns]\n",
    "            trace_df['Norm_Price_Portfolio'] = p_val\n",
    "            if not b_val.empty: trace_df[f'Norm_Price_Benchmark_{inputs.benchmark_ticker}'] = b_val\n",
    "            debug_dict['portfolio_trace'] = trace_df\n",
    "\n",
    "        return EngineOutput(\n",
    "            portfolio_series=p_val, benchmark_series=b_val, normalized_plot_data=plot_data,\n",
    "            tickers=tickers_to_trade, initial_weights=weights, perf_metrics=metrics,\n",
    "            results_df=results_table, start_date=safe_start_date,\n",
    "            calc_end_date=safe_calc_end_date, viz_end_date=safe_viz_end_date, debug_data=debug_dict\n",
    "        )\n",
    "\n",
    "    # --- UPDATED: CAPTURE SNAPSHOT ---\n",
    "    def _get_eligible_universe(self, date_ts, thresholds, audit_container=None):\n",
    "        avail_dates = self.features_df.index.get_level_values('Date').unique().sort_values()\n",
    "        valid_dates = avail_dates[avail_dates <= date_ts]\n",
    "        if valid_dates.empty: return []\n",
    "        day_features = self.features_df.xs(valid_dates[-1], level='Date')\n",
    "\n",
    "        # 1. Determine Dynamic Cutoff\n",
    "        vol_cutoff = thresholds.get('min_median_dollar_volume', 0)\n",
    "        percentile_used = \"N/A\"\n",
    "        dynamic_val = 0\n",
    "        \n",
    "        if 'min_liquidity_percentile' in thresholds:\n",
    "            percentile_used = thresholds['min_liquidity_percentile']\n",
    "            dynamic_val = day_features['RollMedDollarVol'].quantile(percentile_used)\n",
    "            vol_cutoff = max(vol_cutoff, dynamic_val)\n",
    "\n",
    "        # 2. Logic Mask\n",
    "        mask = (\n",
    "            (day_features['RollMedDollarVol'] >= vol_cutoff) &\n",
    "            (day_features['RollingStalePct'] <= thresholds['max_stale_pct']) &\n",
    "            (day_features['RollingSameVolCount'] <= thresholds['max_same_vol_count'])\n",
    "        )\n",
    "\n",
    "        # 3. Capture Detailed Audit Snapshot\n",
    "        if audit_container is not None:\n",
    "            audit_container['date'] = valid_dates[-1]\n",
    "            audit_container['total_tickers_available'] = len(day_features)\n",
    "            audit_container['percentile_setting'] = percentile_used\n",
    "            audit_container['percentile_value_usd'] = dynamic_val\n",
    "            audit_container['final_cutoff_usd'] = vol_cutoff\n",
    "            audit_container['tickers_passed'] = mask.sum()\n",
    "            \n",
    "            # Save the DataFrame!\n",
    "            snapshot = day_features.copy()\n",
    "            snapshot['Calculated_Cutoff'] = vol_cutoff\n",
    "            snapshot['Passed_Vol_Check'] = snapshot['RollMedDollarVol'] >= vol_cutoff\n",
    "            snapshot['Passed_Final'] = mask\n",
    "            # Sort by volume so user can see the cutoff point easily\n",
    "            snapshot = snapshot.sort_values('RollMedDollarVol', ascending=False)\n",
    "            audit_container['universe_snapshot'] = snapshot\n",
    "\n",
    "        return day_features[mask].index.tolist()\n",
    "\n",
    "    def _error_result(self, msg):\n",
    "        return EngineOutput(pd.Series(dtype=float), pd.Series(dtype=float), pd.DataFrame(), [], pd.Series(dtype=float), {}, pd.DataFrame(), pd.Timestamp.min, pd.Timestamp.min, pd.Timestamp.min, msg)\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION E: THE UI (Visualization)\n",
    "# Update this function to read the audit data from the `debug_data` and print it nicely.\n",
    "# Updated print logic to detect date shift\n",
    "# Fixed EngineInput argument mapping\n",
    "# ==============================================================================\n",
    "\n",
    "def plot_walk_forward_analyzer(df_ohlcv, \n",
    "                               default_start_date='2020-01-01', \n",
    "                               default_calc_period=126, \n",
    "                               default_fwd_period=63,\n",
    "                               default_metric='Sharpe (ATR)', \n",
    "                               default_rank_start=1, \n",
    "                               default_rank_end=10,\n",
    "                               default_benchmark_ticker='SPY', \n",
    "                               master_calendar_ticker='SPY', \n",
    "                               quality_thresholds=None, \n",
    "                               debug=False):\n",
    "    \n",
    "    engine = AlphaEngine(df_ohlcv, master_ticker=master_calendar_ticker)\n",
    "    results_container = [None]\n",
    "    debug_container = [None]\n",
    "\n",
    "    # --- UPDATED DEFAULT SETTINGS WITH PERCENTILE ---\n",
    "    if quality_thresholds is None:\n",
    "        quality_thresholds = {\n",
    "            'min_median_dollar_volume': 100_000, # Hard floor\n",
    "            'min_liquidity_percentile': 0.50,    # Top 50%\n",
    "            'max_stale_pct': 0.05, \n",
    "            'max_same_vol_count': 10\n",
    "        }\n",
    "\n",
    "    # (Widget setup code remains the same...)\n",
    "    mode_selector = widgets.RadioButtons(options=['Ranking', 'Manual List'], value='Ranking', description='Portfolio Mode:', layout={'width': 'max-content'})\n",
    "    start_date_picker = widgets.DatePicker(description='Start Date:', value=pd.to_datetime(default_start_date))\n",
    "    calc_period_input = widgets.IntText(value=default_calc_period, description='Calc Period:')\n",
    "    fwd_period_input = widgets.IntText(value=default_fwd_period, description='Fwd Period:')\n",
    "    metric_dropdown = widgets.Dropdown(options=list(METRIC_REGISTRY.keys()), value=default_metric, description='Metric:')\n",
    "    rank_start_input = widgets.IntText(value=default_rank_start, description='Rank Start:')\n",
    "    rank_end_input = widgets.IntText(value=default_rank_end, description='Rank End:')\n",
    "    manual_tickers_input = widgets.Textarea(value='', placeholder='Enter tickers...', description='Manual Tickers:', layout={'width': '400px', 'height': '80px'})\n",
    "    benchmark_input = widgets.Text(value=default_benchmark_ticker, description='Benchmark:', placeholder='Enter Ticker')\n",
    "    update_button = widgets.Button(description=\"Update Chart\", button_style='primary')\n",
    "    ticker_list_output = widgets.Output()\n",
    "\n",
    "    ranking_controls = widgets.HBox([metric_dropdown, rank_start_input, rank_end_input])\n",
    "    manual_controls = widgets.HBox([manual_tickers_input])\n",
    "    date_controls = widgets.HBox([start_date_picker, calc_period_input, fwd_period_input])\n",
    "    ui = widgets.VBox([mode_selector, date_controls, ranking_controls, manual_controls, widgets.HBox([benchmark_input, update_button]), ticker_list_output], layout=widgets.Layout(margin='10px 0 20px 0'))\n",
    "    \n",
    "    def on_mode_change(c):\n",
    "        ranking_controls.layout.display = 'flex' if c['new'] == 'Ranking' else 'none'\n",
    "        manual_controls.layout.display = 'none' if c['new'] == 'Ranking' else 'flex'\n",
    "    mode_selector.observe(on_mode_change, names='value')\n",
    "    on_mode_change({'new': mode_selector.value})\n",
    "\n",
    "    fig = go.FigureWidget()\n",
    "    fig.update_layout(title='Walk-Forward Performance Analysis', height=600, template=\"plotly_white\", hovermode='x unified')\n",
    "    for i in range(50): fig.add_trace(go.Scatter(visible=False, line=dict(width=2)))\n",
    "    fig.add_trace(go.Scatter(name='Benchmark', visible=True, line=dict(color='black', width=3, dash='dash')))\n",
    "    fig.add_trace(go.Scatter(name='Group Portfolio', visible=True, line=dict(color='green', width=3)))\n",
    "\n",
    "    def update_plot(b):\n",
    "        ticker_list_output.clear_output()\n",
    "        manual_list = [t.strip().upper() for t in manual_tickers_input.value.split(',') if t.strip()]\n",
    "        start_date_raw = pd.to_datetime(start_date_picker.value)\n",
    "        \n",
    "        if start_date_raw < (engine.trading_calendar[0] - pd.Timedelta(days=7)):\n",
    "            with ticker_list_output: print(f\"âš ï¸ DATE WARNING: Start date {start_date_raw.date()} is too early.\"); return\n",
    "\n",
    "        inputs = EngineInput(\n",
    "            mode=mode_selector.value,\n",
    "            start_date=start_date_raw,\n",
    "            calc_period=calc_period_input.value,\n",
    "            fwd_period=fwd_period_input.value,\n",
    "            metric=metric_dropdown.value,\n",
    "            benchmark_ticker=benchmark_input.value.strip().upper(),\n",
    "            rank_start=rank_start_input.value,\n",
    "            rank_end=rank_end_input.value,\n",
    "            quality_thresholds=quality_thresholds,\n",
    "            manual_tickers=manual_list,\n",
    "            debug=debug\n",
    "        )\n",
    "        \n",
    "        with ticker_list_output:\n",
    "            res = engine.run(inputs)\n",
    "            results_container[0] = res\n",
    "            debug_container[0] = res.debug_data\n",
    "            if res.error_msg: print(res.error_msg); return\n",
    "\n",
    "            with fig.batch_update():\n",
    "                cols = res.normalized_plot_data.columns.tolist()\n",
    "                for i in range(50):\n",
    "                    if i < len(cols): fig.data[i].update(x=res.normalized_plot_data.index, y=res.normalized_plot_data[cols[i]], name=cols[i], visible=True)\n",
    "                    else: fig.data[i].visible = False\n",
    "                \n",
    "                fig.data[50].update(x=res.benchmark_series.index, y=res.benchmark_series.values, name=f\"Benchmark ({inputs.benchmark_ticker})\", visible=not res.benchmark_series.empty)\n",
    "                fig.data[51].update(x=res.portfolio_series.index, y=res.portfolio_series.values, visible=True)\n",
    "                fig.layout.shapes = [dict(type=\"line\", x0=res.calc_end_date, y0=0, x1=res.calc_end_date, y1=1, xref='x', yref='paper', line=dict(color=\"grey\", width=2, dash=\"dash\"))]\n",
    "\n",
    "            req_date = inputs.start_date.date()\n",
    "            act_date = res.start_date.date()\n",
    "            if req_date != act_date: print(f\"â„¹ï¸ Info: Start date {req_date} is not a trading day. Snapping forward to {act_date}.\")\n",
    "            \n",
    "            # --- LIQUIDITY AUDIT PRINT ---\n",
    "            if inputs.mode == 'Ranking' and res.debug_data and 'audit_liquidity' in res.debug_data:\n",
    "                audit = res.debug_data['audit_liquidity']\n",
    "                if audit:\n",
    "                    pct_str = f\"{audit.get('percentile_setting', 0)*100:.0f}%\"\n",
    "                    cut_val = audit.get('final_cutoff_usd', 0)\n",
    "                    print(\"-\" * 60)\n",
    "                    print(f\"ðŸ” LIQUIDITY CHECK ({act_date})\")\n",
    "                    print(f\"   Universe Size: {audit.get('total_tickers_available')} tickers\")\n",
    "                    print(f\"   Filtering: Top {pct_str} of Market\")\n",
    "                    print(f\"   Calculated Cutoff: ${cut_val:,.0f} / day\")\n",
    "                    print(f\"   Tickers Remaining: {audit.get('tickers_passed')}\")\n",
    "                    print(\"-\" * 60)\n",
    "            \n",
    "            print(f\"Analysis Period: {act_date} to {res.viz_end_date.date()}.\")\n",
    "            \n",
    "            if inputs.mode == 'Ranking': print(\"Ranked Tickers:\"); pprint.pprint(res.tickers)\n",
    "            else: print(\"Manual Portfolio Tickers:\"); pprint.pprint(res.tickers)\n",
    "            \n",
    "            m = res.perf_metrics\n",
    "            rows = [\n",
    "                {'Metric': 'Group Portfolio Gain', 'Full': m.get('full_p_gain'), 'Calc': m.get('calc_p_gain'), 'Fwd': m.get('fwd_p_gain')},\n",
    "                {'Metric': f'Benchmark ({inputs.benchmark_ticker}) Gain', 'Full': m.get('full_b_gain'), 'Calc': m.get('calc_b_gain'), 'Fwd': m.get('fwd_b_gain')},\n",
    "                {'Metric': '== Gain Delta', 'Full': m.get('full_p_gain',0)-m.get('full_b_gain',0), 'Calc': m.get('calc_p_gain',0)-m.get('calc_b_gain',0), 'Fwd': m.get('fwd_p_gain',0)-m.get('fwd_b_gain',0)},\n",
    "                {'Metric': 'Group Sharpe (ATR)', 'Full': m.get('full_p_sharpe_atr'), 'Calc': m.get('calc_p_sharpe_atr'), 'Fwd': m.get('fwd_p_sharpe_atr')},\n",
    "                {'Metric': f'Benchmark Sharpe (ATR)', 'Full': m.get('full_b_sharpe_atr'), 'Calc': m.get('calc_b_sharpe_atr'), 'Fwd': m.get('fwd_b_sharpe_atr')},\n",
    "                {'Metric': '== Sharpe Delta', 'Full': m.get('full_p_sharpe_atr',0)-m.get('full_b_sharpe_atr',0), 'Calc': m.get('calc_p_sharpe_atr',0)-m.get('calc_b_sharpe_atr',0), 'Fwd': m.get('fwd_p_sharpe_atr',0)-m.get('fwd_b_sharpe_atr',0)}\n",
    "            ]\n",
    "            display(pd.DataFrame(rows).set_index('Metric').style.format(\"{:+.2%}\", na_rep=\"N/A\"))\n",
    "\n",
    "    update_button.on_click(update_plot)\n",
    "    update_plot(None)\n",
    "    display(ui, fig)\n",
    "    return results_container, debug_container\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION F: UTILITIES\n",
    "# ==============================================================================\n",
    "\n",
    "def print_nested(d, indent=0, width=4):\n",
    "    \"\"\"Pretty-print any nested dict/list/tuple combination.\"\"\"\n",
    "    spacing = ' ' * indent\n",
    "    if isinstance(d, dict):\n",
    "        for k, v in d.items():\n",
    "            print(f'{spacing}{k}:')\n",
    "            print_nested(v, indent + width, width)\n",
    "    elif isinstance(d, (list, tuple)):\n",
    "        for item in d:\n",
    "            print_nested(item, indent, width)\n",
    "    else:\n",
    "        print(f'{spacing}{d}')\n",
    "\n",
    "def get_ticker_OHLCV(\n",
    "    df_ohlcv: pd.DataFrame,\n",
    "    tickers: Union[str, List[str]],\n",
    "    date_start: str,\n",
    "    date_end: str,\n",
    "    return_format: str = \"dataframe\",\n",
    "    verbose: bool = True\n",
    ") -> Union[pd.DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    Get OHLCV data for specified tickers within a date range.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_ohlcv : pd.DataFrame\n",
    "        DataFrame with MultiIndex of (ticker, date) and OHLCV columns\n",
    "    tickers : str or list of str\n",
    "        Ticker symbol(s) to retrieve\n",
    "    date_start : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    date_end : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    return_format : str, optional\n",
    "        Format to return data in. Options: \n",
    "        - 'dataframe': Single DataFrame with MultiIndex (default)\n",
    "        - 'dict': Dictionary with tickers as keys and DataFrames as values\n",
    "        - 'separate': List of separate DataFrames for each ticker\n",
    "    verbose : bool, optional\n",
    "        Whether to print summary information (default: True)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Union[pd.DataFrame, dict, list]\n",
    "        Filtered OHLCV data in specified format\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If input parameters are invalid\n",
    "    KeyError\n",
    "        If tickers not found in DataFrame\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> # Get data for single ticker\n",
    "    >>> vlo_data = get_ticker_OHLCV(df_ohlcv, 'VLO', '2025-08-13', '2025-09-04')\n",
    "    \n",
    "    >>> # Get data for multiple tickers\n",
    "    >>> multi_data = get_ticker_OHLCV(df_ohlcv, ['VLO', 'JPST'], '2025-08-13', '2025-09-04')\n",
    "    \n",
    "    >>> # Get data as dictionary\n",
    "    >>> data_dict = get_ticker_OHLCV(df_ohlcv, ['VLO', 'JPST'], '2025-08-13', \n",
    "    ...                              '2025-09-04', return_format='dict')\n",
    "    \"\"\"\n",
    "    \n",
    "    # Input validation\n",
    "    if not isinstance(df_ohlcv, pd.DataFrame):\n",
    "        raise TypeError(\"df_ohlcv must be a pandas DataFrame\")\n",
    "    \n",
    "    if not isinstance(df_ohlcv.index, pd.MultiIndex):\n",
    "        raise ValueError(\"DataFrame must have MultiIndex of (ticker, date)\")\n",
    "    \n",
    "    if len(df_ohlcv.index.levels) != 2:\n",
    "        raise ValueError(\"MultiIndex must have exactly 2 levels: (ticker, date)\")\n",
    "    \n",
    "    # Convert single ticker to list for consistent processing\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "    elif not isinstance(tickers, list):\n",
    "        raise TypeError(\"tickers must be a string or list of strings\")\n",
    "    \n",
    "    # Convert dates to Timestamps\n",
    "    try:\n",
    "        start_date = pd.Timestamp(date_start)\n",
    "        end_date = pd.Timestamp(date_end)\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"Invalid date format. Use 'YYYY-MM-DD': {e}\")\n",
    "    \n",
    "    if start_date > end_date:\n",
    "        raise ValueError(\"date_start must be before or equal to date_end\")\n",
    "    \n",
    "    # Check if tickers exist in the DataFrame\n",
    "    available_tickers = df_ohlcv.index.get_level_values(0).unique()\n",
    "    missing_tickers = [t for t in tickers if t not in available_tickers]\n",
    "    \n",
    "    if missing_tickers:\n",
    "        raise KeyError(f\"Ticker(s) not found in DataFrame: {missing_tickers}\")\n",
    "    \n",
    "    # Filter the data using MultiIndex slicing\n",
    "    try:\n",
    "        filtered_data = df_ohlcv.loc[(tickers, slice(date_start, date_end)), :]\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error filtering data: {e}\")\n",
    "    \n",
    "    # Handle empty results\n",
    "    if filtered_data.empty:\n",
    "        if verbose:\n",
    "            print(f\"No data found for tickers {tickers} in date range {date_start} to {date_end}\")\n",
    "        return filtered_data\n",
    "    \n",
    "    # Print summary if verbose\n",
    "    if verbose:\n",
    "        print(f\"Data retrieved for {len(tickers)} ticker(s) from {date_start} to {date_end}\")\n",
    "        print(f\"Total rows: {len(filtered_data)}\")\n",
    "        print(f\"Date range in data: {filtered_data.index.get_level_values(1).min()} to \"\n",
    "              f\"{filtered_data.index.get_level_values(1).max()}\")\n",
    "        \n",
    "        # Print ticker-specific counts\n",
    "        ticker_counts = filtered_data.index.get_level_values(0).value_counts()\n",
    "        for ticker in tickers:\n",
    "            count = ticker_counts.get(ticker, 0)\n",
    "            if count > 0:\n",
    "                print(f\"  {ticker}: {count} rows\")\n",
    "            else:\n",
    "                print(f\"  {ticker}: No data in range\")\n",
    "    \n",
    "    # Return in requested format\n",
    "    if return_format == \"dict\":\n",
    "        result = {}\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result[ticker] = filtered_data.xs(ticker, level=0).loc[date_start:date_end]\n",
    "            except KeyError:\n",
    "                result[ticker] = pd.DataFrame()\n",
    "        return result\n",
    "    \n",
    "    elif return_format == \"separate\":\n",
    "        result = []\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result.append(filtered_data.xs(ticker, level=0).loc[date_start:date_end])\n",
    "            except KeyError:\n",
    "                result.append(pd.DataFrame())\n",
    "        return result\n",
    "    \n",
    "    elif return_format == \"dataframe\":\n",
    "        return filtered_data\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Invalid return_format: {return_format}. \"\n",
    "                         f\"Must be 'dataframe', 'dict', or 'separate'\")\n",
    "\n",
    "def get_ticker_features(\n",
    "    features_df: pd.DataFrame,\n",
    "    tickers: Union[str, List[str]],\n",
    "    date_start: str,\n",
    "    date_end: str,\n",
    "    return_format: str = \"dataframe\",\n",
    "    verbose: bool = True\n",
    ") -> Union[pd.DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    Get features data for specified tickers within a date range.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    features_df : pd.DataFrame\n",
    "        DataFrame with MultiIndex of (ticker, date) and feature columns\n",
    "    tickers : str or list of str\n",
    "        Ticker symbol(s) to retrieve\n",
    "    date_start : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    date_end : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    return_format : str, optional\n",
    "        Format to return data in. Options: \n",
    "        - 'dataframe': Single DataFrame with MultiIndex (default)\n",
    "        - 'dict': Dictionary with tickers as keys and DataFrames as values\n",
    "        - 'separate': List of separate DataFrames for each ticker\n",
    "    verbose : bool, optional\n",
    "        Whether to print summary information (default: True)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Union[pd.DataFrame, dict, list]\n",
    "        Filtered features data in specified format\n",
    "    \"\"\"\n",
    "    # Convert single ticker to list for consistent processing\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "    \n",
    "    # Filter the data using MultiIndex slicing\n",
    "    try:\n",
    "        filtered_data = features_df.loc[(tickers, slice(date_start, date_end)), :]\n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"Error filtering data: {e}\")\n",
    "        return pd.DataFrame() if return_format == \"dataframe\" else {}\n",
    "    \n",
    "    # Handle empty results\n",
    "    if filtered_data.empty:\n",
    "        if verbose:\n",
    "            print(f\"No data found for tickers {tickers} in date range {date_start} to {date_end}\")\n",
    "        return filtered_data\n",
    "    \n",
    "    # Print summary if verbose\n",
    "    if verbose:\n",
    "        print(f\"Features data retrieved for {len(tickers)} ticker(s) from {date_start} to {date_end}\")\n",
    "        print(f\"Total rows: {len(filtered_data)}\")\n",
    "        print(f\"Date range in data: {filtered_data.index.get_level_values(1).min()} to \"\n",
    "              f\"{filtered_data.index.get_level_values(1).max()}\")\n",
    "        print(f\"Available features: {', '.join(filtered_data.columns.tolist())}\")\n",
    "        \n",
    "        # Print ticker-specific counts\n",
    "        ticker_counts = filtered_data.index.get_level_values(0).value_counts()\n",
    "        for ticker in tickers:\n",
    "            count = ticker_counts.get(ticker, 0)\n",
    "            if count > 0:\n",
    "                print(f\"  {ticker}: {count} rows\")\n",
    "            else:\n",
    "                print(f\"  {ticker}: No data in range\")\n",
    "    \n",
    "    # Return in requested format\n",
    "    if return_format == \"dict\":\n",
    "        result = {}\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result[ticker] = filtered_data.xs(ticker, level=0).loc[date_start:date_end]\n",
    "            except KeyError:\n",
    "                result[ticker] = pd.DataFrame()\n",
    "        return result\n",
    "    \n",
    "    elif return_format == \"separate\":\n",
    "        result = []\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result.append(filtered_data.xs(ticker, level=0).loc[date_start:date_end])\n",
    "            except KeyError:\n",
    "                result.append(pd.DataFrame())\n",
    "        return result\n",
    "    \n",
    "    elif return_format == \"dataframe\":\n",
    "        return filtered_data\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Invalid return_format: {return_format}. \"\n",
    "                         f\"Must be 'dataframe', 'dict', or 'separate'\")\n",
    "\n",
    "def create_combined_dict(\n",
    "    df_ohlcv: pd.DataFrame,\n",
    "    features_df: pd.DataFrame,\n",
    "    tickers: Union[str, List[str]],\n",
    "    date_start: str,\n",
    "    date_end: str,\n",
    "    verbose: bool = True\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Create a combined dictionary with both OHLCV and features data for each ticker.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_ohlcv : pd.DataFrame\n",
    "        DataFrame with OHLCV data (MultiIndex: ticker, date)\n",
    "    features_df : pd.DataFrame\n",
    "        DataFrame with features data (MultiIndex: ticker, date)\n",
    "    tickers : str or list of str\n",
    "        Ticker symbol(s) to retrieve\n",
    "    date_start : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    date_end : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    verbose : bool, optional\n",
    "        Whether to print progress information (default: True)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with tickers as keys and combined DataFrames (OHLCV + features) as values\n",
    "    \"\"\"\n",
    "    # Convert single ticker to list\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Creating combined dictionary for {len(tickers)} ticker(s)\")\n",
    "        print(f\"Date range: {date_start} to {date_end}\")\n",
    "        print(\"=\" * 60)\n",
    "    \n",
    "    # Get OHLCV data as dictionary\n",
    "    ohlcv_dict = get_ticker_OHLCV(\n",
    "        df_ohlcv, tickers, date_start, date_end, \n",
    "        return_format='dict', verbose=verbose\n",
    "    )\n",
    "    \n",
    "    # Get features data as dictionary\n",
    "    features_dict = get_ticker_features(\n",
    "        features_df, tickers, date_start, date_end,\n",
    "        return_format='dict', verbose=verbose\n",
    "    )\n",
    "    \n",
    "    # Create combined_dict\n",
    "    combined_dict = {}\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        if verbose:\n",
    "            print(f\"\\nProcessing {ticker}...\")\n",
    "        \n",
    "        # Check if ticker exists in both dictionaries\n",
    "        if ticker in ohlcv_dict and ticker in features_dict:\n",
    "            ohlcv_data = ohlcv_dict[ticker]\n",
    "            features_data = features_dict[ticker]\n",
    "            \n",
    "            # Check if both dataframes have data\n",
    "            if not ohlcv_data.empty and not features_data.empty:\n",
    "                # Combine OHLCV and features data\n",
    "                # Note: Both dataframes have the same index (dates), so we can concatenate\n",
    "                combined_df = pd.concat([ohlcv_data, features_data], axis=1)\n",
    "                \n",
    "                # Ensure proper index naming\n",
    "                combined_df.index.name = 'Date'\n",
    "                \n",
    "                # Store in combined_dict\n",
    "                combined_dict[ticker] = combined_df\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"  âœ“ Successfully combined data\")\n",
    "                    print(f\"  OHLCV shape: {ohlcv_data.shape}\")\n",
    "                    print(f\"  Features shape: {features_data.shape}\")\n",
    "                    print(f\"  Combined shape: {combined_df.shape}\")\n",
    "                    print(f\"  Date range: {combined_df.index.min()} to {combined_df.index.max()}\")\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"  âœ— Cannot combine: One or both dataframes are empty\")\n",
    "                    print(f\"    OHLCV empty: {ohlcv_data.empty}\")\n",
    "                    print(f\"    Features empty: {features_data.empty}\")\n",
    "                combined_dict[ticker] = pd.DataFrame()\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(f\"  âœ— Ticker not found in both dictionaries\")\n",
    "                if ticker not in ohlcv_dict:\n",
    "                    print(f\"    Not in OHLCV data\")\n",
    "                if ticker not in features_dict:\n",
    "                    print(f\"    Not in features data\")\n",
    "            combined_dict[ticker] = pd.DataFrame()\n",
    "    \n",
    "    # Print summary\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"SUMMARY\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Total tickers processed: {len(tickers)}\")\n",
    "        \n",
    "        tickers_with_data = [ticker for ticker, df in combined_dict.items() if not df.empty]\n",
    "        print(f\"Tickers with combined data: {len(tickers_with_data)}\")\n",
    "        \n",
    "        if tickers_with_data:\n",
    "            print(\"\\nTicker details:\")\n",
    "            for ticker in tickers_with_data:\n",
    "                df = combined_dict[ticker]\n",
    "                print(f\"  {ticker}: {df.shape} - {df.index.min()} to {df.index.max()}\")\n",
    "                print(f\"    Columns: {len(df.columns)}\")\n",
    "        \n",
    "        empty_tickers = [ticker for ticker, df in combined_dict.items() if df.empty]\n",
    "        if empty_tickers:\n",
    "            print(f\"\\nTickers with no data: {', '.join(empty_tickers)}\")\n",
    "    \n",
    "    return combined_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "232740e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 9657171 entries, ('A', Timestamp('1999-11-18 00:00:00')) to ('ZWS', Timestamp('2025-12-03 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   Adj Open   float64\n",
      " 1   Adj High   float64\n",
      " 2   Adj Low    float64\n",
      " 3   Adj Close  float64\n",
      " 4   Volume     int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 405.9+ MB\n",
      "df_ohlcv.info():\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Adj Open</th>\n",
       "      <th>Adj High</th>\n",
       "      <th>Adj Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">A</th>\n",
       "      <th>1999-11-18</th>\n",
       "      <td>27.2452</td>\n",
       "      <td>29.9398</td>\n",
       "      <td>23.9519</td>\n",
       "      <td>26.3470</td>\n",
       "      <td>74716395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-19</th>\n",
       "      <td>25.7108</td>\n",
       "      <td>25.7482</td>\n",
       "      <td>23.8396</td>\n",
       "      <td>24.1764</td>\n",
       "      <td>18198354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-22</th>\n",
       "      <td>24.7378</td>\n",
       "      <td>26.3470</td>\n",
       "      <td>23.9893</td>\n",
       "      <td>26.3470</td>\n",
       "      <td>7857764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-23</th>\n",
       "      <td>25.4488</td>\n",
       "      <td>26.1225</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>7138322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-24</th>\n",
       "      <td>24.0267</td>\n",
       "      <td>25.1120</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>24.5881</td>\n",
       "      <td>5785610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ZWS</th>\n",
       "      <th>2025-11-26</th>\n",
       "      <td>47.5400</td>\n",
       "      <td>48.7000</td>\n",
       "      <td>47.3000</td>\n",
       "      <td>48.1300</td>\n",
       "      <td>1154100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-28</th>\n",
       "      <td>48.4600</td>\n",
       "      <td>48.4800</td>\n",
       "      <td>47.7000</td>\n",
       "      <td>47.7000</td>\n",
       "      <td>481400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-01</th>\n",
       "      <td>47.1700</td>\n",
       "      <td>48.1800</td>\n",
       "      <td>47.1500</td>\n",
       "      <td>47.7400</td>\n",
       "      <td>608100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-02</th>\n",
       "      <td>47.9800</td>\n",
       "      <td>48.3100</td>\n",
       "      <td>47.7100</td>\n",
       "      <td>47.8200</td>\n",
       "      <td>838200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-03</th>\n",
       "      <td>47.8800</td>\n",
       "      <td>48.2200</td>\n",
       "      <td>47.4200</td>\n",
       "      <td>47.4500</td>\n",
       "      <td>688255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9657171 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Adj Open  Adj High  Adj Low  Adj Close    Volume\n",
       "Ticker Date                                                        \n",
       "A      1999-11-18   27.2452   29.9398  23.9519    26.3470  74716395\n",
       "       1999-11-19   25.7108   25.7482  23.8396    24.1764  18198354\n",
       "       1999-11-22   24.7378   26.3470  23.9893    26.3470   7857764\n",
       "       1999-11-23   25.4488   26.1225  23.9518    23.9518   7138322\n",
       "       1999-11-24   24.0267   25.1120  23.9518    24.5881   5785610\n",
       "...                     ...       ...      ...        ...       ...\n",
       "ZWS    2025-11-26   47.5400   48.7000  47.3000    48.1300   1154100\n",
       "       2025-11-28   48.4600   48.4800  47.7000    47.7000    481400\n",
       "       2025-12-01   47.1700   48.1800  47.1500    47.7400    608100\n",
       "       2025-12-02   47.9800   48.3100  47.7100    47.8200    838200\n",
       "       2025-12-03   47.8800   48.2200  47.4200    47.4500    688255\n",
       "\n",
       "[9657171 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = r'c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet'\n",
    "df_ohlcv = pd.read_parquet(data_path, engine='pyarrow')\n",
    "print(f'df_ohlcv.info():\\n{df_ohlcv.info()}')\n",
    "df_ohlcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6720574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_container, debug_container = plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    default_start_date='2025-08-13',\n",
    "    default_calc_period=10,\n",
    "    default_fwd_period=5,\n",
    "    default_metric='Sharpe (ATR)',\n",
    "    default_rank_start=15,\n",
    "    default_rank_end=16,\n",
    "    default_benchmark_ticker='VOO', \n",
    "    master_calendar_ticker='VOO',    \n",
    "    quality_thresholds = { \n",
    "        'min_median_dollar_volume': 100_000, # A low \"hard floor\" to filter absolute errors/garbage\n",
    "        # If min_liquidity_percentile is 0.8 (Top 20%), we want values > the 0.8 quantile.            \n",
    "        'min_liquidity_percentile': 0.50,    # Dynamic: Only keep the top 50% of stocks by volume\n",
    "        'max_stale_pct': 0.05, \n",
    "        'max_same_vol_count': 10\n",
    "    },\n",
    "    debug=True  # <-- Activate the new mode!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d7e2a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = generate_features(df_ohlcv=df_ohlcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd30b84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['VOO', 'VLO', 'JPST']\n",
    "date_start = '2025-08-13'\n",
    "date_end = '2025-09-04'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86cc1ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create combined dictionary\n",
    "combined_dict = create_combined_dict(\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    features_df=features_df,\n",
    "    tickers=tickers,\n",
    "    date_start=date_start,\n",
    "    date_end=date_end,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dd55374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Open</th>\n",
       "      <th>Adj High</th>\n",
       "      <th>Adj Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>TR</th>\n",
       "      <th>ATR</th>\n",
       "      <th>ATRP</th>\n",
       "      <th>RollingStalePct</th>\n",
       "      <th>RollMedDollarVol</th>\n",
       "      <th>RollingSameVolCount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-08-13</th>\n",
       "      <td>49.8859</td>\n",
       "      <td>49.8957</td>\n",
       "      <td>49.8760</td>\n",
       "      <td>49.8859</td>\n",
       "      <td>3998082</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.025613</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.534949e+08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-14</th>\n",
       "      <td>49.8859</td>\n",
       "      <td>49.8918</td>\n",
       "      <td>49.8760</td>\n",
       "      <td>49.8760</td>\n",
       "      <td>3662718</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.024912</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.521929e+08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-15</th>\n",
       "      <td>49.9007</td>\n",
       "      <td>49.9056</td>\n",
       "      <td>49.8957</td>\n",
       "      <td>49.8957</td>\n",
       "      <td>3421622</td>\n",
       "      <td>0.0296</td>\n",
       "      <td>0.025247</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.521929e+08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-18</th>\n",
       "      <td>49.9056</td>\n",
       "      <td>49.9056</td>\n",
       "      <td>49.8957</td>\n",
       "      <td>49.8957</td>\n",
       "      <td>4062923</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.024150</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.521929e+08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-19</th>\n",
       "      <td>49.9056</td>\n",
       "      <td>49.9253</td>\n",
       "      <td>49.9056</td>\n",
       "      <td>49.9253</td>\n",
       "      <td>3869010</td>\n",
       "      <td>0.0296</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.506840e+08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-20</th>\n",
       "      <td>49.9253</td>\n",
       "      <td>49.9352</td>\n",
       "      <td>49.9154</td>\n",
       "      <td>49.9352</td>\n",
       "      <td>4704730</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.024201</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.506840e+08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-21</th>\n",
       "      <td>49.9154</td>\n",
       "      <td>49.9352</td>\n",
       "      <td>49.9056</td>\n",
       "      <td>49.9056</td>\n",
       "      <td>3881288</td>\n",
       "      <td>0.0296</td>\n",
       "      <td>0.024587</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.506840e+08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-22</th>\n",
       "      <td>49.9352</td>\n",
       "      <td>49.9647</td>\n",
       "      <td>49.9253</td>\n",
       "      <td>49.9647</td>\n",
       "      <td>4340447</td>\n",
       "      <td>0.0591</td>\n",
       "      <td>0.027052</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.506840e+08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-25</th>\n",
       "      <td>49.9647</td>\n",
       "      <td>49.9647</td>\n",
       "      <td>49.9549</td>\n",
       "      <td>49.9549</td>\n",
       "      <td>4474897</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.025820</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.506840e+08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-26</th>\n",
       "      <td>49.9647</td>\n",
       "      <td>49.9746</td>\n",
       "      <td>49.9647</td>\n",
       "      <td>49.9746</td>\n",
       "      <td>4887785</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.025383</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.506840e+08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-27</th>\n",
       "      <td>49.9746</td>\n",
       "      <td>49.9844</td>\n",
       "      <td>49.9647</td>\n",
       "      <td>49.9844</td>\n",
       "      <td>10636760</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.024977</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.521929e+08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-28</th>\n",
       "      <td>49.9746</td>\n",
       "      <td>49.9844</td>\n",
       "      <td>49.9746</td>\n",
       "      <td>49.9844</td>\n",
       "      <td>5889715</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.023893</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.534949e+08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-29</th>\n",
       "      <td>50.0041</td>\n",
       "      <td>50.0140</td>\n",
       "      <td>49.9943</td>\n",
       "      <td>50.0041</td>\n",
       "      <td>5193621</td>\n",
       "      <td>0.0296</td>\n",
       "      <td>0.024300</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.548926e+08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-02</th>\n",
       "      <td>50.0031</td>\n",
       "      <td>50.0130</td>\n",
       "      <td>49.9933</td>\n",
       "      <td>50.0130</td>\n",
       "      <td>9828727</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.023972</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.552057e+08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-03</th>\n",
       "      <td>50.0130</td>\n",
       "      <td>50.0328</td>\n",
       "      <td>50.0130</td>\n",
       "      <td>50.0328</td>\n",
       "      <td>5485845</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.023674</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.553274e+08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-04</th>\n",
       "      <td>50.0427</td>\n",
       "      <td>50.0526</td>\n",
       "      <td>50.0328</td>\n",
       "      <td>50.0526</td>\n",
       "      <td>6370313</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.023397</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.566896e+08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Adj Open  Adj High  Adj Low  Adj Close    Volume      TR  \\\n",
       "Date                                                                   \n",
       "2025-08-13   49.8859   49.8957  49.8760    49.8859   3998082  0.0197   \n",
       "2025-08-14   49.8859   49.8918  49.8760    49.8760   3662718  0.0158   \n",
       "2025-08-15   49.9007   49.9056  49.8957    49.8957   3421622  0.0296   \n",
       "2025-08-18   49.9056   49.9056  49.8957    49.8957   4062923  0.0099   \n",
       "2025-08-19   49.9056   49.9253  49.9056    49.9253   3869010  0.0296   \n",
       "2025-08-20   49.9253   49.9352  49.9154    49.9352   4704730  0.0198   \n",
       "2025-08-21   49.9154   49.9352  49.9056    49.9056   3881288  0.0296   \n",
       "2025-08-22   49.9352   49.9647  49.9253    49.9647   4340447  0.0591   \n",
       "2025-08-25   49.9647   49.9647  49.9549    49.9549   4474897  0.0098   \n",
       "2025-08-26   49.9647   49.9746  49.9647    49.9746   4887785  0.0197   \n",
       "2025-08-27   49.9746   49.9844  49.9647    49.9844  10636760  0.0197   \n",
       "2025-08-28   49.9746   49.9844  49.9746    49.9844   5889715  0.0098   \n",
       "2025-08-29   50.0041   50.0140  49.9943    50.0041   5193621  0.0296   \n",
       "2025-09-02   50.0031   50.0130  49.9933    50.0130   9828727  0.0197   \n",
       "2025-09-03   50.0130   50.0328  50.0130    50.0328   5485845  0.0198   \n",
       "2025-09-04   50.0427   50.0526  50.0328    50.0526   6370313  0.0198   \n",
       "\n",
       "                 ATR      ATRP  RollingStalePct  RollMedDollarVol  \\\n",
       "Date                                                                \n",
       "2025-08-13  0.025613  0.000513              0.0      2.534949e+08   \n",
       "2025-08-14  0.024912  0.000499              0.0      2.521929e+08   \n",
       "2025-08-15  0.025247  0.000506              0.0      2.521929e+08   \n",
       "2025-08-18  0.024150  0.000484              0.0      2.521929e+08   \n",
       "2025-08-19  0.024540  0.000492              0.0      2.506840e+08   \n",
       "2025-08-20  0.024201  0.000485              0.0      2.506840e+08   \n",
       "2025-08-21  0.024587  0.000493              0.0      2.506840e+08   \n",
       "2025-08-22  0.027052  0.000541              0.0      2.506840e+08   \n",
       "2025-08-25  0.025820  0.000517              0.0      2.506840e+08   \n",
       "2025-08-26  0.025383  0.000508              0.0      2.506840e+08   \n",
       "2025-08-27  0.024977  0.000500              0.0      2.521929e+08   \n",
       "2025-08-28  0.023893  0.000478              0.0      2.534949e+08   \n",
       "2025-08-29  0.024300  0.000486              0.0      2.548926e+08   \n",
       "2025-09-02  0.023972  0.000479              0.0      2.552057e+08   \n",
       "2025-09-03  0.023674  0.000473              0.0      2.553274e+08   \n",
       "2025-09-04  0.023397  0.000467              0.0      2.566896e+08   \n",
       "\n",
       "            RollingSameVolCount  \n",
       "Date                             \n",
       "2025-08-13                  0.0  \n",
       "2025-08-14                  0.0  \n",
       "2025-08-15                  0.0  \n",
       "2025-08-18                  0.0  \n",
       "2025-08-19                  0.0  \n",
       "2025-08-20                  0.0  \n",
       "2025-08-21                  0.0  \n",
       "2025-08-22                  0.0  \n",
       "2025-08-25                  0.0  \n",
       "2025-08-26                  0.0  \n",
       "2025-08-27                  0.0  \n",
       "2025-08-28                  0.0  \n",
       "2025-08-29                  0.0  \n",
       "2025-09-02                  0.0  \n",
       "2025-09-03                  0.0  \n",
       "2025-09-04                  0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dict['JPST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551b239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_nested(results_container)\n",
    "print('='*20)\n",
    "print_nested(debug_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a082cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e7267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tickers = ['SPY', 'AAPL', 'IWM', 'QQQ', 'META', 'EEM', 'BABA']\n",
    "my_tickers = ['NTES', 'LII',]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e0c43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have run the variables setup from the previous step\n",
    "snapshot_df = debug_container[0]['audit_liquidity']['universe_snapshot']\n",
    "\n",
    "if 'AAPL' in snapshot_df.index:\n",
    "    display(snapshot_df.loc[['AAPL']])\n",
    "else:\n",
    "    print(\"AAPL was not present in the data for this date.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32da9680",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "snapshot_df.to_csv('./export_csv/snapshot_df.csv')\n",
    "print(f\"âœ… Snapshot exported to: ./export_csv/snapshot_df.csv\")\n",
    "print(f\"   Shape: {snapshot_df.shape}\")\n",
    "print(f\"   Columns: {list(snapshot_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5e1e53",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Access the data inside the container list\n",
    "current_debug_data = debug_container[0]\n",
    "\n",
    "# 2. Check if the audit data exists (it is created only in 'Ranking' mode)\n",
    "if current_debug_data and 'audit_liquidity' in current_debug_data:\n",
    "    audit = current_debug_data['audit_liquidity']\n",
    "    snapshot_df = audit['universe_snapshot']\n",
    "    \n",
    "    print(f\"ðŸ“… Date: {audit['date'].date()}\")\n",
    "    print(f\"ðŸ’° Calculated Cutoff: ${audit['final_cutoff_usd']:,.0f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# 3. View the tickers right around the cutoff point\n",
    "# Find the index where 'Passed_Vol_Check' switches from True to False\n",
    "    try:\n",
    "        # Get the integer location (iloc) of the last True value\n",
    "        last_pass_iloc = np.where(snapshot_df['Passed_Vol_Check'])[0][-1]\n",
    "        \n",
    "        # Show 5 rows before and 5 rows after the cutoff\n",
    "        start = max(0, last_pass_iloc - 5)\n",
    "        end = min(len(snapshot_df), last_pass_iloc + 6)\n",
    "        \n",
    "        display(snapshot_df.iloc[start:end].style.format({\n",
    "            'RollMedDollarVol': '${:,.0f}',\n",
    "            'Calculated_Cutoff': '${:,.0f}',\n",
    "            'RollingStalePct': '{:.1%}'\n",
    "        }))\n",
    "    except IndexError:\n",
    "        print(\"Could not determine cutoff boundary (maybe all passed or all failed).\")\n",
    "        display(snapshot_df.head())\n",
    "else:\n",
    "    print(\"âš ï¸ No audit data found. Make sure you are in 'Ranking' mode and have clicked 'Update Chart'.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b6b19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(snapshot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2989c8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STARTING ALL TESTS FOR generate_features()\n",
      "============================================================\n",
      "Running test_true_range_calculation...\n",
      "test_true_range_df:\n",
      "                   Adj Open  Adj High  Adj Low  Adj Close  Volume\n",
      "Ticker Date                                                      \n",
      "TEST   2024-01-01       100       105       95        100    1000\n",
      "       2024-01-02       105       108      103        106    1200\n",
      "       2024-01-03        95        97       93         96     800\n",
      "       2024-01-04        98       102      100         99     900\n",
      "       2024-01-05       102       105       98        103    1100\n",
      "\n",
      "\n",
      "Generated DataFrame:\n",
      "                     TR     ATR    ATRP  RollingStalePct  RollMedDollarVol  RollingSameVolCount\n",
      "Ticker Date                                                                                    \n",
      "TEST   2024-01-01   NaN     NaN     NaN              NaN               NaN                  NaN\n",
      "       2024-01-02   8.0  8.0000  0.0755              0.0          113600.0                  0.0\n",
      "       2024-01-03  13.0  8.3571  0.0871              0.0          100000.0                  0.0\n",
      "       2024-01-04   6.0  8.1888  0.0827              0.0           94550.0                  0.0\n",
      "       2024-01-05   7.0  8.1039  0.0787              0.0          100000.0                  0.0\n",
      "âœ“ Day 1 TR is NaN (correct - no previous close)\n",
      "âœ“ Day 2 TR is 8.0 (expected 8.0) - Previous Close BETWEEN High and Low\n",
      "âœ“ Day 3 TR is 13.0 (expected 13.0) - Previous Close ABOVE High\n",
      "âœ“ Day 4 TR is 6.0 (expected 6.0) - Previous Close BELOW Low\n",
      "âœ“ Day 5 TR is 7.0 (expected 7.0) - Previous Close BETWEEN, High-Low dominates\n",
      "\n",
      "âœ… All TR tests passed! All conditions covered:\n",
      "   - Day 2: Previous Close (100) BETWEEN High (108) and Low (103)\n",
      "   - Day 3: Previous Close (106) ABOVE High (97)\n",
      "   - Day 4: Previous Close (96) BELOW Low (100)\n",
      "   - Day 5: Previous Close (99) BETWEEN High (105) and Low (98)\n",
      "\n",
      "==================================================\n",
      "Running test_atr_calculation...\n",
      "test_true_range_df:\n",
      "                   Adj Open  Adj High  Adj Low  Adj Close  Volume\n",
      "Ticker Date                                                      \n",
      "TEST   2024-01-01       100       101       99        100    1000\n",
      "       2024-01-02       102       103      101        102    1000\n",
      "       2024-01-03       103       103      103        103    1000\n",
      "       2024-01-04       110       112      108        111    1000\n",
      "       2024-01-05       108       110      107        109    1000\n",
      "\n",
      "\n",
      "ATR Calculation Results:\n",
      "                    TR     ATR    ATRP\n",
      "Ticker Date                           \n",
      "TEST   2024-01-01  NaN     NaN     NaN\n",
      "       2024-01-02  3.0  3.0000  0.0294\n",
      "       2024-01-03  1.0  2.8571  0.0277\n",
      "       2024-01-04  9.0  3.2959  0.0297\n",
      "       2024-01-05  4.0  3.3462  0.0307\n",
      "âœ“ 2024-01-02 ATR: 3.000000 â‰ˆ 3.000000\n",
      "âœ“ 2024-01-03 ATR: 2.857143 â‰ˆ 2.857143\n",
      "âœ“ 2024-01-04 ATR: 3.295918 â‰ˆ 3.295918\n",
      "âœ“ 2024-01-05 ATR: 3.346210 â‰ˆ 3.346210\n",
      "\n",
      "âœ… All ATR tests passed!\n",
      "\n",
      "==================================================\n",
      "Running test_is_stale_calculation...\n",
      "test_is_stale_df:\n",
      "                   Adj Open  Adj High  Adj Low  Adj Close  Volume\n",
      "Ticker Date                                                      \n",
      "TEST   2024-01-01       100       101       99        100    1000\n",
      "       2024-01-02       102       103      101        102       0\n",
      "       2024-01-03       103       103      103        103     500\n",
      "       2024-01-04       104       105      104        105    1000\n",
      "\n",
      "\n",
      "ðŸ“Š Manual IsStale Calculation:\n",
      "==================================================\n",
      "IsStale = 1 if EITHER condition is true:\n",
      "  1. Volume == 0\n",
      "  2. Adj High == Adj Low (no price movement)\n",
      "Otherwise, IsStale = 0\n",
      "==================================================\n",
      "\n",
      "Calculation details:\n",
      "  TEST, 2024-01-01:\n",
      "    Volume=1000, High=101, Low=99\n",
      "    Conditions met: None (both False)\n",
      "    â†’ IsStale = 0\n",
      "\n",
      "  TEST, 2024-01-02:\n",
      "    Volume=0, High=103, Low=101\n",
      "    Conditions met: Volume=0\n",
      "    â†’ IsStale = 1\n",
      "\n",
      "  TEST, 2024-01-03:\n",
      "    Volume=500, High=103, Low=103\n",
      "    Conditions met: High=Low\n",
      "    â†’ IsStale = 1\n",
      "\n",
      "  TEST, 2024-01-04:\n",
      "    Volume=1000, High=105, Low=104\n",
      "    Conditions met: None (both False)\n",
      "    â†’ IsStale = 0\n",
      "\n",
      "\n",
      "Manual IsStale calculation: [0 1 1 0]\n",
      "Expected: [0, 1, 1, 0]\n",
      "âœ“ IsStale calculation logic is correct\n",
      "\n",
      "==================================================\n",
      "Running test_multiple_tickers...\n",
      "test_multiple_tickers_df:\n",
      "                   Adj Open  Adj High  Adj Low  Adj Close  Volume\n",
      "Ticker Date                                                      \n",
      "A      2024-01-01       100       101       99        100    1000\n",
      "       2024-01-02       102       103      101        102    1000\n",
      "B      2024-01-01        50        52       48         49    2000\n",
      "       2024-01-02        51        53       49         52    2000\n",
      "\n",
      "\n",
      "Multiple Ticker Results:\n",
      "                    TR  ATR\n",
      "Ticker Date                \n",
      "A      2024-01-01  NaN  NaN\n",
      "       2024-01-02  3.0  3.0\n",
      "B      2024-01-01  NaN  NaN\n",
      "       2024-01-02  4.0  4.0\n",
      "âœ“ Ticker A TR: 3.0 (expected 3.0)\n",
      "âœ“ Ticker B TR: 4.0 (expected 4.0)\n",
      "âœ… Ticker separation test passed!\n",
      "\n",
      "==================================================\n",
      "Running test_edge_cases...\n",
      "\n",
      "1. Testing penny stock with low price...\n",
      "df_penny_stock:\n",
      "                   Adj Open  Adj High  Adj Low  Adj Close  Volume\n",
      "Ticker Date                                                      \n",
      "PENNY  2024-01-01      0.10      0.10     0.10       0.10    1000\n",
      "       2024-01-02      0.11      0.11     0.11       0.11    1000\n",
      "\n",
      "âœ“ Penny stock ATRP is 0.0909\n",
      "\n",
      "2. Testing single row data...\n",
      "df_single:\n",
      "                   Adj Open  Adj High  Adj Low  Adj Close  Volume\n",
      "Ticker Date                                                      \n",
      "SINGLE 2024-01-01       100       101       99        100    1000\n",
      "\n",
      "âœ“ Single row TR is NaN (correct)\n",
      "âœ“ Single row rolling metrics are NaN (correct - insufficient periods)\n",
      "\n",
      "âœ… All edge case tests passed!\n",
      "\n",
      "============================================================\n",
      "TEST SUMMARY\n",
      "============================================================\n",
      "âœ… PASS: TR Calculation\n",
      "âœ… PASS: ATR Calculation\n",
      "âœ… PASS: IsStale Calculation\n",
      "âœ… PASS: Multiple Tickers\n",
      "âœ… PASS: Edge Cases\n",
      "\n",
      "============================================================\n",
      "TOTAL: 5/5 tests passed (100.0%)\n",
      "============================================================\n",
      "\n",
      "ðŸŽ‰ ALL TESTS PASSED! Your feature calculations are working correctly.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def test_true_range_calculation():\n",
    "    \"\"\"Test TR = max(High-Low, |High-PrevClose|, |Low-PrevClose|)\"\"\"\n",
    "    print(\"Running test_true_range_calculation...\")\n",
    "    \n",
    "    # 1. SETUP: Create test data for all three conditions\n",
    "    test_data = {\n",
    "        'Adj Open': [100, 105, 95, 98, 102],\n",
    "        'Adj High': [105, 108, 97, 102, 105],\n",
    "        'Adj Low': [95, 103, 93, 100, 98],\n",
    "        'Adj Close': [100, 106, 96, 99, 103],\n",
    "        'Volume': [1000, 1200, 800, 900, 1100]\n",
    "    }\n",
    "    \n",
    "    index = pd.MultiIndex.from_tuples(\n",
    "        [\n",
    "            ('TEST', pd.Timestamp('2024-01-01')),  # Day 1: No previous close\n",
    "            ('TEST', pd.Timestamp('2024-01-02')),  # Day 2: Prev close = 100, High=108, Low=103\n",
    "            ('TEST', pd.Timestamp('2024-01-03')),  # Day 3: Prev close = 106, High=97, Low=93\n",
    "            ('TEST', pd.Timestamp('2024-01-04')),  # Day 4: Prev close = 96, High=102, Low=100\n",
    "            ('TEST', pd.Timestamp('2024-01-05')),  # Day 5: Prev close = 99, High=105, Low=98\n",
    "        ],\n",
    "        names=['Ticker', 'Date']\n",
    "    )\n",
    "    \n",
    "    df_test = pd.DataFrame(test_data, index=index)\n",
    "\n",
    "    print(f'test_true_range_df:\\n{df_test}\\n')\n",
    "    \n",
    "    # 2. EXECUTION: Run function with small window for testing\n",
    "    result = generate_features(df_test, quality_window=5, quality_min_periods=2)\n",
    "    \n",
    "    print(\"\\nGenerated DataFrame:\")\n",
    "    print(result)\n",
    "    \n",
    "    # 3. ASSERTIONS: Verify TR values for all conditions\n",
    "    \n",
    "    all_passed = True\n",
    "    \n",
    "    # Day 1: Should be NaN (no previous close)\n",
    "    if pd.isna(result.loc[('TEST', '2024-01-01'), 'TR']):\n",
    "        print(\"âœ“ Day 1 TR is NaN (correct - no previous close)\")\n",
    "    else:\n",
    "        print(f\"âœ— Day 1 TR should be NaN but got: {result.loc[('TEST', '2024-01-01'), 'TR']}\")\n",
    "        all_passed = False\n",
    "    \n",
    "    # Day 2: Condition 1 - Previous Close (100) is BETWEEN today's High (108) and Low (103)\n",
    "    # max(108-103=5, |108-100|=8, |103-100|=3) = 8\n",
    "    expected_tr_day2 = 8.0\n",
    "    actual_tr_day2 = result.loc[('TEST', '2024-01-02'), 'TR']\n",
    "    if abs(actual_tr_day2 - expected_tr_day2) < 0.0001:\n",
    "        print(f\"âœ“ Day 2 TR is {actual_tr_day2} (expected {expected_tr_day2}) - Previous Close BETWEEN High and Low\")\n",
    "    else:\n",
    "        print(f\"âœ— Day 2 TR should be {expected_tr_day2} but got {actual_tr_day2}\")\n",
    "        all_passed = False\n",
    "    \n",
    "    # Day 3: Condition 2 - Previous Close (106) is ABOVE today's High (97)\n",
    "    # max(97-93=4, |97-106|=9, |93-106|=13) = 13\n",
    "    expected_tr_day3 = 13.0\n",
    "    actual_tr_day3 = result.loc[('TEST', '2024-01-03'), 'TR']\n",
    "    if abs(actual_tr_day3 - expected_tr_day3) < 0.0001:\n",
    "        print(f\"âœ“ Day 3 TR is {actual_tr_day3} (expected {expected_tr_day3}) - Previous Close ABOVE High\")\n",
    "    else:\n",
    "        print(f\"âœ— Day 3 TR should be {expected_tr_day3} but got {actual_tr_day3}\")\n",
    "        all_passed = False\n",
    "    \n",
    "    # Day 4: Condition 3 - Previous Close (96) is BELOW today's Low (100)\n",
    "    # max(102-100=2, |102-96|=6, |100-96|=4) = 6\n",
    "    expected_tr_day4 = 6.0\n",
    "    actual_tr_day4 = result.loc[('TEST', '2024-01-04'), 'TR']\n",
    "    if abs(actual_tr_day4 - expected_tr_day4) < 0.0001:\n",
    "        print(f\"âœ“ Day 4 TR is {actual_tr_day4} (expected {expected_tr_day4}) - Previous Close BELOW Low\")\n",
    "    else:\n",
    "        print(f\"âœ— Day 4 TR should be {expected_tr_day4} but got {actual_tr_day4}\")\n",
    "        all_passed = False\n",
    "    \n",
    "    # Day 5: Additional test - Previous Close (99) is BETWEEN today's High (105) and Low (98)\n",
    "    # max(105-98=7, |105-99|=6, |98-99|=1) = 7 (High-Low dominates)\n",
    "    expected_tr_day5 = 7.0\n",
    "    actual_tr_day5 = result.loc[('TEST', '2024-01-05'), 'TR']\n",
    "    if abs(actual_tr_day5 - expected_tr_day5) < 0.0001:\n",
    "        print(f\"âœ“ Day 5 TR is {actual_tr_day5} (expected {expected_tr_day5}) - Previous Close BETWEEN, High-Low dominates\")\n",
    "    else:\n",
    "        print(f\"âœ— Day 5 TR should be {expected_tr_day5} but got {actual_tr_day5}\")\n",
    "        all_passed = False\n",
    "    \n",
    "    if all_passed:\n",
    "        print(\"\\nâœ… All TR tests passed! All conditions covered:\")\n",
    "        print(\"   - Day 2: Previous Close (100) BETWEEN High (108) and Low (103)\")\n",
    "        print(\"   - Day 3: Previous Close (106) ABOVE High (97)\")\n",
    "        print(\"   - Day 4: Previous Close (96) BELOW Low (100)\")\n",
    "        print(\"   - Day 5: Previous Close (99) BETWEEN High (105) and Low (98)\")\n",
    "    else:\n",
    "        print(\"\\nâŒ Some tests failed!\")\n",
    "    \n",
    "    return all_passed\n",
    "\n",
    "def test_atr_calculation():\n",
    "    \"\"\"Test ATR = EWMA of TR with alpha=1/period\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Running test_atr_calculation...\")\n",
    "    \n",
    "    # Test data with 5 days\n",
    "    test_data = {\n",
    "        'Adj Open': [100, 102, 103, 110, 108],\n",
    "        'Adj High': [101, 103, 103, 112, 110],\n",
    "        'Adj Low': [99, 101, 103, 108, 107],\n",
    "        'Adj Close': [100, 102, 103, 111, 109],\n",
    "        'Volume': [1000, 1000, 1000, 1000, 1000]  # All non-zero for simplicity\n",
    "    }\n",
    "    \n",
    "    index = pd.MultiIndex.from_tuples(\n",
    "        [('TEST', pd.Timestamp(f'2024-01-{i:02d}')) for i in range(1, 6)],\n",
    "        names=['Ticker', 'Date']\n",
    "    )\n",
    "    \n",
    "    df_test = pd.DataFrame(test_data, index=index)\n",
    "\n",
    "    print(f'test_true_range_df:\\n{df_test}\\n')\n",
    "\n",
    "    result = generate_features(df_test, atr_period=14)\n",
    "    \n",
    "    print(\"\\nATR Calculation Results:\")\n",
    "    print(result[['TR', 'ATR', 'ATRP']])\n",
    "    \n",
    "    # Manual calculation from our earlier example\n",
    "    # CORRECTED EXPECTED VALUES WITH MORE PRECISION\n",
    "    expected_atr = {\n",
    "        '2024-01-02': 3.0,\n",
    "        '2024-01-03': 40/14,  # â‰ˆ 2.857142857142857\n",
    "        '2024-01-04': 646/196,  # â‰ˆ 3.2959183673469388\n",
    "        '2024-01-05': 9182/2744,  # â‰ˆ 3.3462099125364433\n",
    "    }\n",
    "\n",
    "    all_passed = True\n",
    "    for date_str, expected in expected_atr.items():\n",
    "        actual = result.loc[('TEST', pd.Timestamp(date_str)), 'ATR']\n",
    "        if abs(actual - expected) < 0.0001:\n",
    "            print(f\"âœ“ {date_str} ATR: {actual:.6f} â‰ˆ {expected:.6f}\")\n",
    "        else:\n",
    "            print(f\"âœ— {date_str} ATR: {actual:.6f} != {expected:.6f}\")\n",
    "            all_passed = False\n",
    "    \n",
    "    if all_passed:\n",
    "        print(\"\\nâœ… All ATR tests passed!\")\n",
    "    else:\n",
    "        print(\"\\nâŒ Some ATR tests failed!\")\n",
    "    \n",
    "    return all_passed\n",
    "\n",
    "def test_is_stale_calculation():\n",
    "    \"\"\"Test IsStale = 1 when Volume=0 OR High=Low\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Running test_is_stale_calculation...\")\n",
    "    \n",
    "    test_data = {\n",
    "        'Adj Open': [100, 102, 103, 104],\n",
    "        'Adj High': [101, 103, 103, 105],  # Day 3: High=Low\n",
    "        'Adj Low': [99, 101, 103, 104],\n",
    "        'Adj Close': [100, 102, 103, 105],\n",
    "        'Volume': [1000, 0, 500, 1000]  # Day 2: Volume=0\n",
    "    }\n",
    "    \n",
    "    index = pd.MultiIndex.from_tuples(\n",
    "        [('TEST', pd.Timestamp(f'2024-01-{i:02d}')) for i in range(1, 5)],\n",
    "        names=['Ticker', 'Date']\n",
    "    )\n",
    "    \n",
    "    df_test = pd.DataFrame(test_data, index=index)\n",
    "\n",
    "    print(f'test_is_stale_df:\\n{df_test}\\n')\n",
    "\n",
    "    # Create IsStale manually to verify\n",
    "    is_stale_manual = np.where(\n",
    "        (df_test['Volume'] == 0) | (df_test['Adj High'] == df_test['Adj Low']),\n",
    "        1, 0\n",
    "    )\n",
    "    \n",
    "    print(\"\\nðŸ“Š Manual IsStale Calculation:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"IsStale = 1 if EITHER condition is true:\")\n",
    "    print(\"  1. Volume == 0\")\n",
    "    print(\"  2. Adj High == Adj Low (no price movement)\")\n",
    "    print(\"Otherwise, IsStale = 0\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Create a temporary DataFrame to display the calculation clearly\n",
    "    manual_calc_df = df_test.copy()\n",
    "    manual_calc_df['IsStale_Manual'] = is_stale_manual\n",
    "    manual_calc_df['Volume==0'] = manual_calc_df['Volume'] == 0\n",
    "    manual_calc_df['High==Low'] = manual_calc_df['Adj High'] == manual_calc_df['Adj Low']\n",
    "    \n",
    "    print(\"\\nCalculation details:\")\n",
    "    for idx, row in manual_calc_df.iterrows():\n",
    "        ticker_date = f\"{idx[0]}, {idx[1].strftime('%Y-%m-%d')}\"\n",
    "        conditions = []\n",
    "        if row['Volume==0']:\n",
    "            conditions.append(\"Volume=0\")\n",
    "        if row['High==Low']:\n",
    "            conditions.append(\"High=Low\")\n",
    "        \n",
    "        condition_str = \" OR \".join(conditions) if conditions else \"None (both False)\"\n",
    "        result = row['IsStale_Manual']\n",
    "        \n",
    "        print(f\"  {ticker_date}:\")\n",
    "        print(f\"    Volume={row['Volume']}, High={row['Adj High']}, Low={row['Adj Low']}\")\n",
    "        print(f\"    Conditions met: {condition_str}\")\n",
    "        print(f\"    â†’ IsStale = {result}\")\n",
    "        print()\n",
    "\n",
    "    expected = [0, 1, 1, 0]  # Day 1: normal, Day 2: vol=0, Day 3: high=low, Day 4: normal\n",
    "    \n",
    "    print(f\"\\nManual IsStale calculation: {is_stale_manual}\")\n",
    "    print(f\"Expected: {expected}\")\n",
    "    \n",
    "    if list(is_stale_manual) == expected:\n",
    "        print(\"âœ“ IsStale calculation logic is correct\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"âœ— IsStale calculation failed. Got {is_stale_manual}, expected {expected}\")\n",
    "        return False\n",
    "\n",
    "def test_multiple_tickers():\n",
    "    \"\"\"Test that calculations don't mix data between tickers\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Running test_multiple_tickers...\")\n",
    "    \n",
    "    test_data = {\n",
    "        'Adj Open': [100, 102, 50, 51],\n",
    "        'Adj High': [101, 103, 52, 53],\n",
    "        'Adj Low': [99, 101, 48, 49],\n",
    "        'Adj Close': [100, 102, 49, 52],\n",
    "        'Volume': [1000, 1000, 2000, 2000]\n",
    "    }\n",
    "    \n",
    "    index = pd.MultiIndex.from_tuples([\n",
    "        ('A', pd.Timestamp('2024-01-01')),\n",
    "        ('A', pd.Timestamp('2024-01-02')),\n",
    "        ('B', pd.Timestamp('2024-01-01')),\n",
    "        ('B', pd.Timestamp('2024-01-02')),\n",
    "    ], names=['Ticker', 'Date'])\n",
    "    \n",
    "    df_test = pd.DataFrame(test_data, index=index)\n",
    "\n",
    "    print(f'test_multiple_tickers_df:\\n{df_test}\\n')\n",
    "\n",
    "    result = generate_features(df_test)\n",
    "    \n",
    "    print(\"\\nMultiple Ticker Results:\")\n",
    "    print(result[['TR', 'ATR']])\n",
    "    \n",
    "    # Ticker A day 2 TR should use A day 1 close, not B day 1 close\n",
    "    tr_a2 = result.loc[('A', '2024-01-02'), 'TR']\n",
    "    expected_a2 = 3.0  # max(103-101=2, |103-100|=3, |101-100|=1) = 3\n",
    "    \n",
    "    tr_b2 = result.loc[('B', '2024-01-02'), 'TR']\n",
    "    expected_b2 = 4.0  # max(53-49=4, |53-49|=4, |49-49|=0) = 4\n",
    "    \n",
    "    tests_passed = 0\n",
    "    total_tests = 2\n",
    "    \n",
    "    if abs(tr_a2 - expected_a2) < 0.0001:\n",
    "        print(f\"âœ“ Ticker A TR: {tr_a2} (expected {expected_a2})\")\n",
    "        tests_passed += 1\n",
    "    else:\n",
    "        print(f\"âœ— Ticker A TR: {tr_a2} != {expected_a2}\")\n",
    "    \n",
    "    if abs(tr_b2 - expected_b2) < 0.0001:\n",
    "        print(f\"âœ“ Ticker B TR: {tr_b2} (expected {expected_b2})\")\n",
    "        tests_passed += 1\n",
    "    else:\n",
    "        print(f\"âœ— Ticker B TR: {tr_b2} != {expected_b2}\")\n",
    "    \n",
    "    if tests_passed == total_tests:\n",
    "        print(\"âœ… Ticker separation test passed!\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"âŒ Ticker separation test failed: {tests_passed}/{total_tests} passed\")\n",
    "        return False\n",
    "\n",
    "def test_edge_cases():\n",
    "    \"\"\"Test edge cases like zero price, single row, etc.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Running test_edge_cases...\")\n",
    "    \n",
    "    all_passed = True\n",
    "    \n",
    "    # Test 1: Very low price (penny stock)\n",
    "    print(\"\\n1. Testing penny stock with low price...\")\n",
    "    test_data = {\n",
    "        'Adj Open': [0.10, 0.11],\n",
    "        'Adj High': [0.10, 0.11],\n",
    "        'Adj Low': [0.10, 0.11],\n",
    "        'Adj Close': [0.10, 0.11],\n",
    "        'Volume': [1000, 1000]\n",
    "    }\n",
    "    \n",
    "    index = pd.MultiIndex.from_tuples([\n",
    "        ('PENNY', pd.Timestamp('2024-01-01')),\n",
    "        ('PENNY', pd.Timestamp('2024-01-02')),\n",
    "    ], names=['Ticker', 'Date'])\n",
    "    \n",
    "    df_penny = pd.DataFrame(test_data, index=index)\n",
    "\n",
    "    print(f'df_penny_stock:\\n{df_penny}\\n')\n",
    "\n",
    "    result = generate_features(df_penny)\n",
    "    \n",
    "    # Check ATRP is reasonable (not inf/nan)\n",
    "    atrp_val = result.loc[('PENNY', '2024-01-02'), 'ATRP']\n",
    "    if pd.isna(atrp_val) or np.isinf(atrp_val):\n",
    "        print(f\"âœ— Penny stock ATRP is {atrp_val} (should be finite)\")\n",
    "        all_passed = False\n",
    "    else:\n",
    "        print(f\"âœ“ Penny stock ATRP is {atrp_val:.4f}\")\n",
    "    \n",
    "    # Test 2: Single row\n",
    "    print(\"\\n2. Testing single row data...\")\n",
    "    test_data_single = {\n",
    "        'Adj Open': [100],\n",
    "        'Adj High': [101],\n",
    "        'Adj Low': [99],\n",
    "        'Adj Close': [100],\n",
    "        'Volume': [1000]\n",
    "    }\n",
    "    \n",
    "    index_single = pd.MultiIndex.from_tuples(\n",
    "        [('SINGLE', pd.Timestamp('2024-01-01'))],\n",
    "        names=['Ticker', 'Date']\n",
    "    )\n",
    "    \n",
    "    df_single = pd.DataFrame(test_data_single, index=index_single)\n",
    "\n",
    "    print(f'df_single:\\n{df_single}\\n')\n",
    "\n",
    "    result_single = generate_features(df_single, quality_window=3, quality_min_periods=2)\n",
    "    \n",
    "    # TR should be NaN (no previous close)\n",
    "    if pd.isna(result_single.loc[('SINGLE', '2024-01-01'), 'TR']):\n",
    "        print(\"âœ“ Single row TR is NaN (correct)\")\n",
    "    else:\n",
    "        print(f\"âœ— Single row TR should be NaN but got {result_single.loc[('SINGLE', '2024-01-01'), 'TR']}\")\n",
    "        all_passed = False\n",
    "    \n",
    "    # Rolling metrics should be NaN with min_periods=2\n",
    "    if pd.isna(result_single.loc[('SINGLE', '2024-01-01'), 'RollingStalePct']):\n",
    "        print(\"âœ“ Single row rolling metrics are NaN (correct - insufficient periods)\")\n",
    "    else:\n",
    "        print(f\"âœ— Rolling metrics should be NaN but got {result_single.loc[('SINGLE', '2024-01-01'), 'RollingStalePct']}\")\n",
    "        all_passed = False\n",
    "    \n",
    "    if all_passed:\n",
    "        print(\"\\nâœ… All edge case tests passed!\")\n",
    "    else:\n",
    "        print(\"\\nâŒ Some edge case tests failed!\")\n",
    "    \n",
    "    return all_passed\n",
    "\n",
    "\n",
    "def run_all_tests():\n",
    "    \"\"\"Run all tests and provide summary\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"STARTING ALL TESTS FOR generate_features()\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    test_results = {}\n",
    "    \n",
    "    # Run each test\n",
    "    test_results['TR Calculation'] = test_true_range_calculation()\n",
    "    test_results['ATR Calculation'] = test_atr_calculation()\n",
    "    test_results['IsStale Calculation'] = test_is_stale_calculation()\n",
    "    test_results['Multiple Tickers'] = test_multiple_tickers()\n",
    "    test_results['Edge Cases'] = test_edge_cases()\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEST SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    passed = sum(test_results.values())\n",
    "    total = len(test_results)\n",
    "    \n",
    "    for test_name, result in test_results.items():\n",
    "        status = \"âœ… PASS\" if result else \"âŒ FAIL\"\n",
    "        print(f\"{status}: {test_name}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"TOTAL: {passed}/{total} tests passed ({passed/total*100:.1f}%)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if passed == total:\n",
    "        print(\"\\nðŸŽ‰ ALL TESTS PASSED! Your feature calculations are working correctly.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸  {total - passed} test(s) failed. Review the output above.\")\n",
    "        return False\n",
    "\n",
    "run_all_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328b126b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.test_true_range_calculation()>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the specific test\n",
    "pytest test_features.py::test_true_range_calculation -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d210b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "================================  \n",
    "================================  \n",
    "================================  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05cafb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
