{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9ae2708",
   "metadata": {},
   "source": [
    "# Here is the refactored solution. I have separated the concerns into three distinct layers:\n",
    "1.  **The Data Contract:** explicit `dataclasses` defining exactly what goes in and comes out.\n",
    "2.  **The Engine:** A purely mathematical class (`AlphaEngine`) containing the logic, with no widget/plotting dependencies.\n",
    "3.  **The UI:** A cleaned-up dashboard function that simply sends inputs to the Engine and visualizes the Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc79d79",
   "metadata": {},
   "source": [
    "### Following is the reverse chronological fix log (most recent entry is at the top )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e7f873",
   "metadata": {},
   "source": [
    "v38  \n",
    "Added Momentum and Pullback strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1ecc32",
   "metadata": {},
   "source": [
    "v37  \n",
    "For an automated bot (and for rigorous scientific testing), **Silent Auto-Correction (Clamping)** is dangerous. If the bot asks for \"2080\" and receives data for \"2025\", it creates \"Data Hallucinations.\"\n",
    "\n",
    "We need to replace the \"Clamping\" logic with **\"Strict Validation\" logic**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d784b62",
   "metadata": {},
   "source": [
    "v36  \n",
    "The step `self.df_close = df_ohlcv['Adj Close'].unstack(level=0)` is an expensive \"Pivot\" operation. It takes a \"Tall and Skinny\" table (1 million rows) and reshapes it into a \"Short and Wide\" matrix (Dates x Tickers). Pandas hates doing this repeatedly.\n",
    "\n",
    "Yes, we can pre-compute this matrix and pass it in, just like we did with the featur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92185d85",
   "metadata": {},
   "source": [
    "v35  \n",
    "This is a great optimization step. In data science, this is called **\"Memoization\"** or **\"Caching\"**‚Äîdo the heavy math once, save it, and reuse it.\n",
    "\n",
    "To achieve this, we need to modify the **`AlphaEngine` constructor** to accept pre-calculated features, and update the **`plot_walk_forward_analyzer`** to pass them down.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7578ec93",
   "metadata": {},
   "source": [
    "v34  \n",
    "I have refactored **SECTION D (`AlphaEngine.run`)** to implement the \"Decision Anchor\" logic, and **SECTION E (`plot_walk_forward_analyzer`)** to implement the new \"Timeline\" UI layout and renaming.\n",
    "\n",
    "### Key Changes:\n",
    "1.  **Engine Logic:** The `start_date` input is now treated as the **Decision Date (T0)**. The engine calculates backward for the Lookback period and forward for the Holding period.\n",
    "2.  **Universe Selection:** Tickers are now filtered based on liquidity **on the Decision Date**, not the start of history.\n",
    "3.  **UI Layout:** Inputs are arranged horizontally: `[Lookback] <-> [Decision Date] <-> [Holding]`.\n",
    "4.  **Renaming:** \"Metric\" is now **\"Strategy\"**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17abb82d",
   "metadata": {},
   "source": [
    "v33  \n",
    "**Action Item to make it perfect:**\n",
    "Change the \"Fwd Gain\" calculation in `AlphaEngine.run` to skip one day, or accept that your results are slightly optimistic due to the \"Overnight Gap\" bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68b1a41",
   "metadata": {},
   "source": [
    "```\n",
    "To see the full dataframe of all tickers (both those that passed and those that failed) for a specific date, we need to capture a snapshot of the universe inside the `_get_eligible_universe` method.\n",
    "\n",
    "I have updated the **`AlphaEngine`** class below.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30d1f60",
   "metadata": {},
   "source": [
    "```\n",
    "To verify that the relative percentile logic is working, we can modify the `AlphaEngine` to report exactly **how the cutoff was calculated** for the specific start date.\n",
    "\n",
    "We want to see evidence that:\n",
    "1.  In earlier years (e.g., 2005), the volume cutoff is lower (e.g., $200k).\n",
    "2.  In later years (e.g., 2024), the volume cutoff is higher (e.g., $5M).\n",
    "\n",
    "Here is the updated `AlphaEngine` and `UI` code. I have added a **\"Audit Log\"** feature. When you run the tool, it will now print exactly what the Dollar Volume Threshold was for that specific day.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50de4e99",
   "metadata": {},
   "source": [
    "```\n",
    "The best way to solve this is to switch from a **Fixed Dollar Threshold** (e.g., \"$1 Million\") to a **Relative Percentile Threshold** (e.g., \"Top 50% of the market\").\n",
    "\n",
    "In 2004, a stock trading $200k might have been in the top 50% of liquid stocks. In 2024, that same $200k is illiquid garbage. Using a percentile automatically adjusts for inflation and market growth over time.\n",
    "\n",
    "Here is how to modify your code to support this.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e8a3b9",
   "metadata": {},
   "source": [
    "```\n",
    "To fix this, we need to pass the **actual** calculated start date (the trading day the engine \"snapped\" to) back from the `AlphaEngine` to the UI. Then, the UI can compare the *Requested Date* vs. the *Actual Date* and display the warning message if they differ.\n",
    "\n",
    "Here is the plan:\n",
    "1.  **Update `EngineOutput`**: Add a `start_date` field to the dataclass.\n",
    "2.  **Update `AlphaEngine.run`**: Populate this new field with `safe_start_date`.\n",
    "3.  **Update `plot_walk_forward_analyzer`**: Add logic to compare the user's input date with the engine's returned date and print the \"Info\" message if they are different.\n",
    "\n",
    "Here is the updated code (Sections C, D, and E have changed):\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb918f61",
   "metadata": {},
   "source": [
    "```\n",
    "I have updated the `AlphaEngine.run` method. specifically inside the `if inputs.mode == 'Manual List':` block. It now iterates through every manual ticker and performs two checks:\n",
    "1.  **Existence**: Is the ticker in the database?\n",
    "2.  **Availability**: Does the ticker have a valid price on the specific `Start Date`?\n",
    "\n",
    "If any ticker fails, it compiles a specific error message explaining why (e.g., \"No price data on start date\") and aborts the calculation immediately.  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b728a8",
   "metadata": {},
   "source": [
    "```\n",
    "The `snapshot_df` contains **every single feature** calculated by your `generate_features` function for that specific day, plus the new audit columns we added.\n",
    "\n",
    "Here is exactly what is inside that DataFrame:\n",
    "\n",
    "### 1. The Core Features (from `generate_features`)\n",
    "*   **`TR`**: True Range\n",
    "*   **`ATR`**: Average True Range\n",
    "*   **`ATRP`**: Average True Range Percent (Volatility)\n",
    "*   **`RollingStalePct`**: How often the price didn't move or volume was 0.\n",
    "*   **`RollMedDollarVol`**: Median Daily Dollar Volume (Liquidity).\n",
    "*   **`RollingSameVolCount`**: Data quality check for repeated volume numbers.\n",
    "\n",
    "### 2. The Audit Columns (Added during filtering)\n",
    "*   **`Calculated_Cutoff`**: The specific dollar amount required to pass on that day.\n",
    "*   **`Passed_Vol_Check`**: `True` if the ticker met the liquidity requirement.\n",
    "*   **`Passed_Final`**: `True` if it passed **all** checks (Liquidity + Stale + Quality).\n",
    "\n",
    "=========================================\n",
    "\n",
    "Here are the formulas translated directly into the Python `pandas` code used in your `generate_features` function.\n",
    "\n",
    "I have simplified the code slightly to assume a single ticker context (removing the `groupby` wrapper) so you can see the raw math clearly.\n",
    "\n",
    "### 1. True Range (TR)\n",
    "Calculates the maximum of the three price differences.\n",
    "\n",
    "prev_close = df_ohlcv['Adj Close'].shift(1)\n",
    "\n",
    "# The three components\n",
    "diff1 = df_ohlcv['Adj High'] - df_ohlcv['Adj Low']\n",
    "diff2 = (df_ohlcv['Adj High'] - prev_close).abs()\n",
    "diff3 = (df_ohlcv['Adj Low'] - prev_close).abs()\n",
    "\n",
    "# Taking the max of the three\n",
    "tr = pd.concat([diff1, diff2, diff3], axis=1).max(axis=1)\n",
    "\n",
    "### 2. Average True Range (ATR)\n",
    "Uses an Exponential Weighted Mean (EWM) with a specific alpha smoothing factor.\n",
    "\n",
    "# N = atr_period (e.g., 14)\n",
    "# alpha = 1 / N\n",
    "atr = tr.ewm(alpha=1/14, adjust=False).mean()\n",
    "\n",
    "### 3. ATR Percent (ATRP)\n",
    "Simple division to normalize volatility.\n",
    "\n",
    "atrp = atr / df_ohlcv['Adj Close']\n",
    "\n",
    "### 4. Rolling Stale Percentage\n",
    "Checks if volume is 0 OR if High equals Low (price didn't move), then averages that 1 or 0 signal over the window.\n",
    "\n",
    "# 1. Define the Stale Signal (1 for stale, 0 for active)\n",
    "is_stale = np.where(\n",
    "    (df_ohlcv['Volume'] == 0) | (df_ohlcv['Adj High'] == df_ohlcv['Adj Low']), \n",
    "    1,  \n",
    "    0\n",
    ")\n",
    "\n",
    "# 2. Calculate average over window (W=252)\n",
    "rolling_stale_pct = pd.Series(is_stale).rolling(window=252).mean()\n",
    "\n",
    "### 5. Rolling Median Dollar Volume\n",
    "Calculates raw dollar volume, then finds the median over the window.\n",
    "\n",
    "# 1. Calculate Daily Dollar Volume\n",
    "dollar_volume = df_ohlcv['Adj Close'] * df_ohlcv['Volume']\n",
    "\n",
    "# 2. Get Median over window (W=252)\n",
    "roll_med_dollar_vol = dollar_volume.rolling(window=252).median()\n",
    "\n",
    "### 6. Rolling Same Volume Count\n",
    "Checks if today's volume is exactly the same as yesterday's (a sign of bad data), then sums those occurrences.\n",
    "\n",
    "# 1. Check if Volume(t) - Volume(t-1) equals 0\n",
    "# .diff() calculates current row minus previous row\n",
    "has_same_volume = (df_ohlcv['Volume'].diff() == 0).astype(int)\n",
    "\n",
    "# 2. Sum the errors over window (W=252)\n",
    "rolling_same_vol_count = has_same_volume.rolling(window=252).sum()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb417c7",
   "metadata": {},
   "source": [
    "================================  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1110f2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets\n",
    "import pprint\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Optional, Any, Union\n",
    "from collections import Counter\n",
    "from datetime import datetime, date\n",
    "from pandas.testing import assert_series_equal\n",
    "\n",
    "# pd.set_option('display.max_rows', None)  display all rows\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "pd.set_option('display.precision', 4)\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION A: CORE HELPER FUNCTIONS & FEATURE GENERATION\n",
    "# (Unchanged from previous version)\n",
    "# ==============================================================================\n",
    "# ... (Keep generate_features, calculate_gain, calculate_sharpe, \n",
    "#      calculate_sharpe_atr, calculate_buy_and_hold_performance as is) ...\n",
    "\n",
    "def generate_features(df_ohlcv: pd.DataFrame, atr_period: int = 14, quality_window: int = 252, quality_min_periods: int = 126) -> pd.DataFrame:\n",
    "    # 1. Sort and Group\n",
    "    if not df_ohlcv.index.is_monotonic_increasing: \n",
    "        df_ohlcv = df_ohlcv.sort_index()\n",
    "    grouped = df_ohlcv.groupby(level='Ticker')\n",
    "    \n",
    "    # 2. ATR Calculation (Existing)\n",
    "    prev_close = grouped['Adj Close'].shift(1)\n",
    "    tr = pd.concat([\n",
    "        df_ohlcv['Adj High'] - df_ohlcv['Adj Low'], \n",
    "        abs(df_ohlcv['Adj High'] - prev_close), \n",
    "        abs(df_ohlcv['Adj Low'] - prev_close)\n",
    "    ], axis=1).max(axis=1, skipna=False)\n",
    "    \n",
    "    atr = tr.groupby(level='Ticker').transform(lambda x: x.ewm(alpha=1/atr_period, adjust=False).mean())\n",
    "    atrp = (atr / df_ohlcv['Adj Close']).replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    # 3. --- NEW: MOMENTUM / RETURN FEATURES ---\n",
    "    # We calculate percentage change for specific windows useful for Pullbacks (3D, 5D) and Trends (21D)\n",
    "    # Note: We use grouped.pct_change to respect Ticker boundaries\n",
    "    roc_1 = grouped['Adj Close'].pct_change(1)\n",
    "    roc_3 = grouped['Adj Close'].pct_change(3)\n",
    "    roc_5 = grouped['Adj Close'].pct_change(5)\n",
    "    roc_10 = grouped['Adj Close'].pct_change(10)\n",
    "    roc_21 = grouped['Adj Close'].pct_change(21)\n",
    "\n",
    "    indicator_df = pd.DataFrame({\n",
    "        'TR': tr, \n",
    "        'ATR': atr, \n",
    "        'ATRP': atrp,\n",
    "        'ROC_1': roc_1,\n",
    "        'ROC_3': roc_3,\n",
    "        'ROC_5': roc_5,\n",
    "        'ROC_10': roc_10,\n",
    "        'ROC_21': roc_21\n",
    "    })\n",
    "\n",
    "    # 4. Quality/Liquidity Features (Existing)\n",
    "    quality_temp_df = pd.DataFrame({\n",
    "        'IsStale': np.where((df_ohlcv['Volume'] == 0) | (df_ohlcv['Adj High'] == df_ohlcv['Adj Low']), 1, 0), \n",
    "        'DollarVolume': df_ohlcv['Adj Close'] * df_ohlcv['Volume'], \n",
    "        'HasSameVolume': (grouped['Volume'].diff() == 0).astype(int)\n",
    "    }, index=df_ohlcv.index)\n",
    "    \n",
    "    rolling_result = quality_temp_df.groupby(level='Ticker').rolling(window=quality_window, min_periods=quality_min_periods).agg({\n",
    "        'IsStale': 'mean', \n",
    "        'DollarVolume': 'median', \n",
    "        'HasSameVolume': 'sum'\n",
    "    }).rename(columns={\n",
    "        'IsStale': 'RollingStalePct', \n",
    "        'DollarVolume': 'RollMedDollarVol', \n",
    "        'HasSameVolume': 'RollingSameVolCount'\n",
    "    }).reset_index(level=0, drop=True)\n",
    "    \n",
    "    # 5. Merge\n",
    "    return pd.concat([indicator_df, rolling_result], axis=1)\n",
    "\n",
    "def calculate_gain(price_series): \n",
    "    if price_series.dropna().shape[0] < 2: return np.nan\n",
    "    return (price_series.ffill().iloc[-1] / price_series.bfill().iloc[0]) - 1\n",
    "\n",
    "def calculate_sharpe(return_series):\n",
    "    if return_series.dropna().shape[0] < 2: return np.nan\n",
    "    std = return_series.std()\n",
    "    return (return_series.mean() / std * np.sqrt(252)) if std > 0 else 0.0\n",
    "\n",
    "def calculate_sharpe_atr(return_series, atrp_series):\n",
    "    if return_series.dropna().shape[0] < 2 or atrp_series.dropna().empty: return np.nan\n",
    "    mean_atrp = atrp_series.mean()\n",
    "    return (return_series.mean() / mean_atrp) if mean_atrp > 0 else 0.0\n",
    "\n",
    "def calculate_buy_and_hold_performance(df_close, features_df, tickers, start_date, end_date):\n",
    "    if not tickers: return pd.Series(dtype=float), pd.Series(dtype=float), pd.Series(dtype=float)\n",
    "    ticker_counts = Counter(tickers)\n",
    "    initial_weights = pd.Series({t: c / len(tickers) for t, c in ticker_counts.items()})\n",
    "    prices_raw = df_close[initial_weights.index.tolist()].loc[start_date:end_date]\n",
    "    if prices_raw.dropna(how='all').empty: return pd.Series(dtype=float), pd.Series(dtype=float), pd.Series(dtype=float)\n",
    "    prices_norm = prices_raw.div(prices_raw.bfill().iloc[0])\n",
    "    weighted_growth = prices_norm.mul(initial_weights, axis='columns')\n",
    "    value_series = weighted_growth.sum(axis=1)\n",
    "    return_series = value_series.ffill().pct_change()\n",
    "    full_idx = pd.MultiIndex.from_product([initial_weights.index.tolist(), return_series.index], names=['Ticker', 'Date'])\n",
    "    feat_subset = features_df.reindex(full_idx)['ATRP'].unstack(level='Ticker')\n",
    "    atrp_series = (weighted_growth.div(value_series, axis='index').align(feat_subset, join='inner', axis=1)[0] * weighted_growth.div(value_series, axis='index').align(feat_subset, join='inner', axis=1)[1]).sum(axis=1)\n",
    "    return value_series, return_series, atrp_series\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION B: METRIC REGISTRY (UPDATED)\n",
    "# ==============================================================================\n",
    "\n",
    "# Existing Metrics\n",
    "def metric_price(d): return calculate_gain(d['calc_close'])\n",
    "def metric_sharpe(d): \n",
    "    r = d['daily_returns']\n",
    "    return (r.mean() / r.std() * np.sqrt(252)).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "def metric_sharpe_atr(d):\n",
    "    return (d['daily_returns'].mean() / d['atrp']).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "METRIC_REGISTRY = {\n",
    "    'Price': metric_price,\n",
    "    'Sharpe': metric_sharpe,\n",
    "    'Sharpe (ATR)': metric_sharpe_atr,\n",
    "}\n",
    "\n",
    "# --- NEW: MOMENTUM (High % Return = Rank 1) ---\n",
    "# \"Buy Strength\"\n",
    "METRIC_REGISTRY['Momentum 1D'] = lambda d: d['roc_1']\n",
    "METRIC_REGISTRY['Momentum 3D'] = lambda d: d['roc_3']\n",
    "METRIC_REGISTRY['Momentum 5D'] = lambda d: d['roc_5']\n",
    "METRIC_REGISTRY['Momentum 10D'] = lambda d: d['roc_10']\n",
    "METRIC_REGISTRY['Momentum 1M'] = lambda d: d['roc_21']\n",
    "\n",
    "# --- NEW: PULLBACK (Low/Negative % Return = Rank 1) ---\n",
    "# We invert the value (-) so the deepest drop becomes the largest positive number\n",
    "# Example: -10% becomes +0.10, which ranks higher than -2% (+0.02)\n",
    "METRIC_REGISTRY['Pullback 1D'] = lambda d: -d['roc_1']\n",
    "METRIC_REGISTRY['Pullback 3D'] = lambda d: -d['roc_3']\n",
    "METRIC_REGISTRY['Pullback 5D'] = lambda d: -d['roc_5']\n",
    "METRIC_REGISTRY['Pullback 10D'] = lambda d: -d['roc_10']\n",
    "METRIC_REGISTRY['Pullback 1M'] = lambda d: -d['roc_21']\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION C: DATA CONTRACTS (The API)\n",
    "# Updated EngineOutput to include actual start_date\n",
    "# ==============================================================================\n",
    "\n",
    "@dataclass\n",
    "class EngineInput:\n",
    "    mode: str\n",
    "    start_date: pd.Timestamp\n",
    "    calc_period: int\n",
    "    fwd_period: int\n",
    "    metric: str\n",
    "    benchmark_ticker: str\n",
    "    rank_start: int = 1\n",
    "    rank_end: int = 10\n",
    "    quality_thresholds: Dict[str, float] = field(default_factory=lambda: {'min_median_dollar_volume': 1_000_000, 'max_stale_pct': 0.05, 'max_same_vol_count': 10})\n",
    "    manual_tickers: List[str] = field(default_factory=list)\n",
    "    debug: bool = False\n",
    "\n",
    "@dataclass\n",
    "class EngineOutput:\n",
    "    portfolio_series: pd.Series\n",
    "    benchmark_series: pd.Series\n",
    "    normalized_plot_data: pd.DataFrame\n",
    "    tickers: List[str]\n",
    "    initial_weights: pd.Series\n",
    "    perf_metrics: Dict[str, float]\n",
    "    results_df: pd.DataFrame\n",
    "    start_date: pd.Timestamp # <--- NEW FIELD: The actual trading start date used\n",
    "    calc_end_date: pd.Timestamp\n",
    "    viz_end_date: pd.Timestamp\n",
    "    error_msg: Optional[str] = None\n",
    "    debug_data: Optional[Dict[str, Any]] = None\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION D: THE ALPHA ENGINE (The \"Brain\")\n",
    "# Updated for Decision-Anchor Logic\n",
    "# ==============================================================================\n",
    "\n",
    "class AlphaEngine:\n",
    "    # 1. Add 'df_close_wide' as an optional argument\n",
    "    def __init__(self, df_ohlcv: pd.DataFrame, features_df: pd.DataFrame = None, df_close_wide: pd.DataFrame = None, master_ticker: str = 'SPY'):\n",
    "        print(\"--- ‚öôÔ∏è Initializing AlphaEngine ---\")\n",
    "        \n",
    "        # Handle Features\n",
    "        if features_df is not None:\n",
    "            # print(\"‚ö° Using Pre-Computed Features\") # Optional: Reduce clutter\n",
    "            self.features_df = features_df\n",
    "        else:\n",
    "            print(\"üê¢ Calculating Features from scratch...\")\n",
    "            self.features_df = generate_features(df_ohlcv)\n",
    "            \n",
    "        # 2. Handle Price Matrix (The Optimization)\n",
    "        if df_close_wide is not None:\n",
    "            print(\"‚ö° Using Pre-Computed Price Matrix (Instant Load)\")\n",
    "            self.df_close = df_close_wide\n",
    "        else:\n",
    "            print(\"üê¢ Pivoting Price Data (Slow)...\")\n",
    "            self.df_close = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "        \n",
    "        # Master Ticker Check\n",
    "        if master_ticker not in self.df_close.columns:\n",
    "            master_ticker = self.df_close.columns[0]\n",
    "            print(f\"Warning: Master ticker not found. Using {master_ticker}\")\n",
    "            \n",
    "        self.trading_calendar = self.df_close[master_ticker].dropna().index.unique().sort_values()\n",
    "        # print(\"‚úÖ AlphaEngine Ready.\")\n",
    "\n",
    "    def run(self, inputs: EngineInput) -> EngineOutput:\n",
    "        # --- A. Validate Dates (STRICT VALIDATION MODE) ---\n",
    "        \n",
    "        # 1. Establish Boundaries\n",
    "        # The earliest possible decision requires 'Lookback' days of history before it.\n",
    "        # The latest possible decision is the last day of data.\n",
    "        \n",
    "        if len(self.trading_calendar) <= inputs.calc_period:\n",
    "             return self._error_result(f\"Dataset too small. Has {len(self.trading_calendar)} days, need at least {inputs.calc_period + 1}.\")\n",
    "\n",
    "        min_decision_date = self.trading_calendar[inputs.calc_period]\n",
    "        max_decision_date = self.trading_calendar[-1]\n",
    "\n",
    "        # 2. Check: Is the requested date too early?\n",
    "        # We allow \"snapping\" to valid trading days, but only if within the valid range.\n",
    "        if inputs.start_date < self.trading_calendar[0]:\n",
    "             return self._error_result(f\"‚ùå Date Out of Range (Too Early). Earliest valid decision date (with {inputs.calc_period} day lookback) is {min_decision_date.date()}.\")\n",
    "        \n",
    "        if inputs.start_date < min_decision_date:\n",
    "             return self._error_result(f\"‚ùå Not enough history. Decision date {inputs.start_date.date()} does not have {inputs.calc_period} previous days. Try {min_decision_date.date()} or later.\")\n",
    "\n",
    "        # 3. Check: Is the requested date too late?\n",
    "        if inputs.start_date > max_decision_date:\n",
    "             return self._error_result(f\"‚ùå Date Out of Range (Too Late). Dataset ends on {max_decision_date.date()}. Please choose a date on or before that.\")\n",
    "\n",
    "        # 4. If we pass checks, Find the Index\n",
    "        # searchsorted finds the insertion point (snaps forward to nearest trading day if input is a weekend)\n",
    "        decision_idx = self.trading_calendar.searchsorted(inputs.start_date)\n",
    "        \n",
    "        # Double check to ensure searchsorted didn't push us off the edge (edge case for date > last_date but close)\n",
    "        if decision_idx >= len(self.trading_calendar):\n",
    "             decision_idx = len(self.trading_calendar) - 1\n",
    "\n",
    "        # 5. Set Indices\n",
    "        start_idx = decision_idx - inputs.calc_period\n",
    "        \n",
    "        # Calculate Forward (Holding End)\n",
    "        end_idx = decision_idx + inputs.fwd_period\n",
    "        if end_idx >= len(self.trading_calendar):\n",
    "            end_idx = len(self.trading_calendar) - 1\n",
    "\n",
    "        # 6. Set Safe Dates\n",
    "        safe_start_date = self.trading_calendar[start_idx]      \n",
    "        safe_calc_end_date = self.trading_calendar[decision_idx] \n",
    "        safe_viz_end_date = self.trading_calendar[end_idx] \n",
    "\n",
    "        # --- B. Select Tickers ---\n",
    "        tickers_to_trade = []\n",
    "        results_table = pd.DataFrame()\n",
    "        debug_dict = {}\n",
    "        audit_info = {} \n",
    "\n",
    "        if inputs.mode == 'Manual List':\n",
    "            validation_errors = []\n",
    "            valid_tickers = []\n",
    "            for t in inputs.manual_tickers:\n",
    "                if t not in self.df_close.columns:\n",
    "                    validation_errors.append(f\"‚ùå {t}: Ticker not found.\")\n",
    "                    continue\n",
    "                if pd.isna(self.df_close.at[safe_start_date, t]):\n",
    "                    validation_errors.append(f\"‚ö†Ô∏è {t}: No price data on start date.\")\n",
    "                    continue\n",
    "                valid_tickers.append(t)\n",
    "            \n",
    "            if validation_errors: return self._error_result(\"\\n\".join(validation_errors))\n",
    "            if not valid_tickers: return self._error_result(\"No valid tickers.\")\n",
    "            tickers_to_trade = valid_tickers\n",
    "            results_table = pd.DataFrame(index=valid_tickers)\n",
    "            \n",
    "        else: # Ranking Mode\n",
    "            # CRITICAL UPDATE: Filter Universe based on the DECISION DATE (safe_calc_end_date)\n",
    "            # We want stocks that are liquid *now*, not 6 months ago.\n",
    "            eligible_tickers = self._get_eligible_universe(safe_calc_end_date, inputs.quality_thresholds, audit_info)\n",
    "            debug_dict['audit_liquidity'] = audit_info \n",
    "            \n",
    "            if not eligible_tickers: return self._error_result(\"No tickers passed quality filters.\")\n",
    "            \n",
    "            # --- UPDATED INGREDIENTS EXTRACTION ---\n",
    "            # 1. Get Price Data\n",
    "            calc_close = self.df_close.loc[safe_start_date:safe_calc_end_date, eligible_tickers]\n",
    "            \n",
    "            # 2. Get Feature Data (Specifically for the DECISION DATE)\n",
    "            # We use .xs() to grab the row corresponding to safe_calc_end_date for all tickers\n",
    "            feat_slice_current = self.features_df.xs(safe_calc_end_date, level='Date').reindex(eligible_tickers)\n",
    "            \n",
    "            # 3. Get Lookback Means (for ATRP)\n",
    "            idx_product = pd.MultiIndex.from_product([eligible_tickers, calc_close.index], names=['Ticker', 'Date'])\n",
    "            feat_slice_period = self.features_df.reindex(idx_product).dropna(how='all')\n",
    "            atrp_mean = feat_slice_period.groupby(level='Ticker')['ATRP'].mean()\n",
    "\n",
    "            # Extract the specific feature slice for the decision date\n",
    "            feat_slice_current = self.features_df.xs(safe_calc_end_date, level='Date').reindex(eligible_tickers)\n",
    "\n",
    "            # 4. Populate Ingredients\n",
    "            ingredients = { \n",
    "                'calc_close': calc_close, \n",
    "                'daily_returns': calc_close.ffill().pct_change(), \n",
    "                'atrp': atrp_mean,\n",
    "                # --- NEW WIRES CONNECTED HERE ---\n",
    "                'roc_1': feat_slice_current['ROC_1'],\n",
    "                'roc_3': feat_slice_current['ROC_3'],\n",
    "                'roc_5': feat_slice_current['ROC_5'],\n",
    "                'roc_10': feat_slice_current['ROC_10'],\n",
    "                'roc_21': feat_slice_current['ROC_21']\n",
    "            }\n",
    "\n",
    "            if inputs.metric not in METRIC_REGISTRY: return self._error_result(f\"Strategy '{inputs.metric}' not found.\")\n",
    "            metric_vals = METRIC_REGISTRY[inputs.metric](ingredients)\n",
    "            sorted_tickers = metric_vals.sort_values(ascending=False)\n",
    "            \n",
    "            start_r = max(0, inputs.rank_start - 1)\n",
    "            end_r = inputs.rank_end\n",
    "            tickers_to_trade = sorted_tickers.iloc[start_r:end_r].index.tolist()\n",
    "            if not tickers_to_trade: return self._error_result(\"No tickers generated from ranking.\")\n",
    "\n",
    "            results_table = pd.DataFrame({\n",
    "                'Rank': range(inputs.rank_start, inputs.rank_start + len(tickers_to_trade)),\n",
    "                'Ticker': tickers_to_trade,\n",
    "                'Strategy Value': sorted_tickers.loc[tickers_to_trade].values\n",
    "            }).set_index('Ticker')\n",
    "\n",
    "        # --- C. Performance Calculations ---\n",
    "        # Run simulation for the full timeline (Lookback + Holding)\n",
    "        p_val, p_ret, p_atrp = calculate_buy_and_hold_performance(self.df_close, self.features_df, tickers_to_trade, safe_start_date, safe_viz_end_date)\n",
    "        b_val, b_ret, b_atrp = calculate_buy_and_hold_performance(self.df_close, self.features_df, [inputs.benchmark_ticker], safe_start_date, safe_viz_end_date)\n",
    "\n",
    "        # --- D. Final Metrics (With 1-Day Lag Fix) ---\n",
    "        plot_data = self.df_close[list(set(tickers_to_trade))].loc[safe_start_date:safe_viz_end_date]\n",
    "        if not plot_data.empty: plot_data = plot_data / plot_data.bfill().iloc[0]\n",
    "        \n",
    "        calc_end_ts = safe_calc_end_date\n",
    "        metrics = {}\n",
    "        get_gain = lambda s: (s.iloc[-1] / s.iloc[0]) - 1 if len(s) > 0 else 0\n",
    "\n",
    "        # Helper for Lagged Forward Slice (T+1)\n",
    "        def get_lagged_fwd(series, boundary_date):\n",
    "            slice_raw = series.loc[boundary_date:]\n",
    "            if len(slice_raw) > 1:\n",
    "                return slice_raw.iloc[1:] # Skip the boundary day\n",
    "            return pd.Series(dtype=float)\n",
    "\n",
    "        # 1. Portfolio Metrics\n",
    "        metrics['full_p_gain'] = get_gain(p_val)\n",
    "        metrics['calc_p_gain'] = get_gain(p_val.loc[:calc_end_ts])\n",
    "        \n",
    "        p_val_fwd_lagged = get_lagged_fwd(p_val, calc_end_ts)\n",
    "        metrics['fwd_p_gain'] = get_gain(p_val_fwd_lagged)\n",
    "\n",
    "        # Sharpe (ATR)\n",
    "        metrics['full_p_sharpe_atr'] = calculate_sharpe_atr(p_ret, p_atrp)\n",
    "        metrics['calc_p_sharpe_atr'] = calculate_sharpe_atr(p_ret.loc[:calc_end_ts], p_atrp.loc[p_ret.loc[:calc_end_ts].index])\n",
    "        \n",
    "        # Fwd Sharpe Prep\n",
    "        p_ret_fwd_lagged = p_ret.loc[calc_end_ts:].iloc[2:] if len(p_ret.loc[calc_end_ts:]) > 2 else pd.Series(dtype=float)\n",
    "        p_atrp_fwd_lagged = p_atrp.reindex(p_ret_fwd_lagged.index)\n",
    "        metrics['fwd_p_sharpe_atr'] = calculate_sharpe_atr(p_ret_fwd_lagged, p_atrp_fwd_lagged)\n",
    "\n",
    "        # Standard Sharpe\n",
    "        metrics['full_p_sharpe'] = calculate_sharpe(p_ret)\n",
    "        metrics['calc_p_sharpe'] = calculate_sharpe(p_ret.loc[:calc_end_ts])\n",
    "        metrics['fwd_p_sharpe'] = calculate_sharpe(p_ret_fwd_lagged)\n",
    "        \n",
    "        # 2. Benchmark Metrics\n",
    "        if not b_ret.empty:\n",
    "            metrics['full_b_gain'] = get_gain(b_val)\n",
    "            metrics['calc_b_gain'] = get_gain(b_val.loc[:calc_end_ts])\n",
    "            \n",
    "            b_val_fwd_lagged = get_lagged_fwd(b_val, calc_end_ts)\n",
    "            metrics['fwd_b_gain'] = get_gain(b_val_fwd_lagged)\n",
    "            \n",
    "            metrics['full_b_sharpe_atr'] = calculate_sharpe_atr(b_ret, b_atrp)\n",
    "            metrics['calc_b_sharpe_atr'] = calculate_sharpe_atr(b_ret.loc[:calc_end_ts], b_atrp.loc[b_ret.loc[:calc_end_ts].index])\n",
    "            \n",
    "            b_ret_fwd_lagged = b_ret.loc[calc_end_ts:].iloc[2:] if len(b_ret.loc[calc_end_ts:]) > 2 else pd.Series(dtype=float)\n",
    "            b_atrp_fwd_lagged = b_atrp.reindex(b_ret_fwd_lagged.index)\n",
    "            metrics['fwd_b_sharpe_atr'] = calculate_sharpe_atr(b_ret_fwd_lagged, b_atrp_fwd_lagged)\n",
    "\n",
    "            metrics['full_b_sharpe'] = calculate_sharpe(b_ret)\n",
    "            metrics['calc_b_sharpe'] = calculate_sharpe(b_ret.loc[:calc_end_ts])\n",
    "            metrics['fwd_b_sharpe'] = calculate_sharpe(b_ret_fwd_lagged)\n",
    "\n",
    "        if not plot_data.empty: results_table['Fwd Gain'] = (plot_data.iloc[-1] / plot_data.loc[calc_end_ts]) - 1\n",
    "        ticker_counts = Counter(tickers_to_trade)\n",
    "        weights = pd.Series({t: c/len(tickers_to_trade) for t, c in ticker_counts.items()})\n",
    "\n",
    "        if inputs.debug:\n",
    "            trace_df = plot_data.copy()\n",
    "            trace_df.columns = [f'Norm_Price_{c}' for c in trace_df.columns]\n",
    "            trace_df['Norm_Price_Portfolio'] = p_val\n",
    "            if not b_val.empty: trace_df[f'Norm_Price_Benchmark_{inputs.benchmark_ticker}'] = b_val\n",
    "            debug_dict['portfolio_trace'] = trace_df\n",
    "\n",
    "        return EngineOutput(\n",
    "            portfolio_series=p_val, benchmark_series=b_val, normalized_plot_data=plot_data,\n",
    "            tickers=tickers_to_trade, initial_weights=weights, perf_metrics=metrics,\n",
    "            results_df=results_table, start_date=safe_start_date,\n",
    "            calc_end_date=safe_calc_end_date, viz_end_date=safe_viz_end_date, \n",
    "            error_msg=None, debug_data=debug_dict\n",
    "        )\n",
    "\n",
    "    def _get_eligible_universe(self, date_ts, thresholds, audit_container=None):\n",
    "        avail_dates = self.features_df.index.get_level_values('Date').unique().sort_values()\n",
    "        valid_dates = avail_dates[avail_dates <= date_ts]\n",
    "        if valid_dates.empty: return []\n",
    "        day_features = self.features_df.xs(valid_dates[-1], level='Date')\n",
    "\n",
    "        vol_cutoff = thresholds.get('min_median_dollar_volume', 0)\n",
    "        percentile_used = \"N/A\"\n",
    "        dynamic_val = 0\n",
    "        \n",
    "        if 'min_liquidity_percentile' in thresholds:\n",
    "            percentile_used = thresholds['min_liquidity_percentile']\n",
    "            dynamic_val = day_features['RollMedDollarVol'].quantile(percentile_used)\n",
    "            vol_cutoff = max(vol_cutoff, dynamic_val)\n",
    "\n",
    "        mask = (\n",
    "            (day_features['RollMedDollarVol'] >= vol_cutoff) &\n",
    "            (day_features['RollingStalePct'] <= thresholds['max_stale_pct']) &\n",
    "            (day_features['RollingSameVolCount'] <= thresholds['max_same_vol_count'])\n",
    "        )\n",
    "\n",
    "        if audit_container is not None:\n",
    "            audit_container['date'] = valid_dates[-1]\n",
    "            audit_container['total_tickers_available'] = len(day_features)\n",
    "            audit_container['percentile_setting'] = percentile_used\n",
    "            audit_container['percentile_value_usd'] = dynamic_val\n",
    "            audit_container['final_cutoff_usd'] = vol_cutoff\n",
    "            audit_container['tickers_passed'] = mask.sum()\n",
    "            snapshot = day_features.copy()\n",
    "            snapshot['Calculated_Cutoff'] = vol_cutoff\n",
    "            snapshot['Passed_Vol_Check'] = snapshot['RollMedDollarVol'] >= vol_cutoff\n",
    "            snapshot['Passed_Final'] = mask\n",
    "            snapshot = snapshot.sort_values('RollMedDollarVol', ascending=False)\n",
    "            audit_container['universe_snapshot'] = snapshot\n",
    "\n",
    "        return day_features[mask].index.tolist()\n",
    "\n",
    "    def _error_result(self, msg):\n",
    "        return EngineOutput(pd.Series(dtype=float), pd.Series(dtype=float), pd.DataFrame(), [], pd.Series(dtype=float), {}, pd.DataFrame(), pd.Timestamp.min, pd.Timestamp.min, pd.Timestamp.min, msg)\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION E: THE UI (Visualization)\n",
    "# Added precomputed_features\n",
    "# Updated for Timeline Layout\n",
    "# Update this function to read the audit data from the `debug_data` and print it nicely.\n",
    "# Updated print logic to detect date shift\n",
    "# Fixed EngineInput argument mapping\n",
    "# ==============================================================================\n",
    "\n",
    "def plot_walk_forward_analyzer(df_ohlcv, \n",
    "                               precomputed_features=None,\n",
    "                               precomputed_close=None, # <--- NEW ARGUMENT\n",
    "                               default_start_date='2020-01-01', \n",
    "                               default_lookback=126, \n",
    "                               default_holding=63,\n",
    "                               default_strategy='Sharpe (ATR)', \n",
    "                               default_rank_start=1, \n",
    "                               default_rank_end=10,\n",
    "                               default_benchmark_ticker='SPY', \n",
    "                               master_calendar_ticker='XOM', \n",
    "                               quality_thresholds=None, \n",
    "                               debug=False):\n",
    "    \n",
    "    # Pass both optimizations to the Engine\n",
    "    engine = AlphaEngine(\n",
    "        df_ohlcv, \n",
    "        features_df=precomputed_features, \n",
    "        df_close_wide=precomputed_close, # <--- PASS IT HERE\n",
    "        master_ticker=master_calendar_ticker\n",
    "    )\n",
    "    results_container = [None]\n",
    "    debug_container = [None]\n",
    "\n",
    "    if quality_thresholds is None:\n",
    "        quality_thresholds = {\n",
    "            'min_median_dollar_volume': 100_000, \n",
    "            'min_liquidity_percentile': 0.50,    \n",
    "            'max_stale_pct': 0.05, \n",
    "            'max_same_vol_count': 10\n",
    "        }\n",
    "\n",
    "    # --- 1. Define Widgets (Fixed Truncation) ---\n",
    "    mode_selector = widgets.RadioButtons(options=['Ranking', 'Manual List'], value='Ranking', description='Mode:', layout={'width': 'max-content'}, style={'description_width': 'initial'})\n",
    "    \n",
    "    # Timeline Widgets - Added style={'description_width': 'initial'} and increased width slightly\n",
    "    lookback_input = widgets.IntText(\n",
    "        value=default_lookback, \n",
    "        description='Lookback (Days):', \n",
    "        layout={'width': '200px'}, \n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    decision_date_picker = widgets.DatePicker(\n",
    "        description='Decision Date:', \n",
    "        value=pd.to_datetime(default_start_date), \n",
    "        layout={'width': 'auto'},\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    holding_input = widgets.IntText(\n",
    "        value=default_holding, \n",
    "        description='Holding (Days):', \n",
    "        layout={'width': '200px'},\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Strategy Widgets\n",
    "    strategy_dropdown = widgets.Dropdown(\n",
    "        options=list(METRIC_REGISTRY.keys()), \n",
    "        value=default_strategy, \n",
    "        description='Strategy:', \n",
    "        layout={'width': '220px'},\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    benchmark_input = widgets.Text(\n",
    "        value=default_benchmark_ticker, \n",
    "        description='Benchmark:', \n",
    "        placeholder='Enter Ticker', \n",
    "        layout={'width': '180px'},\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Ranking Widgets\n",
    "    rank_start_input = widgets.IntText(value=default_rank_start, description='Rank Start:', layout={'width': '150px'}, style={'description_width': 'initial'})\n",
    "    rank_end_input = widgets.IntText(value=default_rank_end, description='Rank End:', layout={'width': '150px'}, style={'description_width': 'initial'})\n",
    "    \n",
    "    manual_tickers_input = widgets.Textarea(value='', placeholder='Enter tickers...', description='Manual Tickers:', layout={'width': '400px', 'height': '80px'}, style={'description_width': 'initial'})\n",
    "    \n",
    "    update_button = widgets.Button(description=\"Run Simulation\", button_style='primary')\n",
    "    ticker_list_output = widgets.Output()\n",
    "\n",
    "\n",
    "\n",
    "    # --- 2. Create Layouts (Timeline Flow) ---\n",
    "    timeline_box = widgets.HBox([lookback_input, decision_date_picker, holding_input], layout=widgets.Layout(justify_content='space-between', border='1px solid #ddd', padding='10px', margin='5px'))\n",
    "    strategy_box = widgets.HBox([strategy_dropdown, benchmark_input])\n",
    "    ranking_box = widgets.HBox([rank_start_input, rank_end_input])\n",
    "    \n",
    "    # Dynamic Visibility\n",
    "    def on_mode_change(c):\n",
    "        ranking_box.layout.display = 'flex' if c['new'] == 'Ranking' else 'none'\n",
    "        manual_tickers_input.layout.display = 'none' if c['new'] == 'Ranking' else 'flex'\n",
    "        strategy_dropdown.disabled = (c['new'] == 'Manual List')\n",
    "    \n",
    "    mode_selector.observe(on_mode_change, names='value')\n",
    "    on_mode_change({'new': mode_selector.value})\n",
    "\n",
    "    ui = widgets.VBox([\n",
    "        widgets.HTML(\"<b>1. Timeline Configuration:</b> (Past <--- Decision ---> Future)\"),\n",
    "        timeline_box,\n",
    "        widgets.HTML(\"<b>2. Strategy Settings:</b>\"),\n",
    "        widgets.HBox([mode_selector, strategy_box]),\n",
    "        ranking_box,\n",
    "        manual_tickers_input,\n",
    "        widgets.HTML(\"<hr>\"),\n",
    "        update_button,\n",
    "        ticker_list_output\n",
    "    ], layout=widgets.Layout(margin='10px 0 20px 0'))\n",
    "    \n",
    "    fig = go.FigureWidget()\n",
    "    fig.update_layout(title='Event-Driven Walk-Forward Analysis', height=600, template=\"plotly_white\", hovermode='x unified')\n",
    "    for i in range(50): fig.add_trace(go.Scatter(visible=False, line=dict(width=2)))\n",
    "    fig.add_trace(go.Scatter(name='Benchmark', visible=True, line=dict(color='black', width=3, dash='dash')))\n",
    "    fig.add_trace(go.Scatter(name='Group Portfolio', visible=True, line=dict(color='green', width=3)))\n",
    "\n",
    "    def update_plot(b):\n",
    "        ticker_list_output.clear_output()\n",
    "        manual_list = [t.strip().upper() for t in manual_tickers_input.value.split(',') if t.strip()]\n",
    "        decision_date_raw = pd.to_datetime(decision_date_picker.value)\n",
    "        \n",
    "        # MAPPING UI VALUES TO ENGINE INPUTS\n",
    "        # start_date -> Decision Date\n",
    "        # calc_period -> Lookback\n",
    "        # fwd_period -> Holding\n",
    "        inputs = EngineInput(\n",
    "            mode=mode_selector.value,\n",
    "            start_date=decision_date_raw, \n",
    "            calc_period=lookback_input.value,\n",
    "            fwd_period=holding_input.value,\n",
    "            metric=strategy_dropdown.value,\n",
    "            benchmark_ticker=benchmark_input.value.strip().upper(),\n",
    "            rank_start=rank_start_input.value,\n",
    "            rank_end=rank_end_input.value,\n",
    "            quality_thresholds=quality_thresholds,\n",
    "            manual_tickers=manual_list,\n",
    "            debug=debug\n",
    "        )\n",
    "        \n",
    "        with ticker_list_output:\n",
    "            res = engine.run(inputs)\n",
    "            results_container[0] = res\n",
    "            debug_container[0] = res.debug_data\n",
    "            if res.error_msg: print(f\"‚ùå {res.error_msg}\"); return\n",
    "\n",
    "            with fig.batch_update():\n",
    "                cols = res.normalized_plot_data.columns.tolist()\n",
    "                for i in range(50):\n",
    "                    if i < len(cols): fig.data[i].update(x=res.normalized_plot_data.index, y=res.normalized_plot_data[cols[i]], name=cols[i], visible=True)\n",
    "                    else: fig.data[i].visible = False\n",
    "                \n",
    "                fig.data[50].update(x=res.benchmark_series.index, y=res.benchmark_series.values, name=f\"Benchmark ({inputs.benchmark_ticker})\", visible=not res.benchmark_series.empty)\n",
    "                fig.data[51].update(x=res.portfolio_series.index, y=res.portfolio_series.values, visible=True)\n",
    "                \n",
    "                # Draw Line at DECISION DATE (calc_end_date)\n",
    "                fig.layout.shapes = [dict(type=\"line\", x0=res.calc_end_date, y0=0, x1=res.calc_end_date, y1=1, xref='x', yref='paper', line=dict(color=\"red\", width=2, dash=\"dash\"))]\n",
    "                fig.layout.annotations = [dict(x=res.calc_end_date, y=0.05, xref=\"x\", yref=\"paper\", text=\"DECISION\", showarrow=False, bgcolor=\"red\", font=dict(color=\"white\"))]\n",
    "\n",
    "            req_date = inputs.start_date.date()\n",
    "            act_date = res.calc_end_date.date() # Decision date used\n",
    "            \n",
    "            # --- LIQUIDITY AUDIT PRINT ---\n",
    "            if inputs.mode == 'Ranking' and res.debug_data and 'audit_liquidity' in res.debug_data:\n",
    "                audit = res.debug_data['audit_liquidity']\n",
    "                if audit:\n",
    "                    pct_str = f\"{audit.get('percentile_setting', 0)*100:.0f}%\"\n",
    "                    cut_val = audit.get('final_cutoff_usd', 0)\n",
    "                    print(\"-\" * 60)\n",
    "                    print(f\"üîç LIQUIDITY CHECK (On Decision Date: {act_date})\")\n",
    "                    print(f\"   Universe Size: {audit.get('total_tickers_available')} tickers\")\n",
    "                    print(f\"   Filtering: Top {pct_str} of Market\")\n",
    "                    print(f\"   Calculated Cutoff: ${cut_val:,.0f} / day\")\n",
    "                    print(f\"   Tickers Remaining: {audit.get('tickers_passed')}\")\n",
    "                    print(\"-\" * 60)\n",
    "            \n",
    "            print(f\"Simulation Timeline: {res.start_date.date()} (Start) <--- [ {act_date} ] ---> {res.viz_end_date.date()} (End)\")\n",
    "\n",
    "            if inputs.mode == 'Ranking':\n",
    "                print(f\"Ranked Tickers ({len(res.tickers)}):\")\n",
    "                # Slice list into chunks of 10\n",
    "                for i in range(0, len(res.tickers), 10):\n",
    "                    print(\", \".join(res.tickers[i:i+10]))\n",
    "            else:\n",
    "                print(\"Manual Portfolio Tickers:\")\n",
    "                print(\", \".join(res.tickers))            \n",
    "\n",
    "            m = res.perf_metrics\n",
    "            rows = [\n",
    "                {'Metric': 'Group Portfolio Gain', 'Full': m.get('full_p_gain'), 'Lookback': m.get('calc_p_gain'), 'Holding': m.get('fwd_p_gain')},\n",
    "                {'Metric': f'Benchmark ({inputs.benchmark_ticker}) Gain', 'Full': m.get('full_b_gain'), 'Lookback': m.get('calc_b_gain'), 'Holding': m.get('fwd_b_gain')},\n",
    "                {'Metric': '== Gain Delta', 'Full': m.get('full_p_gain',0)-m.get('full_b_gain',0), 'Lookback': m.get('calc_p_gain',0)-m.get('calc_b_gain',0), 'Holding': m.get('fwd_p_gain',0)-m.get('fwd_b_gain',0)},\n",
    "                \n",
    "                {'Metric': 'Group Sharpe', 'Full': m.get('full_p_sharpe'), 'Lookback': m.get('calc_p_sharpe'), 'Holding': m.get('fwd_p_sharpe')},\n",
    "                {'Metric': f'Benchmark Sharpe', 'Full': m.get('full_b_sharpe'), 'Lookback': m.get('calc_b_sharpe'), 'Holding': m.get('fwd_b_sharpe')},\n",
    "                {'Metric': '== Sharpe Delta', 'Full': m.get('full_p_sharpe',0)-m.get('full_b_sharpe',0), 'Lookback': m.get('calc_p_sharpe',0)-m.get('calc_b_sharpe',0), 'Holding': m.get('fwd_p_sharpe',0)-m.get('fwd_b_sharpe',0)},\n",
    "\n",
    "                {'Metric': 'Group Sharpe (ATR)', 'Full': m.get('full_p_sharpe_atr'), 'Lookback': m.get('calc_p_sharpe_atr'), 'Holding': m.get('fwd_p_sharpe_atr')},\n",
    "                {'Metric': f'Benchmark Sharpe (ATR)', 'Full': m.get('full_b_sharpe_atr'), 'Lookback': m.get('calc_b_sharpe_atr'), 'Holding': m.get('fwd_b_sharpe_atr')},\n",
    "                {'Metric': '== Sharpe (ATR) Delta', 'Full': m.get('full_p_sharpe_atr',0)-m.get('full_b_sharpe_atr',0), 'Lookback': m.get('calc_p_sharpe_atr',0)-m.get('calc_b_sharpe_atr',0), 'Holding': m.get('fwd_p_sharpe_atr',0)-m.get('fwd_b_sharpe_atr',0)}\n",
    "            ]\n",
    "            display(pd.DataFrame(rows).set_index('Metric').style.format(\"{:+.4f}\", na_rep=\"N/A\"))\n",
    "\n",
    "    update_button.on_click(update_plot)\n",
    "    update_plot(None)\n",
    "    display(ui, fig)\n",
    "    return results_container, debug_container\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION F: UTILITIES\n",
    "# ==============================================================================\n",
    "\n",
    "def print_nested(d, indent=0, width=4):\n",
    "    \"\"\"Pretty-print any nested dict/list/tuple combination.\"\"\"\n",
    "    spacing = ' ' * indent\n",
    "    if isinstance(d, dict):\n",
    "        for k, v in d.items():\n",
    "            print(f'{spacing}{k}:')\n",
    "            print_nested(v, indent + width, width)\n",
    "    elif isinstance(d, (list, tuple)):\n",
    "        for item in d:\n",
    "            print_nested(item, indent, width)\n",
    "    else:\n",
    "        print(f'{spacing}{d}')\n",
    "\n",
    "def get_ticker_OHLCV(\n",
    "    df_ohlcv: pd.DataFrame,\n",
    "    tickers: Union[str, List[str]],\n",
    "    date_start: str,\n",
    "    date_end: str,\n",
    "    return_format: str = \"dataframe\",\n",
    "    verbose: bool = True\n",
    ") -> Union[pd.DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    Get OHLCV data for specified tickers within a date range.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_ohlcv : pd.DataFrame\n",
    "        DataFrame with MultiIndex of (ticker, date) and OHLCV columns\n",
    "    tickers : str or list of str\n",
    "        Ticker symbol(s) to retrieve\n",
    "    date_start : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    date_end : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    return_format : str, optional\n",
    "        Format to return data in. Options: \n",
    "        - 'dataframe': Single DataFrame with MultiIndex (default)\n",
    "        - 'dict': Dictionary with tickers as keys and DataFrames as values\n",
    "        - 'separate': List of separate DataFrames for each ticker\n",
    "    verbose : bool, optional\n",
    "        Whether to print summary information (default: True)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Union[pd.DataFrame, dict, list]\n",
    "        Filtered OHLCV data in specified format\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If input parameters are invalid\n",
    "    KeyError\n",
    "        If tickers not found in DataFrame\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> # Get data for single ticker\n",
    "    >>> vlo_data = get_ticker_OHLCV(df_ohlcv, 'VLO', '2025-08-13', '2025-09-04')\n",
    "    \n",
    "    >>> # Get data for multiple tickers\n",
    "    >>> multi_data = get_ticker_OHLCV(df_ohlcv, ['VLO', 'JPST'], '2025-08-13', '2025-09-04')\n",
    "    \n",
    "    >>> # Get data as dictionary\n",
    "    >>> data_dict = get_ticker_OHLCV(df_ohlcv, ['VLO', 'JPST'], '2025-08-13', \n",
    "    ...                              '2025-09-04', return_format='dict')\n",
    "    \"\"\"\n",
    "    \n",
    "    # Input validation\n",
    "    if not isinstance(df_ohlcv, pd.DataFrame):\n",
    "        raise TypeError(\"df_ohlcv must be a pandas DataFrame\")\n",
    "    \n",
    "    if not isinstance(df_ohlcv.index, pd.MultiIndex):\n",
    "        raise ValueError(\"DataFrame must have MultiIndex of (ticker, date)\")\n",
    "    \n",
    "    if len(df_ohlcv.index.levels) != 2:\n",
    "        raise ValueError(\"MultiIndex must have exactly 2 levels: (ticker, date)\")\n",
    "    \n",
    "    # Convert single ticker to list for consistent processing\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "    elif not isinstance(tickers, list):\n",
    "        raise TypeError(\"tickers must be a string or list of strings\")\n",
    "    \n",
    "    # Convert dates to Timestamps\n",
    "    try:\n",
    "        start_date = pd.Timestamp(date_start)\n",
    "        end_date = pd.Timestamp(date_end)\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"Invalid date format. Use 'YYYY-MM-DD': {e}\")\n",
    "    \n",
    "    if start_date > end_date:\n",
    "        raise ValueError(\"date_start must be before or equal to date_end\")\n",
    "    \n",
    "    # Check if tickers exist in the DataFrame\n",
    "    available_tickers = df_ohlcv.index.get_level_values(0).unique()\n",
    "    missing_tickers = [t for t in tickers if t not in available_tickers]\n",
    "    \n",
    "    if missing_tickers:\n",
    "        raise KeyError(f\"Ticker(s) not found in DataFrame: {missing_tickers}\")\n",
    "    \n",
    "    # Filter the data using MultiIndex slicing\n",
    "    try:\n",
    "        filtered_data = df_ohlcv.loc[(tickers, slice(date_start, date_end)), :]\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error filtering data: {e}\")\n",
    "    \n",
    "    # Handle empty results\n",
    "    if filtered_data.empty:\n",
    "        if verbose:\n",
    "            print(f\"No data found for tickers {tickers} in date range {date_start} to {date_end}\")\n",
    "        return filtered_data\n",
    "    \n",
    "    # Print summary if verbose\n",
    "    if verbose:\n",
    "        print(f\"Data retrieved for {len(tickers)} ticker(s) from {date_start} to {date_end}\")\n",
    "        print(f\"Total rows: {len(filtered_data)}\")\n",
    "        print(f\"Date range in data: {filtered_data.index.get_level_values(1).min()} to \"\n",
    "              f\"{filtered_data.index.get_level_values(1).max()}\")\n",
    "        \n",
    "        # Print ticker-specific counts\n",
    "        ticker_counts = filtered_data.index.get_level_values(0).value_counts()\n",
    "        for ticker in tickers:\n",
    "            count = ticker_counts.get(ticker, 0)\n",
    "            if count > 0:\n",
    "                print(f\"  {ticker}: {count} rows\")\n",
    "            else:\n",
    "                print(f\"  {ticker}: No data in range\")\n",
    "    \n",
    "    # Return in requested format\n",
    "    if return_format == \"dict\":\n",
    "        result = {}\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result[ticker] = filtered_data.xs(ticker, level=0).loc[date_start:date_end]\n",
    "            except KeyError:\n",
    "                result[ticker] = pd.DataFrame()\n",
    "        return result\n",
    "    \n",
    "    elif return_format == \"separate\":\n",
    "        result = []\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result.append(filtered_data.xs(ticker, level=0).loc[date_start:date_end])\n",
    "            except KeyError:\n",
    "                result.append(pd.DataFrame())\n",
    "        return result\n",
    "    \n",
    "    elif return_format == \"dataframe\":\n",
    "        return filtered_data\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Invalid return_format: {return_format}. \"\n",
    "                         f\"Must be 'dataframe', 'dict', or 'separate'\")\n",
    "\n",
    "def get_ticker_features(\n",
    "    features_df: pd.DataFrame,\n",
    "    tickers: Union[str, List[str]],\n",
    "    date_start: str,\n",
    "    date_end: str,\n",
    "    return_format: str = \"dataframe\",\n",
    "    verbose: bool = True\n",
    ") -> Union[pd.DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    Get features data for specified tickers within a date range.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    features_df : pd.DataFrame\n",
    "        DataFrame with MultiIndex of (ticker, date) and feature columns\n",
    "    tickers : str or list of str\n",
    "        Ticker symbol(s) to retrieve\n",
    "    date_start : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    date_end : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    return_format : str, optional\n",
    "        Format to return data in. Options: \n",
    "        - 'dataframe': Single DataFrame with MultiIndex (default)\n",
    "        - 'dict': Dictionary with tickers as keys and DataFrames as values\n",
    "        - 'separate': List of separate DataFrames for each ticker\n",
    "    verbose : bool, optional\n",
    "        Whether to print summary information (default: True)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Union[pd.DataFrame, dict, list]\n",
    "        Filtered features data in specified format\n",
    "    \"\"\"\n",
    "    # Convert single ticker to list for consistent processing\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "    \n",
    "    # Filter the data using MultiIndex slicing\n",
    "    try:\n",
    "        filtered_data = features_df.loc[(tickers, slice(date_start, date_end)), :]\n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"Error filtering data: {e}\")\n",
    "        return pd.DataFrame() if return_format == \"dataframe\" else {}\n",
    "    \n",
    "    # Handle empty results\n",
    "    if filtered_data.empty:\n",
    "        if verbose:\n",
    "            print(f\"No data found for tickers {tickers} in date range {date_start} to {date_end}\")\n",
    "        return filtered_data\n",
    "    \n",
    "    # Print summary if verbose\n",
    "    if verbose:\n",
    "        print(f\"Features data retrieved for {len(tickers)} ticker(s) from {date_start} to {date_end}\")\n",
    "        print(f\"Total rows: {len(filtered_data)}\")\n",
    "        print(f\"Date range in data: {filtered_data.index.get_level_values(1).min()} to \"\n",
    "              f\"{filtered_data.index.get_level_values(1).max()}\")\n",
    "        print(f\"Available features: {', '.join(filtered_data.columns.tolist())}\")\n",
    "        \n",
    "        # Print ticker-specific counts\n",
    "        ticker_counts = filtered_data.index.get_level_values(0).value_counts()\n",
    "        for ticker in tickers:\n",
    "            count = ticker_counts.get(ticker, 0)\n",
    "            if count > 0:\n",
    "                print(f\"  {ticker}: {count} rows\")\n",
    "            else:\n",
    "                print(f\"  {ticker}: No data in range\")\n",
    "    \n",
    "    # Return in requested format\n",
    "    if return_format == \"dict\":\n",
    "        result = {}\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result[ticker] = filtered_data.xs(ticker, level=0).loc[date_start:date_end]\n",
    "            except KeyError:\n",
    "                result[ticker] = pd.DataFrame()\n",
    "        return result\n",
    "    \n",
    "    elif return_format == \"separate\":\n",
    "        result = []\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result.append(filtered_data.xs(ticker, level=0).loc[date_start:date_end])\n",
    "            except KeyError:\n",
    "                result.append(pd.DataFrame())\n",
    "        return result\n",
    "    \n",
    "    elif return_format == \"dataframe\":\n",
    "        return filtered_data\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Invalid return_format: {return_format}. \"\n",
    "                         f\"Must be 'dataframe', 'dict', or 'separate'\")\n",
    "\n",
    "def create_combined_dict(\n",
    "    df_ohlcv: pd.DataFrame,\n",
    "    features_df: pd.DataFrame,\n",
    "    tickers: Union[str, List[str]],\n",
    "    date_start: str,\n",
    "    date_end: str,\n",
    "    verbose: bool = True\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Create a combined dictionary with both OHLCV and features data for each ticker.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_ohlcv : pd.DataFrame\n",
    "        DataFrame with OHLCV data (MultiIndex: ticker, date)\n",
    "    features_df : pd.DataFrame\n",
    "        DataFrame with features data (MultiIndex: ticker, date)\n",
    "    tickers : str or list of str\n",
    "        Ticker symbol(s) to retrieve\n",
    "    date_start : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    date_end : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    verbose : bool, optional\n",
    "        Whether to print progress information (default: True)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with tickers as keys and combined DataFrames (OHLCV + features) as values\n",
    "    \"\"\"\n",
    "    # Convert single ticker to list\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Creating combined dictionary for {len(tickers)} ticker(s)\")\n",
    "        print(f\"Date range: {date_start} to {date_end}\")\n",
    "        print(\"=\" * 60)\n",
    "    \n",
    "    # Get OHLCV data as dictionary\n",
    "    ohlcv_dict = get_ticker_OHLCV(\n",
    "        df_ohlcv, tickers, date_start, date_end, \n",
    "        return_format='dict', verbose=verbose\n",
    "    )\n",
    "    \n",
    "    # Get features data as dictionary\n",
    "    features_dict = get_ticker_features(\n",
    "        features_df, tickers, date_start, date_end,\n",
    "        return_format='dict', verbose=verbose\n",
    "    )\n",
    "    \n",
    "    # Create combined_dict\n",
    "    combined_dict = {}\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        if verbose:\n",
    "            print(f\"\\nProcessing {ticker}...\")\n",
    "        \n",
    "        # Check if ticker exists in both dictionaries\n",
    "        if ticker in ohlcv_dict and ticker in features_dict:\n",
    "            ohlcv_data = ohlcv_dict[ticker]\n",
    "            features_data = features_dict[ticker]\n",
    "            \n",
    "            # Check if both dataframes have data\n",
    "            if not ohlcv_data.empty and not features_data.empty:\n",
    "                # Combine OHLCV and features data\n",
    "                # Note: Both dataframes have the same index (dates), so we can concatenate\n",
    "                combined_df = pd.concat([ohlcv_data, features_data], axis=1)\n",
    "                \n",
    "                # Ensure proper index naming\n",
    "                combined_df.index.name = 'Date'\n",
    "                \n",
    "                # Store in combined_dict\n",
    "                combined_dict[ticker] = combined_df\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"  ‚úì Successfully combined data\")\n",
    "                    print(f\"  OHLCV shape: {ohlcv_data.shape}\")\n",
    "                    print(f\"  Features shape: {features_data.shape}\")\n",
    "                    print(f\"  Combined shape: {combined_df.shape}\")\n",
    "                    print(f\"  Date range: {combined_df.index.min()} to {combined_df.index.max()}\")\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"  ‚úó Cannot combine: One or both dataframes are empty\")\n",
    "                    print(f\"    OHLCV empty: {ohlcv_data.empty}\")\n",
    "                    print(f\"    Features empty: {features_data.empty}\")\n",
    "                combined_dict[ticker] = pd.DataFrame()\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(f\"  ‚úó Ticker not found in both dictionaries\")\n",
    "                if ticker not in ohlcv_dict:\n",
    "                    print(f\"    Not in OHLCV data\")\n",
    "                if ticker not in features_dict:\n",
    "                    print(f\"    Not in features data\")\n",
    "            combined_dict[ticker] = pd.DataFrame()\n",
    "    \n",
    "    # Print summary\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"SUMMARY\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Total tickers processed: {len(tickers)}\")\n",
    "        \n",
    "        tickers_with_data = [ticker for ticker, df in combined_dict.items() if not df.empty]\n",
    "        print(f\"Tickers with combined data: {len(tickers_with_data)}\")\n",
    "        \n",
    "        if tickers_with_data:\n",
    "            print(\"\\nTicker details:\")\n",
    "            for ticker in tickers_with_data:\n",
    "                df = combined_dict[ticker]\n",
    "                print(f\"  {ticker}: {df.shape} - {df.index.min()} to {df.index.max()}\")\n",
    "                print(f\"    Columns: {len(df.columns)}\")\n",
    "        \n",
    "        empty_tickers = [ticker for ticker, df in combined_dict.items() if df.empty]\n",
    "        if empty_tickers:\n",
    "            print(f\"\\nTickers with no data: {', '.join(empty_tickers)}\")\n",
    "    \n",
    "    return combined_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb31c4e",
   "metadata": {},
   "source": [
    "### Unit Test for Generated Features by Function generate_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2989c8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STARTING ALL TESTS FOR generate_features()\n",
      "============================================================\n",
      "Running test_true_range_calculation (Robust Version)...\n",
      "test_true_range_df input:\n",
      "                   Adj Open  Adj High  Adj Low  Adj Close  Volume\n",
      "Ticker Date                                                      \n",
      "TEST   2024-01-01       100       105       95        100    1000\n",
      "       2024-01-02       105       108      103        106    1200\n",
      "       2024-01-03        95        97       93         96     800\n",
      "       2024-01-04        98       102      100         99     900\n",
      "       2024-01-05       102       105       98        103    1100\n",
      "\n",
      "‚úÖ PD Testing Assertion Passed! All TR values match expected logic.\n",
      "\n",
      "==================================================\n",
      "Running test_atr_calculation...\n",
      "test_true_range_df:\n",
      "                   Adj Open  Adj High  Adj Low  Adj Close  Volume\n",
      "Ticker Date                                                      \n",
      "TEST   2024-01-01       100       101       99        100    1000\n",
      "       2024-01-02       102       103      101        102    1000\n",
      "       2024-01-03       103       103      103        103    1000\n",
      "       2024-01-04       110       112      108        111    1000\n",
      "       2024-01-05       108       110      107        109    1000\n",
      "\n",
      "\n",
      "ATR Calculation Results:\n",
      "                    TR     ATR    ATRP\n",
      "Ticker Date                           \n",
      "TEST   2024-01-01  NaN     NaN     NaN\n",
      "       2024-01-02  3.0  3.0000  0.0294\n",
      "       2024-01-03  1.0  2.8571  0.0277\n",
      "       2024-01-04  9.0  3.2959  0.0297\n",
      "       2024-01-05  4.0  3.3462  0.0307\n",
      "‚úì 2024-01-02 ATR: 3.000000 ‚âà 3.000000\n",
      "‚úì 2024-01-03 ATR: 2.857143 ‚âà 2.857143\n",
      "‚úì 2024-01-04 ATR: 3.295918 ‚âà 3.295918\n",
      "‚úì 2024-01-05 ATR: 3.346210 ‚âà 3.346210\n",
      "\n",
      "‚úÖ All ATR tests passed!\n",
      "\n",
      "==================================================\n",
      "Running test_is_stale_calculation...\n",
      "test_is_stale_df:\n",
      "                   Adj Open  Adj High  Adj Low  Adj Close  Volume\n",
      "Ticker Date                                                      \n",
      "TEST   2024-01-01       100       101       99        100    1000\n",
      "       2024-01-02       102       103      101        102       0\n",
      "       2024-01-03       103       103      103        103     500\n",
      "       2024-01-04       104       105      104        105    1000\n",
      "\n",
      "\n",
      "üìä Manual IsStale Calculation:\n",
      "==================================================\n",
      "IsStale = 1 if EITHER condition is true:\n",
      "  1. Volume == 0\n",
      "  2. Adj High == Adj Low (no price movement)\n",
      "Otherwise, IsStale = 0\n",
      "==================================================\n",
      "\n",
      "Calculation details:\n",
      "  TEST, 2024-01-01:\n",
      "    Volume=1000, High=101, Low=99\n",
      "    Conditions met: None (both False)\n",
      "    ‚Üí IsStale = 0\n",
      "\n",
      "  TEST, 2024-01-02:\n",
      "    Volume=0, High=103, Low=101\n",
      "    Conditions met: Volume=0\n",
      "    ‚Üí IsStale = 1\n",
      "\n",
      "  TEST, 2024-01-03:\n",
      "    Volume=500, High=103, Low=103\n",
      "    Conditions met: High=Low\n",
      "    ‚Üí IsStale = 1\n",
      "\n",
      "  TEST, 2024-01-04:\n",
      "    Volume=1000, High=105, Low=104\n",
      "    Conditions met: None (both False)\n",
      "    ‚Üí IsStale = 0\n",
      "\n",
      "\n",
      "Manual IsStale calculation: [0 1 1 0]\n",
      "Expected: [0, 1, 1, 0]\n",
      "‚úì IsStale calculation logic is correct\n",
      "\n",
      "==================================================\n",
      "Running test_multiple_tickers...\n",
      "test_multiple_tickers_df:\n",
      "                   Adj Open  Adj High  Adj Low  Adj Close  Volume\n",
      "Ticker Date                                                      \n",
      "A      2024-01-01       100       101       99        100    1000\n",
      "       2024-01-02       102       103      101        102    1000\n",
      "B      2024-01-01        50        52       48         49    2000\n",
      "       2024-01-02        51        53       49         52    2000\n",
      "\n",
      "\n",
      "Multiple Ticker Results:\n",
      "                    TR  ATR\n",
      "Ticker Date                \n",
      "A      2024-01-01  NaN  NaN\n",
      "       2024-01-02  3.0  3.0\n",
      "B      2024-01-01  NaN  NaN\n",
      "       2024-01-02  4.0  4.0\n",
      "‚úì Ticker A TR: 3.0 (expected 3.0)\n",
      "‚úì Ticker B TR: 4.0 (expected 4.0)\n",
      "‚úÖ Ticker separation test passed!\n",
      "\n",
      "==================================================\n",
      "Running test_edge_cases...\n",
      "\n",
      "1. Testing penny stock with low price...\n",
      "df_penny_stock:\n",
      "                   Adj Open  Adj High  Adj Low  Adj Close  Volume\n",
      "Ticker Date                                                      \n",
      "PENNY  2024-01-01      0.10      0.10     0.10       0.10    1000\n",
      "       2024-01-02      0.11      0.11     0.11       0.11    1000\n",
      "\n",
      "‚úì Penny stock ATRP is 0.0909\n",
      "\n",
      "2. Testing single row data...\n",
      "df_single:\n",
      "                   Adj Open  Adj High  Adj Low  Adj Close  Volume\n",
      "Ticker Date                                                      \n",
      "SINGLE 2024-01-01       100       101       99        100    1000\n",
      "\n",
      "‚úì Single row TR is NaN (correct)\n",
      "‚úì Single row rolling metrics are NaN (correct - insufficient periods)\n",
      "\n",
      "‚úÖ All edge case tests passed!\n",
      "\n",
      "==================================================\n",
      "Running test_zero_division_protection...\n",
      "test_zero_division_protection_df:\n",
      "                   Adj Open  Adj High  Adj Low  Adj Close  Volume\n",
      "Ticker Date                                                      \n",
      "ZERO   2024-01-01        10        12        8         10    1000\n",
      "       2024-01-02        10        12        8          0    1000\n",
      "       2024-01-03        10        12        8         10    1000\n",
      "\n",
      "‚úÖ Zero Division Test Passed: ATRP is NaN when Close is 0.\n",
      "\n",
      "==================================================\n",
      "Running test_unsorted_input_handling...\n",
      "test_unsorted_input_handling_df:\n",
      "                   Adj Open  Adj High  Adj Low  Adj Close  Volume\n",
      "Ticker Date                                                      \n",
      "A      2024-01-02       100       105      105        105     100\n",
      "       2024-01-01       100       100      100        100     100\n",
      "       2024-01-03       100       110      110        110     100\n",
      "\n",
      "‚úÖ Sorting Test Passed: Logic applied in correct chronological order.\n",
      "\n",
      "==================================================\n",
      "Running test_quality_rolling_features...\n",
      "Input Data:\n",
      "                   Adj Open  Adj High  Adj Low  Adj Close  Volume\n",
      "Ticker Date                                                      \n",
      "TEST   2024-01-01        10        12        8         10     100\n",
      "       2024-01-02        10        12        8         10     100\n",
      "       2024-01-03        20        22       18         20       0\n",
      "       2024-01-04        20        20       20         20      50\n",
      "       2024-01-05        30        35       25         30     200\n",
      "\n",
      "--- Testing RollingStalePct ---\n",
      "‚úÖ RollingStalePct Passed\n",
      "\n",
      "--- Testing RollMedDollarVol ---\n",
      "‚úÖ RollMedDollarVol Passed\n",
      "\n",
      "--- Testing RollingSameVolCount ---\n",
      "‚úÖ RollingSameVolCount Passed\n",
      "\n",
      "üéâ All Rolling Quality Feature Tests Passed!\n",
      "\n",
      "==================================================\n",
      "Running test_math_metrics...\n",
      "s_gain:\n",
      "0    100\n",
      "1    105\n",
      "2    110\n",
      "dtype: int64\n",
      "res_gain:\n",
      "0.10000000000000009\n",
      "‚úÖ Gain Calc (Positive): Passed\n",
      "\n",
      "s_loss:\n",
      "0    100\n",
      "1     95\n",
      "2     90\n",
      "dtype: int64\n",
      "res_loss:\n",
      "-0.09999999999999998\n",
      "‚úÖ Gain Calc (Negative): Passed\n",
      "\n",
      "s_flat:\n",
      "0    0.01\n",
      "1    0.01\n",
      "2    0.01\n",
      "dtype: float64\n",
      "res_sharpe_flat:\n",
      "0.0\n",
      "‚úÖ Sharpe (Zero Volatility): Passed (Returns 0.0)\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Running test_engine_lag_logic...\n",
      "df_test:\n",
      "                   Adj Close  Adj High  Adj Low  Adj Open  Volume\n",
      "Ticker Date                                                      \n",
      "MOCK   2024-01-01      100.0     100.0    100.0     100.0    1000\n",
      "       2024-01-02      100.0     100.0    100.0     100.0    1000\n",
      "       2024-01-03      110.0     110.0    110.0     110.0    1000\n",
      "       2024-01-04      121.0     121.0    121.0     121.0    1000\n",
      "\n",
      "--- ‚öôÔ∏è Initializing AlphaEngine ---\n",
      "üê¢ Calculating Features from scratch...\n",
      "üê¢ Pivoting Price Data (Slow)...\n",
      "Warning: Master ticker not found. Using MOCK\n",
      "  Decision Date: 2024-01-02\n",
      "  Full Series Gain: 0.2100 (Should range Jan 1 -> Jan 4)\n",
      "  Forward Gain: 0.1000\n",
      "‚úÖ LAG VERIFIED: Forward Gain is 10.00%.\n",
      "   The system correctly skips the jump immediately following the decision.\n",
      "   It simulates entry at T+1 Close.\n",
      "\n",
      "============================================================\n",
      "TEST SUMMARY\n",
      "============================================================\n",
      "‚úÖ PASS: TR Calculation\n",
      "‚úÖ PASS: ATR Calculation\n",
      "‚úÖ PASS: IsStale Calculation\n",
      "‚úÖ PASS: Multiple Tickers\n",
      "‚úÖ PASS: Edge Cases\n",
      "‚úÖ PASS: Zero Division Protection\n",
      "‚úÖ PASS: Unsorted Input Handling\n",
      "‚úÖ PASS: Quality Rolling Features\n",
      "‚úÖ PASS: Math Metrics\n",
      "‚úÖ PASS: Engine Lag Logic\n",
      "\n",
      "============================================================\n",
      "TOTAL: 10/10 tests passed (100.0%)\n",
      "============================================================\n",
      "\n",
      "üéâ ALL TESTS PASSED! Your feature calculations are working correctly.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_true_range_calculation():\n",
    "    \"\"\"Test TR = max(High-Low, |High-PrevClose|, |Low-PrevClose|) using robust pandas testing\"\"\"\n",
    "    print(\"Running test_true_range_calculation (Robust Version)...\")\n",
    "    \n",
    "    # 1. SETUP: Create test data\n",
    "    test_data = {\n",
    "        'Adj Open': [100, 105, 95, 98, 102],\n",
    "        'Adj High': [105, 108, 97, 102, 105],\n",
    "        'Adj Low': [95, 103, 93, 100, 98],\n",
    "        'Adj Close': [100, 106, 96, 99, 103],\n",
    "        'Volume': [1000, 1200, 800, 900, 1100]\n",
    "    }\n",
    "    \n",
    "    index = pd.MultiIndex.from_tuples(\n",
    "        [\n",
    "            ('TEST', pd.Timestamp('2024-01-01')),\n",
    "            ('TEST', pd.Timestamp('2024-01-02')),\n",
    "            ('TEST', pd.Timestamp('2024-01-03')),\n",
    "            ('TEST', pd.Timestamp('2024-01-04')),\n",
    "            ('TEST', pd.Timestamp('2024-01-05')),\n",
    "        ],\n",
    "        names=['Ticker', 'Date']\n",
    "    )\n",
    "    \n",
    "    df_test = pd.DataFrame(test_data, index=index)\n",
    "    print(f'test_true_range_df input:\\n{df_test}\\n')\n",
    "    \n",
    "    # 2. EXECUTION: Run function\n",
    "    result = generate_features(df_test, quality_window=5, quality_min_periods=2)\n",
    "    \n",
    "    # 3. ASSERTION: Define EXACT expected series\n",
    "    # Day 1: NaN (No prev close)\n",
    "    # Day 2: 8.0 (PrevClose=100, High=108, Low=103. |108-100|=8)\n",
    "    # Day 3: 13.0 (PrevClose=106, High=97, Low=93. |93-106|=13)\n",
    "    # Day 4: 6.0 (PrevClose=96, High=102, Low=100. |102-96|=6)\n",
    "    # Day 5: 7.0 (PrevClose=99, High=105, Low=98. High-Low=7)\n",
    "    expected_tr_values = [np.nan, 8.0, 13.0, 6.0, 7.0]\n",
    "    \n",
    "    expected_series = pd.Series(\n",
    "        expected_tr_values, \n",
    "        index=result.index, \n",
    "        name='TR',\n",
    "        dtype='float64'\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Check Series Equality\n",
    "        # check_exact=False allows for minor floating point differences (rtol=1e-4)\n",
    "        assert_series_equal(result['TR'], expected_series, check_exact=False, rtol=1e-4)\n",
    "        \n",
    "        print(\"‚úÖ PD Testing Assertion Passed! All TR values match expected logic.\")\n",
    "        return True\n",
    "        \n",
    "    except AssertionError as e:\n",
    "        print(f\"‚ùå PD Testing Assertion Failed: {e}\")\n",
    "        \n",
    "        # Helper output to see what went wrong\n",
    "        print(\"\\nDetailed Comparison (Actual vs Expected):\")\n",
    "        comparison = pd.concat([result['TR'], expected_series], axis=1, keys=['Actual_TR', 'Expected_TR'])\n",
    "        comparison['Diff'] = comparison['Actual_TR'] - comparison['Expected_TR']\n",
    "        print(comparison)\n",
    "        \n",
    "        return False\n",
    "\n",
    "def test_atr_calculation():\n",
    "    \"\"\"Test ATR = EWMA of TR with alpha=1/period\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Running test_atr_calculation...\")\n",
    "    \n",
    "    # Test data with 5 days\n",
    "    test_data = {\n",
    "        'Adj Open': [100, 102, 103, 110, 108],\n",
    "        'Adj High': [101, 103, 103, 112, 110],\n",
    "        'Adj Low': [99, 101, 103, 108, 107],\n",
    "        'Adj Close': [100, 102, 103, 111, 109],\n",
    "        'Volume': [1000, 1000, 1000, 1000, 1000]  # All non-zero for simplicity\n",
    "    }\n",
    "    \n",
    "    index = pd.MultiIndex.from_tuples(\n",
    "        [('TEST', pd.Timestamp(f'2024-01-{i:02d}')) for i in range(1, 6)],\n",
    "        names=['Ticker', 'Date']\n",
    "    )\n",
    "    \n",
    "    df_test = pd.DataFrame(test_data, index=index)\n",
    "\n",
    "    print(f'test_true_range_df:\\n{df_test}\\n')\n",
    "\n",
    "    result = generate_features(df_test, atr_period=14)\n",
    "    \n",
    "    print(\"\\nATR Calculation Results:\")\n",
    "    print(result[['TR', 'ATR', 'ATRP']])\n",
    "    \n",
    "    # Manual calculation from our earlier example\n",
    "    # CORRECTED EXPECTED VALUES WITH MORE PRECISION\n",
    "    expected_atr = {\n",
    "        '2024-01-02': 3.0,\n",
    "        '2024-01-03': 40/14,  # ‚âà 2.857142857142857\n",
    "        '2024-01-04': 646/196,  # ‚âà 3.2959183673469388\n",
    "        '2024-01-05': 9182/2744,  # ‚âà 3.3462099125364433\n",
    "    }\n",
    "\n",
    "    all_passed = True\n",
    "    for date_str, expected in expected_atr.items():\n",
    "        actual = result.loc[('TEST', pd.Timestamp(date_str)), 'ATR']\n",
    "        if abs(actual - expected) < 0.0001:\n",
    "            print(f\"‚úì {date_str} ATR: {actual:.6f} ‚âà {expected:.6f}\")\n",
    "        else:\n",
    "            print(f\"‚úó {date_str} ATR: {actual:.6f} != {expected:.6f}\")\n",
    "            all_passed = False\n",
    "    \n",
    "    if all_passed:\n",
    "        print(\"\\n‚úÖ All ATR tests passed!\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå Some ATR tests failed!\")\n",
    "    \n",
    "    return all_passed\n",
    "\n",
    "def test_is_stale_calculation():\n",
    "    \"\"\"Test IsStale = 1 when Volume=0 OR High=Low\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Running test_is_stale_calculation...\")\n",
    "    \n",
    "    test_data = {\n",
    "        'Adj Open': [100, 102, 103, 104],\n",
    "        'Adj High': [101, 103, 103, 105],  # Day 3: High=Low\n",
    "        'Adj Low': [99, 101, 103, 104],\n",
    "        'Adj Close': [100, 102, 103, 105],\n",
    "        'Volume': [1000, 0, 500, 1000]  # Day 2: Volume=0\n",
    "    }\n",
    "    \n",
    "    index = pd.MultiIndex.from_tuples(\n",
    "        [('TEST', pd.Timestamp(f'2024-01-{i:02d}')) for i in range(1, 5)],\n",
    "        names=['Ticker', 'Date']\n",
    "    )\n",
    "    \n",
    "    df_test = pd.DataFrame(test_data, index=index)\n",
    "\n",
    "    print(f'test_is_stale_df:\\n{df_test}\\n')\n",
    "\n",
    "    # Create IsStale manually to verify\n",
    "    is_stale_manual = np.where(\n",
    "        (df_test['Volume'] == 0) | (df_test['Adj High'] == df_test['Adj Low']),\n",
    "        1, 0\n",
    "    )\n",
    "    \n",
    "    print(\"\\nüìä Manual IsStale Calculation:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"IsStale = 1 if EITHER condition is true:\")\n",
    "    print(\"  1. Volume == 0\")\n",
    "    print(\"  2. Adj High == Adj Low (no price movement)\")\n",
    "    print(\"Otherwise, IsStale = 0\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Create a temporary DataFrame to display the calculation clearly\n",
    "    manual_calc_df = df_test.copy()\n",
    "    manual_calc_df['IsStale_Manual'] = is_stale_manual\n",
    "    manual_calc_df['Volume==0'] = manual_calc_df['Volume'] == 0\n",
    "    manual_calc_df['High==Low'] = manual_calc_df['Adj High'] == manual_calc_df['Adj Low']\n",
    "    \n",
    "    print(\"\\nCalculation details:\")\n",
    "    for idx, row in manual_calc_df.iterrows():\n",
    "        ticker_date = f\"{idx[0]}, {idx[1].strftime('%Y-%m-%d')}\"\n",
    "        conditions = []\n",
    "        if row['Volume==0']:\n",
    "            conditions.append(\"Volume=0\")\n",
    "        if row['High==Low']:\n",
    "            conditions.append(\"High=Low\")\n",
    "        \n",
    "        condition_str = \" OR \".join(conditions) if conditions else \"None (both False)\"\n",
    "        result = row['IsStale_Manual']\n",
    "        \n",
    "        print(f\"  {ticker_date}:\")\n",
    "        print(f\"    Volume={row['Volume']}, High={row['Adj High']}, Low={row['Adj Low']}\")\n",
    "        print(f\"    Conditions met: {condition_str}\")\n",
    "        print(f\"    ‚Üí IsStale = {result}\")\n",
    "        print()\n",
    "\n",
    "    expected = [0, 1, 1, 0]  # Day 1: normal, Day 2: vol=0, Day 3: high=low, Day 4: normal\n",
    "    \n",
    "    print(f\"\\nManual IsStale calculation: {is_stale_manual}\")\n",
    "    print(f\"Expected: {expected}\")\n",
    "    \n",
    "    if list(is_stale_manual) == expected:\n",
    "        print(\"‚úì IsStale calculation logic is correct\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"‚úó IsStale calculation failed. Got {is_stale_manual}, expected {expected}\")\n",
    "        return False\n",
    "\n",
    "def test_multiple_tickers():\n",
    "    \"\"\"Test that calculations don't mix data between tickers\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Running test_multiple_tickers...\")\n",
    "    \n",
    "    test_data = {\n",
    "        'Adj Open': [100, 102, 50, 51],\n",
    "        'Adj High': [101, 103, 52, 53],\n",
    "        'Adj Low': [99, 101, 48, 49],\n",
    "        'Adj Close': [100, 102, 49, 52],\n",
    "        'Volume': [1000, 1000, 2000, 2000]\n",
    "    }\n",
    "    \n",
    "    index = pd.MultiIndex.from_tuples([\n",
    "        ('A', pd.Timestamp('2024-01-01')),\n",
    "        ('A', pd.Timestamp('2024-01-02')),\n",
    "        ('B', pd.Timestamp('2024-01-01')),\n",
    "        ('B', pd.Timestamp('2024-01-02')),\n",
    "    ], names=['Ticker', 'Date'])\n",
    "    \n",
    "    df_test = pd.DataFrame(test_data, index=index)\n",
    "\n",
    "    print(f'test_multiple_tickers_df:\\n{df_test}\\n')\n",
    "\n",
    "    result = generate_features(df_test)\n",
    "    \n",
    "    print(\"\\nMultiple Ticker Results:\")\n",
    "    print(result[['TR', 'ATR']])\n",
    "    \n",
    "    # Ticker A day 2 TR should use A day 1 close, not B day 1 close\n",
    "    tr_a2 = result.loc[('A', '2024-01-02'), 'TR']\n",
    "    expected_a2 = 3.0  # max(103-101=2, |103-100|=3, |101-100|=1) = 3\n",
    "    \n",
    "    tr_b2 = result.loc[('B', '2024-01-02'), 'TR']\n",
    "    expected_b2 = 4.0  # max(53-49=4, |53-49|=4, |49-49|=0) = 4\n",
    "    \n",
    "    tests_passed = 0\n",
    "    total_tests = 2\n",
    "    \n",
    "    if abs(tr_a2 - expected_a2) < 0.0001:\n",
    "        print(f\"‚úì Ticker A TR: {tr_a2} (expected {expected_a2})\")\n",
    "        tests_passed += 1\n",
    "    else:\n",
    "        print(f\"‚úó Ticker A TR: {tr_a2} != {expected_a2}\")\n",
    "    \n",
    "    if abs(tr_b2 - expected_b2) < 0.0001:\n",
    "        print(f\"‚úì Ticker B TR: {tr_b2} (expected {expected_b2})\")\n",
    "        tests_passed += 1\n",
    "    else:\n",
    "        print(f\"‚úó Ticker B TR: {tr_b2} != {expected_b2}\")\n",
    "    \n",
    "    if tests_passed == total_tests:\n",
    "        print(\"‚úÖ Ticker separation test passed!\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"‚ùå Ticker separation test failed: {tests_passed}/{total_tests} passed\")\n",
    "        return False\n",
    "\n",
    "def test_edge_cases():\n",
    "    \"\"\"Test edge cases like zero price, single row, etc.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Running test_edge_cases...\")\n",
    "    \n",
    "    all_passed = True\n",
    "    \n",
    "    # Test 1: Very low price (penny stock)\n",
    "    print(\"\\n1. Testing penny stock with low price...\")\n",
    "    test_data = {\n",
    "        'Adj Open': [0.10, 0.11],\n",
    "        'Adj High': [0.10, 0.11],\n",
    "        'Adj Low': [0.10, 0.11],\n",
    "        'Adj Close': [0.10, 0.11],\n",
    "        'Volume': [1000, 1000]\n",
    "    }\n",
    "    \n",
    "    index = pd.MultiIndex.from_tuples([\n",
    "        ('PENNY', pd.Timestamp('2024-01-01')),\n",
    "        ('PENNY', pd.Timestamp('2024-01-02')),\n",
    "    ], names=['Ticker', 'Date'])\n",
    "    \n",
    "    df_penny = pd.DataFrame(test_data, index=index)\n",
    "\n",
    "    print(f'df_penny_stock:\\n{df_penny}\\n')\n",
    "\n",
    "    result = generate_features(df_penny)\n",
    "    \n",
    "    # Check ATRP is reasonable (not inf/nan)\n",
    "    atrp_val = result.loc[('PENNY', '2024-01-02'), 'ATRP']\n",
    "    if pd.isna(atrp_val) or np.isinf(atrp_val):\n",
    "        print(f\"‚úó Penny stock ATRP is {atrp_val} (should be finite)\")\n",
    "        all_passed = False\n",
    "    else:\n",
    "        print(f\"‚úì Penny stock ATRP is {atrp_val:.4f}\")\n",
    "    \n",
    "    # Test 2: Single row\n",
    "    print(\"\\n2. Testing single row data...\")\n",
    "    test_data_single = {\n",
    "        'Adj Open': [100],\n",
    "        'Adj High': [101],\n",
    "        'Adj Low': [99],\n",
    "        'Adj Close': [100],\n",
    "        'Volume': [1000]\n",
    "    }\n",
    "    \n",
    "    index_single = pd.MultiIndex.from_tuples(\n",
    "        [('SINGLE', pd.Timestamp('2024-01-01'))],\n",
    "        names=['Ticker', 'Date']\n",
    "    )\n",
    "    \n",
    "    df_single = pd.DataFrame(test_data_single, index=index_single)\n",
    "\n",
    "    print(f'df_single:\\n{df_single}\\n')\n",
    "\n",
    "    result_single = generate_features(df_single, quality_window=3, quality_min_periods=2)\n",
    "    \n",
    "    # TR should be NaN (no previous close)\n",
    "    if pd.isna(result_single.loc[('SINGLE', '2024-01-01'), 'TR']):\n",
    "        print(\"‚úì Single row TR is NaN (correct)\")\n",
    "    else:\n",
    "        print(f\"‚úó Single row TR should be NaN but got {result_single.loc[('SINGLE', '2024-01-01'), 'TR']}\")\n",
    "        all_passed = False\n",
    "    \n",
    "    # Rolling metrics should be NaN with min_periods=2\n",
    "    if pd.isna(result_single.loc[('SINGLE', '2024-01-01'), 'RollingStalePct']):\n",
    "        print(\"‚úì Single row rolling metrics are NaN (correct - insufficient periods)\")\n",
    "    else:\n",
    "        print(f\"‚úó Rolling metrics should be NaN but got {result_single.loc[('SINGLE', '2024-01-01'), 'RollingStalePct']}\")\n",
    "        all_passed = False\n",
    "    \n",
    "    if all_passed:\n",
    "        print(\"\\n‚úÖ All edge case tests passed!\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå Some edge case tests failed!\")\n",
    "    \n",
    "    return all_passed\n",
    "\n",
    "def test_zero_division_protection():\n",
    "    \"\"\"Test that Zero Price doesn't cause Inf values in ATRP\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Running test_zero_division_protection...\")\n",
    "\n",
    "    test_data = {\n",
    "        'Adj Open': [10, 10, 10],\n",
    "        'Adj High': [12, 12, 12],\n",
    "        'Adj Low': [8, 8, 8],\n",
    "        'Adj Close': [10, 0, 10], # Day 2 Price is ZERO\n",
    "        'Volume': [1000, 1000, 1000]\n",
    "    }\n",
    "    index = pd.MultiIndex.from_tuples(\n",
    "        [('ZERO', pd.Timestamp(f'2024-01-0{i}')) for i in range(1, 4)],\n",
    "        names=['Ticker', 'Date']\n",
    "    )\n",
    "    df_test = pd.DataFrame(test_data, index=index)\n",
    "\n",
    "    print(f'test_zero_division_protection_df:\\n{df_test}\\n')\n",
    "\n",
    "    # Run features\n",
    "    result = generate_features(df_test, atr_period=2)\n",
    "    \n",
    "    # Check Day 2 ATRP\n",
    "    atrp_val = result.loc[('ZERO', '2024-01-02'), 'ATRP']\n",
    "    \n",
    "    if pd.isna(atrp_val):\n",
    "        print(\"‚úÖ Zero Division Test Passed: ATRP is NaN when Close is 0.\")\n",
    "        return True\n",
    "    elif np.isinf(atrp_val):\n",
    "        print(f\"‚ùå Zero Division Test Failed: ATRP is Infinite ({atrp_val}).\")\n",
    "        return False\n",
    "    else:\n",
    "        print(f\"‚ùå Zero Division Test Failed: Unexpected value {atrp_val}\")\n",
    "        return False\n",
    "\n",
    "def test_unsorted_input_handling():\n",
    "    \"\"\"Test that function handles unsorted dates correctly via sorting\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)    \n",
    "    print(\"Running test_unsorted_input_handling...\")\n",
    "    \n",
    "    # Data is out of order: Day 2, Day 1, Day 3\n",
    "    index = pd.MultiIndex.from_tuples([\n",
    "        ('A', pd.Timestamp('2024-01-02')), \n",
    "        ('A', pd.Timestamp('2024-01-01')), \n",
    "        ('A', pd.Timestamp('2024-01-03'))\n",
    "    ], names=['Ticker', 'Date'])\n",
    "    \n",
    "    # Prices: 100 -> 105 -> 110\n",
    "    # If processed in order given: \n",
    "    # 1. 105 (No prev)\n",
    "    # 2. 100 (Prev is 105) -> Change -5\n",
    "    # 3. 110 (Prev is 100) -> Change +10\n",
    "    \n",
    "    # If sorted correctly:\n",
    "    # 1. 100 (No prev)\n",
    "    # 2. 105 (Prev is 100) -> Change +5\n",
    "    # 3. 110 (Prev is 105) -> Change +5\n",
    "    \n",
    "    test_data = {\n",
    "        'Adj Open': [100, 100, 100],\n",
    "        'Adj High': [105, 100, 110], \n",
    "        'Adj Low': [105, 100, 110],\n",
    "        'Adj Close': [105, 100, 110], # 105, 100, 110\n",
    "        'Volume': [100, 100, 100]\n",
    "    }\n",
    "    \n",
    "    df_test = pd.DataFrame(test_data, index=index)\n",
    "\n",
    "    print(f'test_unsorted_input_handling_df:\\n{df_test}\\n')\n",
    "\n",
    "    # Run features\n",
    "    result = generate_features(df_test)\n",
    "    \n",
    "    # Inspect 2024-01-02 (Should be Day 2 in sorted order)\n",
    "    # Prev close (Jan 1) was 100. Current High 105. TR should be roughly 5.\n",
    "    tr_day_2 = result.loc[('A', '2024-01-02'), 'TR']\n",
    "    \n",
    "    # If it wasn't sorted, Day 2 would be treated as the first row (TR=NaN) \n",
    "    # or compared against whatever came before it in memory.\n",
    "    \n",
    "    if pd.isna(tr_day_2):\n",
    "         print(\"‚ùå Sorting Test Failed: Day 2 TR is NaN (likely treated as first row).\")\n",
    "         return False\n",
    "    elif abs(tr_day_2 - 5.0) < 0.1:\n",
    "         print(\"‚úÖ Sorting Test Passed: Logic applied in correct chronological order.\")\n",
    "         return True\n",
    "    else:\n",
    "         print(f\"‚ùå Sorting Test Failed: Day 2 TR is {tr_day_2}, expected ~5.0\")\n",
    "         return False\n",
    "\n",
    "    \"\"\"Test TR = max(High-Low, |High-PrevClose|, |Low-PrevClose|) using robust pandas testing\"\"\"\n",
    "    print(\"Running test_true_range_calculation (Robust Version)...\")\n",
    "    \n",
    "    # 1. SETUP: Create test data\n",
    "    test_data = {\n",
    "        'Adj Open': [100, 105, 95, 98, 102],\n",
    "        'Adj High': [105, 108, 97, 102, 105],\n",
    "        'Adj Low': [95, 103, 93, 100, 98],\n",
    "        'Adj Close': [100, 106, 96, 99, 103],\n",
    "        'Volume': [1000, 1200, 800, 900, 1100]\n",
    "    }\n",
    "    \n",
    "    index = pd.MultiIndex.from_tuples(\n",
    "        [\n",
    "            ('TEST', pd.Timestamp('2024-01-01')),\n",
    "            ('TEST', pd.Timestamp('2024-01-02')),\n",
    "            ('TEST', pd.Timestamp('2024-01-03')),\n",
    "            ('TEST', pd.Timestamp('2024-01-04')),\n",
    "            ('TEST', pd.Timestamp('2024-01-05')),\n",
    "        ],\n",
    "        names=['Ticker', 'Date']\n",
    "    )\n",
    "    \n",
    "    df_test = pd.DataFrame(test_data, index=index)\n",
    "    print(f'test_true_range_df input:\\n{df_test}\\n')\n",
    "    \n",
    "    # 2. EXECUTION: Run function\n",
    "    result = generate_features(df_test, quality_window=5, quality_min_periods=2)\n",
    "    \n",
    "    # 3. ASSERTION: Define EXACT expected series\n",
    "    # Day 1: NaN (No prev close)\n",
    "    # Day 2: 8.0 (PrevClose=100, High=108, Low=103. |108-100|=8)\n",
    "    # Day 3: 13.0 (PrevClose=106, High=97, Low=93. |93-106|=13)\n",
    "    # Day 4: 6.0 (PrevClose=96, High=102, Low=100. |102-96|=6)\n",
    "    # Day 5: 7.0 (PrevClose=99, High=105, Low=98. High-Low=7)\n",
    "    expected_tr_values = [np.nan, 8.0, 13.0, 6.0, 7.0]\n",
    "    \n",
    "    expected_series = pd.Series(\n",
    "        expected_tr_values, \n",
    "        index=result.index, \n",
    "        name='TR',\n",
    "        dtype='float64'\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Check Series Equality\n",
    "        # check_exact=False allows for minor floating point differences (rtol=1e-4)\n",
    "        assert_series_equal(result['TR'], expected_series, check_exact=False, rtol=1e-4)\n",
    "        \n",
    "        print(\"‚úÖ PD Testing Assertion Passed! All TR values match expected logic.\")\n",
    "        return True\n",
    "        \n",
    "    except AssertionError as e:\n",
    "        print(f\"‚ùå PD Testing Assertion Failed: {e}\")\n",
    "        \n",
    "        # Helper output to see what went wrong\n",
    "        print(\"\\nDetailed Comparison (Actual vs Expected):\")\n",
    "        comparison = pd.concat([result['TR'], expected_series], axis=1, keys=['Actual_TR', 'Expected_TR'])\n",
    "        comparison['Diff'] = comparison['Actual_TR'] - comparison['Expected_TR']\n",
    "        print(comparison)\n",
    "        \n",
    "        return False\n",
    "\n",
    "def test_quality_rolling_features():\n",
    "    \"\"\"\n",
    "    Test RollingStalePct, RollMedDollarVol, and RollingSameVolCount \n",
    "    verifying logic for Stale(Vol=0), Stale(H=L), SameVolume, and Median calculations.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Running test_quality_rolling_features...\")\n",
    "\n",
    "    # 1. SETUP: Create specific test data\n",
    "    # We set up 5 days to test a window of 4\n",
    "    test_data = {\n",
    "        # Day 1: Normal Base Day. $Vol = 10*100 = 1000.\n",
    "        # Day 2: Same Volume as D1. $Vol = 10*100 = 1000.\n",
    "        # Day 3: Stale (Volume=0). $Vol = 20*0 = 0.\n",
    "        # Day 4: Stale (High=Low). $Vol = 20*50 = 1000.\n",
    "        # Day 5: Normal High Vol. $Vol = 30*200 = 6000.\n",
    "        \n",
    "        'Adj Open':  [10,   10,   20,   20,   30],\n",
    "        'Adj High':  [12,   12,   22,   20,   35], # Day 4 High=20\n",
    "        'Adj Low':   [8,    8,    18,   20,   25], # Day 4 Low=20 (H=L)\n",
    "        'Adj Close': [10,   10,   20,   20,   30],\n",
    "        'Volume':    [100,  100,  0,    50,   200] # Day 2 same as D1, Day 3 is 0\n",
    "    }\n",
    "\n",
    "    index = pd.MultiIndex.from_tuples(\n",
    "        [('TEST', pd.Timestamp(f'2024-01-0{i}')) for i in range(1, 6)],\n",
    "        names=['Ticker', 'Date']\n",
    "    )\n",
    "\n",
    "    df_test = pd.DataFrame(test_data, index=index)\n",
    "    print(f'Input Data:\\n{df_test}')\n",
    "\n",
    "    # 2. EXECUTION: Use window=4, min_periods=2 to capture partial rolling\n",
    "    # We expect Day 1 to be NaN (count=1 < min_periods=2)\n",
    "    result = generate_features(df_test, quality_window=4, quality_min_periods=2)\n",
    "    \n",
    "    # 3. VERIFICATION\n",
    "\n",
    "    # --- A. Test RollingStalePct ---\n",
    "    print(\"\\n--- Testing RollingStalePct ---\")\n",
    "    # Logic:\n",
    "    # Day 1: IsStale=0. Result=NaN (min_periods)\n",
    "    # Day 2: IsStale=0. Window=[0,0]. Mean=0.0\n",
    "    # Day 3: IsStale=1 (Vol=0). Window=[0,0,1]. Mean=1/3 (~0.333)\n",
    "    # Day 4: IsStale=1 (High=Low). Window=[0,0,1,1]. Mean=2/4 = 0.5\n",
    "    # Day 5: IsStale=0. Window=[0,1,1,0] (Day 1 drops off). Mean=2/4 = 0.5\n",
    "    \n",
    "    expected_stale = pd.Series(\n",
    "        [np.nan, 0.0, 1/3, 0.5, 0.5],\n",
    "        index=result.index, name='RollingStalePct'\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        assert_series_equal(result['RollingStalePct'], expected_stale, check_exact=False, rtol=1e-4)\n",
    "        print(\"‚úÖ RollingStalePct Passed\")\n",
    "    except AssertionError as e:\n",
    "        print(f\"‚ùå RollingStalePct Failed: {e}\")\n",
    "        return False\n",
    "\n",
    "    # --- B. Test RollMedDollarVol ---\n",
    "    print(\"\\n--- Testing RollMedDollarVol ---\")\n",
    "    # Logic: $Vol = Close * Volume\n",
    "    # D1: 1000. Result=NaN\n",
    "    # D2: 1000. Window=[1000, 1000]. Median=1000\n",
    "    # D3: 0.    Window=[1000, 1000, 0]. Sorted=[0, 1000, 1000]. Median=1000\n",
    "    # D4: 1000. Window=[1000, 1000, 0, 1000]. Sorted=[0, 1000, 1000, 1000]. Median=(1000+1000)/2 = 1000\n",
    "    # D5: 6000. Window=[1000, 0, 1000, 6000]. Sorted=[0, 1000, 1000, 6000]. Median=1000\n",
    "    \n",
    "    expected_dollar = pd.Series(\n",
    "        [np.nan, 1000.0, 1000.0, 1000.0, 1000.0],\n",
    "        index=result.index, name='RollMedDollarVol'\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        assert_series_equal(result['RollMedDollarVol'], expected_dollar, check_exact=False, rtol=1e-4)\n",
    "        print(\"‚úÖ RollMedDollarVol Passed\")\n",
    "    except AssertionError as e:\n",
    "        print(f\"‚ùå RollMedDollarVol Failed: {e}\")\n",
    "        return False\n",
    "\n",
    "    # --- C. Test RollingSameVolCount ---\n",
    "    print(\"\\n--- Testing RollingSameVolCount ---\")\n",
    "    # Logic: HasSameVolume = (Volume == PrevVolume)\n",
    "    # D1: NaN/0 (First row diff is NaN, astype(int) -> 0). Result=NaN (min_periods)\n",
    "    # D2: 1 (100==100). Window=[0, 1]. Sum=1\n",
    "    # D3: 0 (0!=100).   Window=[0, 1, 0]. Sum=1\n",
    "    # D4: 0 (50!=0).    Window=[0, 1, 0, 0]. Sum=1\n",
    "    # D5: 0 (200!=50).  Window=[1, 0, 0, 0] (D1 drops). Sum=1\n",
    "    \n",
    "    expected_same_vol = pd.Series(\n",
    "        [np.nan, 1.0, 1.0, 1.0, 1.0],\n",
    "        index=result.index, name='RollingSameVolCount'\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        assert_series_equal(result['RollingSameVolCount'], expected_same_vol, check_exact=False, rtol=1e-4)\n",
    "        print(\"‚úÖ RollingSameVolCount Passed\")\n",
    "    except AssertionError as e:\n",
    "        print(f\"‚ùå RollingSameVolCount Failed: {e}\")\n",
    "        return False\n",
    "\n",
    "    print(\"\\nüéâ All Rolling Quality Feature Tests Passed!\")\n",
    "    return True\n",
    "\n",
    "def test_math_metrics():\n",
    "    \"\"\"Verifies calculate_gain and calculate_sharpe are mathematically precise.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Running test_math_metrics...\")\n",
    "    all_passed = True\n",
    "\n",
    "    # --- 1. Test calculate_gain ---\n",
    "    # Case A: Price goes 100 -> 110 (10% gain)\n",
    "    s_gain = pd.Series([100, 105, 110])\n",
    "    res_gain = calculate_gain(s_gain)\n",
    "\n",
    "    print(f's_gain:\\n{s_gain}')\n",
    "    print(f'res_gain:\\n{res_gain}')    \n",
    "    \n",
    "    if abs(res_gain - 0.10) < 1e-9:\n",
    "        print(\"‚úÖ Gain Calc (Positive): Passed\\n\")\n",
    "    else:\n",
    "        print(f\"‚ùå Gain Calc (Positive): Failed. Got {res_gain}\\n\")\n",
    "        all_passed = False\n",
    "\n",
    "    # Case B: Price goes 100 -> 90 (10% loss)\n",
    "    s_loss = pd.Series([100, 95, 90])\n",
    "    res_loss = calculate_gain(s_loss)\n",
    "\n",
    "    print(f's_loss:\\n{s_loss}')\n",
    "    print(f'res_loss:\\n{res_loss}')  \n",
    "\n",
    "    if abs(res_loss - (-0.10)) < 1e-9:\n",
    "        print(\"‚úÖ Gain Calc (Negative): Passed\\n\")\n",
    "    else:\n",
    "        print(f\"‚ùå Gain Calc (Negative): Failed. Got {res_loss}\\n\")\n",
    "        all_passed = False\n",
    "\n",
    "    # --- 2. Test calculate_sharpe ---\n",
    "    # Case: Flat return (0 volatility) -> Should return 0.0 (handle divide by zero)\n",
    "    s_flat = pd.Series([0.01, 0.01, 0.01]) \n",
    "    res_sharpe_flat = calculate_sharpe(s_flat)\n",
    "\n",
    "    print(f's_flat:\\n{s_flat}')\n",
    "    print(f'res_sharpe_flat:\\n{res_sharpe_flat}')  \n",
    "\n",
    "    if res_sharpe_flat == 0.0:\n",
    "        print(\"‚úÖ Sharpe (Zero Volatility): Passed (Returns 0.0)\\n\")\n",
    "    else:\n",
    "        print(f\"‚ùå Sharpe (Zero Volatility): Failed. Got {res_sharpe_flat}\\n\")\n",
    "        all_passed = False\n",
    "    \n",
    "    return all_passed\n",
    "\n",
    "def test_engine_lag_logic():\n",
    "    \"\"\"\n",
    "    CRITICAL TEST: Verifies the '1-Day Lag' logic.\n",
    "    If we make a decision on Day T, we cannot trade at Day T's close (Lookahead bias).\n",
    "    We effectively enter at Day T+1 Close (in this implementation).\n",
    "    \n",
    "    Scenario:\n",
    "    Day 1: 100\n",
    "    Day 2: 100  <-- Decision Date (End of Calc Period)\n",
    "    Day 3: 110  <-- T+1 (Price jumps 10%)\n",
    "    Day 4: 121  <-- T+2 (Price jumps 10%)\n",
    "    \n",
    "    If 'Fwd Gain' includes Day 2->3 jump, it implies T+0 execution (Lookahead).\n",
    "    If 'Fwd Gain' is Day 3->4, it implies T+1 execution (Realistic).\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"\\nRunning test_engine_lag_logic...\")\n",
    "    \n",
    "    # 1. Setup Mock Data\n",
    "    dates = pd.to_datetime(['2024-01-01', '2024-01-02', '2024-01-03', '2024-01-04'])\n",
    "    # Prices: Flat, Flat, +10%, +10%\n",
    "    prices = [100.0, 100.0, 110.0, 121.0] \n",
    "    \n",
    "    df_test = pd.DataFrame({\n",
    "        'Adj Close': prices,\n",
    "        'Adj High': prices,\n",
    "        'Adj Low': prices, \n",
    "        'Adj Open': prices,\n",
    "        'Volume': [1000]*4\n",
    "    }, index=pd.MultiIndex.from_product([['MOCK'], dates], names=['Ticker', 'Date']))\n",
    "\n",
    "    print(f'df_test:\\n{df_test}\\n')\n",
    "\n",
    "    # 2. Initialize Engine\n",
    "    engine = AlphaEngine(df_test)\n",
    "    \n",
    "    # 3. Run Strategy\n",
    "    # Decision Date = 2024-01-02.\n",
    "    # We define Lookback=1 (uses Jan 1-2).\n",
    "    # We define Forward=2 (uses Jan 3-4).\n",
    "    inputs = EngineInput(\n",
    "        mode='Manual List',\n",
    "        start_date=pd.Timestamp('2024-01-02'),\n",
    "        calc_period=1,\n",
    "        fwd_period=2,\n",
    "        metric='Price', # Irrelevant for manual\n",
    "        benchmark_ticker='MOCK', # Compare against self\n",
    "        manual_tickers=['MOCK']\n",
    "    )\n",
    "    \n",
    "    res = engine.run(inputs)\n",
    "    \n",
    "    # 4. Analyze Results\n",
    "    metrics = res.perf_metrics\n",
    "    \n",
    "    print(f\"  Decision Date: {res.calc_end_date.date()}\")\n",
    "    print(f\"  Full Series Gain: {metrics['full_p_gain']:.4f} (Should range Jan 1 -> Jan 4)\")\n",
    "    print(f\"  Forward Gain: {metrics['fwd_p_gain']:.4f}\")\n",
    "    \n",
    "    # --- VERIFICATION LOGIC ---\n",
    "    \n",
    "    # Full Gain: 100 -> 121 = 21% (0.2100)\n",
    "    # Forward Logic in Engine:\n",
    "    #   Slice starts at Decision Date (Jan 2).\n",
    "    #   get_lagged_fwd(val, Jan 2) -> Slice [Jan 2, Jan 3, Jan 4] -> iloc[1:] -> [Jan 3, Jan 4].\n",
    "    #   Calc Gain on [Jan 3 (110), Jan 4 (121)].\n",
    "    #   Expected: (121 / 110) - 1 = 1.1 - 1 = 0.10 (10%).\n",
    "    \n",
    "    # If the engine was T+0 (Lookahead), it would use Jan 2 (100) -> Jan 4 (121) = 21%.\n",
    "    \n",
    "    expected_fwd_gain = 0.10\n",
    "    \n",
    "    if abs(metrics['fwd_p_gain'] - expected_fwd_gain) < 1e-4:\n",
    "        print(f\"‚úÖ LAG VERIFIED: Forward Gain is {metrics['fwd_p_gain']:.2%}.\")\n",
    "        print(\"   The system correctly skips the jump immediately following the decision.\")\n",
    "        print(\"   It simulates entry at T+1 Close.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"‚ùå LAG FAILURE: Forward Gain is {metrics['fwd_p_gain']:.2%}.\")\n",
    "        print(f\"   Expected {expected_fwd_gain:.2%} (T+1 entry).\")\n",
    "        return False\n",
    "\n",
    "def run_all_tests():\n",
    "    \"\"\"Run all tests and provide summary\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"STARTING ALL TESTS FOR generate_features()\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    test_results = {}\n",
    "    \n",
    "    # Run each test\n",
    "    test_results['TR Calculation'] = test_true_range_calculation()\n",
    "    test_results['ATR Calculation'] = test_atr_calculation()\n",
    "    test_results['IsStale Calculation'] = test_is_stale_calculation()\n",
    "    test_results['Multiple Tickers'] = test_multiple_tickers()\n",
    "    test_results['Edge Cases'] = test_edge_cases()\n",
    "    test_results['Zero Division Protection'] = test_zero_division_protection()\n",
    "    test_results['Unsorted Input Handling'] = test_unsorted_input_handling()    \n",
    "    test_results['Quality Rolling Features'] = test_quality_rolling_features()   \n",
    "    test_results['Math Metrics'] = test_math_metrics()    \n",
    "    test_results['Engine Lag Logic'] = test_engine_lag_logic()   \n",
    "\n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEST SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    passed = sum(test_results.values())\n",
    "    total = len(test_results)\n",
    "    \n",
    "    for test_name, result in test_results.items():\n",
    "        status = \"‚úÖ PASS\" if result else \"‚ùå FAIL\"\n",
    "        print(f\"{status}: {test_name}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"TOTAL: {passed}/{total} tests passed ({passed/total*100:.1f}%)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if passed == total:\n",
    "        print(\"\\nüéâ ALL TESTS PASSED! Your feature calculations are working correctly.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  {total - passed} test(s) failed. Review the output above.\")\n",
    "        return False\n",
    "\n",
    "run_all_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "232740e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 9641787 entries, ('A', Timestamp('1999-11-18 00:00:00')) to ('ZWS', Timestamp('2025-12-11 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   Adj Open   float64\n",
      " 1   Adj High   float64\n",
      " 2   Adj Low    float64\n",
      " 3   Adj Close  float64\n",
      " 4   Volume     int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 405.3+ MB\n",
      "df_ohlcv.info():\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Adj Open</th>\n",
       "      <th>Adj High</th>\n",
       "      <th>Adj Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">A</th>\n",
       "      <th>1999-11-18</th>\n",
       "      <td>27.2452</td>\n",
       "      <td>29.9398</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>26.3470</td>\n",
       "      <td>74716417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-19</th>\n",
       "      <td>25.7108</td>\n",
       "      <td>25.7482</td>\n",
       "      <td>23.8396</td>\n",
       "      <td>24.1764</td>\n",
       "      <td>18198344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-22</th>\n",
       "      <td>24.7378</td>\n",
       "      <td>26.3470</td>\n",
       "      <td>23.9893</td>\n",
       "      <td>26.3470</td>\n",
       "      <td>7857766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-23</th>\n",
       "      <td>25.4488</td>\n",
       "      <td>26.1225</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>7138322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-24</th>\n",
       "      <td>24.0267</td>\n",
       "      <td>25.1120</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>24.5881</td>\n",
       "      <td>5785608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ZWS</th>\n",
       "      <th>2025-12-05</th>\n",
       "      <td>46.8600</td>\n",
       "      <td>47.2700</td>\n",
       "      <td>46.4400</td>\n",
       "      <td>46.8600</td>\n",
       "      <td>886700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-08</th>\n",
       "      <td>46.9400</td>\n",
       "      <td>47.2000</td>\n",
       "      <td>46.2900</td>\n",
       "      <td>46.3800</td>\n",
       "      <td>683900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-09</th>\n",
       "      <td>46.2900</td>\n",
       "      <td>46.6500</td>\n",
       "      <td>45.8700</td>\n",
       "      <td>45.9300</td>\n",
       "      <td>605000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-10</th>\n",
       "      <td>46.0100</td>\n",
       "      <td>47.1100</td>\n",
       "      <td>45.9400</td>\n",
       "      <td>46.8600</td>\n",
       "      <td>1248300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-11</th>\n",
       "      <td>47.0600</td>\n",
       "      <td>47.8900</td>\n",
       "      <td>46.8800</td>\n",
       "      <td>47.5900</td>\n",
       "      <td>618204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9641787 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Adj Open  Adj High  Adj Low  Adj Close    Volume\n",
       "Ticker Date                                                        \n",
       "A      1999-11-18   27.2452   29.9398  23.9518    26.3470  74716417\n",
       "       1999-11-19   25.7108   25.7482  23.8396    24.1764  18198344\n",
       "       1999-11-22   24.7378   26.3470  23.9893    26.3470   7857766\n",
       "       1999-11-23   25.4488   26.1225  23.9518    23.9518   7138322\n",
       "       1999-11-24   24.0267   25.1120  23.9518    24.5881   5785608\n",
       "...                     ...       ...      ...        ...       ...\n",
       "ZWS    2025-12-05   46.8600   47.2700  46.4400    46.8600    886700\n",
       "       2025-12-08   46.9400   47.2000  46.2900    46.3800    683900\n",
       "       2025-12-09   46.2900   46.6500  45.8700    45.9300    605000\n",
       "       2025-12-10   46.0100   47.1100  45.9400    46.8600   1248300\n",
       "       2025-12-11   47.0600   47.8900  46.8800    47.5900    618204\n",
       "\n",
       "[9641787 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = r'c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet'\n",
    "df_ohlcv = pd.read_parquet(data_path, engine='pyarrow')\n",
    "print(f'df_ohlcv.info():\\n{df_ohlcv.info()}')\n",
    "df_ohlcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "957c5c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating features... this might take few minutes...\n",
      "1. Calculating Features...\n",
      "2. Pivoting Price Matrix...\n",
      "‚úÖ Optimization Complete. Ready for UI.\n"
     ]
    }
   ],
   "source": [
    "# Calculate features ONCE and store them in a variable\n",
    "print(\"Calculating features... this might take few minutes...\")\n",
    "print(\"1. Calculating Features...\")\n",
    "my_features = generate_features(\n",
    "    df_ohlcv=df_ohlcv, \n",
    "    atr_period=14,\n",
    "    quality_window=252,\n",
    "    quality_min_periods=126\n",
    ")\n",
    "\n",
    "print(\"2. Pivoting Price Matrix...\")\n",
    "# This is the line that takes 12 seconds, but now we only run it ONCE.\n",
    "my_close_matrix = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "\n",
    "print(\"‚úÖ Optimization Complete. Ready for UI.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaa8a33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_features:\n",
      "                       TR     ATR    ATRP   ROC_1   ROC_3   ROC_5  ROC_10  ROC_21  RollingStalePct  RollMedDollarVol  RollingSameVolCount\n",
      "Ticker Date                                                                                                                              \n",
      "A      1999-11-18     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN              NaN               NaN                  NaN\n",
      "       1999-11-19  2.5074  2.5074  0.1037 -0.0824     NaN     NaN     NaN     NaN              NaN               NaN                  NaN\n",
      "       1999-11-22  2.3577  2.4967  0.0948  0.0898     NaN     NaN     NaN     NaN              NaN               NaN                  NaN\n",
      "       1999-11-23  2.3952  2.4895  0.1039 -0.0909 -0.0909     NaN     NaN     NaN              NaN               NaN                  NaN\n",
      "       1999-11-24  1.1602  2.3945  0.0974  0.0266  0.0170     NaN     NaN     NaN              NaN               NaN                  NaN\n",
      "...                   ...     ...     ...     ...     ...     ...     ...     ...              ...               ...                  ...\n",
      "ZWS    2025-12-05  0.8300  1.0948  0.0234 -0.0013 -0.0201 -0.0176  0.0319 -0.0242              0.0        3.2573e+07                  0.0\n",
      "       2025-12-08  0.9100  1.0816  0.0233 -0.0102 -0.0226 -0.0285 -0.0051 -0.0239              0.0        3.2494e+07                  0.0\n",
      "       2025-12-09  0.7800  1.0601  0.0231 -0.0097 -0.0211 -0.0395 -0.0288 -0.0299              0.0        3.2494e+07                  0.0\n",
      "       2025-12-10  1.1800  1.0687  0.0228  0.0202  0.0000 -0.0124 -0.0242 -0.0132              0.0        3.2573e+07                  0.0\n",
      "       2025-12-11  1.0300  1.0659  0.0224  0.0156  0.0261  0.0143 -0.0112 -0.0080              0.0        3.2494e+07                  0.0\n",
      "\n",
      "[9641787 rows x 11 columns]\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 9641787 entries, ('A', Timestamp('1999-11-18 00:00:00')) to ('ZWS', Timestamp('2025-12-11 00:00:00'))\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Dtype  \n",
      "---  ------               -----  \n",
      " 0   TR                   float64\n",
      " 1   ATR                  float64\n",
      " 2   ATRP                 float64\n",
      " 3   ROC_1                float64\n",
      " 4   ROC_3                float64\n",
      " 5   ROC_5                float64\n",
      " 6   ROC_10               float64\n",
      " 7   ROC_21               float64\n",
      " 8   RollingStalePct      float64\n",
      " 9   RollMedDollarVol     float64\n",
      " 10  RollingSameVolCount  float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 846.7+ MB\n"
     ]
    }
   ],
   "source": [
    "print(f'my_features:\\n{my_features}\\n')\n",
    "my_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cb1bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ‚öôÔ∏è Initializing AlphaEngine ---\n",
      "‚ö° Using Pre-Computed Price Matrix (Instant Load)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3246b0550240498a8b9b1378c7bc5ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>1. Timeline Configuration:</b> (Past <--- Decision ---> Future)'), HBox(children‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de02c43cdb234ee09dba738f6dd0d240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'width': 2},\n",
       "              'name': 'JPST',\n",
       "              'type': 'scatter',\n",
       "              'uid': '7379b3f3-2d7a-4e16-9282-c178c76a077f',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 7, 30, 0, 0),\n",
       "                          datetime.datetime(2025, 7, 31, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 1, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 4, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 5, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 6, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 7, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 11, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 12, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 0.99980294, 1.00174542, 1.00194249, 1.00194249, 1.00194249,\n",
       "                          1.00214156, 1.0025377 , 1.00234063, 1.00293384, 1.00313291, 1.00293384,\n",
       "                          1.00332998, 1.00332998, 1.00392519, 1.00412426])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'LOW',\n",
       "              'type': 'scatter',\n",
       "              'uid': '9fba22fa-cfa5-4e98-bfb8-a7e51d4f1003',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 7, 30, 0, 0),\n",
       "                          datetime.datetime(2025, 7, 31, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 1, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 4, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 5, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 6, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 7, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 11, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 12, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 0.98302823, 0.99547095, 1.02805357, 1.04410186, 1.04775161,\n",
       "                          1.0489402 , 1.06032689, 1.05461366, 1.07668447, 1.12707397, 1.11265172,\n",
       "                          1.10829942, 1.10315177, 1.12720653, 1.13063535])},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '9fc577f4-a3d5-4a9a-b6df-672ee3d25fea', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '8b8849ea-79d0-4a49-a416-f4656921c792', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '379fb45e-2a0e-4bbd-826a-13b9197a4cd1', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '25bf13e1-5ec2-4e55-bbbc-262038f50025', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '823de9ef-d407-4805-94ba-c7c8b01131b9', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '6c55d8cd-a918-4f85-b54e-ffb06cc8e507', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '08d0fdff-1195-4572-964d-e7fe01ec57f0', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'dea9b620-384b-46d1-bf12-ea97bc02488f', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '1e6e25e4-f560-4399-9695-2f6081443271', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '614cc368-6a34-402c-85d2-97f8feb7d6b7', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '176f5409-d938-41f0-8e73-3bc034a57ca1', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '223e0ebb-3a6d-4271-b8a0-f9142bab295e', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '2adbcd76-4b76-432e-8d42-5a0a5dd60291', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '1a6756f4-f182-492f-b822-bb32095da5ea', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '5ca839e2-45a6-472b-abfc-dbc4e5f939ba', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '49ef3238-ea4f-4db7-9167-b5a83cb5b66e', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '4272449f-75e6-49d7-93f3-5ec2fb32f300', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '69e73808-cd9e-4c1c-aced-778f4b1c67c6', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '92649109-005b-433f-9e84-ee96483973f9', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '896bf49a-5393-4fe8-8b3f-73b44e135be7', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'a8f7dce4-bbb9-4169-a0a1-1bd4e2412dc9', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '21b3174f-f776-4cf1-949f-cff287ebbdf2', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '9776590b-7850-43fe-98e5-bddd2cb577f8', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'cd6394ae-1f89-47fd-b834-5bb6d003e745', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'f16a0dcd-b332-4f55-8d58-d52cc74efa84', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'edd2181a-5ca3-4bd7-afc5-b5b79b7a6c4e', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'e721b56a-6257-4136-a8b1-3690e3b73b69', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '7381046a-06be-4753-a8f5-d1d421b38b4a', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '89105181-d6f4-4db1-a061-99ea57292646', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '3a1c1c3e-6286-4eef-a044-610f28a2e9c0', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'ceceb1d5-7aa0-442f-9b05-435b5ef74a23', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '7fde80e1-1742-445e-a8c0-222e66284e7a', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '776ec572-0953-43de-aace-4f5fcaa81f70', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'f2d40199-04bf-4072-bbc9-a09eab8da984', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'ab911bf3-0c31-4144-9579-a693a129a125', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '245b0049-2056-4481-9c8b-02cfaba3f972', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '73e53acd-27db-4067-9d57-e7d0e22ff40c', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'ad714353-14b7-4c75-8b96-39761c4d24c7', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '027a2861-863a-4aa7-9674-55e44df16807', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'adf3dff6-1023-408e-a414-cef3b3236731', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'f608f25c-271d-46ed-a7cd-5273f33f0bbd', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '699ee415-1a39-414e-ac42-665a4e486637', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'd16acfd9-b89f-4fcd-afc5-6a7862b92a49', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'bd95a42e-a768-42ee-b5e2-6b5d6cda40bc', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '3ed1cf3e-9e92-4a63-8eb1-b2152d916a53', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '33a9f74b-de96-45c5-b7ba-cafaa7ebf79b', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '1b57dbee-a330-4262-ae13-67e11024d16f', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '6d64cd0c-89e7-43fd-bdcc-4c2502b6d608', 'visible': False},\n",
       "             {'line': {'color': 'black', 'dash': 'dash', 'width': 3},\n",
       "              'name': 'Benchmark (SPY)',\n",
       "              'type': 'scatter',\n",
       "              'uid': '98b5fafc-3e69-4789-8922-bd4dd898b3f3',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 7, 30, 0, 0),\n",
       "                          datetime.datetime(2025, 7, 31, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 1, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 4, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 5, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 6, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 7, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 11, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 12, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 0.99624786, 0.97991958, 0.99481434, 0.98977092, 0.99735264,\n",
       "                          0.99651655, 1.00428635, 1.00230123, 1.01297127, 1.01643891, 1.01653375,\n",
       "                          1.01415349, 1.01393222, 1.00843204, 1.00575307])},\n",
       "             {'line': {'color': 'green', 'width': 3},\n",
       "              'name': 'Group Portfolio',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd2381ab1-5bde-4dc3-a35f-f4571f9a7d0e',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 7, 30, 0, 0),\n",
       "                          datetime.datetime(2025, 7, 31, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 1, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 4, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 5, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 6, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 7, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 8, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 11, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 12, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 0.99141558, 0.99860819, 1.01499803, 1.02302217, 1.02484705,\n",
       "                          1.02554088, 1.03143229, 1.02847715, 1.03980916, 1.06510344, 1.05779278,\n",
       "                          1.0558147 , 1.05324087, 1.06556586, 1.06737981])}],\n",
       "    'layout': {'annotations': [{'bgcolor': 'red',\n",
       "                                'font': {'color': 'white'},\n",
       "                                'showarrow': False,\n",
       "                                'text': 'DECISION',\n",
       "                                'x': Timestamp('2025-08-13 00:00:00'),\n",
       "                                'xref': 'x',\n",
       "                                'y': 0.05,\n",
       "                                'yref': 'paper'}],\n",
       "               'height': 600,\n",
       "               'hovermode': 'x unified',\n",
       "               'shapes': [{'line': {'color': 'red', 'dash': 'dash', 'width': 2},\n",
       "                           'type': 'line',\n",
       "                           'x0': Timestamp('2025-08-13 00:00:00'),\n",
       "                           'x1': Timestamp('2025-08-13 00:00:00'),\n",
       "                           'xref': 'x',\n",
       "                           'y0': 0,\n",
       "                           'y1': 1,\n",
       "                           'yref': 'paper'}],\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Event-Driven Walk-Forward Analysis'}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_container, debug_container = plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    precomputed_features=my_features, # Fast Features\n",
    "    precomputed_close=my_close_matrix, # Fast Prices    \n",
    "    default_start_date='2025-08-13',\n",
    "    default_lookback=10,     # Was default_calc_period\n",
    "    default_holding=5,       # Was default_fwd_period\n",
    "    default_strategy='Sharpe (ATR)', # Was default_metric\n",
    "    default_rank_start=15,\n",
    "    default_rank_end=16,\n",
    "    default_benchmark_ticker='SPY', \n",
    "    master_calendar_ticker='XOM',    \n",
    "    quality_thresholds = { \n",
    "        'min_median_dollar_volume': 100_000, # A low \"hard floor\" to filter absolute errors/garbage\n",
    "        # If min_liquidity_percentile is 0.8 (Top 20%), we want values > the 0.8 quantile.            \n",
    "        'min_liquidity_percentile': 0.50,    # Dynamic: Only keep the top 50% of stocks by volume\n",
    "        'max_stale_pct': 0.05, \n",
    "        'max_same_vol_count': 10\n",
    "    },\n",
    "    debug=True  # <-- Activate the new mode!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "551b239f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EngineOutput(portfolio_series=Date\n",
      "2025-07-30    1.0000\n",
      "2025-07-31    0.9914\n",
      "2025-08-01    0.9986\n",
      "2025-08-04    1.0150\n",
      "2025-08-05    1.0230\n",
      "2025-08-06    1.0248\n",
      "2025-08-07    1.0255\n",
      "2025-08-08    1.0314\n",
      "2025-08-11    1.0285\n",
      "2025-08-12    1.0398\n",
      "2025-08-13    1.0651\n",
      "2025-08-14    1.0578\n",
      "2025-08-15    1.0558\n",
      "2025-08-18    1.0532\n",
      "2025-08-19    1.0656\n",
      "2025-08-20    1.0674\n",
      "dtype: float64, benchmark_series=Date\n",
      "2025-07-30    1.0000\n",
      "2025-07-31    0.9962\n",
      "2025-08-01    0.9799\n",
      "2025-08-04    0.9948\n",
      "2025-08-05    0.9898\n",
      "2025-08-06    0.9974\n",
      "2025-08-07    0.9965\n",
      "2025-08-08    1.0043\n",
      "2025-08-11    1.0023\n",
      "2025-08-12    1.0130\n",
      "2025-08-13    1.0164\n",
      "2025-08-14    1.0165\n",
      "2025-08-15    1.0142\n",
      "2025-08-18    1.0139\n",
      "2025-08-19    1.0084\n",
      "2025-08-20    1.0058\n",
      "dtype: float64, normalized_plot_data=Ticker        JPST     LOW\n",
      "Date                      \n",
      "2025-07-30  1.0000  1.0000\n",
      "2025-07-31  0.9998  0.9830\n",
      "2025-08-01  1.0017  0.9955\n",
      "2025-08-04  1.0019  1.0281\n",
      "2025-08-05  1.0019  1.0441\n",
      "2025-08-06  1.0019  1.0478\n",
      "2025-08-07  1.0021  1.0489\n",
      "2025-08-08  1.0025  1.0603\n",
      "2025-08-11  1.0023  1.0546\n",
      "2025-08-12  1.0029  1.0767\n",
      "2025-08-13  1.0031  1.1271\n",
      "2025-08-14  1.0029  1.1127\n",
      "2025-08-15  1.0033  1.1083\n",
      "2025-08-18  1.0033  1.1032\n",
      "2025-08-19  1.0039  1.1272\n",
      "2025-08-20  1.0041  1.1306, tickers=['LOW', 'JPST'], initial_weights=LOW     0.5\n",
      "JPST    0.5\n",
      "dtype: float64, perf_metrics={'full_p_gain': 0.06737980526742682, 'calc_p_gain': 0.06510344146042168, 'fwd_p_gain': 0.009063235740263353, 'full_p_sharpe_atr': 0.40702084610400946, 'calc_p_sharpe_atr': 0.6044106010089558, 'fwd_p_sharpe_atr': 0.20022905365527116, 'full_p_sharpe': 7.787635152452495, 'calc_p_sharpe': 10.649501158912415, 'fwd_p_sharpe': 5.514145728672722, 'full_b_gain': 0.005753066985298094, 'calc_b_gain': 0.01643891475661685, 'fwd_b_gain': -0.01060533267409558, 'full_b_sharpe_atr': 0.04723211142709824, 'calc_b_sharpe_atr': 0.18814433653877657, 'fwd_b_sharpe_atr': -0.3252028953406366, 'full_b_sharpe': 0.8465034132333867, 'calc_b_sharpe': 2.883471297880455, 'fwd_b_sharpe': -19.75644262439131}, results_df=        Rank  Strategy Value  Fwd Gain\n",
      "Ticker                                \n",
      "LOW       15          0.6045    0.0032\n",
      "JPST      16          0.5915    0.0010, start_date=Timestamp('2025-07-30 00:00:00'), calc_end_date=Timestamp('2025-08-13 00:00:00'), viz_end_date=Timestamp('2025-08-20 00:00:00'), error_msg=None, debug_data={'audit_liquidity': {'date': Timestamp('2025-08-13 00:00:00'), 'total_tickers_available': 1619, 'percentile_setting': 0.5, 'percentile_value_usd': 111430348.4486, 'final_cutoff_usd': 111430348.4486, 'tickers_passed': 800, 'universe_snapshot':              TR      ATR    ATRP   ROC_1   ROC_3   ROC_5  ROC_10  ROC_21  RollingStalePct  RollMedDollarVol  RollingSameVolCount  Calculated_Cutoff  Passed_Vol_Check  Passed_Final\n",
      "Ticker                                                                                                                                                                             \n",
      "SPY      3.5000   5.6850  0.0088  0.0034  0.0121  0.0191  0.0164  0.0366              0.0        3.3654e+10                  0.0         1.1143e+08              True          True\n",
      "NVDA     4.6190   4.3540  0.0240 -0.0086 -0.0061  0.0121  0.0129  0.0638              0.0        3.0490e+10                  0.0         1.1143e+08              True          True\n",
      "TSLA    10.7800  12.9654  0.0382 -0.0043  0.0295  0.0609  0.0638  0.0920              0.0        2.8007e+10                  0.0         1.1143e+08              True          True\n",
      "QQQ      4.3750   6.4681  0.0112  0.0005  0.0101  0.0230  0.0217  0.0424              0.0        1.8455e+10                  0.0         1.1143e+08              True          True\n",
      "AAPL     5.3440   5.2710  0.0226  0.0160  0.0185  0.0954  0.1174  0.1171              0.0        1.0290e+10                  0.0         1.1143e+08              True          True\n",
      "...         ...      ...     ...     ...     ...     ...     ...     ...              ...               ...                  ...                ...               ...           ...\n",
      "OTF      0.5599   0.3501  0.0244  0.0229 -0.0074 -0.0140 -0.0360 -0.0521              NaN               NaN                  NaN         1.1143e+08             False         False\n",
      "SAIL     1.9500   1.1548  0.0580  0.0501  0.0370 -0.0168 -0.0888 -0.0226              NaN               NaN                  NaN         1.1143e+08             False         False\n",
      "SBIL     0.0266   0.0382  0.0004  0.0000  0.0003  0.0007  0.0017  0.0032              NaN               NaN                  NaN         1.1143e+08             False         False\n",
      "SNDK     1.6600   2.2216  0.0473  0.0038  0.0602  0.1166  0.0834  0.1004              NaN               NaN                  NaN         1.1143e+08             False         False\n",
      "STRC     0.5314   1.4645  0.0155  0.0011  0.0041  0.0093  0.0360     NaN              NaN               NaN                  NaN         1.1143e+08             False         False\n",
      "\n",
      "[1619 rows x 14 columns]}, 'portfolio_trace':             Norm_Price_JPST  Norm_Price_LOW  Norm_Price_Portfolio  Norm_Price_Benchmark_SPY\n",
      "Date                                                                                       \n",
      "2025-07-30           1.0000          1.0000                1.0000                    1.0000\n",
      "2025-07-31           0.9998          0.9830                0.9914                    0.9962\n",
      "2025-08-01           1.0017          0.9955                0.9986                    0.9799\n",
      "2025-08-04           1.0019          1.0281                1.0150                    0.9948\n",
      "2025-08-05           1.0019          1.0441                1.0230                    0.9898\n",
      "2025-08-06           1.0019          1.0478                1.0248                    0.9974\n",
      "2025-08-07           1.0021          1.0489                1.0255                    0.9965\n",
      "2025-08-08           1.0025          1.0603                1.0314                    1.0043\n",
      "2025-08-11           1.0023          1.0546                1.0285                    1.0023\n",
      "2025-08-12           1.0029          1.0767                1.0398                    1.0130\n",
      "2025-08-13           1.0031          1.1271                1.0651                    1.0164\n",
      "2025-08-14           1.0029          1.1127                1.0578                    1.0165\n",
      "2025-08-15           1.0033          1.1083                1.0558                    1.0142\n",
      "2025-08-18           1.0033          1.1032                1.0532                    1.0139\n",
      "2025-08-19           1.0039          1.1272                1.0656                    1.0084\n",
      "2025-08-20           1.0041          1.1306                1.0674                    1.0058})\n",
      "====================\n",
      "audit_liquidity:\n",
      "    date:\n",
      "        2025-08-13 00:00:00\n",
      "    total_tickers_available:\n",
      "        1619\n",
      "    percentile_setting:\n",
      "        0.5\n",
      "    percentile_value_usd:\n",
      "        111430348.4486\n",
      "    final_cutoff_usd:\n",
      "        111430348.4486\n",
      "    tickers_passed:\n",
      "        800\n",
      "    universe_snapshot:\n",
      "                     TR      ATR    ATRP   ROC_1   ROC_3   ROC_5  ROC_10  ROC_21  RollingStalePct  RollMedDollarVol  RollingSameVolCount  Calculated_Cutoff  Passed_Vol_Check  Passed_Final\n",
      "Ticker                                                                                                                                                                             \n",
      "SPY      3.5000   5.6850  0.0088  0.0034  0.0121  0.0191  0.0164  0.0366              0.0        3.3654e+10                  0.0         1.1143e+08              True          True\n",
      "NVDA     4.6190   4.3540  0.0240 -0.0086 -0.0061  0.0121  0.0129  0.0638              0.0        3.0490e+10                  0.0         1.1143e+08              True          True\n",
      "TSLA    10.7800  12.9654  0.0382 -0.0043  0.0295  0.0609  0.0638  0.0920              0.0        2.8007e+10                  0.0         1.1143e+08              True          True\n",
      "QQQ      4.3750   6.4681  0.0112  0.0005  0.0101  0.0230  0.0217  0.0424              0.0        1.8455e+10                  0.0         1.1143e+08              True          True\n",
      "AAPL     5.3440   5.2710  0.0226  0.0160  0.0185  0.0954  0.1174  0.1171              0.0        1.0290e+10                  0.0         1.1143e+08              True          True\n",
      "...         ...      ...     ...     ...     ...     ...     ...     ...              ...               ...                  ...                ...               ...           ...\n",
      "OTF      0.5599   0.3501  0.0244  0.0229 -0.0074 -0.0140 -0.0360 -0.0521              NaN               NaN                  NaN         1.1143e+08             False         False\n",
      "SAIL     1.9500   1.1548  0.0580  0.0501  0.0370 -0.0168 -0.0888 -0.0226              NaN               NaN                  NaN         1.1143e+08             False         False\n",
      "SBIL     0.0266   0.0382  0.0004  0.0000  0.0003  0.0007  0.0017  0.0032              NaN               NaN                  NaN         1.1143e+08             False         False\n",
      "SNDK     1.6600   2.2216  0.0473  0.0038  0.0602  0.1166  0.0834  0.1004              NaN               NaN                  NaN         1.1143e+08             False         False\n",
      "STRC     0.5314   1.4645  0.0155  0.0011  0.0041  0.0093  0.0360     NaN              NaN               NaN                  NaN         1.1143e+08             False         False\n",
      "\n",
      "[1619 rows x 14 columns]\n",
      "portfolio_trace:\n",
      "                Norm_Price_JPST  Norm_Price_LOW  Norm_Price_Portfolio  Norm_Price_Benchmark_SPY\n",
      "Date                                                                                       \n",
      "2025-07-30           1.0000          1.0000                1.0000                    1.0000\n",
      "2025-07-31           0.9998          0.9830                0.9914                    0.9962\n",
      "2025-08-01           1.0017          0.9955                0.9986                    0.9799\n",
      "2025-08-04           1.0019          1.0281                1.0150                    0.9948\n",
      "2025-08-05           1.0019          1.0441                1.0230                    0.9898\n",
      "2025-08-06           1.0019          1.0478                1.0248                    0.9974\n",
      "2025-08-07           1.0021          1.0489                1.0255                    0.9965\n",
      "2025-08-08           1.0025          1.0603                1.0314                    1.0043\n",
      "2025-08-11           1.0023          1.0546                1.0285                    1.0023\n",
      "2025-08-12           1.0029          1.0767                1.0398                    1.0130\n",
      "2025-08-13           1.0031          1.1271                1.0651                    1.0164\n",
      "2025-08-14           1.0029          1.1127                1.0578                    1.0165\n",
      "2025-08-15           1.0033          1.1083                1.0558                    1.0142\n",
      "2025-08-18           1.0033          1.1032                1.0532                    1.0139\n",
      "2025-08-19           1.0039          1.1272                1.0656                    1.0084\n",
      "2025-08-20           1.0041          1.1306                1.0674                    1.0058\n"
     ]
    }
   ],
   "source": [
    "print_nested(results_container)\n",
    "print('='*20)\n",
    "print_nested(debug_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86cc1ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOO:\n",
      "                Adj Open  Adj High  Adj Low  Adj Close    Volume      TR     ATR    ATRP       ROC_1       ROC_3   ROC_5  ROC_10  ROC_21  RollingStalePct  RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                        \n",
      "2025-08-13   591.169   592.336  589.125    591.149   5408423   3.241  5.2072  0.0088  3.4867e-03  1.2120e-02  0.0193  0.0165  0.0367              0.0        2.9400e+09                  0.0\n",
      "2025-08-14   589.235   591.817  588.816    591.159   6254536   3.001  5.0496  0.0085  1.6916e-05  1.4216e-02  0.0199  0.0204  0.0333              0.0        2.9409e+09                  0.0\n",
      "2025-08-15   592.166   592.256  588.976    589.883   7216880   3.280  4.9232  0.0083 -2.1585e-03  1.3376e-03  0.0100  0.0352  0.0249              0.0        2.9461e+09                  0.0\n",
      "2025-08-18   589.295   590.332  588.666    589.674   5326890   1.666  4.6906  0.0080 -3.5431e-04 -2.4951e-03  0.0117  0.0193  0.0250              0.0        2.9601e+09                  0.0\n",
      "2025-08-19   589.564   590.431  585.266    586.453   6758573   5.165  4.7245  0.0081 -5.4623e-03 -7.9606e-03 -0.0045  0.0187  0.0176              0.0        2.9699e+09                  0.0\n",
      "2025-08-20   586.134   586.323  580.191    584.907   7133944   6.262  4.8343  0.0083 -2.6362e-03 -8.4356e-03 -0.0106  0.0085  0.0149              0.0        2.9739e+09                  0.0\n",
      "2025-08-21   583.262   584.788  580.988    582.604   4821048   3.919  4.7689  0.0082 -3.9374e-03 -1.1990e-02 -0.0145  0.0051  0.0024              0.0        2.9739e+09                  0.0\n",
      "2025-08-22   584.598   592.625  584.169    591.518   6407572  10.021  5.1441  0.0087  1.5300e-02  8.6367e-03  0.0028  0.0128  0.0171              0.0        2.9782e+09                  0.0\n",
      "2025-08-25   590.362   591.538  588.866    589.016   6501540   2.672  4.9675  0.0084 -4.2298e-03  7.0250e-03 -0.0011  0.0105  0.0087              0.0        2.9897e+09                  0.0\n",
      "2025-08-26   588.696   591.738  588.108    591.369   4790260   3.630  4.8719  0.0082  3.9948e-03  1.5045e-02  0.0084  0.0039  0.0130              0.0        2.9897e+09                  0.0\n",
      "2025-08-27   590.830   593.443  590.751    592.725   6189049   2.692  4.7162  0.0080  2.2930e-03  2.0405e-03  0.0134  0.0027  0.0180              0.0        3.0027e+09                  0.0\n",
      "2025-08-28   593.373   595.367  591.578    594.819   5073167   3.789  4.6500  0.0078  3.5328e-03  9.8520e-03  0.0210  0.0062  0.0228              0.0        3.0112e+09                  0.0\n",
      "2025-08-29   593.543   593.852  589.564    591.389   7533483   5.255  4.6932  0.0079 -5.7665e-03  3.3820e-05 -0.0002  0.0026  0.0208              0.0        3.0187e+09                  0.0\n",
      "2025-09-02   584.389   587.121  582.006    587.031  11148492   9.383  5.0282  0.0086 -7.3691e-03 -9.6065e-03 -0.0034 -0.0045  0.0302              0.0        3.0200e+09                  0.0\n",
      "2025-09-03   589.125   590.541  587.101    590.033   8229368   3.510  4.9198  0.0083  5.1139e-03 -8.0461e-03 -0.0023  0.0061  0.0200              0.0        3.0275e+09                  0.0\n",
      "2025-09-04   590.780   595.068  589.913    594.889   8068609   5.155  4.9366  0.0083  8.2300e-03  5.9183e-03  0.0037  0.0171  0.0333              0.0        3.0434e+09                  0.0\n",
      "VLO:\n",
      "                Adj Open  Adj High  Adj Low  Adj Close   Volume     TR     ATR    ATRP       ROC_1   ROC_3   ROC_5  ROC_10  ROC_21  RollingStalePct  RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                  \n",
      "2025-08-13   132.554   135.426  132.226    135.297  2106399  3.200  3.7578  0.0278  2.0770e-02  0.0215  0.0202 -0.0151 -0.0775              0.0        3.7834e+08                  0.0\n",
      "2025-08-14   134.035   135.595  132.495    134.969  1918018  3.100  3.7108  0.0275 -2.4243e-03  0.0307  0.0244 -0.0109 -0.0437              0.0        3.7834e+08                  0.0\n",
      "2025-08-15   134.621   136.489  134.164    135.943  2050146  2.325  3.6118  0.0266  7.2165e-03  0.0256  0.0263  0.0272 -0.0467              0.0        3.7834e+08                  0.0\n",
      "2025-08-18   134.820   136.191  134.174    135.953  1881489  2.017  3.4979  0.0257  7.3560e-05  0.0048  0.0383  0.0131 -0.0563              0.0        3.7414e+08                  0.0\n",
      "2025-08-19   136.410   139.013  136.012    137.066  1549912  3.060  3.4666  0.0253  8.1867e-03  0.0155  0.0341  0.0080 -0.0494              0.0        3.7414e+08                  0.0\n",
      "2025-08-20   137.443   140.335  137.135    139.630  2096034  3.269  3.4525  0.0247  1.8706e-02  0.0271  0.0320  0.0528 -0.0238              0.0        3.7414e+08                  0.0\n",
      "2025-08-21   139.113   139.600  137.016    139.411  2409398  2.614  3.3926  0.0243 -1.5684e-03  0.0254  0.0329  0.0581 -0.0414              0.0        3.7206e+08                  0.0\n",
      "2025-08-22   140.087   144.787  139.252    144.459  2119682  5.535  3.5456  0.0245  3.6209e-02  0.0539  0.0626  0.0906  0.0443              0.0        3.7077e+08                  0.0\n",
      "2025-08-25   144.091   146.963  143.396    146.188  2053165  3.567  3.5472  0.0243  1.1969e-02  0.0470  0.0753  0.1164  0.0447              0.0        3.6939e+08                  0.0\n",
      "2025-08-26   145.721   146.288  144.231    146.029  2608143  2.057  3.4407  0.0236 -1.0876e-03  0.0475  0.0654  0.1017  0.0235              0.0        3.7077e+08                  0.0\n",
      "2025-08-27   145.840   150.521  145.840    149.825  2162852  4.681  3.5293  0.0236  2.5995e-02  0.0371  0.0730  0.1074  0.0502              0.0        3.7077e+08                  0.0\n",
      "2025-08-28   149.895   150.898  148.583    150.213  2106097  2.315  3.4426  0.0229  2.5897e-03  0.0275  0.0775  0.1129  0.0935              0.0        3.6939e+08                  0.0\n",
      "2025-08-29   150.879   152.290  149.159    151.057  2256842  3.131  3.4203  0.0226  5.6187e-03  0.0344  0.0457  0.1112  0.1071              0.0        3.6939e+08                  0.0\n",
      "2025-09-02   151.385   153.333  150.302    153.313  3237386  3.031  3.3925  0.0221  1.4935e-02  0.0233  0.0487  0.1277  0.1584              0.0        3.7077e+08                  0.0\n",
      "2025-09-03   154.854   158.262  153.224    154.406  3099723  5.038  3.5101  0.0227  7.1292e-03  0.0279  0.0574  0.1265  0.1506              0.0        3.7206e+08                  0.0\n",
      "2025-09-04   154.595   156.165  153.780    154.416  2627766  2.385  3.4297  0.0222  6.4764e-05  0.0222  0.0306  0.1059  0.1356              0.0        3.7206e+08                  0.0\n",
      "JPST:\n",
      "                Adj Open  Adj High  Adj Low  Adj Close    Volume      TR     ATR    ATRP   ROC_1   ROC_3   ROC_5  ROC_10  ROC_21  RollingStalePct  RollMedDollarVol  RollingSameVolCount\n",
      "Date                                                                                                                                                                                \n",
      "2025-08-13   49.8859   49.8957  49.8760    49.8859   3998082  0.0197  0.0256  0.0005  0.0002  0.0006  0.0012  0.0031  0.0051              0.0        2.5349e+08                  0.0\n",
      "2025-08-14   49.8859   49.8918  49.8760    49.8760   3662718  0.0158  0.0249  0.0005 -0.0002  0.0006  0.0008  0.0031  0.0047              0.0        2.5219e+08                  0.0\n",
      "2025-08-15   49.9007   49.9056  49.8957    49.8957   3421622  0.0296  0.0252  0.0005  0.0004  0.0004  0.0008  0.0016  0.0049              0.0        2.5219e+08                  0.0\n",
      "2025-08-18   49.9056   49.9056  49.8957    49.8957   4062922  0.0099  0.0241  0.0005  0.0000  0.0002  0.0010  0.0014  0.0043              0.0        2.5219e+08                  0.0\n",
      "2025-08-19   49.9056   49.9253  49.9056    49.9253   3869010  0.0296  0.0245  0.0005  0.0006  0.0010  0.0010  0.0020  0.0049              0.0        2.5068e+08                  0.0\n",
      "2025-08-20   49.9253   49.9352  49.9154    49.9352   4704730  0.0198  0.0242  0.0005  0.0002  0.0008  0.0010  0.0022  0.0047              0.0        2.5068e+08                  0.0\n",
      "2025-08-21   49.9154   49.9352  49.9056    49.9056   3881288  0.0296  0.0246  0.0005 -0.0006  0.0002  0.0006  0.0014  0.0043              0.0        2.5068e+08                  0.0\n",
      "2025-08-22   49.9352   49.9647  49.9253    49.9647   4340447  0.0591  0.0270  0.0005  0.0012  0.0008  0.0014  0.0022  0.0055              0.0        2.5068e+08                  0.0\n",
      "2025-08-25   49.9647   49.9647  49.9549    49.9549   4474897  0.0098  0.0258  0.0005 -0.0002  0.0004  0.0012  0.0022  0.0049              0.0        2.5068e+08                  0.0\n",
      "2025-08-26   49.9647   49.9746  49.9647    49.9746   4887785  0.0197  0.0254  0.0005  0.0004  0.0014  0.0010  0.0020  0.0053              0.0        2.5068e+08                  0.0\n",
      "2025-08-27   49.9746   49.9844  49.9647    49.9844  10636760  0.0197  0.0250  0.0005  0.0002  0.0004  0.0010  0.0020  0.0051              0.0        2.5219e+08                  0.0\n",
      "2025-08-28   49.9746   49.9844  49.9746    49.9844   5889715  0.0098  0.0239  0.0005  0.0000  0.0006  0.0016  0.0022  0.0051              0.0        2.5349e+08                  0.0\n",
      "2025-08-29   50.0041   50.0140  49.9943    50.0041   5193621  0.0296  0.0243  0.0005  0.0004  0.0006  0.0008  0.0022  0.0057              0.0        2.5489e+08                  0.0\n",
      "2025-09-02   50.0032   50.0130  49.9933    50.0130   9828726  0.0197  0.0240  0.0005  0.0002  0.0006  0.0012  0.0024  0.0039              0.0        2.5521e+08                  0.0\n",
      "2025-09-03   50.0130   50.0328  50.0130    50.0328   5485845  0.0198  0.0237  0.0005  0.0004  0.0010  0.0012  0.0022  0.0041              0.0        2.5533e+08                  0.0\n",
      "2025-09-04   50.0427   50.0526  50.0328    50.0526   6370313  0.0198  0.0234  0.0005  0.0004  0.0010  0.0014  0.0024  0.0045              0.0        2.5669e+08                  0.0\n"
     ]
    }
   ],
   "source": [
    "my_tickers = ['VOO', 'VLO', 'JPST']\n",
    "date_start = '2025-08-13'\n",
    "date_end = '2025-09-04'\n",
    "\n",
    "# Create combined dictionary\n",
    "combined_dict = create_combined_dict(\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    features_df=my_features,\n",
    "    tickers=my_tickers,\n",
    "    date_start=date_start,\n",
    "    date_end=date_end,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print_nested(combined_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f5e1e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÖ Date: 2025-08-13\n",
      "üí∞ Calculated Cutoff: $111,430,348\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_755ce\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_755ce_level0_col0\" class=\"col_heading level0 col0\" >TR</th>\n",
       "      <th id=\"T_755ce_level0_col1\" class=\"col_heading level0 col1\" >ATR</th>\n",
       "      <th id=\"T_755ce_level0_col2\" class=\"col_heading level0 col2\" >ATRP</th>\n",
       "      <th id=\"T_755ce_level0_col3\" class=\"col_heading level0 col3\" >ROC_1</th>\n",
       "      <th id=\"T_755ce_level0_col4\" class=\"col_heading level0 col4\" >ROC_3</th>\n",
       "      <th id=\"T_755ce_level0_col5\" class=\"col_heading level0 col5\" >ROC_5</th>\n",
       "      <th id=\"T_755ce_level0_col6\" class=\"col_heading level0 col6\" >ROC_10</th>\n",
       "      <th id=\"T_755ce_level0_col7\" class=\"col_heading level0 col7\" >ROC_21</th>\n",
       "      <th id=\"T_755ce_level0_col8\" class=\"col_heading level0 col8\" >RollingStalePct</th>\n",
       "      <th id=\"T_755ce_level0_col9\" class=\"col_heading level0 col9\" >RollMedDollarVol</th>\n",
       "      <th id=\"T_755ce_level0_col10\" class=\"col_heading level0 col10\" >RollingSameVolCount</th>\n",
       "      <th id=\"T_755ce_level0_col11\" class=\"col_heading level0 col11\" >Calculated_Cutoff</th>\n",
       "      <th id=\"T_755ce_level0_col12\" class=\"col_heading level0 col12\" >Passed_Vol_Check</th>\n",
       "      <th id=\"T_755ce_level0_col13\" class=\"col_heading level0 col13\" >Passed_Final</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Ticker</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "      <th class=\"blank col9\" >&nbsp;</th>\n",
       "      <th class=\"blank col10\" >&nbsp;</th>\n",
       "      <th class=\"blank col11\" >&nbsp;</th>\n",
       "      <th class=\"blank col12\" >&nbsp;</th>\n",
       "      <th class=\"blank col13\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_755ce_level0_row0\" class=\"row_heading level0 row0\" >TD</th>\n",
       "      <td id=\"T_755ce_row0_col0\" class=\"data row0 col0\" >1.300000</td>\n",
       "      <td id=\"T_755ce_row0_col1\" class=\"data row0 col1\" >0.840629</td>\n",
       "      <td id=\"T_755ce_row0_col2\" class=\"data row0 col2\" >0.011287</td>\n",
       "      <td id=\"T_755ce_row0_col3\" class=\"data row0 col3\" >0.017347</td>\n",
       "      <td id=\"T_755ce_row0_col4\" class=\"data row0 col4\" >0.016792</td>\n",
       "      <td id=\"T_755ce_row0_col5\" class=\"data row0 col5\" >0.014161</td>\n",
       "      <td id=\"T_755ce_row0_col6\" class=\"data row0 col6\" >0.012507</td>\n",
       "      <td id=\"T_755ce_row0_col7\" class=\"data row0 col7\" >0.014023</td>\n",
       "      <td id=\"T_755ce_row0_col8\" class=\"data row0 col8\" >0.0%</td>\n",
       "      <td id=\"T_755ce_row0_col9\" class=\"data row0 col9\" >$111,982,661</td>\n",
       "      <td id=\"T_755ce_row0_col10\" class=\"data row0 col10\" >0.000000</td>\n",
       "      <td id=\"T_755ce_row0_col11\" class=\"data row0 col11\" >$111,430,348</td>\n",
       "      <td id=\"T_755ce_row0_col12\" class=\"data row0 col12\" >True</td>\n",
       "      <td id=\"T_755ce_row0_col13\" class=\"data row0 col13\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_755ce_level0_row1\" class=\"row_heading level0 row1\" >WCC</th>\n",
       "      <td id=\"T_755ce_row1_col0\" class=\"data row1 col0\" >4.979000</td>\n",
       "      <td id=\"T_755ce_row1_col1\" class=\"data row1 col1\" >6.014023</td>\n",
       "      <td id=\"T_755ce_row1_col2\" class=\"data row1 col2\" >0.027975</td>\n",
       "      <td id=\"T_755ce_row1_col3\" class=\"data row1 col3\" >0.019641</td>\n",
       "      <td id=\"T_755ce_row1_col4\" class=\"data row1 col4\" >0.054533</td>\n",
       "      <td id=\"T_755ce_row1_col5\" class=\"data row1 col5\" >0.044409</td>\n",
       "      <td id=\"T_755ce_row1_col6\" class=\"data row1 col6\" >0.012452</td>\n",
       "      <td id=\"T_755ce_row1_col7\" class=\"data row1 col7\" >0.087209</td>\n",
       "      <td id=\"T_755ce_row1_col8\" class=\"data row1 col8\" >0.0%</td>\n",
       "      <td id=\"T_755ce_row1_col9\" class=\"data row1 col9\" >$111,830,156</td>\n",
       "      <td id=\"T_755ce_row1_col10\" class=\"data row1 col10\" >0.000000</td>\n",
       "      <td id=\"T_755ce_row1_col11\" class=\"data row1 col11\" >$111,430,348</td>\n",
       "      <td id=\"T_755ce_row1_col12\" class=\"data row1 col12\" >True</td>\n",
       "      <td id=\"T_755ce_row1_col13\" class=\"data row1 col13\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_755ce_level0_row2\" class=\"row_heading level0 row2\" >SPYV</th>\n",
       "      <td id=\"T_755ce_row2_col0\" class=\"data row2 col0\" >0.507600</td>\n",
       "      <td id=\"T_755ce_row2_col1\" class=\"data row2 col1\" >0.455391</td>\n",
       "      <td id=\"T_755ce_row2_col2\" class=\"data row2 col2\" >0.008441</td>\n",
       "      <td id=\"T_755ce_row2_col3\" class=\"data row2 col3\" >0.008934</td>\n",
       "      <td id=\"T_755ce_row2_col4\" class=\"data row2 col4\" >0.016694</td>\n",
       "      <td id=\"T_755ce_row2_col5\" class=\"data row2 col5\" >0.027877</td>\n",
       "      <td id=\"T_755ce_row2_col6\" class=\"data row2 col6\" >0.018606</td>\n",
       "      <td id=\"T_755ce_row2_col7\" class=\"data row2 col7\" >0.032774</td>\n",
       "      <td id=\"T_755ce_row2_col8\" class=\"data row2 col8\" >0.0%</td>\n",
       "      <td id=\"T_755ce_row2_col9\" class=\"data row2 col9\" >$111,711,573</td>\n",
       "      <td id=\"T_755ce_row2_col10\" class=\"data row2 col10\" >0.000000</td>\n",
       "      <td id=\"T_755ce_row2_col11\" class=\"data row2 col11\" >$111,430,348</td>\n",
       "      <td id=\"T_755ce_row2_col12\" class=\"data row2 col12\" >True</td>\n",
       "      <td id=\"T_755ce_row2_col13\" class=\"data row2 col13\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_755ce_level0_row3\" class=\"row_heading level0 row3\" >GNRC</th>\n",
       "      <td id=\"T_755ce_row3_col0\" class=\"data row3 col0\" >5.920000</td>\n",
       "      <td id=\"T_755ce_row3_col1\" class=\"data row3 col1\" >5.932117</td>\n",
       "      <td id=\"T_755ce_row3_col2\" class=\"data row3 col2\" >0.029244</td>\n",
       "      <td id=\"T_755ce_row3_col3\" class=\"data row3 col3\" >0.020064</td>\n",
       "      <td id=\"T_755ce_row3_col4\" class=\"data row3 col4\" >0.033631</td>\n",
       "      <td id=\"T_755ce_row3_col5\" class=\"data row3 col5\" >0.046104</td>\n",
       "      <td id=\"T_755ce_row3_col6\" class=\"data row3 col6\" >0.120718</td>\n",
       "      <td id=\"T_755ce_row3_col7\" class=\"data row3 col7\" >0.381718</td>\n",
       "      <td id=\"T_755ce_row3_col8\" class=\"data row3 col8\" >0.0%</td>\n",
       "      <td id=\"T_755ce_row3_col9\" class=\"data row3 col9\" >$111,583,772</td>\n",
       "      <td id=\"T_755ce_row3_col10\" class=\"data row3 col10\" >0.000000</td>\n",
       "      <td id=\"T_755ce_row3_col11\" class=\"data row3 col11\" >$111,430,348</td>\n",
       "      <td id=\"T_755ce_row3_col12\" class=\"data row3 col12\" >True</td>\n",
       "      <td id=\"T_755ce_row3_col13\" class=\"data row3 col13\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_755ce_level0_row4\" class=\"row_heading level0 row4\" >BR</th>\n",
       "      <td id=\"T_755ce_row4_col0\" class=\"data row4 col0\" >3.825000</td>\n",
       "      <td id=\"T_755ce_row4_col1\" class=\"data row4 col1\" >5.553364</td>\n",
       "      <td id=\"T_755ce_row4_col2\" class=\"data row4 col2\" >0.021305</td>\n",
       "      <td id=\"T_755ce_row4_col3\" class=\"data row4 col3\" >-0.003125</td>\n",
       "      <td id=\"T_755ce_row4_col4\" class=\"data row4 col4\" >-0.016017</td>\n",
       "      <td id=\"T_755ce_row4_col5\" class=\"data row4 col5\" >-0.019522</td>\n",
       "      <td id=\"T_755ce_row4_col6\" class=\"data row4 col6\" >0.060810</td>\n",
       "      <td id=\"T_755ce_row4_col7\" class=\"data row4 col7\" >0.119486</td>\n",
       "      <td id=\"T_755ce_row4_col8\" class=\"data row4 col8\" >0.0%</td>\n",
       "      <td id=\"T_755ce_row4_col9\" class=\"data row4 col9\" >$111,542,641</td>\n",
       "      <td id=\"T_755ce_row4_col10\" class=\"data row4 col10\" >0.000000</td>\n",
       "      <td id=\"T_755ce_row4_col11\" class=\"data row4 col11\" >$111,430,348</td>\n",
       "      <td id=\"T_755ce_row4_col12\" class=\"data row4 col12\" >True</td>\n",
       "      <td id=\"T_755ce_row4_col13\" class=\"data row4 col13\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_755ce_level0_row5\" class=\"row_heading level0 row5\" >PATH</th>\n",
       "      <td id=\"T_755ce_row5_col0\" class=\"data row5 col0\" >0.525000</td>\n",
       "      <td id=\"T_755ce_row5_col1\" class=\"data row5 col1\" >0.361355</td>\n",
       "      <td id=\"T_755ce_row5_col2\" class=\"data row5 col2\" >0.032880</td>\n",
       "      <td id=\"T_755ce_row5_col3\" class=\"data row5 col3\" >0.046667</td>\n",
       "      <td id=\"T_755ce_row5_col4\" class=\"data row5 col4\" >0.030957</td>\n",
       "      <td id=\"T_755ce_row5_col5\" class=\"data row5 col5\" >-0.020499</td>\n",
       "      <td id=\"T_755ce_row5_col6\" class=\"data row5 col6\" >-0.084929</td>\n",
       "      <td id=\"T_755ce_row5_col7\" class=\"data row5 col7\" >-0.112278</td>\n",
       "      <td id=\"T_755ce_row5_col8\" class=\"data row5 col8\" >0.0%</td>\n",
       "      <td id=\"T_755ce_row5_col9\" class=\"data row5 col9\" >$111,506,538</td>\n",
       "      <td id=\"T_755ce_row5_col10\" class=\"data row5 col10\" >0.000000</td>\n",
       "      <td id=\"T_755ce_row5_col11\" class=\"data row5 col11\" >$111,430,348</td>\n",
       "      <td id=\"T_755ce_row5_col12\" class=\"data row5 col12\" >True</td>\n",
       "      <td id=\"T_755ce_row5_col13\" class=\"data row5 col13\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_755ce_level0_row6\" class=\"row_heading level0 row6\" >BN</th>\n",
       "      <td id=\"T_755ce_row6_col0\" class=\"data row6 col0\" >0.665800</td>\n",
       "      <td id=\"T_755ce_row6_col1\" class=\"data row6 col1\" >0.981159</td>\n",
       "      <td id=\"T_755ce_row6_col2\" class=\"data row6 col2\" >0.022251</td>\n",
       "      <td id=\"T_755ce_row6_col3\" class=\"data row6 col3\" >0.010220</td>\n",
       "      <td id=\"T_755ce_row6_col4\" class=\"data row6 col4\" >0.023489</td>\n",
       "      <td id=\"T_755ce_row6_col5\" class=\"data row6 col5\" >-0.018669</td>\n",
       "      <td id=\"T_755ce_row6_col6\" class=\"data row6 col6\" >-0.018379</td>\n",
       "      <td id=\"T_755ce_row6_col7\" class=\"data row6 col7\" >0.045792</td>\n",
       "      <td id=\"T_755ce_row6_col8\" class=\"data row6 col8\" >0.0%</td>\n",
       "      <td id=\"T_755ce_row6_col9\" class=\"data row6 col9\" >$111,354,159</td>\n",
       "      <td id=\"T_755ce_row6_col10\" class=\"data row6 col10\" >0.000000</td>\n",
       "      <td id=\"T_755ce_row6_col11\" class=\"data row6 col11\" >$111,430,348</td>\n",
       "      <td id=\"T_755ce_row6_col12\" class=\"data row6 col12\" >False</td>\n",
       "      <td id=\"T_755ce_row6_col13\" class=\"data row6 col13\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_755ce_level0_row7\" class=\"row_heading level0 row7\" >ESS</th>\n",
       "      <td id=\"T_755ce_row7_col0\" class=\"data row7 col0\" >5.862000</td>\n",
       "      <td id=\"T_755ce_row7_col1\" class=\"data row7 col1\" >6.316036</td>\n",
       "      <td id=\"T_755ce_row7_col2\" class=\"data row7 col2\" >0.024650</td>\n",
       "      <td id=\"T_755ce_row7_col3\" class=\"data row7 col3\" >0.018661</td>\n",
       "      <td id=\"T_755ce_row7_col4\" class=\"data row7 col4\" >0.016261</td>\n",
       "      <td id=\"T_755ce_row7_col5\" class=\"data row7 col5\" >0.016540</td>\n",
       "      <td id=\"T_755ce_row7_col6\" class=\"data row7 col6\" >-0.036244</td>\n",
       "      <td id=\"T_755ce_row7_col7\" class=\"data row7 col7\" >-0.077383</td>\n",
       "      <td id=\"T_755ce_row7_col8\" class=\"data row7 col8\" >0.0%</td>\n",
       "      <td id=\"T_755ce_row7_col9\" class=\"data row7 col9\" >$111,199,576</td>\n",
       "      <td id=\"T_755ce_row7_col10\" class=\"data row7 col10\" >0.000000</td>\n",
       "      <td id=\"T_755ce_row7_col11\" class=\"data row7 col11\" >$111,430,348</td>\n",
       "      <td id=\"T_755ce_row7_col12\" class=\"data row7 col12\" >False</td>\n",
       "      <td id=\"T_755ce_row7_col13\" class=\"data row7 col13\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_755ce_level0_row8\" class=\"row_heading level0 row8\" >HEI</th>\n",
       "      <td id=\"T_755ce_row8_col0\" class=\"data row8 col0\" >10.890000</td>\n",
       "      <td id=\"T_755ce_row8_col1\" class=\"data row8 col1\" >8.083050</td>\n",
       "      <td id=\"T_755ce_row8_col2\" class=\"data row8 col2\" >0.025830</td>\n",
       "      <td id=\"T_755ce_row8_col3\" class=\"data row8 col3\" >-0.009935</td>\n",
       "      <td id=\"T_755ce_row8_col4\" class=\"data row8 col4\" >-0.001468</td>\n",
       "      <td id=\"T_755ce_row8_col5\" class=\"data row8 col5\" >-0.011405</td>\n",
       "      <td id=\"T_755ce_row8_col6\" class=\"data row8 col6\" >-0.037849</td>\n",
       "      <td id=\"T_755ce_row8_col7\" class=\"data row8 col7\" >-0.016407</td>\n",
       "      <td id=\"T_755ce_row8_col8\" class=\"data row8 col8\" >0.0%</td>\n",
       "      <td id=\"T_755ce_row8_col9\" class=\"data row8 col9\" >$110,696,672</td>\n",
       "      <td id=\"T_755ce_row8_col10\" class=\"data row8 col10\" >0.000000</td>\n",
       "      <td id=\"T_755ce_row8_col11\" class=\"data row8 col11\" >$111,430,348</td>\n",
       "      <td id=\"T_755ce_row8_col12\" class=\"data row8 col12\" >False</td>\n",
       "      <td id=\"T_755ce_row8_col13\" class=\"data row8 col13\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_755ce_level0_row9\" class=\"row_heading level0 row9\" >EQR</th>\n",
       "      <td id=\"T_755ce_row9_col0\" class=\"data row9 col0\" >1.365300</td>\n",
       "      <td id=\"T_755ce_row9_col1\" class=\"data row9 col1\" >1.267539</td>\n",
       "      <td id=\"T_755ce_row9_col2\" class=\"data row9 col2\" >0.020021</td>\n",
       "      <td id=\"T_755ce_row9_col3\" class=\"data row9 col3\" >0.020573</td>\n",
       "      <td id=\"T_755ce_row9_col4\" class=\"data row9 col4\" >0.012500</td>\n",
       "      <td id=\"T_755ce_row9_col5\" class=\"data row9 col5\" >0.009306</td>\n",
       "      <td id=\"T_755ce_row9_col6\" class=\"data row9 col6\" >-0.020062</td>\n",
       "      <td id=\"T_755ce_row9_col7\" class=\"data row9 col7\" >-0.032361</td>\n",
       "      <td id=\"T_755ce_row9_col8\" class=\"data row9 col8\" >0.0%</td>\n",
       "      <td id=\"T_755ce_row9_col9\" class=\"data row9 col9\" >$110,509,146</td>\n",
       "      <td id=\"T_755ce_row9_col10\" class=\"data row9 col10\" >0.000000</td>\n",
       "      <td id=\"T_755ce_row9_col11\" class=\"data row9 col11\" >$111,430,348</td>\n",
       "      <td id=\"T_755ce_row9_col12\" class=\"data row9 col12\" >False</td>\n",
       "      <td id=\"T_755ce_row9_col13\" class=\"data row9 col13\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_755ce_level0_row10\" class=\"row_heading level0 row10\" >EVR</th>\n",
       "      <td id=\"T_755ce_row10_col0\" class=\"data row10 col0\" >7.571000</td>\n",
       "      <td id=\"T_755ce_row10_col1\" class=\"data row10 col1\" >8.138151</td>\n",
       "      <td id=\"T_755ce_row10_col2\" class=\"data row10 col2\" >0.025982</td>\n",
       "      <td id=\"T_755ce_row10_col3\" class=\"data row10 col3\" >0.022705</td>\n",
       "      <td id=\"T_755ce_row10_col4\" class=\"data row10 col4\" >0.064721</td>\n",
       "      <td id=\"T_755ce_row10_col5\" class=\"data row10 col5\" >0.050583</td>\n",
       "      <td id=\"T_755ce_row10_col6\" class=\"data row10 col6\" >0.014892</td>\n",
       "      <td id=\"T_755ce_row10_col7\" class=\"data row10 col7\" >0.097110</td>\n",
       "      <td id=\"T_755ce_row10_col8\" class=\"data row10 col8\" >0.0%</td>\n",
       "      <td id=\"T_755ce_row10_col9\" class=\"data row10 col9\" >$109,897,218</td>\n",
       "      <td id=\"T_755ce_row10_col10\" class=\"data row10 col10\" >0.000000</td>\n",
       "      <td id=\"T_755ce_row10_col11\" class=\"data row10 col11\" >$111,430,348</td>\n",
       "      <td id=\"T_755ce_row10_col12\" class=\"data row10 col12\" >False</td>\n",
       "      <td id=\"T_755ce_row10_col13\" class=\"data row10 col13\" >False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ea0f01cb50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Access the data inside the container list\n",
    "current_debug_data = debug_container[0]\n",
    "\n",
    "# 2. Check if the audit data exists (it is created only in 'Ranking' mode)\n",
    "if current_debug_data and 'audit_liquidity' in current_debug_data:\n",
    "    audit = current_debug_data['audit_liquidity']\n",
    "    snapshot_df = audit['universe_snapshot']\n",
    "    \n",
    "    print(f\"üìÖ Date: {audit['date'].date()}\")\n",
    "    print(f\"üí∞ Calculated Cutoff: ${audit['final_cutoff_usd']:,.0f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# 3. View the tickers right around the cutoff point\n",
    "# Find the index where 'Passed_Vol_Check' switches from True to False\n",
    "    try:\n",
    "        # Get the integer location (iloc) of the last True value\n",
    "        last_pass_iloc = np.where(snapshot_df['Passed_Vol_Check'])[0][-1]\n",
    "        \n",
    "        # Show 5 rows before and 5 rows after the cutoff\n",
    "        start = max(0, last_pass_iloc - 5)\n",
    "        end = min(len(snapshot_df), last_pass_iloc + 6)\n",
    "        \n",
    "        display(snapshot_df.iloc[start:end].style.format({\n",
    "            'RollMedDollarVol': '${:,.0f}',\n",
    "            'Calculated_Cutoff': '${:,.0f}',\n",
    "            'RollingStalePct': '{:.1%}'\n",
    "        }))\n",
    "    except IndexError:\n",
    "        print(\"Could not determine cutoff boundary (maybe all passed or all failed).\")\n",
    "        display(snapshot_df.head())\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No audit data found. Make sure you are in 'Ranking' mode and have clicked 'Update Chart'.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32da9680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Snapshot exported to: ./export_csv/snapshot_df.csv\n",
      "   Shape: (1619, 14)\n",
      "   Columns: ['TR', 'ATR', 'ATRP', 'ROC_1', 'ROC_3', 'ROC_5', 'ROC_10', 'ROC_21', 'RollingStalePct', 'RollMedDollarVol', 'RollingSameVolCount', 'Calculated_Cutoff', 'Passed_Vol_Check', 'Passed_Final']\n"
     ]
    }
   ],
   "source": [
    "snapshot_df.to_csv('./export_csv/snapshot_df.csv')\n",
    "print(f\"‚úÖ Snapshot exported to: ./export_csv/snapshot_df.csv\")\n",
    "print(f\"   Shape: {snapshot_df.shape}\")\n",
    "print(f\"   Columns: {list(snapshot_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1e0c43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TR</th>\n",
       "      <th>ATR</th>\n",
       "      <th>ATRP</th>\n",
       "      <th>ROC_1</th>\n",
       "      <th>ROC_3</th>\n",
       "      <th>ROC_5</th>\n",
       "      <th>ROC_10</th>\n",
       "      <th>ROC_21</th>\n",
       "      <th>RollingStalePct</th>\n",
       "      <th>RollMedDollarVol</th>\n",
       "      <th>RollingSameVolCount</th>\n",
       "      <th>Calculated_Cutoff</th>\n",
       "      <th>Passed_Vol_Check</th>\n",
       "      <th>Passed_Final</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>5.344</td>\n",
       "      <td>5.271</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.1174</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0290e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1143e+08</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TR    ATR    ATRP  ROC_1   ROC_3   ROC_5  ROC_10  ROC_21  RollingStalePct  RollMedDollarVol  RollingSameVolCount  Calculated_Cutoff  Passed_Vol_Check  Passed_Final\n",
       "Ticker                                                                                                                                                                        \n",
       "AAPL    5.344  5.271  0.0226  0.016  0.0185  0.0954  0.1174  0.1171              0.0        1.0290e+10                  0.0         1.1143e+08              True          True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming you have run the variables setup from the previous step\n",
    "snapshot_df = debug_container[0]['audit_liquidity']['universe_snapshot']\n",
    "\n",
    "if 'AAPL' in snapshot_df.index:\n",
    "    display(snapshot_df.loc[['AAPL']])\n",
    "else:\n",
    "    print(\"AAPL was not present in the data for this date.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d210b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "================================  \n",
    "================================  \n",
    "================================  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96683b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohlcv.loc['SPY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd30b84c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd55374",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dict['JPST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a082cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e7267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tickers = ['SPY', 'AAPL', 'IWM', 'QQQ', 'META', 'EEM', 'BABA']\n",
    "my_tickers = ['NTES', 'LII',]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b6b19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(snapshot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32e1b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your data is loaded in 'df_ohlcv'\n",
    "print(\"--- üöÄ LAUNCHING APP ---\")\n",
    "\n",
    "# 1. We clear any old features so it calculates the new ROC columns\n",
    "# 2. We pass 'debug=True' so we can see the audit logs in the console\n",
    "results, debug_data = plot_walk_forward_analyzer(\n",
    "    df_ohlcv, \n",
    "    precomputed_features=None, # Force recalculation of new features\n",
    "    default_strategy='Pullback 5D', # Try one of your new strategies!\n",
    "    debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05cafb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
