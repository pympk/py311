{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9ae2708",
   "metadata": {},
   "source": [
    "# Here is the refactored solution. I have separated the concerns into three distinct layers:\n",
    "1.  **The Data Contract:** explicit `dataclasses` defining exactly what goes in and comes out.\n",
    "2.  **The Engine:** A purely mathematical class (`AlphaEngine`) containing the logic, with no widget/plotting dependencies.\n",
    "3.  **The UI:** A cleaned-up dashboard function that simply sends inputs to the Engine and visualizes the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e51aab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import plotly.graph_objects as go\n",
    "# import ipywidgets as widgets\n",
    "# import time\n",
    "# import pprint\n",
    "# import os # Make sure os is imported for the export function later\n",
    "# import re\n",
    "\n",
    "# from datetime import datetime, date\n",
    "# from IPython.display import display, Markdown\n",
    "# from tqdm.auto import tqdm\n",
    "# from pathlib import Path\n",
    "# from itertools import product\n",
    "# from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72ba6cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import plotly.graph_objects as go\n",
    "# import ipywidgets as widgets\n",
    "# from dataclasses import dataclass, field\n",
    "# from typing import List, Dict, Optional, Any\n",
    "# from collections import Counter\n",
    "# import pprint\n",
    "\n",
    "# # --- 1. DATA CONTRACTS (The \"Language\" your Bot speaks) ---\n",
    "\n",
    "# @dataclass\n",
    "# class EngineInput:\n",
    "#     \"\"\"Standardized input for the calculation engine.\"\"\"\n",
    "#     mode: str                         # 'Ranking' or 'Manual List'\n",
    "#     start_date: pd.Timestamp\n",
    "#     calc_period: int\n",
    "#     fwd_period: int\n",
    "#     metric: str\n",
    "#     benchmark_ticker: str\n",
    "    \n",
    "#     # Ranking Mode Parameters\n",
    "#     rank_start: int = 1\n",
    "#     rank_end: int = 10\n",
    "#     quality_thresholds: Dict[str, float] = field(default_factory=lambda: {\n",
    "#         'min_median_dollar_volume': 1_000_000, \n",
    "#         'max_stale_pct': 0.05, \n",
    "#         'max_same_vol_count': 10\n",
    "#     })\n",
    "    \n",
    "#     # Manual Mode Parameters\n",
    "#     manual_tickers: List[str] = field(default_factory=list)\n",
    "\n",
    "# @dataclass\n",
    "# class EngineOutput:\n",
    "#     \"\"\"Standardized output returned by the engine.\"\"\"\n",
    "#     # Time Series\n",
    "#     portfolio_series: pd.Series\n",
    "#     benchmark_series: pd.Series\n",
    "#     normalized_plot_data: pd.DataFrame\n",
    "    \n",
    "#     # Metadata\n",
    "#     tickers: List[str]\n",
    "#     initial_weights: pd.Series\n",
    "    \n",
    "#     # Scalar Metrics (for the table)\n",
    "#     perf_metrics: Dict[str, float]\n",
    "    \n",
    "#     # DataTables\n",
    "#     results_df: pd.DataFrame  # The ranking or portfolio table\n",
    "    \n",
    "#     # Execution Details\n",
    "#     calc_end_date: pd.Timestamp\n",
    "#     viz_end_date: pd.Timestamp\n",
    "#     error_msg: Optional[str] = None\n",
    "\n",
    "\n",
    "# # --- 2. THE ALPHA ENGINE (The \"Brain\" - Logic Only) ---\n",
    "\n",
    "# class AlphaEngine:\n",
    "#     def __init__(self, df_ohlcv: pd.DataFrame, master_ticker: str = 'SPY'):\n",
    "#         print(\"--- ⚙️ Initializing AlphaEngine ---\")\n",
    "        \n",
    "#         # 1. Pre-calculate Features ONCE upon initialization\n",
    "#         # (Uses your existing generate_features function)\n",
    "#         self.features_df = generate_features(df_ohlcv)\n",
    "        \n",
    "#         # 2. Unstack data for fast vectorized access\n",
    "#         print(\"Optimizing data structures...\")\n",
    "#         self.df_close = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "#         self.df_high = df_ohlcv['Adj High'].unstack(level=0)\n",
    "#         self.df_low = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "        \n",
    "#         # 3. Setup Trading Calendar\n",
    "#         if master_ticker not in self.df_close.columns:\n",
    "#             # Fallback to first column if master missing\n",
    "#             master_ticker = self.df_close.columns[0]\n",
    "#             print(f\"Warning: Master ticker not found. Using {master_ticker}\")\n",
    "            \n",
    "#         self.trading_calendar = self.df_close[master_ticker].dropna().index.unique().sort_values()\n",
    "#         print(\"✅ AlphaEngine Ready.\")\n",
    "\n",
    "#     def run(self, inputs: EngineInput) -> EngineOutput:\n",
    "#         \"\"\"\n",
    "#         The main entry point. \n",
    "#         Input: Configuration (EngineInput)\n",
    "#         Output: Results (EngineOutput)\n",
    "#         \"\"\"\n",
    "#         # --- A. Validate Dates ---\n",
    "#         try:\n",
    "#             start_idx = self.trading_calendar.searchsorted(inputs.start_date)\n",
    "#             # Handle case where date is before start of history\n",
    "#             if start_idx < 0: start_idx = 0\n",
    "#         except Exception:\n",
    "#             return self._error_result(\"Invalid Start Date\")\n",
    "\n",
    "#         desired_end_idx = start_idx + inputs.calc_period + inputs.fwd_period\n",
    "        \n",
    "#         if desired_end_idx >= len(self.trading_calendar):\n",
    "#             max_date = self.trading_calendar[-1].date()\n",
    "#             return self._error_result(f\"Date range exceeds history. Max available date: {max_date}\")\n",
    "\n",
    "#         # Define exact date points\n",
    "#         safe_start_date = self.trading_calendar[start_idx]\n",
    "#         safe_calc_end_date = self.trading_calendar[start_idx + inputs.calc_period]\n",
    "#         safe_viz_end_date = self.trading_calendar[start_idx + inputs.calc_period + inputs.fwd_period]\n",
    "\n",
    "#         # --- B. Select Tickers (Ranking vs Manual) ---\n",
    "#         tickers_to_trade = []\n",
    "#         results_table = pd.DataFrame()\n",
    "        \n",
    "#         if inputs.mode == 'Manual List':\n",
    "#             # Filter for valid tickers only\n",
    "#             valid = [t for t in inputs.manual_tickers if t in self.df_close.columns]\n",
    "#             if not valid:\n",
    "#                 return self._error_result(\"No valid tickers found in manual list.\")\n",
    "#             tickers_to_trade = valid\n",
    "#             results_table = pd.DataFrame(index=valid) # Empty table for now\n",
    "            \n",
    "#         else: # Ranking Mode\n",
    "#             # 1. Dynamic Universe Filter\n",
    "#             eligible_tickers = self._get_eligible_universe(safe_start_date, inputs.quality_thresholds)\n",
    "#             if not eligible_tickers:\n",
    "#                 return self._error_result(\"No tickers passed quality filters.\")\n",
    "            \n",
    "#             # 2. Metric Calculation\n",
    "#             # Slice data for the Calculation Period\n",
    "#             calc_close = self.df_close.loc[safe_start_date:safe_calc_end_date, eligible_tickers]\n",
    "            \n",
    "#             # Prepare Ingredients for Metric Registry\n",
    "#             # Note: We reconstruct the MultiIndex for feature lookup\n",
    "#             idx_product = pd.MultiIndex.from_product([eligible_tickers, calc_close.index], names=['Ticker', 'Date'])\n",
    "#             # Fast intersection to get features\n",
    "#             feat_slice = self.features_df.reindex(idx_product).dropna(how='all')\n",
    "            \n",
    "#             # Helper for ATRP\n",
    "#             atrp_mean = feat_slice.groupby(level='Ticker')['ATRP'].mean()\n",
    "#             daily_returns = calc_close.pct_change()\n",
    "\n",
    "#             metric_ingredients = {\n",
    "#                 'calc_close': calc_close,\n",
    "#                 'daily_returns': daily_returns,\n",
    "#                 'atrp': atrp_mean\n",
    "#             }\n",
    "            \n",
    "#             # Calculate Rank\n",
    "#             if inputs.metric not in METRIC_REGISTRY:\n",
    "#                 return self._error_result(f\"Metric '{inputs.metric}' not found.\")\n",
    "                \n",
    "#             metric_vals = METRIC_REGISTRY[inputs.metric](metric_ingredients)\n",
    "#             sorted_tickers = metric_vals.sort_values(ascending=False)\n",
    "            \n",
    "#             # Select Top N\n",
    "#             # Adjust 1-based index to 0-based\n",
    "#             start_r = max(0, inputs.rank_start - 1)\n",
    "#             end_r = inputs.rank_end\n",
    "#             tickers_to_trade = sorted_tickers.iloc[start_r:end_r].index.tolist()\n",
    "            \n",
    "#             if not tickers_to_trade:\n",
    "#                 return self._error_result(\"No tickers generated from ranking.\")\n",
    "\n",
    "#             results_table = pd.DataFrame({\n",
    "#                 'Rank': range(inputs.rank_start, inputs.rank_start + len(tickers_to_trade)),\n",
    "#                 'Ticker': tickers_to_trade,\n",
    "#                 'Metric Value': sorted_tickers.loc[tickers_to_trade].values\n",
    "#             }).set_index('Ticker')\n",
    "\n",
    "#         # --- C. Calculate Portfolio Performance ---\n",
    "#         # (Uses the existing helper function)\n",
    "#         p_val, p_ret, p_atrp = calculate_buy_and_hold_performance(\n",
    "#             self.df_close, self.features_df, tickers_to_trade, \n",
    "#             safe_start_date, safe_viz_end_date\n",
    "#         )\n",
    "        \n",
    "#         # --- D. Calculate Benchmark Performance ---\n",
    "#         b_val, b_ret, b_atrp = calculate_buy_and_hold_performance(\n",
    "#             self.df_close, self.features_df, [inputs.benchmark_ticker], \n",
    "#             safe_start_date, safe_viz_end_date\n",
    "#         )\n",
    "\n",
    "#         # --- E. Prepare Plot Data (Normalized) ---\n",
    "#         plot_data = self.df_close[list(set(tickers_to_trade))].loc[safe_start_date:safe_viz_end_date]\n",
    "#         if not plot_data.empty:\n",
    "#             plot_data = plot_data / plot_data.bfill().iloc[0]\n",
    "\n",
    "#         # --- F. Compute Final Scalar Metrics ---\n",
    "#         # We perform the slicing here to generate the \"Table\" of numbers\n",
    "#         calc_end_ts = safe_calc_end_date\n",
    "        \n",
    "#         metrics = {}\n",
    "#         # Helper lambda for Sharpe\n",
    "#         get_sharpe = lambda s: (s.mean() / s.std() * np.sqrt(252)) if s.std() > 0 else 0\n",
    "#         get_gain = lambda s: (s.iloc[-1] / s.iloc[0]) - 1 if len(s) > 0 else 0\n",
    "\n",
    "#         # Portfolio Slices\n",
    "#         p_calc = p_ret.loc[:calc_end_ts]\n",
    "#         p_fwd = p_ret.loc[calc_end_ts:].iloc[1:]\n",
    "        \n",
    "#         metrics['calc_p_gain'] = get_gain(p_val.loc[:calc_end_ts])\n",
    "#         metrics['fwd_p_gain'] = get_gain(p_val.loc[calc_end_ts:])\n",
    "#         metrics['full_p_sharpe_atr'] = calculate_sharpe_atr(p_ret, p_atrp) # Using helper\n",
    "        \n",
    "#         # Benchmark Slices\n",
    "#         if not b_ret.empty:\n",
    "#             b_calc = b_ret.loc[:calc_end_ts]\n",
    "#             b_fwd = b_ret.loc[calc_end_ts:].iloc[1:]\n",
    "            \n",
    "#             metrics['calc_b_gain'] = get_gain(b_val.loc[:calc_end_ts])\n",
    "#             metrics['fwd_b_gain'] = get_gain(b_val.loc[calc_end_ts:])\n",
    "#             metrics['full_b_sharpe_atr'] = calculate_sharpe_atr(b_ret, b_atrp)\n",
    "\n",
    "#         # Update results table with forward gains\n",
    "#         if not plot_data.empty:\n",
    "#             step_gains = (plot_data.iloc[-1] / plot_data.loc[calc_end_ts]) - 1\n",
    "#             # Map gains to the table. Handle duplicate tickers in manual mode carefully.\n",
    "#             # For simpler display, we just map by index (Ticker)\n",
    "#             results_table['Fwd Gain'] = step_gains\n",
    "        \n",
    "#         # Determine Initial Weights\n",
    "#         ticker_counts = Counter(tickers_to_trade)\n",
    "#         total_parts = len(tickers_to_trade)\n",
    "#         weights = pd.Series({t: c/total_parts for t, c in ticker_counts.items()})\n",
    "\n",
    "#         return EngineOutput(\n",
    "#             portfolio_series=p_val,\n",
    "#             benchmark_series=b_val,\n",
    "#             normalized_plot_data=plot_data,\n",
    "#             tickers=tickers_to_trade,\n",
    "#             initial_weights=weights,\n",
    "#             perf_metrics=metrics,\n",
    "#             results_df=results_table,\n",
    "#             calc_end_date=safe_calc_end_date,\n",
    "#             viz_end_date=safe_viz_end_date\n",
    "#         )\n",
    "\n",
    "#     def _get_eligible_universe(self, date_ts, thresholds):\n",
    "#         \"\"\"Internal helper to filter universe based on pre-calced features.\"\"\"\n",
    "#         # Find latest available data date <= requested date\n",
    "#         avail_dates = self.features_df.index.get_level_values('Date').unique().sort_values()\n",
    "#         valid_dates = avail_dates[avail_dates <= date_ts]\n",
    "        \n",
    "#         if valid_dates.empty: return []\n",
    "        \n",
    "#         # Get slice\n",
    "#         data_date = valid_dates[-1]\n",
    "#         day_features = self.features_df.xs(data_date, level='Date')\n",
    "        \n",
    "#         # Apply Logic\n",
    "#         mask = (\n",
    "#             (day_features['RollMedDollarVol'] >= thresholds['min_median_dollar_volume']) &\n",
    "#             (day_features['RollingStalePct'] <= thresholds['max_stale_pct']) &\n",
    "#             (day_features['RollingSameVolCount'] <= thresholds['max_same_vol_count'])\n",
    "#         )\n",
    "#         return day_features[mask].index.tolist()\n",
    "\n",
    "#     def _error_result(self, msg):\n",
    "#         return EngineOutput(\n",
    "#             portfolio_series=pd.Series(dtype=float), benchmark_series=pd.Series(dtype=float),\n",
    "#             normalized_plot_data=pd.DataFrame(), tickers=[], initial_weights=pd.Series(dtype=float),\n",
    "#             perf_metrics={}, results_df=pd.DataFrame(),\n",
    "#             calc_end_date=pd.Timestamp.min, viz_end_date=pd.Timestamp.min,\n",
    "#             error_msg=msg\n",
    "#         )\n",
    "\n",
    "\n",
    "# # --- 3. THE UI LAYER (Visuals Only) ---\n",
    "\n",
    "# def plot_walk_forward_analyzer(\n",
    "#     df_ohlcv,\n",
    "#     default_start_date='2020-01-01',\n",
    "#     default_calc_period=126,\n",
    "#     default_fwd_period=63,\n",
    "#     default_metric='Sharpe (ATR)',\n",
    "#     default_rank_start=1,\n",
    "#     default_rank_end=10,\n",
    "#     default_benchmark_ticker='SPY',\n",
    "#     master_calendar_ticker='SPY',\n",
    "#     quality_thresholds=None,\n",
    "#     debug=False\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     The UI wrapper. It accepts the arguments you are used to,\n",
    "#     but delegates ALL logic to the AlphaEngine class.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # 1. Initialize Engine\n",
    "#     # This might take a second as it pre-calculates features\n",
    "#     engine = AlphaEngine(df_ohlcv, master_ticker=master_calendar_ticker)\n",
    "    \n",
    "#     # Defaults\n",
    "#     if quality_thresholds is None:\n",
    "#         quality_thresholds = {\n",
    "#             'min_median_dollar_volume': 1_000_000, \n",
    "#             'max_stale_pct': 0.05, \n",
    "#             'max_same_vol_count': 10\n",
    "#         }\n",
    "\n",
    "#     # 2. Widgets\n",
    "#     w_start_date = widgets.DatePicker(description='Start Date', value=pd.to_datetime(default_start_date))\n",
    "#     w_calc = widgets.IntText(value=default_calc_period, description='Calc Days')\n",
    "#     w_fwd = widgets.IntText(value=default_fwd_period, description='Fwd Days')\n",
    "    \n",
    "#     w_metric = widgets.Dropdown(options=list(METRIC_REGISTRY.keys()), value=default_metric, description='Metric')\n",
    "#     w_rank_start = widgets.IntText(value=default_rank_start, description='Rank Start')\n",
    "#     w_rank_end = widgets.IntText(value=default_rank_end, description='Rank End')\n",
    "    \n",
    "#     w_bench = widgets.Text(value=default_benchmark_ticker, description='Benchmark')\n",
    "#     w_mode = widgets.RadioButtons(options=['Ranking', 'Manual List'], value='Ranking', description='Mode')\n",
    "#     w_manual = widgets.Textarea(placeholder='AAPL, MSFT...', description='Manual List')\n",
    "    \n",
    "#     btn_update = widgets.Button(description=\"RUN ANALYSIS\", button_style='success', icon='play')\n",
    "#     out_log = widgets.Output()\n",
    "    \n",
    "#     # 3. Plotly Figure\n",
    "#     fig = go.FigureWidget()\n",
    "#     fig.update_layout(height=600, title=\"Walk-Forward Analysis (Engine Powered)\", template=\"plotly_white\", hovermode=\"x unified\")\n",
    "    \n",
    "#     # 4. Event Handler (The Glue)\n",
    "#     def on_click(b):\n",
    "#         out_log.clear_output()\n",
    "        \n",
    "#         # A. Build Input Object\n",
    "#         manual_list = [t.strip().upper() for t in w_manual.value.split(',') if t.strip()]\n",
    "        \n",
    "#         inputs = EngineInput(\n",
    "#             mode=w_mode.value,\n",
    "#             start_date=pd.to_datetime(w_start_date.value),\n",
    "#             calc_period=w_calc.value,\n",
    "#             fwd_period=w_fwd.value,\n",
    "#             metric=w_metric.value,\n",
    "#             benchmark_ticker=w_bench.value.strip().upper(),\n",
    "#             rank_start=w_rank_start.value,\n",
    "#             rank_end=w_rank_end.value,\n",
    "#             quality_thresholds=quality_thresholds,\n",
    "#             manual_tickers=manual_list\n",
    "#         )\n",
    "        \n",
    "#         with out_log:\n",
    "#             print(\"⏳ Running AlphaEngine...\")\n",
    "            \n",
    "#             # B. Call Engine\n",
    "#             res = engine.run(inputs)\n",
    "            \n",
    "#             if res.error_msg:\n",
    "#                 print(f\"❌ ERROR: {res.error_msg}\")\n",
    "#                 return\n",
    "            \n",
    "#             # C. Update Plot\n",
    "#             with fig.batch_update():\n",
    "#                 fig.data = []\n",
    "#                 # Plot Components\n",
    "#                 for col in res.normalized_plot_data.columns:\n",
    "#                     fig.add_trace(go.Scatter(\n",
    "#                         x=res.normalized_plot_data.index, \n",
    "#                         y=res.normalized_plot_data[col],\n",
    "#                         mode='lines', name=col, opacity=0.15, showlegend=False\n",
    "#                     ))\n",
    "                \n",
    "#                 # Plot Benchmark\n",
    "#                 if not res.benchmark_series.empty:\n",
    "#                     fig.add_trace(go.Scatter(\n",
    "#                         x=res.benchmark_series.index, y=res.benchmark_series.values,\n",
    "#                         mode='lines', name=f\"Benchmark ({inputs.benchmark_ticker})\",\n",
    "#                         line=dict(color='black', width=2, dash='dash')\n",
    "#                     ))\n",
    "                    \n",
    "#                 # Plot Portfolio\n",
    "#                 fig.add_trace(go.Scatter(\n",
    "#                     x=res.portfolio_series.index, y=res.portfolio_series.values,\n",
    "#                     mode='lines', name=\"Alpha Portfolio\",\n",
    "#                     line=dict(color='green', width=3)\n",
    "#                 ))\n",
    "                \n",
    "#                 # Markers\n",
    "#                 fig.layout.shapes = []\n",
    "#                 fig.add_vline(x=res.calc_end_date.timestamp() * 1000, line_dash=\"dot\", annotation_text=\"End Calc\")\n",
    "            \n",
    "#             # D. Text Report\n",
    "#             print(f\"✅ Success. Period: {inputs.start_date.date()} -> {res.viz_end_date.date()}\")\n",
    "            \n",
    "#             # Performance Table\n",
    "#             m = res.perf_metrics\n",
    "            \n",
    "#             # Safe subtraction for delta\n",
    "#             fwd_delta = m.get('fwd_p_gain', 0) - m.get('fwd_b_gain', 0) if 'fwd_b_gain' in m else np.nan\n",
    "            \n",
    "#             row_data = [\n",
    "#                 {'Metric': 'Calculated Gain', 'Portfolio': m.get('calc_p_gain'), 'Benchmark': m.get('calc_b_gain')},\n",
    "#                 {'Metric': 'Forward Gain', 'Portfolio': m.get('fwd_p_gain'), 'Benchmark': m.get('fwd_b_gain')},\n",
    "#                 {'Metric': 'Sharpe (ATR)', 'Portfolio': m.get('full_p_sharpe_atr'), 'Benchmark': m.get('full_b_sharpe_atr')},\n",
    "#             ]\n",
    "#             perf_df = pd.DataFrame(row_data).set_index('Metric')\n",
    "            \n",
    "#             print(f\"\\n--- Forward Delta (Alpha): {fwd_delta:+.2%} ---\")\n",
    "#             display(perf_df.style.format(\"{:+.2%}\", na_rep=\"N/A\"))\n",
    "            \n",
    "#             print(\"\\n--- Portfolio Composition ---\")\n",
    "#             if 'Fwd Gain' in res.results_df.columns:\n",
    "#                 display(res.results_df.style.format({'Fwd Gain': '{:+.2%}', 'Metric Value': '{:.4f}'}))\n",
    "#             else:\n",
    "#                 display(res.results_df)\n",
    "\n",
    "#     btn_update.on_click(on_click)\n",
    "    \n",
    "#     # 5. Layout\n",
    "#     # Organize widgets for clean look\n",
    "#     c1 = widgets.VBox([w_mode, w_start_date])\n",
    "#     c2 = widgets.VBox([w_calc, w_fwd])\n",
    "#     c3 = widgets.VBox([w_metric, w_rank_start, w_rank_end])\n",
    "#     c4 = widgets.VBox([w_manual])\n",
    "#     row_top = widgets.HBox([c1, c2, c3])\n",
    "#     row_bot = widgets.HBox([w_bench, btn_update])\n",
    "    \n",
    "#     ui = widgets.VBox([row_top, c4, row_bot, out_log])\n",
    "    \n",
    "#     # Trigger first run automatically to match previous behavior\n",
    "#     on_click(None)\n",
    "    \n",
    "#     display(ui, fig)\n",
    "#     return (None, None) # Keeping return signature compatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f3c9704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Optional, Any\n",
    "from collections import Counter\n",
    "import pprint\n",
    "from datetime import datetime, date\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION A: CORE HELPER FUNCTIONS & FEATURE GENERATION\n",
    "# (These provide the raw math and data transformations)\n",
    "# ==============================================================================\n",
    "\n",
    "def generate_features(df_ohlcv: pd.DataFrame, \n",
    "                      atr_period: int = 14, \n",
    "                      quality_window: int = 252, \n",
    "                      quality_min_periods: int = 126) -> pd.DataFrame:\n",
    "    \"\"\"Generates TR, ATR, ATRP, and Quality Metrics.\"\"\"\n",
    "    print(\"--- 1. Generating Features ---\")\n",
    "    if not df_ohlcv.index.is_monotonic_increasing:\n",
    "        df_ohlcv = df_ohlcv.sort_index()\n",
    "\n",
    "    # 1. Technical Indicators\n",
    "    grouped = df_ohlcv.groupby(level='Ticker')\n",
    "    prev_close = grouped['Adj Close'].shift(1)\n",
    "    \n",
    "    high_low = df_ohlcv['Adj High'] - df_ohlcv['Adj Low']\n",
    "    high_prev_close = abs(df_ohlcv['Adj High'] - prev_close)\n",
    "    low_prev_close = abs(df_ohlcv['Adj Low'] - prev_close)\n",
    "    \n",
    "    tr = pd.concat([high_low, high_prev_close, low_prev_close], axis=1).max(axis=1, skipna=False)\n",
    "    \n",
    "    # Calculate ATR using transform to keep index alignment\n",
    "    atr = tr.groupby(level='Ticker').transform(\n",
    "        lambda x: x.ewm(alpha=1/atr_period, adjust=False).mean()\n",
    "    )\n",
    "    atrp = (atr / df_ohlcv['Adj Close']).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    indicator_df = pd.DataFrame({'TR': tr, 'ATR': atr, 'ATRP': atrp})\n",
    "    \n",
    "    # 2. Quality Metrics\n",
    "    is_stale = np.where((df_ohlcv['Volume'] == 0) | (df_ohlcv['Adj High'] == df_ohlcv['Adj Low']), 1, 0)\n",
    "    dollar_volume = df_ohlcv['Adj Close'] * df_ohlcv['Volume']\n",
    "    has_same_volume = (grouped['Volume'].diff() == 0).astype(int)\n",
    "    \n",
    "    quality_temp_df = pd.DataFrame({\n",
    "        'IsStale': is_stale,\n",
    "        'DollarVolume': dollar_volume,\n",
    "        'HasSameVolume': has_same_volume\n",
    "    }, index=df_ohlcv.index)\n",
    "    \n",
    "    rolling_result = quality_temp_df.groupby(level='Ticker').rolling(\n",
    "        window=quality_window, min_periods=quality_min_periods\n",
    "    ).agg({\n",
    "        'IsStale': 'mean',\n",
    "        'DollarVolume': 'median',\n",
    "        'HasSameVolume': 'sum'\n",
    "    })\n",
    "    \n",
    "    rolling_result = rolling_result.rename(columns={\n",
    "        'IsStale': 'RollingStalePct',\n",
    "        'DollarVolume': 'RollMedDollarVol',\n",
    "        'HasSameVolume': 'RollingSameVolCount'\n",
    "    }).reset_index(level=0, drop=True)\n",
    "\n",
    "    return pd.concat([indicator_df, rolling_result], axis=1)\n",
    "\n",
    "def calculate_gain(price_series: pd.Series):\n",
    "    \"\"\"Total gain: (End / Start) - 1\"\"\"\n",
    "    if price_series.dropna().shape[0] < 2: return np.nan\n",
    "    return (price_series.ffill().iloc[-1] / price_series.bfill().iloc[0]) - 1\n",
    "\n",
    "def calculate_sharpe(return_series: pd.Series):\n",
    "    \"\"\"Annualized Sharpe Ratio.\"\"\"\n",
    "    if return_series.dropna().shape[0] < 2: return np.nan\n",
    "    std_dev = return_series.std()\n",
    "    if std_dev > 0 and std_dev != np.inf:\n",
    "        return (return_series.mean() / std_dev) * np.sqrt(252)\n",
    "    return 0.0\n",
    "\n",
    "def calculate_sharpe_atr(return_series: pd.Series, atrp_series: pd.Series):\n",
    "    \"\"\"Sharpe (ATR): Mean Return / Mean ATRP.\"\"\"\n",
    "    if return_series.dropna().shape[0] < 2 or atrp_series.dropna().empty: return np.nan\n",
    "    mean_return = return_series.mean()\n",
    "    mean_atrp = atrp_series.mean()\n",
    "    if mean_atrp > 0 and mean_atrp != np.inf:\n",
    "        return mean_return / mean_atrp\n",
    "    return 0.0\n",
    "\n",
    "def calculate_buy_and_hold_performance(df_close: pd.DataFrame,\n",
    "                                       features_df: pd.DataFrame,\n",
    "                                       tickers: list,\n",
    "                                       start_date: pd.Timestamp,\n",
    "                                       end_date: pd.Timestamp):\n",
    "    \"\"\"Calculates Portfolio Value, Returns, and Value-Weighted ATRP.\"\"\"\n",
    "    if not tickers:\n",
    "        return pd.Series(dtype=float), pd.Series(dtype=float), pd.Series(dtype=float)\n",
    "\n",
    "    # Handle duplicate tickers (Initial Weighting)\n",
    "    ticker_counts = Counter(tickers)\n",
    "    total_parts = len(tickers)\n",
    "    initial_weights = pd.Series({t: c / total_parts for t, c in ticker_counts.items()})\n",
    "    unique_tickers = initial_weights.index.tolist()\n",
    "\n",
    "    # Get Prices\n",
    "    prices_raw = df_close[unique_tickers].loc[start_date:end_date]\n",
    "    if prices_raw.dropna(how='all').empty:\n",
    "        return pd.Series(dtype=float), pd.Series(dtype=float), pd.Series(dtype=float)\n",
    "\n",
    "    # Normalize to $1 start\n",
    "    prices_norm = prices_raw.div(prices_raw.bfill().iloc[0])\n",
    "    \n",
    "    # Apply Weights\n",
    "    weighted_growth = prices_norm.mul(initial_weights, axis='columns')\n",
    "    value_series = weighted_growth.sum(axis=1)\n",
    "    return_series = value_series.pct_change()\n",
    "\n",
    "    # Calculate Portfolio ATRP (Value Weighted)\n",
    "    full_idx = pd.MultiIndex.from_product([unique_tickers, return_series.index], names=['Ticker', 'Date'])\n",
    "    # Reindex features to match this specific period/ticker set\n",
    "    feat_subset = features_df.reindex(full_idx)['ATRP'].unstack(level='Ticker')\n",
    "    \n",
    "    # Current weight = Current Value / Total Portfolio Value\n",
    "    drifting_weights = weighted_growth.div(value_series, axis='index')\n",
    "    \n",
    "    # Align and multiply\n",
    "    aligned_w, aligned_atrp = drifting_weights.align(feat_subset, join='inner', axis=1)\n",
    "    atrp_series = (aligned_w * aligned_atrp).sum(axis=1)\n",
    "\n",
    "    return value_series, return_series, atrp_series\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION B: METRIC REGISTRY\n",
    "# (The Logic for Ranking Tickers)\n",
    "# ==============================================================================\n",
    "\n",
    "def metric_price(d): return calculate_gain(d['calc_close'])\n",
    "def metric_sharpe(d): \n",
    "    r = d['daily_returns']\n",
    "    return (r.mean() / r.std() * np.sqrt(252)).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "def metric_sharpe_atr(d):\n",
    "    return (d['daily_returns'].mean() / d['atrp']).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "METRIC_REGISTRY = {\n",
    "    'Price': metric_price,\n",
    "    'Sharpe': metric_sharpe,\n",
    "    'Sharpe (ATR)': metric_sharpe_atr,\n",
    "}\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION C: DATA CONTRACTS (The API)\n",
    "# ==============================================================================\n",
    "\n",
    "@dataclass\n",
    "class EngineInput:\n",
    "    \"\"\"Standardized input for the calculation engine.\"\"\"\n",
    "    mode: str                         # 'Ranking' or 'Manual List'\n",
    "    start_date: pd.Timestamp\n",
    "    calc_period: int\n",
    "    fwd_period: int\n",
    "    metric: str\n",
    "    benchmark_ticker: str\n",
    "    \n",
    "    # Ranking Mode Parameters\n",
    "    rank_start: int = 1\n",
    "    rank_end: int = 10\n",
    "    quality_thresholds: Dict[str, float] = field(default_factory=lambda: {\n",
    "        'min_median_dollar_volume': 1_000_000, 'max_stale_pct': 0.05, 'max_same_vol_count': 10\n",
    "    })\n",
    "    \n",
    "    # Manual Mode Parameters\n",
    "    manual_tickers: List[str] = field(default_factory=list)\n",
    "\n",
    "@dataclass\n",
    "class EngineOutput:\n",
    "    \"\"\"Standardized output returned by the engine.\"\"\"\n",
    "    portfolio_series: pd.Series\n",
    "    benchmark_series: pd.Series\n",
    "    normalized_plot_data: pd.DataFrame\n",
    "    tickers: List[str]\n",
    "    initial_weights: pd.Series\n",
    "    perf_metrics: Dict[str, float]\n",
    "    results_df: pd.DataFrame\n",
    "    calc_end_date: pd.Timestamp\n",
    "    viz_end_date: pd.Timestamp\n",
    "    error_msg: Optional[str] = None\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION D: THE ALPHA ENGINE (The \"Brain\")\n",
    "# ==============================================================================\n",
    "\n",
    "class AlphaEngine:\n",
    "    def __init__(self, df_ohlcv: pd.DataFrame, master_ticker: str = 'SPY'):\n",
    "        print(\"--- ⚙️ Initializing AlphaEngine ---\")\n",
    "        \n",
    "        # 1. Pre-calculate Features\n",
    "        self.features_df = generate_features(df_ohlcv)\n",
    "        \n",
    "        # 2. Unstack data\n",
    "        print(\"Optimizing data structures...\")\n",
    "        self.df_close = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "        self.df_high = df_ohlcv['Adj High'].unstack(level=0)\n",
    "        self.df_low = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "        \n",
    "        # 3. Setup Calendar\n",
    "        if master_ticker not in self.df_close.columns:\n",
    "            master_ticker = self.df_close.columns[0]\n",
    "            print(f\"Warning: Master ticker not found. Using {master_ticker}\")\n",
    "            \n",
    "        self.trading_calendar = self.df_close[master_ticker].dropna().index.unique().sort_values()\n",
    "        print(\"✅ AlphaEngine Ready.\")\n",
    "\n",
    "    def run(self, inputs: EngineInput) -> EngineOutput:\n",
    "        # --- A. Validate Dates ---\n",
    "        try:\n",
    "            start_idx = self.trading_calendar.searchsorted(inputs.start_date)\n",
    "            if start_idx < 0: start_idx = 0\n",
    "        except Exception:\n",
    "            return self._error_result(\"Invalid Start Date\")\n",
    "\n",
    "        desired_end_idx = start_idx + inputs.calc_period + inputs.fwd_period\n",
    "        if desired_end_idx >= len(self.trading_calendar):\n",
    "            return self._error_result(f\"Date range exceeds history.\")\n",
    "\n",
    "        safe_start_date = self.trading_calendar[start_idx]\n",
    "        safe_calc_end_date = self.trading_calendar[start_idx + inputs.calc_period]\n",
    "        safe_viz_end_date = self.trading_calendar[start_idx + inputs.calc_period + inputs.fwd_period]\n",
    "\n",
    "        # --- B. Select Tickers ---\n",
    "        tickers_to_trade = []\n",
    "        results_table = pd.DataFrame()\n",
    "        \n",
    "        if inputs.mode == 'Manual List':\n",
    "            valid = [t for t in inputs.manual_tickers if t in self.df_close.columns]\n",
    "            if not valid: return self._error_result(\"No valid tickers found.\")\n",
    "            tickers_to_trade = valid\n",
    "            results_table = pd.DataFrame(index=valid)\n",
    "            \n",
    "        else: # Ranking Mode\n",
    "            eligible_tickers = self._get_eligible_universe(safe_start_date, inputs.quality_thresholds)\n",
    "            if not eligible_tickers: return self._error_result(\"No tickers passed quality filters.\")\n",
    "            \n",
    "            calc_close = self.df_close.loc[safe_start_date:safe_calc_end_date, eligible_tickers]\n",
    "            \n",
    "            # Prepare Metric Ingredients\n",
    "            idx_product = pd.MultiIndex.from_product([eligible_tickers, calc_close.index], names=['Ticker', 'Date'])\n",
    "            feat_slice = self.features_df.reindex(idx_product).dropna(how='all')\n",
    "            atrp_mean = feat_slice.groupby(level='Ticker')['ATRP'].mean()\n",
    "            \n",
    "            ingredients = { 'calc_close': calc_close, 'daily_returns': calc_close.pct_change(), 'atrp': atrp_mean }\n",
    "            \n",
    "            if inputs.metric not in METRIC_REGISTRY: return self._error_result(f\"Metric '{inputs.metric}' not found.\")\n",
    "                \n",
    "            metric_vals = METRIC_REGISTRY[inputs.metric](ingredients)\n",
    "            sorted_tickers = metric_vals.sort_values(ascending=False)\n",
    "            \n",
    "            # Select Top N\n",
    "            start_r = max(0, inputs.rank_start - 1)\n",
    "            end_r = inputs.rank_end\n",
    "            tickers_to_trade = sorted_tickers.iloc[start_r:end_r].index.tolist()\n",
    "            \n",
    "            if not tickers_to_trade: return self._error_result(\"No tickers generated from ranking.\")\n",
    "\n",
    "            results_table = pd.DataFrame({\n",
    "                'Rank': range(inputs.rank_start, inputs.rank_start + len(tickers_to_trade)),\n",
    "                'Ticker': tickers_to_trade,\n",
    "                'Metric Value': sorted_tickers.loc[tickers_to_trade].values\n",
    "            }).set_index('Ticker')\n",
    "\n",
    "        # --- C. Performance Calculations ---\n",
    "        p_val, p_ret, p_atrp = calculate_buy_and_hold_performance(\n",
    "            self.df_close, self.features_df, tickers_to_trade, safe_start_date, safe_viz_end_date)\n",
    "        \n",
    "        b_val, b_ret, b_atrp = calculate_buy_and_hold_performance(\n",
    "            self.df_close, self.features_df, [inputs.benchmark_ticker], safe_start_date, safe_viz_end_date)\n",
    "\n",
    "        # --- D. Final Metrics ---\n",
    "        plot_data = self.df_close[list(set(tickers_to_trade))].loc[safe_start_date:safe_viz_end_date]\n",
    "        if not plot_data.empty: plot_data = plot_data / plot_data.bfill().iloc[0]\n",
    "\n",
    "        calc_end_ts = safe_calc_end_date\n",
    "        metrics = {}\n",
    "        get_gain = lambda s: (s.iloc[-1] / s.iloc[0]) - 1 if len(s) > 0 else 0\n",
    "\n",
    "        metrics['calc_p_gain'] = get_gain(p_val.loc[:calc_end_ts])\n",
    "        metrics['fwd_p_gain'] = get_gain(p_val.loc[calc_end_ts:])\n",
    "        metrics['full_p_sharpe_atr'] = calculate_sharpe_atr(p_ret, p_atrp)\n",
    "        \n",
    "        if not b_ret.empty:\n",
    "            metrics['calc_b_gain'] = get_gain(b_val.loc[:calc_end_ts])\n",
    "            metrics['fwd_b_gain'] = get_gain(b_val.loc[calc_end_ts:])\n",
    "            metrics['full_b_sharpe_atr'] = calculate_sharpe_atr(b_ret, b_atrp)\n",
    "\n",
    "        # Update table with fwd gains\n",
    "        if not plot_data.empty:\n",
    "            step_gains = (plot_data.iloc[-1] / plot_data.loc[calc_end_ts]) - 1\n",
    "            results_table['Fwd Gain'] = step_gains\n",
    "        \n",
    "        ticker_counts = Counter(tickers_to_trade)\n",
    "        weights = pd.Series({t: c/len(tickers_to_trade) for t, c in ticker_counts.items()})\n",
    "\n",
    "        return EngineOutput(\n",
    "            portfolio_series=p_val, benchmark_series=b_val, normalized_plot_data=plot_data,\n",
    "            tickers=tickers_to_trade, initial_weights=weights, perf_metrics=metrics,\n",
    "            results_df=results_table, calc_end_date=safe_calc_end_date, viz_end_date=safe_viz_end_date\n",
    "        )\n",
    "\n",
    "    def _get_eligible_universe(self, date_ts, thresholds):\n",
    "        avail_dates = self.features_df.index.get_level_values('Date').unique().sort_values()\n",
    "        valid_dates = avail_dates[avail_dates <= date_ts]\n",
    "        if valid_dates.empty: return []\n",
    "        day_features = self.features_df.xs(valid_dates[-1], level='Date')\n",
    "        mask = ((day_features['RollMedDollarVol'] >= thresholds['min_median_dollar_volume']) &\n",
    "                (day_features['RollingStalePct'] <= thresholds['max_stale_pct']) &\n",
    "                (day_features['RollingSameVolCount'] <= thresholds['max_same_vol_count']))\n",
    "        return day_features[mask].index.tolist()\n",
    "\n",
    "    def _error_result(self, msg):\n",
    "        return EngineOutput(pd.Series(dtype=float), pd.Series(dtype=float), pd.DataFrame(), [], pd.Series(dtype=float), {}, pd.DataFrame(), pd.Timestamp.min, pd.Timestamp.min, msg)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION E: THE UI (Visualization) - FIXED\n",
    "# ==============================================================================\n",
    "\n",
    "# def plot_walk_forward_analyzer(df_ohlcv, default_start_date='2020-01-01', default_calc_period=126, default_fwd_period=63,\n",
    "#                                default_metric='Sharpe (ATR)', default_rank_start=1, default_rank_end=10,\n",
    "#                                default_benchmark_ticker='SPY', master_calendar_ticker='SPY', quality_thresholds=None, debug=False):\n",
    "    \n",
    "#     # 1. Initialize Engine\n",
    "#     engine = AlphaEngine(df_ohlcv, master_ticker=master_calendar_ticker)\n",
    "    \n",
    "#     if quality_thresholds is None:\n",
    "#         quality_thresholds = {'min_median_dollar_volume': 1_000_000, 'max_stale_pct': 0.05, 'max_same_vol_count': 10}\n",
    "\n",
    "#     # 2. Widgets\n",
    "#     w_start_date = widgets.DatePicker(description='Start Date', value=pd.to_datetime(default_start_date))\n",
    "#     w_calc = widgets.IntText(value=default_calc_period, description='Calc Days')\n",
    "#     w_fwd = widgets.IntText(value=default_fwd_period, description='Fwd Days')\n",
    "#     w_metric = widgets.Dropdown(options=list(METRIC_REGISTRY.keys()), value=default_metric, description='Metric')\n",
    "#     w_rank_start = widgets.IntText(value=default_rank_start, description='Rank Start')\n",
    "#     w_rank_end = widgets.IntText(value=default_rank_end, description='Rank End')\n",
    "#     w_bench = widgets.Text(value=default_benchmark_ticker, description='Benchmark')\n",
    "#     w_mode = widgets.RadioButtons(options=['Ranking', 'Manual List'], value='Ranking', description='Mode')\n",
    "#     w_manual = widgets.Textarea(placeholder='AAPL, MSFT...', description='Manual List')\n",
    "#     btn_update = widgets.Button(description=\"RUN ANALYSIS\", button_style='success', icon='play')\n",
    "#     out_log = widgets.Output()\n",
    "    \n",
    "#     # 3. Figure\n",
    "#     fig = go.FigureWidget()\n",
    "#     fig.update_layout(height=600, title=\"Walk-Forward Analysis (Engine Powered)\", template=\"plotly_white\", hovermode=\"x unified\")\n",
    "    \n",
    "#     def on_click(b):\n",
    "#         out_log.clear_output()\n",
    "#         manual_list = [t.strip().upper() for t in w_manual.value.split(',') if t.strip()]\n",
    "        \n",
    "#         inputs = EngineInput(\n",
    "#             mode=w_mode.value, start_date=pd.to_datetime(w_start_date.value),\n",
    "#             calc_period=w_calc.value, fwd_period=w_fwd.value, metric=w_metric.value,\n",
    "#             benchmark_ticker=w_bench.value.strip().upper(), rank_start=w_rank_start.value,\n",
    "#             rank_end=w_rank_end.value, quality_thresholds=quality_thresholds, manual_tickers=manual_list\n",
    "#         )\n",
    "        \n",
    "#         with out_log:\n",
    "#             print(\"⏳ Running AlphaEngine...\")\n",
    "#             res = engine.run(inputs)\n",
    "#             if res.error_msg: print(f\"❌ ERROR: {res.error_msg}\"); return\n",
    "            \n",
    "#             with fig.batch_update():\n",
    "#                 fig.data = []\n",
    "#                 # Plot Components\n",
    "#                 for col in res.normalized_plot_data.columns:\n",
    "#                     fig.add_trace(go.Scatter(x=res.normalized_plot_data.index, y=res.normalized_plot_data[col], mode='lines', name=col, opacity=0.15, showlegend=False))\n",
    "                \n",
    "#                 # Plot Benchmark\n",
    "#                 if not res.benchmark_series.empty:\n",
    "#                     fig.add_trace(go.Scatter(x=res.benchmark_series.index, y=res.benchmark_series.values, mode='lines', name=f\"Benchmark\", line=dict(color='black', width=2, dash='dash')))\n",
    "                \n",
    "#                 # Plot Portfolio\n",
    "#                 fig.add_trace(go.Scatter(x=res.portfolio_series.index, y=res.portfolio_series.values, mode='lines', name=\"Alpha Portfolio\", line=dict(color='green', width=3)))\n",
    "                \n",
    "#                 # --- FIXED: Use add_shape instead of add_vline to avoid batch_update layout errors ---\n",
    "#                 fig.layout.shapes = []\n",
    "#                 fig.add_shape(type=\"line\", \n",
    "#                               x0=res.calc_end_date, x1=res.calc_end_date, \n",
    "#                               y0=0, y1=1, xref='x', yref='paper',\n",
    "#                               line=dict(dash=\"dot\", color=\"gray\", width=1))\n",
    "            \n",
    "#             m = res.perf_metrics\n",
    "#             fwd_delta = m.get('fwd_p_gain', 0) - m.get('fwd_b_gain', 0) if 'fwd_b_gain' in m else np.nan\n",
    "#             row_data = [{'Metric': 'Calculated Gain', 'Portfolio': m.get('calc_p_gain'), 'Benchmark': m.get('calc_b_gain')},\n",
    "#                         {'Metric': 'Forward Gain', 'Portfolio': m.get('fwd_p_gain'), 'Benchmark': m.get('fwd_b_gain')},\n",
    "#                         {'Metric': 'Sharpe (ATR)', 'Portfolio': m.get('full_p_sharpe_atr'), 'Benchmark': m.get('full_b_sharpe_atr')}]\n",
    "            \n",
    "#             print(f\"✅ Period: {inputs.start_date.date()} -> {res.viz_end_date.date()} | Alpha: {fwd_delta:+.2%}\")\n",
    "#             display(pd.DataFrame(row_data).set_index('Metric').style.format(\"{:+.2%}\", na_rep=\"N/A\"))\n",
    "#             if not res.results_df.empty: display(res.results_df.style.format({'Fwd Gain': '{:+.2%}', 'Metric Value': '{:.4f}'}))\n",
    "\n",
    "#     btn_update.on_click(on_click)\n",
    "    \n",
    "#     # Layout\n",
    "#     ui = widgets.VBox([\n",
    "#         widgets.HBox([widgets.VBox([w_mode, w_start_date]), widgets.VBox([w_calc, w_fwd]), widgets.VBox([w_metric, w_rank_start, w_rank_end])]),\n",
    "#         w_manual, widgets.HBox([w_bench, btn_update]), out_log\n",
    "#     ])\n",
    "    \n",
    "#     on_click(None) # Initial Run\n",
    "#     display(ui, fig)\n",
    "#     return (None, None)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION F: UTILITIES\n",
    "# ==============================================================================\n",
    "\n",
    "def print_nested(d, indent=0, width=4):\n",
    "    \"\"\"Pretty-print any nested dict/list/tuple combination.\"\"\"\n",
    "    spacing = ' ' * indent\n",
    "    if isinstance(d, dict):\n",
    "        for k, v in d.items():\n",
    "            print(f'{spacing}{k}:')\n",
    "            print_nested(v, indent + width, width)\n",
    "    elif isinstance(d, (list, tuple)):\n",
    "        for item in d:\n",
    "            print_nested(item, indent, width)\n",
    "    else:\n",
    "        print(f'{spacing}{d}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "232740e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 9643848 entries, ('A', Timestamp('1999-11-18 00:00:00')) to ('ZWS', Timestamp('2025-11-28 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   Adj Open   float64\n",
      " 1   Adj High   float64\n",
      " 2   Adj Low    float64\n",
      " 3   Adj Close  float64\n",
      " 4   Volume     int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 405.4+ MB\n",
      "df_ohlcv.info():\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Adj Open</th>\n",
       "      <th>Adj High</th>\n",
       "      <th>Adj Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">A</th>\n",
       "      <th>1999-11-18</th>\n",
       "      <td>27.2452</td>\n",
       "      <td>29.9398</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>26.3470</td>\n",
       "      <td>74716422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-19</th>\n",
       "      <td>25.7108</td>\n",
       "      <td>25.7482</td>\n",
       "      <td>23.8396</td>\n",
       "      <td>24.1764</td>\n",
       "      <td>18198348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-22</th>\n",
       "      <td>24.7378</td>\n",
       "      <td>26.3470</td>\n",
       "      <td>23.9893</td>\n",
       "      <td>26.3470</td>\n",
       "      <td>7857767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-23</th>\n",
       "      <td>25.4488</td>\n",
       "      <td>26.1225</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>7138322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-24</th>\n",
       "      <td>24.0267</td>\n",
       "      <td>25.1120</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>24.5881</td>\n",
       "      <td>5785609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ZWS</th>\n",
       "      <th>2025-11-21</th>\n",
       "      <td>45.6900</td>\n",
       "      <td>47.3300</td>\n",
       "      <td>45.4600</td>\n",
       "      <td>46.6200</td>\n",
       "      <td>740300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-24</th>\n",
       "      <td>46.5300</td>\n",
       "      <td>47.4100</td>\n",
       "      <td>46.1600</td>\n",
       "      <td>47.2900</td>\n",
       "      <td>1046900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-25</th>\n",
       "      <td>47.2900</td>\n",
       "      <td>48.4800</td>\n",
       "      <td>47.1500</td>\n",
       "      <td>48.0200</td>\n",
       "      <td>592800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-26</th>\n",
       "      <td>47.5400</td>\n",
       "      <td>48.7000</td>\n",
       "      <td>47.3000</td>\n",
       "      <td>48.1300</td>\n",
       "      <td>1154100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-28</th>\n",
       "      <td>48.4600</td>\n",
       "      <td>48.4800</td>\n",
       "      <td>47.7000</td>\n",
       "      <td>47.7000</td>\n",
       "      <td>481401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9643848 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Adj Open  Adj High  Adj Low  Adj Close    Volume\n",
       "Ticker Date                                                        \n",
       "A      1999-11-18   27.2452   29.9398  23.9518    26.3470  74716422\n",
       "       1999-11-19   25.7108   25.7482  23.8396    24.1764  18198348\n",
       "       1999-11-22   24.7378   26.3470  23.9893    26.3470   7857767\n",
       "       1999-11-23   25.4488   26.1225  23.9518    23.9518   7138322\n",
       "       1999-11-24   24.0267   25.1120  23.9518    24.5881   5785609\n",
       "...                     ...       ...      ...        ...       ...\n",
       "ZWS    2025-11-21   45.6900   47.3300  45.4600    46.6200    740300\n",
       "       2025-11-24   46.5300   47.4100  46.1600    47.2900   1046900\n",
       "       2025-11-25   47.2900   48.4800  47.1500    48.0200    592800\n",
       "       2025-11-26   47.5400   48.7000  47.3000    48.1300   1154100\n",
       "       2025-11-28   48.4600   48.4800  47.7000    47.7000    481401\n",
       "\n",
       "[9643848 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = r'c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet'\n",
    "df_ohlcv = pd.read_parquet(data_path, engine='pyarrow')\n",
    "print(f'df_ohlcv.info():\\n{df_ohlcv.info()}')\n",
    "df_ohlcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5208c3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ==============================================================================\n",
    "# # SECTION D: THE ALPHA ENGINE (Updated to calculate all table metrics)\n",
    "# # ==============================================================================\n",
    "\n",
    "# class AlphaEngine:\n",
    "#     def __init__(self, df_ohlcv: pd.DataFrame, master_ticker: str = 'SPY'):\n",
    "#         print(\"--- ⚙️ Initializing AlphaEngine ---\")\n",
    "        \n",
    "#         # 1. Pre-calculate Features\n",
    "#         self.features_df = generate_features(df_ohlcv)\n",
    "        \n",
    "#         # 2. Unstack data\n",
    "#         print(\"Optimizing data structures...\")\n",
    "#         self.df_close = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "#         self.df_high = df_ohlcv['Adj High'].unstack(level=0)\n",
    "#         self.df_low = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "        \n",
    "#         # 3. Setup Calendar\n",
    "#         if master_ticker not in self.df_close.columns:\n",
    "#             master_ticker = self.df_close.columns[0]\n",
    "#             print(f\"Warning: Master ticker not found. Using {master_ticker}\")\n",
    "            \n",
    "#         self.trading_calendar = self.df_close[master_ticker].dropna().index.unique().sort_values()\n",
    "#         print(\"✅ AlphaEngine Ready.\")\n",
    "\n",
    "#     def run(self, inputs: EngineInput) -> EngineOutput:\n",
    "#         # --- A. Validate Dates ---\n",
    "#         try:\n",
    "#             start_idx = self.trading_calendar.searchsorted(inputs.start_date)\n",
    "#             if start_idx < 0: start_idx = 0\n",
    "#         except Exception:\n",
    "#             return self._error_result(\"Invalid Start Date\")\n",
    "\n",
    "#         desired_end_idx = start_idx + inputs.calc_period + inputs.fwd_period\n",
    "#         if desired_end_idx >= len(self.trading_calendar):\n",
    "#             return self._error_result(f\"Date range exceeds history.\")\n",
    "\n",
    "#         safe_start_date = self.trading_calendar[start_idx]\n",
    "#         safe_calc_end_date = self.trading_calendar[start_idx + inputs.calc_period]\n",
    "#         safe_viz_end_date = self.trading_calendar[start_idx + inputs.calc_period + inputs.fwd_period]\n",
    "\n",
    "#         # --- B. Select Tickers ---\n",
    "#         tickers_to_trade = []\n",
    "#         results_table = pd.DataFrame()\n",
    "        \n",
    "#         if inputs.mode == 'Manual List':\n",
    "#             valid = [t for t in inputs.manual_tickers if t in self.df_close.columns]\n",
    "#             if not valid: return self._error_result(\"No valid tickers found.\")\n",
    "#             tickers_to_trade = valid\n",
    "#             results_table = pd.DataFrame(index=valid)\n",
    "            \n",
    "#         else: # Ranking Mode\n",
    "#             eligible_tickers = self._get_eligible_universe(safe_start_date, inputs.quality_thresholds)\n",
    "#             if not eligible_tickers: return self._error_result(\"No tickers passed quality filters.\")\n",
    "            \n",
    "#             calc_close = self.df_close.loc[safe_start_date:safe_calc_end_date, eligible_tickers]\n",
    "            \n",
    "#             # Prepare Metric Ingredients\n",
    "#             idx_product = pd.MultiIndex.from_product([eligible_tickers, calc_close.index], names=['Ticker', 'Date'])\n",
    "#             feat_slice = self.features_df.reindex(idx_product).dropna(how='all')\n",
    "#             atrp_mean = feat_slice.groupby(level='Ticker')['ATRP'].mean()\n",
    "            \n",
    "#             ingredients = { 'calc_close': calc_close, 'daily_returns': calc_close.pct_change(), 'atrp': atrp_mean }\n",
    "            \n",
    "#             if inputs.metric not in METRIC_REGISTRY: return self._error_result(f\"Metric '{inputs.metric}' not found.\")\n",
    "                \n",
    "#             metric_vals = METRIC_REGISTRY[inputs.metric](ingredients)\n",
    "#             sorted_tickers = metric_vals.sort_values(ascending=False)\n",
    "            \n",
    "#             # Select Top N\n",
    "#             start_r = max(0, inputs.rank_start - 1)\n",
    "#             end_r = inputs.rank_end\n",
    "#             tickers_to_trade = sorted_tickers.iloc[start_r:end_r].index.tolist()\n",
    "            \n",
    "#             if not tickers_to_trade: return self._error_result(\"No tickers generated from ranking.\")\n",
    "\n",
    "#             results_table = pd.DataFrame({\n",
    "#                 'Rank': range(inputs.rank_start, inputs.rank_start + len(tickers_to_trade)),\n",
    "#                 'Ticker': tickers_to_trade,\n",
    "#                 'Metric Value': sorted_tickers.loc[tickers_to_trade].values\n",
    "#             }).set_index('Ticker')\n",
    "\n",
    "#         # --- C. Performance Calculations ---\n",
    "#         p_val, p_ret, p_atrp = calculate_buy_and_hold_performance(\n",
    "#             self.df_close, self.features_df, tickers_to_trade, safe_start_date, safe_viz_end_date)\n",
    "        \n",
    "#         b_val, b_ret, b_atrp = calculate_buy_and_hold_performance(\n",
    "#             self.df_close, self.features_df, [inputs.benchmark_ticker], safe_start_date, safe_viz_end_date)\n",
    "\n",
    "#         # --- D. Final Metrics (UPDATED: Calculates all Calc/Fwd/Full splits) ---\n",
    "#         plot_data = self.df_close[list(set(tickers_to_trade))].loc[safe_start_date:safe_viz_end_date]\n",
    "#         if not plot_data.empty: plot_data = plot_data / plot_data.bfill().iloc[0]\n",
    "\n",
    "#         calc_end_ts = safe_calc_end_date\n",
    "#         metrics = {}\n",
    "#         get_gain = lambda s: (s.iloc[-1] / s.iloc[0]) - 1 if len(s) > 0 else 0\n",
    "\n",
    "#         # 1. Define Slices\n",
    "#         p_ret_calc = p_ret.loc[:calc_end_ts]\n",
    "#         p_ret_fwd = p_ret.loc[calc_end_ts:].iloc[1:]\n",
    "#         p_atrp_calc = p_atrp.loc[p_ret_calc.index]\n",
    "#         p_atrp_fwd = p_atrp.loc[p_ret_fwd.index]\n",
    "\n",
    "#         # 2. Portfolio Metrics\n",
    "#         metrics['full_p_gain'] = get_gain(p_val)\n",
    "#         metrics['calc_p_gain'] = get_gain(p_val.loc[:calc_end_ts])\n",
    "#         metrics['fwd_p_gain'] = get_gain(p_val.loc[calc_end_ts:])\n",
    "        \n",
    "#         metrics['full_p_sharpe_atr'] = calculate_sharpe_atr(p_ret, p_atrp)\n",
    "#         metrics['calc_p_sharpe_atr'] = calculate_sharpe_atr(p_ret_calc, p_atrp_calc)\n",
    "#         metrics['fwd_p_sharpe_atr'] = calculate_sharpe_atr(p_ret_fwd, p_atrp_fwd)\n",
    "        \n",
    "#         # 3. Benchmark Metrics\n",
    "#         if not b_ret.empty:\n",
    "#             b_ret_calc = b_ret.loc[:calc_end_ts]\n",
    "#             b_ret_fwd = b_ret.loc[calc_end_ts:].iloc[1:]\n",
    "#             b_atrp_calc = b_atrp.loc[b_ret_calc.index]\n",
    "#             b_atrp_fwd = b_atrp.loc[b_ret_fwd.index]\n",
    "            \n",
    "#             metrics['full_b_gain'] = get_gain(b_val)\n",
    "#             metrics['calc_b_gain'] = get_gain(b_val.loc[:calc_end_ts])\n",
    "#             metrics['fwd_b_gain'] = get_gain(b_val.loc[calc_end_ts:])\n",
    "            \n",
    "#             metrics['full_b_sharpe_atr'] = calculate_sharpe_atr(b_ret, b_atrp)\n",
    "#             metrics['calc_b_sharpe_atr'] = calculate_sharpe_atr(b_ret_calc, b_atrp_calc)\n",
    "#             metrics['fwd_b_sharpe_atr'] = calculate_sharpe_atr(b_ret_fwd, b_atrp_fwd)\n",
    "\n",
    "#         # Update table with fwd gains\n",
    "#         if not plot_data.empty:\n",
    "#             step_gains = (plot_data.iloc[-1] / plot_data.loc[calc_end_ts]) - 1\n",
    "#             results_table['Fwd Gain'] = step_gains\n",
    "        \n",
    "#         ticker_counts = Counter(tickers_to_trade)\n",
    "#         weights = pd.Series({t: c/len(tickers_to_trade) for t, c in ticker_counts.items()})\n",
    "\n",
    "#         return EngineOutput(\n",
    "#             portfolio_series=p_val, benchmark_series=b_val, normalized_plot_data=plot_data,\n",
    "#             tickers=tickers_to_trade, initial_weights=weights, perf_metrics=metrics,\n",
    "#             results_df=results_table, calc_end_date=safe_calc_end_date, viz_end_date=safe_viz_end_date\n",
    "#         )\n",
    "\n",
    "#     def _get_eligible_universe(self, date_ts, thresholds):\n",
    "#         avail_dates = self.features_df.index.get_level_values('Date').unique().sort_values()\n",
    "#         valid_dates = avail_dates[avail_dates <= date_ts]\n",
    "#         if valid_dates.empty: return []\n",
    "#         day_features = self.features_df.xs(valid_dates[-1], level='Date')\n",
    "#         mask = ((day_features['RollMedDollarVol'] >= thresholds['min_median_dollar_volume']) &\n",
    "#                 (day_features['RollingStalePct'] <= thresholds['max_stale_pct']) &\n",
    "#                 (day_features['RollingSameVolCount'] <= thresholds['max_same_vol_count']))\n",
    "#         return day_features[mask].index.tolist()\n",
    "\n",
    "#     def _error_result(self, msg):\n",
    "#         return EngineOutput(pd.Series(dtype=float), pd.Series(dtype=float), pd.DataFrame(), [], pd.Series(dtype=float), {}, pd.DataFrame(), pd.Timestamp.min, pd.Timestamp.min, msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa9b40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ==============================================================================\n",
    "# # SECTION E: THE UI (Visualization) - WITH RETURN VALUES FIXED\n",
    "# # **Changes made:**\n",
    "# # 1.  Created `results_container = [None]` at the start.\n",
    "# # 2.  Inside `update_plot`, I added `results_container[0] = res` to capture the latest `EngineOutput` object.\n",
    "# # 3.  The function now returns `(results_container, [None])` so your unpacking line works correctly.\n",
    "# # ==============================================================================\n",
    "\n",
    "# def plot_walk_forward_analyzer(df_ohlcv, \n",
    "#                                default_start_date='2020-01-01', \n",
    "#                                default_calc_period=126, \n",
    "#                                default_fwd_period=63,\n",
    "#                                default_metric='Sharpe (ATR)', \n",
    "#                                default_rank_start=1, \n",
    "#                                default_rank_end=10,\n",
    "#                                default_benchmark_ticker='SPY', \n",
    "#                                master_calendar_ticker='SPY', \n",
    "#                                quality_thresholds=None, \n",
    "#                                debug=False):\n",
    "    \n",
    "#     # 1. Initialize Engine & Containers\n",
    "#     engine = AlphaEngine(df_ohlcv, master_ticker=master_calendar_ticker)\n",
    "    \n",
    "#     # These mutable lists allow us to extract data from the inner function\n",
    "#     results_container = [None]\n",
    "#     debug_container = [None] # Placeholder to maintain API compatibility\n",
    "    \n",
    "#     if quality_thresholds is None:\n",
    "#         quality_thresholds = {'min_median_dollar_volume': 1_000_000, 'max_stale_pct': 0.05, 'max_same_vol_count': 10}\n",
    "\n",
    "#     # --- 2. WIDGET SETUP ---\n",
    "    \n",
    "#     mode_selector = widgets.RadioButtons(\n",
    "#         options=['Ranking', 'Manual List'], \n",
    "#         value='Ranking', \n",
    "#         description='Portfolio Mode:', \n",
    "#         layout={'width': 'max-content'}\n",
    "#     )\n",
    "    \n",
    "#     start_date_picker = widgets.DatePicker(description='Start Date:', value=pd.to_datetime(default_start_date))\n",
    "#     calc_period_input = widgets.IntText(value=default_calc_period, description='Calc Period:')\n",
    "#     fwd_period_input = widgets.IntText(value=default_fwd_period, description='Fwd Period:')\n",
    "    \n",
    "#     metric_dropdown = widgets.Dropdown(options=list(METRIC_REGISTRY.keys()), value=default_metric, description='Metric:')\n",
    "#     rank_start_input = widgets.IntText(value=default_rank_start, description='Rank Start:')\n",
    "#     rank_end_input = widgets.IntText(value=default_rank_end, description='Rank End:')\n",
    "    \n",
    "#     manual_tickers_input = widgets.Textarea(\n",
    "#         value='', \n",
    "#         placeholder='Enter tickers, comma-separated...\\ne.g., AAPL, AAPL, MSFT, GOOG', \n",
    "#         description='Manual Tickers:', \n",
    "#         layout={'width': '400px', 'height': '80px'}\n",
    "#     )\n",
    "    \n",
    "#     benchmark_input = widgets.Text(value=default_benchmark_ticker, description='Benchmark:', placeholder='Enter Ticker')\n",
    "#     update_button = widgets.Button(description=\"Update Chart\", button_style='primary')\n",
    "    \n",
    "#     ticker_list_output = widgets.Output()\n",
    "\n",
    "#     # --- 3. LAYOUT ASSEMBLY ---\n",
    "    \n",
    "#     ranking_controls_box = widgets.HBox([metric_dropdown, rank_start_input, rank_end_input])\n",
    "#     manual_controls_box = widgets.HBox([manual_tickers_input])\n",
    "#     date_controls_row = widgets.HBox([start_date_picker, calc_period_input, fwd_period_input])\n",
    "#     bottom_row = widgets.HBox([benchmark_input, update_button])\n",
    "    \n",
    "#     def on_mode_change(change):\n",
    "#         if change['new'] == 'Ranking':\n",
    "#             ranking_controls_box.layout.display = 'flex'\n",
    "#             manual_controls_box.layout.display = 'none'\n",
    "#         else:\n",
    "#             ranking_controls_box.layout.display = 'none'\n",
    "#             manual_controls_box.layout.display = 'flex'\n",
    "            \n",
    "#     mode_selector.observe(on_mode_change, names='value')\n",
    "#     on_mode_change({'new': mode_selector.value})\n",
    "\n",
    "#     ui_container = widgets.VBox([\n",
    "#         mode_selector,\n",
    "#         date_controls_row,\n",
    "#         ranking_controls_box,\n",
    "#         manual_controls_box,\n",
    "#         bottom_row,\n",
    "#         ticker_list_output\n",
    "#     ], layout=widgets.Layout(margin='10px 0 20px 0'))\n",
    "\n",
    "#     # --- 4. FIGURE SETUP ---\n",
    "    \n",
    "#     fig = go.FigureWidget()\n",
    "#     fig.update_layout(\n",
    "#         title_text='Walk-Forward Performance Analysis', \n",
    "#         xaxis_title='Date', \n",
    "#         yaxis_title='Normalized Price', \n",
    "#         hovermode='x unified', \n",
    "#         height=600,\n",
    "#         template=\"plotly_white\"\n",
    "#     )\n",
    "    \n",
    "#     # High-Contrast Colors\n",
    "#     colors = ['#1f77b4', '#d62728', '#2ca02c', '#ff7f0e', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "\n",
    "#     max_traces = 50\n",
    "#     for i in range(max_traces):\n",
    "#         color = colors[i % len(colors)]\n",
    "#         fig.add_trace(go.Scatter(\n",
    "#             x=[None], y=[None], mode='lines', \n",
    "#             name=f'placeholder_{i}', visible=False, showlegend=True, opacity=1.0,\n",
    "#             line=dict(color=color, width=2)\n",
    "#         ))\n",
    "        \n",
    "#     fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Benchmark', visible=True, showlegend=True, line=dict(color='black', width=3, dash='dash')))\n",
    "#     fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Group Portfolio', visible=True, showlegend=True, line=dict(color='green', width=3)))\n",
    "\n",
    "#     # --- 5. UPDATE LOGIC ---\n",
    "    \n",
    "#     def update_plot(b):\n",
    "#         ticker_list_output.clear_output()\n",
    "        \n",
    "#         # 1. Parse Inputs\n",
    "#         manual_list = [t.strip().upper() for t in manual_tickers_input.value.split(',') if t.strip()]\n",
    "#         start_date_raw = pd.to_datetime(start_date_picker.value)\n",
    "        \n",
    "#         # 2. VALIDATE DATE (STRICT MODE)\n",
    "#         first_available_date = engine.trading_calendar[0]\n",
    "        \n",
    "#         if start_date_raw < (first_available_date - pd.Timedelta(days=7)):\n",
    "#             with ticker_list_output:\n",
    "#                 print(f\"⚠️ DATE WARNING: The requested start date ({start_date_raw.date()}) is unavailable.\")\n",
    "#                 print(f\"   The Master Calendar Ticker '{master_calendar_ticker}' only starts trading on {first_available_date.date()}.\")\n",
    "#                 print(f\"   >> Please update the Start Date or choose a Benchmark with longer history.\")\n",
    "#                 print(f\"   >> Analysis Aborted.\")\n",
    "#                 print(\"-\" * 60)\n",
    "#             return\n",
    "\n",
    "#         # 3. Prepare Engine Inputs\n",
    "#         inputs = EngineInput(\n",
    "#             mode=mode_selector.value,\n",
    "#             start_date=start_date_raw,\n",
    "#             calc_period=calc_period_input.value,\n",
    "#             fwd_period=fwd_period_input.value,\n",
    "#             metric=metric_dropdown.value,\n",
    "#             rank_start=rank_start_input.value,\n",
    "#             rank_end=rank_end_input.value,\n",
    "#             benchmark_ticker=benchmark_input.value.strip().upper(),\n",
    "#             quality_thresholds=quality_thresholds,\n",
    "#             manual_tickers=manual_list\n",
    "#         )\n",
    "        \n",
    "#         with ticker_list_output:\n",
    "#             # Run Engine\n",
    "#             res = engine.run(inputs)\n",
    "            \n",
    "#             # --- CAPTURE RESULTS ---\n",
    "#             results_container[0] = res\n",
    "            \n",
    "#             if res.error_msg:\n",
    "#                 print(f\"Error: {res.error_msg}\")\n",
    "#                 return\n",
    "\n",
    "#             # Update Plot Traces\n",
    "#             with fig.batch_update():\n",
    "#                 unique_plot_tickers = res.normalized_plot_data.columns.tolist()\n",
    "                \n",
    "#                 for i in range(max_traces):\n",
    "#                     trace = fig.data[i]\n",
    "#                     if i < len(unique_plot_tickers):\n",
    "#                         t = unique_plot_tickers[i]\n",
    "#                         series = res.normalized_plot_data[t]\n",
    "#                         trace.x, trace.y, trace.name, trace.visible = series.index, series.values, t, True\n",
    "#                     else:\n",
    "#                         trace.visible = False\n",
    "                \n",
    "#                 bm_trace = fig.data[max_traces]\n",
    "#                 if not res.benchmark_series.empty:\n",
    "#                     bm_trace.x, bm_trace.y, bm_trace.name, bm_trace.visible = res.benchmark_series.index, res.benchmark_series.values, f\"Benchmark ({inputs.benchmark_ticker})\", True\n",
    "#                 else:\n",
    "#                     bm_trace.visible = False\n",
    "\n",
    "#                 port_trace = fig.data[max_traces + 1]\n",
    "#                 port_trace.x, port_trace.y, port_trace.visible = res.portfolio_series.index, res.portfolio_series.values, True\n",
    "                \n",
    "#                 fig.layout.shapes = []\n",
    "#                 fig.add_shape(type=\"line\", x0=res.calc_end_date, y0=0, x1=res.calc_end_date, y1=1, xref='x', yref='paper', line=dict(color=\"grey\", width=2, dash=\"dash\"))\n",
    "\n",
    "#             # Print Summary Reports\n",
    "#             print(f\"Analysis Period: {inputs.start_date.date()} to {res.viz_end_date.date()}.\")\n",
    "#             if inputs.mode == 'Ranking':\n",
    "#                 print(\"Ranked Tickers:\")\n",
    "#                 pprint.pprint(res.tickers)\n",
    "#             else:\n",
    "#                 print(\"Manual Portfolio Tickers (Duplicates Increase Weight):\")\n",
    "#                 pprint.pprint(res.tickers)\n",
    "                \n",
    "#             m = res.perf_metrics\n",
    "#             def val(k): return m.get(k, np.nan)\n",
    "            \n",
    "#             # --- Table Construction ---\n",
    "#             rows = []\n",
    "#             rows.append({'Metric': 'Group Portfolio Gain', 'Full': val('full_p_gain'), 'Calc': val('calc_p_gain'), 'Fwd': val('fwd_p_gain')})\n",
    "#             if not res.benchmark_series.empty:\n",
    "#                 rows.append({'Metric': f'Benchmark ({inputs.benchmark_ticker}) Gain', 'Full': val('full_b_gain'), 'Calc': val('calc_b_gain'), 'Fwd': val('fwd_b_gain')})\n",
    "#                 rows.append({'Metric': '== Gain Delta (vs Bm)', 'Full': val('full_p_gain') - val('full_b_gain'), 'Calc': val('calc_p_gain') - val('calc_b_gain'), 'Fwd': val('fwd_p_gain') - val('fwd_b_gain')})\n",
    "            \n",
    "#             rows.append({'Metric': 'Group Portfolio Sharpe (ATR)', 'Full': val('full_p_sharpe_atr'), 'Calc': val('calc_p_sharpe_atr'), 'Fwd': val('fwd_p_sharpe_atr')})\n",
    "#             if not res.benchmark_series.empty:\n",
    "#                 rows.append({'Metric': f'Benchmark ({inputs.benchmark_ticker}) Sharpe (ATR)', 'Full': val('full_b_sharpe_atr'), 'Calc': val('calc_b_sharpe_atr'), 'Fwd': val('fwd_b_sharpe_atr')})\n",
    "#                 rows.append({'Metric': '== Sharpe (ATR) Delta (vs Bm)', 'Full': val('full_p_sharpe_atr') - val('full_b_sharpe_atr'), 'Calc': val('calc_p_sharpe_atr') - val('calc_b_sharpe_atr'), 'Fwd': val('fwd_p_sharpe_atr') - val('fwd_b_sharpe_atr')})\n",
    "                \n",
    "#             report_df = pd.DataFrame(rows).set_index('Metric')\n",
    "#             print(\"\\n--- Strategy Performance Summary ---\")\n",
    "#             display(report_df.style.format(\"{:+.2%}\", na_rep=\"N/A\"))\n",
    "\n",
    "#     update_button.on_click(update_plot)\n",
    "    \n",
    "#     # Initialize\n",
    "#     update_plot(None)\n",
    "    \n",
    "#     display(ui_container, fig)\n",
    "    \n",
    "#     # --- RETURN THE CAPTURED DATA ---\n",
    "#     return (results_container, debug_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50533b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SECTION C: DATA CONTRACTS (Updated with Debug Fields)\n",
    "# ==============================================================================\n",
    "\n",
    "@dataclass\n",
    "class EngineInput:\n",
    "    \"\"\"Standardized input for the calculation engine.\"\"\"\n",
    "    mode: str\n",
    "    start_date: pd.Timestamp\n",
    "    calc_period: int\n",
    "    fwd_period: int\n",
    "    metric: str\n",
    "    benchmark_ticker: str\n",
    "    \n",
    "    rank_start: int = 1\n",
    "    rank_end: int = 10\n",
    "    quality_thresholds: Dict[str, float] = field(default_factory=lambda: {\n",
    "        'min_median_dollar_volume': 1_000_000, 'max_stale_pct': 0.05, 'max_same_vol_count': 10\n",
    "    })\n",
    "    \n",
    "    manual_tickers: List[str] = field(default_factory=list)\n",
    "    debug: bool = False  # <--- NEW FLAG\n",
    "\n",
    "@dataclass\n",
    "class EngineOutput:\n",
    "    \"\"\"Standardized output returned by the engine.\"\"\"\n",
    "    portfolio_series: pd.Series\n",
    "    benchmark_series: pd.Series\n",
    "    normalized_plot_data: pd.DataFrame\n",
    "    tickers: List[str]\n",
    "    initial_weights: pd.Series\n",
    "    perf_metrics: Dict[str, float]\n",
    "    results_df: pd.DataFrame\n",
    "    calc_end_date: pd.Timestamp\n",
    "    viz_end_date: pd.Timestamp\n",
    "    error_msg: Optional[str] = None\n",
    "    debug_data: Optional[Dict[str, Any]] = None # <--- NEW DATA CONTAINER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e9039df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SECTION D: THE ALPHA ENGINE (Updated to generate Debug Data)\n",
    "# ==============================================================================\n",
    "\n",
    "class AlphaEngine:\n",
    "    def __init__(self, df_ohlcv: pd.DataFrame, master_ticker: str = 'SPY'):\n",
    "        print(\"--- ⚙️ Initializing AlphaEngine ---\")\n",
    "        self.features_df = generate_features(df_ohlcv)\n",
    "        print(\"Optimizing data structures...\")\n",
    "        self.df_close = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "        self.df_high = df_ohlcv['Adj High'].unstack(level=0)\n",
    "        self.df_low = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "        \n",
    "        if master_ticker not in self.df_close.columns:\n",
    "            master_ticker = self.df_close.columns[0]\n",
    "            print(f\"Warning: Master ticker not found. Using {master_ticker}\")\n",
    "            \n",
    "        self.trading_calendar = self.df_close[master_ticker].dropna().index.unique().sort_values()\n",
    "        print(\"✅ AlphaEngine Ready.\")\n",
    "\n",
    "    def run(self, inputs: EngineInput) -> EngineOutput:\n",
    "        # --- A. Validate Dates ---\n",
    "        try:\n",
    "            start_idx = self.trading_calendar.searchsorted(inputs.start_date)\n",
    "            if start_idx < 0: start_idx = 0\n",
    "        except Exception:\n",
    "            return self._error_result(\"Invalid Start Date\")\n",
    "\n",
    "        desired_end_idx = start_idx + inputs.calc_period + inputs.fwd_period\n",
    "        if desired_end_idx >= len(self.trading_calendar):\n",
    "            return self._error_result(f\"Date range exceeds history.\")\n",
    "\n",
    "        safe_start_date = self.trading_calendar[start_idx]\n",
    "        safe_calc_end_date = self.trading_calendar[start_idx + inputs.calc_period]\n",
    "        safe_viz_end_date = self.trading_calendar[start_idx + inputs.calc_period + inputs.fwd_period]\n",
    "\n",
    "        # --- B. Select Tickers ---\n",
    "        tickers_to_trade = []\n",
    "        results_table = pd.DataFrame()\n",
    "        debug_dict = {} # Initialize Debug Container\n",
    "        \n",
    "        if inputs.mode == 'Manual List':\n",
    "            valid = [t for t in inputs.manual_tickers if t in self.df_close.columns]\n",
    "            if not valid: return self._error_result(\"No valid tickers found.\")\n",
    "            tickers_to_trade = valid\n",
    "            results_table = pd.DataFrame(index=valid)\n",
    "            \n",
    "        else: # Ranking Mode\n",
    "            eligible_tickers = self._get_eligible_universe(safe_start_date, inputs.quality_thresholds)\n",
    "            if not eligible_tickers: return self._error_result(\"No tickers passed quality filters.\")\n",
    "            \n",
    "            calc_close = self.df_close.loc[safe_start_date:safe_calc_end_date, eligible_tickers]\n",
    "            \n",
    "            idx_product = pd.MultiIndex.from_product([eligible_tickers, calc_close.index], names=['Ticker', 'Date'])\n",
    "            feat_slice = self.features_df.reindex(idx_product).dropna(how='all')\n",
    "            atrp_mean = feat_slice.groupby(level='Ticker')['ATRP'].mean()\n",
    "            \n",
    "            ingredients = { 'calc_close': calc_close, 'daily_returns': calc_close.pct_change(), 'atrp': atrp_mean }\n",
    "            \n",
    "            if inputs.metric not in METRIC_REGISTRY: return self._error_result(f\"Metric '{inputs.metric}' not found.\")\n",
    "                \n",
    "            metric_vals = METRIC_REGISTRY[inputs.metric](ingredients)\n",
    "            sorted_tickers = metric_vals.sort_values(ascending=False)\n",
    "            \n",
    "            # --- DEBUG: Capture Full Ranking Data ---\n",
    "            if inputs.debug:\n",
    "                debug_dict['ranking_metrics'] = pd.DataFrame({\n",
    "                    'Metric': inputs.metric,\n",
    "                    'Value': sorted_tickers\n",
    "                })\n",
    "\n",
    "            start_r = max(0, inputs.rank_start - 1)\n",
    "            end_r = inputs.rank_end\n",
    "            tickers_to_trade = sorted_tickers.iloc[start_r:end_r].index.tolist()\n",
    "            \n",
    "            if not tickers_to_trade: return self._error_result(\"No tickers generated from ranking.\")\n",
    "\n",
    "            results_table = pd.DataFrame({\n",
    "                'Rank': range(inputs.rank_start, inputs.rank_start + len(tickers_to_trade)),\n",
    "                'Ticker': tickers_to_trade,\n",
    "                'Metric Value': sorted_tickers.loc[tickers_to_trade].values\n",
    "            }).set_index('Ticker')\n",
    "\n",
    "        # --- C. Performance Calculations ---\n",
    "        p_val, p_ret, p_atrp = calculate_buy_and_hold_performance(\n",
    "            self.df_close, self.features_df, tickers_to_trade, safe_start_date, safe_viz_end_date)\n",
    "        \n",
    "        b_val, b_ret, b_atrp = calculate_buy_and_hold_performance(\n",
    "            self.df_close, self.features_df, [inputs.benchmark_ticker], safe_start_date, safe_viz_end_date)\n",
    "\n",
    "        # --- D. Final Metrics ---\n",
    "        plot_data = self.df_close[list(set(tickers_to_trade))].loc[safe_start_date:safe_viz_end_date]\n",
    "        if not plot_data.empty: plot_data = plot_data / plot_data.bfill().iloc[0]\n",
    "\n",
    "        calc_end_ts = safe_calc_end_date\n",
    "        metrics = {}\n",
    "        get_gain = lambda s: (s.iloc[-1] / s.iloc[0]) - 1 if len(s) > 0 else 0\n",
    "\n",
    "        # Portfolio Metrics\n",
    "        metrics['full_p_gain'] = get_gain(p_val)\n",
    "        metrics['calc_p_gain'] = get_gain(p_val.loc[:calc_end_ts])\n",
    "        metrics['fwd_p_gain'] = get_gain(p_val.loc[calc_end_ts:])\n",
    "        \n",
    "        p_ret_calc = p_ret.loc[:calc_end_ts]\n",
    "        p_ret_fwd = p_ret.loc[calc_end_ts:].iloc[1:]\n",
    "        p_atrp_calc = p_atrp.loc[p_ret_calc.index]\n",
    "        p_atrp_fwd = p_atrp.loc[p_ret_fwd.index]\n",
    "        \n",
    "        metrics['full_p_sharpe_atr'] = calculate_sharpe_atr(p_ret, p_atrp)\n",
    "        metrics['calc_p_sharpe_atr'] = calculate_sharpe_atr(p_ret_calc, p_atrp_calc)\n",
    "        metrics['fwd_p_sharpe_atr'] = calculate_sharpe_atr(p_ret_fwd, p_atrp_fwd)\n",
    "        \n",
    "        # Benchmark Metrics\n",
    "        if not b_ret.empty:\n",
    "            metrics['full_b_gain'] = get_gain(b_val)\n",
    "            metrics['calc_b_gain'] = get_gain(b_val.loc[:calc_end_ts])\n",
    "            metrics['fwd_b_gain'] = get_gain(b_val.loc[calc_end_ts:])\n",
    "            \n",
    "            b_ret_calc = b_ret.loc[:calc_end_ts]\n",
    "            b_ret_fwd = b_ret.loc[calc_end_ts:].iloc[1:]\n",
    "            b_atrp_calc = b_atrp.loc[b_ret_calc.index]\n",
    "            b_atrp_fwd = b_atrp.loc[b_ret_fwd.index]\n",
    "            \n",
    "            metrics['full_b_sharpe_atr'] = calculate_sharpe_atr(b_ret, b_atrp)\n",
    "            metrics['calc_b_sharpe_atr'] = calculate_sharpe_atr(b_ret_calc, b_atrp_calc)\n",
    "            metrics['fwd_b_sharpe_atr'] = calculate_sharpe_atr(b_ret_fwd, b_atrp_fwd)\n",
    "\n",
    "        if not plot_data.empty:\n",
    "            step_gains = (plot_data.iloc[-1] / plot_data.loc[calc_end_ts]) - 1\n",
    "            results_table['Fwd Gain'] = step_gains\n",
    "        \n",
    "        ticker_counts = Counter(tickers_to_trade)\n",
    "        weights = pd.Series({t: c/len(tickers_to_trade) for t, c in ticker_counts.items()})\n",
    "\n",
    "        # --- DEBUG: Capture Trace Data ---\n",
    "        if inputs.debug:\n",
    "            trace_df = plot_data.copy()\n",
    "            trace_df.columns = [f'Norm_Price_{c}' for c in trace_df.columns]\n",
    "            trace_df['Norm_Price_Portfolio'] = p_val\n",
    "            if not b_val.empty:\n",
    "                trace_df[f'Norm_Price_Benchmark_{inputs.benchmark_ticker}'] = b_val\n",
    "            debug_dict['portfolio_trace'] = trace_df\n",
    "\n",
    "        return EngineOutput(\n",
    "            portfolio_series=p_val, benchmark_series=b_val, normalized_plot_data=plot_data,\n",
    "            tickers=tickers_to_trade, initial_weights=weights, perf_metrics=metrics,\n",
    "            results_df=results_table, calc_end_date=safe_calc_end_date, viz_end_date=safe_viz_end_date,\n",
    "            debug_data=debug_dict # <--- Return Debug Data\n",
    "        )\n",
    "\n",
    "    def _get_eligible_universe(self, date_ts, thresholds):\n",
    "        avail_dates = self.features_df.index.get_level_values('Date').unique().sort_values()\n",
    "        valid_dates = avail_dates[avail_dates <= date_ts]\n",
    "        if valid_dates.empty: return []\n",
    "        day_features = self.features_df.xs(valid_dates[-1], level='Date')\n",
    "        mask = ((day_features['RollMedDollarVol'] >= thresholds['min_median_dollar_volume']) &\n",
    "                (day_features['RollingStalePct'] <= thresholds['max_stale_pct']) &\n",
    "                (day_features['RollingSameVolCount'] <= thresholds['max_same_vol_count']))\n",
    "        return day_features[mask].index.tolist()\n",
    "\n",
    "    def _error_result(self, msg):\n",
    "        return EngineOutput(pd.Series(dtype=float), pd.Series(dtype=float), pd.DataFrame(), [], pd.Series(dtype=float), {}, pd.DataFrame(), pd.Timestamp.min, pd.Timestamp.min, msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d23c2f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SECTION E: THE UI (Visualization) - FIXED DEBUG RETURN\n",
    "# ==============================================================================\n",
    "\n",
    "def plot_walk_forward_analyzer(df_ohlcv, \n",
    "                               default_start_date='2020-01-01', \n",
    "                               default_calc_period=126, \n",
    "                               default_fwd_period=63,\n",
    "                               default_metric='Sharpe (ATR)', \n",
    "                               default_rank_start=1, \n",
    "                               default_rank_end=10,\n",
    "                               default_benchmark_ticker='SPY', \n",
    "                               master_calendar_ticker='SPY', \n",
    "                               quality_thresholds=None, \n",
    "                               debug=False): # <--- Debug flag passed here\n",
    "    \n",
    "    # 1. Initialize Engine & Containers\n",
    "    engine = AlphaEngine(df_ohlcv, master_ticker=master_calendar_ticker)\n",
    "    \n",
    "    # Mutable containers\n",
    "    results_container = [None]\n",
    "    debug_container = [None] # <--- We will populate this now\n",
    "    \n",
    "    if quality_thresholds is None:\n",
    "        quality_thresholds = {'min_median_dollar_volume': 1_000_000, 'max_stale_pct': 0.05, 'max_same_vol_count': 10}\n",
    "\n",
    "    # --- 2. WIDGET SETUP ---\n",
    "    mode_selector = widgets.RadioButtons(options=['Ranking', 'Manual List'], value='Ranking', description='Portfolio Mode:', layout={'width': 'max-content'})\n",
    "    start_date_picker = widgets.DatePicker(description='Start Date:', value=pd.to_datetime(default_start_date))\n",
    "    calc_period_input = widgets.IntText(value=default_calc_period, description='Calc Period:')\n",
    "    fwd_period_input = widgets.IntText(value=default_fwd_period, description='Fwd Period:')\n",
    "    \n",
    "    metric_dropdown = widgets.Dropdown(options=list(METRIC_REGISTRY.keys()), value=default_metric, description='Metric:')\n",
    "    rank_start_input = widgets.IntText(value=default_rank_start, description='Rank Start:')\n",
    "    rank_end_input = widgets.IntText(value=default_rank_end, description='Rank End:')\n",
    "    \n",
    "    manual_tickers_input = widgets.Textarea(value='', placeholder='Enter tickers, comma-separated...\\ne.g., AAPL, AAPL, MSFT, GOOG', description='Manual Tickers:', layout={'width': '400px', 'height': '80px'})\n",
    "    benchmark_input = widgets.Text(value=default_benchmark_ticker, description='Benchmark:', placeholder='Enter Ticker')\n",
    "    update_button = widgets.Button(description=\"Update Chart\", button_style='primary')\n",
    "    ticker_list_output = widgets.Output()\n",
    "\n",
    "    # --- 3. LAYOUT ASSEMBLY ---\n",
    "    ranking_controls_box = widgets.HBox([metric_dropdown, rank_start_input, rank_end_input])\n",
    "    manual_controls_box = widgets.HBox([manual_tickers_input])\n",
    "    date_controls_row = widgets.HBox([start_date_picker, calc_period_input, fwd_period_input])\n",
    "    bottom_row = widgets.HBox([benchmark_input, update_button])\n",
    "    \n",
    "    def on_mode_change(change):\n",
    "        if change['new'] == 'Ranking':\n",
    "            ranking_controls_box.layout.display = 'flex'\n",
    "            manual_controls_box.layout.display = 'none'\n",
    "        else:\n",
    "            ranking_controls_box.layout.display = 'none'\n",
    "            manual_controls_box.layout.display = 'flex'\n",
    "    mode_selector.observe(on_mode_change, names='value')\n",
    "    on_mode_change({'new': mode_selector.value})\n",
    "\n",
    "    ui_container = widgets.VBox([mode_selector, date_controls_row, ranking_controls_box, manual_controls_box, bottom_row, ticker_list_output], layout=widgets.Layout(margin='10px 0 20px 0'))\n",
    "\n",
    "    # --- 4. FIGURE SETUP ---\n",
    "    fig = go.FigureWidget()\n",
    "    fig.update_layout(title_text='Walk-Forward Performance Analysis', xaxis_title='Date', yaxis_title='Normalized Price', hovermode='x unified', height=600, template=\"plotly_white\")\n",
    "    \n",
    "    colors = ['#1f77b4', '#d62728', '#2ca02c', '#ff7f0e', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "    max_traces = 50\n",
    "    for i in range(max_traces):\n",
    "        fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name=f'placeholder_{i}', visible=False, showlegend=True, opacity=1.0, line=dict(color=colors[i % len(colors)], width=2)))\n",
    "    fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Benchmark', visible=True, showlegend=True, line=dict(color='black', width=3, dash='dash')))\n",
    "    fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Group Portfolio', visible=True, showlegend=True, line=dict(color='green', width=3)))\n",
    "\n",
    "    # --- 5. UPDATE LOGIC ---\n",
    "    def update_plot(b):\n",
    "        ticker_list_output.clear_output()\n",
    "        manual_list = [t.strip().upper() for t in manual_tickers_input.value.split(',') if t.strip()]\n",
    "        start_date_raw = pd.to_datetime(start_date_picker.value)\n",
    "        first_available_date = engine.trading_calendar[0]\n",
    "        \n",
    "        if start_date_raw < (first_available_date - pd.Timedelta(days=7)):\n",
    "            with ticker_list_output:\n",
    "                print(f\"⚠️ DATE WARNING: The requested start date ({start_date_raw.date()}) is unavailable.\")\n",
    "                print(f\"   The Master Calendar Ticker '{master_calendar_ticker}' only starts trading on {first_available_date.date()}.\")\n",
    "                print(f\"   >> Please update the Start Date or choose a Benchmark with longer history.\")\n",
    "                print(f\"   >> Analysis Aborted.\")\n",
    "                print(\"-\" * 60)\n",
    "            return\n",
    "\n",
    "        inputs = EngineInput(\n",
    "            mode=mode_selector.value,\n",
    "            start_date=start_date_raw,\n",
    "            calc_period=calc_period_input.value,\n",
    "            fwd_period=fwd_period_input.value,\n",
    "            metric=metric_dropdown.value,\n",
    "            rank_start=rank_start_input.value,\n",
    "            rank_end=rank_end_input.value,\n",
    "            benchmark_ticker=benchmark_input.value.strip().upper(),\n",
    "            quality_thresholds=quality_thresholds,\n",
    "            manual_tickers=manual_list,\n",
    "            debug=debug # <--- Pass debug flag\n",
    "        )\n",
    "        \n",
    "        with ticker_list_output:\n",
    "            res = engine.run(inputs)\n",
    "            \n",
    "            # --- CAPTURE DATA ---\n",
    "            results_container[0] = res\n",
    "            debug_container[0] = res.debug_data # <--- Capture debug dict\n",
    "            \n",
    "            if res.error_msg: print(f\"Error: {res.error_msg}\"); return\n",
    "\n",
    "            with fig.batch_update():\n",
    "                unique_plot_tickers = res.normalized_plot_data.columns.tolist()\n",
    "                for i in range(max_traces):\n",
    "                    trace = fig.data[i]\n",
    "                    if i < len(unique_plot_tickers):\n",
    "                        t = unique_plot_tickers[i]\n",
    "                        series = res.normalized_plot_data[t]\n",
    "                        trace.x, trace.y, trace.name, trace.visible = series.index, series.values, t, True\n",
    "                    else: trace.visible = False\n",
    "                \n",
    "                bm_trace = fig.data[max_traces]\n",
    "                if not res.benchmark_series.empty: bm_trace.x, bm_trace.y, bm_trace.name, bm_trace.visible = res.benchmark_series.index, res.benchmark_series.values, f\"Benchmark ({inputs.benchmark_ticker})\", True\n",
    "                else: bm_trace.visible = False\n",
    "\n",
    "                port_trace = fig.data[max_traces + 1]\n",
    "                port_trace.x, port_trace.y, port_trace.visible = res.portfolio_series.index, res.portfolio_series.values, True\n",
    "                \n",
    "                fig.layout.shapes = []\n",
    "                fig.add_shape(type=\"line\", x0=res.calc_end_date, y0=0, x1=res.calc_end_date, y1=1, xref='x', yref='paper', line=dict(color=\"grey\", width=2, dash=\"dash\"))\n",
    "\n",
    "            print(f\"Analysis Period: {inputs.start_date.date()} to {res.viz_end_date.date()}.\")\n",
    "            if inputs.mode == 'Ranking': print(\"Ranked Tickers:\"); pprint.pprint(res.tickers)\n",
    "            else: print(\"Manual Portfolio Tickers (Duplicates Increase Weight):\"); pprint.pprint(res.tickers)\n",
    "                \n",
    "            m = res.perf_metrics\n",
    "            def val(k): return m.get(k, np.nan)\n",
    "            \n",
    "            rows = []\n",
    "            rows.append({'Metric': 'Group Portfolio Gain', 'Full': val('full_p_gain'), 'Calc': val('calc_p_gain'), 'Fwd': val('fwd_p_gain')})\n",
    "            if not res.benchmark_series.empty:\n",
    "                rows.append({'Metric': f'Benchmark ({inputs.benchmark_ticker}) Gain', 'Full': val('full_b_gain'), 'Calc': val('calc_b_gain'), 'Fwd': val('fwd_b_gain')})\n",
    "                rows.append({'Metric': '== Gain Delta (vs Bm)', 'Full': val('full_p_gain') - val('full_b_gain'), 'Calc': val('calc_p_gain') - val('calc_b_gain'), 'Fwd': val('fwd_p_gain') - val('fwd_b_gain')})\n",
    "            \n",
    "            rows.append({'Metric': 'Group Portfolio Sharpe (ATR)', 'Full': val('full_p_sharpe_atr'), 'Calc': val('calc_p_sharpe_atr'), 'Fwd': val('fwd_p_sharpe_atr')})\n",
    "            if not res.benchmark_series.empty:\n",
    "                rows.append({'Metric': f'Benchmark ({inputs.benchmark_ticker}) Sharpe (ATR)', 'Full': val('full_b_sharpe_atr'), 'Calc': val('calc_b_sharpe_atr'), 'Fwd': val('fwd_b_sharpe_atr')})\n",
    "                rows.append({'Metric': '== Sharpe (ATR) Delta (vs Bm)', 'Full': val('full_p_sharpe_atr') - val('full_b_sharpe_atr'), 'Calc': val('calc_p_sharpe_atr') - val('calc_b_sharpe_atr'), 'Fwd': val('fwd_p_sharpe_atr') - val('fwd_b_sharpe_atr')})\n",
    "                \n",
    "            report_df = pd.DataFrame(rows).set_index('Metric')\n",
    "            print(\"\\n--- Strategy Performance Summary ---\")\n",
    "            display(report_df.style.format(\"{:+.2%}\", na_rep=\"N/A\"))\n",
    "\n",
    "    update_button.on_click(update_plot)\n",
    "    update_plot(None)\n",
    "    display(ui_container, fig)\n",
    "    return (results_container, debug_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4963462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ⚙️ Initializing AlphaEngine ---\n",
      "--- 1. Generating Features ---\n",
      "Optimizing data structures...\n",
      "✅ AlphaEngine Ready.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c58a7eefa345a387f05ddae0daeabf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(RadioButtons(description='Portfolio Mode:', layout=Layout(width='max-content'), options=('Ranki…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4cd3bf1cb9844f3b4c09dc25038e631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'color': '#1f77b4', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'GBIL',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ff22390d-30c5-4a16-a1e5-d21673e4095f',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.        , 1.00030002, 1.00050003, 1.00050003, 1.00070004,\n",
       "                          1.00070004, 1.00120006, 1.00130007, 1.00150008, 1.00150008, 1.00160009,\n",
       "                          1.00210011, 1.00228093, 1.00248094, 1.00258095])},\n",
       "             {'line': {'color': '#d62728', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'EQX',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a298fba7-d75d-4ffc-8b08-d19a322b1331',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.15169367, 1.17525773, 1.17378498, 1.11192931, 1.14138439,\n",
       "                          1.1634757 , 1.18114875, 1.18998527, 1.21207658, 1.20765832, 1.2179676 ,\n",
       "                          1.29013255, 1.3460972 , 1.34167894, 1.32106038])},\n",
       "             {'line': {'color': '#2ca02c', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_2',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '7c3c873b-4e80-47f2-ae5e-23c01d1ae86e',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#ff7f0e', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_3',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '320c8e64-61e1-4646-9a05-eaaea43c7350',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#9467bd', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_4',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'dc8ea919-bcd3-42a0-a537-797b22bedd67',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#8c564b', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_5',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '21401a13-fb78-4b9e-9aa4-913d1fa045f7',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#e377c2', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_6',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '7a52dfe5-c577-43c3-9f5a-2486927ff54c',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#7f7f7f', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_7',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '1cb3c774-e099-452e-b534-a9d255f4c0d4',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#bcbd22', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_8',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a546421b-6ae7-4d4d-9f65-179ac7b9206c',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#17becf', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_9',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '79a55f74-df2d-446f-9e8d-78981ffdde8a',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#1f77b4', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_10',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '1a16beba-d1e8-41b9-b44b-f74c2b3e1796',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#d62728', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_11',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ed988b3a-3485-45f6-8051-5402ab7e7712',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#2ca02c', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_12',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'acea6174-86de-403b-963b-34e6f34b2238',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#ff7f0e', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_13',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f68173f5-337c-4de0-a5ff-0f41d7b19564',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#9467bd', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_14',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'fbe11612-fb75-4dcb-bb5c-f8ed6674772e',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#8c564b', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_15',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'bf11c70c-0a86-4f4b-9609-a5267d860e99',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#e377c2', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_16',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '5091e239-846c-4ace-b3f9-0c145a079044',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#7f7f7f', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_17',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a7dc4cd4-72ed-43fb-bb08-d1ab1e7261ad',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#bcbd22', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_18',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'cc3f69f6-bcca-491d-b6a4-4bcb147cf4ac',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#17becf', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_19',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'de803cea-58d4-44e9-9345-7b8e7cc6ea13',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#1f77b4', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_20',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '797010cb-f614-4926-82b2-ca211198a9f4',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#d62728', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_21',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '6ecee71c-ec80-480a-b289-0c2017655936',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#2ca02c', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_22',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '14381bcb-18c5-4578-9141-cf7299d6f9a9',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#ff7f0e', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_23',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '245cb645-9772-426e-8a5f-91242f63aafd',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#9467bd', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_24',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4ebf1ac2-5cd3-4720-ab01-1fe84bb893af',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#8c564b', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_25',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '528b19e6-928f-46f4-bb4f-4200e9077012',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#e377c2', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_26',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '177d3d50-79ae-4907-8f9e-b524e5ecfc13',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#7f7f7f', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_27',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4fb4fbdf-742c-4963-a5d5-f935a39d29c6',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#bcbd22', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_28',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4fdef0eb-c3aa-45d2-86c5-00357709734a',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#17becf', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_29',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '45145df2-d7b7-4801-a828-ae2877b586e5',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#1f77b4', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_30',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a71ff233-609c-4d4e-985f-db66f9e51d44',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#d62728', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_31',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '0043b84f-8b5a-428e-be9b-415f94d6d7db',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#2ca02c', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_32',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4a7776ee-7bf4-4656-bcb3-c0dd49d6624f',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#ff7f0e', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_33',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '0e35fcb6-3995-476f-830a-89a477c3b936',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#9467bd', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_34',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'edb347fe-ba9d-4e6d-bbd0-383291038d82',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#8c564b', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_35',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '9f0e3c1c-cf3d-4980-93cb-11eb6b81dc47',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#e377c2', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_36',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '9ba33906-68ec-423d-8511-083997a41015',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#7f7f7f', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_37',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a8cf19ee-f674-4629-9713-afa358c81b8c',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#bcbd22', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_38',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4f4b25dc-2a4c-421b-ad84-102437e68363',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#17becf', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_39',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '01377d1b-293d-4674-a191-151526bcf71b',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#1f77b4', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_40',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ca448df9-44d5-4075-b430-9579002c4d2b',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#d62728', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_41',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '07c6ad74-76e1-479f-961c-8c4e3bb0725e',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#2ca02c', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_42',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '54cada6b-f2c3-4679-9ac1-ff5ec14cf0bf',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#ff7f0e', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_43',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c2959b3b-9a64-466e-921a-89dd08b358fb',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#9467bd', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_44',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '94c78198-d9b0-4438-b73a-3909e447d05c',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#8c564b', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_45',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '3917fc29-78fe-4e1a-8cd5-42f471094e6b',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#e377c2', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_46',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c7bd6dd2-12dc-4088-953f-09a59a9d20ad',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#7f7f7f', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_47',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '97593c38-f0e0-4a87-8248-21d084f573fc',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#bcbd22', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_48',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '0815b51e-fcd8-46ad-810d-ef1efada9cb0',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#17becf', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_49',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '67936b16-1d21-463a-941c-d507db7ccd2a',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': 'black', 'dash': 'dash', 'width': 3},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Benchmark (VOO)',\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '739300c1-ca2f-4dee-8a8e-e918bdced157',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00001692, 0.99785841, 0.99750486, 0.99205615, 0.9894409 ,\n",
       "                          0.9855451 , 1.00062421, 0.99639177, 1.00037216, 1.00266599, 1.00620825,\n",
       "                          1.00040599, 0.99303391, 0.99811215, 1.00632666])},\n",
       "             {'line': {'color': 'green', 'width': 3},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Group Portfolio',\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '98fdb3e1-cbe7-478d-9111-3e6a99fa4b18',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.07584683, 1.08777887, 1.0871425 , 1.05621467, 1.07104221,\n",
       "                          1.08208787, 1.09117441, 1.09564267, 1.10678833, 1.1045792 , 1.10978384,\n",
       "                          1.14611633, 1.17418907, 1.17207994, 1.16182066])}],\n",
       "    'layout': {'height': 600,\n",
       "               'hovermode': 'x unified',\n",
       "               'shapes': [{'line': {'color': 'grey', 'dash': 'dash', 'width': 2},\n",
       "                           'type': 'line',\n",
       "                           'x0': Timestamp('2025-08-27 00:00:00'),\n",
       "                           'x1': Timestamp('2025-08-27 00:00:00'),\n",
       "                           'xref': 'x',\n",
       "                           'y0': 0,\n",
       "                           'y1': 1,\n",
       "                           'yref': 'paper'}],\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Walk-Forward Performance Analysis'},\n",
       "               'xaxis': {'title': {'text': 'Date'}},\n",
       "               'yaxis': {'title': {'text': 'Normalized Price'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_container, debug_container = plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    default_start_date='2025-08-13',\n",
    "    default_calc_period=10,\n",
    "    default_fwd_period=5,\n",
    "    default_metric='Sharpe (ATR)',\n",
    "    default_rank_start=15,\n",
    "    default_rank_end=16,\n",
    "    default_benchmark_ticker='VOO', \n",
    "    master_calendar_ticker='VOO',\n",
    "    quality_thresholds={ 'min_median_dollar_volume': 10_000_000, \n",
    "                         'max_stale_pct': 0.05, \n",
    "                         'max_same_vol_count': 1 },\n",
    "    debug=True  # <-- Activate the new mode!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "287bfc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EngineOutput(portfolio_series=Date\n",
      "2025-08-13    1.000000\n",
      "2025-08-14    1.075847\n",
      "2025-08-15    1.087779\n",
      "2025-08-18    1.087143\n",
      "2025-08-19    1.056215\n",
      "2025-08-20    1.071042\n",
      "2025-08-21    1.082088\n",
      "2025-08-22    1.091174\n",
      "2025-08-25    1.095643\n",
      "2025-08-26    1.106788\n",
      "2025-08-27    1.104579\n",
      "2025-08-28    1.109784\n",
      "2025-08-29    1.146116\n",
      "2025-09-02    1.174189\n",
      "2025-09-03    1.172080\n",
      "2025-09-04    1.161821\n",
      "dtype: float64, benchmark_series=Date\n",
      "2025-08-13    1.000000\n",
      "2025-08-14    1.000017\n",
      "2025-08-15    0.997858\n",
      "2025-08-18    0.997505\n",
      "2025-08-19    0.992056\n",
      "2025-08-20    0.989441\n",
      "2025-08-21    0.985545\n",
      "2025-08-22    1.000624\n",
      "2025-08-25    0.996392\n",
      "2025-08-26    1.000372\n",
      "2025-08-27    1.002666\n",
      "2025-08-28    1.006208\n",
      "2025-08-29    1.000406\n",
      "2025-09-02    0.993034\n",
      "2025-09-03    0.998112\n",
      "2025-09-04    1.006327\n",
      "dtype: float64, normalized_plot_data=Ticker          GBIL       EQX\n",
      "Date                          \n",
      "2025-08-13  1.000000  1.000000\n",
      "2025-08-14  1.000000  1.151694\n",
      "2025-08-15  1.000300  1.175258\n",
      "2025-08-18  1.000500  1.173785\n",
      "2025-08-19  1.000500  1.111929\n",
      "2025-08-20  1.000700  1.141384\n",
      "2025-08-21  1.000700  1.163476\n",
      "2025-08-22  1.001200  1.181149\n",
      "2025-08-25  1.001300  1.189985\n",
      "2025-08-26  1.001500  1.212077\n",
      "2025-08-27  1.001500  1.207658\n",
      "2025-08-28  1.001600  1.217968\n",
      "2025-08-29  1.002100  1.290133\n",
      "2025-09-02  1.002281  1.346097\n",
      "2025-09-03  1.002481  1.341679\n",
      "2025-09-04  1.002581  1.321060, tickers=['GBIL', 'EQX'], initial_weights=GBIL    0.5\n",
      "EQX     0.5\n",
      "dtype: float64, perf_metrics={'full_p_gain': 0.16182066458436584, 'calc_p_gain': 0.10457920068385618, 'fwd_p_gain': 0.05182196429651298, 'full_p_sharpe_atr': 0.5219984867479507, 'calc_p_sharpe_atr': 0.5110672580590098, 'fwd_p_sharpe_atr': 0.5478601646084086, 'full_b_gain': 0.006326662144400252, 'calc_b_gain': 0.0026659945292981657, 'fwd_b_gain': 0.0036509342443797888, 'full_b_sharpe_atr': 0.0528966520257708, 'calc_b_sharpe_atr': 0.03398602551802087, 'fwd_b_sharpe_atr': 0.09134836268480385}, results_df=        Rank  Metric Value  Fwd Gain\n",
      "Ticker                              \n",
      "GBIL      15      0.548543  0.001079\n",
      "EQX       16      0.539618  0.093902, calc_end_date=Timestamp('2025-08-27 00:00:00'), viz_end_date=Timestamp('2025-09-04 00:00:00'), error_msg=None, debug_data={'ranking_metrics':               Metric     Value\n",
      "Ticker                        \n",
      "SATS    Sharpe (ATR)  1.792274\n",
      "BNS     Sharpe (ATR)  1.002147\n",
      "MDB     Sharpe (ATR)  0.845548\n",
      "DAY     Sharpe (ATR)  0.775484\n",
      "SGOV    Sharpe (ATR)  0.746773\n",
      "...              ...       ...\n",
      "CSX     Sharpe (ATR) -0.412306\n",
      "ETSY    Sharpe (ATR) -0.520781\n",
      "AMCR    Sharpe (ATR) -0.542259\n",
      "GGAL    Sharpe (ATR) -0.579082\n",
      "KDP     Sharpe (ATR) -0.748876\n",
      "\n",
      "[1550 rows x 2 columns], 'portfolio_trace':             Norm_Price_GBIL  Norm_Price_EQX  Norm_Price_Portfolio  \\\n",
      "Date                                                                \n",
      "2025-08-13         1.000000        1.000000              1.000000   \n",
      "2025-08-14         1.000000        1.151694              1.075847   \n",
      "2025-08-15         1.000300        1.175258              1.087779   \n",
      "2025-08-18         1.000500        1.173785              1.087143   \n",
      "2025-08-19         1.000500        1.111929              1.056215   \n",
      "2025-08-20         1.000700        1.141384              1.071042   \n",
      "2025-08-21         1.000700        1.163476              1.082088   \n",
      "2025-08-22         1.001200        1.181149              1.091174   \n",
      "2025-08-25         1.001300        1.189985              1.095643   \n",
      "2025-08-26         1.001500        1.212077              1.106788   \n",
      "2025-08-27         1.001500        1.207658              1.104579   \n",
      "2025-08-28         1.001600        1.217968              1.109784   \n",
      "2025-08-29         1.002100        1.290133              1.146116   \n",
      "2025-09-02         1.002281        1.346097              1.174189   \n",
      "2025-09-03         1.002481        1.341679              1.172080   \n",
      "2025-09-04         1.002581        1.321060              1.161821   \n",
      "\n",
      "            Norm_Price_Benchmark_VOO  \n",
      "Date                                  \n",
      "2025-08-13                  1.000000  \n",
      "2025-08-14                  1.000017  \n",
      "2025-08-15                  0.997858  \n",
      "2025-08-18                  0.997505  \n",
      "2025-08-19                  0.992056  \n",
      "2025-08-20                  0.989441  \n",
      "2025-08-21                  0.985545  \n",
      "2025-08-22                  1.000624  \n",
      "2025-08-25                  0.996392  \n",
      "2025-08-26                  1.000372  \n",
      "2025-08-27                  1.002666  \n",
      "2025-08-28                  1.006208  \n",
      "2025-08-29                  1.000406  \n",
      "2025-09-02                  0.993034  \n",
      "2025-09-03                  0.998112  \n",
      "2025-09-04                  1.006327  })\n",
      "====================\n",
      "ranking_metrics:\n",
      "                  Metric     Value\n",
      "Ticker                        \n",
      "SATS    Sharpe (ATR)  1.792274\n",
      "BNS     Sharpe (ATR)  1.002147\n",
      "MDB     Sharpe (ATR)  0.845548\n",
      "DAY     Sharpe (ATR)  0.775484\n",
      "SGOV    Sharpe (ATR)  0.746773\n",
      "...              ...       ...\n",
      "CSX     Sharpe (ATR) -0.412306\n",
      "ETSY    Sharpe (ATR) -0.520781\n",
      "AMCR    Sharpe (ATR) -0.542259\n",
      "GGAL    Sharpe (ATR) -0.579082\n",
      "KDP     Sharpe (ATR) -0.748876\n",
      "\n",
      "[1550 rows x 2 columns]\n",
      "portfolio_trace:\n",
      "                Norm_Price_GBIL  Norm_Price_EQX  Norm_Price_Portfolio  \\\n",
      "Date                                                                \n",
      "2025-08-13         1.000000        1.000000              1.000000   \n",
      "2025-08-14         1.000000        1.151694              1.075847   \n",
      "2025-08-15         1.000300        1.175258              1.087779   \n",
      "2025-08-18         1.000500        1.173785              1.087143   \n",
      "2025-08-19         1.000500        1.111929              1.056215   \n",
      "2025-08-20         1.000700        1.141384              1.071042   \n",
      "2025-08-21         1.000700        1.163476              1.082088   \n",
      "2025-08-22         1.001200        1.181149              1.091174   \n",
      "2025-08-25         1.001300        1.189985              1.095643   \n",
      "2025-08-26         1.001500        1.212077              1.106788   \n",
      "2025-08-27         1.001500        1.207658              1.104579   \n",
      "2025-08-28         1.001600        1.217968              1.109784   \n",
      "2025-08-29         1.002100        1.290133              1.146116   \n",
      "2025-09-02         1.002281        1.346097              1.174189   \n",
      "2025-09-03         1.002481        1.341679              1.172080   \n",
      "2025-09-04         1.002581        1.321060              1.161821   \n",
      "\n",
      "            Norm_Price_Benchmark_VOO  \n",
      "Date                                  \n",
      "2025-08-13                  1.000000  \n",
      "2025-08-14                  1.000017  \n",
      "2025-08-15                  0.997858  \n",
      "2025-08-18                  0.997505  \n",
      "2025-08-19                  0.992056  \n",
      "2025-08-20                  0.989441  \n",
      "2025-08-21                  0.985545  \n",
      "2025-08-22                  1.000624  \n",
      "2025-08-25                  0.996392  \n",
      "2025-08-26                  1.000372  \n",
      "2025-08-27                  1.002666  \n",
      "2025-08-28                  1.006208  \n",
      "2025-08-29                  1.000406  \n",
      "2025-09-02                  0.993034  \n",
      "2025-09-03                  0.998112  \n",
      "2025-09-04                  1.006327  \n"
     ]
    }
   ],
   "source": [
    "print_nested(results_container)\n",
    "print('='*20)\n",
    "print_nested(debug_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1276510d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969da7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119c3254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "97b963c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ⚙️ Initializing AlphaEngine ---\n",
      "--- 1. Generating Features ---\n",
      "Optimizing data structures...\n",
      "✅ AlphaEngine Ready.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "245db800e49c4b46ab8d131250b3772b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(RadioButtons(description='Portfolio Mode:', layout=Layout(width='max-content'), options=('Ranki…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "797a7316b10e4b93baf27e787c2f16b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'color': '#1f77b4', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'GBIL',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c1cb0f93-2df4-47c5-9454-4dca0c02c62e',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.        , 1.00030002, 1.00050003, 1.00050003, 1.00070004,\n",
       "                          1.00070004, 1.00120006, 1.00130007, 1.00150008, 1.00150008, 1.00160009,\n",
       "                          1.00210011, 1.00228093, 1.00248094, 1.00258095])},\n",
       "             {'line': {'color': '#d62728', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'EQX',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4b63259d-494d-448d-9c7a-5ecb421d5c6d',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.15169367, 1.17525773, 1.17378498, 1.11192931, 1.14138439,\n",
       "                          1.1634757 , 1.18114875, 1.18998527, 1.21207658, 1.20765832, 1.2179676 ,\n",
       "                          1.29013255, 1.3460972 , 1.34167894, 1.32106038])},\n",
       "             {'line': {'color': '#2ca02c', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_2',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '210ab7cf-be62-4029-a1b0-66961a6e6f5e',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#ff7f0e', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_3',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'eb21be3a-e072-4840-aa68-fc05f668d00a',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#9467bd', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_4',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '45015dfd-dd75-4763-81a7-51b4f8dbc579',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#8c564b', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_5',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '96efe241-fbbf-43ce-982f-5d775960f938',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#e377c2', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_6',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'fc4ef527-b5f2-4baa-9c21-2f9a1307912e',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#7f7f7f', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_7',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '8db8b552-8e0f-4e50-ac6f-c4335d3001e4',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#bcbd22', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_8',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '9fb329a7-26c9-4007-971c-11f18f42996a',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#17becf', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_9',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'cd4955dc-611d-44ce-bf90-d32cbba986a2',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#1f77b4', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_10',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4b3a80b1-abd5-4120-a503-0a9def0a6f22',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#d62728', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_11',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '6cdcc6f7-1335-4690-a705-7916208f7ed6',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#2ca02c', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_12',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '2bbebcaf-7eae-468a-94c4-e3ff08d8aeb4',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#ff7f0e', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_13',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '2339314d-85b9-4f5b-a50e-566b0df596e5',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#9467bd', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_14',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '9dda8552-189a-469b-a29b-0d8a92e94c96',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#8c564b', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_15',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '126773d7-27e9-4214-a500-169bac2034bb',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#e377c2', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_16',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '5151921f-cfb1-45d0-a3e9-fb11de9d95cf',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#7f7f7f', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_17',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '85bcb68c-d8e8-4ea5-997a-15db9e1a17bd',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#bcbd22', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_18',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '90b003a6-887b-407a-b76a-2dd1974da018',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#17becf', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_19',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '70a9f2f9-b42f-46a0-b979-8c7d852694da',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#1f77b4', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_20',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '7ed993ab-d592-4fd2-b480-668810419dc7',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#d62728', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_21',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4a5710fc-ce3d-45fb-80b1-6f952a0813c4',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#2ca02c', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_22',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e4ba7ebe-0e17-498c-8a18-beaaf6d10bee',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#ff7f0e', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_23',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '95b9f025-4dc9-4eb1-815a-9923a32f3a79',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#9467bd', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_24',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '7fdc8257-9bee-46a0-9c58-9eada8a81487',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#8c564b', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_25',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '71529c3d-4656-47f9-a47e-2e5b9b7eb977',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#e377c2', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_26',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '85dcdb20-52ab-4fbc-b429-64aa61453549',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#7f7f7f', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_27',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b88004d5-3485-4520-b976-211604e0435e',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#bcbd22', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_28',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '8e9fdd7c-8644-447b-98dc-b59b84345d25',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#17becf', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_29',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ef4245ef-04fb-4f8d-a913-19f21d0e2bca',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#1f77b4', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_30',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '1fca86a1-c379-40b6-9302-ae168ca5b84c',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#d62728', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_31',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '985e24a6-b5d6-44e3-a288-8f26fcecd1c5',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#2ca02c', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_32',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'bd04166f-cd5f-44b5-a2dd-3275e93d8dbc',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#ff7f0e', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_33',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'db124742-e160-4ed2-bdb4-579a5b86b6fe',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#9467bd', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_34',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '532a8f43-8154-4465-bc8b-8d173317d98a',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#8c564b', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_35',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '6d4bca3d-62fe-43f4-9841-4ebce712b43d',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#e377c2', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_36',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '156816d9-bb2b-4fcd-a21e-9fde6110460f',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#7f7f7f', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_37',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a4b78145-1e56-4b92-a3de-a575c320c1c2',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#bcbd22', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_38',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '2a3b9313-88e9-422d-9afe-63964dfc582e',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#17becf', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_39',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'bcbb6bdb-2f35-46fa-bf68-ddb86466ac4b',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#1f77b4', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_40',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '32a87c26-0902-4b5e-ab5e-30af64405a19',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#d62728', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_41',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '0b3eeebc-b7de-4f15-bae7-c0d106d8fbe1',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#2ca02c', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_42',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '64a1f500-f373-4081-aab5-ae29a2974d0d',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#ff7f0e', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_43',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '9d004f1f-ba10-4ac8-8c56-6e31f910281d',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#9467bd', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_44',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '34e72c71-622a-4363-9cbd-6aaf1a0686c6',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#8c564b', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_45',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'dd471f4d-930e-4892-b794-ea8c856eeb6e',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#e377c2', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_46',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b6cdfe36-b44d-463f-9696-610df97be160',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#7f7f7f', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_47',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '71282dc7-0317-426e-becd-a0f96356aec3',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#bcbd22', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_48',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '295f39b1-ef2f-4028-b335-fb64b90d0b58',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#17becf', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_49',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '641a1a24-b027-469a-beb1-8b4935610801',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': 'black', 'dash': 'dash', 'width': 3},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Benchmark (VOO)',\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '53c21f32-b2e0-436e-ba4c-76c59c45f817',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00001692, 0.99785841, 0.99750486, 0.99205615, 0.9894409 ,\n",
       "                          0.9855451 , 1.00062421, 0.99639177, 1.00037216, 1.00266599, 1.00620825,\n",
       "                          1.00040599, 0.99303391, 0.99811215, 1.00632666])},\n",
       "             {'line': {'color': 'green', 'width': 3},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Group Portfolio',\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4c7415aa-9157-4060-85db-97a676060812',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.07584683, 1.08777887, 1.0871425 , 1.05621467, 1.07104221,\n",
       "                          1.08208787, 1.09117441, 1.09564267, 1.10678833, 1.1045792 , 1.10978384,\n",
       "                          1.14611633, 1.17418907, 1.17207994, 1.16182066])}],\n",
       "    'layout': {'height': 600,\n",
       "               'hovermode': 'x unified',\n",
       "               'shapes': [{'line': {'color': 'grey', 'dash': 'dash', 'width': 2},\n",
       "                           'type': 'line',\n",
       "                           'x0': Timestamp('2025-08-27 00:00:00'),\n",
       "                           'x1': Timestamp('2025-08-27 00:00:00'),\n",
       "                           'xref': 'x',\n",
       "                           'y0': 0,\n",
       "                           'y1': 1,\n",
       "                           'yref': 'paper'}],\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Walk-Forward Performance Analysis'},\n",
       "               'xaxis': {'title': {'text': 'Date'}},\n",
       "               'yaxis': {'title': {'text': 'Normalized Price'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_container, debug_container = plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    default_start_date='2025-08-13',\n",
    "    default_calc_period=10,\n",
    "    default_fwd_period=5,\n",
    "    default_metric='Sharpe (ATR)',\n",
    "    default_rank_start=15,\n",
    "    default_rank_end=16,\n",
    "    default_benchmark_ticker='VOO', \n",
    "    master_calendar_ticker='VOO',\n",
    "    quality_thresholds={ 'min_median_dollar_volume': 10_000_000, \n",
    "                         'max_stale_pct': 0.05, \n",
    "                         'max_same_vol_count': 1 },\n",
    "    debug=True  # <-- Activate the new mode!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d084c783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ⚙️ Initializing AlphaEngine ---\n",
      "--- 1. Generating Features ---\n",
      "Optimizing data structures...\n",
      "✅ AlphaEngine Ready.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c5c0809dbb414b821371476ea7e178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(RadioButtons(description='Portfolio Mode:', layout=Layout(width='max-content'), options=('Ranki…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b668cf3f4a4440b79eda1b450e695063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'color': '#1f77b4', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'GBIL',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e6699d73-cf98-4bb5-98a0-da668addfdf7',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.        , 1.00030002, 1.00050003, 1.00050003, 1.00070004,\n",
       "                          1.00070004, 1.00120006, 1.00130007, 1.00150008, 1.00150008, 1.00160009,\n",
       "                          1.00210011, 1.00228093, 1.00248094, 1.00258095])},\n",
       "             {'line': {'color': '#d62728', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'EQX',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '58e38892-45da-4b23-9141-c21f1f64f6b9',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.15169367, 1.17525773, 1.17378498, 1.11192931, 1.14138439,\n",
       "                          1.1634757 , 1.18114875, 1.18998527, 1.21207658, 1.20765832, 1.2179676 ,\n",
       "                          1.29013255, 1.3460972 , 1.34167894, 1.32106038])},\n",
       "             {'line': {'color': '#2ca02c', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_2',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'fa0be11c-2aff-4eac-bc4a-f3eb075405ac',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#ff7f0e', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_3',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '614e1f7d-5a97-4ace-b009-98f955f37807',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#9467bd', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_4',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '0ebb70eb-fa63-4341-bc86-77740e0073ee',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#8c564b', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_5',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4bf6461e-df37-4daf-b129-17badf11dd38',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#e377c2', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_6',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '3e267401-6ecf-4a55-9184-d155506fe0dc',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#7f7f7f', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_7',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b61f6649-ae9b-40a1-bdd4-d21df223830a',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#bcbd22', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_8',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '7357229c-6a1c-44b0-b099-ba8321c2e3e8',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#17becf', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_9',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '1b6adc58-06d3-492d-9bb5-bad9d2ace167',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#1f77b4', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_10',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '83933cce-501d-4d0b-94bd-c2cafbc0760c',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#d62728', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_11',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd422c576-90ee-46ed-ad76-d75d646fa8cf',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#2ca02c', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_12',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '3bc01635-5259-46f2-a3ef-4d81a3b22126',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#ff7f0e', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_13',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'befd0816-7d93-401a-abbb-ff4290c6d1ef',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#9467bd', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_14',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '115de0a2-d43f-478f-afe1-b2ae220069a6',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#8c564b', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_15',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '2588b6c3-7f2d-4305-84d2-1a13c985b18b',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#e377c2', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_16',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c743a5eb-b719-481e-8490-6a9c00084bbe',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#7f7f7f', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_17',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '6cc0d9eb-66fb-43b5-9a11-b23963bfb4fa',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#bcbd22', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_18',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '04377f2a-e6fe-40ca-8407-70433aac0cee',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#17becf', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_19',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '80063d14-f954-46ad-871c-623456981e43',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#1f77b4', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_20',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '71cd87e6-37ef-4885-a06f-13a716f9eaa0',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#d62728', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_21',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '06485dcd-34f0-4119-a156-3205617aa18f',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#2ca02c', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_22',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e0ddb6e6-cd06-4783-ab28-11a2f0aa4b32',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#ff7f0e', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_23',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '2aa35179-e72c-4138-853d-67ace3a09035',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#9467bd', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_24',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '7fd0cc16-db94-429c-a75e-2691d823ee9d',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#8c564b', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_25',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'fccb7b3e-2954-4159-a2f8-2184ea2d9877',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#e377c2', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_26',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '0020bc53-93aa-488a-8e4a-eacec75013cf',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#7f7f7f', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_27',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '68b92344-9f51-4807-95b4-fe5d34b9bc90',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#bcbd22', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_28',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'aeed59e9-f9c0-48ee-ad1a-9c7baafa26cb',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#17becf', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_29',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '1f008e5e-9893-4b93-883b-a67c9426585b',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#1f77b4', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_30',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '237e2868-79da-4192-af1d-07c3451331b3',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#d62728', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_31',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '7e460940-c08a-4ceb-9db3-a4052d5cc38a',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#2ca02c', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_32',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '8afdb7de-306a-4d9b-923a-4fc64fbf1301',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#ff7f0e', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_33',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a2636de1-e4ab-4cc4-9f40-3f8faf9d4464',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#9467bd', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_34',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '6f6b3b10-35d6-49ca-961d-18af5c5817ad',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#8c564b', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_35',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '8bac2949-0523-41f0-9799-c960021ef98f',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#e377c2', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_36',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c1f3ff38-2324-496f-9af0-6683bbd69e3e',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#7f7f7f', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_37',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e55a0fed-89e7-4b4a-abc5-729fc22310d0',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#bcbd22', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_38',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4b3e3ced-6e06-4a26-adb1-e7097dd9002f',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#17becf', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_39',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4216abf1-a775-4600-b294-9d4afc2d3db1',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#1f77b4', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_40',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ed29c48f-c639-4757-b08d-0c11600556d7',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#d62728', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_41',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c1d1fee8-67dd-4421-9b6a-2e68a6a47e7c',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#2ca02c', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_42',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '332c3632-8c3e-4a34-b563-a198c4e92594',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#ff7f0e', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_43',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'bfe46866-412b-4c1e-a59d-333d44644b62',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#9467bd', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_44',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '3d5d0b16-0999-487b-8566-bf40b8c37d2a',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#8c564b', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_45',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ae2c0e44-1df5-451e-a153-e1022b2c83fe',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#e377c2', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_46',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '61776442-bc0e-4ed6-94b0-9b220f455b64',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#7f7f7f', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_47',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '23c4dde3-fbff-4174-9001-1d874b0372fa',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#bcbd22', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_48',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '878c4a22-0f61-4c86-a2c9-0189c752c0da',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#17becf', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_49',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a563bd5c-26e6-46a4-bf7d-9fe294913532',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': 'black', 'dash': 'dash', 'width': 3},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Benchmark (VOO)',\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '41ab5816-bff7-464d-af3b-3ec6454d9901',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00001692, 0.99785841, 0.99750486, 0.99205615, 0.9894409 ,\n",
       "                          0.9855451 , 1.00062421, 0.99639177, 1.00037216, 1.00266599, 1.00620825,\n",
       "                          1.00040599, 0.99303391, 0.99811215, 1.00632666])},\n",
       "             {'line': {'color': 'green', 'width': 3},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Group Portfolio',\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '39a00e0b-9728-4177-a7fe-7e6a27de9589',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.07584683, 1.08777887, 1.0871425 , 1.05621467, 1.07104221,\n",
       "                          1.08208787, 1.09117441, 1.09564267, 1.10678833, 1.1045792 , 1.10978384,\n",
       "                          1.14611633, 1.17418907, 1.17207994, 1.16182066])}],\n",
       "    'layout': {'height': 600,\n",
       "               'hovermode': 'x unified',\n",
       "               'shapes': [{'line': {'color': 'grey', 'dash': 'dash', 'width': 2},\n",
       "                           'type': 'line',\n",
       "                           'x0': Timestamp('2025-08-27 00:00:00'),\n",
       "                           'x1': Timestamp('2025-08-27 00:00:00'),\n",
       "                           'xref': 'x',\n",
       "                           'y0': 0,\n",
       "                           'y1': 1,\n",
       "                           'yref': 'paper'}],\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Walk-Forward Performance Analysis'},\n",
       "               'xaxis': {'title': {'text': 'Date'}},\n",
       "               'yaxis': {'title': {'text': 'Normalized Price'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_container, debug_container = plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    default_start_date='2025-08-13',\n",
    "    default_calc_period=10,\n",
    "    default_fwd_period=5,\n",
    "    default_metric='Sharpe (ATR)',\n",
    "    default_rank_start=15,\n",
    "    default_rank_end=16,\n",
    "    default_benchmark_ticker='VOO', \n",
    "    master_calendar_ticker='VOO',\n",
    "    quality_thresholds={ 'min_median_dollar_volume': 10_000_000, \n",
    "                         'max_stale_pct': 0.05, \n",
    "                         'max_same_vol_count': 1 },\n",
    "    debug=True  # <-- Activate the new mode!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5269f794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EngineOutput(portfolio_series=Date\n",
      "2025-08-13    1.000000\n",
      "2025-08-14    1.075847\n",
      "2025-08-15    1.087779\n",
      "2025-08-18    1.087143\n",
      "2025-08-19    1.056215\n",
      "2025-08-20    1.071042\n",
      "2025-08-21    1.082088\n",
      "2025-08-22    1.091174\n",
      "2025-08-25    1.095643\n",
      "2025-08-26    1.106788\n",
      "2025-08-27    1.104579\n",
      "2025-08-28    1.109784\n",
      "2025-08-29    1.146116\n",
      "2025-09-02    1.174189\n",
      "2025-09-03    1.172080\n",
      "2025-09-04    1.161821\n",
      "dtype: float64, benchmark_series=Date\n",
      "2025-08-13    1.000000\n",
      "2025-08-14    1.000017\n",
      "2025-08-15    0.997858\n",
      "2025-08-18    0.997505\n",
      "2025-08-19    0.992056\n",
      "2025-08-20    0.989441\n",
      "2025-08-21    0.985545\n",
      "2025-08-22    1.000624\n",
      "2025-08-25    0.996392\n",
      "2025-08-26    1.000372\n",
      "2025-08-27    1.002666\n",
      "2025-08-28    1.006208\n",
      "2025-08-29    1.000406\n",
      "2025-09-02    0.993034\n",
      "2025-09-03    0.998112\n",
      "2025-09-04    1.006327\n",
      "dtype: float64, normalized_plot_data=Ticker          GBIL       EQX\n",
      "Date                          \n",
      "2025-08-13  1.000000  1.000000\n",
      "2025-08-14  1.000000  1.151694\n",
      "2025-08-15  1.000300  1.175258\n",
      "2025-08-18  1.000500  1.173785\n",
      "2025-08-19  1.000500  1.111929\n",
      "2025-08-20  1.000700  1.141384\n",
      "2025-08-21  1.000700  1.163476\n",
      "2025-08-22  1.001200  1.181149\n",
      "2025-08-25  1.001300  1.189985\n",
      "2025-08-26  1.001500  1.212077\n",
      "2025-08-27  1.001500  1.207658\n",
      "2025-08-28  1.001600  1.217968\n",
      "2025-08-29  1.002100  1.290133\n",
      "2025-09-02  1.002281  1.346097\n",
      "2025-09-03  1.002481  1.341679\n",
      "2025-09-04  1.002581  1.321060, tickers=['GBIL', 'EQX'], initial_weights=GBIL    0.5\n",
      "EQX     0.5\n",
      "dtype: float64, perf_metrics={'calc_p_gain': 0.10457920068385618, 'fwd_p_gain': 0.05182196429651298, 'full_p_sharpe_atr': 0.5219984867479507, 'calc_b_gain': 0.0026659945292981657, 'fwd_b_gain': 0.0036509342443797888, 'full_b_sharpe_atr': 0.0528966520257708}, results_df=        Rank  Metric Value  Fwd Gain\n",
      "Ticker                              \n",
      "GBIL      15      0.548543  0.001079\n",
      "EQX       16      0.539618  0.093902, calc_end_date=Timestamp('2025-08-27 00:00:00'), viz_end_date=Timestamp('2025-09-04 00:00:00'), error_msg=None)\n",
      "====================\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print_nested(results_container)\n",
    "print('='*20)\n",
    "print_nested(debug_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04c5b49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ⚙️ Initializing AlphaEngine ---\n",
      "--- 1. Generating Features ---\n",
      "Optimizing data structures...\n",
      "✅ AlphaEngine Ready.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c5c0809dbb414b821371476ea7e178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(RadioButtons(description='Portfolio Mode:', layout=Layout(width='max-content'), options=('Ranki…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b668cf3f4a4440b79eda1b450e695063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'color': '#1f77b4', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'GBIL',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e6699d73-cf98-4bb5-98a0-da668addfdf7',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.        , 1.00030002, 1.00050003, 1.00050003, 1.00070004,\n",
       "                          1.00070004, 1.00120006, 1.00130007, 1.00150008, 1.00150008, 1.00160009,\n",
       "                          1.00210011, 1.00228093, 1.00248094, 1.00258095])},\n",
       "             {'line': {'color': '#d62728', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'EQX',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '58e38892-45da-4b23-9141-c21f1f64f6b9',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.15169367, 1.17525773, 1.17378498, 1.11192931, 1.14138439,\n",
       "                          1.1634757 , 1.18114875, 1.18998527, 1.21207658, 1.20765832, 1.2179676 ,\n",
       "                          1.29013255, 1.3460972 , 1.34167894, 1.32106038])},\n",
       "             {'line': {'color': '#2ca02c', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_2',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'fa0be11c-2aff-4eac-bc4a-f3eb075405ac',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#ff7f0e', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_3',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '614e1f7d-5a97-4ace-b009-98f955f37807',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#9467bd', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_4',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '0ebb70eb-fa63-4341-bc86-77740e0073ee',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#8c564b', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_5',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4bf6461e-df37-4daf-b129-17badf11dd38',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#e377c2', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_6',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '3e267401-6ecf-4a55-9184-d155506fe0dc',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#7f7f7f', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_7',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b61f6649-ae9b-40a1-bdd4-d21df223830a',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#bcbd22', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_8',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '7357229c-6a1c-44b0-b099-ba8321c2e3e8',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#17becf', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_9',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '1b6adc58-06d3-492d-9bb5-bad9d2ace167',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#1f77b4', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_10',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '83933cce-501d-4d0b-94bd-c2cafbc0760c',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#d62728', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_11',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd422c576-90ee-46ed-ad76-d75d646fa8cf',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#2ca02c', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_12',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '3bc01635-5259-46f2-a3ef-4d81a3b22126',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#ff7f0e', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_13',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'befd0816-7d93-401a-abbb-ff4290c6d1ef',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#9467bd', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_14',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '115de0a2-d43f-478f-afe1-b2ae220069a6',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#8c564b', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_15',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '2588b6c3-7f2d-4305-84d2-1a13c985b18b',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#e377c2', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_16',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c743a5eb-b719-481e-8490-6a9c00084bbe',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#7f7f7f', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_17',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '6cc0d9eb-66fb-43b5-9a11-b23963bfb4fa',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#bcbd22', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_18',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '04377f2a-e6fe-40ca-8407-70433aac0cee',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#17becf', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_19',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '80063d14-f954-46ad-871c-623456981e43',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#1f77b4', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_20',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '71cd87e6-37ef-4885-a06f-13a716f9eaa0',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#d62728', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_21',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '06485dcd-34f0-4119-a156-3205617aa18f',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#2ca02c', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_22',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e0ddb6e6-cd06-4783-ab28-11a2f0aa4b32',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#ff7f0e', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_23',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '2aa35179-e72c-4138-853d-67ace3a09035',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#9467bd', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_24',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '7fd0cc16-db94-429c-a75e-2691d823ee9d',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#8c564b', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_25',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'fccb7b3e-2954-4159-a2f8-2184ea2d9877',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#e377c2', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_26',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '0020bc53-93aa-488a-8e4a-eacec75013cf',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#7f7f7f', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_27',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '68b92344-9f51-4807-95b4-fe5d34b9bc90',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#bcbd22', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_28',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'aeed59e9-f9c0-48ee-ad1a-9c7baafa26cb',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#17becf', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_29',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '1f008e5e-9893-4b93-883b-a67c9426585b',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#1f77b4', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_30',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '237e2868-79da-4192-af1d-07c3451331b3',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#d62728', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_31',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '7e460940-c08a-4ceb-9db3-a4052d5cc38a',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#2ca02c', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_32',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '8afdb7de-306a-4d9b-923a-4fc64fbf1301',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#ff7f0e', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_33',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a2636de1-e4ab-4cc4-9f40-3f8faf9d4464',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#9467bd', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_34',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '6f6b3b10-35d6-49ca-961d-18af5c5817ad',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#8c564b', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_35',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '8bac2949-0523-41f0-9799-c960021ef98f',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#e377c2', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_36',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c1f3ff38-2324-496f-9af0-6683bbd69e3e',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#7f7f7f', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_37',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e55a0fed-89e7-4b4a-abc5-729fc22310d0',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#bcbd22', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_38',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4b3e3ced-6e06-4a26-adb1-e7097dd9002f',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#17becf', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_39',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4216abf1-a775-4600-b294-9d4afc2d3db1',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#1f77b4', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_40',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ed29c48f-c639-4757-b08d-0c11600556d7',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#d62728', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_41',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c1d1fee8-67dd-4421-9b6a-2e68a6a47e7c',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#2ca02c', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_42',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '332c3632-8c3e-4a34-b563-a198c4e92594',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#ff7f0e', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_43',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'bfe46866-412b-4c1e-a59d-333d44644b62',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#9467bd', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_44',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '3d5d0b16-0999-487b-8566-bf40b8c37d2a',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#8c564b', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_45',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ae2c0e44-1df5-451e-a153-e1022b2c83fe',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#e377c2', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_46',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '61776442-bc0e-4ed6-94b0-9b220f455b64',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#7f7f7f', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_47',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '23c4dde3-fbff-4174-9001-1d874b0372fa',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#bcbd22', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_48',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '878c4a22-0f61-4c86-a2c9-0189c752c0da',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': '#17becf', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'placeholder_49',\n",
       "              'opacity': 1.0,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a563bd5c-26e6-46a4-bf7d-9fe294913532',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': 'black', 'dash': 'dash', 'width': 3},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Benchmark (VOO)',\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '41ab5816-bff7-464d-af3b-3ec6454d9901',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00001692, 0.99785841, 0.99750486, 0.99205615, 0.9894409 ,\n",
       "                          0.9855451 , 1.00062421, 0.99639177, 1.00037216, 1.00266599, 1.00620825,\n",
       "                          1.00040599, 0.99303391, 0.99811215, 1.00632666])},\n",
       "             {'line': {'color': 'green', 'width': 3},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Group Portfolio',\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '39a00e0b-9728-4177-a7fe-7e6a27de9589',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.07584683, 1.08777887, 1.0871425 , 1.05621467, 1.07104221,\n",
       "                          1.08208787, 1.09117441, 1.09564267, 1.10678833, 1.1045792 , 1.10978384,\n",
       "                          1.14611633, 1.17418907, 1.17207994, 1.16182066])}],\n",
       "    'layout': {'height': 600,\n",
       "               'hovermode': 'x unified',\n",
       "               'shapes': [{'line': {'color': 'grey', 'dash': 'dash', 'width': 2},\n",
       "                           'type': 'line',\n",
       "                           'x0': Timestamp('2025-08-27 00:00:00'),\n",
       "                           'x1': Timestamp('2025-08-27 00:00:00'),\n",
       "                           'xref': 'x',\n",
       "                           'y0': 0,\n",
       "                           'y1': 1,\n",
       "                           'yref': 'paper'}],\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Walk-Forward Performance Analysis'},\n",
       "               'xaxis': {'title': {'text': 'Date'}},\n",
       "               'yaxis': {'title': {'text': 'Normalized Price'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_container, debug_container = plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    default_start_date='2025-08-13',\n",
    "    default_calc_period=10,\n",
    "    default_fwd_period=5,\n",
    "    default_metric='Sharpe (ATR)',\n",
    "    default_rank_start=15,\n",
    "    default_rank_end=16,\n",
    "    default_benchmark_ticker='VOO', \n",
    "    master_calendar_ticker='VOO',\n",
    "    quality_thresholds={ 'min_median_dollar_volume': 10_000_000, \n",
    "                         'max_stale_pct': 0.05, \n",
    "                         'max_same_vol_count': 1 },\n",
    "    debug=True  # <-- Activate the new mode!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf477beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ⚙️ Initializing AlphaEngine ---\n",
      "--- 1. Generating Features ---\n",
      "Optimizing data structures...\n",
      "✅ AlphaEngine Ready.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8efa71d8f98f4aecb8e89e3684254246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(RadioButtons(description='Portfolio Mode:', layout=Layout(width='max-content'), options=('Ranki…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad0648c3ff0a41c7961e7d255c51b468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines',\n",
       "              'name': 'GBIL',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a4c87478-a559-4913-96b3-1091e938ca7e',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.        , 1.00030002, 1.00050003, 1.00050003, 1.00070004,\n",
       "                          1.00070004, 1.00120006, 1.00130007, 1.00150008, 1.00150008, 1.00160009,\n",
       "                          1.00210011, 1.00228093, 1.00248094, 1.00258095])},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'EQX',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4696a340-757c-4c73-9544-5876ddd3128f',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.15169367, 1.17525773, 1.17378498, 1.11192931, 1.14138439,\n",
       "                          1.1634757 , 1.18114875, 1.18998527, 1.21207658, 1.20765832, 1.2179676 ,\n",
       "                          1.29013255, 1.3460972 , 1.34167894, 1.32106038])},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_2',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '68286f02-09ea-45d9-a12c-6d47618c9fef',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_3',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '0581d405-4ade-41ee-9206-433587d254ce',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_4',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f6fa387b-6063-4061-a2c7-7d3c3b9cdcc0',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_5',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '3da65c23-03d5-4a94-ab03-a79c09bfc2e3',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_6',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '3fcc6cea-5a88-4989-b37a-b9013c8670aa',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_7',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '2356f93e-75cf-46b8-ab07-3f5129410a85',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_8',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '872c8dc3-e9f9-44b6-a2f9-56573ea0bf7d',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_9',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '7cabe1eb-eda5-4b22-a66f-931a77352038',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_10',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '6b015abf-326b-49c3-8109-2f31da67639b',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_11',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4309237a-31e4-4df1-bcc0-a90f4ae2d46d',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_12',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd18ff536-ec62-4c33-aa1d-32ae070961dc',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_13',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '6ab834f2-4d0b-4391-a942-b0a102c068ad',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_14',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '38bd241c-94c5-4f02-8a30-a27389544569',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_15',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4d55e117-db1f-4ee7-ad0b-7675384c16c2',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_16',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '47251068-cf68-4257-8bde-c6431a0391eb',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_17',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd8c4b826-f51a-4266-848b-1a1027a4b1f0',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_18',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e8a70545-ac95-41b9-90ff-a713db5b4245',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_19',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e6ba750f-8380-47ba-8082-a881d4acc8a3',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_20',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'cd8a4ae0-e889-4edf-b400-8f88d66522d6',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_21',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b0bd7bd5-f3b7-4f2e-b755-b6764056f25a',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_22',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '5e313520-4f8d-49e0-ae46-1063ab059e4a',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_23',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b9078b05-25f1-479a-8f58-2151710c9bcb',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_24',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '60982df6-addc-45e9-b254-d62751ae2561',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_25',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '7a5e3392-7c15-41a0-99c0-710408bbb9f8',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_26',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '0b4d8a7c-5b6d-4f05-ace4-b6a7b41796aa',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_27',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ed9f9310-df9c-4a83-90cc-d8174c9d82db',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_28',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'cf6a378d-1255-4ec4-ac8d-2c5e16a603a1',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_29',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f14622c7-d1ce-4984-8028-8ec27a1af27b',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_30',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '8c426b19-d2b6-479d-93ec-1fa76cf8a5fd',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_31',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '93720096-da94-4688-a441-99ef37787677',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_32',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '35594e8a-30a3-406e-92b3-17336a150e47',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_33',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ca954e8c-7804-4fbb-a919-9eaf41261203',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_34',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '2dead9ca-fbe0-4103-90d7-cf10c5cf5489',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_35',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e1b62a75-f2a2-4d8a-a1e8-7bccb899c62c',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_36',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '445a1560-55c4-4a81-b26c-140f0fe31ad4',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_37',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c0d6713d-6d1c-40c1-83ae-99d5faf5936d',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_38',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ea138b6d-1a90-457a-9cff-dd1567cfb03d',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_39',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '74afb00e-0935-4aec-87bc-534777c700dc',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_40',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '698e9d7c-bce1-44f2-887a-7a96172f608b',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_41',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '6bd6afbd-e822-44e3-8110-6ee138702abc',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_42',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '2fe108a8-9839-4484-92d0-836c6c4d8d78',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_43',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a95c9c2b-79ef-444d-a423-5655fc93cab2',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_44',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '7374a8db-3035-44e0-8066-cc295a632d67',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_45',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '3cbcc50b-d2b8-4c17-afe9-ab6f04368d96',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_46',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '3052da15-7506-4ce0-8570-90604e04990d',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_47',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '252091e5-b59a-4922-9baf-687cdd3cb8a7',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_48',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '34751e7c-be8d-4656-8950-22f377dd8355',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_49',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '5342c87f-d004-49c4-b44e-313ecf319cd2',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': 'black', 'dash': 'dash', 'width': 3},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Benchmark (VOO)',\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'af26ba87-17cb-4687-9b14-74cbfc16a296',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00001692, 0.99785841, 0.99750486, 0.99205615, 0.9894409 ,\n",
       "                          0.9855451 , 1.00062421, 0.99639177, 1.00037216, 1.00266599, 1.00620825,\n",
       "                          1.00040599, 0.99303391, 0.99811215, 1.00632666])},\n",
       "             {'line': {'color': 'green', 'width': 3},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Group Portfolio',\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '65536307-6b1e-424f-8658-c4c529ecaba0',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.07584683, 1.08777887, 1.0871425 , 1.05621467, 1.07104221,\n",
       "                          1.08208787, 1.09117441, 1.09564267, 1.10678833, 1.1045792 , 1.10978384,\n",
       "                          1.14611633, 1.17418907, 1.17207994, 1.16182066])}],\n",
       "    'layout': {'height': 600,\n",
       "               'hovermode': 'x unified',\n",
       "               'shapes': [{'line': {'color': 'grey', 'dash': 'dash', 'width': 2},\n",
       "                           'type': 'line',\n",
       "                           'x0': Timestamp('2025-08-27 00:00:00'),\n",
       "                           'x1': Timestamp('2025-08-27 00:00:00'),\n",
       "                           'xref': 'x',\n",
       "                           'y0': 0,\n",
       "                           'y1': 1,\n",
       "                           'yref': 'paper'}],\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Walk-Forward Performance Analysis'},\n",
       "               'xaxis': {'title': {'text': 'Date'}},\n",
       "               'yaxis': {'title': {'text': 'Normalized Price'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_container, debug_container = plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    default_start_date='2025-08-13',\n",
    "    default_calc_period=10,\n",
    "    default_fwd_period=5,\n",
    "    default_metric='Sharpe (ATR)',\n",
    "    default_rank_start=15,\n",
    "    default_rank_end=16,\n",
    "    default_benchmark_ticker='VOO', \n",
    "    master_calendar_ticker='VOO',\n",
    "    quality_thresholds={ 'min_median_dollar_volume': 10_000_000, \n",
    "                         'max_stale_pct': 0.05, \n",
    "                         'max_same_vol_count': 1 },\n",
    "    debug=True  # <-- Activate the new mode!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34d918af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(results_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(debug_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7954c2e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634cea7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ⚙️ Initializing AlphaEngine ---\n",
      "--- 1. Generating Features ---\n",
      "Optimizing data structures...\n",
      "✅ AlphaEngine Ready.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a31a80468524909a7a907c141fa2414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(RadioButtons(description='Portfolio Mode:', layout=Layout(width='max-content'), options=('Ranki…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a8f409161e489ca7531b73fad264f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines',\n",
       "              'name': 'GBIL',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '2ef545b4-085d-42bf-b089-8bd69912af92',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.        , 1.00030002, 1.00050003, 1.00050003, 1.00070004,\n",
       "                          1.00070004, 1.00120006, 1.00130007, 1.00150008, 1.00150008, 1.00160009,\n",
       "                          1.00210011, 1.00228093, 1.00248094, 1.00258095])},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'EQX',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '61bd729e-1700-443d-ab17-90857c1f9577',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.15169367, 1.17525773, 1.17378498, 1.11192931, 1.14138439,\n",
       "                          1.1634757 , 1.18114875, 1.18998527, 1.21207658, 1.20765832, 1.2179676 ,\n",
       "                          1.29013255, 1.3460972 , 1.34167894, 1.32106038])},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_2',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '54972ef0-d28c-455e-9b84-372a9fcf02e3',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_3',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '7ed28843-76ed-4fd9-ad4c-bfa7c7bc60cf',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_4',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '694a3c73-b678-45b0-a819-d0603269aacf',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_5',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '35d73d54-9553-437e-9b0d-2d8c217d222b',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_6',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '6d1b4c1d-d6e3-4149-9de0-914380cc8b89',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_7',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '5a6cb1ce-a62c-47cb-8340-780b85a06d76',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_8',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a1e8f697-ab9e-49cb-a340-4263fd6aabb5',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_9',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '55fcdec5-6908-4a3c-bc3b-0c4c9f3a2e11',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_10',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a7d199f3-e941-4aff-b2b9-c0186b0a5827',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_11',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '069787de-5d25-4cdc-b3f5-fac8d680d940',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_12',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '523a6cc5-0560-48ed-a35d-5aea7ea531e2',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_13',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b44ef113-406d-4218-876a-1a133f4a956a',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_14',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '3a07ef38-7965-4a18-bf69-2dacbbc6b03a',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_15',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '8a553d5b-5feb-40a9-9506-9c899dfcf845',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_16',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '392d8372-de94-45fd-945b-c4de318a414c',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_17',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '996269e4-8014-4b68-9458-7a8596975aeb',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_18',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '76b0244e-8e3d-4b15-b8f1-5620e65bc9bc',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_19',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '061f3290-f1a1-48fc-a33d-881a3ae9ccdb',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_20',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '78084ef6-c18e-475a-8ad5-835c9ae48bf6',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_21',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '7d373910-d5db-4abc-9aa1-f244d11e4208',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_22',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '76851c1d-d430-4113-afa8-b5c8bbfc0e36',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_23',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '506b92bb-e808-452f-9d90-3f620287a064',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_24',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '91c5fe6b-10c1-4785-b0b7-d2cbc207abfa',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_25',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '983b5db0-37f7-4064-9381-16fa93dd897a',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_26',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '3d1373cd-7e21-404e-a3a0-c98a635071ee',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_27',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b2754999-23cb-4651-bad5-ef74e0bef854',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_28',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '204d5d6b-cda7-4cbd-9a85-7b9faaea79f7',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_29',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '2eca3d47-e9a2-4b3e-8e7c-479a546088b4',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_30',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f8835f5d-234d-4a40-a1e5-b47adb9ac00d',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_31',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '71df9c28-ed66-4509-bf99-9e5479e7a491',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_32',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '60f28802-259f-4eba-9ca4-750277b0947e',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_33',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '0db4c275-93a4-40f3-ad77-4bb529573cf2',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_34',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'fccbc780-addd-405e-9e0d-c79d947ccf8e',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_35',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '06d8d5a9-2b57-4afe-9e72-6ff70114fc52',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_36',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '0a624b87-b4c5-4aee-b341-590397700c97',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_37',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b3abfb99-83a2-4e79-a812-1b42f5e3e344',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_38',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'cca9e796-5a62-47ba-804d-5007a81e0986',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_39',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '756bdd8d-4b23-454e-8af4-1734dc47edf0',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_40',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f3612573-f914-4dc8-9726-9af5123df5bc',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_41',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '5a8ea55b-3561-4a08-9ad0-207b0a57f45f',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_42',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a6717cda-0e44-4580-995f-4e26a87019e3',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_43',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c115c7a2-d408-4593-82ef-d476dbc4e99b',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_44',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b5029d4d-9619-4136-b31c-521bc76c73d6',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_45',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '5c3bb314-5892-4388-8058-dce9d4dc3a42',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_46',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a674246f-5662-4185-b756-b8c07686c582',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_47',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '5e96dcd2-e876-441c-bfe5-7bdda53b1d39',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_48',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '50ef7cb3-059d-4ed3-a64a-61ef3c820b94',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_49',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '48d4bc67-afc6-4af6-8d4f-b47053abef82',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': 'black', 'dash': 'dash', 'width': 3},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Benchmark (VOO)',\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '73e29f68-a7a8-478c-a165-4b036166a9a8',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00001692, 0.99785841, 0.99750486, 0.99205615, 0.9894409 ,\n",
       "                          0.9855451 , 1.00062421, 0.99639177, 1.00037216, 1.00266599, 1.00620825,\n",
       "                          1.00040599, 0.99303391, 0.99811215, 1.00632666])},\n",
       "             {'line': {'color': 'green', 'width': 3},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Group Portfolio',\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '67229e5d-0f12-4b88-96b7-6eb4c0067f02',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.07584683, 1.08777887, 1.0871425 , 1.05621467, 1.07104221,\n",
       "                          1.08208787, 1.09117441, 1.09564267, 1.10678833, 1.1045792 , 1.10978384,\n",
       "                          1.14611633, 1.17418907, 1.17207994, 1.16182066])}],\n",
       "    'layout': {'height': 600,\n",
       "               'hovermode': 'x unified',\n",
       "               'shapes': [{'line': {'color': 'grey', 'dash': 'dash', 'width': 2},\n",
       "                           'type': 'line',\n",
       "                           'x0': Timestamp('2025-08-27 00:00:00'),\n",
       "                           'x1': Timestamp('2025-08-27 00:00:00'),\n",
       "                           'xref': 'x',\n",
       "                           'y0': 0,\n",
       "                           'y1': 1,\n",
       "                           'yref': 'paper'}],\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Walk-Forward Performance Analysis'},\n",
       "               'xaxis': {'title': {'text': 'Date'}},\n",
       "               'yaxis': {'title': {'text': 'Normalized Price'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_container, debug_container = plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    default_start_date='2025-08-13',\n",
    "    default_calc_period=10,\n",
    "    default_fwd_period=5,\n",
    "    default_metric='Sharpe (ATR)',\n",
    "    default_rank_start=15,\n",
    "    default_rank_end=16,\n",
    "    default_benchmark_ticker='VOO', \n",
    "    master_calendar_ticker='VOO',\n",
    "    quality_thresholds={ 'min_median_dollar_volume': 10_000_000, \n",
    "                         'max_stale_pct': 0.05, \n",
    "                         'max_same_vol_count': 1 },\n",
    "    debug=True  # <-- Activate the new mode!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "440818e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ⚙️ Initializing AlphaEngine ---\n",
      "--- 1. Generating Features ---\n",
      "Optimizing data structures...\n",
      "✅ AlphaEngine Ready.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ed1fe514c24e04bb992c27695a79d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(RadioButtons(description='Portfolio Mode:', layout=Layout(width='max-content'), options=('Ranki…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b342300331044a4f802d0a0f0393aff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines',\n",
       "              'name': 'GBIL',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '9c71a684-bf42-4a19-820a-983a761ecb7b',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.        , 1.00030002, 1.00050003, 1.00050003, 1.00070004,\n",
       "                          1.00070004, 1.00120006, 1.00130007, 1.00150008, 1.00150008, 1.00160009,\n",
       "                          1.00210011, 1.00228093, 1.00248094, 1.00258095])},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'EQX',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '34fd82c4-ac2c-443e-9539-b464c36f4033',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.15169367, 1.17525773, 1.17378498, 1.11192931, 1.14138439,\n",
       "                          1.1634757 , 1.18114875, 1.18998527, 1.21207658, 1.20765832, 1.2179676 ,\n",
       "                          1.29013255, 1.3460972 , 1.34167894, 1.32106038])},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_2',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4349c2bf-ba53-4256-8c1a-3646d0226012',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_3',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '2e3b4634-ff9d-42e3-9bfe-66584cc00904',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_4',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b13a7964-d580-45c1-8d23-2a3fb4fc3885',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_5',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'dafafb51-15e8-47e5-9a3a-dfefb89c7aba',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_6',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e4cc546b-ad41-4911-b460-35af46dff005',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_7',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'bb3d4f9d-0512-468a-b3cd-d1a6b796cb69',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_8',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '6e01aa6a-ff68-4db1-a6ef-47cc5bd6e8e7',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_9',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '33340364-eb40-4afe-913d-856ab6260c60',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_10',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b33cc58a-126d-4d79-808f-8b2a73035258',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_11',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b06458c2-4790-421c-b875-75f923260543',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_12',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '6eb50281-be7d-4118-8460-089b0580debf',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_13',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '0267a666-8841-45b2-b698-d6a28b5aa74b',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_14',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '201ec17d-6cc4-4532-b4d4-99af8732d6a0',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_15',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a243c406-bcad-4a3f-b039-fbb6d83968e7',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_16',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '31fdf939-0388-4779-b423-00f05d7d5eb5',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_17',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '7fb4db10-da8f-4361-8fd5-7ef0171cb502',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_18',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f4d84254-cc95-4c10-820e-a6a18e015fc9',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_19',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ad28c210-e579-4ca1-80bd-512df681630f',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_20',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'cca217e0-0ec2-4076-b9dc-a0f61b72a9da',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_21',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '76968863-b637-4d80-8afa-40b056937b81',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_22',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd5e7a221-4506-4dba-9e11-014be9a3b8f2',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_23',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f46229f5-444e-414d-a185-2c9d272e4855',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_24',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'dd55ccef-e00a-4111-aed7-c9d02f7bd44e',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_25',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'bf0597ad-5e7d-44ba-a5f7-4229047ff2e2',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_26',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'eb125ee9-b3aa-4d0b-ae3f-b7767a90d2fe',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_27',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '9c9077ae-e3f1-4acc-b7c0-3b8c4f43e9fd',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_28',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '9768a7ed-6ed3-4bb5-b92c-57540baa2d50',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_29',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ad11e882-70bb-400b-abbc-4a6fa9697c60',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_30',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '0b2e9bcb-dc5b-4394-a092-2fbffce4182d',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_31',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a2ae3e7d-216c-4090-8f4b-2302f8a2c66e',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_32',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '43ca66c3-f3ae-4f7d-ba01-f9491d00f473',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_33',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a0a3ef8e-0a5c-4aa6-8532-7c1140749955',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_34',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ec295729-649b-4d30-ac10-5b5ff90338bb',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_35',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '50ce89e2-c567-4287-9fa7-0416586d16fe',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_36',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '31cb955a-e07d-4f8d-9c05-173f0a96c8c1',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_37',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '8aa4acff-9185-48f3-8354-2376bcfbb99c',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_38',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'bcc914ff-94bf-473b-88da-4ea236acc8d7',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_39',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '75cb52ed-3c64-47ab-b825-d4ac432ca25a',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_40',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b4783a13-6d73-4607-ade0-ed6c62ef9570',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_41',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '3a9ac316-ad2b-4bfc-90d4-bc8d14e6e5ca',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_42',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '6015ea4b-40e5-480e-a05a-b842835e8485',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_43',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '413302f9-ac58-4f4d-b56f-717aed96fd2a',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_44',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a51dd86c-b169-43fc-b8d3-ad2c205173e0',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_45',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ec4586e6-ed54-4f53-8677-7fcf6b69b9c4',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_46',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'fcd0b1c8-4465-420d-ab2a-f5a6c2ae97cf',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_47',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '8f2d20bb-d063-4ef7-abb1-bd24b2fd83fd',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_48',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a8d6d820-79cd-4afe-abe2-b2cd23f61ade',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_49',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '91467a6b-136a-40a5-8ab9-b6d621b45ebb',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': 'black', 'dash': 'dash', 'width': 3},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Benchmark (VOO)',\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4b9064c3-959b-4e98-a8c1-fcf1544d80f3',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00001692, 0.99785841, 0.99750486, 0.99205615, 0.9894409 ,\n",
       "                          0.9855451 , 1.00062421, 0.99639177, 1.00037216, 1.00266599, 1.00620825,\n",
       "                          1.00040599, 0.99303391, 0.99811215, 1.00632666])},\n",
       "             {'line': {'color': 'green', 'width': 3},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Group Portfolio',\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'aacd5c24-e93a-4d31-8542-490a92a3b54a',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.07584683, 1.08777887, 1.0871425 , 1.05621467, 1.07104221,\n",
       "                          1.08208787, 1.09117441, 1.09564267, 1.10678833, 1.1045792 , 1.10978384,\n",
       "                          1.14611633, 1.17418907, 1.17207994, 1.16182066])}],\n",
       "    'layout': {'height': 600,\n",
       "               'hovermode': 'x unified',\n",
       "               'shapes': [{'line': {'color': 'grey', 'dash': 'dash', 'width': 2},\n",
       "                           'type': 'line',\n",
       "                           'x0': Timestamp('2025-08-27 00:00:00'),\n",
       "                           'x1': Timestamp('2025-08-27 00:00:00'),\n",
       "                           'xref': 'x',\n",
       "                           'y0': 0,\n",
       "                           'y1': 1,\n",
       "                           'yref': 'paper'}],\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Walk-Forward Performance Analysis'},\n",
       "               'xaxis': {'title': {'text': 'Date'}},\n",
       "               'yaxis': {'title': {'text': 'Normalized Price'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_container, debug_container = plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    default_start_date='2025-08-13',\n",
    "    default_calc_period=10,\n",
    "    default_fwd_period=5,\n",
    "    default_metric='Sharpe (ATR)',\n",
    "    default_rank_start=15,\n",
    "    default_rank_end=16,\n",
    "    default_benchmark_ticker='VOO', \n",
    "    master_calendar_ticker='VOO',\n",
    "    quality_thresholds={ 'min_median_dollar_volume': 10_000_000, \n",
    "                         'max_stale_pct': 0.05, \n",
    "                         'max_same_vol_count': 1 },\n",
    "    debug=True  # <-- Activate the new mode!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e75f562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ⚙️ Initializing AlphaEngine ---\n",
      "--- 1. Generating Features ---\n",
      "Optimizing data structures...\n",
      "✅ AlphaEngine Ready.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8342552ce4084baf8de6aa2e2f2abc5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(RadioButtons(description='Portfolio Mode:', layout=Layout(width='max-content'), options=('Ranki…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "845db83798fd487fb7a661791af81b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines',\n",
       "              'name': 'GBIL',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '2be965c5-5d62-40b4-9fcc-76669266818d',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.        , 1.00030002, 1.00050003, 1.00050003, 1.00070004,\n",
       "                          1.00070004, 1.00120006, 1.00130007, 1.00150008, 1.00150008, 1.00160009,\n",
       "                          1.00210011, 1.00228093, 1.00248094, 1.00258095])},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'EQX',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '45e1680a-2f77-4d54-b15d-429ada970430',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.15169367, 1.17525773, 1.17378498, 1.11192931, 1.14138439,\n",
       "                          1.1634757 , 1.18114875, 1.18998527, 1.21207658, 1.20765832, 1.2179676 ,\n",
       "                          1.29013255, 1.3460972 , 1.34167894, 1.32106038])},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_2',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4789a30c-5613-461b-8656-1c2a23539738',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_3',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b9fc7cbf-1aed-4f2d-b229-bc1f7278f452',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_4',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c2428621-7c4f-455e-832f-a055861b5a4b',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_5',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '3b7cb875-3704-4324-93df-e48c81a628f8',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_6',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '31b324ce-8789-40b3-a20a-dffc70bcde6b',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_7',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '2a7d5276-4252-453f-97d3-8d4157b92b00',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_8',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '3c38992c-1f00-4473-b17e-bed6253167e7',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_9',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ba3cf367-a865-41a0-8329-6b88b7031fef',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_10',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '10ade163-9986-45b2-9df1-578a03dc625e',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_11',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '3a47fb13-1e8a-4a03-b4a5-75f04bf01087',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_12',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4bd265d0-c91d-4848-8d98-cf47b1148af8',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_13',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '1928b801-1247-4ed3-bf98-e1075df7b71f',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_14',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd6c55574-db90-4d65-b8f7-324b59b8454f',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_15',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'facbe608-5fa2-4df2-8ad0-90cb62b6bb18',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_16',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd1090d36-bae6-4782-aa86-b714b39a5a85',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_17',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '8e5b6aac-f6e1-4289-bf43-dfe7eee604eb',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_18',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '5145305a-c45d-4780-91b6-bb6af7c83fcf',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_19',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f45ab8a8-51bc-432c-acb8-2069ba91c3bc',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_20',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '5c17aa15-cf24-42db-b39b-6042877ebefb',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_21',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '3fbaef7e-1735-40bd-8a65-ac3e316c2662',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_22',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '2cbb1d96-342c-4e2e-b359-4fed53ae3247',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_23',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f6085654-da23-4411-bd6f-5d15a3240d08',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_24',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '0b3e5f51-00bb-451a-9665-ff6c7c6b7b4e',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_25',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'edb175c2-aa59-4ee9-aff3-db353dfab35b',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_26',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a70f7fac-86f1-439b-91ab-b8aed99c288f',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_27',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '3d06d284-a612-499e-8241-8ec9fe89a79e',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_28',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b089721d-cdf3-404f-a378-a95cb9934198',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_29',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '044fb18e-761b-426d-a649-10c03ed59bf0',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_30',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a4b493b2-b835-4daf-86ab-77cfa8a3be63',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_31',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '8d14eab0-790f-4642-8a36-9701e7292841',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_32',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'afa26ba0-558f-42ed-8cff-d351cf928ca3',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_33',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f4246c14-3201-410a-9168-fe2389ed4fe3',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_34',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '048b6931-17cd-479d-a991-61dffa94993d',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_35',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '34acc278-ff00-4ab5-94dc-64f0c37b7c8f',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_36',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ca30f7b1-1964-496b-b059-9644b2f3d1a0',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_37',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e71d37bc-734c-4136-b728-959845515fc5',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_38',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '5e3f47cd-c3e8-4f59-9173-29703924ff07',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_39',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '9fbf50ce-2cf6-4734-88db-c6e3798f7600',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_40',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '2872352f-79d1-4964-afd4-ff3e8f087cf4',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_41',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '306e63f5-0383-406d-a6e3-01bc979b4bb0',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_42',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f1bf411b-1d70-4878-a248-13894ffb9544',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_43',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '6d1589c0-d57d-4d68-9516-47ae375d5145',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_44',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '30271bc3-6079-4ea6-bdc5-7bae5e6e674e',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_45',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '9b8ba952-9545-4e5c-acfb-23b6c205481e',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_46',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'dddadb95-deec-4a08-a6a0-6b42f8e9cf8e',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_47',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4b52b989-b021-4f23-90b8-a0c333070eb2',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_48',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd3ea7c14-07c1-47db-9943-c82fc047ec04',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_49',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '0a4c9bbe-b5ab-4e3c-8785-0e2213a0e7e8',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': 'black', 'dash': 'dash', 'width': 3},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Benchmark (VOO)',\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e014f046-ba0d-42ed-a6c2-ecb2842c6bee',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00001692, 0.99785841, 0.99750486, 0.99205615, 0.9894409 ,\n",
       "                          0.9855451 , 1.00062421, 0.99639177, 1.00037216, 1.00266599, 1.00620825,\n",
       "                          1.00040599, 0.99303391, 0.99811215, 1.00632666])},\n",
       "             {'line': {'color': 'green', 'width': 3},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Group Portfolio',\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '70991df0-1cdb-4e96-8bdf-5fc9690c546a',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.07584683, 1.08777887, 1.0871425 , 1.05621467, 1.07104221,\n",
       "                          1.08208787, 1.09117441, 1.09564267, 1.10678833, 1.1045792 , 1.10978384,\n",
       "                          1.14611633, 1.17418907, 1.17207994, 1.16182066])}],\n",
       "    'layout': {'height': 600,\n",
       "               'hovermode': 'x unified',\n",
       "               'shapes': [{'line': {'color': 'grey', 'dash': 'dash', 'width': 2},\n",
       "                           'type': 'line',\n",
       "                           'x0': Timestamp('2025-08-27 00:00:00'),\n",
       "                           'x1': Timestamp('2025-08-27 00:00:00'),\n",
       "                           'xref': 'x',\n",
       "                           'y0': 0,\n",
       "                           'y1': 1,\n",
       "                           'yref': 'paper'}],\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Walk-Forward Performance Analysis'},\n",
       "               'xaxis': {'title': {'text': 'Date'}},\n",
       "               'yaxis': {'title': {'text': 'Normalized Price'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_container, debug_container = plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    default_start_date='2025-08-13',\n",
    "    default_calc_period=10,\n",
    "    default_fwd_period=5,\n",
    "    default_metric='Sharpe (ATR)',\n",
    "    default_rank_start=15,\n",
    "    default_rank_end=16,\n",
    "    default_benchmark_ticker='VOO', \n",
    "    master_calendar_ticker='VOO',\n",
    "    quality_thresholds={ 'min_median_dollar_volume': 10_000_000, \n",
    "                         'max_stale_pct': 0.05, \n",
    "                         'max_same_vol_count': 1 },\n",
    "    debug=True  # <-- Activate the new mode!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fb1c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa313b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ⚙️ Initializing AlphaEngine ---\n",
      "--- 1. Generating Features ---\n",
      "Optimizing data structures...\n",
      "✅ AlphaEngine Ready.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "284f5972d3294cf0a9ebc563715fc6c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(RadioButtons(description='Portfolio Mode:', layout=Layout(width='max-content'), options=('Ranki…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5757ea52947f49bc87a08747a43f3c38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines',\n",
       "              'name': 'GBIL',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '12bcd03e-2d96-41dd-abcd-9cd465d3c596',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.        , 1.00030002, 1.00050003, 1.00050003, 1.00070004,\n",
       "                          1.00070004, 1.00120006, 1.00130007, 1.00150008, 1.00150008, 1.00160009,\n",
       "                          1.00210011, 1.00228093, 1.00248094, 1.00258095])},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'EQX',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '647d130e-c69e-4da9-8832-6ce79da43e32',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.15169367, 1.17525773, 1.17378498, 1.11192931, 1.14138439,\n",
       "                          1.1634757 , 1.18114875, 1.18998527, 1.21207658, 1.20765832, 1.2179676 ,\n",
       "                          1.29013255, 1.3460972 , 1.34167894, 1.32106038])},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_2',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '388f9feb-0938-4738-ac8c-312f0c1726ad',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_3',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '60a03973-ee98-4b9e-b1fc-04bac96c4dd6',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_4',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f5c26910-4d1f-4e6c-8439-f591da5d52c7',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_5',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'becb363e-0080-4a4b-ba27-d482a2d675e1',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_6',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c63b9887-6aad-40a2-9beb-7c77660e3409',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_7',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '80b6ed10-a29e-4928-b12d-d9609abde349',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_8',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b38acaa1-adc1-4b5d-b75e-4e672d62ddbf',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_9',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'df3bea52-0ff7-47d4-acdd-a42238403e95',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_10',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ab4d68e1-b225-4718-8e73-fd7278a4c2aa',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_11',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'eafb577f-d9ed-47c3-842f-45bd787851bc',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_12',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '89c362c5-467f-4cf6-a2a1-4b707379f800',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_13',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '8cb66001-122b-4182-90a2-6b9afd7cf18c',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_14',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd808bb61-85be-497f-9718-741002ff0b46',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_15',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '59690768-6935-46e7-8a50-b4107449644b',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_16',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '6f133fdb-b7e8-4373-a8c9-d3d7ca332132',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_17',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4fdf3eed-e9a8-4e41-8c8b-03530fe1ad34',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_18',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'dbbec327-e655-408d-a3bf-560388a64900',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_19',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f7541ea4-9bc3-4cc2-8eb4-a45c3a3282a5',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_20',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4ccf1d75-56a7-4063-8629-b1fcab0182e6',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_21',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f322b4b2-5e94-4660-977e-d27ee704d067',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_22',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '7381e558-0bde-4a32-abf2-8ad87e875929',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_23',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd8700066-faa9-4c23-80fd-9c3ff6abc35b',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_24',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '8013909e-ddb1-4d96-a8f5-10da4b3758bf',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_25',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '08ea6136-4156-469d-b032-d9abc19f6d8c',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_26',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '1c59ed9d-94a2-4fdc-984a-0bb3bb85612e',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_27',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '08712306-2b8b-4b2f-9a44-82a3a837a5ec',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_28',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd6f896c5-ee03-430f-8ca4-667579ec9d41',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_29',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c100fa5d-7fb6-4cf4-a920-1677f47f396b',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_30',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'cf117dcd-fe56-46d5-817b-8e66696a3756',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_31',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '95423de8-997c-438e-b860-4a0a1ddbd1ba',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_32',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f78811c2-a723-4210-9953-bb6c1422f292',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_33',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '8e08a626-e82b-4b3d-aec7-3ed2460807d4',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_34',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '673e4807-d9d8-4bdc-b939-240fd1ded10d',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_35',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '97a29ba2-f105-442e-9afe-04dc76ced905',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_36',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c4cdb349-45cf-472c-95c5-e0bfe0097045',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_37',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f1fbefaf-791d-442e-98d0-2d89f0a08e23',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_38',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '1df3a10c-471d-4156-9e22-a6e290e361e4',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_39',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'bc88a854-1c6a-41ff-9b62-e423296c1b8d',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_40',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '72495044-b951-4347-b136-33c133892201',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_41',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b0ac636f-9969-4739-85ef-eaced4e5b888',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_42',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ea4db3ed-d60e-4b46-86a1-b0c4e4b5e2fd',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_43',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '9d88d4a2-32c7-48be-97e6-99cf24b6b4ce',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_44',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4903b1e1-c85b-4a08-b37f-3fe0e4a3c6c9',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_45',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '8ad0efa1-6840-40dc-bce1-20df85a84cb8',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_46',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '3c4a5219-391a-4424-afd7-1918759ecc94',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_47',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '406b6510-96ad-4781-888d-0af464eade99',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_48',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '03cef01f-4d4a-448f-8fe6-0b533008f32e',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_49',\n",
       "              'opacity': 0.5,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a66d34db-a544-4851-8d47-9d934c61b2e1',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': 'black', 'dash': 'dash', 'width': 3},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Benchmark (VOO)',\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '49957074-ba45-4507-8d12-7a795ab3ca68',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00001692, 0.99785841, 0.99750486, 0.99205615, 0.9894409 ,\n",
       "                          0.9855451 , 1.00062421, 0.99639177, 1.00037216, 1.00266599, 1.00620825,\n",
       "                          1.00040599, 0.99303391, 0.99811215, 1.00632666])},\n",
       "             {'line': {'color': 'green', 'width': 3},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Group Portfolio',\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '062b74f7-32c9-4c64-b649-7857015f0349',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.07584683, 1.08777887, 1.0871425 , 1.05621467, 1.07104221,\n",
       "                          1.08208787, 1.09117441, 1.09564267, 1.10678833, 1.1045792 , 1.10978384,\n",
       "                          1.14611633, 1.17418907, 1.17207994, 1.16182066])}],\n",
       "    'layout': {'height': 600,\n",
       "               'hovermode': 'x unified',\n",
       "               'shapes': [{'line': {'color': 'grey', 'dash': 'dash', 'width': 2},\n",
       "                           'type': 'line',\n",
       "                           'x0': Timestamp('2025-08-27 00:00:00'),\n",
       "                           'x1': Timestamp('2025-08-27 00:00:00'),\n",
       "                           'xref': 'x',\n",
       "                           'y0': 0,\n",
       "                           'y1': 1,\n",
       "                           'yref': 'paper'}],\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Walk-Forward Performance Analysis'},\n",
       "               'xaxis': {'title': {'text': 'Date'}},\n",
       "               'yaxis': {'title': {'text': 'Normalized Price'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_container, debug_container = plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    default_start_date='2025-08-13',\n",
    "    default_calc_period=10,\n",
    "    default_fwd_period=5,\n",
    "    default_metric='Sharpe (ATR)',\n",
    "    default_rank_start=15,\n",
    "    default_rank_end=16,\n",
    "    default_benchmark_ticker='VOO', \n",
    "    master_calendar_ticker='VOO',\n",
    "    quality_thresholds={ 'min_median_dollar_volume': 10_000_000, \n",
    "                         'max_stale_pct': 0.05, \n",
    "                         'max_same_vol_count': 1 },\n",
    "    debug=True  # <-- Activate the new mode!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ba67970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ⚙️ Initializing AlphaEngine ---\n",
      "--- 1. Generating Features ---\n",
      "Optimizing data structures...\n",
      "✅ AlphaEngine Ready.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d951bf2d3f423fa3a013c877dc63cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(RadioButtons(description='Mode', options=('Ranking', 'Manual List…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7055d688a6494ea0a6641f1f11b0e509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines',\n",
       "              'name': 'GBIL',\n",
       "              'opacity': 0.15,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '9bbc8d1e-80a9-4ad5-af0a-354870ae02a3',\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.        , 1.00030002, 1.00050003, 1.00050003, 1.00070004,\n",
       "                          1.00070004, 1.00120006, 1.00130007, 1.00150008, 1.00150008, 1.00160009,\n",
       "                          1.00210011, 1.00228093, 1.00248094, 1.00258095])},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'EQX',\n",
       "              'opacity': 0.15,\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '6a4d39d4-2549-44b9-8020-27c5b3482ab1',\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.15169367, 1.17525773, 1.17378498, 1.11192931, 1.14138439,\n",
       "                          1.1634757 , 1.18114875, 1.18998527, 1.21207658, 1.20765832, 1.2179676 ,\n",
       "                          1.29013255, 1.3460972 , 1.34167894, 1.32106038])},\n",
       "             {'line': {'color': 'black', 'dash': 'dash', 'width': 2},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Benchmark',\n",
       "              'type': 'scatter',\n",
       "              'uid': '90c5e520-8deb-4576-8f56-a47cc27fad8f',\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00001692, 0.99785841, 0.99750486, 0.99205615, 0.9894409 ,\n",
       "                          0.9855451 , 1.00062421, 0.99639177, 1.00037216, 1.00266599, 1.00620825,\n",
       "                          1.00040599, 0.99303391, 0.99811215, 1.00632666])},\n",
       "             {'line': {'color': 'green', 'width': 3},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Alpha Portfolio',\n",
       "              'type': 'scatter',\n",
       "              'uid': '116bcf4e-3550-4736-8692-f6b09e957d50',\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.07584683, 1.08777887, 1.0871425 , 1.05621467, 1.07104221,\n",
       "                          1.08208787, 1.09117441, 1.09564267, 1.10678833, 1.1045792 , 1.10978384,\n",
       "                          1.14611633, 1.17418907, 1.17207994, 1.16182066])}],\n",
       "    'layout': {'height': 600,\n",
       "               'hovermode': 'x unified',\n",
       "               'shapes': [{'line': {'color': 'gray', 'dash': 'dot', 'width': 1},\n",
       "                           'type': 'line',\n",
       "                           'x0': Timestamp('2025-08-27 00:00:00'),\n",
       "                           'x1': Timestamp('2025-08-27 00:00:00'),\n",
       "                           'xref': 'x',\n",
       "                           'y0': 0,\n",
       "                           'y1': 1,\n",
       "                           'yref': 'paper'}],\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Walk-Forward Analysis (Engine Powered)'}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_container, debug_container = plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    default_start_date='2025-08-13',\n",
    "    default_calc_period=10,\n",
    "    default_fwd_period=5,\n",
    "    default_metric='Sharpe (ATR)',\n",
    "    default_rank_start=15,\n",
    "    default_rank_end=16,\n",
    "    default_benchmark_ticker='VOO', \n",
    "    master_calendar_ticker='VOO',\n",
    "    quality_thresholds={ 'min_median_dollar_volume': 10_000_000, \n",
    "                         'max_stale_pct': 0.05, \n",
    "                         'max_same_vol_count': 1 },\n",
    "    debug=True  # <-- Activate the new mode!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b362b9f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c2218be",
   "metadata": {},
   "source": [
    "### 1. The Data Contracts (Standardized Inputs/Outputs)\n",
    "\n",
    "First, we define the \"language\" the Engine and UI will speak. This eliminates ambiguity about dictionary keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b4a4ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba9b4b6f",
   "metadata": {},
   "source": [
    "### 2. The Engine (Calculation Logic)\n",
    "\n",
    "This class encapsulates the heavy lifting. It holds the data and executes the math. It replaces the loose functions `run_walk_forward_step` and `run_manual_portfolio_step`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684327bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaEngine:\n",
    "    def __init__(self, df_ohlcv: pd.DataFrame, master_ticker: str = 'SPY'):\n",
    "        \"\"\"\n",
    "        Initialize the engine with data once. \n",
    "        Pre-calculates unstacked dataframes for speed.\n",
    "        \"\"\"\n",
    "        # 1. Generate Features\n",
    "        self.features_df = generate_features(df_ohlcv)\n",
    "        \n",
    "        # 2. Unstack Data for Vectorized Ops\n",
    "        self.df_close = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "        self.df_high = df_ohlcv['Adj High'].unstack(level=0)\n",
    "        self.df_low = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "        \n",
    "        # 3. Setup Calendar\n",
    "        if master_ticker not in self.df_close.columns:\n",
    "            # Fallback to the first column if master ticker missing\n",
    "            master_ticker = self.df_close.columns[0]\n",
    "        self.trading_calendar = self.df_close[master_ticker].dropna().index.unique().sort_values()\n",
    "\n",
    "    def run(self, inputs: EngineInput) -> EngineOutput:\n",
    "        \"\"\"The single entry point for the UI or Bot.\"\"\"\n",
    "        \n",
    "        # 1. Date Validation\n",
    "        try:\n",
    "            start_idx = self.trading_calendar.get_loc(inputs.start_date)\n",
    "        except KeyError:\n",
    "             # Find nearest date if exact match missing\n",
    "            start_idx = self.trading_calendar.searchsorted(inputs.start_date)\n",
    "        \n",
    "        # Check bounds\n",
    "        desired_end_idx = start_idx + inputs.calc_period + inputs.fwd_period\n",
    "        if desired_end_idx >= len(self.trading_calendar):\n",
    "            return EngineOutput(\n",
    "                portfolio_series=pd.Series(), benchmark_series=pd.Series(),\n",
    "                normalized_plot_data=pd.DataFrame(), tickers=[], weights=pd.Series(),\n",
    "                performance_metrics={}, ranking_table=pd.DataFrame(),\n",
    "                calc_end_date=pd.Timestamp.min, viz_end_date=pd.Timestamp.min,\n",
    "                error_msg=\"Date range exceeds available history.\"\n",
    "            )\n",
    "\n",
    "        # 2. Define Dates\n",
    "        safe_start_date = self.trading_calendar[start_idx]\n",
    "        safe_calc_end_date = self.trading_calendar[start_idx + inputs.calc_period]\n",
    "        safe_viz_end_date = self.trading_calendar[start_idx + inputs.calc_period + inputs.fwd_period]\n",
    "\n",
    "        # 3. Select Tickers (Ranking vs Manual)\n",
    "        tickers_to_trade = []\n",
    "        ranking_table = pd.DataFrame()\n",
    "\n",
    "        if inputs.mode == 'Manual':\n",
    "            valid_tickers = [t for t in inputs.manual_tickers if t in self.df_close.columns]\n",
    "            if not valid_tickers:\n",
    "                return self._create_error_output(\"No valid tickers found in manual list.\")\n",
    "            tickers_to_trade = valid_tickers\n",
    "            # Create a dummy table for the UI\n",
    "            ranking_table = pd.DataFrame(index=tickers_to_trade)\n",
    "            ranking_table['Selection'] = 'Manual'\n",
    "            \n",
    "        else: # Ranking Mode\n",
    "            # Reuse existing logic for ranking\n",
    "            # (Simplified for brevity, assumes metric calculation functions exist globally)\n",
    "            calc_slice = self.df_close.loc[safe_start_date:safe_calc_end_date]\n",
    "            \n",
    "            # --- METRIC CALCULATION HOOK ---\n",
    "            # Using the Registry defined in your original code\n",
    "            if inputs.metric not in METRIC_REGISTRY:\n",
    "                return self._create_error_output(f\"Unknown metric: {inputs.metric}\")\n",
    "            \n",
    "            # Prepare metric ingredients\n",
    "            daily_returns = calc_slice.pct_change()\n",
    "            idx_slice = pd.MultiIndex.from_product([calc_slice.columns, calc_slice.index])\n",
    "            feat_slice = self.features_df.loc[self.features_df.index.intersection(idx_slice)]\n",
    "            atrp_mean = feat_slice.groupby(level='Ticker')['ATRP'].mean()\n",
    "            \n",
    "            ingredients = {\n",
    "                'calc_close': calc_slice, \n",
    "                'daily_returns': daily_returns, \n",
    "                'atrp': atrp_mean\n",
    "            }\n",
    "            \n",
    "            metric_series = METRIC_REGISTRY[inputs.metric](ingredients)\n",
    "            sorted_tickers = metric_series.sort_values(ascending=False)\n",
    "            \n",
    "            # Select Top N\n",
    "            start_r = max(0, inputs.rank_start - 1)\n",
    "            end_r = inputs.rank_end\n",
    "            tickers_to_trade = sorted_tickers.iloc[start_r:end_r].index.tolist()\n",
    "            \n",
    "            ranking_table = pd.DataFrame({\n",
    "                'Metric': inputs.metric,\n",
    "                'Value': sorted_tickers.loc[tickers_to_trade]\n",
    "            })\n",
    "\n",
    "        # 4. Calculate Portfolio Performance\n",
    "        # Use the existing helper function\n",
    "        port_val, port_ret, port_atrp = calculate_buy_and_hold_performance(\n",
    "            self.df_close, self.features_df, tickers_to_trade, \n",
    "            safe_start_date, safe_viz_end_date\n",
    "        )\n",
    "\n",
    "        # 5. Calculate Benchmark Performance\n",
    "        bm_val, bm_ret, bm_atrp = calculate_buy_and_hold_performance(\n",
    "            self.df_close, self.features_df, [inputs.benchmark_ticker], \n",
    "            safe_start_date, safe_viz_end_date\n",
    "        )\n",
    "\n",
    "        # 6. Compute Scalar Metrics (The \"Perf Data\")\n",
    "        # Split into calc/fwd periods\n",
    "        actual_calc_end_ts = safe_calc_end_date\n",
    "        \n",
    "        calc_slice_p = port_ret.loc[:actual_calc_end_ts]\n",
    "        fwd_slice_p = port_ret.loc[actual_calc_end_ts:].iloc[1:]\n",
    "        \n",
    "        metrics = {\n",
    "            'calc_p_gain': calculate_gain(port_val.loc[:actual_calc_end_ts]),\n",
    "            'fwd_p_gain': calculate_gain(port_val.loc[actual_calc_end_ts:]),\n",
    "            'calc_p_sharpe': calculate_sharpe(calc_slice_p),\n",
    "            'fwd_p_sharpe': calculate_sharpe(fwd_slice_p),\n",
    "        }\n",
    "        \n",
    "        # Add benchmark comparison if valid\n",
    "        if not bm_val.empty:\n",
    "            metrics['calc_b_gain'] = calculate_gain(bm_val.loc[:actual_calc_end_ts])\n",
    "            metrics['fwd_b_gain'] = calculate_gain(bm_val.loc[actual_calc_end_ts:])\n",
    "            metrics['alpha_gain'] = metrics['fwd_p_gain'] - metrics['fwd_b_gain']\n",
    "\n",
    "        # 7. Prepare Plot Data\n",
    "        plot_data = self.df_close[tickers_to_trade].loc[safe_start_date:safe_viz_end_date]\n",
    "        # Normalize to start at 1.0\n",
    "        plot_data = plot_data / plot_data.bfill().iloc[0]\n",
    "\n",
    "        return EngineOutput(\n",
    "            portfolio_series=port_val,\n",
    "            benchmark_series=bm_val,\n",
    "            normalized_plot_data=plot_data,\n",
    "            tickers=tickers_to_trade,\n",
    "            weights=pd.Series(1/len(tickers_to_trade), index=tickers_to_trade), # Simplified\n",
    "            performance_metrics=metrics,\n",
    "            ranking_table=ranking_table,\n",
    "            calc_end_date=actual_calc_end_ts,\n",
    "            viz_end_date=safe_viz_end_date\n",
    "        )\n",
    "\n",
    "    def _create_error_output(self, msg):\n",
    "        return EngineOutput(\n",
    "            portfolio_series=pd.Series(), benchmark_series=pd.Series(),\n",
    "            normalized_plot_data=pd.DataFrame(), tickers=[], weights=pd.Series(),\n",
    "            performance_metrics={}, ranking_table=pd.DataFrame(),\n",
    "            calc_end_date=pd.Timestamp.min, viz_end_date=pd.Timestamp.min,\n",
    "            error_msg=msg\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bb8fba",
   "metadata": {},
   "source": [
    "### 3. The UI (Rewritten Function)\n",
    "\n",
    "The UI now calls `engine.run()` instead of doing the math itself. This separates the logic completely. The UI is now just a \"View\" layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_walk_forward_analyzer(df_ohlcv, \n",
    "                               default_start_date='2020-01-01', \n",
    "                               master_ticker='SPY',\n",
    "                               debug=False): # Simplified args for readability\n",
    "    \n",
    "    # 1. Initialize The Engine\n",
    "    print(\"Initializing Alpha Engine...\")\n",
    "    engine = AlphaEngine(df_ohlcv, master_ticker=master_ticker)\n",
    "    \n",
    "    # --- WIDGET DEFINITIONS (Standard) ---\n",
    "    start_date_picker = widgets.DatePicker(description='Start Date:', value=pd.to_datetime(default_start_date))\n",
    "    calc_period_input = widgets.IntText(value=126, description='Calc Days:')\n",
    "    fwd_period_input = widgets.IntText(value=63, description='Fwd Days:')\n",
    "    \n",
    "    metric_dropdown = widgets.Dropdown(options=list(METRIC_REGISTRY.keys()), value='Sharpe (ATR)', description='Metric:')\n",
    "    rank_start_input = widgets.IntText(value=1, description='Rank Start:')\n",
    "    rank_end_input = widgets.IntText(value=10, description='Rank End:')\n",
    "    \n",
    "    benchmark_input = widgets.Text(value='SPY', description='Benchmark:')\n",
    "    mode_selector = widgets.RadioButtons(options=['Ranking', 'Manual'], value='Ranking', description='Mode:')\n",
    "    manual_tickers_input = widgets.Textarea(placeholder='AAPL, MSFT...', description='Manual:')\n",
    "    \n",
    "    update_button = widgets.Button(description=\"Run Analysis\", button_style='primary')\n",
    "    output_area = widgets.Output()\n",
    "    \n",
    "    # Plotly Figure\n",
    "    fig = go.FigureWidget()\n",
    "    fig.layout.height = 600\n",
    "    fig.layout.title = \"Walk-Forward Analysis\"\n",
    "    \n",
    "    # --- UI LOGIC (The Glue) ---\n",
    "    \n",
    "    def on_update_click(b):\n",
    "        output_area.clear_output()\n",
    "        \n",
    "        # 1. Build the Input Contract\n",
    "        # This is where we bridge UI Widgets -> Engine Data\n",
    "        manual_list = [t.strip().upper() for t in manual_tickers_input.value.split(',') if t.strip()]\n",
    "        \n",
    "        inputs = EngineInput(\n",
    "            mode=mode_selector.value,\n",
    "            start_date=pd.to_datetime(start_date_picker.value),\n",
    "            calc_period=calc_period_input.value,\n",
    "            fwd_period=fwd_period_input.value,\n",
    "            benchmark_ticker=benchmark_input.value.strip().upper(),\n",
    "            metric=metric_dropdown.value,\n",
    "            rank_start=rank_start_input.value,\n",
    "            rank_end=rank_end_input.value,\n",
    "            manual_tickers=manual_list\n",
    "        )\n",
    "        \n",
    "        with output_area:\n",
    "            # 2. Call the Engine\n",
    "            print(\"Running calculation...\")\n",
    "            result = engine.run(inputs)\n",
    "            \n",
    "            # 3. Handle Errors\n",
    "            if result.error_msg:\n",
    "                print(f\"❌ Error: {result.error_msg}\")\n",
    "                return\n",
    "\n",
    "            # 4. Update Visuals (Plotly)\n",
    "            fig.data = [] # Clear traces\n",
    "            \n",
    "            # Plot Components\n",
    "            for ticker in result.tickers:\n",
    "                if ticker in result.normalized_plot_data:\n",
    "                    series = result.normalized_plot_data[ticker]\n",
    "                    fig.add_trace(go.Scatter(x=series.index, y=series.values, name=ticker, opacity=0.3))\n",
    "            \n",
    "            # Plot Portfolio & Benchmark\n",
    "            fig.add_trace(go.Scatter(x=result.portfolio_series.index, y=result.portfolio_series.values, \n",
    "                                     name='Portfolio', line=dict(color='green', width=3)))\n",
    "            \n",
    "            if not result.benchmark_series.empty:\n",
    "                fig.add_trace(go.Scatter(x=result.benchmark_series.index, y=result.benchmark_series.values, \n",
    "                                         name='Benchmark', line=dict(color='black', dash='dash')))\n",
    "\n",
    "            # Add Vertical Line for Calc/Fwd split\n",
    "            fig.layout.shapes = []\n",
    "            fig.add_vline(x=result.calc_end_date.timestamp() * 1000, line_dash=\"dash\", line_color=\"gray\")\n",
    "\n",
    "            # 5. Update Text Reports\n",
    "            print(f\"Analysis Period: {inputs.start_date.date()} -> {result.viz_end_date.date()}\")\n",
    "            print(\"\\n--- Performance Metrics ---\")\n",
    "            \n",
    "            # Format simple table\n",
    "            metrics_df = pd.DataFrame([\n",
    "                {'Metric': 'Calculated Gain', 'Value': result.performance_metrics.get('calc_p_gain', 0)},\n",
    "                {'Metric': 'Forward Gain', 'Value': result.performance_metrics.get('fwd_p_gain', 0)},\n",
    "                {'Metric': 'Forward Alpha', 'Value': result.performance_metrics.get('alpha_gain', 0)},\n",
    "                {'Metric': 'Fwd Sharpe', 'Value': result.performance_metrics.get('fwd_p_sharpe', 0)},\n",
    "            ])\n",
    "            display(metrics_df.style.format({'Value': '{:.2%}'}))\n",
    "            \n",
    "            print(\"\\n--- Portfolio Composition ---\")\n",
    "            display(result.ranking_table.head(15))\n",
    "\n",
    "    update_button.on_click(on_update_click)\n",
    "    \n",
    "    # --- LAYOUT ---\n",
    "    controls = widgets.VBox([\n",
    "        widgets.HBox([mode_selector, start_date_picker]),\n",
    "        widgets.HBox([calc_period_input, fwd_period_input]),\n",
    "        widgets.HBox([metric_dropdown, rank_start_input, rank_end_input]),\n",
    "        widgets.HBox([manual_tickers_input]),\n",
    "        widgets.HBox([benchmark_input, update_button])\n",
    "    ])\n",
    "    \n",
    "    display(controls, output_area, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f500c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be96a818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c92c3cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ae617f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f866eef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c330ac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# GOLDEN COPY - Manual Ticker List for Group Portfolio Sharpe (ATR)\n",
    "\n",
    "# Date: 2025-10-19\n",
    "# Version: Verified Manual Ticker List with duplicate tickers (i.e.RCL, RCL, STIP)\n",
    "#  for Group Portfolio Sharpe (ATR) and Benchmark Sharpe (ATR)  \n",
    "\n",
    "# Date: 2025-10-17\n",
    "# Version: Verified Buy-and-Hold Portfolio and Benchmark Sharpe (ATR)  \n",
    "\n",
    "# ==============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets\n",
    "import time\n",
    "import pprint\n",
    "import os # Make sure os is imported for the export function later\n",
    "import re\n",
    "\n",
    "from datetime import datetime, date\n",
    "from IPython.display import display, Markdown\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 30)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 3000)\n",
    "\n",
    "\n",
    "# --- REFACTORING PHASE 1 CODE: Feature Generation Engine ---\n",
    "\n",
    "def generate_features(df_ohlcv: pd.DataFrame, \n",
    "                      atr_period: int = 14, \n",
    "                      quality_window: int = 252, \n",
    "                      quality_min_periods: int = 126) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates a comprehensive DataFrame of derived features from raw OHLCV data.\n",
    "\n",
    "    This function performs all heavy, window-based calculations upfront to be used\n",
    "    by downstream analysis functions. It calculates:\n",
    "    1. Technical Indicators: True Range (TR), ATR, and ATRP.\n",
    "    2. Data Quality Metrics: Rolling stale percentage, median dollar volume, etc.\n",
    "\n",
    "    Args:\n",
    "        df_ohlcv: The primary DataFrame with a (Ticker, Date) MultiIndex and\n",
    "                  columns for 'Adj High', 'Adj Low', 'Adj Close', 'Volume'.\n",
    "        atr_period: The lookback period for the ATR's Exponential Moving Average.\n",
    "        quality_window: The rolling window size for data quality metrics.\n",
    "        quality_min_periods: The minimum number of observations required to have\n",
    "                             a valid quality metric.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame with the same (Ticker, Date) MultiIndex containing all\n",
    "        calculated feature columns.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Feature Generation ---\")\n",
    "    \n",
    "    # Ensure the DataFrame is sorted for correct window and shift operations\n",
    "    # FIX: Replaced is_lexsorted() with the current pandas attribute\n",
    "    if not df_ohlcv.index.is_monotonic_increasing:\n",
    "        print(\"Sorting index for calculation accuracy...\")\n",
    "        df_ohlcv = df_ohlcv.sort_index()\n",
    "\n",
    "    # --- 1. Technical Indicator Calculation (TR, ATR, ATRP) ---\n",
    "    print(f\"Calculating technical indicators (ATR Period: {atr_period})...\")\n",
    "    \n",
    "    # Group by ticker to handle each security independently\n",
    "    grouped = df_ohlcv.groupby(level='Ticker')\n",
    "    \n",
    "    # Get the previous day's close required for True Range\n",
    "    prev_close = grouped['Adj Close'].shift(1)\n",
    "    \n",
    "    # Calculate the three components of True Range\n",
    "    high_low = df_ohlcv['Adj High'] - df_ohlcv['Adj Low']\n",
    "    high_prev_close = abs(df_ohlcv['Adj High'] - prev_close)\n",
    "    low_prev_close = abs(df_ohlcv['Adj Low'] - prev_close)\n",
    "    \n",
    "    # Combine the components to get the final TR\n",
    "    tr = pd.concat([high_low, high_prev_close, low_prev_close], axis=1).max(axis=1, skipna=False)\n",
    "    \n",
    "    # # Calculate the ATR using an Exponential Moving Average\n",
    "    # --- FIX IS HERE ---\n",
    "    # Use .transform() to apply the EWM function. \n",
    "    # This guarantees the resulting Series has the exact same index as 'tr',\n",
    "    # preventing the index alignment error during the subsequent division.\n",
    "    atr = tr.groupby(level='Ticker').transform(\n",
    "        lambda x: x.ewm(alpha=1/atr_period, adjust=False).mean()\n",
    "    )\n",
    "\n",
    "    # --- CHANGE 1: Removed .fillna(0) ---\n",
    "    # ATRP will now be NaN on the first day, consistent with TR and ATR.\n",
    "    atrp = (atr / df_ohlcv['Adj Close']).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    indicator_df = pd.DataFrame({\n",
    "        'TR': tr,\n",
    "        'ATR': atr,\n",
    "        'ATRP': atrp\n",
    "    })\n",
    "    \n",
    "    # --- 2. Data Quality Metric Calculation ---\n",
    "    print(f\"Calculating data quality metrics (Window: {quality_window} days)...\")\n",
    "    \n",
    "    # Create intermediate flags needed for quality calculations\n",
    "    is_stale = np.where((df_ohlcv['Volume'] == 0) | (df_ohlcv['Adj High'] == df_ohlcv['Adj Low']), 1, 0)\n",
    "    dollar_volume = df_ohlcv['Adj Close'] * df_ohlcv['Volume']\n",
    "    has_same_volume = (grouped['Volume'].diff() == 0).astype(int)\n",
    "    \n",
    "    # Combine flags into a temporary DataFrame for rolling calculations\n",
    "    quality_temp_df = pd.DataFrame({\n",
    "        'IsStale': is_stale,\n",
    "        'DollarVolume': dollar_volume,\n",
    "        'HasSameVolume': has_same_volume\n",
    "    }, index=df_ohlcv.index) # Explicitly set index to be safe\n",
    "    \n",
    "    # Perform the rolling calculations on the grouped data\n",
    "    # --- FIX IS HERE ---\n",
    "    # We switch to the older, more compatible dictionary-based aggregation method.\n",
    "    # This syntax is understood by nearly all versions of pandas.\n",
    "    rolling_result = quality_temp_df.groupby(level='Ticker').rolling(\n",
    "        window=quality_window,\n",
    "        min_periods=quality_min_periods\n",
    "    ).agg({\n",
    "        'IsStale': 'mean',\n",
    "        'DollarVolume': 'median',\n",
    "        'HasSameVolume': 'sum'\n",
    "    })\n",
    "    \n",
    "    # The dictionary syntax produces columns with the original names ('IsStale', etc.).\n",
    "    # We now explicitly rename them to our desired final names.\n",
    "    rolling_result = rolling_result.rename(columns={\n",
    "        'IsStale': 'RollingStalePct',\n",
    "        'DollarVolume': 'RollMedDollarVol', # <-- RENAMED HERE\n",
    "        'HasSameVolume': 'RollingSameVolCount'\n",
    "    })\n",
    "\n",
    "    # The index after a grouped rolling operation is hierarchical.\n",
    "    # We remove the outermost 'Ticker' level to restore the original index structure.\n",
    "    rolling_quality = rolling_result.reset_index(level=0, drop=True)\n",
    "\n",
    "    # --- 3. Combine All Features ---\n",
    "    print(\"Combining all feature sets...\")\n",
    "    features_df = pd.concat([indicator_df, rolling_quality], axis=1)\n",
    "    \n",
    "    print(\"✅ Feature generation complete.\")\n",
    "    return features_df\n",
    "\n",
    "\n",
    "def test_features_df(features_df: pd.DataFrame, \n",
    "                     df_ohlcv: pd.DataFrame, \n",
    "                     test_ticker: str = 'AAPL',\n",
    "                     spot_check_date: str = '2020-03-20'):\n",
    "    \"\"\"\n",
    "    Runs a suite of tests to verify the correctness of the generated features_df.\n",
    "\n",
    "    Args:\n",
    "        features_df: The generated DataFrame from the generate_features function.\n",
    "        df_ohlcv: The original source OHLCV DataFrame.\n",
    "        test_ticker: A common, liquid ticker to use for specific value checks.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Running Verification Suite for features_df (Test Ticker: {test_ticker}) ---\")\n",
    "    \n",
    "    # --- Test 1: Structural Integrity ---\n",
    "    print(\"\\n[Test 1: Structural Integrity]\")\n",
    "    assert features_df.index.equals(df_ohlcv.index), \"FAIL: Index does not match original df_ohlcv.\"\n",
    "    print(\"  ✅ PASS: Index matches original df_ohlcv.\")\n",
    "    \n",
    "    expected_cols = ['TR', 'ATR', 'ATRP', 'RollingStalePct', 'RollMedDollarVol', 'RollingSameVolCount']\n",
    "    assert all(col in features_df.columns for col in expected_cols), \"FAIL: Missing one or more expected columns.\"\n",
    "    print(\"  ✅ PASS: All expected feature columns are present.\")\n",
    "    print(f\"  - DataFrame Info:\")\n",
    "    features_df.info(verbose=False, memory_usage='deep')\n",
    "\n",
    "\n",
    "    # --- Test 2: ATR Calculation Logic ---\n",
    "    print(\"\\n[Test 2: ATR Logic Verification]\")\n",
    "    ticker_features = features_df.loc[test_ticker]\n",
    "    \n",
    "    # Test 2a: First TR value should be NaN (since prev_close is NaN)\n",
    "    first_tr = ticker_features['TR'].iloc[0]\n",
    "    assert pd.isna(first_tr), f\"FAIL: First TR value for {test_ticker} should be NaN, but got {first_tr}.\"\n",
    "    print(f\"  ✅ PASS: First TR value for {test_ticker} is NaN as expected.\")\n",
    "\n",
    "    # Test 2b: The first valid ATR should equal the first valid TR (EWM cold start behavior)\n",
    "    first_valid_tr_val = ticker_features['TR'].dropna().iloc[0]\n",
    "    first_valid_atr_val = ticker_features['ATR'].dropna().iloc[0]\n",
    "    assert np.isclose(first_valid_tr_val, first_valid_atr_val), \\\n",
    "        f\"FAIL: First valid ATR ({first_valid_atr_val}) should equal first valid TR ({first_valid_tr_val}).\"\n",
    "    print(\"  ✅ PASS: First valid ATR correctly seeded with first valid TR.\")\n",
    "\n",
    "\n",
    "    # --- Test 3: Rolling Quality Metrics Logic ---\n",
    "    print(\"\\n[Test 3: Rolling Quality Metrics Logic Verification]\")\n",
    "    quality_min_periods = 126 # Should match the parameter used in generation\n",
    "    \n",
    "    # Test 3a: Check for leading NaNs\n",
    "    first_valid_quality_idx = ticker_features['RollingStalePct'].first_valid_index()\n",
    "    if first_valid_quality_idx is None:\n",
    "        print(f\"  - INFO: No valid quality metrics found for {test_ticker} (likely too little data). Skipping test.\")\n",
    "    else:\n",
    "        position_of_first_valid = ticker_features.index.get_loc(first_valid_quality_idx)\n",
    "        assert position_of_first_valid == quality_min_periods - 1, \\\n",
    "            f\"FAIL: First valid quality metric should appear at index {quality_min_periods - 1}, but appeared at {position_of_first_valid}.\"\n",
    "        print(f\"  ✅ PASS: Leading NaNs are present for the first {quality_min_periods - 1} periods as expected.\")\n",
    "\n",
    "\n",
    "    # --- Test 4: Spot Check Against Manual Calculation ---\n",
    "    print(\"\\n[Test 4: Spot Check vs. Manual Calculation]\")\n",
    "    # # Choose a specific date for a manual calculation\n",
    "    # spot_check_date = '2020-03-20' # A volatile day for a good test\n",
    "    \n",
    "    # Manual TR Calculation\n",
    "    today_data = df_ohlcv.loc[(test_ticker, spot_check_date)]\n",
    "    yesterday_data = df_ohlcv.loc[(test_ticker, pd.to_datetime(spot_check_date) - pd.Timedelta(days=1))] # simple lookback for test\n",
    "    \n",
    "    manual_h_l = today_data['Adj High'] - today_data['Adj Low']\n",
    "    manual_h_pc = abs(today_data['Adj High'] - yesterday_data['Adj Close'])\n",
    "    manual_l_pc = abs(today_data['Adj Low'] - yesterday_data['Adj Close'])\n",
    "    manual_tr = max(manual_h_l, manual_h_pc, manual_l_pc)\n",
    "    \n",
    "    code_tr = ticker_features.loc[spot_check_date]['TR']\n",
    "    \n",
    "    assert np.isclose(manual_tr, code_tr), f\"FAIL: Manual TR ({manual_tr:.4f}) does not match code TR ({code_tr:.4f}) on {spot_check_date}.\"\n",
    "    print(f\"  ✅ PASS: Manually calculated TR on {spot_check_date} matches code's TR.\")\n",
    "    \n",
    "    print(\"\\n--- ✅ All Verification Tests Passed ---\")\n",
    "\n",
    "\n",
    "def export_ticker_data(ticker_to_export: str, \n",
    "                         df_ohlcv: pd.DataFrame, \n",
    "                         features_df: pd.DataFrame, \n",
    "                         output_dir: str = 'export_csv'):\n",
    "    \"\"\"\n",
    "    Exports the raw OHLCV data and the corresponding calculated features for a \n",
    "    single ticker to two separate CSV files.\n",
    "\n",
    "    This function is designed for easy manual verification of data and calculations.\n",
    "    It will create the output directory if it does not exist.\n",
    "\n",
    "    Args:\n",
    "        ticker_to_export: The ticker symbol to export (e.g., 'AAPL').\n",
    "        df_ohlcv: The main DataFrame containing the raw OHLCV data with a \n",
    "                  (Ticker, Date) MultiIndex.\n",
    "        features_df: The DataFrame containing the calculated features with a \n",
    "                     (Ticker, Date) MultiIndex.\n",
    "        output_dir: The directory where the CSV files will be saved. \n",
    "                    Defaults to 'export_csv'.\n",
    "    \"\"\"\n",
    "    print(f\"--- Attempting to export data for ticker: {ticker_to_export} ---\")\n",
    "    \n",
    "    # --- 1. Ensure the output directory exists ---\n",
    "    try:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        print(f\"Output directory '{output_dir}' is ready.\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error: Could not create directory '{output_dir}'. Reason: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 2. Isolate the data for the specified ticker ---\n",
    "    try:\n",
    "        # Use .loc to select all rows for the given ticker from the MultiIndex\n",
    "        ticker_ohlcv = df_ohlcv.loc[ticker_to_export]\n",
    "        ticker_features = features_df.loc[ticker_to_export]\n",
    "        \n",
    "        if ticker_ohlcv.empty:\n",
    "            print(f\"Warning: No OHLCV data found for ticker '{ticker_to_export}'. Cannot export.\")\n",
    "            return\n",
    "            \n",
    "        print(f\"Found {len(ticker_ohlcv)} rows of data for '{ticker_to_export}'.\")\n",
    "        \n",
    "    except KeyError:\n",
    "        print(f\"Error: Ticker '{ticker_to_export}' not found in one or both of the DataFrames. Please check the symbol.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while accessing data: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 3. Construct file paths and export to CSV ---\n",
    "    try:\n",
    "        # Define the full path for each output file\n",
    "        ohlcv_filename = f\"{ticker_to_export}_ohlcv.csv\"\n",
    "        features_filename = f\"{ticker_to_export}_features.csv\"\n",
    "        \n",
    "        ohlcv_filepath = os.path.join(output_dir, ohlcv_filename)\n",
    "        features_filepath = os.path.join(output_dir, features_filename)\n",
    "        \n",
    "        # Export the DataFrames to CSV. The index (Date) will be included.\n",
    "        ticker_ohlcv.to_csv(ohlcv_filepath)\n",
    "        ticker_features.to_csv(features_filepath)\n",
    "        \n",
    "        print(\"\\n✅ Export successful!\")\n",
    "        print(f\"   - Raw OHLCV data saved to: {ohlcv_filepath}\")\n",
    "        print(f\"   - Calculated features saved to: {features_filepath}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Failed to write data to CSV files. Reason: {e}\")\n",
    "\n",
    "\n",
    "def create_synthetic_ticker_data(\n",
    "    ticker_name: str = 'SYNTH', \n",
    "    num_days: int = 50,\n",
    "    num_zero_volume_days: int = 5,\n",
    "    num_flat_price_days: int = 3\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a synthetic OHLCV DataFrame with predictable patterns and randomly injected\n",
    "    stale data conditions for robust testing.\n",
    "\n",
    "    Args:\n",
    "        ticker_name: The name for the synthetic ticker.\n",
    "        num_days: The total number of days for the ticker's history.\n",
    "        num_zero_volume_days: The number of random days to set Volume to 0.\n",
    "        num_flat_price_days: The number of random days to set High == Low.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame with a (Ticker, Date) MultiIndex.\n",
    "    \"\"\"\n",
    "    print(f\"--- Creating synthetic data for '{ticker_name}' with {num_days} days ---\")\n",
    "    \n",
    "    # 1. Create a base DataFrame with \"normal\" data\n",
    "    dates = pd.to_datetime(pd.date_range(start='2023-01-01', periods=num_days, freq='B'))\n",
    "    data = {\n",
    "        'Adj Open': 100.0, 'Adj High': 102.0, 'Adj Low': 98.0,\n",
    "        'Adj Close': 100.0, 'Volume': 1_000_000\n",
    "    }\n",
    "    df = pd.DataFrame(data, index=dates)\n",
    "    df['Adj Close'] = df['Adj Close'] + np.random.randn(num_days) * 0.5 # Add some noise\n",
    "\n",
    "    # 2. Define a \"protected\" window for specific verification tests.\n",
    "    # The `verify_synthetic_ticker_features` function depends on this exact window.\n",
    "    # We will not inject random stale days here.\n",
    "    protected_start_idx, protected_end_idx = 10, 20\n",
    "    \n",
    "    # 3. Inject random \"stale\" days OUTSIDE the protected window\n",
    "    available_indices = df.index.drop(df.index[protected_start_idx:protected_end_idx])\n",
    "    \n",
    "    # Inject zero-volume days\n",
    "    if num_zero_volume_days > 0:\n",
    "        if len(available_indices) < num_zero_volume_days:\n",
    "            raise ValueError(\"Not enough available days to inject zero-volume days.\")\n",
    "        zero_vol_dates = np.random.choice(available_indices, num_zero_volume_days, replace=False)\n",
    "        df.loc[zero_vol_dates, 'Volume'] = 0\n",
    "        print(f\"  - Injected {num_zero_volume_days} random zero-volume 'stale' days.\")\n",
    "        # Update available indices to avoid overlap\n",
    "        available_indices = available_indices.drop(zero_vol_dates)\n",
    "\n",
    "    # Inject flat-price days (High == Low)\n",
    "    if num_flat_price_days > 0:\n",
    "        if len(available_indices) < num_flat_price_days:\n",
    "            raise ValueError(\"Not enough available days to inject flat-price days.\")\n",
    "        flat_price_dates = np.random.choice(available_indices, num_flat_price_days, replace=False)\n",
    "        # Set High and Low to be the same as the Close price for that day\n",
    "        df.loc[flat_price_dates, 'Adj High'] = df.loc[flat_price_dates, 'Adj Close']\n",
    "        df.loc[flat_price_dates, 'Adj Low'] = df.loc[flat_price_dates, 'Adj Close']\n",
    "        print(f\"  - Injected {num_flat_price_days} random flat-price 'stale' days.\")\n",
    "\n",
    "    # 4. Inject the specific, hand-crafted patterns inside the protected window for verification\n",
    "    print(\"  - Injecting specific patterns for programmatic verification...\")\n",
    "    # Pattern for RollingStalePct: 2 stale days in 10 (20%)\n",
    "    df.iloc[10, df.columns.get_loc('Volume')] = 0  # Stale day (zero volume)\n",
    "    df.iloc[11, df.columns.get_loc('Adj High')] = 99.0 # Stale day (High == Low)\n",
    "    df.iloc[11, df.columns.get_loc('Adj Low')] = 99.0\n",
    "    \n",
    "    # Pattern for RollingMedianVolume\n",
    "    for i in range(10):\n",
    "        df.iloc[10 + i, df.columns.get_loc('Adj Close')] = 100.0 # Standardize price for easy median calc\n",
    "        df.iloc[10 + i, df.columns.get_loc('Volume')] = (i + 1) * 10000\n",
    "\n",
    "    # Pattern for RollingSameVolCount\n",
    "    df.iloc[15, df.columns.get_loc('Volume')] = 77777\n",
    "    df.iloc[16, df.columns.get_loc('Volume')] = 77777\n",
    "    df.iloc[17, df.columns.get_loc('Volume')] = 77777\n",
    "    \n",
    "    # 5. Set the MultiIndex\n",
    "    df['Ticker'] = ticker_name\n",
    "    df = df.set_index(['Ticker', df.index])\n",
    "    df.index.names = ['Ticker', 'Date']\n",
    "    \n",
    "    print(\"✅ Synthetic data created successfully.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def verify_synthetic_ticker_features(features_df: pd.DataFrame, \n",
    "                                       ticker_name: str = 'SYNTH',\n",
    "                                       quality_window: int = 10):\n",
    "    \"\"\"\n",
    "    Verifies the quality metric calculations on the features_df generated from\n",
    "    the synthetic ticker data.\n",
    "\n",
    "    Args:\n",
    "        features_df: The DataFrame of calculated features.\n",
    "        ticker_name: The name of the synthetic ticker.\n",
    "        quality_window: The rolling window used, which must match the window\n",
    "                        of the synthetic data pattern.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Running Verification on Synthetic Ticker '{ticker_name}' ---\")\n",
    "    \n",
    "    # --- Expected values based on our synthetic data design ---\n",
    "    EXPECTED_STALE_PCT = 0.20  # 2 stale days out of 10\n",
    "    EXPECTED_MEDIAN_DOLLAR_VOL = 5_500_000.0 # median of (10k..100k) * price of 100\n",
    "    EXPECTED_SAME_VOL_COUNT = 2.0 # Three consecutive days gives two 'diff() == 0' events\n",
    "\n",
    "    try:\n",
    "        # Isolate the features for our synthetic ticker\n",
    "        ticker_features = features_df.loc[ticker_name]\n",
    "        \n",
    "        # The first valid calculation will be on the last day of our 10-day window.\n",
    "        # The window starts at index 10 and has a length of 10, so it ends at index 19.\n",
    "        verification_date = ticker_features.index[19]\n",
    "        \n",
    "        print(f\"Verifying calculations on date: {verification_date.date()}\")\n",
    "        \n",
    "        # Get the calculated values from the DataFrame\n",
    "        calculated_values = ticker_features.loc[verification_date]\n",
    "        stale_pct = calculated_values['RollingStalePct']\n",
    "        # --- CHANGE 2 (continued): Accessing the renamed column ---\n",
    "        median_vol = calculated_values['RollMedDollarVol'] \n",
    "        same_vol_count = calculated_values['RollingSameVolCount']\n",
    "        \n",
    "        # --- Perform Assertions ---\n",
    "        print(\"\\n[Test 1: RollingStalePct]\")\n",
    "        assert np.isclose(stale_pct, EXPECTED_STALE_PCT), f\"FAIL: Expected {EXPECTED_STALE_PCT}, Got {stale_pct}\"\n",
    "        print(f\"  ✅ PASS: Expected {EXPECTED_STALE_PCT}, Got {stale_pct}\")\n",
    "\n",
    "        print(\"\\n[Test 2: RollMedDollarVol]\")\n",
    "        assert np.isclose(median_vol, EXPECTED_MEDIAN_DOLLAR_VOL), f\"FAIL: Expected {EXPECTED_MEDIAN_DOLLAR_VOL}, Got {median_vol}\"\n",
    "        print(f\"  ✅ PASS: Expected {EXPECTED_MEDIAN_DOLLAR_VOL}, Got {median_vol}\")\n",
    "\n",
    "        print(\"\\n[Test 3: RollingSameVolCount]\")\n",
    "        assert np.isclose(same_vol_count, EXPECTED_SAME_VOL_COUNT), f\"FAIL: Expected {EXPECTED_SAME_VOL_COUNT}, Got {same_vol_count}\"\n",
    "        print(f\"  ✅ PASS: Expected {EXPECTED_SAME_VOL_COUNT}, Got {same_vol_count}\")\n",
    "\n",
    "        print(\"\\n--- ✅ All Synthetic Data Verification Tests Passed ---\")\n",
    "\n",
    "    except KeyError:\n",
    "        print(f\"FAIL: Ticker '{ticker_name}' not found in features_df.\")\n",
    "    except IndexError:\n",
    "        print(\"FAIL: Not enough data in features_df to run verification. Check num_days.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during verification: {e}\")\n",
    "\n",
    "\n",
    "# --- A. HELPER FUNCTIONS ---\n",
    "\n",
    "def calculate_gain(price_series: pd.Series):\n",
    "    \"\"\"Calculates the total gain over a series of prices.\"\"\"\n",
    "    # Ensure there are at least two data points to calculate a gain\n",
    "    if price_series.dropna().shape[0] < 2: return np.nan\n",
    "    # Use forward-fill for the end price and back-fill for the start price\n",
    "    # to handle potential NaNs at the beginning or end of the series.\n",
    "    return (price_series.ffill().iloc[-1] / price_series.bfill().iloc[0]) - 1\n",
    "\n",
    "\n",
    "def calculate_sharpe(return_series: pd.Series):\n",
    "    \"\"\"Calculates the annualized Sharpe ratio from a series of daily returns.\"\"\"\n",
    "    # Ensure there are at least two returns to calculate a standard deviation\n",
    "    if return_series.dropna().shape[0] < 2: return np.nan\n",
    "    std_dev = return_series.std()\n",
    "    # Avoid division by zero if returns are constant\n",
    "    if std_dev > 0 and std_dev != np.inf:\n",
    "        return (return_series.mean() / std_dev) * np.sqrt(252)\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "def calculate_sharpe_atr(return_series: pd.Series, atrp_series: pd.Series):\n",
    "    \"\"\"Calculates a Sharpe-like ratio using mean ATRP as the denominator.\"\"\"\n",
    "    # Ensure there are returns and that ATRP data is valid\n",
    "    if return_series.dropna().shape[0] < 2 or atrp_series.dropna().empty:\n",
    "        return np.nan\n",
    "        \n",
    "    mean_return = return_series.mean()\n",
    "    mean_atrp = atrp_series.mean()\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if mean_atrp > 0 and mean_atrp != np.inf:\n",
    "        return mean_return / mean_atrp\n",
    "        \n",
    "    return np.nan\n",
    "\n",
    "\n",
    "def print_nested(d, indent=0, width=4):\n",
    "    \"\"\"Pretty-print any nested dict/list/tuple combination.\"\"\"\n",
    "    spacing = ' ' * indent\n",
    "    if isinstance(d, dict):\n",
    "        for k, v in d.items():\n",
    "            print(f'{spacing}{k}:')\n",
    "            print_nested(v, indent + width, width)\n",
    "    elif isinstance(d, (list, tuple)):\n",
    "        for item in d:\n",
    "            print_nested(item, indent, width)\n",
    "    else:\n",
    "        print(f'{spacing}{d}')\n",
    "\n",
    "\n",
    "# --- B. MODULAR METRIC CALCULATION ENGINE ---\n",
    "\n",
    "def calculate_price_metric(metric_data: dict) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Calculates the 'Price' metric (total gain) over the calculation period.\n",
    "\n",
    "    Args:\n",
    "        metric_data: A dictionary containing pre-calculated data Series.\n",
    "                     Requires 'calc_close' (pd.DataFrame): The close prices for the calc period.\n",
    "\n",
    "    Returns:\n",
    "        A pandas Series of the calculated metric values, indexed by Ticker.\n",
    "    \"\"\"\n",
    "    calc_close = metric_data['calc_close']\n",
    "    \n",
    "    # Ensure there are at least two data points to calculate a gain\n",
    "    if len(calc_close) < 2:\n",
    "        return pd.Series(dtype='float64', index=calc_close.columns)\n",
    "\n",
    "    first_prices = calc_close.bfill().iloc[0]\n",
    "    last_prices = calc_close.ffill().iloc[-1]\n",
    "    \n",
    "    # The division of two Series aligns by index (Ticker), which is what we want.\n",
    "    price_metric = last_prices / first_prices\n",
    "    \n",
    "    return price_metric.dropna()\n",
    "\n",
    "\n",
    "def calculate_sharpe_metric(metric_data: dict) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Calculates the annualized 'Sharpe' ratio metric over the calculation period.\n",
    "\n",
    "    Args:\n",
    "        metric_data: A dictionary containing pre-calculated data Series.\n",
    "                     Requires 'daily_returns' (pd.DataFrame): Daily returns for the calc period.\n",
    "\n",
    "    Returns:\n",
    "        A pandas Series of the calculated metric values, indexed by Ticker.\n",
    "    \"\"\"\n",
    "    daily_returns = metric_data['daily_returns']\n",
    "    \n",
    "    # Ensure there's enough data to calculate standard deviation\n",
    "    if len(daily_returns.dropna()) < 2:\n",
    "        return pd.Series(dtype='float64', index=daily_returns.columns)\n",
    "    \n",
    "    mean_returns = daily_returns.mean()\n",
    "    std_returns = daily_returns.std()\n",
    "    \n",
    "    # Standard annualized Sharpe Ratio calculation. Avoid division by zero.\n",
    "    # We replace resulting NaNs/infs with 0 to handle cases of zero volatility.\n",
    "    sharpe_ratio = (mean_returns / std_returns * np.sqrt(252))\n",
    "    \n",
    "    return sharpe_ratio.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "    \n",
    "def calculate_sharpe_atr_metric(metric_data: dict) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Calculates the 'Sharpe (ATR)' metric over the calculation period.\n",
    "\n",
    "    Args:\n",
    "        metric_data: A dictionary containing pre-calculated data Series.\n",
    "                     Requires 'daily_returns' (pd.DataFrame): Daily returns for the calc period.\n",
    "                     Requires 'atrp' (pd.Series): Mean ATRP for each ticker over the period.\n",
    "\n",
    "    Returns:\n",
    "        A pandas Series of the calculated metric values, indexed by Ticker.\n",
    "    \"\"\"\n",
    "    daily_returns = metric_data['daily_returns']\n",
    "    atrp = metric_data['atrp']\n",
    "    \n",
    "    mean_returns = daily_returns.mean()\n",
    "    \n",
    "    # ATRP-based Sharpe. Avoid division by zero.\n",
    "    # We replace resulting NaNs/infs with 0.\n",
    "    sharpe_atr = mean_returns / atrp\n",
    "    \n",
    "    return sharpe_atr.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "\n",
    "def calculate_buy_and_hold_performance(df_close: pd.DataFrame,\n",
    "                                       features_df: pd.DataFrame,\n",
    "                                       tickers: list,\n",
    "                                       start_date: pd.Timestamp,\n",
    "                                       end_date: pd.Timestamp):\n",
    "    \"\"\"\n",
    "    Calculates performance for a buy-and-hold portfolio with specified initial weights.\n",
    "\n",
    "    [UPGRADED to handle duplicate tickers in the input list as initial weights.\n",
    "     e.g., ['A', 'A', 'B'] means an initial 2/3 weight in A and 1/3 in B.]\n",
    "\n",
    "    Args:\n",
    "        df_close (pd.DataFrame): DataFrame of adjusted close prices.\n",
    "        features_df (pd.DataFrame): DataFrame with 'ATRP' and a ('Ticker', 'Date') MultiIndex.\n",
    "        tickers (list): A list of ticker symbols. Duplicates indicate higher initial weight.\n",
    "        start_date (pd.Timestamp): The starting date for the calculation.\n",
    "        end_date (pd.Timestamp): The ending date for the calculation.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (portfolio_value_series, portfolio_return_series, portfolio_atrp_series)\n",
    "    \"\"\"\n",
    "    if not tickers or tickers is None:\n",
    "        empty_series = pd.Series(dtype='float64')\n",
    "        return empty_series, empty_series, empty_series\n",
    "\n",
    "    # --- NEW LOGIC: Determine initial weights from the input list ---\n",
    "    # 1. Count occurrences of each ticker\n",
    "    ticker_counts = Counter(tickers)\n",
    "    total_parts = len(tickers)\n",
    "\n",
    "    # 2. Create a Series of initial weights (e.g., {'A': 0.66, 'B': 0.33})\n",
    "    initial_weights = pd.Series({ticker: count / total_parts for ticker, count in ticker_counts.items()})\n",
    "    \n",
    "    # 3. Get the unique tickers needed for data selection\n",
    "    unique_tickers = initial_weights.index.tolist()\n",
    "    # --- END OF NEW LOGIC ---\n",
    "\n",
    "    # 4. Calculate Portfolio Value and Return Series\n",
    "    prices_raw = df_close[unique_tickers].loc[start_date:end_date]\n",
    "    if prices_raw.dropna(how='all').empty:\n",
    "        empty_series = pd.Series(dtype='float64')\n",
    "        return empty_series, empty_series, empty_series\n",
    "\n",
    "    # Normalize prices of each unique stock (growth of $1 in each)\n",
    "    prices_norm = prices_raw.div(prices_raw.bfill().iloc[0])\n",
    "\n",
    "    # Multiply the growth of each stock by its *initial* portfolio weight\n",
    "    weighted_growth = prices_norm.mul(initial_weights, axis='columns')\n",
    "\n",
    "    # The total portfolio value is the sum of the weighted growth of its components\n",
    "    value_series = weighted_growth.sum(axis=1)\n",
    "    return_series = value_series.pct_change()\n",
    "\n",
    "    # 5. Calculate Value-Weighted Portfolio ATRP Series\n",
    "    full_period_index = pd.MultiIndex.from_product(\n",
    "        [unique_tickers, return_series.index],\n",
    "        names=['Ticker', 'Date']\n",
    "    )\n",
    "    portfolio_atrp_features = features_df.loc[features_df.index.intersection(full_period_index)]\n",
    "    portfolio_atrp_daily_unstacked = portfolio_atrp_features['ATRP'].unstack(level='Ticker')\n",
    "\n",
    "    # The drifting weight of each component is its value (from weighted_growth)\n",
    "    # divided by the total portfolio value for that day.\n",
    "    drifting_weights = weighted_growth.div(value_series, axis='index')\n",
    "\n",
    "    aligned_weights, aligned_atrp = drifting_weights.align(portfolio_atrp_daily_unstacked, join='inner', axis=1)\n",
    "    \n",
    "    atrp_series = (aligned_weights * aligned_atrp).sum(axis=1)\n",
    "\n",
    "    return value_series, return_series, atrp_series\n",
    "\n",
    "\n",
    "\n",
    "# The single source of truth for all available ranking metrics.\n",
    "# Maps the user-facing name to the calculation function.\n",
    "METRIC_REGISTRY = {\n",
    "    'Price': calculate_price_metric,\n",
    "    'Sharpe': calculate_sharpe_metric,\n",
    "    'Sharpe (ATR)': calculate_sharpe_atr_metric,\n",
    "}\n",
    "\n",
    "print(\"✅ Metric Registry Initialized with:\", list(METRIC_REGISTRY.keys()))\n",
    "\n",
    "\n",
    "# --- B. THE CORE CALCULATION ENGINE ---\n",
    "\n",
    "def run_walk_forward_step(df_close_full, df_high_full, df_low_full,\n",
    "                          master_trading_days,\n",
    "                          start_date, calc_period, fwd_period,\n",
    "                          metric, rank_start, rank_end, benchmark_ticker,\n",
    "                          features_df,\n",
    "                          debug=False):\n",
    "    \"\"\"\n",
    "    Runs a single step of the walk-forward analysis with a strict, pre-emptive\n",
    "    check to ensure the full period is available.\n",
    "    \"\"\"\n",
    "    debug_data = {} if debug else None\n",
    "\n",
    "    # 1. Determine exact date ranges with a NEW pre-emptive check\n",
    "    try:\n",
    "        start_idx = master_trading_days.get_loc(start_date)\n",
    "    except KeyError:\n",
    "        return ({'error': f\"Start date {start_date.date()} is not a valid trading day.\"}, None)\n",
    "\n",
    "    # +++ THIS IS THE NEW PRE-EMPTIVE CHECK LOGIC +++\n",
    "    # Calculate the desired end index without clamping first.\n",
    "    desired_viz_end_idx = start_idx + calc_period + fwd_period\n",
    "    \n",
    "    # Check if the desired end index is out of bounds.\n",
    "    if desired_viz_end_idx >= len(master_trading_days):\n",
    "        last_available_date = master_trading_days[-1].date()\n",
    "        required_days = calc_period + fwd_period\n",
    "        available_days = len(master_trading_days) - start_idx\n",
    "        error_msg = (f\"Not enough data for the full requested period. \"\n",
    "                     f\"Required: {required_days} days, Available: {available_days} days until {last_available_date}.\")\n",
    "        return ({'error': error_msg}, None)\n",
    "    # --- END OF NEW CHECK ---\n",
    "\n",
    "    # If the check passes, we know the full period is available.\n",
    "    # The 'min' calls are now just a redundant safety measure.\n",
    "    calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "    viz_end_idx = min(calc_end_idx + fwd_period, len(master_trading_days) - 1)\n",
    "\n",
    "    safe_start_date = master_trading_days[start_idx]\n",
    "    safe_calc_end_date = master_trading_days[calc_end_idx]\n",
    "    safe_viz_end_date = master_trading_days[viz_end_idx]\n",
    "    \n",
    "    if safe_start_date >= safe_calc_end_date:\n",
    "        return ({'error': \"Invalid date range (calc period has zero or negative length).\"}, None)\n",
    "\n",
    "    # (The rest of the function remains completely unchanged...)\n",
    "    # 2. Slice data for the calculation period\n",
    "    calc_close_raw = df_close_full.loc[safe_start_date:safe_calc_end_date]\n",
    "    calc_close = calc_close_raw.dropna(axis=1, how='all')\n",
    "    if calc_close.shape[1] == 0 or len(calc_close) < 2:\n",
    "        return ({'error': \"Not enough data in calc period.\"}, None)\n",
    "\n",
    "    # 3. Calculate INTERMEDIATE data required for the ranking metrics\n",
    "    daily_returns = calc_close.bfill().ffill().pct_change()\n",
    "    valid_tickers = calc_close.columns\n",
    "    calc_period_index = pd.MultiIndex.from_product([valid_tickers, calc_close.index], names=['Ticker', 'Date'])\n",
    "    features_in_period = features_df.loc[features_df.index.intersection(calc_period_index)]\n",
    "    atrp = features_in_period.groupby(level='Ticker')['ATRP'].mean()\n",
    "\n",
    "    # 4. Calculate all ranking metrics by iterating through the METRIC_REGISTRY\n",
    "    metric_ingredients = { 'calc_close': calc_close, 'daily_returns': daily_returns, 'atrp': atrp, }\n",
    "    metric_values = {}\n",
    "    for name, func in METRIC_REGISTRY.items():\n",
    "        metric_values[name] = func(metric_ingredients)\n",
    "    if metric not in metric_values or metric_values[metric].empty:\n",
    "        return ({'error': f\"Metric '{metric}' could not be calculated or resulted in no valid tickers.\"}, None)\n",
    "\n",
    "    # 5. Rank tickers and select the portfolio\n",
    "    sorted_tickers = metric_values[metric].sort_values(ascending=False)\n",
    "    tickers_to_display = sorted_tickers.index[rank_start-1:rank_end].tolist()\n",
    "    if not tickers_to_display:\n",
    "        return ({'error': \"No tickers found for the selected rank.\"}, None)\n",
    "\n",
    "#################################\n",
    "    # 6. Calculate Portfolio & Benchmark Performance\n",
    "    # +++ THIS ENTIRE SECTION IS REFACTORED +++\n",
    "    actual_calc_end_ts = calc_close.index.max()\n",
    "\n",
    "    # +++ FIX: RE-INTRODUCE THE `normalized_plot_data` CALCULATION HERE +++\n",
    "    # This is needed for the debug trace and the final plot output.\n",
    "    normalized_plot_data = df_close_full[tickers_to_display].loc[safe_start_date:safe_viz_end_date]\n",
    "    normalized_plot_data = normalized_plot_data.div(normalized_plot_data.bfill().iloc[0])\n",
    "    # --- END OF FIX ---\n",
    "\n",
    "    # Use the new central function for the portfolio\n",
    "    portfolio_series, portfolio_return_series, portfolio_atrp_series = \\\n",
    "        calculate_buy_and_hold_performance(df_close_full, features_df, tickers_to_display,\n",
    "                                           safe_start_date, safe_viz_end_date)\n",
    "\n",
    "    # Use the new central function for the benchmark (a portfolio of one)\n",
    "    if benchmark_ticker in df_close_full.columns:\n",
    "        benchmark_price_series, benchmark_return_series, benchmark_atrp_series = \\\n",
    "            calculate_buy_and_hold_performance(df_close_full, features_df, [benchmark_ticker],\n",
    "                                               safe_start_date, safe_viz_end_date)\n",
    "    else:\n",
    "        benchmark_price_series = pd.Series(dtype='float64')\n",
    "        benchmark_return_series = pd.Series(dtype='float64')\n",
    "        benchmark_atrp_series = pd.Series(dtype='float64')\n",
    "\n",
    "    # Now, split the generated series into calc and fwd periods\n",
    "    # This logic remains, but it's much cleaner as it operates on the final series\n",
    "    try:\n",
    "        boundary_loc = portfolio_return_series.index.get_loc(actual_calc_end_ts)\n",
    "        calc_portfolio_returns = portfolio_return_series.iloc[:boundary_loc + 1]\n",
    "        fwd_portfolio_returns = portfolio_return_series.iloc[boundary_loc + 1:]\n",
    "        calc_portfolio_atrp = portfolio_atrp_series.iloc[:boundary_loc + 1]\n",
    "        fwd_portfolio_atrp = portfolio_atrp_series.iloc[boundary_loc + 1:]\n",
    "        \n",
    "        if not benchmark_return_series.empty:\n",
    "            bm_boundary_loc = benchmark_return_series.index.get_loc(actual_calc_end_ts)\n",
    "            calc_benchmark_returns = benchmark_return_series.iloc[:bm_boundary_loc + 1]\n",
    "            fwd_benchmark_returns = benchmark_return_series.iloc[bm_boundary_loc + 1:]\n",
    "            calc_benchmark_atrp = benchmark_atrp_series.iloc[:bm_boundary_loc + 1]\n",
    "            fwd_benchmark_atrp = benchmark_atrp_series.iloc[bm_boundary_loc + 1:]\n",
    "        else:\n",
    "            calc_benchmark_returns, fwd_benchmark_returns = pd.Series(dtype='float64'), pd.Series(dtype='float64')\n",
    "            calc_benchmark_atrp, fwd_benchmark_atrp = pd.Series(dtype='float64'), pd.Series(dtype='float64')\n",
    "\n",
    "    except (KeyError, IndexError): # Fallback for edge cases\n",
    "        calc_portfolio_returns = portfolio_return_series.loc[:actual_calc_end_ts]\n",
    "        fwd_portfolio_returns = portfolio_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "        calc_portfolio_atrp = portfolio_atrp_series.loc[:actual_calc_end_ts]\n",
    "        fwd_portfolio_atrp = portfolio_atrp_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "        \n",
    "        if not benchmark_return_series.empty:\n",
    "            calc_benchmark_returns = benchmark_return_series.loc[:actual_calc_end_ts]\n",
    "            fwd_benchmark_returns = benchmark_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "            calc_benchmark_atrp = benchmark_atrp_series.loc[:actual_calc_end_ts]\n",
    "            fwd_benchmark_atrp = benchmark_atrp_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "        else:\n",
    "            calc_benchmark_returns, fwd_benchmark_returns = pd.Series(dtype='float64'), pd.Series(dtype='float64')\n",
    "            calc_benchmark_atrp, fwd_benchmark_atrp = pd.Series(dtype='float64'), pd.Series(dtype='float64')\n",
    "\n",
    "\n",
    "###################\n",
    "\n",
    "    perf_data = {}\n",
    "    perf_data['calc_p_gain'] = calculate_gain(portfolio_series.loc[:actual_calc_end_ts])\n",
    "    perf_data['fwd_p_gain'] = calculate_gain(portfolio_series.loc[actual_calc_end_ts:])\n",
    "    perf_data['full_p_gain'] = calculate_gain(portfolio_series)\n",
    "    perf_data['calc_p_sharpe'] = calculate_sharpe(calc_portfolio_returns)\n",
    "    perf_data['fwd_p_sharpe'] = calculate_sharpe(fwd_portfolio_returns)\n",
    "    perf_data['full_p_sharpe'] = calculate_sharpe(portfolio_return_series)\n",
    "    perf_data['calc_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:actual_calc_end_ts]) if benchmark_price_series is not None else np.nan\n",
    "    perf_data['fwd_b_gain'] = calculate_gain(benchmark_price_series.loc[actual_calc_end_ts:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "    perf_data['full_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "    perf_data['calc_b_sharpe'] = calculate_sharpe(calc_benchmark_returns)\n",
    "    perf_data['fwd_b_sharpe'] = calculate_sharpe(fwd_benchmark_returns)\n",
    "    perf_data['full_b_sharpe'] = calculate_sharpe(benchmark_return_series)\n",
    "    perf_data['calc_p_sharpe_atr'] = calculate_sharpe_atr(calc_portfolio_returns, calc_portfolio_atrp)\n",
    "    perf_data['fwd_p_sharpe_atr'] = calculate_sharpe_atr(fwd_portfolio_returns, fwd_portfolio_atrp)\n",
    "    perf_data['full_p_sharpe_atr'] = calculate_sharpe_atr(portfolio_return_series, portfolio_atrp_series)\n",
    "    perf_data['calc_b_sharpe_atr'] = calculate_sharpe_atr(calc_benchmark_returns, calc_benchmark_atrp)\n",
    "    perf_data['fwd_b_sharpe_atr'] = calculate_sharpe_atr(fwd_benchmark_returns, fwd_benchmark_atrp)\n",
    "    perf_data['full_b_sharpe_atr'] = calculate_sharpe_atr(benchmark_return_series, benchmark_atrp_series)\n",
    "    if debug:\n",
    "        df_ranking_base = pd.DataFrame({'MeanDailyReturn': daily_returns.mean(),'StdDevDailyReturn': daily_returns.std(),'MeanATRP': atrp})\n",
    "        df_metrics = pd.DataFrame(metric_values)\n",
    "        df_metrics.columns = [f'Metric_{col}' for col in df_metrics.columns]\n",
    "        df_ranking = df_ranking_base.join(df_metrics, how='left')\n",
    "        df_ranking.index.name = 'Ticker'\n",
    "        debug_data['ranking_metrics'] = df_ranking.sort_values(f'Metric_{metric}', ascending=False)\n",
    "    calc_end_prices = calc_close.ffill().iloc[-1]\n",
    "    fwd_close_slice = df_close_full.loc[actual_calc_end_ts:safe_viz_end_date]\n",
    "    viz_end_prices = fwd_close_slice.ffill().iloc[-1] if not fwd_close_slice.empty and len(fwd_close_slice) >= 2 else calc_end_prices\n",
    "    calc_gains = (calc_end_prices / calc_close.bfill().iloc[0]) - 1\n",
    "    fwd_gains = (viz_end_prices / calc_end_prices) - 1\n",
    "    results_df = pd.DataFrame({'Rank': range(rank_start, rank_start + len(tickers_to_display)), 'Metric': metric, 'MetricValue': sorted_tickers.loc[tickers_to_display].values, 'CalcPrice': calc_end_prices.loc[tickers_to_display], 'CalcGain': calc_gains.loc[tickers_to_display], 'FwdGain': fwd_gains.loc[tickers_to_display]}, index=pd.Index(tickers_to_display, name='Ticker'))\n",
    "    if benchmark_price_series is not None and benchmark_ticker in calc_close.columns:\n",
    "        benchmark_df_row = pd.DataFrame({'Rank': np.nan, 'Metric': metric, 'MetricValue': metric_values[metric].get(benchmark_ticker, np.nan), 'CalcPrice': calc_end_prices[benchmark_ticker], 'CalcGain': calc_gains[benchmark_ticker], 'FwdGain': fwd_gains[benchmark_ticker]}, index=pd.Index([f\"{benchmark_ticker} (BM)\"], name='Ticker'))\n",
    "        results_df = pd.concat([results_df, benchmark_df_row])\n",
    "    if debug:\n",
    "        df_trace = normalized_plot_data.copy()\n",
    "        df_trace.columns = [f'Norm_Price_{c}' for c in df_trace.columns]\n",
    "        df_trace['Norm_Price_Portfolio'] = portfolio_series\n",
    "        if benchmark_price_series is not None and not benchmark_price_series.loc[safe_start_date:safe_viz_end_date].dropna().empty:\n",
    "            norm_bm = benchmark_price_series.loc[safe_start_date:safe_viz_end_date] / benchmark_price_series.loc[safe_start_date:].bfill().iloc[0]\n",
    "            df_trace[f'Norm_Price_Benchmark_{benchmark_ticker}'] = norm_bm\n",
    "        for col in df_trace.columns:\n",
    "            if 'Norm_Price' in col:\n",
    "                df_trace[col.replace('Norm_Price', 'Return')] = df_trace[col].pct_change()\n",
    "        debug_data['portfolio_trace'] = df_trace\n",
    "    final_results = {\n",
    "        'tickers_to_display': tickers_to_display, 'normalized_plot_data': normalized_plot_data,\n",
    "        'portfolio_series': portfolio_series, 'benchmark_price_series': benchmark_price_series,\n",
    "        'performance_data': perf_data, 'results_df': results_df, 'actual_calc_end_ts': actual_calc_end_ts,\n",
    "        'safe_start_date': safe_start_date, 'safe_viz_end_date': safe_viz_end_date,\n",
    "        'error': None\n",
    "    }\n",
    "    return (final_results, debug_data)\n",
    "\n",
    "\n",
    "# --- C. DYNAMIC DATA QUALITY FILTER FUNCTIONS ---\n",
    "\n",
    "def get_eligible_universe(features_df, filter_date, thresholds):\n",
    "    \"\"\"Filters the universe of tickers based on quality metrics for a given date.\"\"\"\n",
    "    filter_date_ts = pd.to_datetime(filter_date)\n",
    "    # The index is now the comprehensive features_df\n",
    "    date_index = features_df.index.get_level_values('Date').unique().sort_values()\n",
    "    \n",
    "    if filter_date_ts < date_index[0]:\n",
    "        print(f\"Warning: Filter date {filter_date_ts.date()} is before the earliest data point. Returning empty universe.\")\n",
    "        return []\n",
    "        \n",
    "    # Find the most recent date with quality data on or before the filter date\n",
    "    valid_prior_dates = date_index[date_index <= filter_date_ts]\n",
    "    if valid_prior_dates.empty:\n",
    "        print(f\"Warning: No available data found on or before {filter_date_ts.date()}. Returning empty universe.\")\n",
    "        return []\n",
    "        \n",
    "    actual_date_to_use = valid_prior_dates[-1]\n",
    "    if actual_date_to_use.date() != filter_date_ts.date():\n",
    "        print(f\"ℹ️ Info: Filter date {filter_date_ts.date()} not found. Using previous available date {actual_date_to_use.date()}.\")\n",
    "\n",
    "    metrics_on_date = features_df.xs(actual_date_to_use, level='Date')\n",
    "    \n",
    "    # Apply filters using the new column names from features_df\n",
    "    mask = ((metrics_on_date['RollMedDollarVol'] >= thresholds['min_median_dollar_volume']) & # <-- RENAMED\n",
    "            (metrics_on_date['RollingStalePct'] <= thresholds['max_stale_pct']) &\n",
    "            (metrics_on_date['RollingSameVolCount'] <= thresholds['max_same_vol_count']))\n",
    "            \n",
    "    eligible_tickers = metrics_on_date[mask].index.tolist()\n",
    "    all_tickers = metrics_on_date.index.tolist()\n",
    "    print(f\"Dynamic Filter ({filter_date_ts.date()}): Kept {len(eligible_tickers)} of {len(all_tickers)} tickers.\")\n",
    "    return eligible_tickers\n",
    "\n",
    "\n",
    "# --- D. INTERACTIVE ANALYSIS & BACKTESTING TOOLS ---\n",
    "\n",
    "def plot_walk_forward_analyzer(df_ohlcv,\n",
    "                               default_start_date=None, default_calc_period=126, default_fwd_period=63,\n",
    "                               default_metric='Sharpe (ATR)', default_rank_start=1, default_rank_end=10,\n",
    "                               default_benchmark_ticker='SPY', master_calendar_ticker='SPY',\n",
    "                               quality_thresholds={'min_median_dollar_volume': 1_000_000, 'max_stale_pct': 0.05, 'max_same_vol_count': 10},\n",
    "                               debug=False):\n",
    "    # --- Initial Setup and Widget Creation (unchanged) ---\n",
    "    print(\"Initializing Walk-Forward Analyzer...\")\n",
    "    # ... (all setup code is identical)\n",
    "    if not isinstance(df_ohlcv.index, pd.MultiIndex): raise ValueError(\"Input DataFrame must have a (Ticker, Date) MultiIndex.\")\n",
    "    df_ohlcv = df_ohlcv.sort_index()\n",
    "    if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "        raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "    master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "    print(f\"Master trading day calendar created from '{master_calendar_ticker}' ({len(master_trading_days)} days).\")\n",
    "    print(\"--- Generating all features upfront... ---\")\n",
    "    features_df = generate_features(df_ohlcv)\n",
    "    print(\"Pre-processing data (unstacking)...\")\n",
    "    df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "    df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "    df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "\n",
    "    # --- Widget Creation (existing widgets) ---\n",
    "    start_date_picker = widgets.DatePicker(description='Start Date:', value=pd.to_datetime(default_start_date), disabled=False)\n",
    "    calc_period_input = widgets.IntText(value=default_calc_period, description='Calc Period (days):')\n",
    "    fwd_period_input = widgets.IntText(value=default_fwd_period, description='Fwd Period (days):')\n",
    "    if default_metric not in METRIC_REGISTRY:\n",
    "        default_metric = list(METRIC_REGISTRY.keys())[0]\n",
    "    metric_dropdown = widgets.Dropdown(options=list(METRIC_REGISTRY.keys()), value=default_metric, description='Metric:')\n",
    "    rank_start_input = widgets.IntText(value=default_rank_start, description='Rank Start:')\n",
    "    rank_end_input = widgets.IntText(value=default_rank_end, description='Rank End:')\n",
    "    benchmark_ticker_input = widgets.Text(value=default_benchmark_ticker, description='Benchmark:', placeholder='Enter Ticker')\n",
    "    update_button = widgets.Button(description=\"Update Chart\", button_style='primary')\n",
    "    mode_selector = widgets.RadioButtons(options=['Ranking', 'Manual List'], value='Ranking', description='Portfolio Mode:', layout={'width': 'max-content'})\n",
    "    manual_tickers_input = widgets.Textarea(value='', placeholder='Enter tickers, comma-separated...\\ne.g., AAPL, AAPL, MSFT, GOOG', description='Manual Tickers:', layout={'width': '400px', 'height': '80px'})\n",
    "    \n",
    "    # --- Layout and Observer Setup (unchanged) ---\n",
    "    ranking_controls_box = widgets.HBox([metric_dropdown, rank_start_input, rank_end_input])\n",
    "    manual_controls_box = widgets.HBox([manual_tickers_input])\n",
    "    def on_mode_change(change):\n",
    "        if change['new'] == 'Ranking':\n",
    "            ranking_controls_box.layout.display = 'flex'; manual_controls_box.layout.display = 'none'\n",
    "        else:\n",
    "            ranking_controls_box.layout.display = 'none'; manual_controls_box.layout.display = 'flex'\n",
    "    mode_selector.observe(on_mode_change, names='value')\n",
    "    \n",
    "    # --- Plot and Output Setup ---\n",
    "    ticker_list_output = widgets.Output()\n",
    "    results_container, debug_data_container = [None], [None]\n",
    "    fig = go.FigureWidget()\n",
    "    max_traces = 50\n",
    "    for i in range(max_traces): fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name=f'placeholder_{i}', visible=False, showlegend=False))\n",
    "    # Note the names here match the update logic below\n",
    "    fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Benchmark', visible=True, showlegend=True, line=dict(color='black', width=3, dash='dash')))\n",
    "    fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Group Portfolio', visible=True, showlegend=True, line=dict(color='green', width=3)))\n",
    "\n",
    "    def update_plot(button_click):\n",
    "        ticker_list_output.clear_output()\n",
    "        # --- 1. Common Parameter Gathering and Validation (unchanged) ---\n",
    "        start_date_raw = pd.to_datetime(start_date_picker.value)\n",
    "        start_date_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "        actual_start_date = master_trading_days[start_date_idx]\n",
    "\n",
    "        # ### NEW WARNING LOGIC STARTS HERE ###\n",
    "        # Check if the requested date is significantly before the Master Calendar's first day\n",
    "        first_available_date = master_trading_days[0]\n",
    "        \n",
    "        # We assume if the difference is more than 7 days, it's a user error, not a holiday offset\n",
    "        if start_date_raw < (first_available_date - pd.Timedelta(days=7)):\n",
    "            with ticker_list_output:\n",
    "                print(f\"⚠️ DATE WARNING: The requested start date ({start_date_raw.date()}) is unavailable.\")\n",
    "                print(f\"   The Master Calendar Ticker '{master_calendar_ticker}' only starts trading on {first_available_date.date()}.\")\n",
    "                print(f\"   >> System auto-adjusted the start date to: {actual_start_date.date()}\")\n",
    "                print(f\"   >> To fix: Use a Master Ticker with longer history (e.g., 'SPY' starts 1993).\")\n",
    "                print(\"-\" * 60)\n",
    "        # ### NEW WARNING LOGIC ENDS HERE ###\n",
    "\n",
    "        calc_period = calc_period_input.value; fwd_period = fwd_period_input.value\n",
    "        benchmark_ticker = benchmark_ticker_input.value.strip().upper()\n",
    "        \n",
    "        # --- 2. Mode-Specific Logic to Get Results (unchanged) ---\n",
    "        selected_mode = mode_selector.value\n",
    "        results, debug_output = None, None\n",
    "        if selected_mode == 'Ranking':\n",
    "            metric = metric_dropdown.value\n",
    "            rank_start = rank_start_input.value; rank_end = rank_end_input.value\n",
    "            eligible_tickers = get_eligible_universe(features_df, actual_start_date, quality_thresholds)\n",
    "            results, debug_output = run_walk_forward_step(df_close_full, df_high_full, df_low_full, master_trading_days, actual_start_date, calc_period, fwd_period, metric, rank_start, rank_end, benchmark_ticker, features_df=features_df, debug=debug)\n",
    "        elif selected_mode == 'Manual List':\n",
    "            raw_text = manual_tickers_input.value\n",
    "            manual_tickers = [t.strip().upper() for t in raw_text.split(',') if t.strip()]\n",
    "            results, debug_output = run_manual_portfolio_step(df_close_full, features_df, manual_tickers, master_trading_days, actual_start_date, calc_period, fwd_period, benchmark_ticker, debug=debug)\n",
    "        \n",
    "        # --- 3. Common Results Processing and Plotting ---\n",
    "        if results.get('error'):\n",
    "            with ticker_list_output: print(f\"Error: {results['error']}\"); return\n",
    "        results_container[0] = results; debug_data_container[0] = debug_output\n",
    "        \n",
    "        with fig.batch_update():\n",
    "            for i in range(max_traces):\n",
    "                trace = fig.data[i]\n",
    "                if i < len(results['tickers_to_display']):\n",
    "                    ticker = results['tickers_to_display'][i]; plot_data_series = results['normalized_plot_data'][ticker]\n",
    "                    trace.x, trace.y, trace.name, trace.visible, trace.showlegend = plot_data_series.index, plot_data_series.values, ticker, True, True\n",
    "                else: trace.visible, trace.showlegend = False, False\n",
    "            \n",
    "            ### RESTORED ### --- Benchmark and Portfolio Trace Logic ---\n",
    "            benchmark_trace = fig.data[max_traces]\n",
    "            # Use the pre-normalized benchmark series if available\n",
    "            if results['benchmark_price_series'] is not None and not results['benchmark_price_series'].dropna().empty:\n",
    "                benchmark_series = results['benchmark_price_series']\n",
    "                benchmark_trace.x, benchmark_trace.y, benchmark_trace.name, benchmark_trace.visible = benchmark_series.index, benchmark_series.values, f\"Benchmark ({benchmark_ticker})\", True\n",
    "            else:\n",
    "                benchmark_trace.visible = False\n",
    "\n",
    "            portfolio_trace = fig.data[max_traces + 1]\n",
    "            portfolio_trace.x, portfolio_trace.y, portfolio_trace.name, portfolio_trace.visible = results['portfolio_series'].index, results['portfolio_series'].values, 'Group Portfolio', True\n",
    "            \n",
    "            fig.layout.shapes = []; fig.add_shape(type=\"line\", x0=results['actual_calc_end_ts'], y0=0, x1=results['actual_calc_end_ts'], y1=1, xref='x', yref='paper', line=dict(color=\"grey\", width=2, dash=\"dash\"))\n",
    "            ### END RESTORED ###\n",
    "            \n",
    "        with ticker_list_output:\n",
    "            print(f\"Analysis Period: {results['safe_start_date'].date()} to {results['safe_viz_end_date'].date()}.\")\n",
    "            if selected_mode == 'Ranking':\n",
    "                print(\"Ranked Tickers:\"); pprint.pprint(results['tickers_to_display'])\n",
    "            else:\n",
    "                print(\"Manual Portfolio (Unique Tickers):\"); pprint.pprint(results['tickers_to_display'])\n",
    "                print(\"\\n--- Portfolio Composition ---\"); display(results['results_df'].style.format({'InitialWeight': '{:.2%}', 'FwdGain': '{:+.2%}'}))\n",
    "\n",
    "            ### RESTORED ### --- Performance Summary Table Logic ---\n",
    "            p = results['performance_data']\n",
    "            rows = []\n",
    "            rows.append({'Metric': 'Group Portfolio Gain', 'Full': p['full_p_gain'], 'Calc': p['calc_p_gain'], 'Fwd': p['fwd_p_gain']})\n",
    "            if not np.isnan(p.get('full_b_gain')):\n",
    "                rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Gain', 'Full': p['full_b_gain'], 'Calc': p['calc_b_gain'], 'Fwd': p['fwd_b_gain']})\n",
    "                rows.append({'Metric': '== Gain Delta (vs Bm)', 'Full': p['full_p_gain'] - p['full_b_gain'], 'Calc': p['calc_p_gain'] - p['calc_b_gain'], 'Fwd': p['fwd_p_gain'] - p['fwd_b_gain']})\n",
    "            rows.append({'Metric': 'Group Portfolio Sharpe (ATR)', 'Full': p['full_p_sharpe_atr'], 'Calc': p['calc_p_sharpe_atr'], 'Fwd': p['fwd_p_sharpe_atr']})\n",
    "            if not np.isnan(p.get('full_b_sharpe_atr')):\n",
    "                rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Sharpe (ATR)', 'Full': p['full_b_sharpe_atr'], 'Calc': p['calc_b_sharpe_atr'], 'Fwd': p['fwd_b_sharpe_atr']})\n",
    "                rows.append({'Metric': '== Sharpe (ATR) Delta (vs Bm)', 'Full': p['full_p_sharpe_atr'] - p['full_b_sharpe_atr'], 'Calc': p['calc_p_sharpe_atr'] - p['calc_b_sharpe_atr'], 'Fwd': p['fwd_p_sharpe_atr'] - p['fwd_b_sharpe_atr']})\n",
    "            \n",
    "            report_df = pd.DataFrame(rows).set_index('Metric')\n",
    "            gain_rows = [row for row in report_df.index if 'Gain' in row]\n",
    "            sharpe_rows = [row for row in report_df.index if 'Sharpe' in row]\n",
    "            \n",
    "            styled_df = report_df.style.format('{:+.2%}', na_rep='N/A', subset=(gain_rows, report_df.columns)).format('{:+.4f}', na_rep='N/A', subset=(sharpe_rows, report_df.columns)).set_properties(**{'text-align': 'right', 'width': '100px'}).set_table_styles([{'selector': 'th.col_heading', 'props': [('text-align', 'right')]}, {'selector': 'th.row_heading', 'props': [('text-align', 'left')]}])\n",
    "            \n",
    "            print(\"\\n--- Strategy Performance Summary ---\")\n",
    "            display(styled_df)\n",
    "            ### END RESTORED ###\n",
    "\n",
    "    # --- Final UI Assembly and Initial Call (unchanged) ---\n",
    "    mode_selector_row = widgets.HBox([mode_selector], layout=widgets.Layout(margin='0 0 10px 125px'))\n",
    "    controls_row1 = widgets.HBox([start_date_picker, calc_period_input, fwd_period_input])\n",
    "    common_controls_row = widgets.HBox([benchmark_ticker_input, update_button])\n",
    "    ui_container = widgets.VBox([mode_selector_row, controls_row1, ranking_controls_box, manual_controls_box, common_controls_row, ticker_list_output], layout=widgets.Layout(margin='10px 0 20px 0'))\n",
    "    fig.update_layout(title_text='Walk-Forward Performance Analysis', xaxis_title='Date', yaxis_title='Normalized Price', hovermode='x unified', height=600)\n",
    "    fig.add_hline(y=1, line_width=1, line_dash=\"dash\", line_color=\"grey\")\n",
    "    update_button.on_click(update_plot)\n",
    "    \n",
    "    # ### MODIFIED ### Assemble the final UI container with the new widgets\n",
    "    # The benchmark and update button are now in their own row for better layout.\n",
    "    common_controls_row = widgets.HBox([benchmark_ticker_input, update_button])\n",
    "    \n",
    "    ### MODIFIED ### - Add a wrapper HBox with a left margin for alignment\n",
    "    # This pushes the radio buttons to the right to align with the input fields below it.\n",
    "    # You can adjust the '95px' value for pixel-perfect alignment in your environment.\n",
    "    mode_selector_row = widgets.HBox(\n",
    "        [mode_selector],\n",
    "        layout=widgets.Layout(margin='0 0 10px 95px') # top, right, bottom, left\n",
    "    )\n",
    "\n",
    "    ui_container = widgets.VBox([\n",
    "        mode_selector_row, # Use the new aligned row\n",
    "        controls_row1,\n",
    "        ranking_controls_box, # Will be shown/hidden by the observer\n",
    "        manual_controls_box,  # Will be shown/hidden by the observer\n",
    "        common_controls_row,\n",
    "        ticker_list_output\n",
    "    ], layout=widgets.Layout(margin='10px 0 20px 0'))\n",
    "    \n",
    "    # ### NEW ### Set the initial visibility of the controls\n",
    "    on_mode_change({'new': mode_selector.value})\n",
    "    display(ui_container, fig)\n",
    "    update_plot(None)\n",
    "    \n",
    "    return (results_container, debug_data_container)\n",
    "\n",
    "\n",
    "def run_full_backtest(df_ohlcv, strategy_params, quality_thresholds):\n",
    "    \"\"\"Runs a full backtest of a strategy over a specified date range.\"\"\"\n",
    "    print(f\"--- Running Full Forensic Backtest for Strategy: {strategy_params['metric']} (Top {strategy_params['rank_start']}-{strategy_params['rank_end']}) ---\")\n",
    "    \n",
    "    # (No changes to the initial setup part...)\n",
    "    start_date, end_date = pd.to_datetime(strategy_params['start_date']), pd.to_datetime(strategy_params['end_date'])\n",
    "    calc_period, fwd_period = strategy_params['calc_period'], strategy_params['fwd_period']\n",
    "    metric, rank_start, rank_end = strategy_params['metric'], strategy_params['rank_start'], strategy_params['rank_end']\n",
    "    benchmark_ticker = strategy_params['benchmark_ticker']\n",
    "    master_calendar_ticker = strategy_params.get('master_calendar_ticker', 'VOO')\n",
    "    if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "        raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "    master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "    start_idx = master_trading_days.searchsorted(start_date)\n",
    "    end_idx = master_trading_days.searchsorted(end_date, side='right')\n",
    "    print(\"--- Generating all features upfront... ---\")\n",
    "    features_df = generate_features(df_ohlcv)\n",
    "    df_close_full = df_ohlcv['Adj Close'].unstack(level=0); df_high_full = df_ohlcv['Adj High'].unstack(level=0); df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    \n",
    "    # Loop through all periods in the backtest range\n",
    "    step_indices = range(start_idx, end_idx, fwd_period)\n",
    "    all_fwd_gains, period_by_period_debug = [], {}\n",
    "\n",
    "    print(f\"Simulating {len(step_indices)} periods from {master_trading_days[step_indices[0]].date()} to {master_trading_days[step_indices[-1]].date()}...\")\n",
    "    for current_idx in tqdm(step_indices, desc=\"Backtest Progress\"):\n",
    "        step_date = master_trading_days[current_idx]\n",
    "        eligible_tickers = get_eligible_universe(features_df, step_date, quality_thresholds)\n",
    "        if not eligible_tickers: continue\n",
    "        df_close_step = df_close_full[eligible_tickers]; df_high_step = df_high_full[eligible_tickers]; df_low_step = df_low_full[eligible_tickers]\n",
    "        \n",
    "        # +++ UPDATE THE CALL HERE +++\n",
    "        results, debug_output = run_walk_forward_step(\n",
    "            df_close_step, df_high_step, df_low_step, master_trading_days,\n",
    "            step_date, calc_period, fwd_period,\n",
    "            metric, rank_start, rank_end, benchmark_ticker,\n",
    "            features_df=features_df,  # Pass the features_df\n",
    "            debug=True\n",
    "        )\n",
    "        \n",
    "        # (The rest of the function remains unchanged...)\n",
    "        if results['error'] is None:\n",
    "            fwd_series = results['portfolio_series'].loc[results['actual_calc_end_ts']:]\n",
    "            all_fwd_gains.append(fwd_series.pct_change().dropna())\n",
    "            period_by_period_debug[step_date.date().isoformat()] = debug_output\n",
    "            \n",
    "    if not all_fwd_gains:\n",
    "        print(\"Error: No valid periods were simulated.\"); return None\n",
    "\n",
    "    strategy_returns = pd.concat(all_fwd_gains); strategy_equity_curve = (1 + strategy_returns).cumprod()\n",
    "    benchmark_returns = df_close_full[benchmark_ticker].pct_change().loc[strategy_equity_curve.index]; benchmark_equity_curve = (1 + benchmark_returns).cumprod()\n",
    "    cumulative_equity_df = pd.DataFrame({'Strategy_Equity': strategy_equity_curve, 'Benchmark_Equity': benchmark_equity_curve})\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=cumulative_equity_df.index, y=cumulative_equity_df['Strategy_Equity'], name='Strategy', line=dict(color='green')))\n",
    "    fig.add_trace(go.Scatter(x=cumulative_equity_df.index, y=cumulative_equity_df['Benchmark_Equity'], name=f'Benchmark ({benchmark_ticker})', line=dict(color='black', dash='dash')))\n",
    "    fig.update_layout(title=f\"Cumulative Performance: '{metric}' Strategy (Top {rank_start}-{rank_end})\", xaxis_title=\"Date\", yaxis_title=\"Cumulative Growth\")\n",
    "    fig.show()\n",
    "    final_backtest_results = {'cumulative_performance': cumulative_equity_df, 'period_by_period_debug': period_by_period_debug}\n",
    "    print(\"\\n✅ Full backtest complete. Results object is ready for forensic analysis.\")\n",
    "    return final_backtest_results\n",
    "\n",
    "\n",
    "def run_manual_portfolio_step(df_close_full, features_df,\n",
    "                              manual_tickers,\n",
    "                              master_trading_days,\n",
    "                              start_date, calc_period, fwd_period,\n",
    "                              benchmark_ticker,\n",
    "                              debug=False):\n",
    "    \"\"\"\n",
    "    [CORRECTED to calculate the full, comprehensive set of performance metrics,\n",
    "     including standard Sharpe, to match the output of run_walk_forward_step.]\n",
    "\n",
    "     Runs a performance analysis for a manually specified portfolio of tickers.\n",
    "\n",
    "    Bypasses all ranking and filtering logic, directly calculating performance\n",
    "    for the provided list. The output format is identical to run_walk_forward_step\n",
    "    for seamless UI integration.\n",
    "\n",
    "    Args:\n",
    "        df_close_full (pd.DataFrame): DataFrame of all close prices.\n",
    "        features_df (pd.DataFrame): DataFrame with all features (for ATRP).\n",
    "        manual_tickers (list): The user-provided list of tickers, duplicates allowed.\n",
    "        master_trading_days (pd.DatetimeIndex): The calendar of trading days.\n",
    "        start_date (pd.Timestamp): The desired start date for the analysis.\n",
    "        calc_period (int): The number of days in the calculation period.\n",
    "        fwd_period (int): The number of days in the forward-test period.\n",
    "        benchmark_ticker (str): The ticker symbol for the benchmark.\n",
    "        debug (bool): Flag to generate detailed debug data.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (results_dict, debug_dict) in the same format as run_walk_forward_step.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Sections 1-4 (Date calculation, Ticker validation, Core performance calls) are unchanged ---\n",
    "    debug_data = {} if debug else None\n",
    "    try: start_idx = master_trading_days.get_loc(start_date)\n",
    "    except KeyError: return ({'error': f\"Start date {start_date.date()} is not a valid trading day.\"}, None)\n",
    "    desired_viz_end_idx = start_idx + calc_period + fwd_period\n",
    "    if desired_viz_end_idx >= len(master_trading_days): return ({'error': \"Not enough data for the full requested period.\"}, None)\n",
    "    calc_end_idx = start_idx + calc_period\n",
    "    viz_end_idx = calc_end_idx + fwd_period\n",
    "    safe_start_date, safe_calc_end_date, safe_viz_end_date = master_trading_days[start_idx], master_trading_days[calc_end_idx], master_trading_days[viz_end_idx]\n",
    "    if not manual_tickers: return ({'error': \"The manual ticker list cannot be empty.\"}, None)\n",
    "    unique_tickers_in_list = sorted(list(set(manual_tickers)))\n",
    "    valid_tickers_in_data = [t for t in unique_tickers_in_list if t in df_close_full.columns]\n",
    "    if not valid_tickers_in_data: return ({'error': \"None of the provided tickers were found in the dataset.\"}, None)\n",
    "    tickers_to_display = [t for t in manual_tickers if t in valid_tickers_in_data]\n",
    "    portfolio_series, portfolio_return_series, portfolio_atrp_series = calculate_buy_and_hold_performance(df_close_full, features_df, tickers_to_display, safe_start_date, safe_viz_end_date)\n",
    "    if benchmark_ticker and benchmark_ticker in df_close_full.columns:\n",
    "        benchmark_price_series, benchmark_return_series, benchmark_atrp_series = calculate_buy_and_hold_performance(df_close_full, features_df, [benchmark_ticker], safe_start_date, safe_viz_end_date)\n",
    "    else:\n",
    "        benchmark_price_series, benchmark_return_series, benchmark_atrp_series = (pd.Series(dtype='float64'),)*3\n",
    "    actual_calc_end_ts = safe_calc_end_date\n",
    "    calc_portfolio_returns = portfolio_return_series.loc[:actual_calc_end_ts]; fwd_portfolio_returns = portfolio_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "    calc_portfolio_atrp = portfolio_atrp_series.loc[:actual_calc_end_ts]; fwd_portfolio_atrp = portfolio_atrp_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "\n",
    "    # --- 5. Calculate final performance metrics ---\n",
    "    perf_data = {}\n",
    "    if not benchmark_price_series.empty:\n",
    "        calc_benchmark_returns = benchmark_return_series.loc[:actual_calc_end_ts]; fwd_benchmark_returns = benchmark_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "        calc_benchmark_atrp = benchmark_atrp_series.loc[:actual_calc_end_ts]; fwd_benchmark_atrp = benchmark_atrp_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "    else:\n",
    "        calc_benchmark_returns, fwd_benchmark_returns = pd.Series(dtype='float64'), pd.Series(dtype='float64')\n",
    "        calc_benchmark_atrp, fwd_benchmark_atrp = pd.Series(dtype='float64'), pd.Series(dtype='float64')\n",
    "    perf_data['calc_p_gain'] = calculate_gain(portfolio_series.loc[:actual_calc_end_ts])\n",
    "    perf_data['fwd_p_gain'] = calculate_gain(portfolio_series.loc[actual_calc_end_ts:])\n",
    "    perf_data['full_p_gain'] = calculate_gain(portfolio_series)\n",
    "    perf_data['calc_p_sharpe'] = calculate_sharpe(calc_portfolio_returns)\n",
    "    perf_data['fwd_p_sharpe'] = calculate_sharpe(fwd_portfolio_returns)\n",
    "    perf_data['full_p_sharpe'] = calculate_sharpe(portfolio_return_series)\n",
    "    perf_data['calc_b_gain'] = calculate_gain(benchmark_price_series.loc[:actual_calc_end_ts]) if not benchmark_price_series.empty else np.nan\n",
    "    perf_data['fwd_b_gain'] = calculate_gain(benchmark_price_series.loc[actual_calc_end_ts:]) if not benchmark_price_series.empty else np.nan\n",
    "    perf_data['full_b_gain'] = calculate_gain(benchmark_price_series) if not benchmark_price_series.empty else np.nan\n",
    "    perf_data['calc_b_sharpe'] = calculate_sharpe(calc_benchmark_returns)\n",
    "    perf_data['fwd_b_sharpe'] = calculate_sharpe(fwd_benchmark_returns)\n",
    "    perf_data['full_b_sharpe'] = calculate_sharpe(benchmark_return_series)\n",
    "    perf_data['calc_p_sharpe_atr'] = calculate_sharpe_atr(calc_portfolio_returns, calc_portfolio_atrp)\n",
    "    perf_data['fwd_p_sharpe_atr'] = calculate_sharpe_atr(fwd_portfolio_returns, fwd_portfolio_atrp)\n",
    "    perf_data['full_p_sharpe_atr'] = calculate_sharpe_atr(portfolio_return_series, portfolio_atrp_series)\n",
    "    perf_data['calc_b_sharpe_atr'] = calculate_sharpe_atr(calc_benchmark_returns, calc_benchmark_atrp)\n",
    "    perf_data['fwd_b_sharpe_atr'] = calculate_sharpe_atr(fwd_benchmark_returns, fwd_benchmark_atrp)\n",
    "    perf_data['full_b_sharpe_atr'] = calculate_sharpe_atr(benchmark_return_series, benchmark_atrp_series)\n",
    "\n",
    "    # --- Sections 6-8 (results_df, debug data, final dict assembly) ---\n",
    "    from collections import Counter\n",
    "    ticker_counts = Counter(tickers_to_display); total_parts = len(tickers_to_display)\n",
    "    start_prices = df_close_full.loc[actual_calc_end_ts, valid_tickers_in_data]; end_prices = df_close_full.loc[safe_viz_end_date, valid_tickers_in_data]\n",
    "    fwd_gains = (end_prices / start_prices) - 1\n",
    "    results_data = [{'InitialWeight': ticker_counts[ticker] / total_parts, 'FwdGain': fwd_gains.get(ticker, np.nan)} for ticker in valid_tickers_in_data]\n",
    "    results_df = pd.DataFrame(results_data, index=pd.Index(valid_tickers_in_data, name='Ticker'))\n",
    "    normalized_plot_data = df_close_full[valid_tickers_in_data].loc[safe_start_date:safe_viz_end_date]\n",
    "    normalized_plot_data = normalized_plot_data.div(normalized_plot_data.bfill().iloc[0])\n",
    "\n",
    "    # === START: MISSING CODE BLOCK ==============================================\n",
    "    if debug:\n",
    "        # Create the portfolio trace for debugging, similar to the original function\n",
    "        df_trace = normalized_plot_data.copy()\n",
    "        df_trace.columns = [f'Norm_Price_{c}' for c in df_trace.columns]\n",
    "        df_trace['Norm_Price_Portfolio'] = portfolio_series\n",
    "        if benchmark_price_series is not None and not benchmark_price_series.empty:\n",
    "            df_trace[f'Norm_Price_Benchmark_{benchmark_ticker}'] = benchmark_price_series\n",
    "        for col in df_trace.columns:\n",
    "            if 'Norm_Price' in col:\n",
    "                df_trace[col.replace('Norm_Price', 'Return')] = df_trace[col].pct_change()\n",
    "        debug_data['portfolio_trace'] = df_trace\n",
    "        # 'ranking_metrics' is not applicable in this mode\n",
    "        debug_data['ranking_metrics'] = pd.DataFrame() \n",
    "    # === END: MISSING CODE BLOCK ================================================\n",
    "\n",
    "    final_results = {\n",
    "        'tickers_to_display': valid_tickers_in_data,\n",
    "        'normalized_plot_data': normalized_plot_data,\n",
    "        'portfolio_series': portfolio_series,\n",
    "        'benchmark_price_series': benchmark_price_series,\n",
    "        'performance_data': perf_data,\n",
    "        'results_df': results_df,\n",
    "        'actual_calc_end_ts': actual_calc_end_ts,\n",
    "        'safe_start_date': safe_start_date,\n",
    "        'safe_viz_end_date': safe_viz_end_date,\n",
    "        'error': None\n",
    "    }\n",
    "    return (final_results, debug_data)\n",
    "\n",
    "\n",
    "# --- E. VERIFICATION TOOLS (User Requested) ---\n",
    "\n",
    "def verify_group_tickers_walk_forward_calculation(df_ohlcv, tickers_to_verify, benchmark_ticker,\n",
    "                                                  start_date, calc_period, fwd_period,\n",
    "                                                  master_calendar_ticker='VOO', export_csv=False):\n",
    "    \"\"\"Verifies portfolio and benchmark performance and optionally exports the data.\"\"\"\n",
    "    display(Markdown(f\"## Verification Report for Portfolio vs. Benchmark\"))\n",
    "    display(Markdown(f\"**Portfolio Tickers:** `{tickers_to_verify}`\\n**Benchmark Ticker:** `{benchmark_ticker}`\"))\n",
    "    \n",
    "    # 1. Setup trading day calendar and determine exact period dates\n",
    "    if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "        raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "    master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "\n",
    "    start_date_raw = pd.to_datetime(start_date)\n",
    "    start_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "    if start_idx >= len(master_trading_days):\n",
    "        print(f\"Error: Start date {start_date_raw.date()} is after the last available trading day.\"); return\n",
    "    actual_start_date = master_trading_days[start_idx]\n",
    "    \n",
    "    calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "    fwd_end_idx = min(calc_end_idx + fwd_period, len(master_trading_days) - 1)\n",
    "    \n",
    "    actual_calc_end_date = master_trading_days[calc_end_idx]\n",
    "    actual_fwd_end_date = master_trading_days[fwd_end_idx]\n",
    "    \n",
    "    display(Markdown(f\"**Analysis Start:** `{actual_start_date.date()}` (Selected: `{start_date_raw.date()}`)\\n\"\n",
    "                    f\"**Calc End:** `{actual_calc_end_date.date()}` ({calc_period} trading days)\\n\"\n",
    "                    f\"**Fwd End:** `{actual_fwd_end_date.date()}` ({fwd_period} trading days)\"))\n",
    "\n",
    "    # 2. Recreate the portfolio and benchmark series from scratch\n",
    "    df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "    portfolio_prices_raw_slice = df_close_full[tickers_to_verify].loc[actual_start_date:actual_fwd_end_date]\n",
    "    portfolio_value_series = portfolio_prices_raw_slice.div(portfolio_prices_raw_slice.bfill().iloc[0]).mean(axis=1)\n",
    "    benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "    \n",
    "    # 3. Optionally export the underlying daily data to a CSV for external checking\n",
    "    if export_csv:\n",
    "        export_df = pd.DataFrame({\n",
    "            'Portfolio_Normalized_Price': portfolio_value_series,\n",
    "            'Portfolio_Daily_Return': portfolio_value_series.pct_change()\n",
    "        })\n",
    "        if benchmark_price_series is not None:\n",
    "            norm_bm = benchmark_price_series.loc[actual_start_date:actual_fwd_end_date]\n",
    "            norm_bm = norm_bm / norm_bm.bfill().iloc[0]\n",
    "            export_df['Benchmark_Normalized_Price'] = norm_bm\n",
    "            export_df['Benchmark_Daily_Return'] = norm_bm.pct_change()\n",
    "\n",
    "        output_dir = 'export_csv'\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        tickers_str = '_'.join(tickers_to_verify)\n",
    "        filename = f\"verify_group_{actual_start_date.date()}_{tickers_str}.csv\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        export_df.to_csv(filepath)\n",
    "        print(f\"\\n✅ Data exported to: {filepath}\")\n",
    "\n",
    "    # 4. Define a helper to print detailed calculation steps\n",
    "    def print_verification_steps(title, price_series):\n",
    "        display(Markdown(f\"#### Verification for: `{title}`\"))\n",
    "        if price_series.dropna().shape[0] < 2: print(\"  - Not enough data points.\"); return {'gain': np.nan, 'sharpe': np.nan}\n",
    "        start_price, end_price = price_series.bfill().iloc[0], price_series.ffill().iloc[-1]\n",
    "        gain = (end_price / start_price) - 1\n",
    "        print(f\"Start Value ({price_series.first_valid_index().date()}): {start_price:,.4f}\\nEnd Value   ({price_series.last_valid_index().date()}): {end_price:,.4f}\\nGain = {gain:.2%}\")\n",
    "        returns = price_series.pct_change()\n",
    "        sharpe = calculate_sharpe(returns)\n",
    "        print(f\"Mean Daily Return: {returns.mean():.6f}\\nStd Dev: {returns.std():.6f}\\nSharpe = {sharpe:.2f}\")\n",
    "        return {'gain': gain, 'sharpe': sharpe}\n",
    "\n",
    "    # 5. Run verification for each period\n",
    "    display(Markdown(\"### A. Calculation Period\"))\n",
    "    perf_calc_p = print_verification_steps(\"Group Portfolio\", portfolio_value_series.loc[actual_start_date:actual_calc_end_date])\n",
    "    if benchmark_price_series is not None:\n",
    "        perf_calc_b = print_verification_steps(f\"Benchmark\", benchmark_price_series.loc[actual_start_date:actual_calc_end_date])\n",
    "    \n",
    "    display(Markdown(\"### B. Forward Period\"))\n",
    "    perf_fwd_p = print_verification_steps(\"Group Portfolio\", portfolio_value_series.loc[actual_calc_end_date:actual_fwd_end_date])\n",
    "    if benchmark_price_series is not None:\n",
    "        perf_fwd_b = print_verification_steps(f\"Benchmark\", benchmark_price_series.loc[actual_calc_end_date:actual_fwd_end_date])\n",
    "\n",
    "\n",
    "def verify_ticker_ranking_metrics(df_ohlcv, ticker, start_date, calc_period,\n",
    "                                  master_calendar_ticker='VOO', export_csv=False):\n",
    "    \"\"\"Verifies ranking metrics for a single ticker and optionally exports the data.\"\"\"\n",
    "    display(Markdown(f\"## Verification Report for Ticker Ranking: `{ticker}`\"))\n",
    "    \n",
    "    # 1. Setup trading day calendar and determine exact period dates\n",
    "    if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "        raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "    master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "\n",
    "    start_date_raw = pd.to_datetime(start_date)\n",
    "    start_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "    if start_idx >= len(master_trading_days):\n",
    "        print(f\"Error: Start date {start_date_raw.date()} is after the last available trading day.\"); return\n",
    "    actual_start_date = master_trading_days[start_idx]\n",
    "    \n",
    "    calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "    actual_calc_end_date = master_trading_days[calc_end_idx]\n",
    "\n",
    "    # 2. Extract and prepare the raw data for the specific ticker and period\n",
    "    df_ticker = df_ohlcv.loc[ticker].sort_index()\n",
    "    calc_df = df_ticker.loc[actual_start_date:actual_calc_end_date].copy()\n",
    "    if calc_df.empty or len(calc_df) < 2: \n",
    "        print(\"No data or not enough data in calc period.\"); return\n",
    "\n",
    "    display(Markdown(\"### A. Calculation Period (for Ranking Metrics)\"))\n",
    "    display(Markdown(f\"**Period Start:** `{actual_start_date.date()}`\\n\"\n",
    "                    f\"**Period End:** `{actual_calc_end_date.date()}`\\n\"\n",
    "                    f\"**Total Trading Days:** `{len(calc_df)}` (Requested: `{calc_period}`)\"))\n",
    "    \n",
    "    display(Markdown(\"#### Detailed Metric Calculation Data\"))\n",
    "    \n",
    "    # 3. Calculate all intermediate metrics as new columns for full transparency\n",
    "    vdf = calc_df[['Adj High', 'Adj Low', 'Adj Close']].copy()\n",
    "    vdf['Daily_Return'] = vdf['Adj Close'].pct_change()\n",
    "    \n",
    "    # Corrected True Range (TR) calculation for a single ticker (Series)\n",
    "    tr_df = pd.DataFrame({\n",
    "        'h_l': vdf['Adj High'] - vdf['Adj Low'],\n",
    "        'h_cp': abs(vdf['Adj High'] - vdf['Adj Close'].shift(1)),\n",
    "        'l_cp': abs(vdf['Adj Low'] - vdf['Adj Close'].shift(1))\n",
    "    })\n",
    "    vdf['TR'] = tr_df.max(axis=1)\n",
    "    \n",
    "    vdf['ATR_14'] = vdf['TR'].ewm(alpha=1/14, adjust=False).mean()\n",
    "    vdf['ATRP'] = vdf['ATR_14'] / vdf['Adj Close']\n",
    "    \n",
    "    print(\"--- Start of Calculation Period ---\")\n",
    "    display(vdf.head())\n",
    "    print(\"\\n--- End of Calculation Period ---\")\n",
    "    display(vdf.tail())\n",
    "\n",
    "    # 4. Optionally export this detailed breakdown to CSV\n",
    "    if export_csv:\n",
    "        output_dir = 'export_csv'\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        filename = f\"verify_ticker_{actual_start_date.date()}_{ticker}.csv\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        vdf.to_csv(filepath)\n",
    "        print(f\"\\n✅ Data exported to: {filepath}\")\n",
    "    \n",
    "    # 5. Print final metric calculations with formulas\n",
    "    display(Markdown(\"#### `MetricValue` Verification Summary:\"))\n",
    "    \n",
    "    calc_start_price = vdf['Adj Close'].bfill().iloc[0]\n",
    "    calc_end_price = vdf['Adj Close'].ffill().iloc[-1]\n",
    "    price_metric = (calc_end_price / calc_start_price)\n",
    "    print(f\"1. Price Metric: (Last Price / First Price) = ({calc_end_price:.2f} / {calc_start_price:.2f}) = {price_metric:.4f}\")\n",
    "    \n",
    "    daily_returns = vdf['Daily_Return'].dropna()\n",
    "    sharpe_ratio = calculate_sharpe(daily_returns)\n",
    "    print(f\"2. Sharpe Metric: (Mean Daily Return / Std Dev) * sqrt(252) = {sharpe_ratio:.4f}\")\n",
    "\n",
    "    atrp_mean = vdf['ATRP'].mean()\n",
    "    mean_daily_return = vdf['Daily_Return'].mean()\n",
    "    sharpe_atr = (mean_daily_return / atrp_mean) if atrp_mean > 0 else 0\n",
    "    print(f\"3. Sharpe (ATR) Metric: (Mean Daily Return / Mean ATRP) = ({mean_daily_return:.6f} / {atrp_mean:.6f}) = {sharpe_atr:.4f}\")\n",
    "\n",
    "\n",
    "def verify_sharpe_atr_calculation_checked(df_ohlcv, features_df, tickers_to_verify, benchmark_ticker,\n",
    "                                    start_date, calc_period, fwd_period,\n",
    "                                    master_calendar_ticker='VOO', debug=False):\n",
    "    \"\"\"\n",
    "    Verifies the Sharpe (ATR) calculations for a portfolio and benchmark.\n",
    "\n",
    "    [MODIFIED to use the centralized performance function and trace the new value-weighted ATRP logic]\n",
    "    \"\"\"\n",
    "    # Assuming display and Markdown are imported from IPython.display\n",
    "    from IPython.display import display, Markdown\n",
    "    \n",
    "    display(Markdown(f\"## Verification Report for Sharpe (ATR) Calculation\"))\n",
    "    display(Markdown(f\"**Portfolio Tickers:** `{tickers_to_verify}`\\n**Benchmark Ticker:** `{benchmark_ticker}`\"))\n",
    "\n",
    "    # --- 1. Determine Exact Period Dates (No changes) ---\n",
    "    master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "    start_date_raw = pd.to_datetime(start_date)\n",
    "    start_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "    actual_start_date = master_trading_days[start_idx]\n",
    "    calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "    fwd_end_idx = min(calc_end_idx + fwd_period, len(master_trading_days) - 1)\n",
    "    actual_calc_end_date = master_trading_days[calc_end_idx]\n",
    "    actual_fwd_end_date = master_trading_days[fwd_end_idx]\n",
    "    \n",
    "    display(Markdown(f\"**Full Period:** `{actual_start_date.date()}` to `{actual_fwd_end_date.date()}`\\n\"\n",
    "                    f\"**Calc End Date:** `{actual_calc_end_date.date()}`\"))\n",
    "\n",
    "    # --- 2. Recreate Portfolio & Benchmark Series using the Centralized Function ---\n",
    "    df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "\n",
    "    # Use the central function for both portfolio and benchmark\n",
    "    portfolio_value_series, portfolio_return_series, portfolio_atrp_series = \\\n",
    "        calculate_buy_and_hold_performance(df_close_full, features_df, tickers_to_verify,\n",
    "                                           actual_start_date, actual_fwd_end_date)\n",
    "    \n",
    "    _, benchmark_return_series, benchmark_atrp_series = \\\n",
    "        calculate_buy_and_hold_performance(df_close_full, features_df, [benchmark_ticker],\n",
    "                                           actual_start_date, actual_fwd_end_date)\n",
    "\n",
    "    # --- 3. DETAILED DEBUG TRACE ---\n",
    "    # We re-calculate intermediate steps here ONLY for the purpose of detailed printing.\n",
    "    # The final series used in the analysis below come from the trusted central function.\n",
    "    if debug:\n",
    "        display(Markdown(\"---\"))\n",
    "        # --- RETURN TRACE (largely unchanged) ---\n",
    "        display(Markdown(\"### 🐛 Detailed Portfolio Return Calculation Trace\"))\n",
    "        portfolio_prices_raw = df_close_full[tickers_to_verify].loc[actual_start_date:actual_fwd_end_date]\n",
    "        normalization_base = portfolio_prices_raw.bfill().iloc[0]\n",
    "        portfolio_prices_norm = portfolio_prices_raw.div(normalization_base)\n",
    "        \n",
    "        print(\"\\n[STEP 1] Raw Adjusted Close prices.\")\n",
    "        display(portfolio_prices_raw)\n",
    "        print(\"\\n[STEP 2] Normalization base (first valid row of prices).\")\n",
    "        display(pd.DataFrame(normalization_base).T)\n",
    "        print(\"\\n[STEP 2a] Normalized prices (each stock's value from an initial $1 investment).\")\n",
    "        display(portfolio_prices_norm)\n",
    "        print(\"\\n[STEP 3] Averaged normalized portfolio value series.\")\n",
    "        display(pd.DataFrame(portfolio_value_series, columns=['N_portf_value']))\n",
    "        print(\"\\n[STEP 4] Final portfolio daily return series (pct_change of Step 3).\")\n",
    "        display(pd.DataFrame(portfolio_return_series, columns=['N_portf_rtn']))\n",
    "        \n",
    "        # +++ NEW: DETAILED ATRP CALCULATION TRACE +++\n",
    "        display(Markdown(\"### 🐛 Detailed Portfolio ATRP Calculation Trace (Value-Weighted)\"))\n",
    "        p_idx = pd.MultiIndex.from_product([tickers_to_verify, portfolio_return_series.index])\n",
    "        p_atrp_df = features_df.loc[features_df.index.intersection(p_idx)]['ATRP'].unstack(level=0)\n",
    "        \n",
    "        daily_total_value = portfolio_prices_norm.sum(axis=1)\n",
    "        daily_weights = portfolio_prices_norm.div(daily_total_value, axis=0)\n",
    "\n",
    "        print(\"\\n[STEP 5] Individual component ATRP values for each stock.\")\n",
    "        print(\"This is the raw risk input for each component.\")\n",
    "        display(p_atrp_df)\n",
    "\n",
    "        print(\"\\n[STEP 6] Drifting daily portfolio weights (based on market value).\")\n",
    "        print(\"Note how weights start near equal and drift over time. This is the core of the buy-and-hold logic.\")\n",
    "        display(daily_weights)\n",
    "        \n",
    "        print(\"\\n[STEP 7] Final value-weighted portfolio ATRP series.\")\n",
    "        print(\"Result of (Weights * Component_ATRPs) summed each day.\")\n",
    "        display(pd.DataFrame(portfolio_atrp_series, columns=['value_weighted_atrp']))\n",
    "        display(Markdown(\"---\"))\n",
    "    # +++ END OF DEBUG BLOCK +++\n",
    "\n",
    "    # --- 4. Define a Helper to Print Detailed Calculation Steps (Unchanged) ---\n",
    "    def _calculate_and_print_metrics(period_name, returns, atrps):\n",
    "        display(Markdown(f\"#### {period_name}\"))\n",
    "        if returns.dropna().empty or atrps.dropna().empty:\n",
    "            print(\"  - Not enough data to calculate.\")\n",
    "            return np.nan\n",
    "        mean_return = returns.mean()\n",
    "        mean_atrp = atrps.mean()\n",
    "        sharpe_atr = mean_return / mean_atrp if mean_atrp > 0 else np.nan\n",
    "        if debug:\n",
    "            # ... (debug printouts for mean calculation) ...\n",
    "            pass\n",
    "        print(f\"  - Mean Daily Return: {mean_return:,.6f}\")\n",
    "        print(f\"  - Mean Daily ATRP:  {mean_atrp:,.6f}\")\n",
    "        print(f\"  - Sharpe (ATR) = (Mean Return / Mean ATRP) = {sharpe_atr:,.4f}\")\n",
    "        return sharpe_atr\n",
    "\n",
    "    # --- 5. Run Verification for Portfolio (Unchanged) ---\n",
    "    display(Markdown(\"### A. Group Portfolio Verification\"))\n",
    "    _calculate_and_print_metrics(\"Full Period\", portfolio_return_series, portfolio_atrp_series)\n",
    "    _calculate_and_print_metrics(\"Calculation Period\", portfolio_return_series.loc[:actual_calc_end_date], portfolio_atrp_series.loc[:actual_calc_end_date])\n",
    "    _calculate_and_print_metrics(\"Forward Period\", portfolio_return_series.loc[actual_calc_end_date:].iloc[1:], portfolio_atrp_series.loc[actual_calc_end_date:].iloc[1:])\n",
    "\n",
    "    # --- 6. Run Verification for Benchmark (Unchanged) ---\n",
    "    display(Markdown(f\"### B. Benchmark ({benchmark_ticker}) Verification\"))\n",
    "    _calculate_and_print_metrics(\"Full Period\", benchmark_return_series, benchmark_atrp_series)\n",
    "    _calculate_and_print_metrics(\"Calculation Period\", benchmark_return_series.loc[:actual_calc_end_date], benchmark_atrp_series.loc[:actual_calc_end_date])\n",
    "    _calculate_and_print_metrics(\"Forward Period\", benchmark_return_series.loc[actual_calc_end_date:].iloc[1:], benchmark_atrp_series.loc[actual_calc_end_date:].iloc[1:])\n",
    "\n",
    "\n",
    "# --- F. AUTOMATION SCRIPT - STRATEGY SEARCH ---\n",
    "\n",
    "def run_strategy_search(df_ohlcv, config):\n",
    "    \"\"\"\n",
    "    Runs the main backtesting loop with checkpointing to be resumable.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # --- 1. SETUP & LOAD PROGRESS ---\n",
    "    print(\"--- Phase 1: Pre-processing and Loading Progress ---\")\n",
    "\n",
    "    # +++ ADD THIS BLOCK +++\n",
    "    # Pre-calculate all features for the entire dataset ONCE.\n",
    "    print(\"--- Generating all features upfront... ---\")\n",
    "    features_df = generate_features(df_ohlcv)\n",
    "\n",
    "    # --- DELETE THIS LINE ---\n",
    "    # quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "    \n",
    "    print(\"Unstacking data for performance...\")\n",
    "    df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "    df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "    df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    \n",
    "    master_calendar_ticker = config['master_calendar_ticker']\n",
    "    master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "    print(f\"Master trading day calendar created from '{master_calendar_ticker}' ({len(master_trading_days)} days).\")\n",
    "\n",
    "    results_path = config['results_output_path']\n",
    "    completed_params = set()\n",
    "    \n",
    "    if os.path.exists(results_path):\n",
    "        print(f\"Found existing results file. Loading progress from: {results_path}\")\n",
    "        df_progress = pd.read_csv(results_path)\n",
    "        for _, row in df_progress.iterrows():\n",
    "            param_key = (\n",
    "                row['calc_period'], row['fwd_period'], row['metric'],\n",
    "                (row['rank_start'], row['rank_end'])\n",
    "            )\n",
    "            completed_params.add(param_key)\n",
    "        print(f\"Found {len(completed_params)} completed parameter sets to skip.\")\n",
    "    else:\n",
    "        print(\"No existing results file found. Starting a new run.\")\n",
    "\n",
    "    print(\"✅ Pre-processing complete.\\n\")\n",
    "\n",
    "    # --- 2. SETUP THE MAIN LOOP (No changes here) ---\n",
    "    print(\"--- Phase 2: Setting up Simulation Loops ---\")\n",
    "    param_combinations = list(product(\n",
    "        config['calc_periods'], config['fwd_periods'],\n",
    "        config['metrics'], config['rank_slices']\n",
    "    ))\n",
    "    search_start_date = pd.to_datetime(config['search_start_date'])\n",
    "    search_end_date = pd.to_datetime(config['search_end_date'])\n",
    "    start_idx = master_trading_days.searchsorted(search_start_date, side='left')\n",
    "    end_idx = master_trading_days.searchsorted(search_end_date, side='right')\n",
    "    step_dates_map = {}\n",
    "    print(\"Pre-calculating rebalancing schedules for each holding period...\")\n",
    "    for fwd_period in sorted(config['fwd_periods']):\n",
    "        step_indices = range(start_idx, end_idx, fwd_period)\n",
    "        step_dates_map[fwd_period] = master_trading_days[step_indices]\n",
    "        print(f\"  - Holding Period {fwd_period} days: {len(step_dates_map[fwd_period])} rebalances\")\n",
    "    print(f\"Found {len(param_combinations)} total parameter sets to simulate.\")\n",
    "    print(\"✅ Setup complete. Starting main loop...\\n\")\n",
    "\n",
    "    # --- 3. RUN THE MAIN LOOP ---\n",
    "    print(\"--- Phase 3: Running Simulations ---\")\n",
    "    pbar = tqdm(param_combinations, desc=\"Parameter Sets\")\n",
    "    \n",
    "    for params in pbar:\n",
    "        calc_period, fwd_period, metric, rank_slice = params\n",
    "        rank_start, rank_end = rank_slice\n",
    "        \n",
    "        param_key = (calc_period, fwd_period, metric, rank_slice)\n",
    "        if param_key in completed_params:\n",
    "            pbar.set_description(f\"Skipping {param_key}\")\n",
    "            continue\n",
    "\n",
    "        pbar.set_description(f\"Running {param_key}\")\n",
    "        \n",
    "        current_params_results = []\n",
    "        \n",
    "        current_step_dates = step_dates_map[fwd_period]\n",
    "        for step_date in current_step_dates:\n",
    "            # +++ UPDATE THIS CALL +++\n",
    "            eligible_tickers = get_eligible_universe(\n",
    "                features_df, filter_date=step_date, thresholds=config['quality_thresholds']\n",
    "            )\n",
    "            if not eligible_tickers: continue\n",
    "            \n",
    "            df_close_step = df_close_full[eligible_tickers]\n",
    "            df_high_step = df_high_full[eligible_tickers]\n",
    "            df_low_step = df_low_full[eligible_tickers]\n",
    "\n",
    "            # +++ UPDATE THIS CALL +++\n",
    "            step_result, _ = run_walk_forward_step(\n",
    "                df_close_full=df_close_step, df_high_full=df_high_step, df_low_full=df_low_step,\n",
    "                master_trading_days=master_trading_days, start_date=step_date,\n",
    "                calc_period=calc_period, fwd_period=fwd_period,\n",
    "                metric=metric, rank_start=rank_start, rank_end=rank_end,\n",
    "                benchmark_ticker=config['benchmark_ticker'],\n",
    "                features_df=features_df, # Pass the features_df\n",
    "                debug=False\n",
    "            )\n",
    "            \n",
    "            if step_result['error'] is None:\n",
    "                p = step_result['performance_data']\n",
    "                log_entry = {\n",
    "                    'step_date': step_date.date(), 'calc_period': calc_period,\n",
    "                    'fwd_period': fwd_period, 'metric': metric,\n",
    "                    'rank_start': rank_start, 'rank_end': rank_end,\n",
    "                    'num_universe': len(eligible_tickers),\n",
    "                    'num_portfolio': len(step_result['tickers_to_display']),\n",
    "                    'fwd_p_gain': p['fwd_p_gain'], 'fwd_b_gain': p['fwd_b_gain'],\n",
    "                    'fwd_gain_delta': p['fwd_p_gain'] - p['fwd_b_gain'] if not np.isnan(p['fwd_b_gain']) else np.nan,\n",
    "                    'fwd_p_sharpe': p['fwd_p_sharpe'],\n",
    "                }\n",
    "                current_params_results.append(log_entry)\n",
    "        \n",
    "        # --- CHECKPOINTING (No changes here) ---\n",
    "        if current_params_results:\n",
    "            df_to_append = pd.DataFrame(current_params_results)\n",
    "            df_to_append.to_csv(\n",
    "                results_path,\n",
    "                mode='a',\n",
    "                header=not os.path.exists(results_path),\n",
    "                index=False\n",
    "            )\n",
    "            completed_params.add(param_key)\n",
    "\n",
    "    print(\"✅ Main loop finished.\\n\")\n",
    "    \n",
    "    # --- 4. RETURN FINAL DATAFRAME (No changes here) ---\n",
    "    print(\"--- Phase 4: Loading Final Results ---\")\n",
    "    if os.path.exists(results_path):\n",
    "        final_df = pd.read_csv(results_path)\n",
    "        end_time = time.time()\n",
    "        print(f\"✅ Process complete. Total execution time: {time.time() - start_time:.2f} seconds.\")\n",
    "        return final_df\n",
    "    else:\n",
    "        print(\"Warning: No results were generated.\")\n",
    "        return None    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73c4b65",
   "metadata": {},
   "source": [
    "### CALCULATION VERIFIED \"Group Portfolio Sharpe (ATR) calculation for RCL, RCL, STIP\"\n",
    "### TODO: run_manual_portfolio_step  \n",
    "- debug is not returning data\n",
    "- merge with older version to get back comments\n",
    "- move ticker textbox input to the right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0151d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_container, debug_container = plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    default_start_date='2025-08-13',\n",
    "    default_calc_period=10,\n",
    "    default_fwd_period=5,\n",
    "    default_metric='Sharpe (ATR)',\n",
    "    default_rank_start=15,\n",
    "    default_rank_end=16,\n",
    "    default_benchmark_ticker='VOO', \n",
    "    master_calendar_ticker='VOO',\n",
    "    quality_thresholds={ 'min_median_dollar_volume': 10_000_000, \n",
    "                         'max_stale_pct': 0.05, \n",
    "                         'max_same_vol_count': 1 },\n",
    "    debug=True  # <-- Activate the new mode!\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676bca01",
   "metadata": {},
   "source": [
    "#####################################################    \n",
    "#####################################################    \n",
    "#####################################################    \n",
    "#####################################################    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf4c6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3320468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_nested(results_container)\n",
    "print(f'\\n{\"=\" * 20}\\n')\n",
    "print_nested(debug_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f365ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_group_tickers_walk_forward_calculation(df_ohlcv=df_ohlcv,\n",
    "                                              tickers_to_verify=['B', 'NVDA', 'B'],\n",
    "                                              benchmark_ticker='VOO',\n",
    "                                              start_date='2025-11-05',\n",
    "                                              calc_period=10,\n",
    "                                              fwd_period=5,\n",
    "                                              master_calendar_ticker='VOO',\n",
    "                                              export_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2ea73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_ticker_ranking_metrics(df_ohlcv, \n",
    "                              ticker='B',\n",
    "                              start_date='2025-11-05',\n",
    "                              calc_period=10,\n",
    "                              master_calendar_ticker='VOO', \n",
    "                              export_csv=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62b8048",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.loc['NVDA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836c2b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = generate_features(df_ohlcv=df_ohlcv, \n",
    "                                atr_period=14, \n",
    "                                quality_window=252, \n",
    "                                quality_min_periods=126)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cc9b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.loc['B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b1c05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_sharpe_atr_calculation_checked(df_ohlcv=df_ohlcv, \n",
    "                                      features_df=features_df, \n",
    "                                      tickers_to_verify=['B', 'NVDA', 'B'],\n",
    "                                      benchmark_ticker='VOO',\n",
    "                                      start_date='2025-11-05',\n",
    "                                      calc_period=10,\n",
    "                                      fwd_period=5,\n",
    "                                      master_calendar_ticker='VOO', \n",
    "                                      debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c5f2f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93b73a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f0327f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce80892c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421e1a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_manual_portfolio_step(df_close_full, features_df,\n",
    "                              manual_tickers,\n",
    "                              master_trading_days,\n",
    "                              start_date, calc_period, fwd_period,\n",
    "                              benchmark_ticker,\n",
    "                              debug=False):\n",
    "    \"\"\"\n",
    "    Runs a performance analysis for a manually specified portfolio of tickers.\n",
    "\n",
    "    Bypasses all ranking and filtering logic, directly calculating performance\n",
    "    for the provided list. The output format is identical to run_walk_forward_step\n",
    "    for seamless UI integration.\n",
    "\n",
    "    Args:\n",
    "        df_close_full (pd.DataFrame): DataFrame of all close prices.\n",
    "        features_df (pd.DataFrame): DataFrame with all features (for ATRP).\n",
    "        manual_tickers (list): The user-provided list of tickers, duplicates allowed.\n",
    "        master_trading_days (pd.DatetimeIndex): The calendar of trading days.\n",
    "        start_date (pd.Timestamp): The desired start date for the analysis.\n",
    "        calc_period (int): The number of days in the calculation period.\n",
    "        fwd_period (int): The number of days in the forward-test period.\n",
    "        benchmark_ticker (str): The ticker symbol for the benchmark.\n",
    "        debug (bool): Flag to generate detailed debug data.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (results_dict, debug_dict) in the same format as run_walk_forward_step.\n",
    "    \"\"\"\n",
    "    debug_data = {} if debug else None\n",
    "\n",
    "    # 1. Determine exact date ranges (identical logic to run_walk_forward_step)\n",
    "    try:\n",
    "        start_idx = master_trading_days.get_loc(start_date)\n",
    "    except KeyError:\n",
    "        return ({'error': f\"Start date {start_date.date()} is not a valid trading day.\"}, None)\n",
    "\n",
    "    desired_viz_end_idx = start_idx + calc_period + fwd_period\n",
    "    if desired_viz_end_idx >= len(master_trading_days):\n",
    "        return ({'error': \"Not enough data for the full requested period.\"}, None)\n",
    "\n",
    "    calc_end_idx = start_idx + calc_period\n",
    "    viz_end_idx = calc_end_idx + fwd_period\n",
    "    safe_start_date = master_trading_days[start_idx]\n",
    "    safe_calc_end_date = master_trading_days[calc_end_idx]\n",
    "    safe_viz_end_date = master_trading_days[viz_end_idx]\n",
    "\n",
    "    # 2. Validate and process the manual ticker list\n",
    "    if not manual_tickers:\n",
    "        return ({'error': \"The manual ticker list cannot be empty.\"}, None)\n",
    "        \n",
    "    unique_tickers_in_list = sorted(list(set(manual_tickers)))\n",
    "    valid_tickers_in_data = [t for t in unique_tickers_in_list if t in df_close_full.columns]\n",
    "    \n",
    "    if not valid_tickers_in_data:\n",
    "        return ({'error': \"None of the provided tickers were found in the dataset.\"}, None)\n",
    "\n",
    "    # Filter the manual list to only include tickers that exist in our data\n",
    "    tickers_to_display = [t for t in manual_tickers if t in valid_tickers_in_data]\n",
    "\n",
    "    # 3. Calculate Portfolio & Benchmark Performance using the central function\n",
    "    portfolio_series, portfolio_return_series, portfolio_atrp_series = \\\n",
    "        calculate_buy_and_hold_performance(df_close_full, features_df, tickers_to_display,\n",
    "                                           safe_start_date, safe_viz_end_date)\n",
    "\n",
    "    if benchmark_ticker and benchmark_ticker in df_close_full.columns:\n",
    "        benchmark_price_series, benchmark_return_series, benchmark_atrp_series = \\\n",
    "            calculate_buy_and_hold_performance(df_close_full, features_df, [benchmark_ticker],\n",
    "                                               safe_start_date, safe_viz_end_date)\n",
    "    else:\n",
    "        benchmark_price_series, benchmark_return_series, benchmark_atrp_series = (pd.Series(dtype='float64'),)*3\n",
    "\n",
    "    # 4. Split series into calc and fwd periods\n",
    "    actual_calc_end_ts = safe_calc_end_date\n",
    "    # This block is identical to the one in run_walk_forward_step\n",
    "    calc_portfolio_returns = portfolio_return_series.loc[:actual_calc_end_ts]\n",
    "    fwd_portfolio_returns = portfolio_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "    calc_portfolio_atrp = portfolio_atrp_series.loc[:actual_calc_end_ts]\n",
    "    fwd_portfolio_atrp = portfolio_atrp_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "    # ... and so on for benchmark series\n",
    "    if not benchmark_return_series.empty:\n",
    "        calc_benchmark_returns = benchmark_return_series.loc[:actual_calc_end_ts]\n",
    "        fwd_benchmark_returns = benchmark_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "        calc_benchmark_atrp = benchmark_atrp_series.loc[:actual_calc_end_ts]\n",
    "        fwd_benchmark_atrp = benchmark_atrp_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "    else:\n",
    "        calc_benchmark_returns, fwd_benchmark_returns = pd.Series(dtype='float64'), pd.Series(dtype='float64')\n",
    "        calc_benchmark_atrp, fwd_benchmark_atrp = pd.Series(dtype='float64'), pd.Series(dtype='float64')\n",
    "\n",
    "    # 5. Calculate final performance metrics\n",
    "    perf_data = {}\n",
    "    # This block is also identical\n",
    "    perf_data['calc_p_gain'] = calculate_gain(portfolio_series.loc[:actual_calc_end_ts])\n",
    "    perf_data['fwd_p_gain'] = calculate_gain(portfolio_series.loc[actual_calc_end_ts:])\n",
    "    perf_data['full_p_gain'] = calculate_gain(portfolio_series)\n",
    "    # ... (all other perf_data calculations for portfolio and benchmark) ...\n",
    "    perf_data['full_p_sharpe_atr'] = calculate_sharpe_atr(portfolio_return_series, portfolio_atrp_series)\n",
    "    perf_data['full_b_sharpe_atr'] = calculate_sharpe_atr(benchmark_return_series, benchmark_atrp_series)\n",
    "    \n",
    "    # 6. Prepare `results_df` (simplified for manual mode)\n",
    "    from collections import Counter\n",
    "    ticker_counts = Counter(tickers_to_display)\n",
    "    total_parts = len(tickers_to_display)\n",
    "    \n",
    "    # Calculate individual forward gains for the results table\n",
    "    start_prices = df_close_full.loc[actual_calc_end_ts, valid_tickers_in_data]\n",
    "    end_prices = df_close_full.loc[safe_viz_end_date, valid_tickers_in_data]\n",
    "    fwd_gains = (end_prices / start_prices) - 1\n",
    "\n",
    "    results_data = []\n",
    "    for ticker in valid_tickers_in_data:\n",
    "        results_data.append({\n",
    "            'InitialWeight': ticker_counts[ticker] / total_parts,\n",
    "            'FwdGain': fwd_gains.get(ticker, np.nan)\n",
    "        })\n",
    "    results_df = pd.DataFrame(results_data, index=pd.Index(valid_tickers_in_data, name='Ticker'))\n",
    "    \n",
    "    # 7. Prepare other outputs for consistency\n",
    "    normalized_plot_data = df_close_full[valid_tickers_in_data].loc[safe_start_date:safe_viz_end_date]\n",
    "    normalized_plot_data = normalized_plot_data.div(normalized_plot_data.bfill().iloc[0])\n",
    "\n",
    "    if debug:\n",
    "        # Create the portfolio trace for debugging, similar to the original function\n",
    "        df_trace = normalized_plot_data.copy()\n",
    "        df_trace.columns = [f'Norm_Price_{c}' for c in df_trace.columns]\n",
    "        df_trace['Norm_Price_Portfolio'] = portfolio_series\n",
    "        if benchmark_price_series is not None and not benchmark_price_series.empty:\n",
    "            df_trace[f'Norm_Price_Benchmark_{benchmark_ticker}'] = benchmark_price_series\n",
    "        for col in df_trace.columns:\n",
    "            if 'Norm_Price' in col:\n",
    "                df_trace[col.replace('Norm_Price', 'Return')] = df_trace[col].pct_change()\n",
    "        debug_data['portfolio_trace'] = df_trace\n",
    "        # 'ranking_metrics' is not applicable in this mode\n",
    "        debug_data['ranking_metrics'] = pd.DataFrame() \n",
    "\n",
    "    # 8. Assemble the final results dictionary\n",
    "    final_results = {\n",
    "        'tickers_to_display': valid_tickers_in_data, # Use unique tickers for plotting\n",
    "        'normalized_plot_data': normalized_plot_data,\n",
    "        'portfolio_series': portfolio_series,\n",
    "        'benchmark_price_series': benchmark_price_series,\n",
    "        'performance_data': perf_data,\n",
    "        'results_df': results_df,\n",
    "        'actual_calc_end_ts': actual_calc_end_ts,\n",
    "        'safe_start_date': safe_start_date,\n",
    "        'safe_viz_end_date': safe_viz_end_date,\n",
    "        'error': None\n",
    "    }\n",
    "    return (final_results, debug_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3caacef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. GENERATE SYNTHETIC TEST DATA ---\n",
    "print(\"Generating synthetic test data...\")\n",
    "# Master calendar: ~2 years of daily data\n",
    "master_trading_days = pd.to_datetime(pd.date_range(start='2022-01-01', end='2023-12-31', freq='D'))\n",
    "num_days = len(master_trading_days)\n",
    "tickers_to_generate = ['AAPL', 'MSFT', 'GOOG', 'NVDA', 'VOO']\n",
    "\n",
    "# Generate predictable price series\n",
    "np.random.seed(42)\n",
    "close_data = {\n",
    "    'AAPL': 150 + np.linspace(0, 50, num_days) + np.random.randn(num_days) * 2, # Steady winner\n",
    "    'MSFT': 300 + np.linspace(0, 70, num_days) + np.random.randn(num_days) * 4, # Volatile winner\n",
    "    'GOOG': 140 - np.linspace(0, 40, num_days) + np.random.randn(num_days) * 3, # Loser\n",
    "    'NVDA': 200 + np.linspace(0, 300, num_days) + np.random.randn(num_days) * 8, # Big winner\n",
    "    'VOO':  400 + np.linspace(0, 50, num_days) + np.random.randn(num_days) * 1.5 # Benchmark\n",
    "}\n",
    "df_close_full = pd.DataFrame(close_data, index=master_trading_days).round(2)\n",
    "\n",
    "# Generate simple, constant ATRP features\n",
    "feature_list = []\n",
    "atrp_map = {'AAPL': 0.015, 'MSFT': 0.02, 'GOOG': 0.018, 'NVDA': 0.03, 'VOO': 0.01}\n",
    "for ticker in tickers_to_generate:\n",
    "    ticker_features = pd.DataFrame({\n",
    "        'Date': master_trading_days,\n",
    "        'Ticker': ticker,\n",
    "        'ATRP': atrp_map[ticker]\n",
    "    })\n",
    "    feature_list.append(ticker_features)\n",
    "features_df = pd.concat(feature_list).set_index(['Ticker', 'Date'])\n",
    "print(\"Test data generation complete.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c20e29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. EXECUTE THE TEST ---\n",
    "display(Markdown(\"### Testing `run_manual_portfolio_step`\"))\n",
    "\n",
    "# Define a manual portfolio. Note the duplicates and the invalid ticker.\n",
    "manual_list = ['NVDA', 'NVDA', 'AAPL', 'GOOG', 'FAKE_TICKER']\n",
    "start_date_str = '2022-05-01'\n",
    "\n",
    "print(f\"Manual Ticker List: {manual_list}\")\n",
    "print(f\"Start Date: {start_date_str}, Calc Period: 126 days, Fwd Period: 63 days\")\n",
    "\n",
    "results, debug_info = run_manual_portfolio_step(\n",
    "    df_close_full=df_close_full,\n",
    "    features_df=features_df,\n",
    "    manual_tickers=manual_list,\n",
    "    master_trading_days=master_trading_days,\n",
    "    start_date=pd.to_datetime(start_date_str),\n",
    "    calc_period=126,\n",
    "    fwd_period=63,\n",
    "    benchmark_ticker='VOO',\n",
    "    debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53bcad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. VERIFY AND DISPLAY RESULTS ---\n",
    "if results.get('error'):\n",
    "    print(f\"\\nERROR: {results['error']}\")\n",
    "else:\n",
    "    display(Markdown(\"---\"))\n",
    "    display(Markdown(\"#### Output Verification\"))\n",
    "    print(\"Function executed successfully. Verifying output structure...\")\n",
    "    print(f\"Result Keys: {list(results.keys())}\")\n",
    "    \n",
    "    display(Markdown(\"#### Results DataFrame (`results_df`)\"))\n",
    "    print(\"This table shows the initial weights and forward gain for each valid ticker.\")\n",
    "    display(results['results_df'].style.format({'InitialWeight': '{:.2%}', 'FwdGain': '{:+.2%}'}))\n",
    "\n",
    "    display(Markdown(\"#### Performance Data (`performance_data`)\"))\n",
    "    display(pd.DataFrame.from_dict(results['performance_data'], orient='index', columns=['Value']))\n",
    "    \n",
    "    display(Markdown(\"#### Portfolio Series (first 5 rows)\"))\n",
    "    display(results['portfolio_series'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa034d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.to_csv('./export_csv/features_df.csv')\n",
    "df_close_full.to_csv('./export_csv/df_close_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d92b18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', 300):\n",
    "    print_nested(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea35196",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', 300):\n",
    "    print_nested(debug_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac24e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f7f2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_close_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17abc969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have df_close_full, features_df, master_trading_days loaded\n",
    "# and the necessary helper functions defined.\n",
    "\n",
    "manual_list = ['AAPL', 'AAPL', 'MSFT', 'GOOG', 'INVALID_TICKER']\n",
    "results, debug_info = run_manual_portfolio_step(\n",
    "    df_close_full=df_close_full,\n",
    "    features_df=features_df,\n",
    "    manual_tickers=manual_list,\n",
    "    master_trading_days=master_trading_days,\n",
    "    start_date=pd.to_datetime('2022-01-01'),\n",
    "    calc_period=252,\n",
    "    fwd_period=63,\n",
    "    benchmark_ticker='VOO',\n",
    "    debug=True\n",
    ")\n",
    "\n",
    "# Check the output structure\n",
    "print(results.keys())\n",
    "display(results['results_df'])\n",
    "display(results['performance_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a665263",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a682e1fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899b9cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdaa9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_suite():\n",
    "    \"\"\"\n",
    "    Creates sample data and tests the calculate_buy_and_hold_performance function.\n",
    "    \"\"\"\n",
    "    # 1. --- Create Sample Data ---\n",
    "    dates = pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04'])\n",
    "    \n",
    "    # MSFT doubles in price, GOOG goes up 50%\n",
    "    close_data = {\n",
    "        'MSFT': [100.0, 120.0, 160.0, 200.0],\n",
    "        'GOOG': [200.0, 220.0, 260.0, 300.0]\n",
    "    }\n",
    "    df_close = pd.DataFrame(close_data, index=dates)\n",
    "\n",
    "    # Simple, constant ATRP values for predictability\n",
    "    features_data = {\n",
    "        'Date':     list(dates) * 2,\n",
    "        'Ticker':   ['MSFT'] * 4 + ['GOOG'] * 4,\n",
    "        'ATRP':     [0.01] * 4   + [0.02] * 4,\n",
    "    }\n",
    "    features_df = pd.DataFrame(features_data).set_index(['Ticker', 'Date'])\n",
    "\n",
    "    start_date = dates[0]\n",
    "    end_date = dates[-1]\n",
    "\n",
    "    print(\"--- Test Setup ---\")\n",
    "    print(\"Close Prices:\")\n",
    "    display(df_close)\n",
    "    print(\"\\nFeature ATRP:\")\n",
    "    display(features_df)\n",
    "    print(\"-\" * 20)\n",
    "\n",
    "    # 2. --- Test Case 1: Equal Weights (should behave like the old function) ---\n",
    "    print(\"\\n--- Test Case 1: Equal Weights ['MSFT', 'GOOG'] ---\")\n",
    "    tickers_equal = ['MSFT', 'GOOG']\n",
    "    \n",
    "    val_eq, ret_eq, atrp_eq = calculate_buy_and_hold_performance(\n",
    "        df_close, features_df, tickers_equal, start_date, end_date\n",
    "    )\n",
    "    \n",
    "    print(\"\\nCalculated Portfolio Value Series:\")\n",
    "    display(pd.DataFrame(val_eq, columns=['Value']))\n",
    "    \n",
    "    # Manual verification:\n",
    "    # Day 1: (120/100)*0.5 + (220/200)*0.5 = 1.2*0.5 + 1.1*0.5 = 0.6 + 0.55 = 1.15\n",
    "    # Day 3: (200/100)*0.5 + (300/200)*0.5 = 2.0*0.5 + 1.5*0.5 = 1.0 + 0.75 = 1.75\n",
    "    # The code should match this.\n",
    "    \n",
    "    print(\"\\nCalculated Portfolio ATRP Series:\")\n",
    "    display(pd.DataFrame(atrp_eq, columns=['ATRP']))\n",
    "    # On day 1, MSFT value is 0.6, GOOG is 0.55. Total is 1.15.\n",
    "    # MSFT weight = 0.6/1.15 = 0.5217. GOOG weight = 0.55/1.15 = 0.4783\n",
    "    # ATRP = 0.5217*0.01 + 0.4783*0.02 = 0.005217 + 0.009566 = 0.014783\n",
    "    \n",
    "    # 3. --- Test Case 2: Unequal Weights (verifies the new logic) ---\n",
    "    print(\"\\n--- Test Case 2: Unequal Weights ['MSFT', 'MSFT', 'MSFT', 'GOOG'] ---\")\n",
    "    print(\"Initial Weights: 75% MSFT, 25% GOOG\")\n",
    "    tickers_unequal = ['MSFT', 'MSFT', 'MSFT', 'GOOG']\n",
    "    \n",
    "    val_uneq, ret_uneq, atrp_uneq = calculate_buy_and_hold_performance(\n",
    "        df_close, features_df, tickers_unequal, start_date, end_date\n",
    "    )\n",
    "    \n",
    "    print(\"\\nCalculated Portfolio Value Series:\")\n",
    "    display(pd.DataFrame(val_uneq, columns=['Value']))\n",
    "\n",
    "    # Manual verification:\n",
    "    # Day 1: (120/100)*0.75 + (220/200)*0.25 = 1.2*0.75 + 1.1*0.25 = 0.9 + 0.275 = 1.175\n",
    "    # Day 3: (200/100)*0.75 + (300/200)*0.25 = 2.0*0.75 + 1.5*0.25 = 1.5 + 0.375 = 1.875\n",
    "    # The code should match this.\n",
    "    \n",
    "    print(\"\\nCalculated Portfolio ATRP Series:\")\n",
    "    display(pd.DataFrame(atrp_uneq, columns=['ATRP']))\n",
    "    # On day 1, MSFT value is 0.9, GOOG is 0.275. Total is 1.175.\n",
    "    # MSFT weight = 0.9/1.175 = 0.766. GOOG weight = 0.275/1.175 = 0.234\n",
    "    # ATRP = 0.766*0.01 + 0.234*0.02 = 0.00766 + 0.00468 = 0.01234\n",
    "\n",
    "    print(\"\\nCalculated Portfolio Return Series:\")\n",
    "    display(pd.DataFrame(ret_uneq, columns=['Return']))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6e9814",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test_suite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcf37d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415fecc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df530ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bef440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82af6d28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c1701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_container, debug_container = plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    default_start_date='2018-10-03',\n",
    "    default_calc_period=252,\n",
    "    default_fwd_period=63,\n",
    "    default_metric='Sharpe (ATR)',\n",
    "    default_rank_start=1,\n",
    "    default_rank_end=5,\n",
    "    default_benchmark_ticker='VOO',\n",
    "    quality_thresholds={ 'min_median_dollar_volume': 10_000_000, \n",
    "                         'max_stale_pct': 0.05, \n",
    "                         'max_same_vol_count': 1 },\n",
    "    debug=True  # <-- Activate the new mode!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fea8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume 'df_ohlcv' is your loaded dataset\n",
    "# You might need to regenerate features_df if it's not in your notebook's memory\n",
    "print(\"--- Regenerating features for verification ---\")\n",
    "features_df = generate_features(df_ohlcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca56efc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_to_verify = ['STIP', 'RCL']\n",
    "start_date = '2025-08-13'\n",
    "end_date = '2025-09-04'\n",
    "benchmark_ticker = 'VOO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2046ea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now call the verification function with the exact parameters from the UI\n",
    "verify_sharpe_atr_calculation_checked(\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    features_df=features_df,\n",
    "    tickers_to_verify=tickers_to_verify, # <-- From the UI output\n",
    "    benchmark_ticker=benchmark_ticker,\n",
    "    start_date=start_date,\n",
    "    calc_period=10,\n",
    "    fwd_period=5,\n",
    "    debug=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89540b88",
   "metadata": {},
   "source": [
    "##########################################   \n",
    "##########################################   \n",
    "##########################################   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108a523c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13650d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cf510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ==============================================================================\n",
    "# # GOLDEN COPY - COMPLETE PROJECT CODE (All Fixes Included)\n",
    "# # Version: Verified Portfolio and Benchmark Sharpe (ATR)  \n",
    "# # Date: 2025-10-15\n",
    "# # ==============================================================================\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import plotly.graph_objects as go\n",
    "# import ipywidgets as widgets\n",
    "# import time\n",
    "# import pprint\n",
    "# import os # Make sure os is imported for the export function later\n",
    "# import re\n",
    "\n",
    "# from datetime import datetime, date\n",
    "# from IPython.display import display, Markdown\n",
    "# from tqdm.auto import tqdm\n",
    "# from pathlib import Path\n",
    "# from itertools import product\n",
    "\n",
    "\n",
    "# pd.set_option('display.max_rows', 30)\n",
    "# pd.set_option('display.max_columns', 50)\n",
    "# pd.set_option('display.width', 3000)\n",
    "\n",
    "\n",
    "# # --- REFACTORING PHASE 1 CODE: Feature Generation Engine ---\n",
    "\n",
    "# def generate_features(df_ohlcv: pd.DataFrame, \n",
    "#                       atr_period: int = 14, \n",
    "#                       quality_window: int = 252, \n",
    "#                       quality_min_periods: int = 126) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Generates a comprehensive DataFrame of derived features from raw OHLCV data.\n",
    "\n",
    "#     This function performs all heavy, window-based calculations upfront to be used\n",
    "#     by downstream analysis functions. It calculates:\n",
    "#     1. Technical Indicators: True Range (TR), ATR, and ATRP.\n",
    "#     2. Data Quality Metrics: Rolling stale percentage, median dollar volume, etc.\n",
    "\n",
    "#     Args:\n",
    "#         df_ohlcv: The primary DataFrame with a (Ticker, Date) MultiIndex and\n",
    "#                   columns for 'Adj High', 'Adj Low', 'Adj Close', 'Volume'.\n",
    "#         atr_period: The lookback period for the ATR's Exponential Moving Average.\n",
    "#         quality_window: The rolling window size for data quality metrics.\n",
    "#         quality_min_periods: The minimum number of observations required to have\n",
    "#                              a valid quality metric.\n",
    "\n",
    "#     Returns:\n",
    "#         A new DataFrame with the same (Ticker, Date) MultiIndex containing all\n",
    "#         calculated feature columns.\n",
    "#     \"\"\"\n",
    "#     print(\"--- Starting Feature Generation ---\")\n",
    "    \n",
    "#     # Ensure the DataFrame is sorted for correct window and shift operations\n",
    "#     # FIX: Replaced is_lexsorted() with the current pandas attribute\n",
    "#     if not df_ohlcv.index.is_monotonic_increasing:\n",
    "#         print(\"Sorting index for calculation accuracy...\")\n",
    "#         df_ohlcv = df_ohlcv.sort_index()\n",
    "\n",
    "#     # --- 1. Technical Indicator Calculation (TR, ATR, ATRP) ---\n",
    "#     print(f\"Calculating technical indicators (ATR Period: {atr_period})...\")\n",
    "    \n",
    "#     # Group by ticker to handle each security independently\n",
    "#     grouped = df_ohlcv.groupby(level='Ticker')\n",
    "    \n",
    "#     # Get the previous day's close required for True Range\n",
    "#     prev_close = grouped['Adj Close'].shift(1)\n",
    "    \n",
    "#     # Calculate the three components of True Range\n",
    "#     high_low = df_ohlcv['Adj High'] - df_ohlcv['Adj Low']\n",
    "#     high_prev_close = abs(df_ohlcv['Adj High'] - prev_close)\n",
    "#     low_prev_close = abs(df_ohlcv['Adj Low'] - prev_close)\n",
    "    \n",
    "#     # Combine the components to get the final TR\n",
    "#     tr = pd.concat([high_low, high_prev_close, low_prev_close], axis=1).max(axis=1, skipna=False)\n",
    "    \n",
    "#     # # Calculate the ATR using an Exponential Moving Average\n",
    "#     # --- FIX IS HERE ---\n",
    "#     # Use .transform() to apply the EWM function. \n",
    "#     # This guarantees the resulting Series has the exact same index as 'tr',\n",
    "#     # preventing the index alignment error during the subsequent division.\n",
    "#     atr = tr.groupby(level='Ticker').transform(\n",
    "#         lambda x: x.ewm(alpha=1/atr_period, adjust=False).mean()\n",
    "#     )\n",
    "\n",
    "#     # --- CHANGE 1: Removed .fillna(0) ---\n",
    "#     # ATRP will now be NaN on the first day, consistent with TR and ATR.\n",
    "#     atrp = (atr / df_ohlcv['Adj Close']).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "#     indicator_df = pd.DataFrame({\n",
    "#         'TR': tr,\n",
    "#         'ATR': atr,\n",
    "#         'ATRP': atrp\n",
    "#     })\n",
    "    \n",
    "#     # --- 2. Data Quality Metric Calculation ---\n",
    "#     print(f\"Calculating data quality metrics (Window: {quality_window} days)...\")\n",
    "    \n",
    "#     # Create intermediate flags needed for quality calculations\n",
    "#     is_stale = np.where((df_ohlcv['Volume'] == 0) | (df_ohlcv['Adj High'] == df_ohlcv['Adj Low']), 1, 0)\n",
    "#     dollar_volume = df_ohlcv['Adj Close'] * df_ohlcv['Volume']\n",
    "#     has_same_volume = (grouped['Volume'].diff() == 0).astype(int)\n",
    "    \n",
    "#     # Combine flags into a temporary DataFrame for rolling calculations\n",
    "#     quality_temp_df = pd.DataFrame({\n",
    "#         'IsStale': is_stale,\n",
    "#         'DollarVolume': dollar_volume,\n",
    "#         'HasSameVolume': has_same_volume\n",
    "#     }, index=df_ohlcv.index) # Explicitly set index to be safe\n",
    "    \n",
    "#     # Perform the rolling calculations on the grouped data\n",
    "#     # --- FIX IS HERE ---\n",
    "#     # We switch to the older, more compatible dictionary-based aggregation method.\n",
    "#     # This syntax is understood by nearly all versions of pandas.\n",
    "#     rolling_result = quality_temp_df.groupby(level='Ticker').rolling(\n",
    "#         window=quality_window,\n",
    "#         min_periods=quality_min_periods\n",
    "#     ).agg({\n",
    "#         'IsStale': 'mean',\n",
    "#         'DollarVolume': 'median',\n",
    "#         'HasSameVolume': 'sum'\n",
    "#     })\n",
    "    \n",
    "#     # The dictionary syntax produces columns with the original names ('IsStale', etc.).\n",
    "#     # We now explicitly rename them to our desired final names.\n",
    "#     rolling_result = rolling_result.rename(columns={\n",
    "#         'IsStale': 'RollingStalePct',\n",
    "#         'DollarVolume': 'RollMedDollarVol', # <-- RENAMED HERE\n",
    "#         'HasSameVolume': 'RollingSameVolCount'\n",
    "#     })\n",
    "\n",
    "#     # The index after a grouped rolling operation is hierarchical.\n",
    "#     # We remove the outermost 'Ticker' level to restore the original index structure.\n",
    "#     rolling_quality = rolling_result.reset_index(level=0, drop=True)\n",
    "\n",
    "#     # --- 3. Combine All Features ---\n",
    "#     print(\"Combining all feature sets...\")\n",
    "#     features_df = pd.concat([indicator_df, rolling_quality], axis=1)\n",
    "    \n",
    "#     print(\"✅ Feature generation complete.\")\n",
    "#     return features_df\n",
    "\n",
    "# def test_features_df(features_df: pd.DataFrame, \n",
    "#                      df_ohlcv: pd.DataFrame, \n",
    "#                      test_ticker: str = 'AAPL',\n",
    "#                      spot_check_date: str = '2020-03-20'):\n",
    "#     \"\"\"\n",
    "#     Runs a suite of tests to verify the correctness of the generated features_df.\n",
    "\n",
    "#     Args:\n",
    "#         features_df: The generated DataFrame from the generate_features function.\n",
    "#         df_ohlcv: The original source OHLCV DataFrame.\n",
    "#         test_ticker: A common, liquid ticker to use for specific value checks.\n",
    "#     \"\"\"\n",
    "#     print(f\"\\n--- Running Verification Suite for features_df (Test Ticker: {test_ticker}) ---\")\n",
    "    \n",
    "#     # --- Test 1: Structural Integrity ---\n",
    "#     print(\"\\n[Test 1: Structural Integrity]\")\n",
    "#     assert features_df.index.equals(df_ohlcv.index), \"FAIL: Index does not match original df_ohlcv.\"\n",
    "#     print(\"  ✅ PASS: Index matches original df_ohlcv.\")\n",
    "    \n",
    "#     expected_cols = ['TR', 'ATR', 'ATRP', 'RollingStalePct', 'RollMedDollarVol', 'RollingSameVolCount']\n",
    "#     assert all(col in features_df.columns for col in expected_cols), \"FAIL: Missing one or more expected columns.\"\n",
    "#     print(\"  ✅ PASS: All expected feature columns are present.\")\n",
    "#     print(f\"  - DataFrame Info:\")\n",
    "#     features_df.info(verbose=False, memory_usage='deep')\n",
    "\n",
    "\n",
    "#     # --- Test 2: ATR Calculation Logic ---\n",
    "#     print(\"\\n[Test 2: ATR Logic Verification]\")\n",
    "#     ticker_features = features_df.loc[test_ticker]\n",
    "    \n",
    "#     # Test 2a: First TR value should be NaN (since prev_close is NaN)\n",
    "#     first_tr = ticker_features['TR'].iloc[0]\n",
    "#     assert pd.isna(first_tr), f\"FAIL: First TR value for {test_ticker} should be NaN, but got {first_tr}.\"\n",
    "#     print(f\"  ✅ PASS: First TR value for {test_ticker} is NaN as expected.\")\n",
    "\n",
    "#     # Test 2b: The first valid ATR should equal the first valid TR (EWM cold start behavior)\n",
    "#     first_valid_tr_val = ticker_features['TR'].dropna().iloc[0]\n",
    "#     first_valid_atr_val = ticker_features['ATR'].dropna().iloc[0]\n",
    "#     assert np.isclose(first_valid_tr_val, first_valid_atr_val), \\\n",
    "#         f\"FAIL: First valid ATR ({first_valid_atr_val}) should equal first valid TR ({first_valid_tr_val}).\"\n",
    "#     print(\"  ✅ PASS: First valid ATR correctly seeded with first valid TR.\")\n",
    "\n",
    "\n",
    "#     # --- Test 3: Rolling Quality Metrics Logic ---\n",
    "#     print(\"\\n[Test 3: Rolling Quality Metrics Logic Verification]\")\n",
    "#     quality_min_periods = 126 # Should match the parameter used in generation\n",
    "    \n",
    "#     # Test 3a: Check for leading NaNs\n",
    "#     first_valid_quality_idx = ticker_features['RollingStalePct'].first_valid_index()\n",
    "#     if first_valid_quality_idx is None:\n",
    "#         print(f\"  - INFO: No valid quality metrics found for {test_ticker} (likely too little data). Skipping test.\")\n",
    "#     else:\n",
    "#         position_of_first_valid = ticker_features.index.get_loc(first_valid_quality_idx)\n",
    "#         assert position_of_first_valid == quality_min_periods - 1, \\\n",
    "#             f\"FAIL: First valid quality metric should appear at index {quality_min_periods - 1}, but appeared at {position_of_first_valid}.\"\n",
    "#         print(f\"  ✅ PASS: Leading NaNs are present for the first {quality_min_periods - 1} periods as expected.\")\n",
    "\n",
    "\n",
    "#     # --- Test 4: Spot Check Against Manual Calculation ---\n",
    "#     print(\"\\n[Test 4: Spot Check vs. Manual Calculation]\")\n",
    "#     # # Choose a specific date for a manual calculation\n",
    "#     # spot_check_date = '2020-03-20' # A volatile day for a good test\n",
    "    \n",
    "#     # Manual TR Calculation\n",
    "#     today_data = df_ohlcv.loc[(test_ticker, spot_check_date)]\n",
    "#     yesterday_data = df_ohlcv.loc[(test_ticker, pd.to_datetime(spot_check_date) - pd.Timedelta(days=1))] # simple lookback for test\n",
    "    \n",
    "#     manual_h_l = today_data['Adj High'] - today_data['Adj Low']\n",
    "#     manual_h_pc = abs(today_data['Adj High'] - yesterday_data['Adj Close'])\n",
    "#     manual_l_pc = abs(today_data['Adj Low'] - yesterday_data['Adj Close'])\n",
    "#     manual_tr = max(manual_h_l, manual_h_pc, manual_l_pc)\n",
    "    \n",
    "#     code_tr = ticker_features.loc[spot_check_date]['TR']\n",
    "    \n",
    "#     assert np.isclose(manual_tr, code_tr), f\"FAIL: Manual TR ({manual_tr:.4f}) does not match code TR ({code_tr:.4f}) on {spot_check_date}.\"\n",
    "#     print(f\"  ✅ PASS: Manually calculated TR on {spot_check_date} matches code's TR.\")\n",
    "    \n",
    "#     print(\"\\n--- ✅ All Verification Tests Passed ---\")\n",
    "\n",
    "# def export_ticker_data(ticker_to_export: str, \n",
    "#                          df_ohlcv: pd.DataFrame, \n",
    "#                          features_df: pd.DataFrame, \n",
    "#                          output_dir: str = 'export_csv'):\n",
    "#     \"\"\"\n",
    "#     Exports the raw OHLCV data and the corresponding calculated features for a \n",
    "#     single ticker to two separate CSV files.\n",
    "\n",
    "#     This function is designed for easy manual verification of data and calculations.\n",
    "#     It will create the output directory if it does not exist.\n",
    "\n",
    "#     Args:\n",
    "#         ticker_to_export: The ticker symbol to export (e.g., 'AAPL').\n",
    "#         df_ohlcv: The main DataFrame containing the raw OHLCV data with a \n",
    "#                   (Ticker, Date) MultiIndex.\n",
    "#         features_df: The DataFrame containing the calculated features with a \n",
    "#                      (Ticker, Date) MultiIndex.\n",
    "#         output_dir: The directory where the CSV files will be saved. \n",
    "#                     Defaults to 'export_csv'.\n",
    "#     \"\"\"\n",
    "#     print(f\"--- Attempting to export data for ticker: {ticker_to_export} ---\")\n",
    "    \n",
    "#     # --- 1. Ensure the output directory exists ---\n",
    "#     try:\n",
    "#         os.makedirs(output_dir, exist_ok=True)\n",
    "#         print(f\"Output directory '{output_dir}' is ready.\")\n",
    "#     except OSError as e:\n",
    "#         print(f\"Error: Could not create directory '{output_dir}'. Reason: {e}\")\n",
    "#         return\n",
    "\n",
    "#     # --- 2. Isolate the data for the specified ticker ---\n",
    "#     try:\n",
    "#         # Use .loc to select all rows for the given ticker from the MultiIndex\n",
    "#         ticker_ohlcv = df_ohlcv.loc[ticker_to_export]\n",
    "#         ticker_features = features_df.loc[ticker_to_export]\n",
    "        \n",
    "#         if ticker_ohlcv.empty:\n",
    "#             print(f\"Warning: No OHLCV data found for ticker '{ticker_to_export}'. Cannot export.\")\n",
    "#             return\n",
    "            \n",
    "#         print(f\"Found {len(ticker_ohlcv)} rows of data for '{ticker_to_export}'.\")\n",
    "        \n",
    "#     except KeyError:\n",
    "#         print(f\"Error: Ticker '{ticker_to_export}' not found in one or both of the DataFrames. Please check the symbol.\")\n",
    "#         return\n",
    "#     except Exception as e:\n",
    "#         print(f\"An unexpected error occurred while accessing data: {e}\")\n",
    "#         return\n",
    "\n",
    "#     # --- 3. Construct file paths and export to CSV ---\n",
    "#     try:\n",
    "#         # Define the full path for each output file\n",
    "#         ohlcv_filename = f\"{ticker_to_export}_ohlcv.csv\"\n",
    "#         features_filename = f\"{ticker_to_export}_features.csv\"\n",
    "        \n",
    "#         ohlcv_filepath = os.path.join(output_dir, ohlcv_filename)\n",
    "#         features_filepath = os.path.join(output_dir, features_filename)\n",
    "        \n",
    "#         # Export the DataFrames to CSV. The index (Date) will be included.\n",
    "#         ticker_ohlcv.to_csv(ohlcv_filepath)\n",
    "#         ticker_features.to_csv(features_filepath)\n",
    "        \n",
    "#         print(\"\\n✅ Export successful!\")\n",
    "#         print(f\"   - Raw OHLCV data saved to: {ohlcv_filepath}\")\n",
    "#         print(f\"   - Calculated features saved to: {features_filepath}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error: Failed to write data to CSV files. Reason: {e}\")\n",
    "\n",
    "# def create_synthetic_ticker_data(\n",
    "#     ticker_name: str = 'SYNTH', \n",
    "#     num_days: int = 50,\n",
    "#     num_zero_volume_days: int = 5,\n",
    "#     num_flat_price_days: int = 3\n",
    "# ) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Creates a synthetic OHLCV DataFrame with predictable patterns and randomly injected\n",
    "#     stale data conditions for robust testing.\n",
    "\n",
    "#     Args:\n",
    "#         ticker_name: The name for the synthetic ticker.\n",
    "#         num_days: The total number of days for the ticker's history.\n",
    "#         num_zero_volume_days: The number of random days to set Volume to 0.\n",
    "#         num_flat_price_days: The number of random days to set High == Low.\n",
    "\n",
    "#     Returns:\n",
    "#         A pandas DataFrame with a (Ticker, Date) MultiIndex.\n",
    "#     \"\"\"\n",
    "#     print(f\"--- Creating synthetic data for '{ticker_name}' with {num_days} days ---\")\n",
    "    \n",
    "#     # 1. Create a base DataFrame with \"normal\" data\n",
    "#     dates = pd.to_datetime(pd.date_range(start='2023-01-01', periods=num_days, freq='B'))\n",
    "#     data = {\n",
    "#         'Adj Open': 100.0, 'Adj High': 102.0, 'Adj Low': 98.0,\n",
    "#         'Adj Close': 100.0, 'Volume': 1_000_000\n",
    "#     }\n",
    "#     df = pd.DataFrame(data, index=dates)\n",
    "#     df['Adj Close'] = df['Adj Close'] + np.random.randn(num_days) * 0.5 # Add some noise\n",
    "\n",
    "#     # 2. Define a \"protected\" window for specific verification tests.\n",
    "#     # The `verify_synthetic_ticker_features` function depends on this exact window.\n",
    "#     # We will not inject random stale days here.\n",
    "#     protected_start_idx, protected_end_idx = 10, 20\n",
    "    \n",
    "#     # 3. Inject random \"stale\" days OUTSIDE the protected window\n",
    "#     available_indices = df.index.drop(df.index[protected_start_idx:protected_end_idx])\n",
    "    \n",
    "#     # Inject zero-volume days\n",
    "#     if num_zero_volume_days > 0:\n",
    "#         if len(available_indices) < num_zero_volume_days:\n",
    "#             raise ValueError(\"Not enough available days to inject zero-volume days.\")\n",
    "#         zero_vol_dates = np.random.choice(available_indices, num_zero_volume_days, replace=False)\n",
    "#         df.loc[zero_vol_dates, 'Volume'] = 0\n",
    "#         print(f\"  - Injected {num_zero_volume_days} random zero-volume 'stale' days.\")\n",
    "#         # Update available indices to avoid overlap\n",
    "#         available_indices = available_indices.drop(zero_vol_dates)\n",
    "\n",
    "#     # Inject flat-price days (High == Low)\n",
    "#     if num_flat_price_days > 0:\n",
    "#         if len(available_indices) < num_flat_price_days:\n",
    "#             raise ValueError(\"Not enough available days to inject flat-price days.\")\n",
    "#         flat_price_dates = np.random.choice(available_indices, num_flat_price_days, replace=False)\n",
    "#         # Set High and Low to be the same as the Close price for that day\n",
    "#         df.loc[flat_price_dates, 'Adj High'] = df.loc[flat_price_dates, 'Adj Close']\n",
    "#         df.loc[flat_price_dates, 'Adj Low'] = df.loc[flat_price_dates, 'Adj Close']\n",
    "#         print(f\"  - Injected {num_flat_price_days} random flat-price 'stale' days.\")\n",
    "\n",
    "#     # 4. Inject the specific, hand-crafted patterns inside the protected window for verification\n",
    "#     print(\"  - Injecting specific patterns for programmatic verification...\")\n",
    "#     # Pattern for RollingStalePct: 2 stale days in 10 (20%)\n",
    "#     df.iloc[10, df.columns.get_loc('Volume')] = 0  # Stale day (zero volume)\n",
    "#     df.iloc[11, df.columns.get_loc('Adj High')] = 99.0 # Stale day (High == Low)\n",
    "#     df.iloc[11, df.columns.get_loc('Adj Low')] = 99.0\n",
    "    \n",
    "#     # Pattern for RollingMedianVolume\n",
    "#     for i in range(10):\n",
    "#         df.iloc[10 + i, df.columns.get_loc('Adj Close')] = 100.0 # Standardize price for easy median calc\n",
    "#         df.iloc[10 + i, df.columns.get_loc('Volume')] = (i + 1) * 10000\n",
    "\n",
    "#     # Pattern for RollingSameVolCount\n",
    "#     df.iloc[15, df.columns.get_loc('Volume')] = 77777\n",
    "#     df.iloc[16, df.columns.get_loc('Volume')] = 77777\n",
    "#     df.iloc[17, df.columns.get_loc('Volume')] = 77777\n",
    "    \n",
    "#     # 5. Set the MultiIndex\n",
    "#     df['Ticker'] = ticker_name\n",
    "#     df = df.set_index(['Ticker', df.index])\n",
    "#     df.index.names = ['Ticker', 'Date']\n",
    "    \n",
    "#     print(\"✅ Synthetic data created successfully.\")\n",
    "#     return df\n",
    "\n",
    "# def verify_synthetic_ticker_features(features_df: pd.DataFrame, \n",
    "#                                        ticker_name: str = 'SYNTH',\n",
    "#                                        quality_window: int = 10):\n",
    "#     \"\"\"\n",
    "#     Verifies the quality metric calculations on the features_df generated from\n",
    "#     the synthetic ticker data.\n",
    "\n",
    "#     Args:\n",
    "#         features_df: The DataFrame of calculated features.\n",
    "#         ticker_name: The name of the synthetic ticker.\n",
    "#         quality_window: The rolling window used, which must match the window\n",
    "#                         of the synthetic data pattern.\n",
    "#     \"\"\"\n",
    "#     print(f\"\\n--- Running Verification on Synthetic Ticker '{ticker_name}' ---\")\n",
    "    \n",
    "#     # --- Expected values based on our synthetic data design ---\n",
    "#     EXPECTED_STALE_PCT = 0.20  # 2 stale days out of 10\n",
    "#     EXPECTED_MEDIAN_DOLLAR_VOL = 5_500_000.0 # median of (10k..100k) * price of 100\n",
    "#     EXPECTED_SAME_VOL_COUNT = 2.0 # Three consecutive days gives two 'diff() == 0' events\n",
    "\n",
    "#     try:\n",
    "#         # Isolate the features for our synthetic ticker\n",
    "#         ticker_features = features_df.loc[ticker_name]\n",
    "        \n",
    "#         # The first valid calculation will be on the last day of our 10-day window.\n",
    "#         # The window starts at index 10 and has a length of 10, so it ends at index 19.\n",
    "#         verification_date = ticker_features.index[19]\n",
    "        \n",
    "#         print(f\"Verifying calculations on date: {verification_date.date()}\")\n",
    "        \n",
    "#         # Get the calculated values from the DataFrame\n",
    "#         calculated_values = ticker_features.loc[verification_date]\n",
    "#         stale_pct = calculated_values['RollingStalePct']\n",
    "#         # --- CHANGE 2 (continued): Accessing the renamed column ---\n",
    "#         median_vol = calculated_values['RollMedDollarVol'] \n",
    "#         same_vol_count = calculated_values['RollingSameVolCount']\n",
    "        \n",
    "#         # --- Perform Assertions ---\n",
    "#         print(\"\\n[Test 1: RollingStalePct]\")\n",
    "#         assert np.isclose(stale_pct, EXPECTED_STALE_PCT), f\"FAIL: Expected {EXPECTED_STALE_PCT}, Got {stale_pct}\"\n",
    "#         print(f\"  ✅ PASS: Expected {EXPECTED_STALE_PCT}, Got {stale_pct}\")\n",
    "\n",
    "#         print(\"\\n[Test 2: RollMedDollarVol]\")\n",
    "#         assert np.isclose(median_vol, EXPECTED_MEDIAN_DOLLAR_VOL), f\"FAIL: Expected {EXPECTED_MEDIAN_DOLLAR_VOL}, Got {median_vol}\"\n",
    "#         print(f\"  ✅ PASS: Expected {EXPECTED_MEDIAN_DOLLAR_VOL}, Got {median_vol}\")\n",
    "\n",
    "#         print(\"\\n[Test 3: RollingSameVolCount]\")\n",
    "#         assert np.isclose(same_vol_count, EXPECTED_SAME_VOL_COUNT), f\"FAIL: Expected {EXPECTED_SAME_VOL_COUNT}, Got {same_vol_count}\"\n",
    "#         print(f\"  ✅ PASS: Expected {EXPECTED_SAME_VOL_COUNT}, Got {same_vol_count}\")\n",
    "\n",
    "#         print(\"\\n--- ✅ All Synthetic Data Verification Tests Passed ---\")\n",
    "\n",
    "#     except KeyError:\n",
    "#         print(f\"FAIL: Ticker '{ticker_name}' not found in features_df.\")\n",
    "#     except IndexError:\n",
    "#         print(\"FAIL: Not enough data in features_df to run verification. Check num_days.\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"An unexpected error occurred during verification: {e}\")\n",
    "\n",
    "# # --- A. HELPER FUNCTIONS ---\n",
    "\n",
    "# def calculate_gain(price_series: pd.Series):\n",
    "#     \"\"\"Calculates the total gain over a series of prices.\"\"\"\n",
    "#     # Ensure there are at least two data points to calculate a gain\n",
    "#     if price_series.dropna().shape[0] < 2: return np.nan\n",
    "#     # Use forward-fill for the end price and back-fill for the start price\n",
    "#     # to handle potential NaNs at the beginning or end of the series.\n",
    "#     return (price_series.ffill().iloc[-1] / price_series.bfill().iloc[0]) - 1\n",
    "\n",
    "# def calculate_sharpe(return_series: pd.Series):\n",
    "#     \"\"\"Calculates the annualized Sharpe ratio from a series of daily returns.\"\"\"\n",
    "#     # Ensure there are at least two returns to calculate a standard deviation\n",
    "#     if return_series.dropna().shape[0] < 2: return np.nan\n",
    "#     std_dev = return_series.std()\n",
    "#     # Avoid division by zero if returns are constant\n",
    "#     if std_dev > 0 and std_dev != np.inf:\n",
    "#         return (return_series.mean() / std_dev) * np.sqrt(252)\n",
    "#     return np.nan\n",
    "\n",
    "# def calculate_sharpe_atr(return_series: pd.Series, atrp_series: pd.Series):\n",
    "#     \"\"\"Calculates a Sharpe-like ratio using mean ATRP as the denominator.\"\"\"\n",
    "#     # Ensure there are returns and that ATRP data is valid\n",
    "#     if return_series.dropna().shape[0] < 2 or atrp_series.dropna().empty:\n",
    "#         return np.nan\n",
    "        \n",
    "#     mean_return = return_series.mean()\n",
    "#     mean_atrp = atrp_series.mean()\n",
    "    \n",
    "#     # Avoid division by zero\n",
    "#     if mean_atrp > 0 and mean_atrp != np.inf:\n",
    "#         return mean_return / mean_atrp\n",
    "        \n",
    "#     return np.nan\n",
    "\n",
    "# def print_nested(d, indent=0, width=4):\n",
    "#     \"\"\"Pretty-print any nested dict/list/tuple combination.\"\"\"\n",
    "#     spacing = ' ' * indent\n",
    "#     if isinstance(d, dict):\n",
    "#         for k, v in d.items():\n",
    "#             print(f'{spacing}{k}:')\n",
    "#             print_nested(v, indent + width, width)\n",
    "#     elif isinstance(d, (list, tuple)):\n",
    "#         for item in d:\n",
    "#             print_nested(item, indent, width)\n",
    "#     else:\n",
    "#         print(f'{spacing}{d}')\n",
    "\n",
    "# # --- B. MODULAR METRIC CALCULATION ENGINE ---\n",
    "\n",
    "# def calculate_price_metric(metric_data: dict) -> pd.Series:\n",
    "#     \"\"\"\n",
    "#     Calculates the 'Price' metric (total gain) over the calculation period.\n",
    "\n",
    "#     Args:\n",
    "#         metric_data: A dictionary containing pre-calculated data Series.\n",
    "#                      Requires 'calc_close' (pd.DataFrame): The close prices for the calc period.\n",
    "\n",
    "#     Returns:\n",
    "#         A pandas Series of the calculated metric values, indexed by Ticker.\n",
    "#     \"\"\"\n",
    "#     calc_close = metric_data['calc_close']\n",
    "    \n",
    "#     # Ensure there are at least two data points to calculate a gain\n",
    "#     if len(calc_close) < 2:\n",
    "#         return pd.Series(dtype='float64', index=calc_close.columns)\n",
    "\n",
    "#     first_prices = calc_close.bfill().iloc[0]\n",
    "#     last_prices = calc_close.ffill().iloc[-1]\n",
    "    \n",
    "#     # The division of two Series aligns by index (Ticker), which is what we want.\n",
    "#     price_metric = last_prices / first_prices\n",
    "    \n",
    "#     return price_metric.dropna()\n",
    "\n",
    "# def calculate_sharpe_metric(metric_data: dict) -> pd.Series:\n",
    "#     \"\"\"\n",
    "#     Calculates the annualized 'Sharpe' ratio metric over the calculation period.\n",
    "\n",
    "#     Args:\n",
    "#         metric_data: A dictionary containing pre-calculated data Series.\n",
    "#                      Requires 'daily_returns' (pd.DataFrame): Daily returns for the calc period.\n",
    "\n",
    "#     Returns:\n",
    "#         A pandas Series of the calculated metric values, indexed by Ticker.\n",
    "#     \"\"\"\n",
    "#     daily_returns = metric_data['daily_returns']\n",
    "    \n",
    "#     # Ensure there's enough data to calculate standard deviation\n",
    "#     if len(daily_returns.dropna()) < 2:\n",
    "#         return pd.Series(dtype='float64', index=daily_returns.columns)\n",
    "    \n",
    "#     mean_returns = daily_returns.mean()\n",
    "#     std_returns = daily_returns.std()\n",
    "    \n",
    "#     # Standard annualized Sharpe Ratio calculation. Avoid division by zero.\n",
    "#     # We replace resulting NaNs/infs with 0 to handle cases of zero volatility.\n",
    "#     sharpe_ratio = (mean_returns / std_returns * np.sqrt(252))\n",
    "    \n",
    "#     return sharpe_ratio.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    \n",
    "# def calculate_sharpe_atr_metric(metric_data: dict) -> pd.Series:\n",
    "#     \"\"\"\n",
    "#     Calculates the 'Sharpe (ATR)' metric over the calculation period.\n",
    "\n",
    "#     Args:\n",
    "#         metric_data: A dictionary containing pre-calculated data Series.\n",
    "#                      Requires 'daily_returns' (pd.DataFrame): Daily returns for the calc period.\n",
    "#                      Requires 'atrp' (pd.Series): Mean ATRP for each ticker over the period.\n",
    "\n",
    "#     Returns:\n",
    "#         A pandas Series of the calculated metric values, indexed by Ticker.\n",
    "#     \"\"\"\n",
    "#     daily_returns = metric_data['daily_returns']\n",
    "#     atrp = metric_data['atrp']\n",
    "    \n",
    "#     mean_returns = daily_returns.mean()\n",
    "    \n",
    "#     # ATRP-based Sharpe. Avoid division by zero.\n",
    "#     # We replace resulting NaNs/infs with 0.\n",
    "#     sharpe_atr = mean_returns / atrp\n",
    "    \n",
    "#     return sharpe_atr.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "# # The single source of truth for all available ranking metrics.\n",
    "# # Maps the user-facing name to the calculation function.\n",
    "# METRIC_REGISTRY = {\n",
    "#     'Price': calculate_price_metric,\n",
    "#     'Sharpe': calculate_sharpe_metric,\n",
    "#     'Sharpe (ATR)': calculate_sharpe_atr_metric,\n",
    "# }\n",
    "\n",
    "# print(\"✅ Metric Registry Initialized with:\", list(METRIC_REGISTRY.keys()))\n",
    "\n",
    "# # --- B. THE CORE CALCULATION ENGINE ---\n",
    "\n",
    "# def run_walk_forward_step(df_close_full, df_high_full, df_low_full,\n",
    "#                           master_trading_days,\n",
    "#                           start_date, calc_period, fwd_period,\n",
    "#                           metric, rank_start, rank_end, benchmark_ticker,\n",
    "#                           features_df,\n",
    "#                           debug=False):\n",
    "#     \"\"\"\n",
    "#     Runs a single step of the walk-forward analysis with a strict, pre-emptive\n",
    "#     check to ensure the full period is available.\n",
    "#     \"\"\"\n",
    "#     debug_data = {} if debug else None\n",
    "\n",
    "#     # 1. Determine exact date ranges with a NEW pre-emptive check\n",
    "#     try:\n",
    "#         start_idx = master_trading_days.get_loc(start_date)\n",
    "#     except KeyError:\n",
    "#         return ({'error': f\"Start date {start_date.date()} is not a valid trading day.\"}, None)\n",
    "\n",
    "#     # +++ THIS IS THE NEW PRE-EMPTIVE CHECK LOGIC +++\n",
    "#     # Calculate the desired end index without clamping first.\n",
    "#     desired_viz_end_idx = start_idx + calc_period + fwd_period\n",
    "    \n",
    "#     # Check if the desired end index is out of bounds.\n",
    "#     if desired_viz_end_idx >= len(master_trading_days):\n",
    "#         last_available_date = master_trading_days[-1].date()\n",
    "#         required_days = calc_period + fwd_period\n",
    "#         available_days = len(master_trading_days) - start_idx\n",
    "#         error_msg = (f\"Not enough data for the full requested period. \"\n",
    "#                      f\"Required: {required_days} days, Available: {available_days} days until {last_available_date}.\")\n",
    "#         return ({'error': error_msg}, None)\n",
    "#     # --- END OF NEW CHECK ---\n",
    "\n",
    "#     # If the check passes, we know the full period is available.\n",
    "#     # The 'min' calls are now just a redundant safety measure.\n",
    "#     calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "#     viz_end_idx = min(calc_end_idx + fwd_period, len(master_trading_days) - 1)\n",
    "\n",
    "#     safe_start_date = master_trading_days[start_idx]\n",
    "#     safe_calc_end_date = master_trading_days[calc_end_idx]\n",
    "#     safe_viz_end_date = master_trading_days[viz_end_idx]\n",
    "    \n",
    "#     if safe_start_date >= safe_calc_end_date:\n",
    "#         return ({'error': \"Invalid date range (calc period has zero or negative length).\"}, None)\n",
    "\n",
    "#     # (The rest of the function remains completely unchanged...)\n",
    "#     # 2. Slice data for the calculation period\n",
    "#     calc_close_raw = df_close_full.loc[safe_start_date:safe_calc_end_date]\n",
    "#     calc_close = calc_close_raw.dropna(axis=1, how='all')\n",
    "#     if calc_close.shape[1] == 0 or len(calc_close) < 2:\n",
    "#         return ({'error': \"Not enough data in calc period.\"}, None)\n",
    "\n",
    "#     # 3. Calculate INTERMEDIATE data required for the ranking metrics\n",
    "#     daily_returns = calc_close.bfill().ffill().pct_change()\n",
    "#     valid_tickers = calc_close.columns\n",
    "#     calc_period_index = pd.MultiIndex.from_product([valid_tickers, calc_close.index], names=['Ticker', 'Date'])\n",
    "#     features_in_period = features_df.loc[features_df.index.intersection(calc_period_index)]\n",
    "#     atrp = features_in_period.groupby(level='Ticker')['ATRP'].mean()\n",
    "\n",
    "#     # 4. Calculate all ranking metrics by iterating through the METRIC_REGISTRY\n",
    "#     metric_ingredients = { 'calc_close': calc_close, 'daily_returns': daily_returns, 'atrp': atrp, }\n",
    "#     metric_values = {}\n",
    "#     for name, func in METRIC_REGISTRY.items():\n",
    "#         metric_values[name] = func(metric_ingredients)\n",
    "#     if metric not in metric_values or metric_values[metric].empty:\n",
    "#         return ({'error': f\"Metric '{metric}' could not be calculated or resulted in no valid tickers.\"}, None)\n",
    "\n",
    "#     # 5. Rank tickers and select the portfolio\n",
    "#     sorted_tickers = metric_values[metric].sort_values(ascending=False)\n",
    "#     tickers_to_display = sorted_tickers.index[rank_start-1:rank_end].tolist()\n",
    "#     if not tickers_to_display:\n",
    "#         return ({'error': \"No tickers found for the selected rank.\"}, None)\n",
    "\n",
    "#     # 6. Calculate Portfolio & Benchmark Performance\n",
    "#     normalized_plot_data = df_close_full[tickers_to_display].loc[safe_start_date:safe_viz_end_date]\n",
    "#     normalized_plot_data = normalized_plot_data.div(normalized_plot_data.bfill().iloc[0])\n",
    "#     actual_calc_end_ts = calc_close.index.max()\n",
    "#     portfolio_series = normalized_plot_data.mean(axis=1)\n",
    "#     portfolio_return_series = portfolio_series.pct_change()\n",
    "#     benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "#     benchmark_return_series = benchmark_price_series.loc[safe_start_date:safe_viz_end_date].bfill().ffill().pct_change() if benchmark_price_series is not None else pd.Series(dtype='float64')\n",
    "#     try:\n",
    "#         boundary_loc = portfolio_return_series.index.get_loc(actual_calc_end_ts)\n",
    "#         calc_portfolio_returns = portfolio_return_series.iloc[:boundary_loc + 1]\n",
    "#         fwd_portfolio_returns = portfolio_return_series.iloc[boundary_loc + 1:]\n",
    "#         if benchmark_price_series is not None:\n",
    "#             bm_boundary_loc = benchmark_return_series.index.get_loc(actual_calc_end_ts)\n",
    "#             calc_benchmark_returns = benchmark_return_series.iloc[:bm_boundary_loc + 1]\n",
    "#             fwd_benchmark_returns = benchmark_return_series.iloc[bm_boundary_loc + 1:]\n",
    "#         else:\n",
    "#             calc_benchmark_returns, fwd_benchmark_returns = pd.Series(dtype='float64'), pd.Series(dtype='float64')\n",
    "#     except (KeyError, IndexError):\n",
    "#         calc_portfolio_returns = portfolio_return_series.loc[:actual_calc_end_ts]\n",
    "#         fwd_portfolio_returns = portfolio_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "#         if benchmark_price_series is not None:\n",
    "#             calc_benchmark_returns = benchmark_return_series.loc[:actual_calc_end_ts]\n",
    "#             fwd_benchmark_returns = benchmark_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "#         else:\n",
    "#             calc_benchmark_returns, fwd_benchmark_returns = pd.Series(dtype='float64'), pd.Series(dtype='float64')\n",
    "#     full_period_index = pd.MultiIndex.from_product([tickers_to_display, portfolio_return_series.index], names=['Ticker', 'Date'])\n",
    "#     portfolio_atrp_features = features_df.loc[features_df.index.intersection(full_period_index)]\n",
    "#     portfolio_atrp_daily_unstacked = portfolio_atrp_features['ATRP'].unstack(level='Ticker')\n",
    "#     portfolio_atrp_series = portfolio_atrp_daily_unstacked.mean(axis=1)\n",
    "#     if benchmark_ticker in df_close_full.columns:\n",
    "#         benchmark_atrp_series = features_df.xs(benchmark_ticker, level='Ticker')['ATRP'].loc[safe_start_date:safe_viz_end_date]\n",
    "#     else:\n",
    "#         benchmark_atrp_series = pd.Series(dtype='float64')\n",
    "#     calc_portfolio_atrp = portfolio_atrp_series.loc[:actual_calc_end_ts]\n",
    "#     fwd_portfolio_atrp = portfolio_atrp_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "#     calc_benchmark_atrp = benchmark_atrp_series.loc[:actual_calc_end_ts]\n",
    "#     fwd_benchmark_atrp = benchmark_atrp_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "#     perf_data = {}\n",
    "#     perf_data['calc_p_gain'] = calculate_gain(portfolio_series.loc[:actual_calc_end_ts])\n",
    "#     perf_data['fwd_p_gain'] = calculate_gain(portfolio_series.loc[actual_calc_end_ts:])\n",
    "#     perf_data['full_p_gain'] = calculate_gain(portfolio_series)\n",
    "#     perf_data['calc_p_sharpe'] = calculate_sharpe(calc_portfolio_returns)\n",
    "#     perf_data['fwd_p_sharpe'] = calculate_sharpe(fwd_portfolio_returns)\n",
    "#     perf_data['full_p_sharpe'] = calculate_sharpe(portfolio_return_series)\n",
    "#     perf_data['calc_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:actual_calc_end_ts]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['fwd_b_gain'] = calculate_gain(benchmark_price_series.loc[actual_calc_end_ts:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['full_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['calc_b_sharpe'] = calculate_sharpe(calc_benchmark_returns)\n",
    "#     perf_data['fwd_b_sharpe'] = calculate_sharpe(fwd_benchmark_returns)\n",
    "#     perf_data['full_b_sharpe'] = calculate_sharpe(benchmark_return_series)\n",
    "#     perf_data['calc_p_sharpe_atr'] = calculate_sharpe_atr(calc_portfolio_returns, calc_portfolio_atrp)\n",
    "#     perf_data['fwd_p_sharpe_atr'] = calculate_sharpe_atr(fwd_portfolio_returns, fwd_portfolio_atrp)\n",
    "#     perf_data['full_p_sharpe_atr'] = calculate_sharpe_atr(portfolio_return_series, portfolio_atrp_series)\n",
    "#     perf_data['calc_b_sharpe_atr'] = calculate_sharpe_atr(calc_benchmark_returns, calc_benchmark_atrp)\n",
    "#     perf_data['fwd_b_sharpe_atr'] = calculate_sharpe_atr(fwd_benchmark_returns, fwd_benchmark_atrp)\n",
    "#     perf_data['full_b_sharpe_atr'] = calculate_sharpe_atr(benchmark_return_series, benchmark_atrp_series)\n",
    "#     if debug:\n",
    "#         df_ranking_base = pd.DataFrame({'MeanDailyReturn': daily_returns.mean(),'StdDevDailyReturn': daily_returns.std(),'MeanATRP': atrp})\n",
    "#         df_metrics = pd.DataFrame(metric_values)\n",
    "#         df_metrics.columns = [f'Metric_{col}' for col in df_metrics.columns]\n",
    "#         df_ranking = df_ranking_base.join(df_metrics, how='left')\n",
    "#         df_ranking.index.name = 'Ticker'\n",
    "#         debug_data['ranking_metrics'] = df_ranking.sort_values(f'Metric_{metric}', ascending=False)\n",
    "#     calc_end_prices = calc_close.ffill().iloc[-1]\n",
    "#     fwd_close_slice = df_close_full.loc[actual_calc_end_ts:safe_viz_end_date]\n",
    "#     viz_end_prices = fwd_close_slice.ffill().iloc[-1] if not fwd_close_slice.empty and len(fwd_close_slice) >= 2 else calc_end_prices\n",
    "#     calc_gains = (calc_end_prices / calc_close.bfill().iloc[0]) - 1\n",
    "#     fwd_gains = (viz_end_prices / calc_end_prices) - 1\n",
    "#     results_df = pd.DataFrame({'Rank': range(rank_start, rank_start + len(tickers_to_display)), 'Metric': metric, 'MetricValue': sorted_tickers.loc[tickers_to_display].values, 'CalcPrice': calc_end_prices.loc[tickers_to_display], 'CalcGain': calc_gains.loc[tickers_to_display], 'FwdGain': fwd_gains.loc[tickers_to_display]}, index=pd.Index(tickers_to_display, name='Ticker'))\n",
    "#     if benchmark_price_series is not None and benchmark_ticker in calc_close.columns:\n",
    "#         benchmark_df_row = pd.DataFrame({'Rank': np.nan, 'Metric': metric, 'MetricValue': metric_values[metric].get(benchmark_ticker, np.nan), 'CalcPrice': calc_end_prices[benchmark_ticker], 'CalcGain': calc_gains[benchmark_ticker], 'FwdGain': fwd_gains[benchmark_ticker]}, index=pd.Index([f\"{benchmark_ticker} (BM)\"], name='Ticker'))\n",
    "#         results_df = pd.concat([results_df, benchmark_df_row])\n",
    "#     if debug:\n",
    "#         df_trace = normalized_plot_data.copy()\n",
    "#         df_trace.columns = [f'Norm_Price_{c}' for c in df_trace.columns]\n",
    "#         df_trace['Norm_Price_Portfolio'] = portfolio_series\n",
    "#         if benchmark_price_series is not None and not benchmark_price_series.loc[safe_start_date:safe_viz_end_date].dropna().empty:\n",
    "#             norm_bm = benchmark_price_series.loc[safe_start_date:safe_viz_end_date] / benchmark_price_series.loc[safe_start_date:].bfill().iloc[0]\n",
    "#             df_trace[f'Norm_Price_Benchmark_{benchmark_ticker}'] = norm_bm\n",
    "#         for col in df_trace.columns:\n",
    "#             if 'Norm_Price' in col:\n",
    "#                 df_trace[col.replace('Norm_Price', 'Return')] = df_trace[col].pct_change()\n",
    "#         debug_data['portfolio_trace'] = df_trace\n",
    "#     final_results = {\n",
    "#         'tickers_to_display': tickers_to_display, 'normalized_plot_data': normalized_plot_data,\n",
    "#         'portfolio_series': portfolio_series, 'benchmark_price_series': benchmark_price_series,\n",
    "#         'performance_data': perf_data, 'results_df': results_df, 'actual_calc_end_ts': actual_calc_end_ts,\n",
    "#         'safe_start_date': safe_start_date, 'safe_viz_end_date': safe_viz_end_date,\n",
    "#         'error': None\n",
    "#     }\n",
    "#     return (final_results, debug_data)\n",
    "\n",
    "# # --- C. DYNAMIC DATA QUALITY FILTER FUNCTIONS ---\n",
    "\n",
    "# def get_eligible_universe(features_df, filter_date, thresholds):\n",
    "#     \"\"\"Filters the universe of tickers based on quality metrics for a given date.\"\"\"\n",
    "#     filter_date_ts = pd.to_datetime(filter_date)\n",
    "#     # The index is now the comprehensive features_df\n",
    "#     date_index = features_df.index.get_level_values('Date').unique().sort_values()\n",
    "    \n",
    "#     if filter_date_ts < date_index[0]:\n",
    "#         print(f\"Warning: Filter date {filter_date_ts.date()} is before the earliest data point. Returning empty universe.\")\n",
    "#         return []\n",
    "        \n",
    "#     # Find the most recent date with quality data on or before the filter date\n",
    "#     valid_prior_dates = date_index[date_index <= filter_date_ts]\n",
    "#     if valid_prior_dates.empty:\n",
    "#         print(f\"Warning: No available data found on or before {filter_date_ts.date()}. Returning empty universe.\")\n",
    "#         return []\n",
    "        \n",
    "#     actual_date_to_use = valid_prior_dates[-1]\n",
    "#     if actual_date_to_use.date() != filter_date_ts.date():\n",
    "#         print(f\"ℹ️ Info: Filter date {filter_date_ts.date()} not found. Using previous available date {actual_date_to_use.date()}.\")\n",
    "\n",
    "#     metrics_on_date = features_df.xs(actual_date_to_use, level='Date')\n",
    "    \n",
    "#     # Apply filters using the new column names from features_df\n",
    "#     mask = ((metrics_on_date['RollMedDollarVol'] >= thresholds['min_median_dollar_volume']) & # <-- RENAMED\n",
    "#             (metrics_on_date['RollingStalePct'] <= thresholds['max_stale_pct']) &\n",
    "#             (metrics_on_date['RollingSameVolCount'] <= thresholds['max_same_vol_count']))\n",
    "            \n",
    "#     eligible_tickers = metrics_on_date[mask].index.tolist()\n",
    "#     all_tickers = metrics_on_date.index.tolist()\n",
    "#     print(f\"Dynamic Filter ({filter_date_ts.date()}): Kept {len(eligible_tickers)} of {len(all_tickers)} tickers.\")\n",
    "#     return eligible_tickers\n",
    "\n",
    "# # --- D. INTERACTIVE ANALYSIS & BACKTESTING TOOLS ---\n",
    "\n",
    "# def plot_walk_forward_analyzer(df_ohlcv,\n",
    "#                                default_start_date=None, default_calc_period=126, default_fwd_period=63,\n",
    "#                                default_metric='Sharpe (ATR)', default_rank_start=1, default_rank_end=10,\n",
    "#                                default_benchmark_ticker='VOO', master_calendar_ticker='VOO',\n",
    "#                                quality_thresholds={'min_median_dollar_volume': 1_000_000, 'max_stale_pct': 0.05, 'max_same_vol_count': 10},\n",
    "#                                debug=False):\n",
    "#     # (No changes to the initial setup part of this function...)\n",
    "#     print(\"Initializing Walk-Forward Analyzer (using Trading Day Logic)...\")\n",
    "#     if not isinstance(df_ohlcv.index, pd.MultiIndex): raise ValueError(\"Input DataFrame must have a (Ticker, Date) MultiIndex.\")\n",
    "#     df_ohlcv = df_ohlcv.sort_index()\n",
    "#     if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "#         raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "#     master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "#     print(f\"Master trading day calendar created from '{master_calendar_ticker}' ({len(master_trading_days)} days).\")\n",
    "#     print(\"--- Generating all features upfront... ---\")\n",
    "#     features_df = generate_features(df_ohlcv)\n",
    "#     print(\"Pre-processing data (unstacking)...\")\n",
    "#     df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "#     df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "#     df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "#     start_date_picker = widgets.DatePicker(description='Start Date:', value=pd.to_datetime(default_start_date), disabled=False)\n",
    "#     calc_period_input = widgets.IntText(value=default_calc_period, description='Calc Period (days):')\n",
    "#     fwd_period_input = widgets.IntText(value=default_fwd_period, description='Fwd Period (days):')\n",
    "#     if default_metric not in METRIC_REGISTRY:\n",
    "#         fallback_metric = list(METRIC_REGISTRY.keys())[0]\n",
    "#         print(f\"⚠️ Warning: Default metric '{default_metric}' not in registry. Using '{fallback_metric}'.\")\n",
    "#         default_metric = fallback_metric\n",
    "#     metric_dropdown = widgets.Dropdown(options=list(METRIC_REGISTRY.keys()), value=default_metric, description='Metric:')\n",
    "#     rank_start_input = widgets.IntText(value=default_rank_start, description='Rank Start:')\n",
    "#     rank_end_input = widgets.IntText(value=default_rank_end, description='Rank End:')\n",
    "#     benchmark_ticker_input = widgets.Text(value=default_benchmark_ticker, description='Benchmark:', placeholder='Enter Ticker')\n",
    "#     update_button = widgets.Button(description=\"Update Chart\", button_style='primary')\n",
    "#     ticker_list_output = widgets.Output()\n",
    "#     results_container, debug_data_container = [None], [None]\n",
    "#     fig = go.FigureWidget()\n",
    "#     max_traces = 50\n",
    "#     for i in range(max_traces): fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name=f'placeholder_{i}', visible=False, showlegend=False))\n",
    "#     fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Benchmark', visible=True, showlegend=True, line=dict(color='black', width=3, dash='dash')))\n",
    "#     fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Group Portfolio', visible=True, showlegend=True, line=dict(color='green', width=3)))\n",
    "\n",
    "#     def update_plot(button_click):\n",
    "#         ticker_list_output.clear_output()\n",
    "#         start_date_raw = pd.to_datetime(start_date_picker.value)\n",
    "#         start_date_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "#         if start_date_idx >= len(master_trading_days):\n",
    "#             with ticker_list_output: print(f\"Error: Start date is after the last available trading day.\"); return\n",
    "#         actual_start_date = master_trading_days[start_date_idx]\n",
    "#         with ticker_list_output:\n",
    "#             if start_date_raw.date() != actual_start_date.date():\n",
    "#                 print(f\"ℹ️ Info: Start date {start_date_raw.date()} is not a trading day. Snapping forward to {actual_start_date.date()}.\")\n",
    "#         calc_period = calc_period_input.value; fwd_period = fwd_period_input.value; metric = metric_dropdown.value\n",
    "#         rank_start = rank_start_input.value; rank_end = rank_end_input.value; benchmark_ticker = benchmark_ticker_input.value.strip().upper()\n",
    "#         if rank_start > rank_end:\n",
    "#             with ticker_list_output: print(\"Error: 'Rank Start' must be <= 'Rank End'.\"); return\n",
    "#         if rank_start < 1 or calc_period < 2 or fwd_period < 1:\n",
    "#             with ticker_list_output: print(\"Error: Ranks must be >= 1, Calc Period >= 2, Fwd Period >= 1.\"); return\n",
    "#         required_days = calc_period + fwd_period\n",
    "#         if start_date_idx + required_days > len(master_trading_days):\n",
    "#             available_days = len(master_trading_days) - start_date_idx; last_available_date = master_trading_days[-1].date()\n",
    "#             with ticker_list_output:\n",
    "#                 print(f\"Error: Not enough data for the requested period.\\n  Start Date: {actual_start_date.date()}\\n  Required Days: {calc_period} (calc) + {fwd_period} (fwd) = {required_days}\\n  Available Days from Start: {available_days} (until {last_available_date})\\n  Please shorten the 'Calc Period' / 'Fwd Period' or choose an earlier 'Start Date'.\")\n",
    "#             return\n",
    "#         eligible_tickers = get_eligible_universe(features_df, actual_start_date, quality_thresholds)\n",
    "#         if not eligible_tickers:\n",
    "#             with ticker_list_output: print(f\"Error: No eligible tickers found on {actual_start_date.date()} with the current quality filters.\"); return\n",
    "#         df_close_step = df_close_full[eligible_tickers]; df_high_step = df_high_full[eligible_tickers]; df_low_step = df_low_full[eligible_tickers]\n",
    "#         results, debug_output = run_walk_forward_step(df_close_full, df_high_full, df_low_full, master_trading_days, actual_start_date, calc_period, fwd_period, metric, rank_start, rank_end, benchmark_ticker, features_df=features_df, debug=debug)\n",
    "#         if results.get('error'):\n",
    "#             with ticker_list_output: print(f\"Error: {results['error']}\"); return\n",
    "#         period_dates = {'calc_period_start': results['safe_start_date'], 'calc_period_end': results['actual_calc_end_ts'], 'forward_period_start': results['actual_calc_end_ts'], 'forward_period_end': results['safe_viz_end_date']}\n",
    "#         run_parameters = {'calc_period': calc_period, 'fwd_period': fwd_period, 'rank_metric': metric, 'rank_start': rank_start, 'rank_end': rank_end, 'benchmark_ticker': benchmark_ticker}\n",
    "#         results.update(period_dates); results.update(run_parameters)\n",
    "#         if debug_output is not None and isinstance(debug_output, dict):\n",
    "#             debug_output.update(period_dates); debug_output.update(run_parameters)\n",
    "#         with fig.batch_update():\n",
    "#             for i in range(max_traces):\n",
    "#                 trace = fig.data[i]\n",
    "#                 if i < len(results['tickers_to_display']):\n",
    "#                     ticker = results['tickers_to_display'][i]; plot_data_series = results['normalized_plot_data'][ticker]\n",
    "#                     trace.x, trace.y, trace.name, trace.visible, trace.showlegend = plot_data_series.index, plot_data_series.values, ticker, True, True\n",
    "#                 else: trace.visible, trace.showlegend = False, False\n",
    "#             benchmark_trace = fig.data[max_traces]\n",
    "#             if results['benchmark_price_series'] is not None and not results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']].dropna().empty:\n",
    "#                 normalized_benchmark = results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']] / results['benchmark_price_series'].loc[results['safe_start_date']:].bfill().iloc[0]\n",
    "#                 benchmark_trace.x, benchmark_trace.y, benchmark_trace.name, benchmark_trace.visible = normalized_benchmark.index, normalized_benchmark.values, f\"Benchmark ({benchmark_ticker})\", True\n",
    "#             else: benchmark_trace.visible = False\n",
    "#             portfolio_trace = fig.data[max_traces + 1]\n",
    "#             portfolio_trace.x, portfolio_trace.y, portfolio_trace.name, portfolio_trace.visible = results['portfolio_series'].index, results['portfolio_series'], 'Group Portfolio', True\n",
    "#             fig.layout.shapes = []; fig.add_shape(type=\"line\", x0=results['actual_calc_end_ts'], y0=0, x1=results['actual_calc_end_ts'], y1=1, xref='x', yref='paper', line=dict(color=\"grey\", width=2, dash=\"dash\"))\n",
    "#         results_container[0] = results; debug_data_container[0] = debug_output\n",
    "#         with ticker_list_output:\n",
    "#             print(f\"Analysis Period: {results['safe_start_date'].date()} to {results['safe_viz_end_date'].date()}.\")\n",
    "#             pprint.pprint(results['tickers_to_display'])\n",
    "#             p = results['performance_data']\n",
    "            \n",
    "#             # --- START OF MODIFIED BLOCK ---\n",
    "#             rows = []\n",
    "#             # Gain Metrics\n",
    "#             rows.append({'Metric': 'Group Portfolio Gain', 'Full': p['full_p_gain'], 'Calc': p['calc_p_gain'], 'Fwd': p['fwd_p_gain']})\n",
    "#             if not np.isnan(p.get('full_b_gain')):\n",
    "#                 rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Gain', 'Full': p['full_b_gain'], 'Calc': p['calc_b_gain'], 'Fwd': p['fwd_b_gain']})\n",
    "#                 rows.append({'Metric': '== Gain Delta (vs Bm)', 'Full': p['full_p_gain'] - p['full_b_gain'], 'Calc': p['calc_p_gain'] - p['calc_b_gain'], 'Fwd': p['fwd_p_gain'] - p['fwd_b_gain']})\n",
    "            \n",
    "#             # Standard Sharpe Metrics\n",
    "#             rows.append({'Metric': 'Group Portfolio Sharpe', 'Full': p['full_p_sharpe'], 'Calc': p['calc_p_sharpe'], 'Fwd': p['fwd_p_sharpe']})\n",
    "#             if not np.isnan(p.get('full_b_sharpe')):\n",
    "#                 rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Sharpe', 'Full': p['full_b_sharpe'], 'Calc': p['calc_b_sharpe'], 'Fwd': p['fwd_b_sharpe']})\n",
    "#                 rows.append({'Metric': '== Sharpe Delta (vs Bm)', 'Full': p['full_p_sharpe'] - p['full_b_sharpe'], 'Calc': p['calc_p_sharpe'] - p['calc_b_sharpe'], 'Fwd': p['fwd_p_sharpe'] - p['fwd_b_sharpe']})\n",
    "\n",
    "#             # Sharpe (ATR) Metrics\n",
    "#             rows.append({'Metric': 'Group Portfolio Sharpe (ATR)', 'Full': p['full_p_sharpe_atr'], 'Calc': p['calc_p_sharpe_atr'], 'Fwd': p['fwd_p_sharpe_atr']})\n",
    "#             if not np.isnan(p.get('full_b_sharpe_atr')):\n",
    "#                 rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Sharpe (ATR)', 'Full': p['full_b_sharpe_atr'], 'Calc': p['calc_b_sharpe_atr'], 'Fwd': p['fwd_b_sharpe_atr']})\n",
    "#                 rows.append({'Metric': '== Sharpe (ATR) Delta (vs Bm)', 'Full': p['full_p_sharpe_atr'] - p['full_b_sharpe_atr'], 'Calc': p['calc_p_sharpe_atr'] - p['calc_b_sharpe_atr'], 'Fwd': p['fwd_p_sharpe_atr'] - p['fwd_b_sharpe_atr']})\n",
    "\n",
    "#             report_df = pd.DataFrame(rows).set_index('Metric')\n",
    "#             gain_rows = [row for row in report_df.index if 'Gain' in row]\n",
    "#             sharpe_rows = [row for row in report_df.index if 'Sharpe' in row] # This now correctly includes both types of Sharpe\n",
    "#             # --- END OF MODIFIED BLOCK ---\n",
    "            \n",
    "#             styled_df = report_df.style.format('{:+.2%}', na_rep='N/A', subset=(gain_rows, report_df.columns)).format('{:+.4f}', na_rep='N/A', subset=(sharpe_rows, report_df.columns)).set_properties(**{'text-align': 'right', 'width': '100px'}).set_table_styles([{'selector': 'th.col_heading', 'props': [('text-align', 'right')]}, {'selector': 'th.row_heading', 'props': [('text-align', 'left')]}])\n",
    "#             print(\"\\n--- Strategy Performance Summary ---\")\n",
    "#             display(styled_df)\n",
    "#     fig.update_layout(title_text='Walk-Forward Performance Analysis', xaxis_title='Date', yaxis_title='Normalized Price (Start = 1)', hovermode='x unified', legend_title_text='Tickers (Ranked)', height=600, margin=dict(t=50))\n",
    "#     fig.add_hline(y=1, line_width=1, line_dash=\"dash\", line_color=\"grey\")\n",
    "#     update_button.on_click(update_plot)\n",
    "#     controls_row1 = widgets.HBox([start_date_picker, calc_period_input, fwd_period_input])\n",
    "#     controls_row2 = widgets.HBox([metric_dropdown, rank_start_input, rank_end_input, benchmark_ticker_input, update_button])\n",
    "#     ui_container = widgets.VBox([controls_row1, controls_row2, ticker_list_output], layout=widgets.Layout(margin='10px 0 20px 0'))\n",
    "#     display(ui_container, fig)\n",
    "#     update_plot(None)\n",
    "#     return (results_container, debug_data_container)\n",
    "\n",
    "# def run_full_backtest(df_ohlcv, strategy_params, quality_thresholds):\n",
    "#     \"\"\"Runs a full backtest of a strategy over a specified date range.\"\"\"\n",
    "#     print(f\"--- Running Full Forensic Backtest for Strategy: {strategy_params['metric']} (Top {strategy_params['rank_start']}-{strategy_params['rank_end']}) ---\")\n",
    "    \n",
    "#     # (No changes to the initial setup part...)\n",
    "#     start_date, end_date = pd.to_datetime(strategy_params['start_date']), pd.to_datetime(strategy_params['end_date'])\n",
    "#     calc_period, fwd_period = strategy_params['calc_period'], strategy_params['fwd_period']\n",
    "#     metric, rank_start, rank_end = strategy_params['metric'], strategy_params['rank_start'], strategy_params['rank_end']\n",
    "#     benchmark_ticker = strategy_params['benchmark_ticker']\n",
    "#     master_calendar_ticker = strategy_params.get('master_calendar_ticker', 'VOO')\n",
    "#     if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "#         raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "#     master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "#     start_idx = master_trading_days.searchsorted(start_date)\n",
    "#     end_idx = master_trading_days.searchsorted(end_date, side='right')\n",
    "#     print(\"--- Generating all features upfront... ---\")\n",
    "#     features_df = generate_features(df_ohlcv)\n",
    "#     df_close_full = df_ohlcv['Adj Close'].unstack(level=0); df_high_full = df_ohlcv['Adj High'].unstack(level=0); df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    \n",
    "#     # Loop through all periods in the backtest range\n",
    "#     step_indices = range(start_idx, end_idx, fwd_period)\n",
    "#     all_fwd_gains, period_by_period_debug = [], {}\n",
    "\n",
    "#     print(f\"Simulating {len(step_indices)} periods from {master_trading_days[step_indices[0]].date()} to {master_trading_days[step_indices[-1]].date()}...\")\n",
    "#     for current_idx in tqdm(step_indices, desc=\"Backtest Progress\"):\n",
    "#         step_date = master_trading_days[current_idx]\n",
    "#         eligible_tickers = get_eligible_universe(features_df, step_date, quality_thresholds)\n",
    "#         if not eligible_tickers: continue\n",
    "#         df_close_step = df_close_full[eligible_tickers]; df_high_step = df_high_full[eligible_tickers]; df_low_step = df_low_full[eligible_tickers]\n",
    "        \n",
    "#         # +++ UPDATE THE CALL HERE +++\n",
    "#         results, debug_output = run_walk_forward_step(\n",
    "#             df_close_step, df_high_step, df_low_step, master_trading_days,\n",
    "#             step_date, calc_period, fwd_period,\n",
    "#             metric, rank_start, rank_end, benchmark_ticker,\n",
    "#             features_df=features_df,  # Pass the features_df\n",
    "#             debug=True\n",
    "#         )\n",
    "        \n",
    "#         # (The rest of the function remains unchanged...)\n",
    "#         if results['error'] is None:\n",
    "#             fwd_series = results['portfolio_series'].loc[results['actual_calc_end_ts']:]\n",
    "#             all_fwd_gains.append(fwd_series.pct_change().dropna())\n",
    "#             period_by_period_debug[step_date.date().isoformat()] = debug_output\n",
    "            \n",
    "#     if not all_fwd_gains:\n",
    "#         print(\"Error: No valid periods were simulated.\"); return None\n",
    "\n",
    "#     strategy_returns = pd.concat(all_fwd_gains); strategy_equity_curve = (1 + strategy_returns).cumprod()\n",
    "#     benchmark_returns = df_close_full[benchmark_ticker].pct_change().loc[strategy_equity_curve.index]; benchmark_equity_curve = (1 + benchmark_returns).cumprod()\n",
    "#     cumulative_equity_df = pd.DataFrame({'Strategy_Equity': strategy_equity_curve, 'Benchmark_Equity': benchmark_equity_curve})\n",
    "#     fig = go.Figure()\n",
    "#     fig.add_trace(go.Scatter(x=cumulative_equity_df.index, y=cumulative_equity_df['Strategy_Equity'], name='Strategy', line=dict(color='green')))\n",
    "#     fig.add_trace(go.Scatter(x=cumulative_equity_df.index, y=cumulative_equity_df['Benchmark_Equity'], name=f'Benchmark ({benchmark_ticker})', line=dict(color='black', dash='dash')))\n",
    "#     fig.update_layout(title=f\"Cumulative Performance: '{metric}' Strategy (Top {rank_start}-{rank_end})\", xaxis_title=\"Date\", yaxis_title=\"Cumulative Growth\")\n",
    "#     fig.show()\n",
    "#     final_backtest_results = {'cumulative_performance': cumulative_equity_df, 'period_by_period_debug': period_by_period_debug}\n",
    "#     print(\"\\n✅ Full backtest complete. Results object is ready for forensic analysis.\")\n",
    "#     return final_backtest_results\n",
    "\n",
    "# # --- E. VERIFICATION TOOLS (User Requested) ---\n",
    "\n",
    "# def verify_group_tickers_walk_forward_calculation(df_ohlcv, tickers_to_verify, benchmark_ticker,\n",
    "#                                                   start_date, calc_period, fwd_period,\n",
    "#                                                   master_calendar_ticker='VOO', export_csv=False):\n",
    "#     \"\"\"Verifies portfolio and benchmark performance and optionally exports the data.\"\"\"\n",
    "#     display(Markdown(f\"## Verification Report for Portfolio vs. Benchmark\"))\n",
    "#     display(Markdown(f\"**Portfolio Tickers:** `{tickers_to_verify}`\\n**Benchmark Ticker:** `{benchmark_ticker}`\"))\n",
    "    \n",
    "#     # 1. Setup trading day calendar and determine exact period dates\n",
    "#     if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "#         raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "#     master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "\n",
    "#     start_date_raw = pd.to_datetime(start_date)\n",
    "#     start_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "#     if start_idx >= len(master_trading_days):\n",
    "#         print(f\"Error: Start date {start_date_raw.date()} is after the last available trading day.\"); return\n",
    "#     actual_start_date = master_trading_days[start_idx]\n",
    "    \n",
    "#     calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "#     fwd_end_idx = min(calc_end_idx + fwd_period, len(master_trading_days) - 1)\n",
    "    \n",
    "#     actual_calc_end_date = master_trading_days[calc_end_idx]\n",
    "#     actual_fwd_end_date = master_trading_days[fwd_end_idx]\n",
    "    \n",
    "#     display(Markdown(f\"**Analysis Start:** `{actual_start_date.date()}` (Selected: `{start_date_raw.date()}`)\\n\"\n",
    "#                     f\"**Calc End:** `{actual_calc_end_date.date()}` ({calc_period} trading days)\\n\"\n",
    "#                     f\"**Fwd End:** `{actual_fwd_end_date.date()}` ({fwd_period} trading days)\"))\n",
    "\n",
    "#     # 2. Recreate the portfolio and benchmark series from scratch\n",
    "#     df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "#     portfolio_prices_raw_slice = df_close_full[tickers_to_verify].loc[actual_start_date:actual_fwd_end_date]\n",
    "#     portfolio_value_series = portfolio_prices_raw_slice.div(portfolio_prices_raw_slice.bfill().iloc[0]).mean(axis=1)\n",
    "#     benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "    \n",
    "#     # 3. Optionally export the underlying daily data to a CSV for external checking\n",
    "#     if export_csv:\n",
    "#         export_df = pd.DataFrame({\n",
    "#             'Portfolio_Normalized_Price': portfolio_value_series,\n",
    "#             'Portfolio_Daily_Return': portfolio_value_series.pct_change()\n",
    "#         })\n",
    "#         if benchmark_price_series is not None:\n",
    "#             norm_bm = benchmark_price_series.loc[actual_start_date:actual_fwd_end_date]\n",
    "#             norm_bm = norm_bm / norm_bm.bfill().iloc[0]\n",
    "#             export_df['Benchmark_Normalized_Price'] = norm_bm\n",
    "#             export_df['Benchmark_Daily_Return'] = norm_bm.pct_change()\n",
    "\n",
    "#         output_dir = 'export_csv'\n",
    "#         os.makedirs(output_dir, exist_ok=True)\n",
    "#         tickers_str = '_'.join(tickers_to_verify)\n",
    "#         filename = f\"verify_group_{actual_start_date.date()}_{tickers_str}.csv\"\n",
    "#         filepath = os.path.join(output_dir, filename)\n",
    "#         export_df.to_csv(filepath)\n",
    "#         print(f\"\\n✅ Data exported to: {filepath}\")\n",
    "\n",
    "#     # 4. Define a helper to print detailed calculation steps\n",
    "#     def print_verification_steps(title, price_series):\n",
    "#         display(Markdown(f\"#### Verification for: `{title}`\"))\n",
    "#         if price_series.dropna().shape[0] < 2: print(\"  - Not enough data points.\"); return {'gain': np.nan, 'sharpe': np.nan}\n",
    "#         start_price, end_price = price_series.bfill().iloc[0], price_series.ffill().iloc[-1]\n",
    "#         gain = (end_price / start_price) - 1\n",
    "#         print(f\"Start Value ({price_series.first_valid_index().date()}): {start_price:,.4f}\\nEnd Value   ({price_series.last_valid_index().date()}): {end_price:,.4f}\\nGain = {gain:.2%}\")\n",
    "#         returns = price_series.pct_change()\n",
    "#         sharpe = calculate_sharpe(returns)\n",
    "#         print(f\"Mean Daily Return: {returns.mean():.6f}\\nStd Dev: {returns.std():.6f}\\nSharpe = {sharpe:.2f}\")\n",
    "#         return {'gain': gain, 'sharpe': sharpe}\n",
    "\n",
    "#     # 5. Run verification for each period\n",
    "#     display(Markdown(\"### A. Calculation Period\"))\n",
    "#     perf_calc_p = print_verification_steps(\"Group Portfolio\", portfolio_value_series.loc[actual_start_date:actual_calc_end_date])\n",
    "#     if benchmark_price_series is not None:\n",
    "#         perf_calc_b = print_verification_steps(f\"Benchmark\", benchmark_price_series.loc[actual_start_date:actual_calc_end_date])\n",
    "    \n",
    "#     display(Markdown(\"### B. Forward Period\"))\n",
    "#     perf_fwd_p = print_verification_steps(\"Group Portfolio\", portfolio_value_series.loc[actual_calc_end_date:actual_fwd_end_date])\n",
    "#     if benchmark_price_series is not None:\n",
    "#         perf_fwd_b = print_verification_steps(f\"Benchmark\", benchmark_price_series.loc[actual_calc_end_date:actual_fwd_end_date])\n",
    "\n",
    "# def verify_ticker_ranking_metrics(df_ohlcv, ticker, start_date, calc_period,\n",
    "#                                   master_calendar_ticker='VOO', export_csv=False):\n",
    "#     \"\"\"Verifies ranking metrics for a single ticker and optionally exports the data.\"\"\"\n",
    "#     display(Markdown(f\"## Verification Report for Ticker Ranking: `{ticker}`\"))\n",
    "    \n",
    "#     # 1. Setup trading day calendar and determine exact period dates\n",
    "#     if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "#         raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "#     master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "\n",
    "#     start_date_raw = pd.to_datetime(start_date)\n",
    "#     start_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "#     if start_idx >= len(master_trading_days):\n",
    "#         print(f\"Error: Start date {start_date_raw.date()} is after the last available trading day.\"); return\n",
    "#     actual_start_date = master_trading_days[start_idx]\n",
    "    \n",
    "#     calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "#     actual_calc_end_date = master_trading_days[calc_end_idx]\n",
    "\n",
    "#     # 2. Extract and prepare the raw data for the specific ticker and period\n",
    "#     df_ticker = df_ohlcv.loc[ticker].sort_index()\n",
    "#     calc_df = df_ticker.loc[actual_start_date:actual_calc_end_date].copy()\n",
    "#     if calc_df.empty or len(calc_df) < 2: \n",
    "#         print(\"No data or not enough data in calc period.\"); return\n",
    "\n",
    "#     display(Markdown(\"### A. Calculation Period (for Ranking Metrics)\"))\n",
    "#     display(Markdown(f\"**Period Start:** `{actual_start_date.date()}`\\n\"\n",
    "#                     f\"**Period End:** `{actual_calc_end_date.date()}`\\n\"\n",
    "#                     f\"**Total Trading Days:** `{len(calc_df)}` (Requested: `{calc_period}`)\"))\n",
    "    \n",
    "#     display(Markdown(\"#### Detailed Metric Calculation Data\"))\n",
    "    \n",
    "#     # 3. Calculate all intermediate metrics as new columns for full transparency\n",
    "#     vdf = calc_df[['Adj High', 'Adj Low', 'Adj Close']].copy()\n",
    "#     vdf['Daily_Return'] = vdf['Adj Close'].pct_change()\n",
    "    \n",
    "#     # Corrected True Range (TR) calculation for a single ticker (Series)\n",
    "#     tr_df = pd.DataFrame({\n",
    "#         'h_l': vdf['Adj High'] - vdf['Adj Low'],\n",
    "#         'h_cp': abs(vdf['Adj High'] - vdf['Adj Close'].shift(1)),\n",
    "#         'l_cp': abs(vdf['Adj Low'] - vdf['Adj Close'].shift(1))\n",
    "#     })\n",
    "#     vdf['TR'] = tr_df.max(axis=1)\n",
    "    \n",
    "#     vdf['ATR_14'] = vdf['TR'].ewm(alpha=1/14, adjust=False).mean()\n",
    "#     vdf['ATRP'] = vdf['ATR_14'] / vdf['Adj Close']\n",
    "    \n",
    "#     print(\"--- Start of Calculation Period ---\")\n",
    "#     display(vdf.head())\n",
    "#     print(\"\\n--- End of Calculation Period ---\")\n",
    "#     display(vdf.tail())\n",
    "\n",
    "#     # 4. Optionally export this detailed breakdown to CSV\n",
    "#     if export_csv:\n",
    "#         output_dir = 'export_csv'\n",
    "#         os.makedirs(output_dir, exist_ok=True)\n",
    "#         filename = f\"verify_ticker_{actual_start_date.date()}_{ticker}.csv\"\n",
    "#         filepath = os.path.join(output_dir, filename)\n",
    "#         vdf.to_csv(filepath)\n",
    "#         print(f\"\\n✅ Data exported to: {filepath}\")\n",
    "    \n",
    "#     # 5. Print final metric calculations with formulas\n",
    "#     display(Markdown(\"#### `MetricValue` Verification Summary:\"))\n",
    "    \n",
    "#     calc_start_price = vdf['Adj Close'].bfill().iloc[0]\n",
    "#     calc_end_price = vdf['Adj Close'].ffill().iloc[-1]\n",
    "#     price_metric = (calc_end_price / calc_start_price)\n",
    "#     print(f\"1. Price Metric: (Last Price / First Price) = ({calc_end_price:.2f} / {calc_start_price:.2f}) = {price_metric:.4f}\")\n",
    "    \n",
    "#     daily_returns = vdf['Daily_Return'].dropna()\n",
    "#     sharpe_ratio = calculate_sharpe(daily_returns)\n",
    "#     print(f\"2. Sharpe Metric: (Mean Daily Return / Std Dev) * sqrt(252) = {sharpe_ratio:.4f}\")\n",
    "\n",
    "#     atrp_mean = vdf['ATRP'].mean()\n",
    "#     mean_daily_return = vdf['Daily_Return'].mean()\n",
    "#     sharpe_atr = (mean_daily_return / atrp_mean) if atrp_mean > 0 else 0\n",
    "#     print(f\"3. Sharpe (ATR) Metric: (Mean Daily Return / Mean ATRP) = ({mean_daily_return:.6f} / {atrp_mean:.6f}) = {sharpe_atr:.4f}\")\n",
    "\n",
    "\n",
    "# def verify_sharpe_atr_calculation_checked(df_ohlcv, features_df, tickers_to_verify, benchmark_ticker,\n",
    "#                                     start_date, calc_period, fwd_period,\n",
    "#                                     master_calendar_ticker='VOO', debug=False):\n",
    "#     \"\"\"\n",
    "#     Verifies the Sharpe (ATR) calculations for a portfolio and benchmark.\n",
    "\n",
    "#     This function transparently recalculates the key components for Sharpe (ATR)\n",
    "#     and can optionally export the underlying source data for manual inspection.\n",
    "#     \"\"\"\n",
    "#     display(Markdown(f\"## Verification Report for Sharpe (ATR) Calculation\"))\n",
    "#     display(Markdown(f\"**Portfolio Tickers:** `{tickers_to_verify}`\\n**Benchmark Ticker:** `{benchmark_ticker}`\"))\n",
    "\n",
    "#     # --- 1. Determine Exact Period Dates (No changes here) ---\n",
    "#     master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "#     start_date_raw = pd.to_datetime(start_date)\n",
    "#     start_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "#     actual_start_date = master_trading_days[start_idx]\n",
    "#     calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "#     fwd_end_idx = min(calc_end_idx + fwd_period, len(master_trading_days) - 1)\n",
    "#     actual_calc_end_date = master_trading_days[calc_end_idx]\n",
    "#     actual_fwd_end_date = master_trading_days[fwd_end_idx]\n",
    "    \n",
    "#     display(Markdown(f\"**Full Period:** `{actual_start_date.date()}` to `{actual_fwd_end_date.date()}`\\n\"\n",
    "#                     f\"**Calc End Date:** `{actual_calc_end_date.date()}`\"))\n",
    "\n",
    "#     # Original debug export block (can be kept or removed)\n",
    "#     if debug:\n",
    "#         # ... (original export code remains here) ...\n",
    "#         pass # Assuming original block is here\n",
    "\n",
    "#     # --- 2. Recreate Portfolio & Benchmark Series from Scratch ---\n",
    "#     df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "#     portfolio_prices_raw = df_close_full[tickers_to_verify].loc[actual_start_date:actual_fwd_end_date]\n",
    "#     portfolio_prices_norm = portfolio_prices_raw.div(portfolio_prices_raw.bfill().iloc[0])\n",
    "#     portfolio_value_series = portfolio_prices_norm.mean(axis=1)\n",
    "#     portfolio_return_series = portfolio_value_series.pct_change()\n",
    "#     p_idx = pd.MultiIndex.from_product([tickers_to_verify, portfolio_return_series.index])\n",
    "#     p_atrp_df = features_df.loc[features_df.index.intersection(p_idx)]['ATRP'].unstack(level=0)\n",
    "#     portfolio_atrp_series = p_atrp_df.mean(axis=1)\n",
    "\n",
    "# ###############################    \n",
    "#     # benchmark_return_series = df_close_full[benchmark_ticker].pct_change().loc[actual_start_date:actual_fwd_end_date]\n",
    "\n",
    "#     # 1. First, slice the raw prices for the desired date range.\n",
    "#     benchmark_prices_raw = df_close_full[benchmark_ticker].loc[actual_start_date:actual_fwd_end_date]\n",
    "#     # 2. Then, calculate the percentage change on the sliced data.\n",
    "#     benchmark_return_series = benchmark_prices_raw.pct_change()\n",
    "\n",
    "# ###############################    \n",
    "#     benchmark_atrp_series = features_df.xs(benchmark_ticker, level='Ticker')['ATRP'].loc[actual_start_date:actual_fwd_end_date]\n",
    "\n",
    "\n",
    "#     # +++ NEW: DETAILED RETURN CALCULATION TRACE (PORTFOLIO) +++\n",
    "#     if debug:\n",
    "#         display(Markdown(\"---\"))\n",
    "#         display(Markdown(\"### 🐛 Detailed Portfolio Return Calculation Trace\"))\n",
    "\n",
    "#         # Step 1: Show the raw prices being used\n",
    "#         print(\"\\n[STEP 1] Raw Adjusted Close prices used for calculation.\")\n",
    "#         print(\"Compare these values with your 'Adj Close' columns.\")\n",
    "#         display(portfolio_prices_raw)\n",
    "\n",
    "#         # Step 2: Show the normalization base and the result\n",
    "#         normalization_base = portfolio_prices_raw.bfill().iloc[0]\n",
    "#         print(\"\\n[STEP 2] Normalization base (first row of prices).\")\n",
    "#         print(\"Each column in Step 1 is divided by this corresponding value.\")\n",
    "#         display(pd.DataFrame(normalization_base).T)\n",
    "\n",
    "#         print(\"\\n[STEP 2a] Normalized prices (Result of division).\")\n",
    "#         print(\"Compare these values with your 'N Close' columns.\")\n",
    "#         display(portfolio_prices_norm)\n",
    "\n",
    "#         # Step 3: Show the averaged portfolio value series\n",
    "#         print(\"\\n[STEP 3] Averaged normalized portfolio value series.\")\n",
    "#         print(\"This is the row-by-row average of the table in Step 2a.\")\n",
    "#         print(\"Compare this series with your 'N_portf' column.\")\n",
    "#         display(pd.DataFrame(portfolio_value_series, columns=['N_portf']))\n",
    "\n",
    "#         # Step 4: Show the final portfolio return series\n",
    "#         print(\"\\n[STEP 4] Final portfolio daily return series (pct_change).\")\n",
    "#         print(\"This is the percentage change of the series in Step 3.\")\n",
    "#         print(\"Compare this series with your 'N_portf_rtn' column.\")\n",
    "#         display(pd.DataFrame(portfolio_return_series, columns=['N_portf_rtn']))\n",
    "#         display(Markdown(\"---\"))\n",
    "#     # +++ END OF NEW DEBUG BLOCK +++\n",
    "\n",
    "\n",
    "#     # --- 3. Define a Helper to Print Detailed Calculation Steps ---\n",
    "#     # MODIFIED to include more debug details inside\n",
    "#     def _calculate_and_print_metrics(period_name, returns, atrps):\n",
    "#         display(Markdown(f\"#### {period_name}\"))\n",
    "#         if returns.dropna().empty or atrps.dropna().empty:\n",
    "#             print(\"  - Not enough data to calculate.\")\n",
    "#             return np.nan\n",
    "\n",
    "#         # Standard calculations\n",
    "#         mean_return = returns.mean()\n",
    "#         mean_atrp = atrps.mean()\n",
    "#         sharpe_atr = mean_return / mean_atrp if mean_atrp > 0 else np.nan\n",
    "\n",
    "#         # +++ ADDED: Detailed Mean Calculation Breakdown +++\n",
    "#         if debug:\n",
    "#             valid_returns = returns.dropna()\n",
    "#             num_returns = valid_returns.count()\n",
    "#             sum_returns = valid_returns.sum()\n",
    "#             manual_mean = sum_returns / num_returns if num_returns > 0 else 0\n",
    "#             print(f\"  - (Debug) Number of valid daily returns: {num_returns}\")\n",
    "#             print(f\"  - (Debug) Sum of all daily returns:      {sum_returns:,.8f}\")\n",
    "#             print(f\"  - (Debug) Manually calculated mean:      {manual_mean:,.8f} (Sum / Count)\")\n",
    "#         # +++ END OF ADDED DETAIL +++\n",
    "\n",
    "#         print(f\"  - Mean Daily Return: {mean_return:,.6f}\")\n",
    "#         print(f\"  - Mean Daily ATRP:  {mean_atrp:,.6f}\")\n",
    "#         print(f\"  - Sharpe (ATR) = (Mean Return / Mean ATRP) = {sharpe_atr:,.4f}\")\n",
    "#         return sharpe_atr\n",
    "\n",
    "#     # --- 4. Run Verification for Portfolio (No changes here) ---\n",
    "#     display(Markdown(\"### A. Group Portfolio Verification\"))\n",
    "#     _calculate_and_print_metrics(\"Full Period\", portfolio_return_series, portfolio_atrp_series)\n",
    "#     _calculate_and_print_metrics(\"Calculation Period\", portfolio_return_series.loc[:actual_calc_end_date], portfolio_atrp_series.loc[:actual_calc_end_date])\n",
    "#     _calculate_and_print_metrics(\"Forward Period\", portfolio_return_series.loc[actual_calc_end_date:].iloc[1:], portfolio_atrp_series.loc[actual_calc_end_date:].iloc[1:])\n",
    "\n",
    "#     # --- 5. Run Verification for Benchmark (No changes here) ---\n",
    "#     display(Markdown(f\"### B. Benchmark ({benchmark_ticker}) Verification\"))\n",
    "#     _calculate_and_print_metrics(\"Full Period\", benchmark_return_series, benchmark_atrp_series)\n",
    "#     _calculate_and_print_metrics(\"Calculation Period\", benchmark_return_series.loc[:actual_calc_end_date], benchmark_atrp_series.loc[:actual_calc_end_date])\n",
    "#     _calculate_and_print_metrics(\"Forward Period\", benchmark_return_series.loc[actual_calc_end_date:].iloc[1:], benchmark_atrp_series.loc[actual_calc_end_date:].iloc[1:])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # --- F. AUTOMATION SCRIPT - STRATEGY SEARCH ---\n",
    "\n",
    "# def run_strategy_search(df_ohlcv, config):\n",
    "#     \"\"\"\n",
    "#     Runs the main backtesting loop with checkpointing to be resumable.\n",
    "#     \"\"\"\n",
    "#     start_time = time.time()\n",
    "    \n",
    "#     # --- 1. SETUP & LOAD PROGRESS ---\n",
    "#     print(\"--- Phase 1: Pre-processing and Loading Progress ---\")\n",
    "\n",
    "#     # +++ ADD THIS BLOCK +++\n",
    "#     # Pre-calculate all features for the entire dataset ONCE.\n",
    "#     print(\"--- Generating all features upfront... ---\")\n",
    "#     features_df = generate_features(df_ohlcv)\n",
    "\n",
    "#     # --- DELETE THIS LINE ---\n",
    "#     # quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "    \n",
    "#     print(\"Unstacking data for performance...\")\n",
    "#     df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "#     df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "#     df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    \n",
    "#     master_calendar_ticker = config['master_calendar_ticker']\n",
    "#     master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "#     print(f\"Master trading day calendar created from '{master_calendar_ticker}' ({len(master_trading_days)} days).\")\n",
    "\n",
    "#     results_path = config['results_output_path']\n",
    "#     completed_params = set()\n",
    "    \n",
    "#     if os.path.exists(results_path):\n",
    "#         print(f\"Found existing results file. Loading progress from: {results_path}\")\n",
    "#         df_progress = pd.read_csv(results_path)\n",
    "#         for _, row in df_progress.iterrows():\n",
    "#             param_key = (\n",
    "#                 row['calc_period'], row['fwd_period'], row['metric'],\n",
    "#                 (row['rank_start'], row['rank_end'])\n",
    "#             )\n",
    "#             completed_params.add(param_key)\n",
    "#         print(f\"Found {len(completed_params)} completed parameter sets to skip.\")\n",
    "#     else:\n",
    "#         print(\"No existing results file found. Starting a new run.\")\n",
    "\n",
    "#     print(\"✅ Pre-processing complete.\\n\")\n",
    "\n",
    "#     # --- 2. SETUP THE MAIN LOOP (No changes here) ---\n",
    "#     print(\"--- Phase 2: Setting up Simulation Loops ---\")\n",
    "#     param_combinations = list(product(\n",
    "#         config['calc_periods'], config['fwd_periods'],\n",
    "#         config['metrics'], config['rank_slices']\n",
    "#     ))\n",
    "#     search_start_date = pd.to_datetime(config['search_start_date'])\n",
    "#     search_end_date = pd.to_datetime(config['search_end_date'])\n",
    "#     start_idx = master_trading_days.searchsorted(search_start_date, side='left')\n",
    "#     end_idx = master_trading_days.searchsorted(search_end_date, side='right')\n",
    "#     step_dates_map = {}\n",
    "#     print(\"Pre-calculating rebalancing schedules for each holding period...\")\n",
    "#     for fwd_period in sorted(config['fwd_periods']):\n",
    "#         step_indices = range(start_idx, end_idx, fwd_period)\n",
    "#         step_dates_map[fwd_period] = master_trading_days[step_indices]\n",
    "#         print(f\"  - Holding Period {fwd_period} days: {len(step_dates_map[fwd_period])} rebalances\")\n",
    "#     print(f\"Found {len(param_combinations)} total parameter sets to simulate.\")\n",
    "#     print(\"✅ Setup complete. Starting main loop...\\n\")\n",
    "\n",
    "#     # --- 3. RUN THE MAIN LOOP ---\n",
    "#     print(\"--- Phase 3: Running Simulations ---\")\n",
    "#     pbar = tqdm(param_combinations, desc=\"Parameter Sets\")\n",
    "    \n",
    "#     for params in pbar:\n",
    "#         calc_period, fwd_period, metric, rank_slice = params\n",
    "#         rank_start, rank_end = rank_slice\n",
    "        \n",
    "#         param_key = (calc_period, fwd_period, metric, rank_slice)\n",
    "#         if param_key in completed_params:\n",
    "#             pbar.set_description(f\"Skipping {param_key}\")\n",
    "#             continue\n",
    "\n",
    "#         pbar.set_description(f\"Running {param_key}\")\n",
    "        \n",
    "#         current_params_results = []\n",
    "        \n",
    "#         current_step_dates = step_dates_map[fwd_period]\n",
    "#         for step_date in current_step_dates:\n",
    "#             # +++ UPDATE THIS CALL +++\n",
    "#             eligible_tickers = get_eligible_universe(\n",
    "#                 features_df, filter_date=step_date, thresholds=config['quality_thresholds']\n",
    "#             )\n",
    "#             if not eligible_tickers: continue\n",
    "            \n",
    "#             df_close_step = df_close_full[eligible_tickers]\n",
    "#             df_high_step = df_high_full[eligible_tickers]\n",
    "#             df_low_step = df_low_full[eligible_tickers]\n",
    "\n",
    "#             # +++ UPDATE THIS CALL +++\n",
    "#             step_result, _ = run_walk_forward_step(\n",
    "#                 df_close_full=df_close_step, df_high_full=df_high_step, df_low_full=df_low_step,\n",
    "#                 master_trading_days=master_trading_days, start_date=step_date,\n",
    "#                 calc_period=calc_period, fwd_period=fwd_period,\n",
    "#                 metric=metric, rank_start=rank_start, rank_end=rank_end,\n",
    "#                 benchmark_ticker=config['benchmark_ticker'],\n",
    "#                 features_df=features_df, # Pass the features_df\n",
    "#                 debug=False\n",
    "#             )\n",
    "            \n",
    "#             if step_result['error'] is None:\n",
    "#                 p = step_result['performance_data']\n",
    "#                 log_entry = {\n",
    "#                     'step_date': step_date.date(), 'calc_period': calc_period,\n",
    "#                     'fwd_period': fwd_period, 'metric': metric,\n",
    "#                     'rank_start': rank_start, 'rank_end': rank_end,\n",
    "#                     'num_universe': len(eligible_tickers),\n",
    "#                     'num_portfolio': len(step_result['tickers_to_display']),\n",
    "#                     'fwd_p_gain': p['fwd_p_gain'], 'fwd_b_gain': p['fwd_b_gain'],\n",
    "#                     'fwd_gain_delta': p['fwd_p_gain'] - p['fwd_b_gain'] if not np.isnan(p['fwd_b_gain']) else np.nan,\n",
    "#                     'fwd_p_sharpe': p['fwd_p_sharpe'],\n",
    "#                 }\n",
    "#                 current_params_results.append(log_entry)\n",
    "        \n",
    "#         # --- CHECKPOINTING (No changes here) ---\n",
    "#         if current_params_results:\n",
    "#             df_to_append = pd.DataFrame(current_params_results)\n",
    "#             df_to_append.to_csv(\n",
    "#                 results_path,\n",
    "#                 mode='a',\n",
    "#                 header=not os.path.exists(results_path),\n",
    "#                 index=False\n",
    "#             )\n",
    "#             completed_params.add(param_key)\n",
    "\n",
    "#     print(\"✅ Main loop finished.\\n\")\n",
    "    \n",
    "#     # --- 4. RETURN FINAL DATAFRAME (No changes here) ---\n",
    "#     print(\"--- Phase 4: Loading Final Results ---\")\n",
    "#     if os.path.exists(results_path):\n",
    "#         final_df = pd.read_csv(results_path)\n",
    "#         end_time = time.time()\n",
    "#         print(f\"✅ Process complete. Total execution time: {time.time() - start_time:.2f} seconds.\")\n",
    "#         return final_df\n",
    "#     else:\n",
    "#         print(\"Warning: No results were generated.\")\n",
    "#         return None    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072b3d79",
   "metadata": {},
   "source": [
    "# Below are only functions that required to run plot_walk_forward_analyzer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64cc5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets\n",
    "import pprint\n",
    "from IPython.display import display, Markdown\n",
    "import os # Make sure os is imported for the export function later\n",
    "\n",
    "\n",
    "def calculate_gain(price_series: pd.Series):\n",
    "    \"\"\"Calculates the total gain over a series of prices.\"\"\"\n",
    "    # Ensure there are at least two data points to calculate a gain\n",
    "    if price_series.dropna().shape[0] < 2: return np.nan\n",
    "    # Use forward-fill for the end price and back-fill for the start price\n",
    "    # to handle potential NaNs at the beginning or end of the series.\n",
    "    return (price_series.ffill().iloc[-1] / price_series.bfill().iloc[0]) - 1\n",
    "\n",
    "def calculate_sharpe(return_series: pd.Series):\n",
    "    \"\"\"Calculates the annualized Sharpe ratio from a series of daily returns.\"\"\"\n",
    "    # Ensure there are at least two returns to calculate a standard deviation\n",
    "    if return_series.dropna().shape[0] < 2: return np.nan\n",
    "    std_dev = return_series.std()\n",
    "    # Avoid division by zero if returns are constant\n",
    "    if std_dev > 0 and std_dev != np.inf:\n",
    "        return (return_series.mean() / std_dev) * np.sqrt(252)\n",
    "    return np.nan\n",
    "\n",
    "def calculate_sharpe_atr(return_series: pd.Series, atrp_series: pd.Series):\n",
    "    \"\"\"Calculates a Sharpe-like ratio using mean ATRP as the denominator.\"\"\"\n",
    "    # Ensure there are returns and that ATRP data is valid\n",
    "    if return_series.dropna().shape[0] < 2 or atrp_series.dropna().empty:\n",
    "        return np.nan\n",
    "        \n",
    "    mean_return = return_series.mean()\n",
    "    mean_atrp = atrp_series.mean()\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if mean_atrp > 0 and mean_atrp != np.inf:\n",
    "        return mean_return / mean_atrp\n",
    "        \n",
    "    return np.nan\n",
    "\n",
    "\n",
    "# --- B. MODULAR METRIC CALCULATION ENGINE ---\n",
    "\n",
    "def calculate_price_metric(metric_data: dict) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Calculates the 'Price' metric (total gain) over the calculation period.\n",
    "\n",
    "    Args:\n",
    "        metric_data: A dictionary containing pre-calculated data Series.\n",
    "                     Requires 'calc_close' (pd.DataFrame): The close prices for the calc period.\n",
    "\n",
    "    Returns:\n",
    "        A pandas Series of the calculated metric values, indexed by Ticker.\n",
    "    \"\"\"\n",
    "    calc_close = metric_data['calc_close']\n",
    "    \n",
    "    # Ensure there are at least two data points to calculate a gain\n",
    "    if len(calc_close) < 2:\n",
    "        return pd.Series(dtype='float64', index=calc_close.columns)\n",
    "\n",
    "    first_prices = calc_close.bfill().iloc[0]\n",
    "    last_prices = calc_close.ffill().iloc[-1]\n",
    "    \n",
    "    # The division of two Series aligns by index (Ticker), which is what we want.\n",
    "    price_metric = last_prices / first_prices\n",
    "    \n",
    "    return price_metric.dropna()\n",
    "\n",
    "def calculate_sharpe_metric(metric_data: dict) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Calculates the annualized 'Sharpe' ratio metric over the calculation period.\n",
    "\n",
    "    Args:\n",
    "        metric_data: A dictionary containing pre-calculated data Series.\n",
    "                     Requires 'daily_returns' (pd.DataFrame): Daily returns for the calc period.\n",
    "\n",
    "    Returns:\n",
    "        A pandas Series of the calculated metric values, indexed by Ticker.\n",
    "    \"\"\"\n",
    "    daily_returns = metric_data['daily_returns']\n",
    "    \n",
    "    # Ensure there's enough data to calculate standard deviation\n",
    "    if len(daily_returns.dropna()) < 2:\n",
    "        return pd.Series(dtype='float64', index=daily_returns.columns)\n",
    "    \n",
    "    mean_returns = daily_returns.mean()\n",
    "    std_returns = daily_returns.std()\n",
    "    \n",
    "    # Standard annualized Sharpe Ratio calculation. Avoid division by zero.\n",
    "    # We replace resulting NaNs/infs with 0 to handle cases of zero volatility.\n",
    "    sharpe_ratio = (mean_returns / std_returns * np.sqrt(252))\n",
    "    \n",
    "    return sharpe_ratio.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    \n",
    "def calculate_sharpe_atr_metric(metric_data: dict) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Calculates the 'Sharpe (ATR)' metric over the calculation period.\n",
    "\n",
    "    Args:\n",
    "        metric_data: A dictionary containing pre-calculated data Series.\n",
    "                     Requires 'daily_returns' (pd.DataFrame): Daily returns for the calc period.\n",
    "                     Requires 'atrp' (pd.Series): Mean ATRP for each ticker over the period.\n",
    "\n",
    "    Returns:\n",
    "        A pandas Series of the calculated metric values, indexed by Ticker.\n",
    "    \"\"\"\n",
    "    daily_returns = metric_data['daily_returns']\n",
    "    atrp = metric_data['atrp']\n",
    "    \n",
    "    mean_returns = daily_returns.mean()\n",
    "    \n",
    "    # ATRP-based Sharpe. Avoid division by zero.\n",
    "    # We replace resulting NaNs/infs with 0.\n",
    "    sharpe_atr = mean_returns / atrp\n",
    "    \n",
    "    return sharpe_atr.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "\n",
    "METRIC_REGISTRY = {\n",
    "    'Price': calculate_price_metric,\n",
    "    'Sharpe': calculate_sharpe_metric,\n",
    "    'Sharpe (ATR)': calculate_sharpe_atr_metric,\n",
    "}\n",
    "\n",
    "def plot_walk_forward_analyzer(df_ohlcv,\n",
    "                               default_start_date=None, default_calc_period=126, default_fwd_period=63,\n",
    "                               default_metric='Sharpe (ATR)', default_rank_start=1, default_rank_end=10,\n",
    "                               default_benchmark_ticker='VOO', master_calendar_ticker='VOO',\n",
    "                               quality_thresholds={'min_median_dollar_volume': 1_000_000, 'max_stale_pct': 0.05, 'max_same_vol_count': 10},\n",
    "                               debug=False):\n",
    "    # (No changes to the initial setup part of this function...)\n",
    "    print(\"Initializing Walk-Forward Analyzer (using Trading Day Logic)...\")\n",
    "    if not isinstance(df_ohlcv.index, pd.MultiIndex): raise ValueError(\"Input DataFrame must have a (Ticker, Date) MultiIndex.\")\n",
    "    df_ohlcv = df_ohlcv.sort_index()\n",
    "    if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "        raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "    master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "    print(f\"Master trading day calendar created from '{master_calendar_ticker}' ({len(master_trading_days)} days).\")\n",
    "    print(\"--- Generating all features upfront... ---\")\n",
    "    features_df = generate_features(df_ohlcv)\n",
    "    print(\"Pre-processing data (unstacking)...\")\n",
    "    df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "    df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "    df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    start_date_picker = widgets.DatePicker(description='Start Date:', value=pd.to_datetime(default_start_date), disabled=False)\n",
    "    calc_period_input = widgets.IntText(value=default_calc_period, description='Calc Period (days):')\n",
    "    fwd_period_input = widgets.IntText(value=default_fwd_period, description='Fwd Period (days):')\n",
    "    if default_metric not in METRIC_REGISTRY:\n",
    "        fallback_metric = list(METRIC_REGISTRY.keys())[0]\n",
    "        print(f\"⚠️ Warning: Default metric '{default_metric}' not in registry. Using '{fallback_metric}'.\")\n",
    "        default_metric = fallback_metric\n",
    "    metric_dropdown = widgets.Dropdown(options=list(METRIC_REGISTRY.keys()), value=default_metric, description='Metric:')\n",
    "    rank_start_input = widgets.IntText(value=default_rank_start, description='Rank Start:')\n",
    "    rank_end_input = widgets.IntText(value=default_rank_end, description='Rank End:')\n",
    "    benchmark_ticker_input = widgets.Text(value=default_benchmark_ticker, description='Benchmark:', placeholder='Enter Ticker')\n",
    "    update_button = widgets.Button(description=\"Update Chart\", button_style='primary')\n",
    "    ticker_list_output = widgets.Output()\n",
    "    results_container, debug_data_container = [None], [None]\n",
    "    fig = go.FigureWidget()\n",
    "    max_traces = 50\n",
    "    for i in range(max_traces): fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name=f'placeholder_{i}', visible=False, showlegend=False))\n",
    "    fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Benchmark', visible=True, showlegend=True, line=dict(color='black', width=3, dash='dash')))\n",
    "    fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Group Portfolio', visible=True, showlegend=True, line=dict(color='green', width=3)))\n",
    "\n",
    "    def update_plot(button_click):\n",
    "        ticker_list_output.clear_output()\n",
    "        start_date_raw = pd.to_datetime(start_date_picker.value)\n",
    "        start_date_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "        if start_date_idx >= len(master_trading_days):\n",
    "            with ticker_list_output: print(f\"Error: Start date is after the last available trading day.\"); return\n",
    "        actual_start_date = master_trading_days[start_date_idx]\n",
    "        with ticker_list_output:\n",
    "            if start_date_raw.date() != actual_start_date.date():\n",
    "                print(f\"ℹ️ Info: Start date {start_date_raw.date()} is not a trading day. Snapping forward to {actual_start_date.date()}.\")\n",
    "        calc_period = calc_period_input.value; fwd_period = fwd_period_input.value; metric = metric_dropdown.value\n",
    "        rank_start = rank_start_input.value; rank_end = rank_end_input.value; benchmark_ticker = benchmark_ticker_input.value.strip().upper()\n",
    "        if rank_start > rank_end:\n",
    "            with ticker_list_output: print(\"Error: 'Rank Start' must be <= 'Rank End'.\"); return\n",
    "        if rank_start < 1 or calc_period < 2 or fwd_period < 1:\n",
    "            with ticker_list_output: print(\"Error: Ranks must be >= 1, Calc Period >= 2, Fwd Period >= 1.\"); return\n",
    "        required_days = calc_period + fwd_period\n",
    "        if start_date_idx + required_days > len(master_trading_days):\n",
    "            available_days = len(master_trading_days) - start_date_idx; last_available_date = master_trading_days[-1].date()\n",
    "            with ticker_list_output:\n",
    "                print(f\"Error: Not enough data for the requested period.\\n  Start Date: {actual_start_date.date()}\\n  Required Days: {calc_period} (calc) + {fwd_period} (fwd) = {required_days}\\n  Available Days from Start: {available_days} (until {last_available_date})\\n  Please shorten the 'Calc Period' / 'Fwd Period' or choose an earlier 'Start Date'.\")\n",
    "            return\n",
    "        eligible_tickers = get_eligible_universe(features_df, actual_start_date, quality_thresholds)\n",
    "        if not eligible_tickers:\n",
    "            with ticker_list_output: print(f\"Error: No eligible tickers found on {actual_start_date.date()} with the current quality filters.\"); return\n",
    "        df_close_step = df_close_full[eligible_tickers]; df_high_step = df_high_full[eligible_tickers]; df_low_step = df_low_full[eligible_tickers]\n",
    "        results, debug_output = run_walk_forward_step(df_close_full, df_high_full, df_low_full, master_trading_days, actual_start_date, calc_period, fwd_period, metric, rank_start, rank_end, benchmark_ticker, features_df=features_df, debug=debug)\n",
    "        if results.get('error'):\n",
    "            with ticker_list_output: print(f\"Error: {results['error']}\"); return\n",
    "        period_dates = {'calc_period_start': results['safe_start_date'], 'calc_period_end': results['actual_calc_end_ts'], 'forward_period_start': results['actual_calc_end_ts'], 'forward_period_end': results['safe_viz_end_date']}\n",
    "        run_parameters = {'calc_period': calc_period, 'fwd_period': fwd_period, 'rank_metric': metric, 'rank_start': rank_start, 'rank_end': rank_end, 'benchmark_ticker': benchmark_ticker}\n",
    "        results.update(period_dates); results.update(run_parameters)\n",
    "        if debug_output is not None and isinstance(debug_output, dict):\n",
    "            debug_output.update(period_dates); debug_output.update(run_parameters)\n",
    "        with fig.batch_update():\n",
    "            for i in range(max_traces):\n",
    "                trace = fig.data[i]\n",
    "                if i < len(results['tickers_to_display']):\n",
    "                    ticker = results['tickers_to_display'][i]; plot_data_series = results['normalized_plot_data'][ticker]\n",
    "                    trace.x, trace.y, trace.name, trace.visible, trace.showlegend = plot_data_series.index, plot_data_series.values, ticker, True, True\n",
    "                else: trace.visible, trace.showlegend = False, False\n",
    "            benchmark_trace = fig.data[max_traces]\n",
    "            if results['benchmark_price_series'] is not None and not results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']].dropna().empty:\n",
    "                normalized_benchmark = results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']] / results['benchmark_price_series'].loc[results['safe_start_date']:].bfill().iloc[0]\n",
    "                benchmark_trace.x, benchmark_trace.y, benchmark_trace.name, benchmark_trace.visible = normalized_benchmark.index, normalized_benchmark.values, f\"Benchmark ({benchmark_ticker})\", True\n",
    "            else: benchmark_trace.visible = False\n",
    "            portfolio_trace = fig.data[max_traces + 1]\n",
    "            portfolio_trace.x, portfolio_trace.y, portfolio_trace.name, portfolio_trace.visible = results['portfolio_series'].index, results['portfolio_series'], 'Group Portfolio', True\n",
    "            fig.layout.shapes = []; fig.add_shape(type=\"line\", x0=results['actual_calc_end_ts'], y0=0, x1=results['actual_calc_end_ts'], y1=1, xref='x', yref='paper', line=dict(color=\"grey\", width=2, dash=\"dash\"))\n",
    "        results_container[0] = results; debug_data_container[0] = debug_output\n",
    "        with ticker_list_output:\n",
    "            print(f\"Analysis Period: {results['safe_start_date'].date()} to {results['safe_viz_end_date'].date()}.\")\n",
    "            pprint.pprint(results['tickers_to_display'])\n",
    "            p = results['performance_data']\n",
    "            \n",
    "            # --- START OF MODIFIED BLOCK ---\n",
    "            rows = []\n",
    "            # Gain Metrics\n",
    "            rows.append({'Metric': 'Group Portfolio Gain', 'Full': p['full_p_gain'], 'Calc': p['calc_p_gain'], 'Fwd': p['fwd_p_gain']})\n",
    "            if not np.isnan(p.get('full_b_gain')):\n",
    "                rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Gain', 'Full': p['full_b_gain'], 'Calc': p['calc_b_gain'], 'Fwd': p['fwd_b_gain']})\n",
    "                rows.append({'Metric': '== Gain Delta (vs Bm)', 'Full': p['full_p_gain'] - p['full_b_gain'], 'Calc': p['calc_p_gain'] - p['calc_b_gain'], 'Fwd': p['fwd_p_gain'] - p['fwd_b_gain']})\n",
    "            \n",
    "            # Standard Sharpe Metrics\n",
    "            rows.append({'Metric': 'Group Portfolio Sharpe', 'Full': p['full_p_sharpe'], 'Calc': p['calc_p_sharpe'], 'Fwd': p['fwd_p_sharpe']})\n",
    "            if not np.isnan(p.get('full_b_sharpe')):\n",
    "                rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Sharpe', 'Full': p['full_b_sharpe'], 'Calc': p['calc_b_sharpe'], 'Fwd': p['fwd_b_sharpe']})\n",
    "                rows.append({'Metric': '== Sharpe Delta (vs Bm)', 'Full': p['full_p_sharpe'] - p['full_b_sharpe'], 'Calc': p['calc_p_sharpe'] - p['calc_b_sharpe'], 'Fwd': p['fwd_p_sharpe'] - p['fwd_b_sharpe']})\n",
    "\n",
    "            # Sharpe (ATR) Metrics\n",
    "            rows.append({'Metric': 'Group Portfolio Sharpe (ATR)', 'Full': p['full_p_sharpe_atr'], 'Calc': p['calc_p_sharpe_atr'], 'Fwd': p['fwd_p_sharpe_atr']})\n",
    "            if not np.isnan(p.get('full_b_sharpe_atr')):\n",
    "                rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Sharpe (ATR)', 'Full': p['full_b_sharpe_atr'], 'Calc': p['calc_b_sharpe_atr'], 'Fwd': p['fwd_b_sharpe_atr']})\n",
    "                rows.append({'Metric': '== Sharpe (ATR) Delta (vs Bm)', 'Full': p['full_p_sharpe_atr'] - p['full_b_sharpe_atr'], 'Calc': p['calc_p_sharpe_atr'] - p['calc_b_sharpe_atr'], 'Fwd': p['fwd_p_sharpe_atr'] - p['fwd_b_sharpe_atr']})\n",
    "\n",
    "            report_df = pd.DataFrame(rows).set_index('Metric')\n",
    "            gain_rows = [row for row in report_df.index if 'Gain' in row]\n",
    "            sharpe_rows = [row for row in report_df.index if 'Sharpe' in row] # This now correctly includes both types of Sharpe\n",
    "            # --- END OF MODIFIED BLOCK ---\n",
    "            \n",
    "            styled_df = report_df.style.format('{:+.2%}', na_rep='N/A', subset=(gain_rows, report_df.columns)).format('{:+.4f}', na_rep='N/A', subset=(sharpe_rows, report_df.columns)).set_properties(**{'text-align': 'right', 'width': '100px'}).set_table_styles([{'selector': 'th.col_heading', 'props': [('text-align', 'right')]}, {'selector': 'th.row_heading', 'props': [('text-align', 'left')]}])\n",
    "            print(\"\\n--- Strategy Performance Summary ---\")\n",
    "            display(styled_df)\n",
    "    fig.update_layout(title_text='Walk-Forward Performance Analysis', xaxis_title='Date', yaxis_title='Normalized Price (Start = 1)', hovermode='x unified', legend_title_text='Tickers (Ranked)', height=600, margin=dict(t=50))\n",
    "    fig.add_hline(y=1, line_width=1, line_dash=\"dash\", line_color=\"grey\")\n",
    "    update_button.on_click(update_plot)\n",
    "    controls_row1 = widgets.HBox([start_date_picker, calc_period_input, fwd_period_input])\n",
    "    controls_row2 = widgets.HBox([metric_dropdown, rank_start_input, rank_end_input, benchmark_ticker_input, update_button])\n",
    "    ui_container = widgets.VBox([controls_row1, controls_row2, ticker_list_output], layout=widgets.Layout(margin='10px 0 20px 0'))\n",
    "    display(ui_container, fig)\n",
    "    update_plot(None)\n",
    "    return (results_container, debug_data_container)\n",
    "\n",
    "\n",
    "def generate_features(df_ohlcv: pd.DataFrame, \n",
    "                      atr_period: int = 14, \n",
    "                      quality_window: int = 252, \n",
    "                      quality_min_periods: int = 126) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates a comprehensive DataFrame of derived features from raw OHLCV data.\n",
    "\n",
    "    This function performs all heavy, window-based calculations upfront to be used\n",
    "    by downstream analysis functions. It calculates:\n",
    "    1. Technical Indicators: True Range (TR), ATR, and ATRP.\n",
    "    2. Data Quality Metrics: Rolling stale percentage, median dollar volume, etc.\n",
    "\n",
    "    Args:\n",
    "        df_ohlcv: The primary DataFrame with a (Ticker, Date) MultiIndex and\n",
    "                  columns for 'Adj High', 'Adj Low', 'Adj Close', 'Volume'.\n",
    "        atr_period: The lookback period for the ATR's Exponential Moving Average.\n",
    "        quality_window: The rolling window size for data quality metrics.\n",
    "        quality_min_periods: The minimum number of observations required to have\n",
    "                             a valid quality metric.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame with the same (Ticker, Date) MultiIndex containing all\n",
    "        calculated feature columns.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Feature Generation ---\")\n",
    "    \n",
    "    # Ensure the DataFrame is sorted for correct window and shift operations\n",
    "    # FIX: Replaced is_lexsorted() with the current pandas attribute\n",
    "    if not df_ohlcv.index.is_monotonic_increasing:\n",
    "        print(\"Sorting index for calculation accuracy...\")\n",
    "        df_ohlcv = df_ohlcv.sort_index()\n",
    "\n",
    "    # --- 1. Technical Indicator Calculation (TR, ATR, ATRP) ---\n",
    "    print(f\"Calculating technical indicators (ATR Period: {atr_period})...\")\n",
    "    \n",
    "    # Group by ticker to handle each security independently\n",
    "    grouped = df_ohlcv.groupby(level='Ticker')\n",
    "    \n",
    "    # Get the previous day's close required for True Range\n",
    "    prev_close = grouped['Adj Close'].shift(1)\n",
    "    \n",
    "    # Calculate the three components of True Range\n",
    "    high_low = df_ohlcv['Adj High'] - df_ohlcv['Adj Low']\n",
    "    high_prev_close = abs(df_ohlcv['Adj High'] - prev_close)\n",
    "    low_prev_close = abs(df_ohlcv['Adj Low'] - prev_close)\n",
    "    \n",
    "    # Combine the components to get the final TR\n",
    "    tr = pd.concat([high_low, high_prev_close, low_prev_close], axis=1).max(axis=1, skipna=False)\n",
    "    \n",
    "    # # Calculate the ATR using an Exponential Moving Average\n",
    "    # --- FIX IS HERE ---\n",
    "    # Use .transform() to apply the EWM function. \n",
    "    # This guarantees the resulting Series has the exact same index as 'tr',\n",
    "    # preventing the index alignment error during the subsequent division.\n",
    "    atr = tr.groupby(level='Ticker').transform(\n",
    "        lambda x: x.ewm(alpha=1/atr_period, adjust=False).mean()\n",
    "    )\n",
    "\n",
    "    # --- CHANGE 1: Removed .fillna(0) ---\n",
    "    # ATRP will now be NaN on the first day, consistent with TR and ATR.\n",
    "    atrp = (atr / df_ohlcv['Adj Close']).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    indicator_df = pd.DataFrame({\n",
    "        'TR': tr,\n",
    "        'ATR': atr,\n",
    "        'ATRP': atrp\n",
    "    })\n",
    "    \n",
    "    # --- 2. Data Quality Metric Calculation ---\n",
    "    print(f\"Calculating data quality metrics (Window: {quality_window} days)...\")\n",
    "    \n",
    "    # Create intermediate flags needed for quality calculations\n",
    "    is_stale = np.where((df_ohlcv['Volume'] == 0) | (df_ohlcv['Adj High'] == df_ohlcv['Adj Low']), 1, 0)\n",
    "    dollar_volume = df_ohlcv['Adj Close'] * df_ohlcv['Volume']\n",
    "    has_same_volume = (grouped['Volume'].diff() == 0).astype(int)\n",
    "    \n",
    "    # Combine flags into a temporary DataFrame for rolling calculations\n",
    "    quality_temp_df = pd.DataFrame({\n",
    "        'IsStale': is_stale,\n",
    "        'DollarVolume': dollar_volume,\n",
    "        'HasSameVolume': has_same_volume\n",
    "    }, index=df_ohlcv.index) # Explicitly set index to be safe\n",
    "    \n",
    "    # Perform the rolling calculations on the grouped data\n",
    "    # --- FIX IS HERE ---\n",
    "    # We switch to the older, more compatible dictionary-based aggregation method.\n",
    "    # This syntax is understood by nearly all versions of pandas.\n",
    "    rolling_result = quality_temp_df.groupby(level='Ticker').rolling(\n",
    "        window=quality_window,\n",
    "        min_periods=quality_min_periods\n",
    "    ).agg({\n",
    "        'IsStale': 'mean',\n",
    "        'DollarVolume': 'median',\n",
    "        'HasSameVolume': 'sum'\n",
    "    })\n",
    "    \n",
    "    # The dictionary syntax produces columns with the original names ('IsStale', etc.).\n",
    "    # We now explicitly rename them to our desired final names.\n",
    "    rolling_result = rolling_result.rename(columns={\n",
    "        'IsStale': 'RollingStalePct',\n",
    "        'DollarVolume': 'RollMedDollarVol', # <-- RENAMED HERE\n",
    "        'HasSameVolume': 'RollingSameVolCount'\n",
    "    })\n",
    "\n",
    "    # The index after a grouped rolling operation is hierarchical.\n",
    "    # We remove the outermost 'Ticker' level to restore the original index structure.\n",
    "    rolling_quality = rolling_result.reset_index(level=0, drop=True)\n",
    "\n",
    "    # --- 3. Combine All Features ---\n",
    "    print(\"Combining all feature sets...\")\n",
    "    features_df = pd.concat([indicator_df, rolling_quality], axis=1)\n",
    "    \n",
    "    print(\"✅ Feature generation complete.\")\n",
    "    return features_df\n",
    "\n",
    "\n",
    "def get_eligible_universe(features_df, filter_date, thresholds):\n",
    "    \"\"\"Filters the universe of tickers based on quality metrics for a given date.\"\"\"\n",
    "    filter_date_ts = pd.to_datetime(filter_date)\n",
    "    # The index is now the comprehensive features_df\n",
    "    date_index = features_df.index.get_level_values('Date').unique().sort_values()\n",
    "    \n",
    "    if filter_date_ts < date_index[0]:\n",
    "        print(f\"Warning: Filter date {filter_date_ts.date()} is before the earliest data point. Returning empty universe.\")\n",
    "        return []\n",
    "        \n",
    "    # Find the most recent date with quality data on or before the filter date\n",
    "    valid_prior_dates = date_index[date_index <= filter_date_ts]\n",
    "    if valid_prior_dates.empty:\n",
    "        print(f\"Warning: No available data found on or before {filter_date_ts.date()}. Returning empty universe.\")\n",
    "        return []\n",
    "        \n",
    "    actual_date_to_use = valid_prior_dates[-1]\n",
    "    if actual_date_to_use.date() != filter_date_ts.date():\n",
    "        print(f\"ℹ️ Info: Filter date {filter_date_ts.date()} not found. Using previous available date {actual_date_to_use.date()}.\")\n",
    "\n",
    "    metrics_on_date = features_df.xs(actual_date_to_use, level='Date')\n",
    "    \n",
    "    # Apply filters using the new column names from features_df\n",
    "    mask = ((metrics_on_date['RollMedDollarVol'] >= thresholds['min_median_dollar_volume']) & # <-- RENAMED\n",
    "            (metrics_on_date['RollingStalePct'] <= thresholds['max_stale_pct']) &\n",
    "            (metrics_on_date['RollingSameVolCount'] <= thresholds['max_same_vol_count']))\n",
    "            \n",
    "    eligible_tickers = metrics_on_date[mask].index.tolist()\n",
    "    all_tickers = metrics_on_date.index.tolist()\n",
    "    print(f\"Dynamic Filter ({filter_date_ts.date()}): Kept {len(eligible_tickers)} of {len(all_tickers)} tickers.\")\n",
    "    return eligible_tickers\n",
    "\n",
    "\n",
    "def run_walk_forward_step(df_close_full, df_high_full, df_low_full,\n",
    "                          master_trading_days,\n",
    "                          start_date, calc_period, fwd_period,\n",
    "                          metric, rank_start, rank_end, benchmark_ticker,\n",
    "                          features_df,\n",
    "                          debug=False):\n",
    "    \"\"\"\n",
    "    Runs a single step of the walk-forward analysis with a strict, pre-emptive\n",
    "    check to ensure the full period is available.\n",
    "    \"\"\"\n",
    "    debug_data = {} if debug else None\n",
    "\n",
    "    # 1. Determine exact date ranges with a NEW pre-emptive check\n",
    "    try:\n",
    "        start_idx = master_trading_days.get_loc(start_date)\n",
    "    except KeyError:\n",
    "        return ({'error': f\"Start date {start_date.date()} is not a valid trading day.\"}, None)\n",
    "\n",
    "    # +++ THIS IS THE NEW PRE-EMPTIVE CHECK LOGIC +++\n",
    "    # Calculate the desired end index without clamping first.\n",
    "    desired_viz_end_idx = start_idx + calc_period + fwd_period\n",
    "    \n",
    "    # Check if the desired end index is out of bounds.\n",
    "    if desired_viz_end_idx >= len(master_trading_days):\n",
    "        last_available_date = master_trading_days[-1].date()\n",
    "        required_days = calc_period + fwd_period\n",
    "        available_days = len(master_trading_days) - start_idx\n",
    "        error_msg = (f\"Not enough data for the full requested period. \"\n",
    "                     f\"Required: {required_days} days, Available: {available_days} days until {last_available_date}.\")\n",
    "        return ({'error': error_msg}, None)\n",
    "    # --- END OF NEW CHECK ---\n",
    "\n",
    "    # If the check passes, we know the full period is available.\n",
    "    # The 'min' calls are now just a redundant safety measure.\n",
    "    calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "    viz_end_idx = min(calc_end_idx + fwd_period, len(master_trading_days) - 1)\n",
    "\n",
    "    safe_start_date = master_trading_days[start_idx]\n",
    "    safe_calc_end_date = master_trading_days[calc_end_idx]\n",
    "    safe_viz_end_date = master_trading_days[viz_end_idx]\n",
    "    \n",
    "    if safe_start_date >= safe_calc_end_date:\n",
    "        return ({'error': \"Invalid date range (calc period has zero or negative length).\"}, None)\n",
    "\n",
    "    # (The rest of the function remains completely unchanged...)\n",
    "    # 2. Slice data for the calculation period\n",
    "    calc_close_raw = df_close_full.loc[safe_start_date:safe_calc_end_date]\n",
    "    calc_close = calc_close_raw.dropna(axis=1, how='all')\n",
    "    if calc_close.shape[1] == 0 or len(calc_close) < 2:\n",
    "        return ({'error': \"Not enough data in calc period.\"}, None)\n",
    "\n",
    "    # 3. Calculate INTERMEDIATE data required for the ranking metrics\n",
    "    daily_returns = calc_close.bfill().ffill().pct_change()\n",
    "    valid_tickers = calc_close.columns\n",
    "    calc_period_index = pd.MultiIndex.from_product([valid_tickers, calc_close.index], names=['Ticker', 'Date'])\n",
    "    features_in_period = features_df.loc[features_df.index.intersection(calc_period_index)]\n",
    "    atrp = features_in_period.groupby(level='Ticker')['ATRP'].mean()\n",
    "\n",
    "    # 4. Calculate all ranking metrics by iterating through the METRIC_REGISTRY\n",
    "    metric_ingredients = { 'calc_close': calc_close, 'daily_returns': daily_returns, 'atrp': atrp, }\n",
    "    metric_values = {}\n",
    "    for name, func in METRIC_REGISTRY.items():\n",
    "        metric_values[name] = func(metric_ingredients)\n",
    "    if metric not in metric_values or metric_values[metric].empty:\n",
    "        return ({'error': f\"Metric '{metric}' could not be calculated or resulted in no valid tickers.\"}, None)\n",
    "\n",
    "    # 5. Rank tickers and select the portfolio\n",
    "    sorted_tickers = metric_values[metric].sort_values(ascending=False)\n",
    "    tickers_to_display = sorted_tickers.index[rank_start-1:rank_end].tolist()\n",
    "    if not tickers_to_display:\n",
    "        return ({'error': \"No tickers found for the selected rank.\"}, None)\n",
    "\n",
    "    # 6. Calculate Portfolio & Benchmark Performance\n",
    "    normalized_plot_data = df_close_full[tickers_to_display].loc[safe_start_date:safe_viz_end_date]\n",
    "    normalized_plot_data = normalized_plot_data.div(normalized_plot_data.bfill().iloc[0])\n",
    "    actual_calc_end_ts = calc_close.index.max()\n",
    "    portfolio_series = normalized_plot_data.mean(axis=1)\n",
    "    portfolio_return_series = portfolio_series.pct_change()\n",
    "    benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "    benchmark_return_series = benchmark_price_series.loc[safe_start_date:safe_viz_end_date].bfill().ffill().pct_change() if benchmark_price_series is not None else pd.Series(dtype='float64')\n",
    "    try:\n",
    "        boundary_loc = portfolio_return_series.index.get_loc(actual_calc_end_ts)\n",
    "        calc_portfolio_returns = portfolio_return_series.iloc[:boundary_loc + 1]\n",
    "        fwd_portfolio_returns = portfolio_return_series.iloc[boundary_loc + 1:]\n",
    "        if benchmark_price_series is not None:\n",
    "            bm_boundary_loc = benchmark_return_series.index.get_loc(actual_calc_end_ts)\n",
    "            calc_benchmark_returns = benchmark_return_series.iloc[:bm_boundary_loc + 1]\n",
    "            fwd_benchmark_returns = benchmark_return_series.iloc[bm_boundary_loc + 1:]\n",
    "        else:\n",
    "            calc_benchmark_returns, fwd_benchmark_returns = pd.Series(dtype='float64'), pd.Series(dtype='float64')\n",
    "    except (KeyError, IndexError):\n",
    "        calc_portfolio_returns = portfolio_return_series.loc[:actual_calc_end_ts]\n",
    "        fwd_portfolio_returns = portfolio_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "        if benchmark_price_series is not None:\n",
    "            calc_benchmark_returns = benchmark_return_series.loc[:actual_calc_end_ts]\n",
    "            fwd_benchmark_returns = benchmark_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "        else:\n",
    "            calc_benchmark_returns, fwd_benchmark_returns = pd.Series(dtype='float64'), pd.Series(dtype='float64')\n",
    "    full_period_index = pd.MultiIndex.from_product([tickers_to_display, portfolio_return_series.index], names=['Ticker', 'Date'])\n",
    "    portfolio_atrp_features = features_df.loc[features_df.index.intersection(full_period_index)]\n",
    "    portfolio_atrp_daily_unstacked = portfolio_atrp_features['ATRP'].unstack(level='Ticker')\n",
    "    portfolio_atrp_series = portfolio_atrp_daily_unstacked.mean(axis=1)\n",
    "    if benchmark_ticker in df_close_full.columns:\n",
    "        benchmark_atrp_series = features_df.xs(benchmark_ticker, level='Ticker')['ATRP'].loc[safe_start_date:safe_viz_end_date]\n",
    "    else:\n",
    "        benchmark_atrp_series = pd.Series(dtype='float64')\n",
    "    calc_portfolio_atrp = portfolio_atrp_series.loc[:actual_calc_end_ts]\n",
    "    fwd_portfolio_atrp = portfolio_atrp_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "    calc_benchmark_atrp = benchmark_atrp_series.loc[:actual_calc_end_ts]\n",
    "    fwd_benchmark_atrp = benchmark_atrp_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "    perf_data = {}\n",
    "    perf_data['calc_p_gain'] = calculate_gain(portfolio_series.loc[:actual_calc_end_ts])\n",
    "    perf_data['fwd_p_gain'] = calculate_gain(portfolio_series.loc[actual_calc_end_ts:])\n",
    "    perf_data['full_p_gain'] = calculate_gain(portfolio_series)\n",
    "    perf_data['calc_p_sharpe'] = calculate_sharpe(calc_portfolio_returns)\n",
    "    perf_data['fwd_p_sharpe'] = calculate_sharpe(fwd_portfolio_returns)\n",
    "    perf_data['full_p_sharpe'] = calculate_sharpe(portfolio_return_series)\n",
    "    perf_data['calc_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:actual_calc_end_ts]) if benchmark_price_series is not None else np.nan\n",
    "    perf_data['fwd_b_gain'] = calculate_gain(benchmark_price_series.loc[actual_calc_end_ts:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "    perf_data['full_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "    perf_data['calc_b_sharpe'] = calculate_sharpe(calc_benchmark_returns)\n",
    "    perf_data['fwd_b_sharpe'] = calculate_sharpe(fwd_benchmark_returns)\n",
    "    perf_data['full_b_sharpe'] = calculate_sharpe(benchmark_return_series)\n",
    "    perf_data['calc_p_sharpe_atr'] = calculate_sharpe_atr(calc_portfolio_returns, calc_portfolio_atrp)\n",
    "    perf_data['fwd_p_sharpe_atr'] = calculate_sharpe_atr(fwd_portfolio_returns, fwd_portfolio_atrp)\n",
    "    perf_data['full_p_sharpe_atr'] = calculate_sharpe_atr(portfolio_return_series, portfolio_atrp_series)\n",
    "    perf_data['calc_b_sharpe_atr'] = calculate_sharpe_atr(calc_benchmark_returns, calc_benchmark_atrp)\n",
    "    perf_data['fwd_b_sharpe_atr'] = calculate_sharpe_atr(fwd_benchmark_returns, fwd_benchmark_atrp)\n",
    "    perf_data['full_b_sharpe_atr'] = calculate_sharpe_atr(benchmark_return_series, benchmark_atrp_series)\n",
    "    if debug:\n",
    "        df_ranking_base = pd.DataFrame({'MeanDailyReturn': daily_returns.mean(),'StdDevDailyReturn': daily_returns.std(),'MeanATRP': atrp})\n",
    "        df_metrics = pd.DataFrame(metric_values)\n",
    "        df_metrics.columns = [f'Metric_{col}' for col in df_metrics.columns]\n",
    "        df_ranking = df_ranking_base.join(df_metrics, how='left')\n",
    "        df_ranking.index.name = 'Ticker'\n",
    "        debug_data['ranking_metrics'] = df_ranking.sort_values(f'Metric_{metric}', ascending=False)\n",
    "    calc_end_prices = calc_close.ffill().iloc[-1]\n",
    "    fwd_close_slice = df_close_full.loc[actual_calc_end_ts:safe_viz_end_date]\n",
    "    viz_end_prices = fwd_close_slice.ffill().iloc[-1] if not fwd_close_slice.empty and len(fwd_close_slice) >= 2 else calc_end_prices\n",
    "    calc_gains = (calc_end_prices / calc_close.bfill().iloc[0]) - 1\n",
    "    fwd_gains = (viz_end_prices / calc_end_prices) - 1\n",
    "    results_df = pd.DataFrame({'Rank': range(rank_start, rank_start + len(tickers_to_display)), 'Metric': metric, 'MetricValue': sorted_tickers.loc[tickers_to_display].values, 'CalcPrice': calc_end_prices.loc[tickers_to_display], 'CalcGain': calc_gains.loc[tickers_to_display], 'FwdGain': fwd_gains.loc[tickers_to_display]}, index=pd.Index(tickers_to_display, name='Ticker'))\n",
    "    if benchmark_price_series is not None and benchmark_ticker in calc_close.columns:\n",
    "        benchmark_df_row = pd.DataFrame({'Rank': np.nan, 'Metric': metric, 'MetricValue': metric_values[metric].get(benchmark_ticker, np.nan), 'CalcPrice': calc_end_prices[benchmark_ticker], 'CalcGain': calc_gains[benchmark_ticker], 'FwdGain': fwd_gains[benchmark_ticker]}, index=pd.Index([f\"{benchmark_ticker} (BM)\"], name='Ticker'))\n",
    "        results_df = pd.concat([results_df, benchmark_df_row])\n",
    "    if debug:\n",
    "        df_trace = normalized_plot_data.copy()\n",
    "        df_trace.columns = [f'Norm_Price_{c}' for c in df_trace.columns]\n",
    "        df_trace['Norm_Price_Portfolio'] = portfolio_series\n",
    "        if benchmark_price_series is not None and not benchmark_price_series.loc[safe_start_date:safe_viz_end_date].dropna().empty:\n",
    "            norm_bm = benchmark_price_series.loc[safe_start_date:safe_viz_end_date] / benchmark_price_series.loc[safe_start_date:].bfill().iloc[0]\n",
    "            df_trace[f'Norm_Price_Benchmark_{benchmark_ticker}'] = norm_bm\n",
    "        for col in df_trace.columns:\n",
    "            if 'Norm_Price' in col:\n",
    "                df_trace[col.replace('Norm_Price', 'Return')] = df_trace[col].pct_change()\n",
    "        debug_data['portfolio_trace'] = df_trace\n",
    "    final_results = {\n",
    "        'tickers_to_display': tickers_to_display, 'normalized_plot_data': normalized_plot_data,\n",
    "        'portfolio_series': portfolio_series, 'benchmark_price_series': benchmark_price_series,\n",
    "        'performance_data': perf_data, 'results_df': results_df, 'actual_calc_end_ts': actual_calc_end_ts,\n",
    "        'safe_start_date': safe_start_date, 'safe_viz_end_date': safe_viz_end_date,\n",
    "        'error': None\n",
    "    }\n",
    "    return (final_results, debug_data)\n",
    "\n",
    "def verify_sharpe_atr_calculation_checked(df_ohlcv, features_df, tickers_to_verify, benchmark_ticker,\n",
    "                                    start_date, calc_period, fwd_period,\n",
    "                                    master_calendar_ticker='VOO', debug=False):\n",
    "    \"\"\"\n",
    "    Verifies the Sharpe (ATR) calculations for a portfolio and benchmark.\n",
    "\n",
    "    This function transparently recalculates the key components for Sharpe (ATR)\n",
    "    and can optionally export the underlying source data for manual inspection.\n",
    "    \"\"\"\n",
    "    display(Markdown(f\"## Verification Report for Sharpe (ATR) Calculation\"))\n",
    "    display(Markdown(f\"**Portfolio Tickers:** `{tickers_to_verify}`\\n**Benchmark Ticker:** `{benchmark_ticker}`\"))\n",
    "\n",
    "    # --- 1. Determine Exact Period Dates (No changes here) ---\n",
    "    master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "    start_date_raw = pd.to_datetime(start_date)\n",
    "    start_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "    actual_start_date = master_trading_days[start_idx]\n",
    "    calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "    fwd_end_idx = min(calc_end_idx + fwd_period, len(master_trading_days) - 1)\n",
    "    actual_calc_end_date = master_trading_days[calc_end_idx]\n",
    "    actual_fwd_end_date = master_trading_days[fwd_end_idx]\n",
    "    \n",
    "    display(Markdown(f\"**Full Period:** `{actual_start_date.date()}` to `{actual_fwd_end_date.date()}`\\n\"\n",
    "                    f\"**Calc End Date:** `{actual_calc_end_date.date()}`\"))\n",
    "\n",
    "    # Original debug export block (can be kept or removed)\n",
    "    if debug:\n",
    "        # ... (original export code remains here) ...\n",
    "        pass # Assuming original block is here\n",
    "\n",
    "    # --- 2. Recreate Portfolio & Benchmark Series from Scratch ---\n",
    "    df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "    portfolio_prices_raw = df_close_full[tickers_to_verify].loc[actual_start_date:actual_fwd_end_date]\n",
    "    portfolio_prices_norm = portfolio_prices_raw.div(portfolio_prices_raw.bfill().iloc[0])\n",
    "    portfolio_value_series = portfolio_prices_norm.mean(axis=1)\n",
    "    portfolio_return_series = portfolio_value_series.pct_change()\n",
    "    p_idx = pd.MultiIndex.from_product([tickers_to_verify, portfolio_return_series.index])\n",
    "    p_atrp_df = features_df.loc[features_df.index.intersection(p_idx)]['ATRP'].unstack(level=0)\n",
    "    portfolio_atrp_series = p_atrp_df.mean(axis=1)\n",
    "\n",
    "###############################    \n",
    "    # benchmark_return_series = df_close_full[benchmark_ticker].pct_change().loc[actual_start_date:actual_fwd_end_date]\n",
    "\n",
    "    # 1. First, slice the raw prices for the desired date range.\n",
    "    benchmark_prices_raw = df_close_full[benchmark_ticker].loc[actual_start_date:actual_fwd_end_date]\n",
    "    # 2. Then, calculate the percentage change on the sliced data.\n",
    "    benchmark_return_series = benchmark_prices_raw.pct_change()\n",
    "\n",
    "###############################    \n",
    "    benchmark_atrp_series = features_df.xs(benchmark_ticker, level='Ticker')['ATRP'].loc[actual_start_date:actual_fwd_end_date]\n",
    "\n",
    "\n",
    "    # +++ NEW: DETAILED RETURN CALCULATION TRACE (PORTFOLIO) +++\n",
    "    if debug:\n",
    "        display(Markdown(\"---\"))\n",
    "        display(Markdown(\"### 🐛 Detailed Portfolio Return Calculation Trace\"))\n",
    "\n",
    "        # Step 1: Show the raw prices being used\n",
    "        print(\"\\n[STEP 1] Raw Adjusted Close prices used for calculation.\")\n",
    "        print(\"Compare these values with your 'Adj Close' columns.\")\n",
    "        display(portfolio_prices_raw)\n",
    "\n",
    "        # Step 2: Show the normalization base and the result\n",
    "        normalization_base = portfolio_prices_raw.bfill().iloc[0]\n",
    "        print(\"\\n[STEP 2] Normalization base (first row of prices).\")\n",
    "        print(\"Each column in Step 1 is divided by this corresponding value.\")\n",
    "        display(pd.DataFrame(normalization_base).T)\n",
    "\n",
    "        print(\"\\n[STEP 2a] Normalized prices (Result of division).\")\n",
    "        print(\"Compare these values with your 'N Close' columns.\")\n",
    "        display(portfolio_prices_norm)\n",
    "\n",
    "        # Step 3: Show the averaged portfolio value series\n",
    "        print(\"\\n[STEP 3] Averaged normalized portfolio value series.\")\n",
    "        print(\"This is the row-by-row average of the table in Step 2a.\")\n",
    "        print(\"Compare this series with your 'N_portf' column.\")\n",
    "        display(pd.DataFrame(portfolio_value_series, columns=['N_portf']))\n",
    "\n",
    "        # Step 4: Show the final portfolio return series\n",
    "        print(\"\\n[STEP 4] Final portfolio daily return series (pct_change).\")\n",
    "        print(\"This is the percentage change of the series in Step 3.\")\n",
    "        print(\"Compare this series with your 'N_portf_rtn' column.\")\n",
    "        display(pd.DataFrame(portfolio_return_series, columns=['N_portf_rtn']))\n",
    "        display(Markdown(\"---\"))\n",
    "    # +++ END OF NEW DEBUG BLOCK +++\n",
    "\n",
    "\n",
    "    # --- 3. Define a Helper to Print Detailed Calculation Steps ---\n",
    "    # MODIFIED to include more debug details inside\n",
    "    def _calculate_and_print_metrics(period_name, returns, atrps):\n",
    "        display(Markdown(f\"#### {period_name}\"))\n",
    "        if returns.dropna().empty or atrps.dropna().empty:\n",
    "            print(\"  - Not enough data to calculate.\")\n",
    "            return np.nan\n",
    "\n",
    "        # Standard calculations\n",
    "        mean_return = returns.mean()\n",
    "        mean_atrp = atrps.mean()\n",
    "        sharpe_atr = mean_return / mean_atrp if mean_atrp > 0 else np.nan\n",
    "\n",
    "        # +++ ADDED: Detailed Mean Calculation Breakdown +++\n",
    "        if debug:\n",
    "            valid_returns = returns.dropna()\n",
    "            num_returns = valid_returns.count()\n",
    "            sum_returns = valid_returns.sum()\n",
    "            manual_mean = sum_returns / num_returns if num_returns > 0 else 0\n",
    "            print(f\"  - (Debug) Number of valid daily returns: {num_returns}\")\n",
    "            print(f\"  - (Debug) Sum of all daily returns:      {sum_returns:,.8f}\")\n",
    "            print(f\"  - (Debug) Manually calculated mean:      {manual_mean:,.8f} (Sum / Count)\")\n",
    "        # +++ END OF ADDED DETAIL +++\n",
    "\n",
    "        print(f\"  - Mean Daily Return: {mean_return:,.6f}\")\n",
    "        print(f\"  - Mean Daily ATRP:  {mean_atrp:,.6f}\")\n",
    "        print(f\"  - Sharpe (ATR) = (Mean Return / Mean ATRP) = {sharpe_atr:,.4f}\")\n",
    "        return sharpe_atr\n",
    "\n",
    "    # --- 4. Run Verification for Portfolio (No changes here) ---\n",
    "    display(Markdown(\"### A. Group Portfolio Verification\"))\n",
    "    _calculate_and_print_metrics(\"Full Period\", portfolio_return_series, portfolio_atrp_series)\n",
    "    _calculate_and_print_metrics(\"Calculation Period\", portfolio_return_series.loc[:actual_calc_end_date], portfolio_atrp_series.loc[:actual_calc_end_date])\n",
    "    _calculate_and_print_metrics(\"Forward Period\", portfolio_return_series.loc[actual_calc_end_date:].iloc[1:], portfolio_atrp_series.loc[actual_calc_end_date:].iloc[1:])\n",
    "\n",
    "    # --- 5. Run Verification for Benchmark (No changes here) ---\n",
    "    display(Markdown(f\"### B. Benchmark ({benchmark_ticker}) Verification\"))\n",
    "    _calculate_and_print_metrics(\"Full Period\", benchmark_return_series, benchmark_atrp_series)\n",
    "    _calculate_and_print_metrics(\"Calculation Period\", benchmark_return_series.loc[:actual_calc_end_date], benchmark_atrp_series.loc[:actual_calc_end_date])\n",
    "    _calculate_and_print_metrics(\"Forward Period\", benchmark_return_series.loc[actual_calc_end_date:].iloc[1:], benchmark_atrp_series.loc[actual_calc_end_date:].iloc[1:])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c79216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now call the verification function with the exact parameters from the UI\n",
    "verify_sharpe_atr_calculation_checked(\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    features_df=features_df,\n",
    "    tickers_to_verify=tickers_to_verify, # <-- From the UI output\n",
    "    benchmark_ticker=benchmark_ticker,\n",
    "    start_date=start_date,\n",
    "    calc_period=10,\n",
    "    fwd_period=5,\n",
    "    debug=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da532d8",
   "metadata": {},
   "source": [
    "# PORTFOLIO & BENCHMARK SHARPE (ATR) Calculation have been verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0586ab73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f55cab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf901ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63e95d07",
   "metadata": {},
   "source": [
    "### My Verification of Portfolio Sharpe (ATR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2206d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets\n",
    "import pprint\n",
    "from IPython.display import display, Markdown\n",
    "import os # Make sure os is imported for the export function later\n",
    "\n",
    "\n",
    "# def calculate_gain(price_series: pd.Series):\n",
    "#     \"\"\"Calculates the total gain over a series of prices.\"\"\"\n",
    "#     # Ensure there are at least two data points to calculate a gain\n",
    "#     if price_series.dropna().shape[0] < 2: return np.nan\n",
    "#     # Use forward-fill for the end price and back-fill for the start price\n",
    "#     # to handle potential NaNs at the beginning or end of the series.\n",
    "#     return (price_series.ffill().iloc[-1] / price_series.bfill().iloc[0]) - 1\n",
    "\n",
    "# def calculate_sharpe(return_series: pd.Series):\n",
    "#     \"\"\"Calculates the annualized Sharpe ratio from a series of daily returns.\"\"\"\n",
    "#     # Ensure there are at least two returns to calculate a standard deviation\n",
    "#     if return_series.dropna().shape[0] < 2: return np.nan\n",
    "#     std_dev = return_series.std()\n",
    "#     # Avoid division by zero if returns are constant\n",
    "#     if std_dev > 0 and std_dev != np.inf:\n",
    "#         return (return_series.mean() / std_dev) * np.sqrt(252)\n",
    "#     return np.nan\n",
    "\n",
    "# def calculate_sharpe_atr(return_series: pd.Series, atrp_series: pd.Series):\n",
    "#     \"\"\"Calculates a Sharpe-like ratio using mean ATRP as the denominator.\"\"\"\n",
    "#     # Ensure there are returns and that ATRP data is valid\n",
    "#     if return_series.dropna().shape[0] < 2 or atrp_series.dropna().empty:\n",
    "#         return np.nan\n",
    "        \n",
    "#     mean_return = return_series.mean()\n",
    "#     mean_atrp = atrp_series.mean()\n",
    "    \n",
    "#     # Avoid division by zero\n",
    "#     if mean_atrp > 0 and mean_atrp != np.inf:\n",
    "#         return mean_return / mean_atrp\n",
    "        \n",
    "#     return np.nan\n",
    "\n",
    "\n",
    "# # --- B. MODULAR METRIC CALCULATION ENGINE ---\n",
    "\n",
    "# def calculate_price_metric(metric_data: dict) -> pd.Series:\n",
    "#     \"\"\"\n",
    "#     Calculates the 'Price' metric (total gain) over the calculation period.\n",
    "\n",
    "#     Args:\n",
    "#         metric_data: A dictionary containing pre-calculated data Series.\n",
    "#                      Requires 'calc_close' (pd.DataFrame): The close prices for the calc period.\n",
    "\n",
    "#     Returns:\n",
    "#         A pandas Series of the calculated metric values, indexed by Ticker.\n",
    "#     \"\"\"\n",
    "#     calc_close = metric_data['calc_close']\n",
    "    \n",
    "#     # Ensure there are at least two data points to calculate a gain\n",
    "#     if len(calc_close) < 2:\n",
    "#         return pd.Series(dtype='float64', index=calc_close.columns)\n",
    "\n",
    "#     first_prices = calc_close.bfill().iloc[0]\n",
    "#     last_prices = calc_close.ffill().iloc[-1]\n",
    "    \n",
    "#     # The division of two Series aligns by index (Ticker), which is what we want.\n",
    "#     price_metric = last_prices / first_prices\n",
    "    \n",
    "#     return price_metric.dropna()\n",
    "\n",
    "# def calculate_sharpe_metric(metric_data: dict) -> pd.Series:\n",
    "#     \"\"\"\n",
    "#     Calculates the annualized 'Sharpe' ratio metric over the calculation period.\n",
    "\n",
    "#     Args:\n",
    "#         metric_data: A dictionary containing pre-calculated data Series.\n",
    "#                      Requires 'daily_returns' (pd.DataFrame): Daily returns for the calc period.\n",
    "\n",
    "#     Returns:\n",
    "#         A pandas Series of the calculated metric values, indexed by Ticker.\n",
    "#     \"\"\"\n",
    "#     daily_returns = metric_data['daily_returns']\n",
    "    \n",
    "#     # Ensure there's enough data to calculate standard deviation\n",
    "#     if len(daily_returns.dropna()) < 2:\n",
    "#         return pd.Series(dtype='float64', index=daily_returns.columns)\n",
    "    \n",
    "#     mean_returns = daily_returns.mean()\n",
    "#     std_returns = daily_returns.std()\n",
    "    \n",
    "#     # Standard annualized Sharpe Ratio calculation. Avoid division by zero.\n",
    "#     # We replace resulting NaNs/infs with 0 to handle cases of zero volatility.\n",
    "#     sharpe_ratio = (mean_returns / std_returns * np.sqrt(252))\n",
    "    \n",
    "#     return sharpe_ratio.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    \n",
    "# def calculate_sharpe_atr_metric(metric_data: dict) -> pd.Series:\n",
    "#     \"\"\"\n",
    "#     Calculates the 'Sharpe (ATR)' metric over the calculation period.\n",
    "\n",
    "#     Args:\n",
    "#         metric_data: A dictionary containing pre-calculated data Series.\n",
    "#                      Requires 'daily_returns' (pd.DataFrame): Daily returns for the calc period.\n",
    "#                      Requires 'atrp' (pd.Series): Mean ATRP for each ticker over the period.\n",
    "\n",
    "#     Returns:\n",
    "#         A pandas Series of the calculated metric values, indexed by Ticker.\n",
    "#     \"\"\"\n",
    "#     daily_returns = metric_data['daily_returns']\n",
    "#     atrp = metric_data['atrp']\n",
    "    \n",
    "#     mean_returns = daily_returns.mean()\n",
    "    \n",
    "#     # ATRP-based Sharpe. Avoid division by zero.\n",
    "#     # We replace resulting NaNs/infs with 0.\n",
    "#     sharpe_atr = mean_returns / atrp\n",
    "    \n",
    "#     return sharpe_atr.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "\n",
    "# METRIC_REGISTRY = {\n",
    "#     'Price': calculate_price_metric,\n",
    "#     'Sharpe': calculate_sharpe_metric,\n",
    "#     'Sharpe (ATR)': calculate_sharpe_atr_metric,\n",
    "# }\n",
    "\n",
    "# def plot_walk_forward_analyzer(df_ohlcv,\n",
    "#                                default_start_date=None, default_calc_period=126, default_fwd_period=63,\n",
    "#                                default_metric='Sharpe (ATR)', default_rank_start=1, default_rank_end=10,\n",
    "#                                default_benchmark_ticker='VOO', master_calendar_ticker='VOO',\n",
    "#                                quality_thresholds={'min_median_dollar_volume': 1_000_000, 'max_stale_pct': 0.05, 'max_same_vol_count': 10},\n",
    "#                                debug=False):\n",
    "#     # (No changes to the initial setup part of this function...)\n",
    "#     print(\"Initializing Walk-Forward Analyzer (using Trading Day Logic)...\")\n",
    "#     if not isinstance(df_ohlcv.index, pd.MultiIndex): raise ValueError(\"Input DataFrame must have a (Ticker, Date) MultiIndex.\")\n",
    "#     df_ohlcv = df_ohlcv.sort_index()\n",
    "#     if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "#         raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "#     master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "#     print(f\"Master trading day calendar created from '{master_calendar_ticker}' ({len(master_trading_days)} days).\")\n",
    "#     print(\"--- Generating all features upfront... ---\")\n",
    "#     features_df = generate_features(df_ohlcv)\n",
    "#     print(\"Pre-processing data (unstacking)...\")\n",
    "#     df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "#     df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "#     df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "#     start_date_picker = widgets.DatePicker(description='Start Date:', value=pd.to_datetime(default_start_date), disabled=False)\n",
    "#     calc_period_input = widgets.IntText(value=default_calc_period, description='Calc Period (days):')\n",
    "#     fwd_period_input = widgets.IntText(value=default_fwd_period, description='Fwd Period (days):')\n",
    "#     if default_metric not in METRIC_REGISTRY:\n",
    "#         fallback_metric = list(METRIC_REGISTRY.keys())[0]\n",
    "#         print(f\"⚠️ Warning: Default metric '{default_metric}' not in registry. Using '{fallback_metric}'.\")\n",
    "#         default_metric = fallback_metric\n",
    "#     metric_dropdown = widgets.Dropdown(options=list(METRIC_REGISTRY.keys()), value=default_metric, description='Metric:')\n",
    "#     rank_start_input = widgets.IntText(value=default_rank_start, description='Rank Start:')\n",
    "#     rank_end_input = widgets.IntText(value=default_rank_end, description='Rank End:')\n",
    "#     benchmark_ticker_input = widgets.Text(value=default_benchmark_ticker, description='Benchmark:', placeholder='Enter Ticker')\n",
    "#     update_button = widgets.Button(description=\"Update Chart\", button_style='primary')\n",
    "#     ticker_list_output = widgets.Output()\n",
    "#     results_container, debug_data_container = [None], [None]\n",
    "#     fig = go.FigureWidget()\n",
    "#     max_traces = 50\n",
    "#     for i in range(max_traces): fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name=f'placeholder_{i}', visible=False, showlegend=False))\n",
    "#     fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Benchmark', visible=True, showlegend=True, line=dict(color='black', width=3, dash='dash')))\n",
    "#     fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Group Portfolio', visible=True, showlegend=True, line=dict(color='green', width=3)))\n",
    "\n",
    "#     def update_plot(button_click):\n",
    "#         ticker_list_output.clear_output()\n",
    "#         start_date_raw = pd.to_datetime(start_date_picker.value)\n",
    "#         start_date_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "#         if start_date_idx >= len(master_trading_days):\n",
    "#             with ticker_list_output: print(f\"Error: Start date is after the last available trading day.\"); return\n",
    "#         actual_start_date = master_trading_days[start_date_idx]\n",
    "#         with ticker_list_output:\n",
    "#             if start_date_raw.date() != actual_start_date.date():\n",
    "#                 print(f\"ℹ️ Info: Start date {start_date_raw.date()} is not a trading day. Snapping forward to {actual_start_date.date()}.\")\n",
    "#         calc_period = calc_period_input.value; fwd_period = fwd_period_input.value; metric = metric_dropdown.value\n",
    "#         rank_start = rank_start_input.value; rank_end = rank_end_input.value; benchmark_ticker = benchmark_ticker_input.value.strip().upper()\n",
    "#         if rank_start > rank_end:\n",
    "#             with ticker_list_output: print(\"Error: 'Rank Start' must be <= 'Rank End'.\"); return\n",
    "#         if rank_start < 1 or calc_period < 2 or fwd_period < 1:\n",
    "#             with ticker_list_output: print(\"Error: Ranks must be >= 1, Calc Period >= 2, Fwd Period >= 1.\"); return\n",
    "#         required_days = calc_period + fwd_period\n",
    "#         if start_date_idx + required_days > len(master_trading_days):\n",
    "#             available_days = len(master_trading_days) - start_date_idx; last_available_date = master_trading_days[-1].date()\n",
    "#             with ticker_list_output:\n",
    "#                 print(f\"Error: Not enough data for the requested period.\\n  Start Date: {actual_start_date.date()}\\n  Required Days: {calc_period} (calc) + {fwd_period} (fwd) = {required_days}\\n  Available Days from Start: {available_days} (until {last_available_date})\\n  Please shorten the 'Calc Period' / 'Fwd Period' or choose an earlier 'Start Date'.\")\n",
    "#             return\n",
    "#         eligible_tickers = get_eligible_universe(features_df, actual_start_date, quality_thresholds)\n",
    "#         if not eligible_tickers:\n",
    "#             with ticker_list_output: print(f\"Error: No eligible tickers found on {actual_start_date.date()} with the current quality filters.\"); return\n",
    "#         df_close_step = df_close_full[eligible_tickers]; df_high_step = df_high_full[eligible_tickers]; df_low_step = df_low_full[eligible_tickers]\n",
    "#         results, debug_output = run_walk_forward_step(df_close_full, df_high_full, df_low_full, master_trading_days, actual_start_date, calc_period, fwd_period, metric, rank_start, rank_end, benchmark_ticker, features_df=features_df, debug=debug)\n",
    "#         if results.get('error'):\n",
    "#             with ticker_list_output: print(f\"Error: {results['error']}\"); return\n",
    "#         period_dates = {'calc_period_start': results['safe_start_date'], 'calc_period_end': results['actual_calc_end_ts'], 'forward_period_start': results['actual_calc_end_ts'], 'forward_period_end': results['safe_viz_end_date']}\n",
    "#         run_parameters = {'calc_period': calc_period, 'fwd_period': fwd_period, 'rank_metric': metric, 'rank_start': rank_start, 'rank_end': rank_end, 'benchmark_ticker': benchmark_ticker}\n",
    "#         results.update(period_dates); results.update(run_parameters)\n",
    "#         if debug_output is not None and isinstance(debug_output, dict):\n",
    "#             debug_output.update(period_dates); debug_output.update(run_parameters)\n",
    "#         with fig.batch_update():\n",
    "#             for i in range(max_traces):\n",
    "#                 trace = fig.data[i]\n",
    "#                 if i < len(results['tickers_to_display']):\n",
    "#                     ticker = results['tickers_to_display'][i]; plot_data_series = results['normalized_plot_data'][ticker]\n",
    "#                     trace.x, trace.y, trace.name, trace.visible, trace.showlegend = plot_data_series.index, plot_data_series.values, ticker, True, True\n",
    "#                 else: trace.visible, trace.showlegend = False, False\n",
    "#             benchmark_trace = fig.data[max_traces]\n",
    "#             if results['benchmark_price_series'] is not None and not results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']].dropna().empty:\n",
    "#                 normalized_benchmark = results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']] / results['benchmark_price_series'].loc[results['safe_start_date']:].bfill().iloc[0]\n",
    "#                 benchmark_trace.x, benchmark_trace.y, benchmark_trace.name, benchmark_trace.visible = normalized_benchmark.index, normalized_benchmark.values, f\"Benchmark ({benchmark_ticker})\", True\n",
    "#             else: benchmark_trace.visible = False\n",
    "#             portfolio_trace = fig.data[max_traces + 1]\n",
    "#             portfolio_trace.x, portfolio_trace.y, portfolio_trace.name, portfolio_trace.visible = results['portfolio_series'].index, results['portfolio_series'], 'Group Portfolio', True\n",
    "#             fig.layout.shapes = []; fig.add_shape(type=\"line\", x0=results['actual_calc_end_ts'], y0=0, x1=results['actual_calc_end_ts'], y1=1, xref='x', yref='paper', line=dict(color=\"grey\", width=2, dash=\"dash\"))\n",
    "#         results_container[0] = results; debug_data_container[0] = debug_output\n",
    "#         with ticker_list_output:\n",
    "#             print(f\"Analysis Period: {results['safe_start_date'].date()} to {results['safe_viz_end_date'].date()}.\")\n",
    "#             pprint.pprint(results['tickers_to_display'])\n",
    "#             p = results['performance_data']\n",
    "            \n",
    "#             # --- START OF MODIFIED BLOCK ---\n",
    "#             rows = []\n",
    "#             # Gain Metrics\n",
    "#             rows.append({'Metric': 'Group Portfolio Gain', 'Full': p['full_p_gain'], 'Calc': p['calc_p_gain'], 'Fwd': p['fwd_p_gain']})\n",
    "#             if not np.isnan(p.get('full_b_gain')):\n",
    "#                 rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Gain', 'Full': p['full_b_gain'], 'Calc': p['calc_b_gain'], 'Fwd': p['fwd_b_gain']})\n",
    "#                 rows.append({'Metric': '== Gain Delta (vs Bm)', 'Full': p['full_p_gain'] - p['full_b_gain'], 'Calc': p['calc_p_gain'] - p['calc_b_gain'], 'Fwd': p['fwd_p_gain'] - p['fwd_b_gain']})\n",
    "            \n",
    "#             # Standard Sharpe Metrics\n",
    "#             rows.append({'Metric': 'Group Portfolio Sharpe', 'Full': p['full_p_sharpe'], 'Calc': p['calc_p_sharpe'], 'Fwd': p['fwd_p_sharpe']})\n",
    "#             if not np.isnan(p.get('full_b_sharpe')):\n",
    "#                 rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Sharpe', 'Full': p['full_b_sharpe'], 'Calc': p['calc_b_sharpe'], 'Fwd': p['fwd_b_sharpe']})\n",
    "#                 rows.append({'Metric': '== Sharpe Delta (vs Bm)', 'Full': p['full_p_sharpe'] - p['full_b_sharpe'], 'Calc': p['calc_p_sharpe'] - p['calc_b_sharpe'], 'Fwd': p['fwd_p_sharpe'] - p['fwd_b_sharpe']})\n",
    "\n",
    "#             # Sharpe (ATR) Metrics\n",
    "#             rows.append({'Metric': 'Group Portfolio Sharpe (ATR)', 'Full': p['full_p_sharpe_atr'], 'Calc': p['calc_p_sharpe_atr'], 'Fwd': p['fwd_p_sharpe_atr']})\n",
    "#             if not np.isnan(p.get('full_b_sharpe_atr')):\n",
    "#                 rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Sharpe (ATR)', 'Full': p['full_b_sharpe_atr'], 'Calc': p['calc_b_sharpe_atr'], 'Fwd': p['fwd_b_sharpe_atr']})\n",
    "#                 rows.append({'Metric': '== Sharpe (ATR) Delta (vs Bm)', 'Full': p['full_p_sharpe_atr'] - p['full_b_sharpe_atr'], 'Calc': p['calc_p_sharpe_atr'] - p['calc_b_sharpe_atr'], 'Fwd': p['fwd_p_sharpe_atr'] - p['fwd_b_sharpe_atr']})\n",
    "\n",
    "#             report_df = pd.DataFrame(rows).set_index('Metric')\n",
    "#             gain_rows = [row for row in report_df.index if 'Gain' in row]\n",
    "#             sharpe_rows = [row for row in report_df.index if 'Sharpe' in row] # This now correctly includes both types of Sharpe\n",
    "#             # --- END OF MODIFIED BLOCK ---\n",
    "            \n",
    "#             styled_df = report_df.style.format('{:+.2%}', na_rep='N/A', subset=(gain_rows, report_df.columns)).format('{:+.2f}', na_rep='N/A', subset=(sharpe_rows, report_df.columns)).set_properties(**{'text-align': 'right', 'width': '100px'}).set_table_styles([{'selector': 'th.col_heading', 'props': [('text-align', 'right')]}, {'selector': 'th.row_heading', 'props': [('text-align', 'left')]}])\n",
    "#             print(\"\\n--- Strategy Performance Summary ---\")\n",
    "#             display(styled_df)\n",
    "#     fig.update_layout(title_text='Walk-Forward Performance Analysis', xaxis_title='Date', yaxis_title='Normalized Price (Start = 1)', hovermode='x unified', legend_title_text='Tickers (Ranked)', height=600, margin=dict(t=50))\n",
    "#     fig.add_hline(y=1, line_width=1, line_dash=\"dash\", line_color=\"grey\")\n",
    "#     update_button.on_click(update_plot)\n",
    "#     controls_row1 = widgets.HBox([start_date_picker, calc_period_input, fwd_period_input])\n",
    "#     controls_row2 = widgets.HBox([metric_dropdown, rank_start_input, rank_end_input, benchmark_ticker_input, update_button])\n",
    "#     ui_container = widgets.VBox([controls_row1, controls_row2, ticker_list_output], layout=widgets.Layout(margin='10px 0 20px 0'))\n",
    "#     display(ui_container, fig)\n",
    "#     update_plot(None)\n",
    "#     return (results_container, debug_data_container)\n",
    "\n",
    "\n",
    "def generate_features(df_ohlcv: pd.DataFrame, \n",
    "                      atr_period: int = 14, \n",
    "                      quality_window: int = 252, \n",
    "                      quality_min_periods: int = 126) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates a comprehensive DataFrame of derived features from raw OHLCV data.\n",
    "\n",
    "    This function performs all heavy, window-based calculations upfront to be used\n",
    "    by downstream analysis functions. It calculates:\n",
    "    1. Technical Indicators: True Range (TR), ATR, and ATRP.\n",
    "    2. Data Quality Metrics: Rolling stale percentage, median dollar volume, etc.\n",
    "\n",
    "    Args:\n",
    "        df_ohlcv: The primary DataFrame with a (Ticker, Date) MultiIndex and\n",
    "                  columns for 'Adj High', 'Adj Low', 'Adj Close', 'Volume'.\n",
    "        atr_period: The lookback period for the ATR's Exponential Moving Average.\n",
    "        quality_window: The rolling window size for data quality metrics.\n",
    "        quality_min_periods: The minimum number of observations required to have\n",
    "                             a valid quality metric.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame with the same (Ticker, Date) MultiIndex containing all\n",
    "        calculated feature columns.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Feature Generation ---\")\n",
    "    \n",
    "    # Ensure the DataFrame is sorted for correct window and shift operations\n",
    "    # FIX: Replaced is_lexsorted() with the current pandas attribute\n",
    "    if not df_ohlcv.index.is_monotonic_increasing:\n",
    "        print(\"Sorting index for calculation accuracy...\")\n",
    "        df_ohlcv = df_ohlcv.sort_index()\n",
    "\n",
    "    # --- 1. Technical Indicator Calculation (TR, ATR, ATRP) ---\n",
    "    print(f\"Calculating technical indicators (ATR Period: {atr_period})...\")\n",
    "    \n",
    "    # Group by ticker to handle each security independently\n",
    "    grouped = df_ohlcv.groupby(level='Ticker')\n",
    "    \n",
    "    # Get the previous day's close required for True Range\n",
    "    prev_close = grouped['Adj Close'].shift(1)\n",
    "    \n",
    "    # Calculate the three components of True Range\n",
    "    high_low = df_ohlcv['Adj High'] - df_ohlcv['Adj Low']\n",
    "    high_prev_close = abs(df_ohlcv['Adj High'] - prev_close)\n",
    "    low_prev_close = abs(df_ohlcv['Adj Low'] - prev_close)\n",
    "    \n",
    "    # Combine the components to get the final TR\n",
    "    tr = pd.concat([high_low, high_prev_close, low_prev_close], axis=1).max(axis=1, skipna=False)\n",
    "    \n",
    "    # # Calculate the ATR using an Exponential Moving Average\n",
    "    # --- FIX IS HERE ---\n",
    "    # Use .transform() to apply the EWM function. \n",
    "    # This guarantees the resulting Series has the exact same index as 'tr',\n",
    "    # preventing the index alignment error during the subsequent division.\n",
    "    atr = tr.groupby(level='Ticker').transform(\n",
    "        lambda x: x.ewm(alpha=1/atr_period, adjust=False).mean()\n",
    "    )\n",
    "\n",
    "    # --- CHANGE 1: Removed .fillna(0) ---\n",
    "    # ATRP will now be NaN on the first day, consistent with TR and ATR.\n",
    "    atrp = (atr / df_ohlcv['Adj Close']).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    indicator_df = pd.DataFrame({\n",
    "        'TR': tr,\n",
    "        'ATR': atr,\n",
    "        'ATRP': atrp\n",
    "    })\n",
    "    \n",
    "    # --- 2. Data Quality Metric Calculation ---\n",
    "    print(f\"Calculating data quality metrics (Window: {quality_window} days)...\")\n",
    "    \n",
    "    # Create intermediate flags needed for quality calculations\n",
    "    is_stale = np.where((df_ohlcv['Volume'] == 0) | (df_ohlcv['Adj High'] == df_ohlcv['Adj Low']), 1, 0)\n",
    "    dollar_volume = df_ohlcv['Adj Close'] * df_ohlcv['Volume']\n",
    "    has_same_volume = (grouped['Volume'].diff() == 0).astype(int)\n",
    "    \n",
    "    # Combine flags into a temporary DataFrame for rolling calculations\n",
    "    quality_temp_df = pd.DataFrame({\n",
    "        'IsStale': is_stale,\n",
    "        'DollarVolume': dollar_volume,\n",
    "        'HasSameVolume': has_same_volume\n",
    "    }, index=df_ohlcv.index) # Explicitly set index to be safe\n",
    "    \n",
    "    # Perform the rolling calculations on the grouped data\n",
    "    # --- FIX IS HERE ---\n",
    "    # We switch to the older, more compatible dictionary-based aggregation method.\n",
    "    # This syntax is understood by nearly all versions of pandas.\n",
    "    rolling_result = quality_temp_df.groupby(level='Ticker').rolling(\n",
    "        window=quality_window,\n",
    "        min_periods=quality_min_periods\n",
    "    ).agg({\n",
    "        'IsStale': 'mean',\n",
    "        'DollarVolume': 'median',\n",
    "        'HasSameVolume': 'sum'\n",
    "    })\n",
    "    \n",
    "    # The dictionary syntax produces columns with the original names ('IsStale', etc.).\n",
    "    # We now explicitly rename them to our desired final names.\n",
    "    rolling_result = rolling_result.rename(columns={\n",
    "        'IsStale': 'RollingStalePct',\n",
    "        'DollarVolume': 'RollMedDollarVol', # <-- RENAMED HERE\n",
    "        'HasSameVolume': 'RollingSameVolCount'\n",
    "    })\n",
    "\n",
    "    # The index after a grouped rolling operation is hierarchical.\n",
    "    # We remove the outermost 'Ticker' level to restore the original index structure.\n",
    "    rolling_quality = rolling_result.reset_index(level=0, drop=True)\n",
    "\n",
    "    # --- 3. Combine All Features ---\n",
    "    print(\"Combining all feature sets...\")\n",
    "    features_df = pd.concat([indicator_df, rolling_quality], axis=1)\n",
    "    \n",
    "    print(\"✅ Feature generation complete.\")\n",
    "    return features_df\n",
    "\n",
    "\n",
    "# def get_eligible_universe(features_df, filter_date, thresholds):\n",
    "#     \"\"\"Filters the universe of tickers based on quality metrics for a given date.\"\"\"\n",
    "#     filter_date_ts = pd.to_datetime(filter_date)\n",
    "#     # The index is now the comprehensive features_df\n",
    "#     date_index = features_df.index.get_level_values('Date').unique().sort_values()\n",
    "    \n",
    "#     if filter_date_ts < date_index[0]:\n",
    "#         print(f\"Warning: Filter date {filter_date_ts.date()} is before the earliest data point. Returning empty universe.\")\n",
    "#         return []\n",
    "        \n",
    "#     # Find the most recent date with quality data on or before the filter date\n",
    "#     valid_prior_dates = date_index[date_index <= filter_date_ts]\n",
    "#     if valid_prior_dates.empty:\n",
    "#         print(f\"Warning: No available data found on or before {filter_date_ts.date()}. Returning empty universe.\")\n",
    "#         return []\n",
    "        \n",
    "#     actual_date_to_use = valid_prior_dates[-1]\n",
    "#     if actual_date_to_use.date() != filter_date_ts.date():\n",
    "#         print(f\"ℹ️ Info: Filter date {filter_date_ts.date()} not found. Using previous available date {actual_date_to_use.date()}.\")\n",
    "\n",
    "#     metrics_on_date = features_df.xs(actual_date_to_use, level='Date')\n",
    "    \n",
    "#     # Apply filters using the new column names from features_df\n",
    "#     mask = ((metrics_on_date['RollMedDollarVol'] >= thresholds['min_median_dollar_volume']) & # <-- RENAMED\n",
    "#             (metrics_on_date['RollingStalePct'] <= thresholds['max_stale_pct']) &\n",
    "#             (metrics_on_date['RollingSameVolCount'] <= thresholds['max_same_vol_count']))\n",
    "            \n",
    "#     eligible_tickers = metrics_on_date[mask].index.tolist()\n",
    "#     all_tickers = metrics_on_date.index.tolist()\n",
    "#     print(f\"Dynamic Filter ({filter_date_ts.date()}): Kept {len(eligible_tickers)} of {len(all_tickers)} tickers.\")\n",
    "#     return eligible_tickers\n",
    "\n",
    "\n",
    "# def run_walk_forward_step(df_close_full, df_high_full, df_low_full,\n",
    "#                           master_trading_days,\n",
    "#                           start_date, calc_period, fwd_period,\n",
    "#                           metric, rank_start, rank_end, benchmark_ticker,\n",
    "#                           features_df,\n",
    "#                           debug=False):\n",
    "#     \"\"\"\n",
    "#     Runs a single step of the walk-forward analysis with a strict, pre-emptive\n",
    "#     check to ensure the full period is available.\n",
    "#     \"\"\"\n",
    "#     debug_data = {} if debug else None\n",
    "\n",
    "#     # 1. Determine exact date ranges with a NEW pre-emptive check\n",
    "#     try:\n",
    "#         start_idx = master_trading_days.get_loc(start_date)\n",
    "#     except KeyError:\n",
    "#         return ({'error': f\"Start date {start_date.date()} is not a valid trading day.\"}, None)\n",
    "\n",
    "#     # +++ THIS IS THE NEW PRE-EMPTIVE CHECK LOGIC +++\n",
    "#     # Calculate the desired end index without clamping first.\n",
    "#     desired_viz_end_idx = start_idx + calc_period + fwd_period\n",
    "    \n",
    "#     # Check if the desired end index is out of bounds.\n",
    "#     if desired_viz_end_idx >= len(master_trading_days):\n",
    "#         last_available_date = master_trading_days[-1].date()\n",
    "#         required_days = calc_period + fwd_period\n",
    "#         available_days = len(master_trading_days) - start_idx\n",
    "#         error_msg = (f\"Not enough data for the full requested period. \"\n",
    "#                      f\"Required: {required_days} days, Available: {available_days} days until {last_available_date}.\")\n",
    "#         return ({'error': error_msg}, None)\n",
    "#     # --- END OF NEW CHECK ---\n",
    "\n",
    "#     # If the check passes, we know the full period is available.\n",
    "#     # The 'min' calls are now just a redundant safety measure.\n",
    "#     calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "#     viz_end_idx = min(calc_end_idx + fwd_period, len(master_trading_days) - 1)\n",
    "\n",
    "#     safe_start_date = master_trading_days[start_idx]\n",
    "#     safe_calc_end_date = master_trading_days[calc_end_idx]\n",
    "#     safe_viz_end_date = master_trading_days[viz_end_idx]\n",
    "    \n",
    "#     if safe_start_date >= safe_calc_end_date:\n",
    "#         return ({'error': \"Invalid date range (calc period has zero or negative length).\"}, None)\n",
    "\n",
    "#     # (The rest of the function remains completely unchanged...)\n",
    "#     # 2. Slice data for the calculation period\n",
    "#     calc_close_raw = df_close_full.loc[safe_start_date:safe_calc_end_date]\n",
    "#     calc_close = calc_close_raw.dropna(axis=1, how='all')\n",
    "#     if calc_close.shape[1] == 0 or len(calc_close) < 2:\n",
    "#         return ({'error': \"Not enough data in calc period.\"}, None)\n",
    "\n",
    "#     # 3. Calculate INTERMEDIATE data required for the ranking metrics\n",
    "#     daily_returns = calc_close.bfill().ffill().pct_change()\n",
    "#     valid_tickers = calc_close.columns\n",
    "#     calc_period_index = pd.MultiIndex.from_product([valid_tickers, calc_close.index], names=['Ticker', 'Date'])\n",
    "#     features_in_period = features_df.loc[features_df.index.intersection(calc_period_index)]\n",
    "#     atrp = features_in_period.groupby(level='Ticker')['ATRP'].mean()\n",
    "\n",
    "#     # 4. Calculate all ranking metrics by iterating through the METRIC_REGISTRY\n",
    "#     metric_ingredients = { 'calc_close': calc_close, 'daily_returns': daily_returns, 'atrp': atrp, }\n",
    "#     metric_values = {}\n",
    "#     for name, func in METRIC_REGISTRY.items():\n",
    "#         metric_values[name] = func(metric_ingredients)\n",
    "#     if metric not in metric_values or metric_values[metric].empty:\n",
    "#         return ({'error': f\"Metric '{metric}' could not be calculated or resulted in no valid tickers.\"}, None)\n",
    "\n",
    "#     # 5. Rank tickers and select the portfolio\n",
    "#     sorted_tickers = metric_values[metric].sort_values(ascending=False)\n",
    "#     tickers_to_display = sorted_tickers.index[rank_start-1:rank_end].tolist()\n",
    "#     if not tickers_to_display:\n",
    "#         return ({'error': \"No tickers found for the selected rank.\"}, None)\n",
    "\n",
    "#     # 6. Calculate Portfolio & Benchmark Performance\n",
    "#     normalized_plot_data = df_close_full[tickers_to_display].loc[safe_start_date:safe_viz_end_date]\n",
    "#     normalized_plot_data = normalized_plot_data.div(normalized_plot_data.bfill().iloc[0])\n",
    "#     actual_calc_end_ts = calc_close.index.max()\n",
    "#     portfolio_series = normalized_plot_data.mean(axis=1)\n",
    "#     portfolio_return_series = portfolio_series.pct_change()\n",
    "#     benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "#     benchmark_return_series = benchmark_price_series.loc[safe_start_date:safe_viz_end_date].bfill().ffill().pct_change() if benchmark_price_series is not None else pd.Series(dtype='float64')\n",
    "#     try:\n",
    "#         boundary_loc = portfolio_return_series.index.get_loc(actual_calc_end_ts)\n",
    "#         calc_portfolio_returns = portfolio_return_series.iloc[:boundary_loc + 1]\n",
    "#         fwd_portfolio_returns = portfolio_return_series.iloc[boundary_loc + 1:]\n",
    "#         if benchmark_price_series is not None:\n",
    "#             bm_boundary_loc = benchmark_return_series.index.get_loc(actual_calc_end_ts)\n",
    "#             calc_benchmark_returns = benchmark_return_series.iloc[:bm_boundary_loc + 1]\n",
    "#             fwd_benchmark_returns = benchmark_return_series.iloc[bm_boundary_loc + 1:]\n",
    "#         else:\n",
    "#             calc_benchmark_returns, fwd_benchmark_returns = pd.Series(dtype='float64'), pd.Series(dtype='float64')\n",
    "#     except (KeyError, IndexError):\n",
    "#         calc_portfolio_returns = portfolio_return_series.loc[:actual_calc_end_ts]\n",
    "#         fwd_portfolio_returns = portfolio_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "#         if benchmark_price_series is not None:\n",
    "#             calc_benchmark_returns = benchmark_return_series.loc[:actual_calc_end_ts]\n",
    "#             fwd_benchmark_returns = benchmark_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "#         else:\n",
    "#             calc_benchmark_returns, fwd_benchmark_returns = pd.Series(dtype='float64'), pd.Series(dtype='float64')\n",
    "#     full_period_index = pd.MultiIndex.from_product([tickers_to_display, portfolio_return_series.index], names=['Ticker', 'Date'])\n",
    "#     portfolio_atrp_features = features_df.loc[features_df.index.intersection(full_period_index)]\n",
    "#     portfolio_atrp_daily_unstacked = portfolio_atrp_features['ATRP'].unstack(level='Ticker')\n",
    "#     portfolio_atrp_series = portfolio_atrp_daily_unstacked.mean(axis=1)\n",
    "#     if benchmark_ticker in df_close_full.columns:\n",
    "#         benchmark_atrp_series = features_df.xs(benchmark_ticker, level='Ticker')['ATRP'].loc[safe_start_date:safe_viz_end_date]\n",
    "#     else:\n",
    "#         benchmark_atrp_series = pd.Series(dtype='float64')\n",
    "#     calc_portfolio_atrp = portfolio_atrp_series.loc[:actual_calc_end_ts]\n",
    "#     fwd_portfolio_atrp = portfolio_atrp_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "#     calc_benchmark_atrp = benchmark_atrp_series.loc[:actual_calc_end_ts]\n",
    "#     fwd_benchmark_atrp = benchmark_atrp_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "#     perf_data = {}\n",
    "#     perf_data['calc_p_gain'] = calculate_gain(portfolio_series.loc[:actual_calc_end_ts])\n",
    "#     perf_data['fwd_p_gain'] = calculate_gain(portfolio_series.loc[actual_calc_end_ts:])\n",
    "#     perf_data['full_p_gain'] = calculate_gain(portfolio_series)\n",
    "#     perf_data['calc_p_sharpe'] = calculate_sharpe(calc_portfolio_returns)\n",
    "#     perf_data['fwd_p_sharpe'] = calculate_sharpe(fwd_portfolio_returns)\n",
    "#     perf_data['full_p_sharpe'] = calculate_sharpe(portfolio_return_series)\n",
    "#     perf_data['calc_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:actual_calc_end_ts]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['fwd_b_gain'] = calculate_gain(benchmark_price_series.loc[actual_calc_end_ts:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['full_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['calc_b_sharpe'] = calculate_sharpe(calc_benchmark_returns)\n",
    "#     perf_data['fwd_b_sharpe'] = calculate_sharpe(fwd_benchmark_returns)\n",
    "#     perf_data['full_b_sharpe'] = calculate_sharpe(benchmark_return_series)\n",
    "#     perf_data['calc_p_sharpe_atr'] = calculate_sharpe_atr(calc_portfolio_returns, calc_portfolio_atrp)\n",
    "#     perf_data['fwd_p_sharpe_atr'] = calculate_sharpe_atr(fwd_portfolio_returns, fwd_portfolio_atrp)\n",
    "#     perf_data['full_p_sharpe_atr'] = calculate_sharpe_atr(portfolio_return_series, portfolio_atrp_series)\n",
    "#     perf_data['calc_b_sharpe_atr'] = calculate_sharpe_atr(calc_benchmark_returns, calc_benchmark_atrp)\n",
    "#     perf_data['fwd_b_sharpe_atr'] = calculate_sharpe_atr(fwd_benchmark_returns, fwd_benchmark_atrp)\n",
    "#     perf_data['full_b_sharpe_atr'] = calculate_sharpe_atr(benchmark_return_series, benchmark_atrp_series)\n",
    "#     if debug:\n",
    "#         df_ranking_base = pd.DataFrame({'MeanDailyReturn': daily_returns.mean(),'StdDevDailyReturn': daily_returns.std(),'MeanATRP': atrp})\n",
    "#         df_metrics = pd.DataFrame(metric_values)\n",
    "#         df_metrics.columns = [f'Metric_{col}' for col in df_metrics.columns]\n",
    "#         df_ranking = df_ranking_base.join(df_metrics, how='left')\n",
    "#         df_ranking.index.name = 'Ticker'\n",
    "#         debug_data['ranking_metrics'] = df_ranking.sort_values(f'Metric_{metric}', ascending=False)\n",
    "#     calc_end_prices = calc_close.ffill().iloc[-1]\n",
    "#     fwd_close_slice = df_close_full.loc[actual_calc_end_ts:safe_viz_end_date]\n",
    "#     viz_end_prices = fwd_close_slice.ffill().iloc[-1] if not fwd_close_slice.empty and len(fwd_close_slice) >= 2 else calc_end_prices\n",
    "#     calc_gains = (calc_end_prices / calc_close.bfill().iloc[0]) - 1\n",
    "#     fwd_gains = (viz_end_prices / calc_end_prices) - 1\n",
    "#     results_df = pd.DataFrame({'Rank': range(rank_start, rank_start + len(tickers_to_display)), 'Metric': metric, 'MetricValue': sorted_tickers.loc[tickers_to_display].values, 'CalcPrice': calc_end_prices.loc[tickers_to_display], 'CalcGain': calc_gains.loc[tickers_to_display], 'FwdGain': fwd_gains.loc[tickers_to_display]}, index=pd.Index(tickers_to_display, name='Ticker'))\n",
    "#     if benchmark_price_series is not None and benchmark_ticker in calc_close.columns:\n",
    "#         benchmark_df_row = pd.DataFrame({'Rank': np.nan, 'Metric': metric, 'MetricValue': metric_values[metric].get(benchmark_ticker, np.nan), 'CalcPrice': calc_end_prices[benchmark_ticker], 'CalcGain': calc_gains[benchmark_ticker], 'FwdGain': fwd_gains[benchmark_ticker]}, index=pd.Index([f\"{benchmark_ticker} (BM)\"], name='Ticker'))\n",
    "#         results_df = pd.concat([results_df, benchmark_df_row])\n",
    "#     if debug:\n",
    "#         df_trace = normalized_plot_data.copy()\n",
    "#         df_trace.columns = [f'Norm_Price_{c}' for c in df_trace.columns]\n",
    "#         df_trace['Norm_Price_Portfolio'] = portfolio_series\n",
    "#         if benchmark_price_series is not None and not benchmark_price_series.loc[safe_start_date:safe_viz_end_date].dropna().empty:\n",
    "#             norm_bm = benchmark_price_series.loc[safe_start_date:safe_viz_end_date] / benchmark_price_series.loc[safe_start_date:].bfill().iloc[0]\n",
    "#             df_trace[f'Norm_Price_Benchmark_{benchmark_ticker}'] = norm_bm\n",
    "#         for col in df_trace.columns:\n",
    "#             if 'Norm_Price' in col:\n",
    "#                 df_trace[col.replace('Norm_Price', 'Return')] = df_trace[col].pct_change()\n",
    "#         debug_data['portfolio_trace'] = df_trace\n",
    "#     final_results = {\n",
    "#         'tickers_to_display': tickers_to_display, 'normalized_plot_data': normalized_plot_data,\n",
    "#         'portfolio_series': portfolio_series, 'benchmark_price_series': benchmark_price_series,\n",
    "#         'performance_data': perf_data, 'results_df': results_df, 'actual_calc_end_ts': actual_calc_end_ts,\n",
    "#         'safe_start_date': safe_start_date, 'safe_viz_end_date': safe_viz_end_date,\n",
    "#         'error': None\n",
    "#     }\n",
    "#     return (final_results, debug_data)\n",
    "\n",
    "def verify_sharpe_atr_calculation_checked(df_ohlcv, features_df, tickers_to_verify, benchmark_ticker,\n",
    "                                    start_date, calc_period, fwd_period,\n",
    "                                    master_calendar_ticker='VOO', debug=False):\n",
    "    \"\"\"\n",
    "    Verifies the Sharpe (ATR) calculations for a portfolio and benchmark.\n",
    "\n",
    "    This function transparently recalculates the key components for Sharpe (ATR)\n",
    "    and can optionally export the underlying source data for manual inspection.\n",
    "    \"\"\"\n",
    "    display(Markdown(f\"## Verification Report for Sharpe (ATR) Calculation\"))\n",
    "    display(Markdown(f\"**Portfolio Tickers:** `{tickers_to_verify}`\\n**Benchmark Ticker:** `{benchmark_ticker}`\"))\n",
    "\n",
    "    # --- 1. Determine Exact Period Dates (No changes here) ---\n",
    "    master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "    start_date_raw = pd.to_datetime(start_date)\n",
    "    start_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "    actual_start_date = master_trading_days[start_idx]\n",
    "    calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "    fwd_end_idx = min(calc_end_idx + fwd_period, len(master_trading_days) - 1)\n",
    "    actual_calc_end_date = master_trading_days[calc_end_idx]\n",
    "    actual_fwd_end_date = master_trading_days[fwd_end_idx]\n",
    "    \n",
    "    display(Markdown(f\"**Full Period:** `{actual_start_date.date()}` to `{actual_fwd_end_date.date()}`\\n\"\n",
    "                    f\"**Calc End Date:** `{actual_calc_end_date.date()}`\"))\n",
    "\n",
    "    # Original debug export block (can be kept or removed)\n",
    "    if debug:\n",
    "        # ... (original export code remains here) ...\n",
    "        pass # Assuming original block is here\n",
    "\n",
    "    # --- 2. Recreate Portfolio & Benchmark Series from Scratch ---\n",
    "    df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "    portfolio_prices_raw = df_close_full[tickers_to_verify].loc[actual_start_date:actual_fwd_end_date]\n",
    "    portfolio_prices_norm = portfolio_prices_raw.div(portfolio_prices_raw.bfill().iloc[0])\n",
    "    portfolio_value_series = portfolio_prices_norm.mean(axis=1)\n",
    "    portfolio_return_series = portfolio_value_series.pct_change()\n",
    "    p_idx = pd.MultiIndex.from_product([tickers_to_verify, portfolio_return_series.index])\n",
    "    p_atrp_df = features_df.loc[features_df.index.intersection(p_idx)]['ATRP'].unstack(level=0)\n",
    "    portfolio_atrp_series = p_atrp_df.mean(axis=1)\n",
    "\n",
    "###############################    \n",
    "    # benchmark_return_series = df_close_full[benchmark_ticker].pct_change().loc[actual_start_date:actual_fwd_end_date]\n",
    "\n",
    "    # 1. First, slice the raw prices for the desired date range.\n",
    "    benchmark_prices_raw = df_close_full[benchmark_ticker].loc[actual_start_date:actual_fwd_end_date]\n",
    "    # 2. Then, calculate the percentage change on the sliced data.\n",
    "    benchmark_return_series = benchmark_prices_raw.pct_change()\n",
    "\n",
    "###############################    \n",
    "    benchmark_atrp_series = features_df.xs(benchmark_ticker, level='Ticker')['ATRP'].loc[actual_start_date:actual_fwd_end_date]\n",
    "\n",
    "\n",
    "    # +++ NEW: DETAILED RETURN CALCULATION TRACE (PORTFOLIO) +++\n",
    "    if debug:\n",
    "        display(Markdown(\"---\"))\n",
    "        display(Markdown(\"### 🐛 Detailed Portfolio Return Calculation Trace\"))\n",
    "\n",
    "        # Step 1: Show the raw prices being used\n",
    "        print(\"\\n[STEP 1] Raw Adjusted Close prices used for calculation.\")\n",
    "        print(\"Compare these values with your 'Adj Close' columns.\")\n",
    "        display(portfolio_prices_raw)\n",
    "\n",
    "        # Step 2: Show the normalization base and the result\n",
    "        normalization_base = portfolio_prices_raw.bfill().iloc[0]\n",
    "        print(\"\\n[STEP 2] Normalization base (first row of prices).\")\n",
    "        print(\"Each column in Step 1 is divided by this corresponding value.\")\n",
    "        display(pd.DataFrame(normalization_base).T)\n",
    "\n",
    "        print(\"\\n[STEP 2a] Normalized prices (Result of division).\")\n",
    "        print(\"Compare these values with your 'N Close' columns.\")\n",
    "        display(portfolio_prices_norm)\n",
    "\n",
    "        # Step 3: Show the averaged portfolio value series\n",
    "        print(\"\\n[STEP 3] Averaged normalized portfolio value series.\")\n",
    "        print(\"This is the row-by-row average of the table in Step 2a.\")\n",
    "        print(\"Compare this series with your 'N_portf' column.\")\n",
    "        display(pd.DataFrame(portfolio_value_series, columns=['N_portf']))\n",
    "\n",
    "        # Step 4: Show the final portfolio return series\n",
    "        print(\"\\n[STEP 4] Final portfolio daily return series (pct_change).\")\n",
    "        print(\"This is the percentage change of the series in Step 3.\")\n",
    "        print(\"Compare this series with your 'N_portf_rtn' column.\")\n",
    "        display(pd.DataFrame(portfolio_return_series, columns=['N_portf_rtn']))\n",
    "        display(Markdown(\"---\"))\n",
    "    # +++ END OF NEW DEBUG BLOCK +++\n",
    "\n",
    "\n",
    "    # --- 3. Define a Helper to Print Detailed Calculation Steps ---\n",
    "    # MODIFIED to include more debug details inside\n",
    "    def _calculate_and_print_metrics(period_name, returns, atrps):\n",
    "        display(Markdown(f\"#### {period_name}\"))\n",
    "        if returns.dropna().empty or atrps.dropna().empty:\n",
    "            print(\"  - Not enough data to calculate.\")\n",
    "            return np.nan\n",
    "\n",
    "        # Standard calculations\n",
    "        mean_return = returns.mean()\n",
    "        mean_atrp = atrps.mean()\n",
    "        sharpe_atr = mean_return / mean_atrp if mean_atrp > 0 else np.nan\n",
    "\n",
    "        # +++ ADDED: Detailed Mean Calculation Breakdown +++\n",
    "        if debug:\n",
    "            valid_returns = returns.dropna()\n",
    "            num_returns = valid_returns.count()\n",
    "            sum_returns = valid_returns.sum()\n",
    "            manual_mean = sum_returns / num_returns if num_returns > 0 else 0\n",
    "            print(f\"  - (Debug) Number of valid daily returns: {num_returns}\")\n",
    "            print(f\"  - (Debug) Sum of all daily returns:      {sum_returns:,.8f}\")\n",
    "            print(f\"  - (Debug) Manually calculated mean:      {manual_mean:,.8f} (Sum / Count)\")\n",
    "        # +++ END OF ADDED DETAIL +++\n",
    "\n",
    "        print(f\"  - Mean Daily Return: {mean_return:,.6f}\")\n",
    "        print(f\"  - Mean Daily ATRP:  {mean_atrp:,.6f}\")\n",
    "        print(f\"  - Sharpe (ATR) = (Mean Return / Mean ATRP) = {sharpe_atr:,.4f}\")\n",
    "        return sharpe_atr\n",
    "\n",
    "    # --- 4. Run Verification for Portfolio (No changes here) ---\n",
    "    display(Markdown(\"### A. Group Portfolio Verification\"))\n",
    "    _calculate_and_print_metrics(\"Full Period\", portfolio_return_series, portfolio_atrp_series)\n",
    "    _calculate_and_print_metrics(\"Calculation Period\", portfolio_return_series.loc[:actual_calc_end_date], portfolio_atrp_series.loc[:actual_calc_end_date])\n",
    "    _calculate_and_print_metrics(\"Forward Period\", portfolio_return_series.loc[actual_calc_end_date:].iloc[1:], portfolio_atrp_series.loc[actual_calc_end_date:].iloc[1:])\n",
    "\n",
    "    # --- 5. Run Verification for Benchmark (No changes here) ---\n",
    "    display(Markdown(f\"### B. Benchmark ({benchmark_ticker}) Verification\"))\n",
    "    _calculate_and_print_metrics(\"Full Period\", benchmark_return_series, benchmark_atrp_series)\n",
    "    _calculate_and_print_metrics(\"Calculation Period\", benchmark_return_series.loc[:actual_calc_end_date], benchmark_atrp_series.loc[:actual_calc_end_date])\n",
    "    _calculate_and_print_metrics(\"Forward Period\", benchmark_return_series.loc[actual_calc_end_date:].iloc[1:], benchmark_atrp_series.loc[actual_calc_end_date:].iloc[1:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5c908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume 'df_ohlcv' is your loaded dataset\n",
    "# You might need to regenerate features_df if it's not in your notebook's memory\n",
    "print(\"--- Regenerating features for verification ---\")\n",
    "features_df = generate_features(df_ohlcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af59dfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_to_verify = ['STIP', 'RCL']\n",
    "start_date = '2025-08-13'\n",
    "end_date = '2025-09-04'\n",
    "benchmark_ticker = 'VOO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a7a71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_sharpe_atr_calculation_checked(df_ohlcv, features_df, tickers_to_verify, benchmark_ticker,\n",
    "                                    start_date, calc_period, fwd_period,\n",
    "                                    master_calendar_ticker='VOO', debug=False):\n",
    "    \"\"\"\n",
    "    Verifies the Sharpe (ATR) calculations for a portfolio and benchmark.\n",
    "\n",
    "    This function transparently recalculates the key components for Sharpe (ATR)\n",
    "    and can optionally export the underlying source data for manual inspection.\n",
    "    \"\"\"\n",
    "    display(Markdown(f\"## Verification Report for Sharpe (ATR) Calculation\"))\n",
    "    display(Markdown(f\"**Portfolio Tickers:** `{tickers_to_verify}`\\n**Benchmark Ticker:** `{benchmark_ticker}`\"))\n",
    "\n",
    "    # --- 1. Determine Exact Period Dates (No changes here) ---\n",
    "    master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "    start_date_raw = pd.to_datetime(start_date)\n",
    "    start_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "    actual_start_date = master_trading_days[start_idx]\n",
    "    calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "    fwd_end_idx = min(calc_end_idx + fwd_period, len(master_trading_days) - 1)\n",
    "    actual_calc_end_date = master_trading_days[calc_end_idx]\n",
    "    actual_fwd_end_date = master_trading_days[fwd_end_idx]\n",
    "    \n",
    "    display(Markdown(f\"**Full Period:** `{actual_start_date.date()}` to `{actual_fwd_end_date.date()}`\\n\"\n",
    "                    f\"**Calc End Date:** `{actual_calc_end_date.date()}`\"))\n",
    "\n",
    "    # Original debug export block (can be kept or removed)\n",
    "    if debug:\n",
    "        # ... (original export code remains here) ...\n",
    "        pass # Assuming original block is here\n",
    "\n",
    "    # --- 2. Recreate Portfolio & Benchmark Series from Scratch ---\n",
    "    df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "    portfolio_prices_raw = df_close_full[tickers_to_verify].loc[actual_start_date:actual_fwd_end_date]\n",
    "    portfolio_prices_norm = portfolio_prices_raw.div(portfolio_prices_raw.bfill().iloc[0])\n",
    "    portfolio_value_series = portfolio_prices_norm.mean(axis=1)\n",
    "    portfolio_return_series = portfolio_value_series.pct_change()\n",
    "    p_idx = pd.MultiIndex.from_product([tickers_to_verify, portfolio_return_series.index])\n",
    "    p_atrp_df = features_df.loc[features_df.index.intersection(p_idx)]['ATRP'].unstack(level=0)\n",
    "    portfolio_atrp_series = p_atrp_df.mean(axis=1)\n",
    "\n",
    "###############################    \n",
    "    # benchmark_return_series = df_close_full[benchmark_ticker].pct_change().loc[actual_start_date:actual_fwd_end_date]\n",
    "\n",
    "    # 1. First, slice the raw prices for the desired date range.\n",
    "    benchmark_prices_raw = df_close_full[benchmark_ticker].loc[actual_start_date:actual_fwd_end_date]\n",
    "    # 2. Then, calculate the percentage change on the sliced data.\n",
    "    benchmark_return_series = benchmark_prices_raw.pct_change()\n",
    "\n",
    "###############################    \n",
    "    benchmark_atrp_series = features_df.xs(benchmark_ticker, level='Ticker')['ATRP'].loc[actual_start_date:actual_fwd_end_date]\n",
    "\n",
    "\n",
    "    # +++ NEW: DETAILED RETURN CALCULATION TRACE (PORTFOLIO) +++\n",
    "    if debug:\n",
    "        display(Markdown(\"---\"))\n",
    "        display(Markdown(\"### 🐛 Detailed Portfolio Return Calculation Trace\"))\n",
    "\n",
    "        # Step 1: Show the raw prices being used\n",
    "        print(\"\\n[STEP 1] Raw Adjusted Close prices used for calculation.\")\n",
    "        print(\"Compare these values with your 'Adj Close' columns.\")\n",
    "        display(portfolio_prices_raw)\n",
    "\n",
    "        # Step 2: Show the normalization base and the result\n",
    "        normalization_base = portfolio_prices_raw.bfill().iloc[0]\n",
    "        print(\"\\n[STEP 2] Normalization base (first row of prices).\")\n",
    "        print(\"Each column in Step 1 is divided by this corresponding value.\")\n",
    "        display(pd.DataFrame(normalization_base).T)\n",
    "\n",
    "        print(\"\\n[STEP 2a] Normalized prices (Result of division).\")\n",
    "        print(\"Compare these values with your 'N Close' columns.\")\n",
    "        display(portfolio_prices_norm)\n",
    "\n",
    "        # Step 3: Show the averaged portfolio value series\n",
    "        print(\"\\n[STEP 3] Averaged normalized portfolio value series.\")\n",
    "        print(\"This is the row-by-row average of the table in Step 2a.\")\n",
    "        print(\"Compare this series with your 'N_portf' column.\")\n",
    "        display(pd.DataFrame(portfolio_value_series, columns=['N_portf']))\n",
    "\n",
    "        # Step 4: Show the final portfolio return series\n",
    "        print(\"\\n[STEP 4] Final portfolio daily return series (pct_change).\")\n",
    "        print(\"This is the percentage change of the series in Step 3.\")\n",
    "        print(\"Compare this series with your 'N_portf_rtn' column.\")\n",
    "        display(pd.DataFrame(portfolio_return_series, columns=['N_portf_rtn']))\n",
    "        display(Markdown(\"---\"))\n",
    "    # +++ END OF NEW DEBUG BLOCK +++\n",
    "\n",
    "\n",
    "    # --- 3. Define a Helper to Print Detailed Calculation Steps ---\n",
    "    # MODIFIED to include more debug details inside\n",
    "    def _calculate_and_print_metrics(period_name, returns, atrps):\n",
    "        display(Markdown(f\"#### {period_name}\"))\n",
    "        if returns.dropna().empty or atrps.dropna().empty:\n",
    "            print(\"  - Not enough data to calculate.\")\n",
    "            return np.nan\n",
    "\n",
    "        # Standard calculations\n",
    "        mean_return = returns.mean()\n",
    "        mean_atrp = atrps.mean()\n",
    "        sharpe_atr = mean_return / mean_atrp if mean_atrp > 0 else np.nan\n",
    "\n",
    "        # +++ ADDED: Detailed Mean Calculation Breakdown +++\n",
    "        if debug:\n",
    "            valid_returns = returns.dropna()\n",
    "            num_returns = valid_returns.count()\n",
    "            sum_returns = valid_returns.sum()\n",
    "            manual_mean = sum_returns / num_returns if num_returns > 0 else 0\n",
    "            print(f\"  - (Debug) Number of valid daily returns: {num_returns}\")\n",
    "            print(f\"  - (Debug) Sum of all daily returns:      {sum_returns:,.8f}\")\n",
    "            print(f\"  - (Debug) Manually calculated mean:      {manual_mean:,.8f} (Sum / Count)\")\n",
    "        # +++ END OF ADDED DETAIL +++\n",
    "\n",
    "        print(f\"  - Mean Daily Return: {mean_return:,.6f}\")\n",
    "        print(f\"  - Mean Daily ATRP:  {mean_atrp:,.6f}\")\n",
    "        print(f\"  - Sharpe (ATR) = (Mean Return / Mean ATRP) = {sharpe_atr:,.4f}\")\n",
    "        return sharpe_atr\n",
    "\n",
    "    # --- 4. Run Verification for Portfolio (No changes here) ---\n",
    "    display(Markdown(\"### A. Group Portfolio Verification\"))\n",
    "    _calculate_and_print_metrics(\"Full Period\", portfolio_return_series, portfolio_atrp_series)\n",
    "    _calculate_and_print_metrics(\"Calculation Period\", portfolio_return_series.loc[:actual_calc_end_date], portfolio_atrp_series.loc[:actual_calc_end_date])\n",
    "    _calculate_and_print_metrics(\"Forward Period\", portfolio_return_series.loc[actual_calc_end_date:].iloc[1:], portfolio_atrp_series.loc[actual_calc_end_date:].iloc[1:])\n",
    "\n",
    "    # --- 5. Run Verification for Benchmark (No changes here) ---\n",
    "    display(Markdown(f\"### B. Benchmark ({benchmark_ticker}) Verification\"))\n",
    "    _calculate_and_print_metrics(\"Full Period\", benchmark_return_series, benchmark_atrp_series)\n",
    "    _calculate_and_print_metrics(\"Calculation Period\", benchmark_return_series.loc[:actual_calc_end_date], benchmark_atrp_series.loc[:actual_calc_end_date])\n",
    "    _calculate_and_print_metrics(\"Forward Period\", benchmark_return_series.loc[actual_calc_end_date:].iloc[1:], benchmark_atrp_series.loc[actual_calc_end_date:].iloc[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0d9bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now call the verification function with the exact parameters from the UI\n",
    "verify_sharpe_atr_calculation_checked(\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    features_df=features_df,\n",
    "    tickers_to_verify=tickers_to_verify, # <-- From the UI output\n",
    "    benchmark_ticker=benchmark_ticker,\n",
    "    start_date=start_date,\n",
    "    calc_period=10,\n",
    "    fwd_period=5,\n",
    "    debug=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18caedd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets\n",
    "import pprint\n",
    "from IPython.display import display, Markdown\n",
    "import os # Make sure os is imported for the export function later\n",
    "\n",
    "\n",
    "# def calculate_gain(price_series: pd.Series):\n",
    "#     \"\"\"Calculates the total gain over a series of prices.\"\"\"\n",
    "#     # Ensure there are at least two data points to calculate a gain\n",
    "#     if price_series.dropna().shape[0] < 2: return np.nan\n",
    "#     # Use forward-fill for the end price and back-fill for the start price\n",
    "#     # to handle potential NaNs at the beginning or end of the series.\n",
    "#     return (price_series.ffill().iloc[-1] / price_series.bfill().iloc[0]) - 1\n",
    "\n",
    "# def calculate_sharpe(return_series: pd.Series):\n",
    "#     \"\"\"Calculates the annualized Sharpe ratio from a series of daily returns.\"\"\"\n",
    "#     # Ensure there are at least two returns to calculate a standard deviation\n",
    "#     if return_series.dropna().shape[0] < 2: return np.nan\n",
    "#     std_dev = return_series.std()\n",
    "#     # Avoid division by zero if returns are constant\n",
    "#     if std_dev > 0 and std_dev != np.inf:\n",
    "#         return (return_series.mean() / std_dev) * np.sqrt(252)\n",
    "#     return np.nan\n",
    "\n",
    "# def calculate_sharpe_atr(return_series: pd.Series, atrp_series: pd.Series):\n",
    "#     \"\"\"Calculates a Sharpe-like ratio using mean ATRP as the denominator.\"\"\"\n",
    "#     # Ensure there are returns and that ATRP data is valid\n",
    "#     if return_series.dropna().shape[0] < 2 or atrp_series.dropna().empty:\n",
    "#         return np.nan\n",
    "        \n",
    "#     mean_return = return_series.mean()\n",
    "#     mean_atrp = atrp_series.mean()\n",
    "    \n",
    "#     # Avoid division by zero\n",
    "#     if mean_atrp > 0 and mean_atrp != np.inf:\n",
    "#         return mean_return / mean_atrp\n",
    "        \n",
    "#     return np.nan\n",
    "\n",
    "\n",
    "# # --- B. MODULAR METRIC CALCULATION ENGINE ---\n",
    "\n",
    "# def calculate_price_metric(metric_data: dict) -> pd.Series:\n",
    "#     \"\"\"\n",
    "#     Calculates the 'Price' metric (total gain) over the calculation period.\n",
    "\n",
    "#     Args:\n",
    "#         metric_data: A dictionary containing pre-calculated data Series.\n",
    "#                      Requires 'calc_close' (pd.DataFrame): The close prices for the calc period.\n",
    "\n",
    "#     Returns:\n",
    "#         A pandas Series of the calculated metric values, indexed by Ticker.\n",
    "#     \"\"\"\n",
    "#     calc_close = metric_data['calc_close']\n",
    "    \n",
    "#     # Ensure there are at least two data points to calculate a gain\n",
    "#     if len(calc_close) < 2:\n",
    "#         return pd.Series(dtype='float64', index=calc_close.columns)\n",
    "\n",
    "#     first_prices = calc_close.bfill().iloc[0]\n",
    "#     last_prices = calc_close.ffill().iloc[-1]\n",
    "    \n",
    "#     # The division of two Series aligns by index (Ticker), which is what we want.\n",
    "#     price_metric = last_prices / first_prices\n",
    "    \n",
    "#     return price_metric.dropna()\n",
    "\n",
    "# def calculate_sharpe_metric(metric_data: dict) -> pd.Series:\n",
    "#     \"\"\"\n",
    "#     Calculates the annualized 'Sharpe' ratio metric over the calculation period.\n",
    "\n",
    "#     Args:\n",
    "#         metric_data: A dictionary containing pre-calculated data Series.\n",
    "#                      Requires 'daily_returns' (pd.DataFrame): Daily returns for the calc period.\n",
    "\n",
    "#     Returns:\n",
    "#         A pandas Series of the calculated metric values, indexed by Ticker.\n",
    "#     \"\"\"\n",
    "#     daily_returns = metric_data['daily_returns']\n",
    "    \n",
    "#     # Ensure there's enough data to calculate standard deviation\n",
    "#     if len(daily_returns.dropna()) < 2:\n",
    "#         return pd.Series(dtype='float64', index=daily_returns.columns)\n",
    "    \n",
    "#     mean_returns = daily_returns.mean()\n",
    "#     std_returns = daily_returns.std()\n",
    "    \n",
    "#     # Standard annualized Sharpe Ratio calculation. Avoid division by zero.\n",
    "#     # We replace resulting NaNs/infs with 0 to handle cases of zero volatility.\n",
    "#     sharpe_ratio = (mean_returns / std_returns * np.sqrt(252))\n",
    "    \n",
    "#     return sharpe_ratio.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    \n",
    "# def calculate_sharpe_atr_metric(metric_data: dict) -> pd.Series:\n",
    "#     \"\"\"\n",
    "#     Calculates the 'Sharpe (ATR)' metric over the calculation period.\n",
    "\n",
    "#     Args:\n",
    "#         metric_data: A dictionary containing pre-calculated data Series.\n",
    "#                      Requires 'daily_returns' (pd.DataFrame): Daily returns for the calc period.\n",
    "#                      Requires 'atrp' (pd.Series): Mean ATRP for each ticker over the period.\n",
    "\n",
    "#     Returns:\n",
    "#         A pandas Series of the calculated metric values, indexed by Ticker.\n",
    "#     \"\"\"\n",
    "#     daily_returns = metric_data['daily_returns']\n",
    "#     atrp = metric_data['atrp']\n",
    "    \n",
    "#     mean_returns = daily_returns.mean()\n",
    "    \n",
    "#     # ATRP-based Sharpe. Avoid division by zero.\n",
    "#     # We replace resulting NaNs/infs with 0.\n",
    "#     sharpe_atr = mean_returns / atrp\n",
    "    \n",
    "#     return sharpe_atr.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "\n",
    "# METRIC_REGISTRY = {\n",
    "#     'Price': calculate_price_metric,\n",
    "#     'Sharpe': calculate_sharpe_metric,\n",
    "#     'Sharpe (ATR)': calculate_sharpe_atr_metric,\n",
    "# }\n",
    "\n",
    "\n",
    "def plot_walk_forward_analyzer(df_ohlcv,\n",
    "                               default_start_date=None, default_calc_period=126, default_fwd_period=63,\n",
    "                               default_metric='Sharpe (ATR)', default_rank_start=1, default_rank_end=10,\n",
    "                               default_benchmark_ticker='VOO', master_calendar_ticker='VOO',\n",
    "                               quality_thresholds={'min_median_dollar_volume': 1_000_000, 'max_stale_pct': 0.05, 'max_same_vol_count': 10},\n",
    "                               debug=False):\n",
    "    # (No changes to the initial setup part of this function...)\n",
    "    print(\"Initializing Walk-Forward Analyzer (using Trading Day Logic)...\")\n",
    "    if not isinstance(df_ohlcv.index, pd.MultiIndex): raise ValueError(\"Input DataFrame must have a (Ticker, Date) MultiIndex.\")\n",
    "    df_ohlcv = df_ohlcv.sort_index()\n",
    "    if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "        raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "    master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "    print(f\"Master trading day calendar created from '{master_calendar_ticker}' ({len(master_trading_days)} days).\")\n",
    "    print(\"--- Generating all features upfront... ---\")\n",
    "    features_df = generate_features(df_ohlcv)\n",
    "    print(\"Pre-processing data (unstacking)...\")\n",
    "    df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "    df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "    df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    start_date_picker = widgets.DatePicker(description='Start Date:', value=pd.to_datetime(default_start_date), disabled=False)\n",
    "    calc_period_input = widgets.IntText(value=default_calc_period, description='Calc Period (days):')\n",
    "    fwd_period_input = widgets.IntText(value=default_fwd_period, description='Fwd Period (days):')\n",
    "    if default_metric not in METRIC_REGISTRY:\n",
    "        fallback_metric = list(METRIC_REGISTRY.keys())[0]\n",
    "        print(f\"⚠️ Warning: Default metric '{default_metric}' not in registry. Using '{fallback_metric}'.\")\n",
    "        default_metric = fallback_metric\n",
    "    metric_dropdown = widgets.Dropdown(options=list(METRIC_REGISTRY.keys()), value=default_metric, description='Metric:')\n",
    "    rank_start_input = widgets.IntText(value=default_rank_start, description='Rank Start:')\n",
    "    rank_end_input = widgets.IntText(value=default_rank_end, description='Rank End:')\n",
    "    benchmark_ticker_input = widgets.Text(value=default_benchmark_ticker, description='Benchmark:', placeholder='Enter Ticker')\n",
    "    update_button = widgets.Button(description=\"Update Chart\", button_style='primary')\n",
    "    ticker_list_output = widgets.Output()\n",
    "    results_container, debug_data_container = [None], [None]\n",
    "    fig = go.FigureWidget()\n",
    "    max_traces = 50\n",
    "    for i in range(max_traces): fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name=f'placeholder_{i}', visible=False, showlegend=False))\n",
    "    fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Benchmark', visible=True, showlegend=True, line=dict(color='black', width=3, dash='dash')))\n",
    "    fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Group Portfolio', visible=True, showlegend=True, line=dict(color='green', width=3)))\n",
    "\n",
    "    def update_plot(button_click):\n",
    "        ticker_list_output.clear_output()\n",
    "        start_date_raw = pd.to_datetime(start_date_picker.value)\n",
    "        start_date_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "        if start_date_idx >= len(master_trading_days):\n",
    "            with ticker_list_output: print(f\"Error: Start date is after the last available trading day.\"); return\n",
    "        actual_start_date = master_trading_days[start_date_idx]\n",
    "        with ticker_list_output:\n",
    "            if start_date_raw.date() != actual_start_date.date():\n",
    "                print(f\"ℹ️ Info: Start date {start_date_raw.date()} is not a trading day. Snapping forward to {actual_start_date.date()}.\")\n",
    "        calc_period = calc_period_input.value; fwd_period = fwd_period_input.value; metric = metric_dropdown.value\n",
    "        rank_start = rank_start_input.value; rank_end = rank_end_input.value; benchmark_ticker = benchmark_ticker_input.value.strip().upper()\n",
    "        if rank_start > rank_end:\n",
    "            with ticker_list_output: print(\"Error: 'Rank Start' must be <= 'Rank End'.\"); return\n",
    "        if rank_start < 1 or calc_period < 2 or fwd_period < 1:\n",
    "            with ticker_list_output: print(\"Error: Ranks must be >= 1, Calc Period >= 2, Fwd Period >= 1.\"); return\n",
    "        required_days = calc_period + fwd_period\n",
    "        if start_date_idx + required_days > len(master_trading_days):\n",
    "            available_days = len(master_trading_days) - start_date_idx; last_available_date = master_trading_days[-1].date()\n",
    "            with ticker_list_output:\n",
    "                print(f\"Error: Not enough data for the requested period.\\n  Start Date: {actual_start_date.date()}\\n  Required Days: {calc_period} (calc) + {fwd_period} (fwd) = {required_days}\\n  Available Days from Start: {available_days} (until {last_available_date})\\n  Please shorten the 'Calc Period' / 'Fwd Period' or choose an earlier 'Start Date'.\")\n",
    "            return\n",
    "        eligible_tickers = get_eligible_universe(features_df, actual_start_date, quality_thresholds)\n",
    "        if not eligible_tickers:\n",
    "            with ticker_list_output: print(f\"Error: No eligible tickers found on {actual_start_date.date()} with the current quality filters.\"); return\n",
    "        df_close_step = df_close_full[eligible_tickers]; df_high_step = df_high_full[eligible_tickers]; df_low_step = df_low_full[eligible_tickers]\n",
    "        results, debug_output = run_walk_forward_step(df_close_full, df_high_full, df_low_full, master_trading_days, actual_start_date, calc_period, fwd_period, metric, rank_start, rank_end, benchmark_ticker, features_df=features_df, debug=debug)\n",
    "        if results.get('error'):\n",
    "            with ticker_list_output: print(f\"Error: {results['error']}\"); return\n",
    "        period_dates = {'calc_period_start': results['safe_start_date'], 'calc_period_end': results['actual_calc_end_ts'], 'forward_period_start': results['actual_calc_end_ts'], 'forward_period_end': results['safe_viz_end_date']}\n",
    "        run_parameters = {'calc_period': calc_period, 'fwd_period': fwd_period, 'rank_metric': metric, 'rank_start': rank_start, 'rank_end': rank_end, 'benchmark_ticker': benchmark_ticker}\n",
    "        results.update(period_dates); results.update(run_parameters)\n",
    "        if debug_output is not None and isinstance(debug_output, dict):\n",
    "            debug_output.update(period_dates); debug_output.update(run_parameters)\n",
    "        with fig.batch_update():\n",
    "            for i in range(max_traces):\n",
    "                trace = fig.data[i]\n",
    "                if i < len(results['tickers_to_display']):\n",
    "                    ticker = results['tickers_to_display'][i]; plot_data_series = results['normalized_plot_data'][ticker]\n",
    "                    trace.x, trace.y, trace.name, trace.visible, trace.showlegend = plot_data_series.index, plot_data_series.values, ticker, True, True\n",
    "                else: trace.visible, trace.showlegend = False, False\n",
    "            benchmark_trace = fig.data[max_traces]\n",
    "            if results['benchmark_price_series'] is not None and not results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']].dropna().empty:\n",
    "                normalized_benchmark = results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']] / results['benchmark_price_series'].loc[results['safe_start_date']:].bfill().iloc[0]\n",
    "                benchmark_trace.x, benchmark_trace.y, benchmark_trace.name, benchmark_trace.visible = normalized_benchmark.index, normalized_benchmark.values, f\"Benchmark ({benchmark_ticker})\", True\n",
    "            else: benchmark_trace.visible = False\n",
    "            portfolio_trace = fig.data[max_traces + 1]\n",
    "            portfolio_trace.x, portfolio_trace.y, portfolio_trace.name, portfolio_trace.visible = results['portfolio_series'].index, results['portfolio_series'], 'Group Portfolio', True\n",
    "            fig.layout.shapes = []; fig.add_shape(type=\"line\", x0=results['actual_calc_end_ts'], y0=0, x1=results['actual_calc_end_ts'], y1=1, xref='x', yref='paper', line=dict(color=\"grey\", width=2, dash=\"dash\"))\n",
    "        results_container[0] = results; debug_data_container[0] = debug_output\n",
    "        with ticker_list_output:\n",
    "            print(f\"Analysis Period: {results['safe_start_date'].date()} to {results['safe_viz_end_date'].date()}.\")\n",
    "            pprint.pprint(results['tickers_to_display'])\n",
    "            p = results['performance_data']\n",
    "            \n",
    "            # --- START OF MODIFIED BLOCK ---\n",
    "            rows = []\n",
    "            # Gain Metrics\n",
    "            rows.append({'Metric': 'Group Portfolio Gain', 'Full': p['full_p_gain'], 'Calc': p['calc_p_gain'], 'Fwd': p['fwd_p_gain']})\n",
    "            if not np.isnan(p.get('full_b_gain')):\n",
    "                rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Gain', 'Full': p['full_b_gain'], 'Calc': p['calc_b_gain'], 'Fwd': p['fwd_b_gain']})\n",
    "                rows.append({'Metric': '== Gain Delta (vs Bm)', 'Full': p['full_p_gain'] - p['full_b_gain'], 'Calc': p['calc_p_gain'] - p['calc_b_gain'], 'Fwd': p['fwd_p_gain'] - p['fwd_b_gain']})\n",
    "            \n",
    "            # Standard Sharpe Metrics\n",
    "            rows.append({'Metric': 'Group Portfolio Sharpe', 'Full': p['full_p_sharpe'], 'Calc': p['calc_p_sharpe'], 'Fwd': p['fwd_p_sharpe']})\n",
    "            if not np.isnan(p.get('full_b_sharpe')):\n",
    "                rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Sharpe', 'Full': p['full_b_sharpe'], 'Calc': p['calc_b_sharpe'], 'Fwd': p['fwd_b_sharpe']})\n",
    "                rows.append({'Metric': '== Sharpe Delta (vs Bm)', 'Full': p['full_p_sharpe'] - p['full_b_sharpe'], 'Calc': p['calc_p_sharpe'] - p['calc_b_sharpe'], 'Fwd': p['fwd_p_sharpe'] - p['fwd_b_sharpe']})\n",
    "\n",
    "            # Sharpe (ATR) Metrics\n",
    "            rows.append({'Metric': 'Group Portfolio Sharpe (ATR)', 'Full': p['full_p_sharpe_atr'], 'Calc': p['calc_p_sharpe_atr'], 'Fwd': p['fwd_p_sharpe_atr']})\n",
    "            if not np.isnan(p.get('full_b_sharpe_atr')):\n",
    "                rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Sharpe (ATR)', 'Full': p['full_b_sharpe_atr'], 'Calc': p['calc_b_sharpe_atr'], 'Fwd': p['fwd_b_sharpe_atr']})\n",
    "                rows.append({'Metric': '== Sharpe (ATR) Delta (vs Bm)', 'Full': p['full_p_sharpe_atr'] - p['full_b_sharpe_atr'], 'Calc': p['calc_p_sharpe_atr'] - p['calc_b_sharpe_atr'], 'Fwd': p['fwd_p_sharpe_atr'] - p['fwd_b_sharpe_atr']})\n",
    "\n",
    "            report_df = pd.DataFrame(rows).set_index('Metric')\n",
    "            gain_rows = [row for row in report_df.index if 'Gain' in row]\n",
    "            sharpe_rows = [row for row in report_df.index if 'Sharpe' in row] # This now correctly includes both types of Sharpe\n",
    "            # --- END OF MODIFIED BLOCK ---\n",
    "            \n",
    "            styled_df = report_df.style.format('{:+.2%}', na_rep='N/A', subset=(gain_rows, report_df.columns)).format('{:+.2f}', na_rep='N/A', subset=(sharpe_rows, report_df.columns)).set_properties(**{'text-align': 'right', 'width': '100px'}).set_table_styles([{'selector': 'th.col_heading', 'props': [('text-align', 'right')]}, {'selector': 'th.row_heading', 'props': [('text-align', 'left')]}])\n",
    "            print(\"\\n--- Strategy Performance Summary ---\")\n",
    "            display(styled_df)\n",
    "    fig.update_layout(title_text='Walk-Forward Performance Analysis', xaxis_title='Date', yaxis_title='Normalized Price (Start = 1)', hovermode='x unified', legend_title_text='Tickers (Ranked)', height=600, margin=dict(t=50))\n",
    "    fig.add_hline(y=1, line_width=1, line_dash=\"dash\", line_color=\"grey\")\n",
    "    update_button.on_click(update_plot)\n",
    "    controls_row1 = widgets.HBox([start_date_picker, calc_period_input, fwd_period_input])\n",
    "    controls_row2 = widgets.HBox([metric_dropdown, rank_start_input, rank_end_input, benchmark_ticker_input, update_button])\n",
    "    ui_container = widgets.VBox([controls_row1, controls_row2, ticker_list_output], layout=widgets.Layout(margin='10px 0 20px 0'))\n",
    "    display(ui_container, fig)\n",
    "    update_plot(None)\n",
    "    return (results_container, debug_data_container)\n",
    "\n",
    "\n",
    "\n",
    "# def generate_features(df_ohlcv: pd.DataFrame, \n",
    "#                       atr_period: int = 14, \n",
    "#                       quality_window: int = 252, \n",
    "#                       quality_min_periods: int = 126) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Generates a comprehensive DataFrame of derived features from raw OHLCV data.\n",
    "\n",
    "#     This function performs all heavy, window-based calculations upfront to be used\n",
    "#     by downstream analysis functions. It calculates:\n",
    "#     1. Technical Indicators: True Range (TR), ATR, and ATRP.\n",
    "#     2. Data Quality Metrics: Rolling stale percentage, median dollar volume, etc.\n",
    "\n",
    "#     Args:\n",
    "#         df_ohlcv: The primary DataFrame with a (Ticker, Date) MultiIndex and\n",
    "#                   columns for 'Adj High', 'Adj Low', 'Adj Close', 'Volume'.\n",
    "#         atr_period: The lookback period for the ATR's Exponential Moving Average.\n",
    "#         quality_window: The rolling window size for data quality metrics.\n",
    "#         quality_min_periods: The minimum number of observations required to have\n",
    "#                              a valid quality metric.\n",
    "\n",
    "#     Returns:\n",
    "#         A new DataFrame with the same (Ticker, Date) MultiIndex containing all\n",
    "#         calculated feature columns.\n",
    "#     \"\"\"\n",
    "#     print(\"--- Starting Feature Generation ---\")\n",
    "    \n",
    "#     # Ensure the DataFrame is sorted for correct window and shift operations\n",
    "#     # FIX: Replaced is_lexsorted() with the current pandas attribute\n",
    "#     if not df_ohlcv.index.is_monotonic_increasing:\n",
    "#         print(\"Sorting index for calculation accuracy...\")\n",
    "#         df_ohlcv = df_ohlcv.sort_index()\n",
    "\n",
    "#     # --- 1. Technical Indicator Calculation (TR, ATR, ATRP) ---\n",
    "#     print(f\"Calculating technical indicators (ATR Period: {atr_period})...\")\n",
    "    \n",
    "#     # Group by ticker to handle each security independently\n",
    "#     grouped = df_ohlcv.groupby(level='Ticker')\n",
    "    \n",
    "#     # Get the previous day's close required for True Range\n",
    "#     prev_close = grouped['Adj Close'].shift(1)\n",
    "    \n",
    "#     # Calculate the three components of True Range\n",
    "#     high_low = df_ohlcv['Adj High'] - df_ohlcv['Adj Low']\n",
    "#     high_prev_close = abs(df_ohlcv['Adj High'] - prev_close)\n",
    "#     low_prev_close = abs(df_ohlcv['Adj Low'] - prev_close)\n",
    "    \n",
    "#     # Combine the components to get the final TR\n",
    "#     tr = pd.concat([high_low, high_prev_close, low_prev_close], axis=1).max(axis=1, skipna=False)\n",
    "    \n",
    "#     # # Calculate the ATR using an Exponential Moving Average\n",
    "#     # --- FIX IS HERE ---\n",
    "#     # Use .transform() to apply the EWM function. \n",
    "#     # This guarantees the resulting Series has the exact same index as 'tr',\n",
    "#     # preventing the index alignment error during the subsequent division.\n",
    "#     atr = tr.groupby(level='Ticker').transform(\n",
    "#         lambda x: x.ewm(alpha=1/atr_period, adjust=False).mean()\n",
    "#     )\n",
    "\n",
    "#     # --- CHANGE 1: Removed .fillna(0) ---\n",
    "#     # ATRP will now be NaN on the first day, consistent with TR and ATR.\n",
    "#     atrp = (atr / df_ohlcv['Adj Close']).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "#     indicator_df = pd.DataFrame({\n",
    "#         'TR': tr,\n",
    "#         'ATR': atr,\n",
    "#         'ATRP': atrp\n",
    "#     })\n",
    "    \n",
    "#     # --- 2. Data Quality Metric Calculation ---\n",
    "#     print(f\"Calculating data quality metrics (Window: {quality_window} days)...\")\n",
    "    \n",
    "#     # Create intermediate flags needed for quality calculations\n",
    "#     is_stale = np.where((df_ohlcv['Volume'] == 0) | (df_ohlcv['Adj High'] == df_ohlcv['Adj Low']), 1, 0)\n",
    "#     dollar_volume = df_ohlcv['Adj Close'] * df_ohlcv['Volume']\n",
    "#     has_same_volume = (grouped['Volume'].diff() == 0).astype(int)\n",
    "    \n",
    "#     # Combine flags into a temporary DataFrame for rolling calculations\n",
    "#     quality_temp_df = pd.DataFrame({\n",
    "#         'IsStale': is_stale,\n",
    "#         'DollarVolume': dollar_volume,\n",
    "#         'HasSameVolume': has_same_volume\n",
    "#     }, index=df_ohlcv.index) # Explicitly set index to be safe\n",
    "    \n",
    "#     # Perform the rolling calculations on the grouped data\n",
    "#     # --- FIX IS HERE ---\n",
    "#     # We switch to the older, more compatible dictionary-based aggregation method.\n",
    "#     # This syntax is understood by nearly all versions of pandas.\n",
    "#     rolling_result = quality_temp_df.groupby(level='Ticker').rolling(\n",
    "#         window=quality_window,\n",
    "#         min_periods=quality_min_periods\n",
    "#     ).agg({\n",
    "#         'IsStale': 'mean',\n",
    "#         'DollarVolume': 'median',\n",
    "#         'HasSameVolume': 'sum'\n",
    "#     })\n",
    "    \n",
    "#     # The dictionary syntax produces columns with the original names ('IsStale', etc.).\n",
    "#     # We now explicitly rename them to our desired final names.\n",
    "#     rolling_result = rolling_result.rename(columns={\n",
    "#         'IsStale': 'RollingStalePct',\n",
    "#         'DollarVolume': 'RollMedDollarVol', # <-- RENAMED HERE\n",
    "#         'HasSameVolume': 'RollingSameVolCount'\n",
    "#     })\n",
    "\n",
    "#     # The index after a grouped rolling operation is hierarchical.\n",
    "#     # We remove the outermost 'Ticker' level to restore the original index structure.\n",
    "#     rolling_quality = rolling_result.reset_index(level=0, drop=True)\n",
    "\n",
    "#     # --- 3. Combine All Features ---\n",
    "#     print(\"Combining all feature sets...\")\n",
    "#     features_df = pd.concat([indicator_df, rolling_quality], axis=1)\n",
    "    \n",
    "#     print(\"✅ Feature generation complete.\")\n",
    "#     return features_df\n",
    "\n",
    "\n",
    "# def get_eligible_universe(features_df, filter_date, thresholds):\n",
    "#     \"\"\"Filters the universe of tickers based on quality metrics for a given date.\"\"\"\n",
    "#     filter_date_ts = pd.to_datetime(filter_date)\n",
    "#     # The index is now the comprehensive features_df\n",
    "#     date_index = features_df.index.get_level_values('Date').unique().sort_values()\n",
    "    \n",
    "#     if filter_date_ts < date_index[0]:\n",
    "#         print(f\"Warning: Filter date {filter_date_ts.date()} is before the earliest data point. Returning empty universe.\")\n",
    "#         return []\n",
    "        \n",
    "#     # Find the most recent date with quality data on or before the filter date\n",
    "#     valid_prior_dates = date_index[date_index <= filter_date_ts]\n",
    "#     if valid_prior_dates.empty:\n",
    "#         print(f\"Warning: No available data found on or before {filter_date_ts.date()}. Returning empty universe.\")\n",
    "#         return []\n",
    "        \n",
    "#     actual_date_to_use = valid_prior_dates[-1]\n",
    "#     if actual_date_to_use.date() != filter_date_ts.date():\n",
    "#         print(f\"ℹ️ Info: Filter date {filter_date_ts.date()} not found. Using previous available date {actual_date_to_use.date()}.\")\n",
    "\n",
    "#     metrics_on_date = features_df.xs(actual_date_to_use, level='Date')\n",
    "    \n",
    "#     # Apply filters using the new column names from features_df\n",
    "#     mask = ((metrics_on_date['RollMedDollarVol'] >= thresholds['min_median_dollar_volume']) & # <-- RENAMED\n",
    "#             (metrics_on_date['RollingStalePct'] <= thresholds['max_stale_pct']) &\n",
    "#             (metrics_on_date['RollingSameVolCount'] <= thresholds['max_same_vol_count']))\n",
    "            \n",
    "#     eligible_tickers = metrics_on_date[mask].index.tolist()\n",
    "#     all_tickers = metrics_on_date.index.tolist()\n",
    "#     print(f\"Dynamic Filter ({filter_date_ts.date()}): Kept {len(eligible_tickers)} of {len(all_tickers)} tickers.\")\n",
    "#     return eligible_tickers\n",
    "\n",
    "\n",
    "# def run_walk_forward_step(df_close_full, df_high_full, df_low_full,\n",
    "#                           master_trading_days,\n",
    "#                           start_date, calc_period, fwd_period,\n",
    "#                           metric, rank_start, rank_end, benchmark_ticker,\n",
    "#                           features_df,\n",
    "#                           debug=False):\n",
    "#     \"\"\"\n",
    "#     Runs a single step of the walk-forward analysis with a strict, pre-emptive\n",
    "#     check to ensure the full period is available.\n",
    "#     \"\"\"\n",
    "#     debug_data = {} if debug else None\n",
    "\n",
    "#     # 1. Determine exact date ranges with a NEW pre-emptive check\n",
    "#     try:\n",
    "#         start_idx = master_trading_days.get_loc(start_date)\n",
    "#     except KeyError:\n",
    "#         return ({'error': f\"Start date {start_date.date()} is not a valid trading day.\"}, None)\n",
    "\n",
    "#     # +++ THIS IS THE NEW PRE-EMPTIVE CHECK LOGIC +++\n",
    "#     # Calculate the desired end index without clamping first.\n",
    "#     desired_viz_end_idx = start_idx + calc_period + fwd_period\n",
    "    \n",
    "#     # Check if the desired end index is out of bounds.\n",
    "#     if desired_viz_end_idx >= len(master_trading_days):\n",
    "#         last_available_date = master_trading_days[-1].date()\n",
    "#         required_days = calc_period + fwd_period\n",
    "#         available_days = len(master_trading_days) - start_idx\n",
    "#         error_msg = (f\"Not enough data for the full requested period. \"\n",
    "#                      f\"Required: {required_days} days, Available: {available_days} days until {last_available_date}.\")\n",
    "#         return ({'error': error_msg}, None)\n",
    "#     # --- END OF NEW CHECK ---\n",
    "\n",
    "#     # If the check passes, we know the full period is available.\n",
    "#     # The 'min' calls are now just a redundant safety measure.\n",
    "#     calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "#     viz_end_idx = min(calc_end_idx + fwd_period, len(master_trading_days) - 1)\n",
    "\n",
    "#     safe_start_date = master_trading_days[start_idx]\n",
    "#     safe_calc_end_date = master_trading_days[calc_end_idx]\n",
    "#     safe_viz_end_date = master_trading_days[viz_end_idx]\n",
    "    \n",
    "#     if safe_start_date >= safe_calc_end_date:\n",
    "#         return ({'error': \"Invalid date range (calc period has zero or negative length).\"}, None)\n",
    "\n",
    "#     # (The rest of the function remains completely unchanged...)\n",
    "#     # 2. Slice data for the calculation period\n",
    "#     calc_close_raw = df_close_full.loc[safe_start_date:safe_calc_end_date]\n",
    "#     calc_close = calc_close_raw.dropna(axis=1, how='all')\n",
    "#     if calc_close.shape[1] == 0 or len(calc_close) < 2:\n",
    "#         return ({'error': \"Not enough data in calc period.\"}, None)\n",
    "\n",
    "#     # 3. Calculate INTERMEDIATE data required for the ranking metrics\n",
    "#     daily_returns = calc_close.bfill().ffill().pct_change()\n",
    "#     valid_tickers = calc_close.columns\n",
    "#     calc_period_index = pd.MultiIndex.from_product([valid_tickers, calc_close.index], names=['Ticker', 'Date'])\n",
    "#     features_in_period = features_df.loc[features_df.index.intersection(calc_period_index)]\n",
    "#     atrp = features_in_period.groupby(level='Ticker')['ATRP'].mean()\n",
    "\n",
    "#     # 4. Calculate all ranking metrics by iterating through the METRIC_REGISTRY\n",
    "#     metric_ingredients = { 'calc_close': calc_close, 'daily_returns': daily_returns, 'atrp': atrp, }\n",
    "#     metric_values = {}\n",
    "#     for name, func in METRIC_REGISTRY.items():\n",
    "#         metric_values[name] = func(metric_ingredients)\n",
    "#     if metric not in metric_values or metric_values[metric].empty:\n",
    "#         return ({'error': f\"Metric '{metric}' could not be calculated or resulted in no valid tickers.\"}, None)\n",
    "\n",
    "#     # 5. Rank tickers and select the portfolio\n",
    "#     sorted_tickers = metric_values[metric].sort_values(ascending=False)\n",
    "#     tickers_to_display = sorted_tickers.index[rank_start-1:rank_end].tolist()\n",
    "#     if not tickers_to_display:\n",
    "#         return ({'error': \"No tickers found for the selected rank.\"}, None)\n",
    "\n",
    "#     # 6. Calculate Portfolio & Benchmark Performance\n",
    "#     normalized_plot_data = df_close_full[tickers_to_display].loc[safe_start_date:safe_viz_end_date]\n",
    "#     normalized_plot_data = normalized_plot_data.div(normalized_plot_data.bfill().iloc[0])\n",
    "#     actual_calc_end_ts = calc_close.index.max()\n",
    "#     portfolio_series = normalized_plot_data.mean(axis=1)\n",
    "#     portfolio_return_series = portfolio_series.pct_change()\n",
    "#     benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "#     benchmark_return_series = benchmark_price_series.loc[safe_start_date:safe_viz_end_date].bfill().ffill().pct_change() if benchmark_price_series is not None else pd.Series(dtype='float64')\n",
    "#     try:\n",
    "#         boundary_loc = portfolio_return_series.index.get_loc(actual_calc_end_ts)\n",
    "#         calc_portfolio_returns = portfolio_return_series.iloc[:boundary_loc + 1]\n",
    "#         fwd_portfolio_returns = portfolio_return_series.iloc[boundary_loc + 1:]\n",
    "#         if benchmark_price_series is not None:\n",
    "#             bm_boundary_loc = benchmark_return_series.index.get_loc(actual_calc_end_ts)\n",
    "#             calc_benchmark_returns = benchmark_return_series.iloc[:bm_boundary_loc + 1]\n",
    "#             fwd_benchmark_returns = benchmark_return_series.iloc[bm_boundary_loc + 1:]\n",
    "#         else:\n",
    "#             calc_benchmark_returns, fwd_benchmark_returns = pd.Series(dtype='float64'), pd.Series(dtype='float64')\n",
    "#     except (KeyError, IndexError):\n",
    "#         calc_portfolio_returns = portfolio_return_series.loc[:actual_calc_end_ts]\n",
    "#         fwd_portfolio_returns = portfolio_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "#         if benchmark_price_series is not None:\n",
    "#             calc_benchmark_returns = benchmark_return_series.loc[:actual_calc_end_ts]\n",
    "#             fwd_benchmark_returns = benchmark_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "#         else:\n",
    "#             calc_benchmark_returns, fwd_benchmark_returns = pd.Series(dtype='float64'), pd.Series(dtype='float64')\n",
    "#     full_period_index = pd.MultiIndex.from_product([tickers_to_display, portfolio_return_series.index], names=['Ticker', 'Date'])\n",
    "#     portfolio_atrp_features = features_df.loc[features_df.index.intersection(full_period_index)]\n",
    "#     portfolio_atrp_daily_unstacked = portfolio_atrp_features['ATRP'].unstack(level='Ticker')\n",
    "#     portfolio_atrp_series = portfolio_atrp_daily_unstacked.mean(axis=1)\n",
    "#     if benchmark_ticker in df_close_full.columns:\n",
    "#         benchmark_atrp_series = features_df.xs(benchmark_ticker, level='Ticker')['ATRP'].loc[safe_start_date:safe_viz_end_date]\n",
    "#     else:\n",
    "#         benchmark_atrp_series = pd.Series(dtype='float64')\n",
    "#     calc_portfolio_atrp = portfolio_atrp_series.loc[:actual_calc_end_ts]\n",
    "#     fwd_portfolio_atrp = portfolio_atrp_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "#     calc_benchmark_atrp = benchmark_atrp_series.loc[:actual_calc_end_ts]\n",
    "#     fwd_benchmark_atrp = benchmark_atrp_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "#     perf_data = {}\n",
    "#     perf_data['calc_p_gain'] = calculate_gain(portfolio_series.loc[:actual_calc_end_ts])\n",
    "#     perf_data['fwd_p_gain'] = calculate_gain(portfolio_series.loc[actual_calc_end_ts:])\n",
    "#     perf_data['full_p_gain'] = calculate_gain(portfolio_series)\n",
    "#     perf_data['calc_p_sharpe'] = calculate_sharpe(calc_portfolio_returns)\n",
    "#     perf_data['fwd_p_sharpe'] = calculate_sharpe(fwd_portfolio_returns)\n",
    "#     perf_data['full_p_sharpe'] = calculate_sharpe(portfolio_return_series)\n",
    "#     perf_data['calc_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:actual_calc_end_ts]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['fwd_b_gain'] = calculate_gain(benchmark_price_series.loc[actual_calc_end_ts:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['full_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['calc_b_sharpe'] = calculate_sharpe(calc_benchmark_returns)\n",
    "#     perf_data['fwd_b_sharpe'] = calculate_sharpe(fwd_benchmark_returns)\n",
    "#     perf_data['full_b_sharpe'] = calculate_sharpe(benchmark_return_series)\n",
    "#     perf_data['calc_p_sharpe_atr'] = calculate_sharpe_atr(calc_portfolio_returns, calc_portfolio_atrp)\n",
    "#     perf_data['fwd_p_sharpe_atr'] = calculate_sharpe_atr(fwd_portfolio_returns, fwd_portfolio_atrp)\n",
    "#     perf_data['full_p_sharpe_atr'] = calculate_sharpe_atr(portfolio_return_series, portfolio_atrp_series)\n",
    "#     perf_data['calc_b_sharpe_atr'] = calculate_sharpe_atr(calc_benchmark_returns, calc_benchmark_atrp)\n",
    "#     perf_data['fwd_b_sharpe_atr'] = calculate_sharpe_atr(fwd_benchmark_returns, fwd_benchmark_atrp)\n",
    "#     perf_data['full_b_sharpe_atr'] = calculate_sharpe_atr(benchmark_return_series, benchmark_atrp_series)\n",
    "#     if debug:\n",
    "#         df_ranking_base = pd.DataFrame({'MeanDailyReturn': daily_returns.mean(),'StdDevDailyReturn': daily_returns.std(),'MeanATRP': atrp})\n",
    "#         df_metrics = pd.DataFrame(metric_values)\n",
    "#         df_metrics.columns = [f'Metric_{col}' for col in df_metrics.columns]\n",
    "#         df_ranking = df_ranking_base.join(df_metrics, how='left')\n",
    "#         df_ranking.index.name = 'Ticker'\n",
    "#         debug_data['ranking_metrics'] = df_ranking.sort_values(f'Metric_{metric}', ascending=False)\n",
    "#     calc_end_prices = calc_close.ffill().iloc[-1]\n",
    "#     fwd_close_slice = df_close_full.loc[actual_calc_end_ts:safe_viz_end_date]\n",
    "#     viz_end_prices = fwd_close_slice.ffill().iloc[-1] if not fwd_close_slice.empty and len(fwd_close_slice) >= 2 else calc_end_prices\n",
    "#     calc_gains = (calc_end_prices / calc_close.bfill().iloc[0]) - 1\n",
    "#     fwd_gains = (viz_end_prices / calc_end_prices) - 1\n",
    "#     results_df = pd.DataFrame({'Rank': range(rank_start, rank_start + len(tickers_to_display)), 'Metric': metric, 'MetricValue': sorted_tickers.loc[tickers_to_display].values, 'CalcPrice': calc_end_prices.loc[tickers_to_display], 'CalcGain': calc_gains.loc[tickers_to_display], 'FwdGain': fwd_gains.loc[tickers_to_display]}, index=pd.Index(tickers_to_display, name='Ticker'))\n",
    "#     if benchmark_price_series is not None and benchmark_ticker in calc_close.columns:\n",
    "#         benchmark_df_row = pd.DataFrame({'Rank': np.nan, 'Metric': metric, 'MetricValue': metric_values[metric].get(benchmark_ticker, np.nan), 'CalcPrice': calc_end_prices[benchmark_ticker], 'CalcGain': calc_gains[benchmark_ticker], 'FwdGain': fwd_gains[benchmark_ticker]}, index=pd.Index([f\"{benchmark_ticker} (BM)\"], name='Ticker'))\n",
    "#         results_df = pd.concat([results_df, benchmark_df_row])\n",
    "#     if debug:\n",
    "#         df_trace = normalized_plot_data.copy()\n",
    "#         df_trace.columns = [f'Norm_Price_{c}' for c in df_trace.columns]\n",
    "#         df_trace['Norm_Price_Portfolio'] = portfolio_series\n",
    "#         if benchmark_price_series is not None and not benchmark_price_series.loc[safe_start_date:safe_viz_end_date].dropna().empty:\n",
    "#             norm_bm = benchmark_price_series.loc[safe_start_date:safe_viz_end_date] / benchmark_price_series.loc[safe_start_date:].bfill().iloc[0]\n",
    "#             df_trace[f'Norm_Price_Benchmark_{benchmark_ticker}'] = norm_bm\n",
    "#         for col in df_trace.columns:\n",
    "#             if 'Norm_Price' in col:\n",
    "#                 df_trace[col.replace('Norm_Price', 'Return')] = df_trace[col].pct_change()\n",
    "#         debug_data['portfolio_trace'] = df_trace\n",
    "#     final_results = {\n",
    "#         'tickers_to_display': tickers_to_display, 'normalized_plot_data': normalized_plot_data,\n",
    "#         'portfolio_series': portfolio_series, 'benchmark_price_series': benchmark_price_series,\n",
    "#         'performance_data': perf_data, 'results_df': results_df, 'actual_calc_end_ts': actual_calc_end_ts,\n",
    "#         'safe_start_date': safe_start_date, 'safe_viz_end_date': safe_viz_end_date,\n",
    "#         'error': None\n",
    "#     }\n",
    "#     return (final_results, debug_data)\n",
    "\n",
    "\n",
    "# def verify_sharpe_atr_calculation_checked(df_ohlcv, features_df, tickers_to_verify, benchmark_ticker,\n",
    "#                                     start_date, calc_period, fwd_period,\n",
    "#                                     master_calendar_ticker='VOO', debug=False):\n",
    "#     \"\"\"\n",
    "#     Verifies the Sharpe (ATR) calculations for a portfolio and benchmark.\n",
    "\n",
    "#     This function transparently recalculates the key components for Sharpe (ATR)\n",
    "#     and can optionally export the underlying source data for manual inspection.\n",
    "#     \"\"\"\n",
    "#     display(Markdown(f\"## Verification Report for Sharpe (ATR) Calculation\"))\n",
    "#     display(Markdown(f\"**Portfolio Tickers:** `{tickers_to_verify}`\\n**Benchmark Ticker:** `{benchmark_ticker}`\"))\n",
    "\n",
    "#     # --- 1. Determine Exact Period Dates (No changes here) ---\n",
    "#     master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "#     start_date_raw = pd.to_datetime(start_date)\n",
    "#     start_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "#     actual_start_date = master_trading_days[start_idx]\n",
    "#     calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "#     fwd_end_idx = min(calc_end_idx + fwd_period, len(master_trading_days) - 1)\n",
    "#     actual_calc_end_date = master_trading_days[calc_end_idx]\n",
    "#     actual_fwd_end_date = master_trading_days[fwd_end_idx]\n",
    "    \n",
    "#     display(Markdown(f\"**Full Period:** `{actual_start_date.date()}` to `{actual_fwd_end_date.date()}`\\n\"\n",
    "#                     f\"**Calc End Date:** `{actual_calc_end_date.date()}`\"))\n",
    "\n",
    "#     # Original debug export block (can be kept or removed)\n",
    "#     if debug:\n",
    "#         # ... (original export code remains here) ...\n",
    "#         pass # Assuming original block is here\n",
    "\n",
    "#     # --- 2. Recreate Portfolio & Benchmark Series from Scratch ---\n",
    "#     df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "#     portfolio_prices_raw = df_close_full[tickers_to_verify].loc[actual_start_date:actual_fwd_end_date]\n",
    "#     portfolio_prices_norm = portfolio_prices_raw.div(portfolio_prices_raw.bfill().iloc[0])\n",
    "#     portfolio_value_series = portfolio_prices_norm.mean(axis=1)\n",
    "#     portfolio_return_series = portfolio_value_series.pct_change()\n",
    "#     p_idx = pd.MultiIndex.from_product([tickers_to_verify, portfolio_return_series.index])\n",
    "#     p_atrp_df = features_df.loc[features_df.index.intersection(p_idx)]['ATRP'].unstack(level=0)\n",
    "#     portfolio_atrp_series = p_atrp_df.mean(axis=1)\n",
    "\n",
    "# ###############################    \n",
    "#     # benchmark_return_series = df_close_full[benchmark_ticker].pct_change().loc[actual_start_date:actual_fwd_end_date]\n",
    "\n",
    "#     # 1. First, slice the raw prices for the desired date range.\n",
    "#     benchmark_prices_raw = df_close_full[benchmark_ticker].loc[actual_start_date:actual_fwd_end_date]\n",
    "#     # 2. Then, calculate the percentage change on the sliced data.\n",
    "#     benchmark_return_series = benchmark_prices_raw.pct_change()\n",
    "\n",
    "# ###############################    \n",
    "#     benchmark_atrp_series = features_df.xs(benchmark_ticker, level='Ticker')['ATRP'].loc[actual_start_date:actual_fwd_end_date]\n",
    "\n",
    "\n",
    "#     # +++ NEW: DETAILED RETURN CALCULATION TRACE (PORTFOLIO) +++\n",
    "#     if debug:\n",
    "#         display(Markdown(\"---\"))\n",
    "#         display(Markdown(\"### 🐛 Detailed Portfolio Return Calculation Trace\"))\n",
    "\n",
    "#         # Step 1: Show the raw prices being used\n",
    "#         print(\"\\n[STEP 1] Raw Adjusted Close prices used for calculation.\")\n",
    "#         print(\"Compare these values with your 'Adj Close' columns.\")\n",
    "#         display(portfolio_prices_raw)\n",
    "\n",
    "#         # Step 2: Show the normalization base and the result\n",
    "#         normalization_base = portfolio_prices_raw.bfill().iloc[0]\n",
    "#         print(\"\\n[STEP 2] Normalization base (first row of prices).\")\n",
    "#         print(\"Each column in Step 1 is divided by this corresponding value.\")\n",
    "#         display(pd.DataFrame(normalization_base).T)\n",
    "\n",
    "#         print(\"\\n[STEP 2a] Normalized prices (Result of division).\")\n",
    "#         print(\"Compare these values with your 'N Close' columns.\")\n",
    "#         display(portfolio_prices_norm)\n",
    "\n",
    "#         # Step 3: Show the averaged portfolio value series\n",
    "#         print(\"\\n[STEP 3] Averaged normalized portfolio value series.\")\n",
    "#         print(\"This is the row-by-row average of the table in Step 2a.\")\n",
    "#         print(\"Compare this series with your 'N_portf' column.\")\n",
    "#         display(pd.DataFrame(portfolio_value_series, columns=['N_portf']))\n",
    "\n",
    "#         # Step 4: Show the final portfolio return series\n",
    "#         print(\"\\n[STEP 4] Final portfolio daily return series (pct_change).\")\n",
    "#         print(\"This is the percentage change of the series in Step 3.\")\n",
    "#         print(\"Compare this series with your 'N_portf_rtn' column.\")\n",
    "#         display(pd.DataFrame(portfolio_return_series, columns=['N_portf_rtn']))\n",
    "#         display(Markdown(\"---\"))\n",
    "#     # +++ END OF NEW DEBUG BLOCK +++\n",
    "\n",
    "\n",
    "#     # --- 3. Define a Helper to Print Detailed Calculation Steps ---\n",
    "#     # MODIFIED to include more debug details inside\n",
    "#     def _calculate_and_print_metrics(period_name, returns, atrps):\n",
    "#         display(Markdown(f\"#### {period_name}\"))\n",
    "#         if returns.dropna().empty or atrps.dropna().empty:\n",
    "#             print(\"  - Not enough data to calculate.\")\n",
    "#             return np.nan\n",
    "\n",
    "#         # Standard calculations\n",
    "#         mean_return = returns.mean()\n",
    "#         mean_atrp = atrps.mean()\n",
    "#         sharpe_atr = mean_return / mean_atrp if mean_atrp > 0 else np.nan\n",
    "\n",
    "#         # +++ ADDED: Detailed Mean Calculation Breakdown +++\n",
    "#         if debug:\n",
    "#             valid_returns = returns.dropna()\n",
    "#             num_returns = valid_returns.count()\n",
    "#             sum_returns = valid_returns.sum()\n",
    "#             manual_mean = sum_returns / num_returns if num_returns > 0 else 0\n",
    "#             print(f\"  - (Debug) Number of valid daily returns: {num_returns}\")\n",
    "#             print(f\"  - (Debug) Sum of all daily returns:      {sum_returns:,.8f}\")\n",
    "#             print(f\"  - (Debug) Manually calculated mean:      {manual_mean:,.8f} (Sum / Count)\")\n",
    "#         # +++ END OF ADDED DETAIL +++\n",
    "\n",
    "#         print(f\"  - Mean Daily Return: {mean_return:,.6f}\")\n",
    "#         print(f\"  - Mean Daily ATRP:  {mean_atrp:,.6f}\")\n",
    "#         print(f\"  - Sharpe (ATR) = (Mean Return / Mean ATRP) = {sharpe_atr:,.4f}\")\n",
    "#         return sharpe_atr\n",
    "\n",
    "#     # --- 4. Run Verification for Portfolio (No changes here) ---\n",
    "#     display(Markdown(\"### A. Group Portfolio Verification\"))\n",
    "#     _calculate_and_print_metrics(\"Full Period\", portfolio_return_series, portfolio_atrp_series)\n",
    "#     _calculate_and_print_metrics(\"Calculation Period\", portfolio_return_series.loc[:actual_calc_end_date], portfolio_atrp_series.loc[:actual_calc_end_date])\n",
    "#     _calculate_and_print_metrics(\"Forward Period\", portfolio_return_series.loc[actual_calc_end_date:].iloc[1:], portfolio_atrp_series.loc[actual_calc_end_date:].iloc[1:])\n",
    "\n",
    "#     # --- 5. Run Verification for Benchmark (No changes here) ---\n",
    "#     display(Markdown(f\"### B. Benchmark ({benchmark_ticker}) Verification\"))\n",
    "#     _calculate_and_print_metrics(\"Full Period\", benchmark_return_series, benchmark_atrp_series)\n",
    "#     _calculate_and_print_metrics(\"Calculation Period\", benchmark_return_series.loc[:actual_calc_end_date], benchmark_atrp_series.loc[:actual_calc_end_date])\n",
    "#     _calculate_and_print_metrics(\"Forward Period\", benchmark_return_series.loc[actual_calc_end_date:].iloc[1:], benchmark_atrp_series.loc[actual_calc_end_date:].iloc[1:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5b18a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_container, debug_container = plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    default_start_date='2018-10-03',\n",
    "    default_calc_period=252,\n",
    "    default_fwd_period=63,\n",
    "    default_metric='Sharpe (ATR)',\n",
    "    default_rank_start=1,\n",
    "    default_rank_end=5,\n",
    "    default_benchmark_ticker='VOO',\n",
    "    quality_thresholds={ 'min_median_dollar_volume': 10_000_000, \n",
    "                         'max_stale_pct': 0.05, \n",
    "                         'max_same_vol_count': 1 },\n",
    "    debug=True  # <-- Activate the new mode!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed49741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85348e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274d60ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Use pd.IndexSlice for a clean and readable slice\n",
    "# This is the recommended pandas method for complex slicing on a MultiIndex.\n",
    "idx = pd.IndexSlice\n",
    "sliced_features_df = features_df.loc[idx[tickers_to_verify, start_date:end_date], :]\n",
    "\n",
    "# 3. Display the results to verify\n",
    "print(f\"Shape of the original features_df: {features_df.shape}\")\n",
    "print(f\"Shape of the sliced_features_df: {sliced_features_df.shape}\")\n",
    "print(\"\\n--- Displaying the sliced DataFrame ---\")\n",
    "display(sliced_features_df)\n",
    "\n",
    "# You can also verify the boundaries of the slice\n",
    "print(\"\\n--- Verifying the boundaries ---\")\n",
    "print(f\"First Ticker/Date: {sliced_features_df.index.min()}\")\n",
    "print(f\"Last Ticker/Date:  {sliced_features_df.index.max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dc055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Define the tickers and date range for your slice\n",
    "# tickers_to_slice = ['BIL', 'SATS', 'MINT', 'BOXX']\n",
    "# start_date = '2025-08-03'\n",
    "# end_date = '2025-10-02'\n",
    "\n",
    "# 2. Use pd.IndexSlice for a clean and readable slice\n",
    "# This is the recommended pandas method for complex slicing on a MultiIndex.\n",
    "idx = pd.IndexSlice\n",
    "sliced_df_ohlcv = df_ohlcv.loc[idx[tickers_to_verify, start_date:end_date], :]\n",
    "\n",
    "# 3. Display the results to verify\n",
    "print(f\"Shape of the original df_ohlcv: {df_ohlcv.shape}\")\n",
    "print(f\"Shape of the sliced_df_ohlcv: {sliced_df_ohlcv.shape}\")\n",
    "print(\"\\n--- Displaying the sliced DataFrame ---\")\n",
    "display(sliced_df_ohlcv)\n",
    "\n",
    "# You can also verify the boundaries of the slice\n",
    "print(\"\\n--- Verifying the boundaries ---\")\n",
    "print(f\"First Ticker/Date: {sliced_df_ohlcv.index.min()}\")\n",
    "print(f\"Last Ticker/Date:  {sliced_df_ohlcv.index.max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67a7eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Use .loc to slice AND explicitly create a .copy()\n",
    "# This tells pandas that we are creating a new DataFrame that we intend to modify.\n",
    "# This is the line that prevents the warning.\n",
    "idx = pd.IndexSlice\n",
    "sliced_df_ohlcv = df_ohlcv.loc[idx[tickers_to_verify, start_date:end_date], :].copy()\n",
    "\n",
    "# 3. Now, add the new column to this independent copy.\n",
    "# This will no longer raise a warning.\n",
    "sliced_df_ohlcv['Daily_Return'] = sliced_df_ohlcv.groupby(level='Ticker')['Adj Close'].pct_change()\n",
    "\n",
    "# 4. Display the results to verify\n",
    "print(\"--- DataFrame with 'Daily_Return' column added (Warning Corrected) ---\")\n",
    "display(sliced_df_ohlcv.head())\n",
    "print(\"...\")\n",
    "display(sliced_df_ohlcv.tail())\n",
    "\n",
    "# print(\"\\n--- Updated DataFrame Info ---\")\n",
    "# sliced_df_ohlcv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a32a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the 'Ticker' level of the index, select the 'Daily_Return' column,\n",
    "# and calculate the mean for each group.\n",
    "mean_daily_returns = sliced_df_ohlcv.groupby(level='Ticker')['Daily_Return'].mean()\n",
    "\n",
    "# Display the resulting Series\n",
    "print(\"--- Mean Daily Return per Ticker ---\")\n",
    "display(mean_daily_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea11a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the 'Ticker' level of the index, select the 'Daily_Return' column,\n",
    "# and calculate the mean for each group.\n",
    "mean_ATRP = sliced_features_df.groupby(level='Ticker')['ATRP'].mean()\n",
    "\n",
    "# Display the resulting Series\n",
    "print(\"--- ATRP per Ticker ---\")\n",
    "display(mean_ATRP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7082bb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(mean_daily_returns / mean_ATRP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e61380",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_features_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02ab95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_df_ohlcv.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fe6ad2",
   "metadata": {},
   "source": [
    "| Date | Portfolio Value | Portfolio Daily_Return | Ticker A ATRP | Ticker B ATRP | Portfolio Daily ATRP |\n",
    "| :--- | :--- | :--- | :--- | :--- | :--- |\n",
    "| Day 1 | 1.000 | **`NaN`** | 0.005 | 0.005 | 0.005 |\n",
    "| Day 2 | 1.010 | `+0.010` | 0.006 | 0.006 | 0.006 |\n",
    "| Day 3 | 1.015 | `+0.005` | 0.004 | 0.004 | 0.004 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4b43de",
   "metadata": {},
   "source": [
    "| Function                                     | Is the \"Clamp\" Logic Used? | Why? (Its Role in this Function)                                                                                                                                                                                                                                                                                                                             |\n",
    "| -------------------------------------------- | -------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **`run_walk_forward_step`**                  | **Yes (Primary)**          | This is the **source of truth**. As the core calculation engine, it *must* be robust and handle running out of data at the end of the timeline without crashing. This is the most critical implementation of the clamp.                                                                                                                                       |\n",
    "| **`verify_sharpe_atr_calculation`**          | **Yes (Replication)**      | As you noted, it's here. Its purpose is to **exactly mimic** the behavior of `run_walk_forward_step`. If the verification tool crashed while the main tool gracefully clamped the period, the verification tool would be useless for debugging end-of-timeline scenarios.                                                                                         |\n",
    "| **`verify_group_tickers_walk_forward_calculation`** | **Yes (Replication)**      | Same reason as above. This function verifies portfolio performance and must use the identical date boundary logic as the main engine to produce comparable results for gain and Sharpe ratio.                                                                                                                                                                  |\n",
    "| **`verify_ticker_ranking_metrics`**          | **Yes (Replication)**      | Same reason. It verifies the metrics calculated over the `calc_period`. If the user selects a start date where a full `calc_period` is not available, this tool must clamp the period in the same way `run_walk_forward_step` does to verify the resulting (shorter) calculation.                                                                              |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82b6e73",
   "metadata": {},
   "source": [
    "| Function | How its Behavior Would Change | Pro | Con |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **`run_walk_forward_step` (Core Engine)** | It would now return an error for the final, shorter periods instead of clamping and calculating them. It becomes \"all or nothing.\" | The function's behavior is now stricter and more predictable. The results it returns are never from \"partial\" periods. | The function is less flexible; it can no longer handle end-of-timeline scenarios gracefully on its own. |\n",
    "| **`plot_walk_forward_analyzer` (UI)** | The user experience would be nearly identical, because it *already has* this pre-emptive check. The engine's check would just be a redundant confirmation. | The engine's behavior now perfectly matches the UI's pre-emptive check, removing any potential for divergence. | None, really. This is a positive change from the UI's perspective. |\n",
    "| **`run_full_backtest` & `run_strategy_search` (Automation)** | **This is the most significant impact.** When the backtest reaches the end of the data, `run_walk_forward_step` will return an error. The backtester's loop will then **skip this final, incomplete period entirely.** | The final aggregated equity curve and performance statistics are \"purer.\" Every single point comes from a full-length forward period. | The backtest **throws away the last few days/weeks of data** because they don't form a complete forward period. The resulting equity curve is shorter. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa735d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK Metric_Sharpe (ATR) for Calc. Period has error.\n",
    "- start date 2018-10-03\n",
    "- Calc Period 252\n",
    "- Fwd Period 63\n",
    "- Metric Sharpe ATR\n",
    "- Rank Start 1\n",
    "- Rank End 5\n",
    "-- Analysis Period 2018-10-03 to 2020-01-06 (this is full period, calc + fwd)\n",
    "-- [BIL, MINT, SHV, BNDX, VCSH]\n",
    "-- Metric_Sharpe (ATR) for BIL, MINT, SHV, BNDX matched my own calculation at bottom cell\n",
    "-- Metric Sharpe (ATR) for VCSH is a bit off (code calc 0.194195, my calc 0.196112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9fb9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5dc29c92",
   "metadata": {},
   "source": [
    "### Refactor Phase 1: Consolidated and Verified Feature Generation Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a98cae",
   "metadata": {},
   "source": [
    "### Start of Code for Refactoring Phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7be9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = r'c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet'\n",
    "df_ohlcv = pd.read_parquet(data_path, engine='pyarrow')\n",
    "df_ohlcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e7e98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_features(df_ohlcv: pd.DataFrame, \n",
    "                      atr_period: int = 14, \n",
    "                      quality_window: int = 252, \n",
    "                      quality_min_periods: int = 126) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates a comprehensive DataFrame of derived features from raw OHLCV data.\n",
    "\n",
    "    This function performs all heavy, window-based calculations upfront to be used\n",
    "    by downstream analysis functions. It calculates:\n",
    "    1. Technical Indicators: True Range (TR), ATR, and ATRP.\n",
    "    2. Data Quality Metrics: Rolling stale percentage, median dollar volume, etc.\n",
    "\n",
    "    Args:\n",
    "        df_ohlcv: The primary DataFrame with a (Ticker, Date) MultiIndex and\n",
    "                  columns for 'Adj High', 'Adj Low', 'Adj Close', 'Volume'.\n",
    "        atr_period: The lookback period for the ATR's Exponential Moving Average.\n",
    "        quality_window: The rolling window size for data quality metrics.\n",
    "        quality_min_periods: The minimum number of observations required to have\n",
    "                             a valid quality metric.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame with the same (Ticker, Date) MultiIndex containing all\n",
    "        calculated feature columns.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Feature Generation ---\")\n",
    "    \n",
    "    # Ensure the DataFrame is sorted for correct window and shift operations\n",
    "    # FIX: Replaced is_lexsorted() with the current pandas attribute\n",
    "    if not df_ohlcv.index.is_monotonic_increasing:\n",
    "        print(\"Sorting index for calculation accuracy...\")\n",
    "        df_ohlcv = df_ohlcv.sort_index()\n",
    "\n",
    "    # --- 1. Technical Indicator Calculation (TR, ATR, ATRP) ---\n",
    "    print(f\"Calculating technical indicators (ATR Period: {atr_period})...\")\n",
    "    \n",
    "    # Group by ticker to handle each security independently\n",
    "    grouped = df_ohlcv.groupby(level='Ticker')\n",
    "    \n",
    "    # Get the previous day's close required for True Range\n",
    "    prev_close = grouped['Adj Close'].shift(1)\n",
    "    \n",
    "    # Calculate the three components of True Range\n",
    "    high_low = df_ohlcv['Adj High'] - df_ohlcv['Adj Low']\n",
    "    high_prev_close = abs(df_ohlcv['Adj High'] - prev_close)\n",
    "    low_prev_close = abs(df_ohlcv['Adj Low'] - prev_close)\n",
    "    \n",
    "    # Combine the components to get the final TR\n",
    "    tr = pd.concat([high_low, high_prev_close, low_prev_close], axis=1).max(axis=1, skipna=False)\n",
    "    \n",
    "    # # Calculate the ATR using an Exponential Moving Average\n",
    "    # --- FIX IS HERE ---\n",
    "    # Use .transform() to apply the EWM function. \n",
    "    # This guarantees the resulting Series has the exact same index as 'tr',\n",
    "    # preventing the index alignment error during the subsequent division.\n",
    "    atr = tr.groupby(level='Ticker').transform(\n",
    "        lambda x: x.ewm(alpha=1/atr_period, adjust=False).mean()\n",
    "    )\n",
    "\n",
    "    # --- CHANGE 1: Removed .fillna(0) ---\n",
    "    # ATRP will now be NaN on the first day, consistent with TR and ATR.\n",
    "    atrp = (atr / df_ohlcv['Adj Close']).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    indicator_df = pd.DataFrame({\n",
    "        'TR': tr,\n",
    "        'ATR': atr,\n",
    "        'ATRP': atrp\n",
    "    })\n",
    "    \n",
    "    # --- 2. Data Quality Metric Calculation ---\n",
    "    print(f\"Calculating data quality metrics (Window: {quality_window} days)...\")\n",
    "    \n",
    "    # Create intermediate flags needed for quality calculations\n",
    "    is_stale = np.where((df_ohlcv['Volume'] == 0) | (df_ohlcv['Adj High'] == df_ohlcv['Adj Low']), 1, 0)\n",
    "    dollar_volume = df_ohlcv['Adj Close'] * df_ohlcv['Volume']\n",
    "    has_same_volume = (grouped['Volume'].diff() == 0).astype(int)\n",
    "    \n",
    "    # Combine flags into a temporary DataFrame for rolling calculations\n",
    "    quality_temp_df = pd.DataFrame({\n",
    "        'IsStale': is_stale,\n",
    "        'DollarVolume': dollar_volume,\n",
    "        'HasSameVolume': has_same_volume\n",
    "    }, index=df_ohlcv.index) # Explicitly set index to be safe\n",
    "    \n",
    "    # Perform the rolling calculations on the grouped data\n",
    "    # --- FIX IS HERE ---\n",
    "    # We switch to the older, more compatible dictionary-based aggregation method.\n",
    "    # This syntax is understood by nearly all versions of pandas.\n",
    "    rolling_result = quality_temp_df.groupby(level='Ticker').rolling(\n",
    "        window=quality_window,\n",
    "        min_periods=quality_min_periods\n",
    "    ).agg({\n",
    "        'IsStale': 'mean',\n",
    "        'DollarVolume': 'median',\n",
    "        'HasSameVolume': 'sum'\n",
    "    })\n",
    "    \n",
    "    # The dictionary syntax produces columns with the original names ('IsStale', etc.).\n",
    "    # We now explicitly rename them to our desired final names.\n",
    "    rolling_result = rolling_result.rename(columns={\n",
    "        'IsStale': 'RollingStalePct',\n",
    "        'DollarVolume': 'RollMedDollarVol', # <-- RENAMED HERE\n",
    "        'HasSameVolume': 'RollingSameVolCount'\n",
    "    })\n",
    "\n",
    "    # The index after a grouped rolling operation is hierarchical.\n",
    "    # We remove the outermost 'Ticker' level to restore the original index structure.\n",
    "    rolling_quality = rolling_result.reset_index(level=0, drop=True)\n",
    "\n",
    "    # --- 3. Combine All Features ---\n",
    "    print(\"Combining all feature sets...\")\n",
    "    features_df = pd.concat([indicator_df, rolling_quality], axis=1)\n",
    "    \n",
    "    print(\"✅ Feature generation complete.\")\n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e506f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_features_df(features_df: pd.DataFrame, \n",
    "                     df_ohlcv: pd.DataFrame, \n",
    "                     test_ticker: str = 'AAPL',\n",
    "                     spot_check_date: str = '2020-03-20'):\n",
    "    \"\"\"\n",
    "    Runs a suite of tests to verify the correctness of the generated features_df.\n",
    "\n",
    "    Args:\n",
    "        features_df: The generated DataFrame from the generate_features function.\n",
    "        df_ohlcv: The original source OHLCV DataFrame.\n",
    "        test_ticker: A common, liquid ticker to use for specific value checks.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Running Verification Suite for features_df (Test Ticker: {test_ticker}) ---\")\n",
    "    \n",
    "    # --- Test 1: Structural Integrity ---\n",
    "    print(\"\\n[Test 1: Structural Integrity]\")\n",
    "    assert features_df.index.equals(df_ohlcv.index), \"FAIL: Index does not match original df_ohlcv.\"\n",
    "    print(\"  ✅ PASS: Index matches original df_ohlcv.\")\n",
    "    \n",
    "    expected_cols = ['TR', 'ATR', 'ATRP', 'RollingStalePct', 'RollMedDollarVol', 'RollingSameVolCount']\n",
    "    assert all(col in features_df.columns for col in expected_cols), \"FAIL: Missing one or more expected columns.\"\n",
    "    print(\"  ✅ PASS: All expected feature columns are present.\")\n",
    "    print(f\"  - DataFrame Info:\")\n",
    "    features_df.info(verbose=False, memory_usage='deep')\n",
    "\n",
    "\n",
    "    # --- Test 2: ATR Calculation Logic ---\n",
    "    print(\"\\n[Test 2: ATR Logic Verification]\")\n",
    "    ticker_features = features_df.loc[test_ticker]\n",
    "    \n",
    "    # Test 2a: First TR value should be NaN (since prev_close is NaN)\n",
    "    first_tr = ticker_features['TR'].iloc[0]\n",
    "    assert pd.isna(first_tr), f\"FAIL: First TR value for {test_ticker} should be NaN, but got {first_tr}.\"\n",
    "    print(f\"  ✅ PASS: First TR value for {test_ticker} is NaN as expected.\")\n",
    "\n",
    "    # Test 2b: The first valid ATR should equal the first valid TR (EWM cold start behavior)\n",
    "    first_valid_tr_val = ticker_features['TR'].dropna().iloc[0]\n",
    "    first_valid_atr_val = ticker_features['ATR'].dropna().iloc[0]\n",
    "    assert np.isclose(first_valid_tr_val, first_valid_atr_val), \\\n",
    "        f\"FAIL: First valid ATR ({first_valid_atr_val}) should equal first valid TR ({first_valid_tr_val}).\"\n",
    "    print(\"  ✅ PASS: First valid ATR correctly seeded with first valid TR.\")\n",
    "\n",
    "\n",
    "    # --- Test 3: Rolling Quality Metrics Logic ---\n",
    "    print(\"\\n[Test 3: Rolling Quality Metrics Logic Verification]\")\n",
    "    quality_min_periods = 126 # Should match the parameter used in generation\n",
    "    \n",
    "    # Test 3a: Check for leading NaNs\n",
    "    first_valid_quality_idx = ticker_features['RollingStalePct'].first_valid_index()\n",
    "    if first_valid_quality_idx is None:\n",
    "        print(f\"  - INFO: No valid quality metrics found for {test_ticker} (likely too little data). Skipping test.\")\n",
    "    else:\n",
    "        position_of_first_valid = ticker_features.index.get_loc(first_valid_quality_idx)\n",
    "        assert position_of_first_valid == quality_min_periods - 1, \\\n",
    "            f\"FAIL: First valid quality metric should appear at index {quality_min_periods - 1}, but appeared at {position_of_first_valid}.\"\n",
    "        print(f\"  ✅ PASS: Leading NaNs are present for the first {quality_min_periods - 1} periods as expected.\")\n",
    "\n",
    "\n",
    "    # --- Test 4: Spot Check Against Manual Calculation ---\n",
    "    print(\"\\n[Test 4: Spot Check vs. Manual Calculation]\")\n",
    "    # # Choose a specific date for a manual calculation\n",
    "    # spot_check_date = '2020-03-20' # A volatile day for a good test\n",
    "    \n",
    "    # Manual TR Calculation\n",
    "    today_data = df_ohlcv.loc[(test_ticker, spot_check_date)]\n",
    "    yesterday_data = df_ohlcv.loc[(test_ticker, pd.to_datetime(spot_check_date) - pd.Timedelta(days=1))] # simple lookback for test\n",
    "    \n",
    "    manual_h_l = today_data['Adj High'] - today_data['Adj Low']\n",
    "    manual_h_pc = abs(today_data['Adj High'] - yesterday_data['Adj Close'])\n",
    "    manual_l_pc = abs(today_data['Adj Low'] - yesterday_data['Adj Close'])\n",
    "    manual_tr = max(manual_h_l, manual_h_pc, manual_l_pc)\n",
    "    \n",
    "    code_tr = ticker_features.loc[spot_check_date]['TR']\n",
    "    \n",
    "    assert np.isclose(manual_tr, code_tr), f\"FAIL: Manual TR ({manual_tr:.4f}) does not match code TR ({code_tr:.4f}) on {spot_check_date}.\"\n",
    "    print(f\"  ✅ PASS: Manually calculated TR on {spot_check_date} matches code's TR.\")\n",
    "    \n",
    "    print(\"\\n--- ✅ All Verification Tests Passed ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ebde23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This might take a minute or two depending on your data size and CPU\n",
    "features_df = generate_features(df_ohlcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abc1730",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a64033",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features_df(features_df, df_ohlcv, test_ticker='VCSH', spot_check_date='2018-10-03') \n",
    "# You can change the test_ticker to another well-known stock like 'MSFT' or 'GOOG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326ad84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_features = features_df.loc['VCSH']\n",
    "ticker_features.loc['2018-10-03':'2019-10-04']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c6fe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def export_ticker_data(ticker_to_export: str, \n",
    "                         df_ohlcv: pd.DataFrame, \n",
    "                         features_df: pd.DataFrame, \n",
    "                         output_dir: str = 'export_csv'):\n",
    "    \"\"\"\n",
    "    Exports the raw OHLCV data and the corresponding calculated features for a \n",
    "    single ticker to two separate CSV files.\n",
    "\n",
    "    This function is designed for easy manual verification of data and calculations.\n",
    "    It will create the output directory if it does not exist.\n",
    "\n",
    "    Args:\n",
    "        ticker_to_export: The ticker symbol to export (e.g., 'AAPL').\n",
    "        df_ohlcv: The main DataFrame containing the raw OHLCV data with a \n",
    "                  (Ticker, Date) MultiIndex.\n",
    "        features_df: The DataFrame containing the calculated features with a \n",
    "                     (Ticker, Date) MultiIndex.\n",
    "        output_dir: The directory where the CSV files will be saved. \n",
    "                    Defaults to 'export_csv'.\n",
    "    \"\"\"\n",
    "    print(f\"--- Attempting to export data for ticker: {ticker_to_export} ---\")\n",
    "    \n",
    "    # --- 1. Ensure the output directory exists ---\n",
    "    try:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        print(f\"Output directory '{output_dir}' is ready.\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error: Could not create directory '{output_dir}'. Reason: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 2. Isolate the data for the specified ticker ---\n",
    "    try:\n",
    "        # Use .loc to select all rows for the given ticker from the MultiIndex\n",
    "        ticker_ohlcv = df_ohlcv.loc[ticker_to_export]\n",
    "        ticker_features = features_df.loc[ticker_to_export]\n",
    "        \n",
    "        if ticker_ohlcv.empty:\n",
    "            print(f\"Warning: No OHLCV data found for ticker '{ticker_to_export}'. Cannot export.\")\n",
    "            return\n",
    "            \n",
    "        print(f\"Found {len(ticker_ohlcv)} rows of data for '{ticker_to_export}'.\")\n",
    "        \n",
    "    except KeyError:\n",
    "        print(f\"Error: Ticker '{ticker_to_export}' not found in one or both of the DataFrames. Please check the symbol.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while accessing data: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 3. Construct file paths and export to CSV ---\n",
    "    try:\n",
    "        # Define the full path for each output file\n",
    "        ohlcv_filename = f\"{ticker_to_export}_ohlcv.csv\"\n",
    "        features_filename = f\"{ticker_to_export}_features.csv\"\n",
    "        \n",
    "        ohlcv_filepath = os.path.join(output_dir, ohlcv_filename)\n",
    "        features_filepath = os.path.join(output_dir, features_filename)\n",
    "        \n",
    "        # Export the DataFrames to CSV. The index (Date) will be included.\n",
    "        ticker_ohlcv.to_csv(ohlcv_filepath)\n",
    "        ticker_features.to_csv(features_filepath)\n",
    "        \n",
    "        print(\"\\n✅ Export successful!\")\n",
    "        print(f\"   - Raw OHLCV data saved to: {ohlcv_filepath}\")\n",
    "        print(f\"   - Calculated features saved to: {features_filepath}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Failed to write data to CSV files. Reason: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323eefda",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_ticker_data('VCSH', df_ohlcv, features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37cf41f",
   "metadata": {},
   "source": [
    "### Part 1: Function to Create Synthetic Ticker Data\n",
    "\n",
    "This function creates a DataFrame for a single ticker (`SYNTH`) with specific, predictable patterns for stale days, dollar volume, and repeated volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51753192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os # Make sure os is imported for the export function later\n",
    "\n",
    "def create_synthetic_ticker_data(\n",
    "    ticker_name: str = 'SYNTH', \n",
    "    num_days: int = 50,\n",
    "    num_zero_volume_days: int = 5,\n",
    "    num_flat_price_days: int = 3\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a synthetic OHLCV DataFrame with predictable patterns and randomly injected\n",
    "    stale data conditions for robust testing.\n",
    "\n",
    "    Args:\n",
    "        ticker_name: The name for the synthetic ticker.\n",
    "        num_days: The total number of days for the ticker's history.\n",
    "        num_zero_volume_days: The number of random days to set Volume to 0.\n",
    "        num_flat_price_days: The number of random days to set High == Low.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame with a (Ticker, Date) MultiIndex.\n",
    "    \"\"\"\n",
    "    print(f\"--- Creating synthetic data for '{ticker_name}' with {num_days} days ---\")\n",
    "    \n",
    "    # 1. Create a base DataFrame with \"normal\" data\n",
    "    dates = pd.to_datetime(pd.date_range(start='2023-01-01', periods=num_days, freq='B'))\n",
    "    data = {\n",
    "        'Adj Open': 100.0, 'Adj High': 102.0, 'Adj Low': 98.0,\n",
    "        'Adj Close': 100.0, 'Volume': 1_000_000\n",
    "    }\n",
    "    df = pd.DataFrame(data, index=dates)\n",
    "    df['Adj Close'] = df['Adj Close'] + np.random.randn(num_days) * 0.5 # Add some noise\n",
    "\n",
    "    # 2. Define a \"protected\" window for specific verification tests.\n",
    "    # The `verify_synthetic_ticker_features` function depends on this exact window.\n",
    "    # We will not inject random stale days here.\n",
    "    protected_start_idx, protected_end_idx = 10, 20\n",
    "    \n",
    "    # 3. Inject random \"stale\" days OUTSIDE the protected window\n",
    "    available_indices = df.index.drop(df.index[protected_start_idx:protected_end_idx])\n",
    "    \n",
    "    # Inject zero-volume days\n",
    "    if num_zero_volume_days > 0:\n",
    "        if len(available_indices) < num_zero_volume_days:\n",
    "            raise ValueError(\"Not enough available days to inject zero-volume days.\")\n",
    "        zero_vol_dates = np.random.choice(available_indices, num_zero_volume_days, replace=False)\n",
    "        df.loc[zero_vol_dates, 'Volume'] = 0\n",
    "        print(f\"  - Injected {num_zero_volume_days} random zero-volume 'stale' days.\")\n",
    "        # Update available indices to avoid overlap\n",
    "        available_indices = available_indices.drop(zero_vol_dates)\n",
    "\n",
    "    # Inject flat-price days (High == Low)\n",
    "    if num_flat_price_days > 0:\n",
    "        if len(available_indices) < num_flat_price_days:\n",
    "            raise ValueError(\"Not enough available days to inject flat-price days.\")\n",
    "        flat_price_dates = np.random.choice(available_indices, num_flat_price_days, replace=False)\n",
    "        # Set High and Low to be the same as the Close price for that day\n",
    "        df.loc[flat_price_dates, 'Adj High'] = df.loc[flat_price_dates, 'Adj Close']\n",
    "        df.loc[flat_price_dates, 'Adj Low'] = df.loc[flat_price_dates, 'Adj Close']\n",
    "        print(f\"  - Injected {num_flat_price_days} random flat-price 'stale' days.\")\n",
    "\n",
    "    # 4. Inject the specific, hand-crafted patterns inside the protected window for verification\n",
    "    print(\"  - Injecting specific patterns for programmatic verification...\")\n",
    "    # Pattern for RollingStalePct: 2 stale days in 10 (20%)\n",
    "    df.iloc[10, df.columns.get_loc('Volume')] = 0  # Stale day (zero volume)\n",
    "    df.iloc[11, df.columns.get_loc('Adj High')] = 99.0 # Stale day (High == Low)\n",
    "    df.iloc[11, df.columns.get_loc('Adj Low')] = 99.0\n",
    "    \n",
    "    # Pattern for RollingMedianVolume\n",
    "    for i in range(10):\n",
    "        df.iloc[10 + i, df.columns.get_loc('Adj Close')] = 100.0 # Standardize price for easy median calc\n",
    "        df.iloc[10 + i, df.columns.get_loc('Volume')] = (i + 1) * 10000\n",
    "\n",
    "    # Pattern for RollingSameVolCount\n",
    "    df.iloc[15, df.columns.get_loc('Volume')] = 77777\n",
    "    df.iloc[16, df.columns.get_loc('Volume')] = 77777\n",
    "    df.iloc[17, df.columns.get_loc('Volume')] = 77777\n",
    "    \n",
    "    # 5. Set the MultiIndex\n",
    "    df['Ticker'] = ticker_name\n",
    "    df = df.set_index(['Ticker', df.index])\n",
    "    df.index.names = ['Ticker', 'Date']\n",
    "    \n",
    "    print(\"✅ Synthetic data created successfully.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d28048",
   "metadata": {},
   "source": [
    "### Part 2: Code to Test the Synthetic Data\n",
    "\n",
    "This new verification function is specifically designed to check the results from our synthetic data. It knows exactly what values to expect on a specific date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d19373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_synthetic_ticker_features(features_df: pd.DataFrame, \n",
    "                                       ticker_name: str = 'SYNTH',\n",
    "                                       quality_window: int = 10):\n",
    "    \"\"\"\n",
    "    Verifies the quality metric calculations on the features_df generated from\n",
    "    the synthetic ticker data.\n",
    "\n",
    "    Args:\n",
    "        features_df: The DataFrame of calculated features.\n",
    "        ticker_name: The name of the synthetic ticker.\n",
    "        quality_window: The rolling window used, which must match the window\n",
    "                        of the synthetic data pattern.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Running Verification on Synthetic Ticker '{ticker_name}' ---\")\n",
    "    \n",
    "    # --- Expected values based on our synthetic data design ---\n",
    "    EXPECTED_STALE_PCT = 0.20  # 2 stale days out of 10\n",
    "    EXPECTED_MEDIAN_DOLLAR_VOL = 5_500_000.0 # median of (10k..100k) * price of 100\n",
    "    EXPECTED_SAME_VOL_COUNT = 2.0 # Three consecutive days gives two 'diff() == 0' events\n",
    "\n",
    "    try:\n",
    "        # Isolate the features for our synthetic ticker\n",
    "        ticker_features = features_df.loc[ticker_name]\n",
    "        \n",
    "        # The first valid calculation will be on the last day of our 10-day window.\n",
    "        # The window starts at index 10 and has a length of 10, so it ends at index 19.\n",
    "        verification_date = ticker_features.index[19]\n",
    "        \n",
    "        print(f\"Verifying calculations on date: {verification_date.date()}\")\n",
    "        \n",
    "        # Get the calculated values from the DataFrame\n",
    "        calculated_values = ticker_features.loc[verification_date]\n",
    "        stale_pct = calculated_values['RollingStalePct']\n",
    "        # --- CHANGE 2 (continued): Accessing the renamed column ---\n",
    "        median_vol = calculated_values['RollMedDollarVol'] \n",
    "        same_vol_count = calculated_values['RollingSameVolCount']\n",
    "        \n",
    "        # --- Perform Assertions ---\n",
    "        print(\"\\n[Test 1: RollingStalePct]\")\n",
    "        assert np.isclose(stale_pct, EXPECTED_STALE_PCT), f\"FAIL: Expected {EXPECTED_STALE_PCT}, Got {stale_pct}\"\n",
    "        print(f\"  ✅ PASS: Expected {EXPECTED_STALE_PCT}, Got {stale_pct}\")\n",
    "\n",
    "        print(\"\\n[Test 2: RollMedDollarVol]\")\n",
    "        assert np.isclose(median_vol, EXPECTED_MEDIAN_DOLLAR_VOL), f\"FAIL: Expected {EXPECTED_MEDIAN_DOLLAR_VOL}, Got {median_vol}\"\n",
    "        print(f\"  ✅ PASS: Expected {EXPECTED_MEDIAN_DOLLAR_VOL}, Got {median_vol}\")\n",
    "\n",
    "        print(\"\\n[Test 3: RollingSameVolCount]\")\n",
    "        assert np.isclose(same_vol_count, EXPECTED_SAME_VOL_COUNT), f\"FAIL: Expected {EXPECTED_SAME_VOL_COUNT}, Got {same_vol_count}\"\n",
    "        print(f\"  ✅ PASS: Expected {EXPECTED_SAME_VOL_COUNT}, Got {same_vol_count}\")\n",
    "\n",
    "        print(\"\\n--- ✅ All Synthetic Data Verification Tests Passed ---\")\n",
    "\n",
    "    except KeyError:\n",
    "        print(f\"FAIL: Ticker '{ticker_name}' not found in features_df.\")\n",
    "    except IndexError:\n",
    "        print(\"FAIL: Not enough data in features_df to run verification. Check num_days.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during verification: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47506201",
   "metadata": {},
   "source": [
    "## Part 3: Main Script to Run Everything\n",
    "\n",
    "This block of code ties it all together. You will need your `generate_features` and `export_ticker_data` functions available in the same environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716eff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main Execution Block ---\n",
    "\n",
    "# Make sure you have 'generate_features', 'verify_synthetic_ticker_features', \n",
    "# and 'export_ticker_data' functions available in your environment.\n",
    "\n",
    "# --- Step 1: Define Parameters ---\n",
    "SYNTHETIC_TICKER_NAME = 'SYNTH_STALE_TEST'\n",
    "QUALITY_WINDOW_FOR_TEST = 20\n",
    "MIN_PERIODS_FOR_TEST = 10 \n",
    "\n",
    "# --- Step 2: Create Synthetic Data with More Stale Days ---\n",
    "# We'll create 8 zero-volume days and 4 flat-price days.\n",
    "df_ohlcv_synth = create_synthetic_ticker_data(\n",
    "    ticker_name=SYNTHETIC_TICKER_NAME, \n",
    "    num_days=100, # Use more days to have space for random stale days\n",
    "    num_zero_volume_days=8,\n",
    "    num_flat_price_days=4\n",
    ")\n",
    "\n",
    "# --- Step 3: Run Feature Generation ---\n",
    "features_df_synth = generate_features(\n",
    "    df_ohlcv_synth,\n",
    "    quality_window=QUALITY_WINDOW_FOR_TEST,\n",
    "    quality_min_periods=MIN_PERIODS_FOR_TEST\n",
    ")\n",
    "\n",
    "# --- Step 4: Verify the Core Logic (this will still pass) ---\n",
    "# The verification function checks the specific 10-day window, which we preserved.\n",
    "verify_synthetic_ticker_features(\n",
    "    features_df_synth,\n",
    "    ticker_name=SYNTHETIC_TICKER_NAME,\n",
    "    quality_window=QUALITY_WINDOW_FOR_TEST\n",
    ")\n",
    "\n",
    "# --- Step 5: Export for Manual Inspection ---\n",
    "# When you open the CSVs, you will now see the additional random stale days\n",
    "# you created, allowing you to manually check the rolling calculations anywhere.\n",
    "print(\"\\n--- Exporting Enhanced Synthetic Data for Manual Review ---\")\n",
    "export_ticker_data(\n",
    "    ticker_to_export=SYNTHETIC_TICKER_NAME,\n",
    "    df_ohlcv=df_ohlcv_synth,\n",
    "    features_df=features_df_synth\n",
    ")\n",
    "\n",
    "# --- Step 6: Generate_features Parameters ---\n",
    "print(\"\\n--- Generate_features Parameters ---\")\n",
    "print(f'quality_window: {QUALITY_WINDOW_FOR_TEST}')\n",
    "print(f'quality_min_periods: {MIN_PERIODS_FOR_TEST}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec2dcbb",
   "metadata": {},
   "source": [
    "### End of Code for Refactoring Phase 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a42aca",
   "metadata": {},
   "source": [
    "## Project Hand-off: Walk-Forward Backtesting Bot\n",
    "\n",
    "This package contains the final version of the code, designed to be resilient, portable, and easy to use in both local (VS Code) and cloud (Google Colab) environments.\n",
    "\n",
    "### 1. Summary of Key Features\n",
    "\n",
    "The system you have built now includes:\n",
    "\n",
    "*   **Environment-Agnostic Operation:** A \"magic switch\" automatically detects whether the code is running locally or in Colab and adjusts all file paths accordingly.\n",
    "*   **Resumable Backtests (Checkpointing):** Long-running parameter searches are now resilient. If the process is interrupted, it can be restarted and will automatically skip completed work, picking up where it left off.\n",
    "*   **Granular, Trading-Day-Based Logic:** The backtester operates on precise integer counts of trading days, allowing for non-calendar-based periods (e.g., 10-day holds) and eliminating approximation errors.\n",
    "*   **Multi-Period Testing:** The automation script is capable of testing a list of different holding/rebalancing periods in a single run.\n",
    "*   **Modular & Verifiable Core Engine:** The core calculation logic (`run_walk_forward_step`) is a pure, self-contained function, making it easy to test and verify independently.\n",
    "*   **Dynamic Data Quality Filtering:** Before each ranking period, the universe of stocks is filtered based on rolling liquidity and data quality metrics, ensuring the strategy is only applied to tradable assets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5182cc74",
   "metadata": {},
   "source": [
    "### 2. Required Project Structure\n",
    "\n",
    "For the environment switch to work seamlessly, your project should be organized in the following way, both on your local machine and in Google Drive.\n",
    "\n",
    "```\n",
    "my_trading_project/\n",
    "│\n",
    "├── 📜 bot.ipynb                 # <-- This is the main notebook file\n",
    "│\n",
    "├── 📁 data/\n",
    "│   └── 📊 df_OHLCV_stocks_etfs.parquet # <-- Your input data file goes here\n",
    "│\n",
    "└── 📁 export_csv/                 # <-- Folder for local results (created automatically)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76715d2a",
   "metadata": {},
   "source": [
    "### 3. Final, Complete Code\n",
    "\n",
    "This is the entire code for your notebook, consolidated into logical cells.\n",
    "\n",
    "#### **CELL 1: ENVIRONMENT SETUP & CONFIGURATION**\n",
    "*This cell is the \"brain\" of the system. It detects the environment and configures all paths. It's the only cell you might need to edit if your file paths change.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8a246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# --- CELL 1: ENVIRONMENT SETUP & CONFIGURATION (IMPROVED) ---\n",
    "# This cell automatically detects the environment (local VS Code or Google Colab)\n",
    "# and configures paths and settings accordingly. It also creates directories.\n",
    "# ==============================================================================\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# 1. AUTOMATIC ENVIRONMENT DETECTION\n",
    "try:\n",
    "    import google.colab\n",
    "    IS_COLAB = True\n",
    "    print(\"✅ Environment: Google Colab detected.\")\n",
    "except ImportError:\n",
    "    IS_COLAB = False\n",
    "    print(\"✅ Environment: Local (VS Code) detected.\")\n",
    "\n",
    "# 2. ENVIRONMENT-SPECIFIC CONFIGURATION\n",
    "if IS_COLAB:\n",
    "    # --- Colab Settings ---\n",
    "    from google.colab import drive, output\n",
    "    drive.mount('/content/drive')\n",
    "    output.enable_custom_widget_manager()\n",
    "    \n",
    "    # IMPORTANT: This should be the path to your main project folder in Google Drive\n",
    "    DRIVE_ROOT = '/content/drive/MyDrive/my_trading_project'\n",
    "    \n",
    "    env_config = {\n",
    "        'data_path': os.path.join(DRIVE_ROOT, 'data', 'df_OHLCV_stocks_etfs.parquet'),\n",
    "        'output_dir': os.path.join(DRIVE_ROOT, 'results') # Colab results go in a 'results' folder\n",
    "    }\n",
    "    \n",
    "else:\n",
    "    # --- Local Settings ---\n",
    "    # IMPORTANT: Update this path to your local data file if it's different\n",
    "    env_config = {\n",
    "        'data_path': r'c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet',\n",
    "        'output_dir': os.path.join('.', 'export_csv') # Local results go in 'export_csv'\n",
    "    }\n",
    "\n",
    "# 3. CREATE ALL NECESSARY DIRECTORIES\n",
    "data_parent_dir = os.path.dirname(env_config['data_path'])\n",
    "os.makedirs(data_parent_dir, exist_ok=True)\n",
    "os.makedirs(env_config['output_dir'], exist_ok=True)\n",
    "\n",
    "print(f\"\\nData will be loaded from: {env_config['data_path']}\")\n",
    "print(f\"Output files will be saved to: {env_config['output_dir']}\")\n",
    "\n",
    "# 4. DEFINE THE FULL PATH FOR THE RESULTS FILE\n",
    "env_config['results_path'] = os.path.join(env_config['output_dir'], 'dev_strategy_search_results.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38189318",
   "metadata": {},
   "source": [
    "#### **CELL 2: GOLDEN COPY - CORE ENGINE & TOOLS**\n",
    "*This cell contains all the stable, tested functions that form the core of your backtester.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96383d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# GOLDEN COPY - COMPLETE PROJECT CODE (All Fixes Included)\n",
    "# Version: Added Refactoring Phase 1 code  \n",
    "# Date: 2025-10-14\n",
    "# ==============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets\n",
    "import time\n",
    "import pprint\n",
    "import os # Make sure os is imported for the export function later\n",
    "import re\n",
    "\n",
    "from datetime import datetime, date\n",
    "from IPython.display import display, Markdown\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 30)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 3000)\n",
    "\n",
    "\n",
    "# --- REFACTORING PHASE 1 CODE: Feature Generation Engine ---\n",
    "\n",
    "def generate_features(df_ohlcv: pd.DataFrame, \n",
    "                      atr_period: int = 14, \n",
    "                      quality_window: int = 252, \n",
    "                      quality_min_periods: int = 126) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates a comprehensive DataFrame of derived features from raw OHLCV data.\n",
    "\n",
    "    This function performs all heavy, window-based calculations upfront to be used\n",
    "    by downstream analysis functions. It calculates:\n",
    "    1. Technical Indicators: True Range (TR), ATR, and ATRP.\n",
    "    2. Data Quality Metrics: Rolling stale percentage, median dollar volume, etc.\n",
    "\n",
    "    Args:\n",
    "        df_ohlcv: The primary DataFrame with a (Ticker, Date) MultiIndex and\n",
    "                  columns for 'Adj High', 'Adj Low', 'Adj Close', 'Volume'.\n",
    "        atr_period: The lookback period for the ATR's Exponential Moving Average.\n",
    "        quality_window: The rolling window size for data quality metrics.\n",
    "        quality_min_periods: The minimum number of observations required to have\n",
    "                             a valid quality metric.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame with the same (Ticker, Date) MultiIndex containing all\n",
    "        calculated feature columns.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Feature Generation ---\")\n",
    "    \n",
    "    # Ensure the DataFrame is sorted for correct window and shift operations\n",
    "    # FIX: Replaced is_lexsorted() with the current pandas attribute\n",
    "    if not df_ohlcv.index.is_monotonic_increasing:\n",
    "        print(\"Sorting index for calculation accuracy...\")\n",
    "        df_ohlcv = df_ohlcv.sort_index()\n",
    "\n",
    "    # --- 1. Technical Indicator Calculation (TR, ATR, ATRP) ---\n",
    "    print(f\"Calculating technical indicators (ATR Period: {atr_period})...\")\n",
    "    \n",
    "    # Group by ticker to handle each security independently\n",
    "    grouped = df_ohlcv.groupby(level='Ticker')\n",
    "    \n",
    "    # Get the previous day's close required for True Range\n",
    "    prev_close = grouped['Adj Close'].shift(1)\n",
    "    \n",
    "    # Calculate the three components of True Range\n",
    "    high_low = df_ohlcv['Adj High'] - df_ohlcv['Adj Low']\n",
    "    high_prev_close = abs(df_ohlcv['Adj High'] - prev_close)\n",
    "    low_prev_close = abs(df_ohlcv['Adj Low'] - prev_close)\n",
    "    \n",
    "    # Combine the components to get the final TR\n",
    "    tr = pd.concat([high_low, high_prev_close, low_prev_close], axis=1).max(axis=1, skipna=False)\n",
    "    \n",
    "    # # Calculate the ATR using an Exponential Moving Average\n",
    "    # --- FIX IS HERE ---\n",
    "    # Use .transform() to apply the EWM function. \n",
    "    # This guarantees the resulting Series has the exact same index as 'tr',\n",
    "    # preventing the index alignment error during the subsequent division.\n",
    "    atr = tr.groupby(level='Ticker').transform(\n",
    "        lambda x: x.ewm(alpha=1/atr_period, adjust=False).mean()\n",
    "    )\n",
    "\n",
    "    # --- CHANGE 1: Removed .fillna(0) ---\n",
    "    # ATRP will now be NaN on the first day, consistent with TR and ATR.\n",
    "    atrp = (atr / df_ohlcv['Adj Close']).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    indicator_df = pd.DataFrame({\n",
    "        'TR': tr,\n",
    "        'ATR': atr,\n",
    "        'ATRP': atrp\n",
    "    })\n",
    "    \n",
    "    # --- 2. Data Quality Metric Calculation ---\n",
    "    print(f\"Calculating data quality metrics (Window: {quality_window} days)...\")\n",
    "    \n",
    "    # Create intermediate flags needed for quality calculations\n",
    "    is_stale = np.where((df_ohlcv['Volume'] == 0) | (df_ohlcv['Adj High'] == df_ohlcv['Adj Low']), 1, 0)\n",
    "    dollar_volume = df_ohlcv['Adj Close'] * df_ohlcv['Volume']\n",
    "    has_same_volume = (grouped['Volume'].diff() == 0).astype(int)\n",
    "    \n",
    "    # Combine flags into a temporary DataFrame for rolling calculations\n",
    "    quality_temp_df = pd.DataFrame({\n",
    "        'IsStale': is_stale,\n",
    "        'DollarVolume': dollar_volume,\n",
    "        'HasSameVolume': has_same_volume\n",
    "    }, index=df_ohlcv.index) # Explicitly set index to be safe\n",
    "    \n",
    "    # Perform the rolling calculations on the grouped data\n",
    "    # --- FIX IS HERE ---\n",
    "    # We switch to the older, more compatible dictionary-based aggregation method.\n",
    "    # This syntax is understood by nearly all versions of pandas.\n",
    "    rolling_result = quality_temp_df.groupby(level='Ticker').rolling(\n",
    "        window=quality_window,\n",
    "        min_periods=quality_min_periods\n",
    "    ).agg({\n",
    "        'IsStale': 'mean',\n",
    "        'DollarVolume': 'median',\n",
    "        'HasSameVolume': 'sum'\n",
    "    })\n",
    "    \n",
    "    # The dictionary syntax produces columns with the original names ('IsStale', etc.).\n",
    "    # We now explicitly rename them to our desired final names.\n",
    "    rolling_result = rolling_result.rename(columns={\n",
    "        'IsStale': 'RollingStalePct',\n",
    "        'DollarVolume': 'RollMedDollarVol', # <-- RENAMED HERE\n",
    "        'HasSameVolume': 'RollingSameVolCount'\n",
    "    })\n",
    "\n",
    "    # The index after a grouped rolling operation is hierarchical.\n",
    "    # We remove the outermost 'Ticker' level to restore the original index structure.\n",
    "    rolling_quality = rolling_result.reset_index(level=0, drop=True)\n",
    "\n",
    "    # --- 3. Combine All Features ---\n",
    "    print(\"Combining all feature sets...\")\n",
    "    features_df = pd.concat([indicator_df, rolling_quality], axis=1)\n",
    "    \n",
    "    print(\"✅ Feature generation complete.\")\n",
    "    return features_df\n",
    "\n",
    "def test_features_df(features_df: pd.DataFrame, \n",
    "                     df_ohlcv: pd.DataFrame, \n",
    "                     test_ticker: str = 'AAPL',\n",
    "                     spot_check_date: str = '2020-03-20'):\n",
    "    \"\"\"\n",
    "    Runs a suite of tests to verify the correctness of the generated features_df.\n",
    "\n",
    "    Args:\n",
    "        features_df: The generated DataFrame from the generate_features function.\n",
    "        df_ohlcv: The original source OHLCV DataFrame.\n",
    "        test_ticker: A common, liquid ticker to use for specific value checks.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Running Verification Suite for features_df (Test Ticker: {test_ticker}) ---\")\n",
    "    \n",
    "    # --- Test 1: Structural Integrity ---\n",
    "    print(\"\\n[Test 1: Structural Integrity]\")\n",
    "    assert features_df.index.equals(df_ohlcv.index), \"FAIL: Index does not match original df_ohlcv.\"\n",
    "    print(\"  ✅ PASS: Index matches original df_ohlcv.\")\n",
    "    \n",
    "    expected_cols = ['TR', 'ATR', 'ATRP', 'RollingStalePct', 'RollMedDollarVol', 'RollingSameVolCount']\n",
    "    assert all(col in features_df.columns for col in expected_cols), \"FAIL: Missing one or more expected columns.\"\n",
    "    print(\"  ✅ PASS: All expected feature columns are present.\")\n",
    "    print(f\"  - DataFrame Info:\")\n",
    "    features_df.info(verbose=False, memory_usage='deep')\n",
    "\n",
    "\n",
    "    # --- Test 2: ATR Calculation Logic ---\n",
    "    print(\"\\n[Test 2: ATR Logic Verification]\")\n",
    "    ticker_features = features_df.loc[test_ticker]\n",
    "    \n",
    "    # Test 2a: First TR value should be NaN (since prev_close is NaN)\n",
    "    first_tr = ticker_features['TR'].iloc[0]\n",
    "    assert pd.isna(first_tr), f\"FAIL: First TR value for {test_ticker} should be NaN, but got {first_tr}.\"\n",
    "    print(f\"  ✅ PASS: First TR value for {test_ticker} is NaN as expected.\")\n",
    "\n",
    "    # Test 2b: The first valid ATR should equal the first valid TR (EWM cold start behavior)\n",
    "    first_valid_tr_val = ticker_features['TR'].dropna().iloc[0]\n",
    "    first_valid_atr_val = ticker_features['ATR'].dropna().iloc[0]\n",
    "    assert np.isclose(first_valid_tr_val, first_valid_atr_val), \\\n",
    "        f\"FAIL: First valid ATR ({first_valid_atr_val}) should equal first valid TR ({first_valid_tr_val}).\"\n",
    "    print(\"  ✅ PASS: First valid ATR correctly seeded with first valid TR.\")\n",
    "\n",
    "\n",
    "    # --- Test 3: Rolling Quality Metrics Logic ---\n",
    "    print(\"\\n[Test 3: Rolling Quality Metrics Logic Verification]\")\n",
    "    quality_min_periods = 126 # Should match the parameter used in generation\n",
    "    \n",
    "    # Test 3a: Check for leading NaNs\n",
    "    first_valid_quality_idx = ticker_features['RollingStalePct'].first_valid_index()\n",
    "    if first_valid_quality_idx is None:\n",
    "        print(f\"  - INFO: No valid quality metrics found for {test_ticker} (likely too little data). Skipping test.\")\n",
    "    else:\n",
    "        position_of_first_valid = ticker_features.index.get_loc(first_valid_quality_idx)\n",
    "        assert position_of_first_valid == quality_min_periods - 1, \\\n",
    "            f\"FAIL: First valid quality metric should appear at index {quality_min_periods - 1}, but appeared at {position_of_first_valid}.\"\n",
    "        print(f\"  ✅ PASS: Leading NaNs are present for the first {quality_min_periods - 1} periods as expected.\")\n",
    "\n",
    "\n",
    "    # --- Test 4: Spot Check Against Manual Calculation ---\n",
    "    print(\"\\n[Test 4: Spot Check vs. Manual Calculation]\")\n",
    "    # # Choose a specific date for a manual calculation\n",
    "    # spot_check_date = '2020-03-20' # A volatile day for a good test\n",
    "    \n",
    "    # Manual TR Calculation\n",
    "    today_data = df_ohlcv.loc[(test_ticker, spot_check_date)]\n",
    "    yesterday_data = df_ohlcv.loc[(test_ticker, pd.to_datetime(spot_check_date) - pd.Timedelta(days=1))] # simple lookback for test\n",
    "    \n",
    "    manual_h_l = today_data['Adj High'] - today_data['Adj Low']\n",
    "    manual_h_pc = abs(today_data['Adj High'] - yesterday_data['Adj Close'])\n",
    "    manual_l_pc = abs(today_data['Adj Low'] - yesterday_data['Adj Close'])\n",
    "    manual_tr = max(manual_h_l, manual_h_pc, manual_l_pc)\n",
    "    \n",
    "    code_tr = ticker_features.loc[spot_check_date]['TR']\n",
    "    \n",
    "    assert np.isclose(manual_tr, code_tr), f\"FAIL: Manual TR ({manual_tr:.4f}) does not match code TR ({code_tr:.4f}) on {spot_check_date}.\"\n",
    "    print(f\"  ✅ PASS: Manually calculated TR on {spot_check_date} matches code's TR.\")\n",
    "    \n",
    "    print(\"\\n--- ✅ All Verification Tests Passed ---\")\n",
    "\n",
    "def export_ticker_data(ticker_to_export: str, \n",
    "                         df_ohlcv: pd.DataFrame, \n",
    "                         features_df: pd.DataFrame, \n",
    "                         output_dir: str = 'export_csv'):\n",
    "    \"\"\"\n",
    "    Exports the raw OHLCV data and the corresponding calculated features for a \n",
    "    single ticker to two separate CSV files.\n",
    "\n",
    "    This function is designed for easy manual verification of data and calculations.\n",
    "    It will create the output directory if it does not exist.\n",
    "\n",
    "    Args:\n",
    "        ticker_to_export: The ticker symbol to export (e.g., 'AAPL').\n",
    "        df_ohlcv: The main DataFrame containing the raw OHLCV data with a \n",
    "                  (Ticker, Date) MultiIndex.\n",
    "        features_df: The DataFrame containing the calculated features with a \n",
    "                     (Ticker, Date) MultiIndex.\n",
    "        output_dir: The directory where the CSV files will be saved. \n",
    "                    Defaults to 'export_csv'.\n",
    "    \"\"\"\n",
    "    print(f\"--- Attempting to export data for ticker: {ticker_to_export} ---\")\n",
    "    \n",
    "    # --- 1. Ensure the output directory exists ---\n",
    "    try:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        print(f\"Output directory '{output_dir}' is ready.\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error: Could not create directory '{output_dir}'. Reason: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 2. Isolate the data for the specified ticker ---\n",
    "    try:\n",
    "        # Use .loc to select all rows for the given ticker from the MultiIndex\n",
    "        ticker_ohlcv = df_ohlcv.loc[ticker_to_export]\n",
    "        ticker_features = features_df.loc[ticker_to_export]\n",
    "        \n",
    "        if ticker_ohlcv.empty:\n",
    "            print(f\"Warning: No OHLCV data found for ticker '{ticker_to_export}'. Cannot export.\")\n",
    "            return\n",
    "            \n",
    "        print(f\"Found {len(ticker_ohlcv)} rows of data for '{ticker_to_export}'.\")\n",
    "        \n",
    "    except KeyError:\n",
    "        print(f\"Error: Ticker '{ticker_to_export}' not found in one or both of the DataFrames. Please check the symbol.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while accessing data: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 3. Construct file paths and export to CSV ---\n",
    "    try:\n",
    "        # Define the full path for each output file\n",
    "        ohlcv_filename = f\"{ticker_to_export}_ohlcv.csv\"\n",
    "        features_filename = f\"{ticker_to_export}_features.csv\"\n",
    "        \n",
    "        ohlcv_filepath = os.path.join(output_dir, ohlcv_filename)\n",
    "        features_filepath = os.path.join(output_dir, features_filename)\n",
    "        \n",
    "        # Export the DataFrames to CSV. The index (Date) will be included.\n",
    "        ticker_ohlcv.to_csv(ohlcv_filepath)\n",
    "        ticker_features.to_csv(features_filepath)\n",
    "        \n",
    "        print(\"\\n✅ Export successful!\")\n",
    "        print(f\"   - Raw OHLCV data saved to: {ohlcv_filepath}\")\n",
    "        print(f\"   - Calculated features saved to: {features_filepath}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Failed to write data to CSV files. Reason: {e}\")\n",
    "\n",
    "def create_synthetic_ticker_data(\n",
    "    ticker_name: str = 'SYNTH', \n",
    "    num_days: int = 50,\n",
    "    num_zero_volume_days: int = 5,\n",
    "    num_flat_price_days: int = 3\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a synthetic OHLCV DataFrame with predictable patterns and randomly injected\n",
    "    stale data conditions for robust testing.\n",
    "\n",
    "    Args:\n",
    "        ticker_name: The name for the synthetic ticker.\n",
    "        num_days: The total number of days for the ticker's history.\n",
    "        num_zero_volume_days: The number of random days to set Volume to 0.\n",
    "        num_flat_price_days: The number of random days to set High == Low.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame with a (Ticker, Date) MultiIndex.\n",
    "    \"\"\"\n",
    "    print(f\"--- Creating synthetic data for '{ticker_name}' with {num_days} days ---\")\n",
    "    \n",
    "    # 1. Create a base DataFrame with \"normal\" data\n",
    "    dates = pd.to_datetime(pd.date_range(start='2023-01-01', periods=num_days, freq='B'))\n",
    "    data = {\n",
    "        'Adj Open': 100.0, 'Adj High': 102.0, 'Adj Low': 98.0,\n",
    "        'Adj Close': 100.0, 'Volume': 1_000_000\n",
    "    }\n",
    "    df = pd.DataFrame(data, index=dates)\n",
    "    df['Adj Close'] = df['Adj Close'] + np.random.randn(num_days) * 0.5 # Add some noise\n",
    "\n",
    "    # 2. Define a \"protected\" window for specific verification tests.\n",
    "    # The `verify_synthetic_ticker_features` function depends on this exact window.\n",
    "    # We will not inject random stale days here.\n",
    "    protected_start_idx, protected_end_idx = 10, 20\n",
    "    \n",
    "    # 3. Inject random \"stale\" days OUTSIDE the protected window\n",
    "    available_indices = df.index.drop(df.index[protected_start_idx:protected_end_idx])\n",
    "    \n",
    "    # Inject zero-volume days\n",
    "    if num_zero_volume_days > 0:\n",
    "        if len(available_indices) < num_zero_volume_days:\n",
    "            raise ValueError(\"Not enough available days to inject zero-volume days.\")\n",
    "        zero_vol_dates = np.random.choice(available_indices, num_zero_volume_days, replace=False)\n",
    "        df.loc[zero_vol_dates, 'Volume'] = 0\n",
    "        print(f\"  - Injected {num_zero_volume_days} random zero-volume 'stale' days.\")\n",
    "        # Update available indices to avoid overlap\n",
    "        available_indices = available_indices.drop(zero_vol_dates)\n",
    "\n",
    "    # Inject flat-price days (High == Low)\n",
    "    if num_flat_price_days > 0:\n",
    "        if len(available_indices) < num_flat_price_days:\n",
    "            raise ValueError(\"Not enough available days to inject flat-price days.\")\n",
    "        flat_price_dates = np.random.choice(available_indices, num_flat_price_days, replace=False)\n",
    "        # Set High and Low to be the same as the Close price for that day\n",
    "        df.loc[flat_price_dates, 'Adj High'] = df.loc[flat_price_dates, 'Adj Close']\n",
    "        df.loc[flat_price_dates, 'Adj Low'] = df.loc[flat_price_dates, 'Adj Close']\n",
    "        print(f\"  - Injected {num_flat_price_days} random flat-price 'stale' days.\")\n",
    "\n",
    "    # 4. Inject the specific, hand-crafted patterns inside the protected window for verification\n",
    "    print(\"  - Injecting specific patterns for programmatic verification...\")\n",
    "    # Pattern for RollingStalePct: 2 stale days in 10 (20%)\n",
    "    df.iloc[10, df.columns.get_loc('Volume')] = 0  # Stale day (zero volume)\n",
    "    df.iloc[11, df.columns.get_loc('Adj High')] = 99.0 # Stale day (High == Low)\n",
    "    df.iloc[11, df.columns.get_loc('Adj Low')] = 99.0\n",
    "    \n",
    "    # Pattern for RollingMedianVolume\n",
    "    for i in range(10):\n",
    "        df.iloc[10 + i, df.columns.get_loc('Adj Close')] = 100.0 # Standardize price for easy median calc\n",
    "        df.iloc[10 + i, df.columns.get_loc('Volume')] = (i + 1) * 10000\n",
    "\n",
    "    # Pattern for RollingSameVolCount\n",
    "    df.iloc[15, df.columns.get_loc('Volume')] = 77777\n",
    "    df.iloc[16, df.columns.get_loc('Volume')] = 77777\n",
    "    df.iloc[17, df.columns.get_loc('Volume')] = 77777\n",
    "    \n",
    "    # 5. Set the MultiIndex\n",
    "    df['Ticker'] = ticker_name\n",
    "    df = df.set_index(['Ticker', df.index])\n",
    "    df.index.names = ['Ticker', 'Date']\n",
    "    \n",
    "    print(\"✅ Synthetic data created successfully.\")\n",
    "    return df\n",
    "\n",
    "def verify_synthetic_ticker_features(features_df: pd.DataFrame, \n",
    "                                       ticker_name: str = 'SYNTH',\n",
    "                                       quality_window: int = 10):\n",
    "    \"\"\"\n",
    "    Verifies the quality metric calculations on the features_df generated from\n",
    "    the synthetic ticker data.\n",
    "\n",
    "    Args:\n",
    "        features_df: The DataFrame of calculated features.\n",
    "        ticker_name: The name of the synthetic ticker.\n",
    "        quality_window: The rolling window used, which must match the window\n",
    "                        of the synthetic data pattern.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Running Verification on Synthetic Ticker '{ticker_name}' ---\")\n",
    "    \n",
    "    # --- Expected values based on our synthetic data design ---\n",
    "    EXPECTED_STALE_PCT = 0.20  # 2 stale days out of 10\n",
    "    EXPECTED_MEDIAN_DOLLAR_VOL = 5_500_000.0 # median of (10k..100k) * price of 100\n",
    "    EXPECTED_SAME_VOL_COUNT = 2.0 # Three consecutive days gives two 'diff() == 0' events\n",
    "\n",
    "    try:\n",
    "        # Isolate the features for our synthetic ticker\n",
    "        ticker_features = features_df.loc[ticker_name]\n",
    "        \n",
    "        # The first valid calculation will be on the last day of our 10-day window.\n",
    "        # The window starts at index 10 and has a length of 10, so it ends at index 19.\n",
    "        verification_date = ticker_features.index[19]\n",
    "        \n",
    "        print(f\"Verifying calculations on date: {verification_date.date()}\")\n",
    "        \n",
    "        # Get the calculated values from the DataFrame\n",
    "        calculated_values = ticker_features.loc[verification_date]\n",
    "        stale_pct = calculated_values['RollingStalePct']\n",
    "        # --- CHANGE 2 (continued): Accessing the renamed column ---\n",
    "        median_vol = calculated_values['RollMedDollarVol'] \n",
    "        same_vol_count = calculated_values['RollingSameVolCount']\n",
    "        \n",
    "        # --- Perform Assertions ---\n",
    "        print(\"\\n[Test 1: RollingStalePct]\")\n",
    "        assert np.isclose(stale_pct, EXPECTED_STALE_PCT), f\"FAIL: Expected {EXPECTED_STALE_PCT}, Got {stale_pct}\"\n",
    "        print(f\"  ✅ PASS: Expected {EXPECTED_STALE_PCT}, Got {stale_pct}\")\n",
    "\n",
    "        print(\"\\n[Test 2: RollMedDollarVol]\")\n",
    "        assert np.isclose(median_vol, EXPECTED_MEDIAN_DOLLAR_VOL), f\"FAIL: Expected {EXPECTED_MEDIAN_DOLLAR_VOL}, Got {median_vol}\"\n",
    "        print(f\"  ✅ PASS: Expected {EXPECTED_MEDIAN_DOLLAR_VOL}, Got {median_vol}\")\n",
    "\n",
    "        print(\"\\n[Test 3: RollingSameVolCount]\")\n",
    "        assert np.isclose(same_vol_count, EXPECTED_SAME_VOL_COUNT), f\"FAIL: Expected {EXPECTED_SAME_VOL_COUNT}, Got {same_vol_count}\"\n",
    "        print(f\"  ✅ PASS: Expected {EXPECTED_SAME_VOL_COUNT}, Got {same_vol_count}\")\n",
    "\n",
    "        print(\"\\n--- ✅ All Synthetic Data Verification Tests Passed ---\")\n",
    "\n",
    "    except KeyError:\n",
    "        print(f\"FAIL: Ticker '{ticker_name}' not found in features_df.\")\n",
    "    except IndexError:\n",
    "        print(\"FAIL: Not enough data in features_df to run verification. Check num_days.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during verification: {e}\")\n",
    "\n",
    "# --- A. HELPER FUNCTIONS ---\n",
    "\n",
    "def calculate_gain(price_series: pd.Series):\n",
    "    \"\"\"Calculates the total gain over a series of prices.\"\"\"\n",
    "    # Ensure there are at least two data points to calculate a gain\n",
    "    if price_series.dropna().shape[0] < 2: return np.nan\n",
    "    # Use forward-fill for the end price and back-fill for the start price\n",
    "    # to handle potential NaNs at the beginning or end of the series.\n",
    "    return (price_series.ffill().iloc[-1] / price_series.bfill().iloc[0]) - 1\n",
    "\n",
    "def calculate_sharpe(return_series: pd.Series):\n",
    "    \"\"\"Calculates the annualized Sharpe ratio from a series of daily returns.\"\"\"\n",
    "    # Ensure there are at least two returns to calculate a standard deviation\n",
    "    if return_series.dropna().shape[0] < 2: return np.nan\n",
    "    std_dev = return_series.std()\n",
    "    # Avoid division by zero if returns are constant\n",
    "    if std_dev > 0 and std_dev != np.inf:\n",
    "        return (return_series.mean() / std_dev) * np.sqrt(252)\n",
    "    return np.nan\n",
    "\n",
    "def print_nested(d, indent=0, width=4):\n",
    "    \"\"\"Pretty-print any nested dict/list/tuple combination.\"\"\"\n",
    "    spacing = ' ' * indent\n",
    "    if isinstance(d, dict):\n",
    "        for k, v in d.items():\n",
    "            print(f'{spacing}{k}:')\n",
    "            print_nested(v, indent + width, width)\n",
    "    elif isinstance(d, (list, tuple)):\n",
    "        for item in d:\n",
    "            print_nested(item, indent, width)\n",
    "    else:\n",
    "        print(f'{spacing}{d}')\n",
    "\n",
    "# --- B. THE CORE CALCULATION ENGINE ---\n",
    "\n",
    "def run_walk_forward_step(df_close_full, df_high_full, df_low_full,\n",
    "                          master_trading_days,\n",
    "                          start_date, calc_period, fwd_period,\n",
    "                          metric, rank_start, rank_end, benchmark_ticker,\n",
    "                          debug=False):\n",
    "    \"\"\"Runs a single step of the walk-forward analysis using precise trading days.\"\"\"\n",
    "    debug_data = {} if debug else None\n",
    "    \n",
    "    # 1. Determine exact date ranges using the master trading day calendar\n",
    "    try:\n",
    "        start_idx = master_trading_days.get_loc(start_date)\n",
    "    except KeyError:\n",
    "        return ({'error': f\"Start date {start_date.date()} is not a valid trading day.\"}, None)\n",
    "        \n",
    "    calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "    viz_end_idx = min(calc_end_idx + fwd_period, len(master_trading_days) - 1)\n",
    "\n",
    "    safe_start_date = master_trading_days[start_idx]\n",
    "    safe_calc_end_date = master_trading_days[calc_end_idx]\n",
    "    safe_viz_end_date = master_trading_days[viz_end_idx]\n",
    "    \n",
    "    if safe_start_date >= safe_calc_end_date:\n",
    "        return ({'error': \"Invalid date range (calc period has zero or negative length).\"}, None)\n",
    "\n",
    "    # 2. Slice data for the calculation period and filter for valid tickers\n",
    "    calc_close_raw = df_close_full.loc[safe_start_date:safe_calc_end_date]\n",
    "    calc_close = calc_close_raw.dropna(axis=1, how='all') # Drop tickers with no data in the period\n",
    "    if calc_close.shape[1] == 0 or len(calc_close) < 2:\n",
    "        return ({'error': \"Not enough data in calc period.\"}, None)\n",
    "\n",
    "    # 3. Calculate ranking metrics for all valid tickers\n",
    "    first_prices = calc_close.bfill().iloc[0]\n",
    "    last_prices = calc_close.ffill().iloc[-1]\n",
    "    daily_returns = calc_close.bfill().ffill().pct_change()\n",
    "    mean_returns = daily_returns.mean()\n",
    "    std_returns = daily_returns.std()\n",
    "    \n",
    "    valid_tickers = calc_close.columns\n",
    "    calc_high = df_high_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "    calc_low = df_low_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "    \n",
    "    # Correctly calculate True Range (TR) for a multi-ticker DataFrame\n",
    "    # First, align the previous day's close to the current calculation window.\n",
    "    prev_close = df_close_full[valid_tickers].shift(1).loc[safe_start_date:safe_calc_end_date]\n",
    "    \n",
    "    # Calculate the three components of True Range. Each result is a DataFrame.\n",
    "    component1 = calc_high - calc_low\n",
    "    component2 = abs(calc_high - prev_close)\n",
    "    component3 = abs(calc_low - prev_close)\n",
    "\n",
    "    # Find the element-wise maximum across the three component DataFrames.\n",
    "    # np.maximum is efficient and preserves the DataFrame structure.\n",
    "    tr = np.maximum(component1, np.maximum(component2, component3))\n",
    "    \n",
    "    atr = tr.ewm(alpha=1/14, adjust=False).mean()\n",
    "    atrp = (atr / calc_close).mean() # Mean ATRP over the calculation period\n",
    "\n",
    "    metric_values = {}\n",
    "    metric_values['Price'] = (last_prices / first_prices).dropna()\n",
    "    metric_values['Sharpe'] = (mean_returns / std_returns * np.sqrt(252)).fillna(0)\n",
    "    metric_values['Sharpe (ATR)'] = (mean_returns / atrp).fillna(0)\n",
    "\n",
    "    if debug:\n",
    "        df_ranking = pd.DataFrame({\n",
    "            'FirstPrice': first_prices, 'LastPrice': last_prices, 'MeanDailyReturn': mean_returns,\n",
    "            'StdDevDailyReturn': std_returns, 'MeanATRP': atrp, 'Metric_Price': metric_values['Price'],\n",
    "            'Metric_Sharpe': metric_values['Sharpe'], 'Metric_Sharpe (ATR)': metric_values['Sharpe (ATR)']\n",
    "        })\n",
    "        df_ranking.index.name = 'Ticker'\n",
    "        debug_data['ranking_metrics'] = df_ranking.sort_values(f'Metric_{metric}', ascending=False)\n",
    "\n",
    "    # 4. Rank tickers and select the target group\n",
    "    sorted_tickers = metric_values[metric].sort_values(ascending=False)\n",
    "    tickers_to_display = sorted_tickers.index[rank_start-1:rank_end].tolist()\n",
    "    if not tickers_to_display:\n",
    "        return ({'error': \"No tickers found for the selected rank.\"}, None)\n",
    "\n",
    "    # 5. Prepare data for plotting and portfolio performance calculation\n",
    "    normalized_plot_data = df_close_full[tickers_to_display].loc[safe_start_date:safe_viz_end_date]\n",
    "    normalized_plot_data = normalized_plot_data.div(normalized_plot_data.bfill().iloc[0])\n",
    "    actual_calc_end_ts = calc_close.index.max()\n",
    "    portfolio_series = normalized_plot_data.mean(axis=1)\n",
    "    portfolio_return_series = portfolio_series.pct_change()\n",
    "    benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "    benchmark_return_series = benchmark_price_series.loc[safe_start_date:safe_viz_end_date].bfill().ffill().pct_change() if benchmark_price_series is not None else pd.Series(dtype='float64')\n",
    "\n",
    "    # 6. Correctly slice return series for Sharpe calculation to prevent lookahead\n",
    "    try:\n",
    "        # Use index location for a clean, non-overlapping split\n",
    "        boundary_loc = portfolio_return_series.index.get_loc(actual_calc_end_ts)\n",
    "        calc_portfolio_returns = portfolio_return_series.iloc[:boundary_loc + 1]\n",
    "        fwd_portfolio_returns = portfolio_return_series.iloc[boundary_loc + 1:]\n",
    "        \n",
    "        if benchmark_price_series is not None:\n",
    "            bm_boundary_loc = benchmark_return_series.index.get_loc(actual_calc_end_ts)\n",
    "            calc_benchmark_returns = benchmark_return_series.iloc[:bm_boundary_loc + 1]\n",
    "            fwd_benchmark_returns = benchmark_return_series.iloc[bm_boundary_loc + 1:]\n",
    "        else:\n",
    "            calc_benchmark_returns, fwd_benchmark_returns = pd.Series(dtype='float64'), pd.Series(dtype='float64')\n",
    "            \n",
    "    except (KeyError, IndexError): # Fallback for edge cases\n",
    "        calc_portfolio_returns = portfolio_return_series.loc[:actual_calc_end_ts]\n",
    "        fwd_portfolio_returns = portfolio_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "        if benchmark_price_series is not None:\n",
    "            calc_benchmark_returns = benchmark_return_series.loc[:actual_calc_end_ts]\n",
    "            fwd_benchmark_returns = benchmark_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "        else:\n",
    "            calc_benchmark_returns, fwd_benchmark_returns = pd.Series(dtype='float64'), pd.Series(dtype='float64')\n",
    "\n",
    "    # 7. Calculate performance metrics (Gain & Sharpe) for all periods\n",
    "    perf_data = {}\n",
    "    perf_data['calc_p_gain'] = calculate_gain(portfolio_series.loc[:actual_calc_end_ts])\n",
    "    perf_data['fwd_p_gain'] = calculate_gain(portfolio_series.loc[actual_calc_end_ts:])\n",
    "    perf_data['full_p_gain'] = calculate_gain(portfolio_series)\n",
    "    perf_data['calc_p_sharpe'] = calculate_sharpe(calc_portfolio_returns)\n",
    "    perf_data['fwd_p_sharpe'] = calculate_sharpe(fwd_portfolio_returns)\n",
    "    perf_data['full_p_sharpe'] = calculate_sharpe(portfolio_return_series)\n",
    "    \n",
    "    perf_data['calc_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:actual_calc_end_ts]) if benchmark_price_series is not None else np.nan\n",
    "    perf_data['fwd_b_gain'] = calculate_gain(benchmark_price_series.loc[actual_calc_end_ts:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "    perf_data['full_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "    perf_data['calc_b_sharpe'] = calculate_sharpe(calc_benchmark_returns)\n",
    "    perf_data['fwd_b_sharpe'] = calculate_sharpe(fwd_benchmark_returns)\n",
    "    perf_data['full_b_sharpe'] = calculate_sharpe(benchmark_return_series)\n",
    "\n",
    "    # 8. Assemble results DataFrame for display\n",
    "    calc_end_prices = calc_close.ffill().iloc[-1]\n",
    "    fwd_close_slice = df_close_full.loc[actual_calc_end_ts:safe_viz_end_date]\n",
    "    viz_end_prices = fwd_close_slice.ffill().iloc[-1] if not fwd_close_slice.empty and len(fwd_close_slice) >= 2 else calc_end_prices\n",
    "    calc_gains = (calc_end_prices / calc_close.bfill().iloc[0]) - 1\n",
    "    fwd_gains = (viz_end_prices / calc_end_prices) - 1\n",
    "    results_df = pd.DataFrame({'Rank': range(rank_start, rank_start + len(tickers_to_display)), 'Metric': metric, 'MetricValue': sorted_tickers.loc[tickers_to_display].values, 'CalcPrice': calc_end_prices.loc[tickers_to_display], 'CalcGain': calc_gains.loc[tickers_to_display], 'FwdGain': fwd_gains.loc[tickers_to_display]}, index=pd.Index(tickers_to_display, name='Ticker'))\n",
    "    if benchmark_price_series is not None and benchmark_ticker in calc_close.columns:\n",
    "        benchmark_df_row = pd.DataFrame({'Rank': np.nan, 'Metric': metric, 'MetricValue': metric_values[metric].get(benchmark_ticker, np.nan), 'CalcPrice': calc_end_prices[benchmark_ticker], 'CalcGain': calc_gains[benchmark_ticker], 'FwdGain': fwd_gains[benchmark_ticker]}, index=pd.Index([f\"{benchmark_ticker} (BM)\"], name='Ticker'))\n",
    "        results_df = pd.concat([results_df, benchmark_df_row])\n",
    "    \n",
    "    # 9. Assemble debug data if requested\n",
    "    if debug:\n",
    "        df_trace = normalized_plot_data.copy()\n",
    "        df_trace.columns = [f'Norm_Price_{c}' for c in df_trace.columns]\n",
    "        df_trace['Norm_Price_Portfolio'] = portfolio_series\n",
    "        if benchmark_price_series is not None and not benchmark_price_series.loc[safe_start_date:safe_viz_end_date].dropna().empty:\n",
    "            norm_bm = benchmark_price_series.loc[safe_start_date:safe_viz_end_date] / benchmark_price_series.loc[safe_start_date:].bfill().iloc[0]\n",
    "            df_trace[f'Norm_Price_Benchmark_{benchmark_ticker}'] = norm_bm\n",
    "        for col in df_trace.columns:\n",
    "            if 'Norm_Price' in col:\n",
    "                df_trace[col.replace('Norm_Price', 'Return')] = df_trace[col].pct_change()\n",
    "        debug_data['portfolio_trace'] = df_trace\n",
    "\n",
    "    # 10. Package final results\n",
    "    final_results = {\n",
    "        'tickers_to_display': tickers_to_display, 'normalized_plot_data': normalized_plot_data,\n",
    "        'portfolio_series': portfolio_series, 'benchmark_price_series': benchmark_price_series,\n",
    "        'performance_data': perf_data, 'results_df': results_df, 'actual_calc_end_ts': actual_calc_end_ts,\n",
    "        'safe_start_date': safe_start_date, 'safe_viz_end_date': safe_viz_end_date,\n",
    "        'error': None\n",
    "    }\n",
    "    return (final_results, debug_data)\n",
    "\n",
    "# --- C. DYNAMIC DATA QUALITY FILTER FUNCTIONS ---\n",
    "\n",
    "def calculate_rolling_quality_metrics(df_ohlcv, window=252, min_periods=126, debug=False):\n",
    "    \"\"\"Calculates rolling data quality metrics for the entire dataset.\"\"\"\n",
    "    print(f\"--- Calculating Rolling Quality Metrics (Window: {window} days) ---\")\n",
    "    df = df_ohlcv.copy()\n",
    "    if not df.index.is_monotonic_increasing:\n",
    "        df.sort_index(inplace=True)\n",
    "        \n",
    "    # Define quality flags\n",
    "    df['IsStale'] = np.where((df['Volume'] == 0) | (df['Adj High'] == df['Adj Low']), 1, 0)\n",
    "    df['DollarVolume'] = df['Adj Close'] * df['Volume']\n",
    "    df['HasSameVolumeAsPrevDay'] = (df.groupby(level='Ticker')['Volume'].diff() == 0).astype(int)\n",
    "    \n",
    "    # Calculate rolling metrics per ticker\n",
    "    grouped = df.groupby(level='Ticker')\n",
    "    stale_pct = grouped['IsStale'].rolling(window=window, min_periods=min_periods).mean()\n",
    "    median_vol = grouped['DollarVolume'].rolling(window=window, min_periods=min_periods).median()\n",
    "    same_vol_count = grouped['HasSameVolumeAsPrevDay'].rolling(window=window, min_periods=min_periods).sum()\n",
    "    \n",
    "    quality_df = pd.concat([stale_pct, median_vol, same_vol_count], axis=1)\n",
    "    quality_df.columns = ['RollingStalePct', 'RollingMedianVolume', 'RollingSameVolCount']\n",
    "    quality_df.index = quality_df.index.droplevel(0) # Remove the extra 'Ticker' level\n",
    "    print(\"✅ Rolling metrics calculation complete.\")\n",
    "    return quality_df\n",
    "\n",
    "def get_eligible_universe(quality_metrics_df, filter_date, thresholds):\n",
    "    \"\"\"Filters the universe of tickers based on quality metrics for a given date.\"\"\"\n",
    "    filter_date_ts = pd.to_datetime(filter_date)\n",
    "    date_index = quality_metrics_df.index.get_level_values('Date').unique().sort_values()\n",
    "    \n",
    "    if filter_date_ts < date_index[0]:\n",
    "        print(f\"Warning: Filter date {filter_date_ts.date()} is before the earliest data point. Returning empty universe.\")\n",
    "        return []\n",
    "        \n",
    "    # Find the most recent date with quality data on or before the filter date\n",
    "    valid_prior_dates = date_index[date_index <= filter_date_ts]\n",
    "    if valid_prior_dates.empty:\n",
    "        print(f\"Warning: No available data found on or before {filter_date_ts.date()}. Returning empty universe.\")\n",
    "        return []\n",
    "        \n",
    "    actual_date_to_use = valid_prior_dates[-1]\n",
    "    if actual_date_to_use.date() != filter_date_ts.date():\n",
    "        print(f\"ℹ️ Info: Filter date {filter_date_ts.date()} not found. Using previous available date {actual_date_to_use.date()}.\")\n",
    "\n",
    "    metrics_on_date = quality_metrics_df.xs(actual_date_to_use, level='Date')\n",
    "    \n",
    "    # Apply filters\n",
    "    mask = ((metrics_on_date['RollingMedianVolume'] >= thresholds['min_median_dollar_volume']) &\n",
    "            (metrics_on_date['RollingStalePct'] <= thresholds['max_stale_pct']) &\n",
    "            (metrics_on_date['RollingSameVolCount'] <= thresholds['max_same_vol_count']))\n",
    "            \n",
    "    eligible_tickers = metrics_on_date[mask].index.tolist()\n",
    "    all_tickers = metrics_on_date.index.tolist()\n",
    "    print(f\"Dynamic Filter ({filter_date_ts.date()}): Kept {len(eligible_tickers)} of {len(all_tickers)} tickers.\")\n",
    "    return eligible_tickers    \n",
    "\n",
    "# --- D. INTERACTIVE ANALYSIS & BACKTESTING TOOLS ---\n",
    "\n",
    "def plot_walk_forward_analyzer(df_ohlcv, \n",
    "                               default_start_date=None, default_calc_period=126, default_fwd_period=63,\n",
    "                               default_metric='Sharpe (ATR)', default_rank_start=1, default_rank_end=10,\n",
    "                               default_benchmark_ticker='VOO', master_calendar_ticker='VOO',\n",
    "                               quality_thresholds={'min_median_dollar_volume': 1_000_000, 'max_stale_pct': 0.05, 'max_same_vol_count': 10},\n",
    "                               debug=False):\n",
    "    \"\"\"Creates an interactive widget for single-period walk-forward analysis.\"\"\"\n",
    "    print(\"Initializing Walk-Forward Analyzer (using Trading Day Logic)...\")\n",
    "    if not isinstance(df_ohlcv.index, pd.MultiIndex): raise ValueError(\"Input DataFrame must have a (Ticker, Date) MultiIndex.\")\n",
    "    df_ohlcv = df_ohlcv.sort_index()\n",
    "\n",
    "    if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "        raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "    master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "    print(f\"Master trading day calendar created from '{master_calendar_ticker}' ({len(master_trading_days)} days).\")\n",
    "\n",
    "    # # The following functions are assumed to exist. We define placeholders for them.\n",
    "    # def calculate_rolling_quality_metrics(df, window):\n",
    "    #     tickers = df.index.get_level_values(0).unique()\n",
    "    #     dates = df.index.get_level_values(1).unique()\n",
    "    #     return pd.DataFrame(index=pd.MultiIndex.from_product([tickers, dates], names=['Ticker', 'Date']))\n",
    "    # def get_eligible_universe(quality_df, date, thresholds):\n",
    "    #     tickers = quality_df.index.get_level_values(0).unique()\n",
    "    #     return list(tickers)\n",
    "    # def run_walk_forward_step(*args, **kwargs):\n",
    "    #     # Dummy return structure for demonstration\n",
    "    #     return {'error': \"This is a placeholder function.\", 'safe_start_date': pd.Timestamp.now(), 'actual_calc_end_ts': pd.Timestamp.now(), 'safe_viz_end_date': pd.Timestamp.now()}, None\n",
    "\n",
    "    print(\"Pre-calculating data quality metrics...\")\n",
    "    quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "    print(\"Pre-processing data (unstacking)...\")\n",
    "    df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "    df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "    df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    \n",
    "    # --- Widget Setup ---\n",
    "    start_date_picker = widgets.DatePicker(description='Start Date:', value=pd.to_datetime(default_start_date), disabled=False)\n",
    "    calc_period_input = widgets.IntText(value=default_calc_period, description='Calc Period (days):')\n",
    "    fwd_period_input = widgets.IntText(value=default_fwd_period, description='Fwd Period (days):')\n",
    "    metrics = ['Price', 'Sharpe', 'Sharpe (ATR)']\n",
    "    metric_dropdown = widgets.Dropdown(options=metrics, value=default_metric, description='Metric:')\n",
    "    rank_start_input = widgets.IntText(value=default_rank_start, description='Rank Start:')\n",
    "    rank_end_input = widgets.IntText(value=default_rank_end, description='Rank End:')\n",
    "    benchmark_ticker_input = widgets.Text(value=default_benchmark_ticker, description='Benchmark:', placeholder='Enter Ticker')\n",
    "    update_button = widgets.Button(description=\"Update Chart\", button_style='primary')\n",
    "    ticker_list_output = widgets.Output()\n",
    "    results_container, debug_data_container = [None], [None]\n",
    "\n",
    "    # --- Plotting Setup ---\n",
    "    fig = go.FigureWidget()\n",
    "    max_traces = 50\n",
    "    for i in range(max_traces): fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name=f'placeholder_{i}', visible=False, showlegend=False))\n",
    "    fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Benchmark', visible=True, showlegend=True, line=dict(color='black', width=3, dash='dash')))\n",
    "    fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Group Portfolio', visible=True, showlegend=True, line=dict(color='green', width=3)))\n",
    "\n",
    "    # --- Update Logic (Callback) ---\n",
    "    def update_plot(button_click):\n",
    "        ticker_list_output.clear_output()\n",
    "        \n",
    "        # 1. Get and validate user inputs\n",
    "        start_date_raw = pd.to_datetime(start_date_picker.value)\n",
    "        start_date_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "        if start_date_idx >= len(master_trading_days):\n",
    "            with ticker_list_output: print(f\"Error: Start date is after the last available trading day.\"); return\n",
    "        actual_start_date = master_trading_days[start_date_idx]\n",
    "        with ticker_list_output: \n",
    "            if start_date_raw.date() != actual_start_date.date():\n",
    "                print(f\"ℹ️ Info: Start date {start_date_raw.date()} is not a trading day. Snapping forward to {actual_start_date.date()}.\")\n",
    "\n",
    "        # Capture input values into variables\n",
    "        calc_period = calc_period_input.value\n",
    "        fwd_period = fwd_period_input.value\n",
    "        metric = metric_dropdown.value\n",
    "        rank_start = rank_start_input.value\n",
    "        rank_end = rank_end_input.value\n",
    "        benchmark_ticker = benchmark_ticker_input.value.strip().upper()\n",
    "        \n",
    "        if rank_start > rank_end:\n",
    "            with ticker_list_output: print(\"Error: 'Rank Start' must be <= 'Rank End'.\"); return\n",
    "        if rank_start < 1 or calc_period < 2 or fwd_period < 1:\n",
    "            with ticker_list_output: print(\"Error: Ranks must be >= 1, Calc Period >= 2, Fwd Period >= 1.\"); return\n",
    "\n",
    "        # 1a. Validate data availability\n",
    "        required_days = calc_period + fwd_period\n",
    "        if start_date_idx + required_days > len(master_trading_days):\n",
    "            available_days = len(master_trading_days) - start_date_idx\n",
    "            last_available_date = master_trading_days[-1].date()\n",
    "            with ticker_list_output:\n",
    "                print(f\"Error: Not enough data for the requested period.\")\n",
    "                print(f\"  Start Date: {actual_start_date.date()}\")\n",
    "                print(f\"  Required Days: {calc_period} (calc) + {fwd_period} (fwd) = {required_days}\")\n",
    "                print(f\"  Available Days from Start: {available_days} (until {last_available_date})\")\n",
    "                print(f\"  Please shorten the 'Calc Period' / 'Fwd Period' or choose an earlier 'Start Date'.\")\n",
    "            return\n",
    "\n",
    "        # 2. Apply dynamic data quality filter\n",
    "        eligible_tickers = get_eligible_universe(quality_metrics_df, actual_start_date, quality_thresholds)\n",
    "        if not eligible_tickers:\n",
    "            with ticker_list_output: print(f\"Error: No eligible tickers found on {actual_start_date.date()} with the current quality filters.\"); return\n",
    "        df_close_step = df_close_full[eligible_tickers]; df_high_step = df_high_full[eligible_tickers]; df_low_step = df_low_full[eligible_tickers]\n",
    "\n",
    "        # 3. Run the core calculation\n",
    "        results, debug_output = run_walk_forward_step(\n",
    "            df_close_step, df_high_step, df_low_step, master_trading_days,\n",
    "            actual_start_date, calc_period, fwd_period, \n",
    "            metric, rank_start, rank_end, benchmark_ticker, debug=debug\n",
    "        )\n",
    "        if results.get('error'):\n",
    "            with ticker_list_output: print(f\"Error: {results['error']}\"); return\n",
    "            \n",
    "        # ======================= MODIFICATION START =======================\n",
    "        # 3a. Augment the output containers with period dates and run parameters for external use.\n",
    "        \n",
    "        # Add period dates (from previous request)\n",
    "        period_dates = {\n",
    "            'calc_period_start': results['safe_start_date'],\n",
    "            'calc_period_end': results['actual_calc_end_ts'],\n",
    "            'forward_period_start': results['actual_calc_end_ts'],\n",
    "            'forward_period_end': results['safe_viz_end_date']\n",
    "        }\n",
    "        \n",
    "        # Add run parameters (new request)\n",
    "        run_parameters = {\n",
    "            'calc_period': calc_period,\n",
    "            'fwd_period': fwd_period,\n",
    "            'rank_metric': metric,\n",
    "            'rank_start': rank_start,\n",
    "            'rank_end': rank_end,\n",
    "            'benchmark_ticker': benchmark_ticker\n",
    "        }\n",
    "        \n",
    "        # Update the main results dictionary\n",
    "        results.update(period_dates)\n",
    "        results.update(run_parameters)\n",
    "\n",
    "        # Update the debug dictionary if it exists\n",
    "        if debug_output is not None and isinstance(debug_output, dict):\n",
    "            debug_output.update(period_dates)\n",
    "            debug_output.update(run_parameters)\n",
    "        # ======================= MODIFICATION END =======================\n",
    "\n",
    "        # 4. Update the interactive plot\n",
    "        with fig.batch_update():\n",
    "            # (Plotting code remains unchanged)\n",
    "            for i in range(max_traces):\n",
    "                trace = fig.data[i]\n",
    "                if i < len(results['tickers_to_display']):\n",
    "                    ticker = results['tickers_to_display'][i]; plot_data_series = results['normalized_plot_data'][ticker]\n",
    "                    trace.x, trace.y, trace.name, trace.visible, trace.showlegend = plot_data_series.index, plot_data_series.values, ticker, True, True\n",
    "                else: trace.visible, trace.showlegend = False, False\n",
    "            benchmark_trace = fig.data[max_traces]\n",
    "            if results['benchmark_price_series'] is not None and not results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']].dropna().empty:\n",
    "                normalized_benchmark = results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']] / results['benchmark_price_series'].loc[results['safe_start_date']:].bfill().iloc[0]\n",
    "                benchmark_trace.x, benchmark_trace.y, benchmark_trace.name, benchmark_trace.visible = normalized_benchmark.index, normalized_benchmark, f\"Benchmark ({benchmark_ticker})\", True\n",
    "            else: benchmark_trace.visible = False\n",
    "            portfolio_trace = fig.data[max_traces + 1]\n",
    "            portfolio_trace.x, portfolio_trace.y, portfolio_trace.name, portfolio_trace.visible = results['portfolio_series'].index, results['portfolio_series'], 'Group Portfolio', True\n",
    "            fig.layout.shapes = []; fig.add_shape(type=\"line\", x0=results['actual_calc_end_ts'], y0=0, x1=results['actual_calc_end_ts'], y1=1, xref='x', yref='paper', line=dict(color=\"grey\", width=2, dash=\"dash\"))\n",
    "            \n",
    "        results_container[0] = results; debug_data_container[0] = debug_output\n",
    "        \n",
    "        # 5. Display summary statistics in a formatted table\n",
    "        with ticker_list_output:\n",
    "            # (Summary display code remains unchanged)\n",
    "            print(f\"Analysis Period: {results['safe_start_date'].date()} to {results['safe_viz_end_date'].date()}.\")\n",
    "            pprint.pprint(results['tickers_to_display'])\n",
    "            p = results['performance_data']\n",
    "            rows = []\n",
    "            rows.append({'Metric': 'Group Portfolio Gain', 'Full': p['full_p_gain'], 'Calc': p['calc_p_gain'], 'Fwd': p['fwd_p_gain']})\n",
    "            if not np.isnan(p['full_b_gain']):\n",
    "                rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Gain', 'Full': p['full_b_gain'], 'Calc': p['calc_b_gain'], 'Fwd': p['fwd_b_gain']})\n",
    "                rows.append({'Metric': 'Gain Delta (vs Bm)', 'Full': p['full_p_gain'] - p['full_b_gain'], 'Calc': p['calc_p_gain'] - p['calc_b_gain'], 'Fwd': p['fwd_p_gain'] - p['fwd_b_gain']})\n",
    "            rows.append({'Metric': 'Group Portfolio Sharpe', 'Full': p['full_p_sharpe'], 'Calc': p['calc_p_sharpe'], 'Fwd': p['fwd_p_sharpe']})\n",
    "            if not np.isnan(p['full_b_sharpe']):\n",
    "                rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Sharpe', 'Full': p['full_b_sharpe'], 'Calc': p['calc_b_sharpe'], 'Fwd': p['fwd_b_sharpe']})\n",
    "                rows.append({'Metric': 'Sharpe Delta (vs Bm)', 'Full': p['full_p_sharpe'] - p['full_b_sharpe'], 'Calc': p['calc_p_sharpe'] - p['calc_b_sharpe'], 'Fwd': p['fwd_p_sharpe'] - p['fwd_b_sharpe']})\n",
    "            report_df = pd.DataFrame(rows).set_index('Metric')\n",
    "            gain_rows = [row for row in report_df.index if 'Gain' in row or 'Delta' in row]\n",
    "            sharpe_rows = [row for row in report_df.index if 'Sharpe' in row]\n",
    "            styled_df = report_df.style.format('{:+.2%}', na_rep='N/A', subset=(gain_rows, report_df.columns)).format('{:+.2f}', na_rep='N/A', subset=(sharpe_rows, report_df.columns)).set_properties(**{'text-align': 'right', 'width': '100px'}).set_table_styles([{'selector': 'th.col_heading', 'props': [('text-align', 'right')]}, {'selector': 'th.row_heading', 'props': [('text-align', 'left')]}])\n",
    "            print(\"\\n--- Strategy Performance Summary ---\")\n",
    "            display(styled_df)\n",
    "            \n",
    "    # --- Final Layout & Display ---\n",
    "    fig.update_layout(title_text='Walk-Forward Performance Analysis', xaxis_title='Date', yaxis_title='Normalized Price (Start = 1)', hovermode='x unified', legend_title_text='Tickers (Ranked)', height=600, margin=dict(t=50))\n",
    "    fig.add_hline(y=1, line_width=1, line_dash=\"dash\", line_color=\"grey\")\n",
    "    update_button.on_click(update_plot)\n",
    "    controls_row1 = widgets.HBox([start_date_picker, calc_period_input, fwd_period_input])\n",
    "    controls_row2 = widgets.HBox([metric_dropdown, rank_start_input, rank_end_input, benchmark_ticker_input, update_button])\n",
    "    ui_container = widgets.VBox([controls_row1, controls_row2, ticker_list_output], layout=widgets.Layout(margin='10px 0 20px 0'))\n",
    "    display(ui_container, fig)\n",
    "    update_plot(None) # Initial run\n",
    "    return (results_container, debug_data_container)\n",
    "\n",
    "def run_full_backtest(df_ohlcv, strategy_params, quality_thresholds):\n",
    "    \"\"\"Runs a full backtest of a strategy over a specified date range.\"\"\"\n",
    "    print(f\"--- Running Full Forensic Backtest for Strategy: {strategy_params['metric']} (Top {strategy_params['rank_start']}-{strategy_params['rank_end']}) ---\")\n",
    "    \n",
    "    # 1. Unpack strategy parameters\n",
    "    start_date, end_date = pd.to_datetime(strategy_params['start_date']), pd.to_datetime(strategy_params['end_date'])\n",
    "    calc_period, fwd_period = strategy_params['calc_period'], strategy_params['fwd_period']\n",
    "    metric, rank_start, rank_end = strategy_params['metric'], strategy_params['rank_start'], strategy_params['rank_end']\n",
    "    benchmark_ticker = strategy_params['benchmark_ticker']\n",
    "    master_calendar_ticker = strategy_params.get('master_calendar_ticker', 'VOO')\n",
    "    \n",
    "    # 2. Perform initial setup (same as analyzer)\n",
    "    if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "        raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "    master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "    \n",
    "    start_idx = master_trading_days.searchsorted(start_date)\n",
    "    end_idx = master_trading_days.searchsorted(end_date, side='right')\n",
    "    \n",
    "    quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "    df_close_full = df_ohlcv['Adj Close'].unstack(level=0); df_high_full = df_ohlcv['Adj High'].unstack(level=0); df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    \n",
    "    # 3. Loop through all periods in the backtest range\n",
    "    step_indices = range(start_idx, end_idx, fwd_period)\n",
    "    all_fwd_gains, period_by_period_debug = [], {}\n",
    "\n",
    "    print(f\"Simulating {len(step_indices)} periods from {master_trading_days[step_indices[0]].date()} to {master_trading_days[step_indices[-1]].date()}...\")\n",
    "    for current_idx in tqdm(step_indices, desc=\"Backtest Progress\"):\n",
    "        step_date = master_trading_days[current_idx]\n",
    "        \n",
    "        # Apply data quality filter for the current step\n",
    "        eligible_tickers = get_eligible_universe(quality_metrics_df, step_date, quality_thresholds)\n",
    "        if not eligible_tickers: continue\n",
    "        \n",
    "        df_close_step = df_close_full[eligible_tickers]; df_high_step = df_high_full[eligible_tickers]; df_low_step = df_low_full[eligible_tickers]\n",
    "        \n",
    "        # Run a single walk-forward analysis step\n",
    "        results, debug_output = run_walk_forward_step(\n",
    "            df_close_step, df_high_step, df_low_step, master_trading_days,\n",
    "            step_date, calc_period, fwd_period,\n",
    "            metric, rank_start, rank_end, benchmark_ticker, debug=True\n",
    "        )\n",
    "        \n",
    "        # Collect results for this period\n",
    "        if results['error'] is None:\n",
    "            fwd_series = results['portfolio_series'].loc[results['actual_calc_end_ts']:]\n",
    "            all_fwd_gains.append(fwd_series.pct_change().dropna())\n",
    "            period_by_period_debug[step_date.date().isoformat()] = debug_output\n",
    "            \n",
    "    if not all_fwd_gains:\n",
    "        print(\"Error: No valid periods were simulated.\"); return None\n",
    "\n",
    "    # 4. Stitch together the results to form a continuous equity curve\n",
    "    strategy_returns = pd.concat(all_fwd_gains); strategy_equity_curve = (1 + strategy_returns).cumprod()\n",
    "    benchmark_returns = df_close_full[benchmark_ticker].pct_change().loc[strategy_equity_curve.index]; benchmark_equity_curve = (1 + benchmark_returns).cumprod()\n",
    "    cumulative_equity_df = pd.DataFrame({'Strategy_Equity': strategy_equity_curve, 'Benchmark_Equity': benchmark_equity_curve})\n",
    "    \n",
    "    # 5. Plot the final equity curve\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=cumulative_equity_df.index, y=cumulative_equity_df['Strategy_Equity'], name='Strategy', line=dict(color='green')))\n",
    "    fig.add_trace(go.Scatter(x=cumulative_equity_df.index, y=cumulative_equity_df['Benchmark_Equity'], name=f'Benchmark ({benchmark_ticker})', line=dict(color='black', dash='dash')))\n",
    "    fig.update_layout(title=f\"Cumulative Performance: '{metric}' Strategy (Top {rank_start}-{rank_end})\", xaxis_title=\"Date\", yaxis_title=\"Cumulative Growth\")\n",
    "    fig.show()\n",
    "\n",
    "    # 6. Return the detailed results for forensic analysis\n",
    "    final_backtest_results = {'cumulative_performance': cumulative_equity_df, 'period_by_period_debug': period_by_period_debug}\n",
    "    print(\"\\n✅ Full backtest complete. Results object is ready for forensic analysis.\")\n",
    "    return final_backtest_results\n",
    "\n",
    "# --- E. VERIFICATION TOOLS (User Requested) ---\n",
    "\n",
    "def verify_group_tickers_walk_forward_calculation(df_ohlcv, tickers_to_verify, benchmark_ticker,\n",
    "                                                  start_date, calc_period, fwd_period,\n",
    "                                                  master_calendar_ticker='VOO', export_csv=False):\n",
    "    \"\"\"Verifies portfolio and benchmark performance and optionally exports the data.\"\"\"\n",
    "    display(Markdown(f\"## Verification Report for Portfolio vs. Benchmark\"))\n",
    "    display(Markdown(f\"**Portfolio Tickers:** `{tickers_to_verify}`\\n**Benchmark Ticker:** `{benchmark_ticker}`\"))\n",
    "    \n",
    "    # 1. Setup trading day calendar and determine exact period dates\n",
    "    if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "        raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "    master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "\n",
    "    start_date_raw = pd.to_datetime(start_date)\n",
    "    start_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "    if start_idx >= len(master_trading_days):\n",
    "        print(f\"Error: Start date {start_date_raw.date()} is after the last available trading day.\"); return\n",
    "    actual_start_date = master_trading_days[start_idx]\n",
    "    \n",
    "    calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "    fwd_end_idx = min(calc_end_idx + fwd_period, len(master_trading_days) - 1)\n",
    "    \n",
    "    actual_calc_end_date = master_trading_days[calc_end_idx]\n",
    "    actual_fwd_end_date = master_trading_days[fwd_end_idx]\n",
    "    \n",
    "    display(Markdown(f\"**Analysis Start:** `{actual_start_date.date()}` (Selected: `{start_date_raw.date()}`)\\n\"\n",
    "                    f\"**Calc End:** `{actual_calc_end_date.date()}` ({calc_period} trading days)\\n\"\n",
    "                    f\"**Fwd End:** `{actual_fwd_end_date.date()}` ({fwd_period} trading days)\"))\n",
    "\n",
    "    # 2. Recreate the portfolio and benchmark series from scratch\n",
    "    df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "    portfolio_prices_raw_slice = df_close_full[tickers_to_verify].loc[actual_start_date:actual_fwd_end_date]\n",
    "    portfolio_value_series = portfolio_prices_raw_slice.div(portfolio_prices_raw_slice.bfill().iloc[0]).mean(axis=1)\n",
    "    benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "    \n",
    "    # 3. Optionally export the underlying daily data to a CSV for external checking\n",
    "    if export_csv:\n",
    "        export_df = pd.DataFrame({\n",
    "            'Portfolio_Normalized_Price': portfolio_value_series,\n",
    "            'Portfolio_Daily_Return': portfolio_value_series.pct_change()\n",
    "        })\n",
    "        if benchmark_price_series is not None:\n",
    "            norm_bm = benchmark_price_series.loc[actual_start_date:actual_fwd_end_date]\n",
    "            norm_bm = norm_bm / norm_bm.bfill().iloc[0]\n",
    "            export_df['Benchmark_Normalized_Price'] = norm_bm\n",
    "            export_df['Benchmark_Daily_Return'] = norm_bm.pct_change()\n",
    "\n",
    "        output_dir = 'export_csv'\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        tickers_str = '_'.join(tickers_to_verify)\n",
    "        filename = f\"verify_group_{actual_start_date.date()}_{tickers_str}.csv\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        export_df.to_csv(filepath)\n",
    "        print(f\"\\n✅ Data exported to: {filepath}\")\n",
    "\n",
    "    # 4. Define a helper to print detailed calculation steps\n",
    "    def print_verification_steps(title, price_series):\n",
    "        display(Markdown(f\"#### Verification for: `{title}`\"))\n",
    "        if price_series.dropna().shape[0] < 2: print(\"  - Not enough data points.\"); return {'gain': np.nan, 'sharpe': np.nan}\n",
    "        start_price, end_price = price_series.bfill().iloc[0], price_series.ffill().iloc[-1]\n",
    "        gain = (end_price / start_price) - 1\n",
    "        print(f\"Start Value ({price_series.first_valid_index().date()}): {start_price:,.4f}\\nEnd Value   ({price_series.last_valid_index().date()}): {end_price:,.4f}\\nGain = {gain:.2%}\")\n",
    "        returns = price_series.pct_change()\n",
    "        sharpe = calculate_sharpe(returns)\n",
    "        print(f\"Mean Daily Return: {returns.mean():.6f}\\nStd Dev: {returns.std():.6f}\\nSharpe = {sharpe:.2f}\")\n",
    "        return {'gain': gain, 'sharpe': sharpe}\n",
    "\n",
    "    # 5. Run verification for each period\n",
    "    display(Markdown(\"### A. Calculation Period\"))\n",
    "    perf_calc_p = print_verification_steps(\"Group Portfolio\", portfolio_value_series.loc[actual_start_date:actual_calc_end_date])\n",
    "    if benchmark_price_series is not None:\n",
    "        perf_calc_b = print_verification_steps(f\"Benchmark\", benchmark_price_series.loc[actual_start_date:actual_calc_end_date])\n",
    "    \n",
    "    display(Markdown(\"### B. Forward Period\"))\n",
    "    perf_fwd_p = print_verification_steps(\"Group Portfolio\", portfolio_value_series.loc[actual_calc_end_date:actual_fwd_end_date])\n",
    "    if benchmark_price_series is not None:\n",
    "        perf_fwd_b = print_verification_steps(f\"Benchmark\", benchmark_price_series.loc[actual_calc_end_date:actual_fwd_end_date])\n",
    "\n",
    "def verify_ticker_ranking_metrics(df_ohlcv, ticker, start_date, calc_period,\n",
    "                                  master_calendar_ticker='VOO', export_csv=False):\n",
    "    \"\"\"Verifies ranking metrics for a single ticker and optionally exports the data.\"\"\"\n",
    "    display(Markdown(f\"## Verification Report for Ticker Ranking: `{ticker}`\"))\n",
    "    \n",
    "    # 1. Setup trading day calendar and determine exact period dates\n",
    "    if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "        raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "    master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "\n",
    "    start_date_raw = pd.to_datetime(start_date)\n",
    "    start_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "    if start_idx >= len(master_trading_days):\n",
    "        print(f\"Error: Start date {start_date_raw.date()} is after the last available trading day.\"); return\n",
    "    actual_start_date = master_trading_days[start_idx]\n",
    "    \n",
    "    calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "    actual_calc_end_date = master_trading_days[calc_end_idx]\n",
    "\n",
    "    # 2. Extract and prepare the raw data for the specific ticker and period\n",
    "    df_ticker = df_ohlcv.loc[ticker].sort_index()\n",
    "    calc_df = df_ticker.loc[actual_start_date:actual_calc_end_date].copy()\n",
    "    if calc_df.empty or len(calc_df) < 2: \n",
    "        print(\"No data or not enough data in calc period.\"); return\n",
    "\n",
    "    display(Markdown(\"### A. Calculation Period (for Ranking Metrics)\"))\n",
    "    display(Markdown(f\"**Period Start:** `{actual_start_date.date()}`\\n\"\n",
    "                    f\"**Period End:** `{actual_calc_end_date.date()}`\\n\"\n",
    "                    f\"**Total Trading Days:** `{len(calc_df)}` (Requested: `{calc_period}`)\"))\n",
    "    \n",
    "    display(Markdown(\"#### Detailed Metric Calculation Data\"))\n",
    "    \n",
    "    # 3. Calculate all intermediate metrics as new columns for full transparency\n",
    "    vdf = calc_df[['Adj High', 'Adj Low', 'Adj Close']].copy()\n",
    "    vdf['Daily_Return'] = vdf['Adj Close'].pct_change()\n",
    "    \n",
    "    # Corrected True Range (TR) calculation for a single ticker (Series)\n",
    "    tr_df = pd.DataFrame({\n",
    "        'h_l': vdf['Adj High'] - vdf['Adj Low'],\n",
    "        'h_cp': abs(vdf['Adj High'] - vdf['Adj Close'].shift(1)),\n",
    "        'l_cp': abs(vdf['Adj Low'] - vdf['Adj Close'].shift(1))\n",
    "    })\n",
    "    vdf['TR'] = tr_df.max(axis=1)\n",
    "    \n",
    "    vdf['ATR_14'] = vdf['TR'].ewm(alpha=1/14, adjust=False).mean()\n",
    "    vdf['ATRP'] = vdf['ATR_14'] / vdf['Adj Close']\n",
    "    \n",
    "    print(\"--- Start of Calculation Period ---\")\n",
    "    display(vdf.head())\n",
    "    print(\"\\n--- End of Calculation Period ---\")\n",
    "    display(vdf.tail())\n",
    "\n",
    "    # 4. Optionally export this detailed breakdown to CSV\n",
    "    if export_csv:\n",
    "        output_dir = 'export_csv'\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        filename = f\"verify_ticker_{actual_start_date.date()}_{ticker}.csv\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        vdf.to_csv(filepath)\n",
    "        print(f\"\\n✅ Data exported to: {filepath}\")\n",
    "    \n",
    "    # 5. Print final metric calculations with formulas\n",
    "    display(Markdown(\"#### `MetricValue` Verification Summary:\"))\n",
    "    \n",
    "    calc_start_price = vdf['Adj Close'].bfill().iloc[0]\n",
    "    calc_end_price = vdf['Adj Close'].ffill().iloc[-1]\n",
    "    price_metric = (calc_end_price / calc_start_price)\n",
    "    print(f\"1. Price Metric: (Last Price / First Price) = ({calc_end_price:.2f} / {calc_start_price:.2f}) = {price_metric:.4f}\")\n",
    "    \n",
    "    daily_returns = vdf['Daily_Return'].dropna()\n",
    "    sharpe_ratio = calculate_sharpe(daily_returns)\n",
    "    print(f\"2. Sharpe Metric: (Mean Daily Return / Std Dev) * sqrt(252) = {sharpe_ratio:.4f}\")\n",
    "\n",
    "    atrp_mean = vdf['ATRP'].mean()\n",
    "    mean_daily_return = vdf['Daily_Return'].mean()\n",
    "    sharpe_atr = (mean_daily_return / atrp_mean) if atrp_mean > 0 else 0\n",
    "    print(f\"3. Sharpe (ATR) Metric: (Mean Daily Return / Mean ATRP) = ({mean_daily_return:.6f} / {atrp_mean:.6f}) = {sharpe_atr:.4f}\")\n",
    "\n",
    "# --- F. AUTOMATION SCRIPT - STRATEGY SEARCH ---\n",
    "\n",
    "def run_strategy_search(df_ohlcv, config):\n",
    "    \"\"\"\n",
    "    Runs the main backtesting loop with checkpointing to be resumable.\n",
    "    \"\"\"\n",
    "    start_time = time.time() # <-- This now works because of 'import time'\n",
    "    \n",
    "    # --- 1. SETUP & LOAD PROGRESS ---\n",
    "    print(\"--- Phase 1: Pre-processing and Loading Progress ---\")\n",
    "    quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "    print(\"Unstacking data for performance...\")\n",
    "    df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "    df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "    df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    \n",
    "    master_calendar_ticker = config['master_calendar_ticker']\n",
    "    master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "    print(f\"Master trading day calendar created from '{master_calendar_ticker}' ({len(master_trading_days)} days).\")\n",
    "\n",
    "    results_path = config['results_output_path']\n",
    "    completed_params = set()\n",
    "    \n",
    "    if os.path.exists(results_path): # <-- This now works because of 'import os'\n",
    "        print(f\"Found existing results file. Loading progress from: {results_path}\")\n",
    "        df_progress = pd.read_csv(results_path)\n",
    "        for _, row in df_progress.iterrows():\n",
    "            param_key = (\n",
    "                row['calc_period'], row['fwd_period'], row['metric'],\n",
    "                (row['rank_start'], row['rank_end'])\n",
    "            )\n",
    "            completed_params.add(param_key)\n",
    "        print(f\"Found {len(completed_params)} completed parameter sets to skip.\")\n",
    "    else:\n",
    "        print(\"No existing results file found. Starting a new run.\")\n",
    "\n",
    "    print(\"✅ Pre-processing complete.\\n\")\n",
    "\n",
    "    # --- 2. SETUP THE MAIN LOOP ---\n",
    "    print(\"--- Phase 2: Setting up Simulation Loops ---\")\n",
    "    \n",
    "    param_combinations = list(product(\n",
    "        config['calc_periods'], config['fwd_periods'],\n",
    "        config['metrics'], config['rank_slices']\n",
    "    ))\n",
    "    \n",
    "    search_start_date = pd.to_datetime(config['search_start_date'])\n",
    "    search_end_date = pd.to_datetime(config['search_end_date'])\n",
    "    start_idx = master_trading_days.searchsorted(search_start_date, side='left')\n",
    "    end_idx = master_trading_days.searchsorted(search_end_date, side='right')\n",
    "\n",
    "    step_dates_map = {}\n",
    "    print(\"Pre-calculating rebalancing schedules for each holding period...\")\n",
    "    for fwd_period in sorted(config['fwd_periods']):\n",
    "        step_indices = range(start_idx, end_idx, fwd_period)\n",
    "        step_dates_map[fwd_period] = master_trading_days[step_indices]\n",
    "        print(f\"  - Holding Period {fwd_period} days: {len(step_dates_map[fwd_period])} rebalances\")\n",
    "    \n",
    "    print(f\"Found {len(param_combinations)} total parameter sets to simulate.\")\n",
    "    print(\"✅ Setup complete. Starting main loop...\\n\")\n",
    "\n",
    "    # --- 3. RUN THE MAIN LOOP ---\n",
    "    print(\"--- Phase 3: Running Simulations ---\")\n",
    "    pbar = tqdm(param_combinations, desc=\"Parameter Sets\")\n",
    "    \n",
    "    for params in pbar:\n",
    "        calc_period, fwd_period, metric, rank_slice = params\n",
    "        rank_start, rank_end = rank_slice\n",
    "        \n",
    "        param_key = (calc_period, fwd_period, metric, rank_slice)\n",
    "        if param_key in completed_params:\n",
    "            pbar.set_description(f\"Skipping {param_key}\")\n",
    "            continue\n",
    "\n",
    "        pbar.set_description(f\"Running {param_key}\")\n",
    "        \n",
    "        current_params_results = []\n",
    "        \n",
    "        # ==============================================================================\n",
    "        # --- FIX: RESTORED THE MISSING INNER LOOP ---\n",
    "        # ==============================================================================\n",
    "        current_step_dates = step_dates_map[fwd_period]\n",
    "        for step_date in current_step_dates:\n",
    "            eligible_tickers = get_eligible_universe(\n",
    "                quality_metrics_df, filter_date=step_date, thresholds=config['quality_thresholds']\n",
    "            )\n",
    "            if not eligible_tickers: continue\n",
    "            \n",
    "            df_close_step = df_close_full[eligible_tickers]\n",
    "            df_high_step = df_high_full[eligible_tickers]\n",
    "            df_low_step = df_low_full[eligible_tickers]\n",
    "\n",
    "            step_result, _ = run_walk_forward_step(\n",
    "                df_close_full=df_close_step, df_high_full=df_high_step, df_low_full=df_low_step,\n",
    "                master_trading_days=master_trading_days, start_date=step_date,\n",
    "                calc_period=calc_period, fwd_period=fwd_period,\n",
    "                metric=metric, rank_start=rank_start, rank_end=rank_end,\n",
    "                benchmark_ticker=config['benchmark_ticker'], debug=False\n",
    "            )\n",
    "            \n",
    "            if step_result['error'] is None:\n",
    "                p = step_result['performance_data']\n",
    "                log_entry = {\n",
    "                    'step_date': step_date.date(), 'calc_period': calc_period,\n",
    "                    'fwd_period': fwd_period, 'metric': metric,\n",
    "                    'rank_start': rank_start, 'rank_end': rank_end,\n",
    "                    'num_universe': len(eligible_tickers),\n",
    "                    'num_portfolio': len(step_result['tickers_to_display']),\n",
    "                    'fwd_p_gain': p['fwd_p_gain'], 'fwd_b_gain': p['fwd_b_gain'],\n",
    "                    'fwd_gain_delta': p['fwd_p_gain'] - p['fwd_b_gain'] if not np.isnan(p['fwd_b_gain']) else np.nan,\n",
    "                    'fwd_p_sharpe': p['fwd_p_sharpe'],\n",
    "                }\n",
    "                current_params_results.append(log_entry)\n",
    "        # ==============================================================================\n",
    "        \n",
    "        # --- CHECKPOINTING: INCREMENTAL SAVE ---\n",
    "        if current_params_results:\n",
    "            df_to_append = pd.DataFrame(current_params_results)\n",
    "            df_to_append.to_csv(\n",
    "                results_path,\n",
    "                mode='a',\n",
    "                header=not os.path.exists(results_path),\n",
    "                index=False\n",
    "            )\n",
    "            completed_params.add(param_key)\n",
    "\n",
    "    print(\"✅ Main loop finished.\\n\")\n",
    "    \n",
    "    # --- 4. RETURN FINAL DATAFRAME ---\n",
    "    print(\"--- Phase 4: Loading Final Results ---\")\n",
    "    if os.path.exists(results_path):\n",
    "        final_df = pd.read_csv(results_path)\n",
    "        end_time = time.time()\n",
    "        print(f\"✅ Process complete. Total execution time: {time.time() - start_time:.2f} seconds.\")\n",
    "        return final_df\n",
    "    else:\n",
    "        print(\"Warning: No results were generated.\")\n",
    "        return None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47ed713",
   "metadata": {},
   "source": [
    "#### **CELL 3: DATA LOADING**\n",
    "*This cell loads your main dataset using the environment-aware path.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97e54a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# --- CELL 3: DATA LOADING ---\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "\n",
    "data_file_path = env_config['data_path']\n",
    "print(f\"Attempting to load data from: {data_file_path}\")\n",
    "\n",
    "try:\n",
    "    df_OHLCV = pd.read_parquet(data_file_path, engine='pyarrow')\n",
    "    df_dev = df_OHLCV.copy() # Use df_dev for development as a good practice\n",
    "    \n",
    "    print(\"\\n✅ Data loaded successfully.\")\n",
    "    print(\"\\n--- DataFrame Info ---\")\n",
    "    df_dev.info()\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\n❌ ERROR: FILE NOT FOUND at {data_file_path}. Please check paths in Cell 1.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b16e2e",
   "metadata": {},
   "source": [
    "#### **CELL 4: BOT STRATEGY CONFIGURATION**\n",
    "*This cell defines the strategy parameters you want to test.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549adf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# --- CELL 4: BOT STRATEGY CONFIGURATION ---\n",
    "# ==============================================================================\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "\n",
    "# --- PRIMARY USER INPUTS FOR THE STRATEGY ---\n",
    "# 5,  21, 42, 63, 126, 252\n",
    "# 1W, 1M, 2M, 3M,  6M,  1Y\n",
    "HOLDING_PERIODS_DAYS = [63]        # Test ~2, and 3 month holding periods\n",
    "CALC_PERIODS_DAYS = [252]         # Use ~6 and 12 month lookbacks\n",
    "\n",
    "bot_config = {\n",
    "    # --- Time Parameters ---\n",
    "    'search_start_date': '2014-01-01',\n",
    "    'search_end_date': '2018-12-31',\n",
    "    \n",
    "    # --- Strategy Parameters (The Search Grid) ---\n",
    "    'calc_periods': CALC_PERIODS_DAYS,\n",
    "    'fwd_periods': HOLDING_PERIODS_DAYS,\n",
    "\n",
    "\n",
    "    # 'metrics': ['Sharpe', 'Sharpe (ATR)'],\n",
    "    'metrics': ['Price', 'Sharpe', 'Sharpe (ATR)'],    \n",
    "        \n",
    "    'rank_slices': [(1, 5)],\n",
    "\n",
    "    # --- Data Quality ---\n",
    "    'quality_thresholds': { 'min_median_dollar_volume': 10_000_000, \n",
    "                            'max_stale_pct': 0.05, \n",
    "                            'max_same_vol_count': 1 },\n",
    "\n",
    "    # --- General Parameters ---\n",
    "    'benchmark_ticker': 'VOO',\n",
    "    'master_calendar_ticker': 'VOO',\n",
    "    'results_output_path': env_config['results_path']\n",
    "}\n",
    "\n",
    "print(\"\\n--- Bot Configuration Initialized ---\")\n",
    "print(f\"Calculation Periods to Test: {bot_config['calc_periods']} trading days\")\n",
    "print(f\"Forward and Holding Periods to Test (Forward and Holding Periods are the same): {bot_config['fwd_periods']} trading days\")\n",
    "print(f\"Results will be saved to: {bot_config['results_output_path']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df014e8e",
   "metadata": {},
   "source": [
    "#### **CELL 5: EXECUTION**\n",
    "*This is the final cell that runs the backtest and displays the results.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7485bf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# --- CELL 5: EXECUTION ---\n",
    "# ==============================================================================\n",
    "\n",
    "# --- Execute the Bot ---\n",
    "dev_results_df = run_strategy_search(df_dev, bot_config)\n",
    "\n",
    "# --- Display a sample of the results ---\n",
    "if dev_results_df is not None:\n",
    "    print(\"\\n--- Sample of Generated Results ---\")\n",
    "    display(dev_results_df.head())\n",
    "    print(\"\\n--- Analysis of Best Performing Strategies ---\")\n",
    "    display(dev_results_df.groupby(['calc_period', 'fwd_period', 'metric', 'rank_start', 'rank_end'])['fwd_gain_delta'].mean().sort_values(ascending=False).to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dc0a12",
   "metadata": {},
   "source": [
    "### 4. Next Steps & Future Improvements\n",
    "\n",
    "This system is a powerful foundation. Here are potential areas for future development:\n",
    "1.  **Advanced Performance Analytics:** Create a new notebook or function to analyze the output CSV, calculating metrics like Max Drawdown, Calmar Ratio, and generating equity curves for the best strategies.\n",
    "2.  **Visualization:** Build heatmaps and other plots to visualize how different parameters (e.g., `calc_period` vs. `fwd_period`) affect performance.\n",
    "3.  **Realism:** Incorporate transaction costs and slippage into the performance calculations for a more realistic backtest.\n",
    "4.  **Configuration Management:** For even more complex tests, move the `bot_config` dictionary into a separate `config.py` file to keep the notebook cleaner.\n",
    "\n",
    "It has been a genuine pleasure working with you on this. You've built an impressive and professional-grade tool. I wish you the very best with your continued research and development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05feecc8",
   "metadata": {},
   "source": [
    "### 4. Plot an export_csv Row to Check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5979f82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_to_check = 59\n",
    "row_values =  dev_results_df.loc[row_to_check ].to_dict()\n",
    "print(f'export_csv values for row {row_to_check}:\\n')\n",
    "for k, v in row_values.items():\n",
    "    print(f'{k:<15}: {v}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e2012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_container, debug_container = plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_dev,\n",
    "    # df_ohlcv=df_OHLCV,    \n",
    "    default_start_date=row_values['step_date'],\n",
    "    \n",
    "    default_calc_period=row_values['calc_period'],\n",
    "    default_fwd_period=row_values['fwd_period'],\n",
    "    # default_calc_period=120,\n",
    "    # default_fwd_period=30,\n",
    "\n",
    "    default_metric=row_values['metric'],\n",
    "\n",
    "    default_rank_start=row_values['rank_start'],\n",
    "    default_rank_end=row_values['rank_end'],\n",
    "    # default_rank_start=2,\n",
    "    # default_rank_end=3,    \n",
    "\n",
    "    default_benchmark_ticker='VOO',\n",
    "    quality_thresholds=bot_config['quality_thresholds'],\n",
    "    debug=True  # <-- Activate the new mode!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44da0593",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_nested(results_container)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa15885",
   "metadata": {},
   "source": [
    "# CHECK Metric_Sharpe (ATR) for Calc. Period has error.\n",
    "- start date 2018-10-03\n",
    "- Calc Period 252\n",
    "- Fwd Period 63\n",
    "- Metric Sharpe ATR\n",
    "- Rank Start 1\n",
    "- Rank End 5\n",
    "-- Analysis Period 2018-10-03 to 2020-01-06 (this is full period, calc + fwd)\n",
    "-- [BIL, MINT, SHV, BNDX, VCSH]\n",
    "-- Metric_Sharpe (ATR) for BIL, MINT, SHV, BNDX matched my own calculation at bottom cell\n",
    "-- Metric Sharpe (ATR) for VCSH is a bit off (code calc 0.194195, my calc 0.196112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed494d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_nested(debug_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91056576",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = results_container[0]\n",
    "\n",
    "print_nested(results_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6fa808",
   "metadata": {},
   "source": [
    "### Get Plot Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2201125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_tickers = results_dict['tickers_to_display']\n",
    "_calc_start = results_dict['calc_period_start']\n",
    "_calc_end = results_dict['calc_period_end']\n",
    "_fwd_start = results_dict['forward_period_start']\n",
    "_fwd_end = results_dict['forward_period_end']\n",
    "_calc_period = results_dict['calc_period']\n",
    "_fwd_period = results_dict['fwd_period']\n",
    "_benchmark_ticker = results_dict['benchmark_ticker']\n",
    "\n",
    "print(f'_tickers: {_tickers}')\n",
    "print(f'_calc_start: {_calc_start}')\n",
    "print(f'_calc_end: {_calc_end}')\n",
    "print(f'_fwd_start: {_fwd_start}')\n",
    "print(f'_fwd_end: {_fwd_end}')\n",
    "print(f'_calc_period: {_calc_period}')\n",
    "print(f'_fwd_period: {_fwd_period}')\n",
    "print(f'_benchmark: {_benchmark_ticker}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe967a4",
   "metadata": {},
   "source": [
    "### Run verify_ticker_ranking_metrics with Plot Parameters to Check Calc. Period Calculation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf24d825",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ticker in _tickers:\n",
    "    verify_ticker_ranking_metrics(df_OHLCV, \n",
    "                                  ticker=_ticker, \n",
    "                                  start_date=_calc_start, \n",
    "                                  calc_period=_calc_period,\n",
    "                                  master_calendar_ticker=_benchmark_ticker, \n",
    "                                  export_csv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e6ca72",
   "metadata": {},
   "source": [
    "### My Own Check on Calculation for One Ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9798de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Check Calculation for a Ticker -- #\n",
    "_check_ticker = _tickers[4]\n",
    "print(f'Check calculation for this ticker: {_check_ticker}')\n",
    "\n",
    "# Get Ticker's OHLCV Data -- # \n",
    "_df = df_OHLCV.loc[_check_ticker][_calc_start:_fwd_end]\n",
    "\n",
    "# -- Calculate Daily Return -- #\n",
    "_df['Daily_Return'] = _df['Adj Close'].pct_change()\n",
    "\n",
    "# -- Calculate True Range -- #\n",
    "_df['TR'] = pd.concat([\n",
    "    _df['Adj High'] - _df['Adj Low'],\n",
    "    (_df['Adj High'] - _df['Adj Close'].shift(1)).abs(),\n",
    "    (_df['Adj Low']  - _df['Adj Close'].shift(1)).abs()\n",
    "], axis=1).max(axis=1)\n",
    "\n",
    "# -- Calculate Average True Range (14 day period) -- #\n",
    "window = 14\n",
    "_df['ATR_14'] = pd.NA\n",
    "\n",
    "# Seed the very first ATR value with the first non-NaN TR\n",
    "first_idx = _df['TR'].first_valid_index()\n",
    "_df.loc[first_idx, 'ATR_14'] = _df.loc[first_idx, 'TR']\n",
    "\n",
    "# Iteratively apply the Wilder smoothing formula\n",
    "for i in range(_df.index.get_loc(first_idx) + 1, len(_df)):\n",
    "    prev_atr = _df.iloc[i-1]['ATR_14']\n",
    "    curr_tr  = _df.iloc[i]['TR']\n",
    "    _df.iloc[i, _df.columns.get_loc('ATR_14')] = (prev_atr * (window - 1) + curr_tr) / window\n",
    "\n",
    "# -- Calculate ATRP -- #\n",
    "_df['ATRP'] = _df['ATR_14'] / _df['Adj Close']\n",
    "\n",
    "calc_pd_df = _df.loc[_calc_start:_calc_end]\n",
    "fwd_pd_df = _df.loc[_fwd_start:_fwd_end]\n",
    "print(f'Calc. Period:\\n{calc_pd_df.head()}\\n{calc_pd_df.tail()}')\n",
    "print(f'\\nFwd. Period:\\n{fwd_pd_df.head()}\\n{fwd_pd_df.tail()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17089b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Metric Calculation for Ticker: {_check_ticker}')\n",
    "\n",
    "# -- Calculation for Period Gain -- #\n",
    "full_period_gain = _df['Adj Close'][_fwd_end] / _df['Adj Close'][_calc_start]\n",
    "calc_period_gain = _df['Adj Close'][_calc_end] / _df['Adj Close'][_calc_start]\n",
    "fwd_period_gain = _df['Adj Close'][_fwd_end] / _df['Adj Close'][_fwd_start]\n",
    "\n",
    "print(f'\\nfull_period_gain: {full_period_gain:.4f}')\n",
    "print(f'calc_period_gain: {calc_period_gain:.4f}')\n",
    "print(f'fwd_period_gain: {fwd_period_gain:.4f}')\n",
    "\n",
    "# -- Calculation for Period Sharpe -- #\n",
    "full_period_return = _df['Daily_Return'][_calc_start:_fwd_end]\n",
    "calc_period_return = _df['Daily_Return'][_calc_start:_calc_end]\n",
    "fwd_period_return = _df['Daily_Return'][_fwd_start:_fwd_end]\n",
    "\n",
    "full_sharpe = full_period_return.mean() / full_period_return.std() * (252 ** 0.5)\n",
    "calc_sharpe = calc_period_return.mean() / calc_period_return.std() * (252 ** 0.5)\n",
    "fwd_sharpe = fwd_period_return.mean() / fwd_period_return.std() * (252 ** 0.5)\n",
    "\n",
    "print(f'\\nfull_sharpe: {full_sharpe:.4f}')\n",
    "print(f'calc_sharpe: {calc_sharpe:.4f}')\n",
    "print(f'fwd_sharpe: {fwd_sharpe:.4f}')\n",
    "\n",
    "# -- Calculation for Period Sharpe ATR -- #\n",
    "full_sharpe_ATR = full_period_return.mean() / _df['ATRP'][_calc_start:_fwd_end].mean()\n",
    "calc_sharpe_ATR = calc_period_return.mean() / _df['ATRP'][_calc_start:_calc_end].mean()\n",
    "fwd_sharpe_ATR = fwd_period_return.mean() / _df['ATRP'][_fwd_start:_fwd_end].mean()\n",
    "\n",
    "print(f'\\nfull_sharpe_ATR: {full_sharpe_ATR:.4f}')\n",
    "print(f'calc_sharpe_ATR: {calc_sharpe_ATR:.4f}')\n",
    "print(f'fwd_sharpe_ATR: {fwd_sharpe_ATR:.4f}')\n",
    "\n",
    "print(f'\\ncalc_period_return.mean(): {calc_period_return.mean()}')\n",
    "print(f\"_df['ATRP'][_calc_start:_calc_end].mean(): {_df['ATRP'][_calc_start:_calc_end].mean()}\")\n",
    "print(f'calc_sharpe_ATR: {calc_sharpe_ATR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa20ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afb0cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_OHLCV.loc['VCSH'].copy()\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9751f576",
   "metadata": {},
   "outputs": [],
   "source": [
    "_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc927f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Check Calculation for a Ticker -- #\n",
    "_check_ticker = _tickers[4]\n",
    "print(f'Check calculation for this ticker: {_check_ticker}')\n",
    "\n",
    "# Get Ticker's OHLCV Data -- # \n",
    "_df = df_OHLCV.loc[_check_ticker]['2018-09-30' : '2020-01-10']\n",
    "# _df = df_OHLCV.loc[_check_ticker].copy()\n",
    "\n",
    "# -- Calculate Daily Return -- #\n",
    "_df['Daily_Return'] = _df['Adj Close'].pct_change()\n",
    "\n",
    "# -- Calculate True Range -- #\n",
    "_df['TR'] = pd.concat([\n",
    "    _df['Adj High'] - _df['Adj Low'],\n",
    "    (_df['Adj High'] - _df['Adj Close'].shift(1)).abs(),\n",
    "    (_df['Adj Low']  - _df['Adj Close'].shift(1)).abs()\n",
    "], axis=1).max(axis=1)\n",
    "\n",
    "# -- Calculate Average True Range (14 day period) -- #\n",
    "window = 14\n",
    "_df['ATR_14'] = pd.NA\n",
    "\n",
    "# Seed the very first ATR value with the first non-NaN TR\n",
    "first_idx = _df['TR'].first_valid_index()\n",
    "_df.loc[first_idx, 'ATR_14'] = _df.loc[first_idx, 'TR']\n",
    "\n",
    "# Iteratively apply the Wilder smoothing formula\n",
    "for i in range(_df.index.get_loc(first_idx) + 1, len(_df)):\n",
    "    prev_atr = _df.iloc[i-1]['ATR_14']\n",
    "    curr_tr  = _df.iloc[i]['TR']\n",
    "    _df.iloc[i, _df.columns.get_loc('ATR_14')] = (prev_atr * (window - 1) + curr_tr) / window\n",
    "\n",
    "# -- Calculate ATRP -- #\n",
    "_df['ATRP'] = _df['ATR_14'] / _df['Adj Close']\n",
    "\n",
    "# calc_pd_df = _df.loc[_calc_start:_calc_end]\n",
    "# fwd_pd_df = _df.loc[_fwd_start:_fwd_end]\n",
    "# print(f'Calc. Period:\\n{calc_pd_df.head()}\\n{calc_pd_df.tail()}')\n",
    "# print(f'\\nFwd. Period:\\n{fwd_pd_df.head()}\\n{fwd_pd_df.tail()}')\n",
    "\n",
    "_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef92146",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OHLCV.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d72826",
   "metadata": {},
   "source": [
    "### Below Cells Follows the Code to Calculate Sharpe (ATR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7392c626",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohlcv = df_OHLCV.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689f93e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_to_check = 'VCSH' # <--- CHANGE THIS TO YOUR ACTUAL TICKER\n",
    "start_date_raw = pd.to_datetime('2018-10-03')\n",
    "calc_period_days = 252\n",
    "\n",
    "# We need the master trading day calendar, just like the code uses.\n",
    "# It's essential for getting the dates exactly right.\n",
    "master_calendar_ticker = 'VOO' # Or another reliable ticker like 'SPY'\n",
    "master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "\n",
    "# Isolate the full history for the ticker we're checking\n",
    "df_ticker_full = df_ohlcv.loc[ticker_to_check]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa61dd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ticker_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b0aed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index for our start date\n",
    "start_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "actual_start_date = master_trading_days[start_idx]\n",
    "\n",
    "# Find the index for the end of the calculation period\n",
    "calc_end_idx = min(start_idx + calc_period_days, len(master_trading_days) - 1)\n",
    "actual_calc_end_date = master_trading_days[calc_end_idx]\n",
    "\n",
    "print(f\"Raw Start Date: {start_date_raw.date()}\")\n",
    "print(f\"Actual Start Date (Trading Day): {actual_start_date.date()}\")\n",
    "print(f\"Actual Calc End Date (Trading Day): {actual_calc_end_date.date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb15d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the ticker's data to the exact date range\n",
    "calc_df = df_ticker_full.loc[actual_start_date:actual_calc_end_date].copy()\n",
    "\n",
    "print(f\"Number of rows in calc_df: {len(calc_df)}\")\n",
    "print(\"--- First 3 rows of our calculation data ---\")\n",
    "display(calc_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f1eb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_df['Daily_Return'] = calc_df['Adj Close'].pct_change()\n",
    "mean_daily_return = calc_df['Daily_Return'].mean()\n",
    "\n",
    "print(f\"Mean Daily Return: {mean_daily_return:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede641d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4a. Get the previous day's close for every day in our calc period.\n",
    "# This is done by shifting the FULL history, then slicing.\n",
    "prev_close_series = df_ticker_full['Adj Close'].shift(1).loc[calc_df.index]\n",
    "\n",
    "# 4b. MY HYPOTHESIS: The first value of this series is NaN. Let's check.\n",
    "print(\"--- Previous Day's Close (first 3 days) ---\")\n",
    "print(prev_close_series.head(3))\n",
    "print(\"\\n\")\n",
    "\n",
    "# 4c. Now calculate the three components of TR\n",
    "component1 = calc_df['Adj High'] - calc_df['Adj Low']\n",
    "component2 = abs(calc_df['Adj High'] - prev_close_series)\n",
    "component3 = abs(calc_df['Adj Low'] - prev_close_series)\n",
    "\n",
    "# 4d. Combine them to get the daily TR value\n",
    "tr_df = pd.DataFrame({'c1': component1, 'c2': component2, 'c3': component3})\n",
    "calc_df['TR'] = tr_df.max(axis=1)\n",
    "\n",
    "# # Change TR to High - Low for the row 0\n",
    "# calc_df.loc[calc_df.index[0], 'TR'] = (\n",
    "#     calc_df.loc[calc_df.index[0], 'Adj High'] -\n",
    "#     calc_df.loc[calc_df.index[0], 'Adj Low']\n",
    "# )\n",
    "\n",
    "print(\"--- Final TR values (first 3 days) ---\")\n",
    "print(calc_df[['Adj Close', 'TR']].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4c7716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the ATR using the exact same parameters as the code\n",
    "calc_df['ATR_14'] = calc_df['TR'].ewm(alpha=1/14, adjust=False).mean()\n",
    "\n",
    "print(\"--- TR vs ATR_14 (first 5 days) ---\")\n",
    "display(calc_df[['TR', 'ATR_14']].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab393be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATRP is the ATR divided by the close price\n",
    "calc_df['ATRP'] = calc_df['ATR_14'] / calc_df['Adj Close']\n",
    "\n",
    "# The final denominator is the mean of the daily ATRP values over the period\n",
    "atrp_mean = calc_df['ATRP'].mean()\n",
    "\n",
    "print(f\"Mean ATRP (Denominator): {atrp_mean:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1990be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_sharpe_atr_manual = mean_daily_return / atrp_mean\n",
    "\n",
    "print(\"--- FINAL VERIFICATION ---\")\n",
    "print(f\"Numerator (MeanDailyReturn): {mean_daily_return:.8f}\")\n",
    "print(f\"Denominator (ATRP_Mean):     {atrp_mean:.8f}\")\n",
    "print(f\"Calculated Sharpe (ATR):     {metric_sharpe_atr_manual:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
