{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and Configuration\n",
    "\n",
    "This cell contains all imports and user-configurable parameters for the analysis pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "--- Path Configuration ---\n",
      "✅ Project Root: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\n",
      "✅ Data Dir:     c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\n",
      "✅ Source Dir:   c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\src\n",
      "\n",
      "--- Module Verification ---\n",
      "✅ Successfully imported 'utils' and 'plotting_utils'.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt # Import for plotting\n",
    "from IPython.display import display, Markdown\n",
    "from scipy.stats import linregress \n",
    "\n",
    "# --- 1. PANDAS & IPYTHON OPTIONS ---\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 3000)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# --- 2. PROJECT PATH CONFIGURATION ---\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "ROOT_DIR = NOTEBOOK_DIR.parent.parent  # Adjust if your notebook is in a 'notebooks' subdirectory\n",
    "DATA_DIR = ROOT_DIR / 'data'\n",
    "SRC_DIR = ROOT_DIR / 'src'\n",
    "\n",
    "# Add 'src' to the Python path to import custom modules\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.append(str(SRC_DIR))\n",
    "\n",
    "# --- 3. IMPORT CUSTOM MODULES ---\n",
    "import utils\n",
    "import plotting_utils\n",
    "\n",
    "# --- 4. ANALYSIS & FILTERING CONFIGURATION ---\n",
    "\n",
    "# File searching parameters\n",
    "# FILE_PREFIX = ''  # e.g., '2024'\n",
    "FILE_CONTAINS_PATTERN = 'df_OHLCV_clean_stocks_etfs'\n",
    "\n",
    "# # Parameters defining the time windows for metric calculation\n",
    "PERIOD_PARAMS = {\n",
    "    'lookback_days': 22,\n",
    "    'recent_days': 0,\n",
    "}\n",
    "\n",
    "# This is not use for filtering, it's use to calculate metrics in SORT_ORDER\n",
    "# Parameters for filtering the calculated metrics to find candidates\n",
    "METRIC_FILTERS = {\n",
    "    'min_lookback_improvement': 0,\n",
    "    'current_rank_bracket_start': 1,\n",
    "    'current_rank_bracket_end': 1000,\n",
    "    # --- Select ONE mode by commenting out the others ---\n",
    "    # 'Reversal' Mode\n",
    "    'min_recent_bottom_to_recent_start': 0,\n",
    "    'min_recent_bottom_to_current': 0,    \n",
    "    # 'Dip' Mode\n",
    "    # 'min_current_to_recent_start': 10,\n",
    "}\n",
    "\n",
    "# --- 5. VERIFICATION ---\n",
    "print(\"--- Path Configuration ---\")\n",
    "print(f\"✅ Project Root: {ROOT_DIR}\")\n",
    "print(f\"✅ Data Dir:     {DATA_DIR}\")\n",
    "print(f\"✅ Source Dir:   {SRC_DIR}\")\n",
    "assert all([ROOT_DIR.exists(), DATA_DIR.exists(), SRC_DIR.exists()]), \"A key directory was not found!\"\n",
    "\n",
    "print(\"\\n--- Module Verification ---\")\n",
    "print(f\"✅ Successfully imported 'utils' and 'plotting_utils'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Loading latest consolidated Finviz data ---\n",
      "Info: Index is unnamed. Assuming it contains tickers and assigning the name 'Ticker'.\n",
      "✅ Successfully loaded: 2025-09-12_df_finviz_merged_stocks_etfs.parquet\n",
      "Shape: (1463, 139)\n",
      "        No.                Company               Index      Sector                   Industry Country Exchange                                   Info  MktCap AUM, M  Rank  Market Cap, M    P/E  Fwd P/E   PEG    P/S    P/B    P/C  P/FCF  Book/sh  Cash/sh  Dividend %  Dividend TTM Dividend Ex Date  Payout Ratio %    EPS  EPS next Q  EPS this Y %  EPS next Y %  EPS past 5Y %  EPS next 5Y %  Sales past 5Y %  Sales Q/Q %  EPS Q/Q %  EPS YoY TTM %  Sales YoY TTM %  Sales, M  Income, M  EPS Surprise %  Revenue Surprise %  Outstanding, M  Float, M  Float %  Insider Own %  Insider Trans %  Inst Own %  Inst Trans %  Short Float %  Short Ratio  Short Interest, M  ROA %   ROE %  ROIC %  Curr R  Quick R  LTDebt/Eq  Debt/Eq  Gross M %  Oper M %  Profit M %  Perf 3D %  Perf Week %  Perf Month %  Perf Quart %  Perf Half %  Perf Year %  Perf YTD %  Beta   ATR  ATR/Price %  Volatility W %  Volatility M %  SMA20 %  SMA50 %  SMA200 %  50D High %  50D Low %  52W High %  52W Low %        52W Range  All-Time High %  All-Time Low %    RSI  Earnings    IPO Date Optionable Shortable  Employees  Change from Open %  Gap %  Recom  Avg Volume, M  Rel Volume     Volume  Target Price  Prev Close    Open    High     Low   Price  Change % Single Category Asset Type  Expense %  Holdings  AUM, M  Flows 1M, M  Flows% 1M  Flows 3M, M  Flows% 3M  Flows YTD, M  Flows% YTD  Return% 1Y  Return% 3Y  Return% 5Y Tags   Sharpe 3d   Sortino 3d    Omega 3d  Sharpe 5d   Sortino 5d    Omega 5d  Sharpe 10d  Sortino 10d  Omega 10d  Sharpe 15d  Sortino 15d  Omega 15d  Sharpe 30d  Sortino 30d  Omega 30d  Sharpe 60d  Sortino 60d  Omega 60d  Sharpe 120d  Sortino 120d  Omega 120d  Sharpe 250d  Sortino 250d  Omega 250d\n",
      "Ticker                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      "NVDA      1            NVIDIA Corp  DJIA, NDX, S&P 500  Technology             Semiconductors     USA     NASD             Technology, Semiconductors      4321030.0     1      4321030.0  50.61    27.89  1.45  26.15  43.24  76.09  60.00     4.11     2.34        0.02          0.04        9/11/2025            1.16   3.51        1.24           NaN           NaN            NaN            NaN              NaN        55.60      61.23          64.54            71.55  165220.0    86600.0            4.13                1.51         24350.0   23300.0    95.72           4.08            -0.80       67.99          1.73           0.84         1.13             196.70  76.65  109.42   78.42    4.21     3.60       0.10     0.11      69.85     58.09       52.41   4.140556         6.47         -2.08         22.63        53.85        64.50       32.41  2.13  4.84     2.721854            2.05            2.58     1.16     2.12     27.04       -3.61      16.25       -3.61     105.29   86.62 - 184.48            -3.61       533359.99  55.51  Aug 27/a   1/22/1999        Yes       Yes    36000.0               -0.07   0.43   1.35         174.66        0.71  123525769        217.50      177.17  177.94  178.60  176.45  177.82      0.37                                   NaN       NaN     NaN          NaN        NaN          NaN        NaN           NaN         NaN         NaN         NaN         NaN    -    6.229198    27.992689    3.493787  12.468970   436.235684   55.960530    1.936209     3.269837   1.423951   -0.060206    -0.085309   0.989437    0.747411     1.080169   1.139999    3.145329     5.218871   1.688755     1.867452      3.167447    1.441991     0.984842      1.415286    1.194336\n",
      "MSFT      2  Microsoft Corporation  DJIA, NDX, S&P 500  Technology  Software - Infrastructure     USA     NASD  Technology, Software - Infrastructure      3790170.0     2      3790170.0  37.38    27.87  2.25  13.45  11.04  40.08  52.93    46.20    12.72        0.68          3.32        8/21/2025           24.34  13.64        3.65           NaN           NaN            NaN            NaN              NaN        18.10      23.77          15.50            14.93  281720.0   101830.0            8.16                3.40          7430.0    7320.0    98.51           1.48            -0.26       73.31         -0.34           0.80         2.89              58.49  18.00   33.28   22.93    1.35     1.35       0.29     0.33      68.82     45.62       36.15   2.305331         3.01         -2.05          6.48        34.62        23.10       20.97  1.03  7.94     1.557168            1.25            1.39     0.82    -0.10     14.29       -8.20       4.34       -8.20      47.89  344.79 - 555.45            -8.20       639845.66  53.36  Jul 30/a   3/13/1986        Yes       Yes   228000.0                0.70   1.07   1.20          20.26        1.16   23597200        624.36      501.01  506.35  512.55  503.85  509.90      1.77                                   NaN       NaN     NaN          NaN        NaN          NaN        NaN           NaN         NaN         NaN         NaN         NaN    -   12.752518  3589.625439  320.789251  11.180249  5500.580410  694.007992    0.831814     1.107777   1.187282    0.421006     0.563132   1.080631   -1.562981    -2.083460   0.769051    1.429824     2.381983   1.289158     2.073508      4.119370    1.548125     0.682032      1.058333    1.142387\n",
      "AAPL      3              Apple Inc  DJIA, NDX, S&P 500  Technology       Consumer Electronics     USA     NASD       Technology, Consumer Electronics      3473690.0     3      3473690.0  35.58    29.35  4.03   8.50  52.83  62.73  36.12     4.43     3.73        0.44          1.02        8/11/2025           16.11   6.58        1.76           NaN           NaN            NaN            NaN              NaN         9.63      12.19           0.15             5.97  408620.0    99280.0            9.18                4.99         14860.0   14820.0    99.79           0.10            -2.09       64.55          1.15           0.77         2.08             113.58  29.94  149.81   66.96    0.87     0.83       1.25     1.54      46.68     31.87       24.30  -0.119479        -2.34          0.32         17.51        11.63         6.34       -6.53  1.08  4.74     2.025035            2.17            1.72     1.02     5.85      5.67       -3.00      16.16      -10.01      38.33  169.21 - 260.10           -10.01       367841.99  57.15  Jul 31/a  12/12/1980        Yes       Yes   164000.0                2.11  -0.34   2.08          54.68        1.01   55316953        242.54      230.03  229.24  234.51  229.02  234.07      1.76                                   NaN       NaN     NaN          NaN        NaN          NaN        NaN           NaN         NaN         NaN         NaN         NaN    -  108.022218  3589.625439  320.789251  -2.636360    -3.529707    0.664999    0.730838     1.189589   1.129122    1.842245     2.988792   1.379018    4.409409     9.676153   2.232092    3.118618     6.039111   1.772434     0.418330      0.651481    1.091682     0.209388      0.308779    1.042199\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Step 1: Loading latest consolidated Finviz data ---\")\n",
    "\n",
    "# Find the most recent file matching the pattern\n",
    "# This function is now understood to return List[str] (filenames), not List[Path].\n",
    "latest_finviz_filepaths = utils.get_recent_files(\n",
    "    directory_path=DATA_DIR,\n",
    "    extension='parquet',\n",
    "    prefix='202',\n",
    "    contains_pattern='df_finviz_merged_stocks_etfs',\n",
    "    count=1\n",
    ")\n",
    "\n",
    "if not latest_finviz_filepaths:\n",
    "    raise FileNotFoundError(f\"No files found in '{DATA_DIR}' with prefix '{FILE_PREFIX}' and pattern '{FILE_CONTAINS_PATTERN}'\")\n",
    "\n",
    "# Get the filename string from the list\n",
    "latest_filename = latest_finviz_filepaths[0]\n",
    "\n",
    "# Manually construct the full path before loading\n",
    "full_file_path = DATA_DIR / latest_filename\n",
    "df_finviz_latest = pd.read_parquet(full_file_path, engine='pyarrow')\n",
    "\n",
    "\n",
    "# --- Robust Index Setting (this logic remains correct) ---\n",
    "if df_finviz_latest.index.name == 'Ticker':\n",
    "    print(\"Info: 'Ticker' is already the index. No action needed.\")\n",
    "elif 'Ticker' in df_finviz_latest.columns:\n",
    "    print(\"Info: 'Ticker' column found. Setting it as the DataFrame index.\")\n",
    "    df_finviz_latest.set_index('Ticker', inplace=True)\n",
    "elif 'ticker' in df_finviz_latest.columns:\n",
    "    print(\"Info: 'ticker' column found. Renaming and setting as index.\")\n",
    "    df_finviz_latest.rename(columns={'ticker': 'Ticker'}, inplace=True)\n",
    "    df_finviz_latest.set_index('Ticker', inplace=True)\n",
    "elif df_finviz_latest.index.name is None:\n",
    "    print(\"Info: Index is unnamed. Assuming it contains tickers and assigning the name 'Ticker'.\")\n",
    "    df_finviz_latest.index.name = 'Ticker'\n",
    "else:\n",
    "    print(\"ERROR: Loaded DataFrame has an unexpected format.\")\n",
    "    print(f\"Columns: {df_finviz_latest.columns.tolist()}\")\n",
    "    print(f\"Index Name: '{df_finviz_latest.index.name}'\")\n",
    "    raise ValueError(\"Could not find a 'Ticker' column or a usable index to proceed.\")\n",
    "\n",
    "\n",
    "# Correct the print statement to work with the filename string\n",
    "print(f\"✅ Successfully loaded: {latest_filename}\")\n",
    "print(f\"Shape: {df_finviz_latest.shape}\")\n",
    "print(df_finviz_latest.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually construct the full path before loading\n",
    "full_file_path = DATA_DIR / 'df_OHLCV_clean_stocks_etfs.parquet'\n",
    "df_OHLCV = pd.read_parquet(full_file_path, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 2: The Chronological Split Code\n",
    "\n",
    "This cell contains the logic to find the split date and create the `df_train` and `df_test` DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique trading dates in dataset: 250\n",
      "The data will be split on the date: 2025-05-28\n",
      "\n",
      "--- Verification ---\n",
      "Original DataFrame shape: (371000, 5)\n",
      "Training set shape:   (261184, 5)\n",
      "Testing set shape:    (109816, 5)\n",
      "\n",
      "Date Ranges:\n",
      "  Training: 2024-09-13 to 2025-05-28\n",
      "  Testing:  2025-05-29 to 2025-09-12\n",
      "\n",
      "Verification successful: There is no date overlap between train and test sets.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Find the Chronological Split Point ---\n",
    "\n",
    "# Get all unique dates from the index and sort them\n",
    "unique_dates = df_OHLCV.index.get_level_values('Date').unique().sort_values()\n",
    "\n",
    "# Determine the index for the 70% split\n",
    "split_index = int(len(unique_dates) * 0.7)\n",
    "\n",
    "# Find the actual date at that split index\n",
    "split_date = unique_dates[split_index]\n",
    "\n",
    "print(f\"Total unique trading dates in dataset: {len(unique_dates)}\")\n",
    "print(f\"The data will be split on the date: {split_date.date()}\")\n",
    "\n",
    "# --- 2. Create the Training and Testing Sets ---\n",
    "\n",
    "# The training set includes all data UP TO and INCLUDING the split_date\n",
    "df_train = df_OHLCV[df_OHLCV.index.get_level_values('Date') <= split_date]\n",
    "\n",
    "# The testing set includes all data AFTER the split_date\n",
    "df_test = df_OHLCV[df_OHLCV.index.get_level_values('Date') > split_date]\n",
    "\n",
    "\n",
    "# --- 3. Verify the Split ---\n",
    "\n",
    "print(\"\\n--- Verification ---\")\n",
    "print(f\"Original DataFrame shape: {df_OHLCV.shape}\")\n",
    "print(f\"Training set shape:   {df_train.shape}\")\n",
    "print(f\"Testing set shape:    {df_test.shape}\")\n",
    "\n",
    "print(\"\\nDate Ranges:\")\n",
    "print(f\"  Training: {df_train.index.get_level_values('Date').min().date()} to {df_train.index.get_level_values('Date').max().date()}\")\n",
    "print(f\"  Testing:  {df_test.index.get_level_values('Date').min().date()} to {df_test.index.get_level_values('Date').max().date()}\")\n",
    "\n",
    "# Final check to ensure no overlap\n",
    "assert df_train.index.get_level_values('Date').max() < df_test.index.get_level_values('Date').min()\n",
    "print(\"\\nVerification successful: There is no date overlap between train and test sets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Adj Open</th>\n",
       "      <th>Adj High</th>\n",
       "      <th>Adj Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th>2024-09-13</th>\n",
       "      <td>135.7660</td>\n",
       "      <td>136.5590</td>\n",
       "      <td>135.3290</td>\n",
       "      <td>136.2620</td>\n",
       "      <td>924860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAL</th>\n",
       "      <th>2024-09-13</th>\n",
       "      <td>10.9800</td>\n",
       "      <td>11.1800</td>\n",
       "      <td>10.6100</td>\n",
       "      <td>10.6900</td>\n",
       "      <td>36956000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAON</th>\n",
       "      <th>2024-09-13</th>\n",
       "      <td>93.6669</td>\n",
       "      <td>94.8421</td>\n",
       "      <td>93.0793</td>\n",
       "      <td>93.7367</td>\n",
       "      <td>208147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <th>2024-09-13</th>\n",
       "      <td>222.5440</td>\n",
       "      <td>223.0020</td>\n",
       "      <td>220.8820</td>\n",
       "      <td>221.4690</td>\n",
       "      <td>36937711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBV</th>\n",
       "      <th>2024-09-13</th>\n",
       "      <td>187.1660</td>\n",
       "      <td>187.8710</td>\n",
       "      <td>185.1870</td>\n",
       "      <td>187.5040</td>\n",
       "      <td>2815309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZM</th>\n",
       "      <th>2025-05-28</th>\n",
       "      <td>79.1600</td>\n",
       "      <td>80.1750</td>\n",
       "      <td>79.0150</td>\n",
       "      <td>79.6700</td>\n",
       "      <td>2481400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZS</th>\n",
       "      <th>2025-05-28</th>\n",
       "      <td>256.0000</td>\n",
       "      <td>256.0000</td>\n",
       "      <td>252.5000</td>\n",
       "      <td>253.6500</td>\n",
       "      <td>2223400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZTO</th>\n",
       "      <th>2025-05-28</th>\n",
       "      <td>17.0900</td>\n",
       "      <td>17.6400</td>\n",
       "      <td>17.0900</td>\n",
       "      <td>17.5300</td>\n",
       "      <td>4477600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZTS</th>\n",
       "      <th>2025-05-28</th>\n",
       "      <td>165.6060</td>\n",
       "      <td>166.0950</td>\n",
       "      <td>163.9720</td>\n",
       "      <td>164.8490</td>\n",
       "      <td>1729463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZWS</th>\n",
       "      <th>2025-05-28</th>\n",
       "      <td>36.9164</td>\n",
       "      <td>36.9164</td>\n",
       "      <td>36.0881</td>\n",
       "      <td>36.1779</td>\n",
       "      <td>524543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261184 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Adj Open  Adj High   Adj Low  Adj Close    Volume\n",
       "Ticker Date                                                         \n",
       "A      2024-09-13  135.7660  136.5590  135.3290   136.2620    924860\n",
       "AAL    2024-09-13   10.9800   11.1800   10.6100    10.6900  36956000\n",
       "AAON   2024-09-13   93.6669   94.8421   93.0793    93.7367    208147\n",
       "AAPL   2024-09-13  222.5440  223.0020  220.8820   221.4690  36937711\n",
       "ABBV   2024-09-13  187.1660  187.8710  185.1870   187.5040   2815309\n",
       "...                     ...       ...       ...        ...       ...\n",
       "ZM     2025-05-28   79.1600   80.1750   79.0150    79.6700   2481400\n",
       "ZS     2025-05-28  256.0000  256.0000  252.5000   253.6500   2223400\n",
       "ZTO    2025-05-28   17.0900   17.6400   17.0900    17.5300   4477600\n",
       "ZTS    2025-05-28  165.6060  166.0950  163.9720   164.8490   1729463\n",
       "ZWS    2025-05-28   36.9164   36.9164   36.0881    36.1779    524543\n",
       "\n",
       "[261184 rows x 5 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Adj Open</th>\n",
       "      <th>Adj High</th>\n",
       "      <th>Adj Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th>2025-05-29</th>\n",
       "      <td>116.7040</td>\n",
       "      <td>116.7440</td>\n",
       "      <td>112.7630</td>\n",
       "      <td>113.0420</td>\n",
       "      <td>3845481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAL</th>\n",
       "      <th>2025-05-29</th>\n",
       "      <td>11.6400</td>\n",
       "      <td>11.6700</td>\n",
       "      <td>11.3100</td>\n",
       "      <td>11.4000</td>\n",
       "      <td>61318000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAON</th>\n",
       "      <th>2025-05-29</th>\n",
       "      <td>98.1157</td>\n",
       "      <td>98.1157</td>\n",
       "      <td>95.4418</td>\n",
       "      <td>95.9307</td>\n",
       "      <td>547849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <th>2025-05-29</th>\n",
       "      <td>203.3490</td>\n",
       "      <td>203.5790</td>\n",
       "      <td>198.2850</td>\n",
       "      <td>199.7230</td>\n",
       "      <td>51455131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBV</th>\n",
       "      <th>2025-05-29</th>\n",
       "      <td>181.8890</td>\n",
       "      <td>185.1510</td>\n",
       "      <td>181.1260</td>\n",
       "      <td>184.0310</td>\n",
       "      <td>4968445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZM</th>\n",
       "      <th>2025-09-12</th>\n",
       "      <td>84.6000</td>\n",
       "      <td>85.0000</td>\n",
       "      <td>83.8200</td>\n",
       "      <td>83.9800</td>\n",
       "      <td>1856513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZS</th>\n",
       "      <th>2025-09-12</th>\n",
       "      <td>287.0000</td>\n",
       "      <td>288.5300</td>\n",
       "      <td>282.4600</td>\n",
       "      <td>283.1900</td>\n",
       "      <td>1340900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZTO</th>\n",
       "      <th>2025-09-12</th>\n",
       "      <td>19.2600</td>\n",
       "      <td>19.2900</td>\n",
       "      <td>19.0003</td>\n",
       "      <td>19.0600</td>\n",
       "      <td>735599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZTS</th>\n",
       "      <th>2025-09-12</th>\n",
       "      <td>149.6450</td>\n",
       "      <td>150.0500</td>\n",
       "      <td>146.5350</td>\n",
       "      <td>148.2000</td>\n",
       "      <td>3111221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZWS</th>\n",
       "      <th>2025-09-12</th>\n",
       "      <td>47.3700</td>\n",
       "      <td>47.6900</td>\n",
       "      <td>46.6450</td>\n",
       "      <td>46.6800</td>\n",
       "      <td>891856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109816 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Adj Open  Adj High   Adj Low  Adj Close    Volume\n",
       "Ticker Date                                                         \n",
       "A      2025-05-29  116.7040  116.7440  112.7630   113.0420   3845481\n",
       "AAL    2025-05-29   11.6400   11.6700   11.3100    11.4000  61318000\n",
       "AAON   2025-05-29   98.1157   98.1157   95.4418    95.9307    547849\n",
       "AAPL   2025-05-29  203.3490  203.5790  198.2850   199.7230  51455131\n",
       "ABBV   2025-05-29  181.8890  185.1510  181.1260   184.0310   4968445\n",
       "...                     ...       ...       ...        ...       ...\n",
       "ZM     2025-09-12   84.6000   85.0000   83.8200    83.9800   1856513\n",
       "ZS     2025-09-12  287.0000  288.5300  282.4600   283.1900   1340900\n",
       "ZTO    2025-09-12   19.2600   19.2900   19.0003    19.0600    735599\n",
       "ZTS    2025-09-12  149.6450  150.0500  146.5350   148.2000   3111221\n",
       "ZWS    2025-09-12   47.3700   47.6900   46.6450    46.6800    891856\n",
       "\n",
       "[109816 rows x 5 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High-Level Review\n",
    "\n",
    "*   **Configuration Management:** The parameters are split. `strategy_params` are static, while `lookback` and `rolling` are loop variables. This is a common pattern, but it can be improved by unifying them into a single configuration object for each run. This makes logging and debugging much clearer.\n",
    "*   **Encapsulation:** The optimization loop contains three distinct responsibilities: 1) generating parameter combinations, 2) running the backtest for each combination, and 3) calculating performance metrics. These can be encapsulated into their own functions to make the top-level script cleaner and the components more reusable.\n",
    "*   **Performance:** The current structure is logically sound for an optimization task. The most expensive part, `precompute_signals`, *must* be re-run for each parameter combination because its calculations depend on `lookback` and `rolling`. While we can't eliminate this work, we can ensure the structure is clean and acknowledge that for massive speed-ups, one might need to switch to a specialized backtesting library (like `vectorbt`) that can test many parameter combinations at once. We will focus on making the current Python/Pandas implementation as clean and well-structured as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactoring Strategy\n",
    "\n",
    "1.  **Consolidate Parameters:** We'll combine the loop parameters and the static `strategy_params` into a single configuration dictionary for each backtest run.\n",
    "2.  **Create a Performance Analysis Function:** We'll extract the metric calculation logic (win rate, total return, etc.) into a dedicated `analyze_performance` function. This isolates analysis from the optimization loop.\n",
    "3.  **Create an Optimization Orchestrator:** We'll wrap the entire optimization loop in a new function, `run_parameter_optimization`. This function will be responsible for iterating through parameter sets, calling the backtest, calling the performance analysis, and collecting the results.\n",
    "4.  **Refine the `run_backtest` Signature:** We'll update `run_backtest` and its helpers to accept the new consolidated configuration dictionary. This simplifies the function calls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactored Code\n",
    "\n",
    "Here is the complete, refactored solution. I've included the previously refactored functions with slight modifications to accept the new configuration structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_rolling_z_scores(df_group, rolling_window=20):\n",
    "    \"\"\"\n",
    "    Calculates a rolling Z-score for the 'Adj Low' price for an entire ticker history.\n",
    "    \n",
    "    This function is designed to be used with pandas' groupby().apply().\n",
    "    \n",
    "    Args:\n",
    "        df_group (pd.DataFrame): The DataFrame for a single ticker.\n",
    "        rolling_window (int): The lookback window for calculating mean and std.\n",
    "        \n",
    "    Returns:\n",
    "        pd.Series: A Series of Z-scores with the same index as the input df_group.\n",
    "    \"\"\"\n",
    "    # Use the column directly, which is more efficient.\n",
    "    low_price = df_group['Adj Low']\n",
    "    \n",
    "    # Calculate rolling statistics. min_periods=1 ensures we get values even at the start.\n",
    "    rolling_mean = low_price.rolling(window=rolling_window, min_periods=1).mean()\n",
    "    rolling_std = low_price.rolling(window=rolling_window, min_periods=1).std()\n",
    "    \n",
    "    # Calculate the Z-score for all dates at once.\n",
    "    z_score = (low_price - rolling_mean) / rolling_std\n",
    "    \n",
    "    # --- ROBUSTNESS IMPROVEMENTS ---\n",
    "    # 1. Handle division by zero: if std is 0, z_score is inf. Replace with 0.\n",
    "    z_score = z_score.replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "    # 2. Fill any initial NaNs (from std dev calculation) with 0.\n",
    "    z_score = z_score.fillna(0)\n",
    "    \n",
    "    # Return the entire series, renamed appropriately.\n",
    "    return z_score.rename('low_rolling_z_score')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import linregress # We no longer need this for the vectorized function\n",
    "\n",
    "def analyze_ticker_trends_vectorized(df_group, lookback_days=60):\n",
    "    \"\"\"\n",
    "    Vectorized analysis of trends for a ticker's price and volume.\n",
    "    \n",
    "    This version calculates linear regression metrics using rolling covariance\n",
    "    and variance, avoiding the limitations of .apply() and maximizing performance.\n",
    "    \"\"\"\n",
    "    if len(df_group) < lookback_days:\n",
    "        return None # groupby().apply() will correctly handle None returns by skipping the group\n",
    "\n",
    "    # --- 1. Setup for Vectorized Regression ---\n",
    "    \n",
    "    # Create a time-series index [0, 1, 2, ...] that aligns with the data\n",
    "    time_index = pd.Series(np.arange(len(df_group)), index=df_group.index)\n",
    "    \n",
    "    # The variance of a sequence [0, 1, ..., n-1] is constant. Pre-calculate it.\n",
    "    var_time = np.var(np.arange(lookback_days), ddof=0)\n",
    "    \n",
    "    # --- 2. Calculate Rolling Metrics for Each Column ---\n",
    "\n",
    "    # We'll work with a dictionary of the series we want to analyze\n",
    "    series_to_analyze = {\n",
    "        'high': df_group['Adj High'],\n",
    "        'low': df_group['Adj Low'],\n",
    "        'volume': df_group['Volume'].astype(float) # Ensure volume is float\n",
    "    }\n",
    "    \n",
    "    df_results = pd.DataFrame(index=df_group.index)\n",
    "\n",
    "    for name, series in series_to_analyze.items():\n",
    "        # Rolling covariance between the series and the time index\n",
    "        rolling_cov = time_index.rolling(window=lookback_days).cov(series, ddof=0)\n",
    "        \n",
    "        # Rolling variance of the series itself\n",
    "        rolling_var_series = series.rolling(window=lookback_days).var(ddof=0)\n",
    "        \n",
    "        # Slope = cov(t, y) / var(t)\n",
    "        df_results[f'{name}_slope'] = rolling_cov / var_time\n",
    "        \n",
    "        # R-squared = cov(t, y)^2 / (var(t) * var(y))\n",
    "        # Add a small epsilon to prevent division by zero\n",
    "        denominator = (var_time * rolling_var_series) + 1e-9\n",
    "        df_results[f'{name}_r_squared'] = (rolling_cov**2) / denominator\n",
    "\n",
    "    # --- 3. Calculate Volatility and Penalty Scores (as before) ---\n",
    "    \n",
    "    yesterday_low = df_group['Adj Low'].shift(1)\n",
    "    worst_case_returns = (df_group['Adj High'] - yesterday_low) / yesterday_low\n",
    "    df_results['unified_std_dev_returns'] = worst_case_returns.rolling(window=lookback_days).std(ddof=0)\n",
    "    \n",
    "    volume_std_dev = df_group['Volume'].pct_change().rolling(window=lookback_days).std(ddof=0)\n",
    "    df_results['volume_std_dev_returns'] = volume_std_dev\n",
    "    \n",
    "    df_results['low_penalty_score'] = (1 - df_results['low_r_squared']) * (df_results['unified_std_dev_returns'] + 1e-9)\n",
    "    df_results['high_penalty_score'] = (1 - df_results['high_r_squared']) * (df_results['unified_std_dev_returns'] + 1e-9)\n",
    "    df_results['volume_penalty_score'] = (1 - df_results['volume_r_squared']) * (df_results['volume_std_dev_returns'] + 1e-9)\n",
    "    \n",
    "    return df_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Refined Core Backtesting Functions\n",
    "\n",
    "We'll modify the function signatures to accept a single `config` dictionary. This makes them more modular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "\n",
    "# Assume analyze_ticker_trends_vectorized and calculate_rolling_z_scores are defined elsewhere\n",
    "\n",
    "def precompute_signals(df_ohlcv, config):\n",
    "    \"\"\"Pre-computes trading signals using parameters from the config dict.\"\"\"\n",
    "    print(\"Pre-computing features for this parameter set...\")\n",
    "    \n",
    "    # --- KEY CHANGE: Add group_keys=False to prevent duplicate index levels ---\n",
    "    trends = df_ohlcv.groupby(level='Ticker', group_keys=False).apply(\n",
    "        analyze_ticker_trends_vectorized, config['lookback_days']\n",
    "    )\n",
    "    \n",
    "    # --- KEY CHANGE: Add group_keys=False here as well ---\n",
    "    z_scores = df_ohlcv.groupby(level='Ticker', group_keys=False).apply(\n",
    "        calculate_rolling_z_scores, config['rolling_window']\n",
    "    )\n",
    "    \n",
    "    # The rest of the function remains the same\n",
    "    features = trends.join(z_scores).dropna()\n",
    "\n",
    "    signals = features[\n",
    "        (features['low_slope'] > config['slope_thresh']) &\n",
    "        (features['low_r_squared'] > config['r2_thresh']) &\n",
    "        (features['volume_slope'] > 0) &\n",
    "        (features['low_rolling_z_score'] < config['z_entry_thresh'])\n",
    "    ]\n",
    "    return signals.index\n",
    "\n",
    "\n",
    "# The handle_exits_for_day and handle_entries_for_day functions from the previous\n",
    "# review remain the same, but they will receive `config` (formerly `params`).\n",
    "# For brevity, I'll show the updated main backtest function which calls them.\n",
    "\n",
    "def run_backtest(df_ohlcv, config):\n",
    "    \"\"\"\n",
    "    Orchestrates the backtesting process for a single configuration.\n",
    "    \"\"\"\n",
    "    entry_signals = precompute_signals(df_ohlcv, config)\n",
    "    \n",
    "    trades = []\n",
    "    open_positions = {}\n",
    "    all_dates = df_ohlcv.index.get_level_values('Date').unique().sort_values()\n",
    "    \n",
    "    # We need a sufficient buffer for the largest lookback/rolling window\n",
    "    start_index = max(config['lookback_days'], config['rolling_window'])\n",
    "\n",
    "    for i in range(start_index, len(all_dates) - 1): # No tqdm here, outer loop will have it\n",
    "        current_date = all_dates[i]\n",
    "        next_day_date = all_dates[i+1]\n",
    "\n",
    "        closed_trades, open_positions = handle_exits_for_day(\n",
    "            current_date, next_day_date, open_positions, df_ohlcv, config\n",
    "        )\n",
    "        trades.extend(closed_trades)\n",
    "\n",
    "        signals_today = entry_signals[entry_signals.get_level_values('Date') == current_date]\n",
    "        tickers_with_signal = signals_today.get_level_values('Ticker')\n",
    "        \n",
    "        open_positions = handle_entries_for_day(\n",
    "            current_date, next_day_date, tickers_with_signal, open_positions, df_ohlcv\n",
    "        )\n",
    "                \n",
    "    return pd.DataFrame(trades)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: New Encapsulated Helper Functions\n",
    "\n",
    "These new functions isolate the logic for performance analysis and the optimization loop itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_performance(trade_results):\n",
    "    \"\"\"\n",
    "    Calculates performance metrics from a DataFrame of trades.\n",
    "    \n",
    "    Returns a dictionary of key metrics.\n",
    "    \"\"\"\n",
    "    if trade_results.empty:\n",
    "        return {'num_trades': 0, 'win_rate': 0, 'avg_return': 0, 'total_return': 0}\n",
    "    \n",
    "    win_rate = (trade_results['return'] > 0).mean()\n",
    "    total_return = (1 + trade_results['return']).prod() - 1\n",
    "    avg_return = trade_results['return'].mean()\n",
    "    \n",
    "    return {\n",
    "        'num_trades': len(trade_results),\n",
    "        'win_rate': win_rate,\n",
    "        'avg_return': avg_return,\n",
    "        'total_return': total_return\n",
    "    }\n",
    "\n",
    "def run_parameter_optimization(df, param_grid, static_params):\n",
    "    \"\"\"\n",
    "    Orchestrates the entire parameter optimization process.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The OHLCV data.\n",
    "        param_grid (dict): Dictionary with lists of parameters to test.\n",
    "        static_params (dict): Dictionary of parameters that are not being optimized.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A summary of results for each parameter combination.\n",
    "    \"\"\"\n",
    "    results_log = []\n",
    "    \n",
    "    # Use itertools.product to create a clean generator for all combinations\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    param_combinations = [dict(zip(keys, v)) for v in product(*values)]\n",
    "\n",
    "    print(f\"Starting optimization for {len(param_combinations)} combinations...\")\n",
    "    \n",
    "    for param_set in tqdm(param_combinations, desc=\"Optimization Progress\"):\n",
    "        # Combine static and dynamic parameters into a single config for this run\n",
    "        current_config = {**static_params, **param_set}\n",
    "        \n",
    "        # 1. Run the backtest with the current configuration\n",
    "        trade_results = run_backtest(df, current_config)\n",
    "        \n",
    "        # 2. Analyze the performance of this run\n",
    "        performance_metrics = analyze_performance(trade_results)\n",
    "        \n",
    "        # 3. Log the results\n",
    "        log_entry = {**param_set, **performance_metrics}\n",
    "        results_log.append(log_entry)\n",
    "        \n",
    "    return pd.DataFrame(results_log)\n",
    "\n",
    "def handle_exits_for_day(current_date, next_day_date, open_positions, df_ohlcv, config):\n",
    "    \"\"\"\n",
    "    Checks all open positions for exit signals based on the current_date's data\n",
    "    and executes them on the next_day_date.\n",
    "    \n",
    "    Returns a list of closed trades and the updated open_positions dictionary.\n",
    "    \"\"\"\n",
    "    closed_trades = []\n",
    "    positions_to_close = []\n",
    "\n",
    "    for ticker, pos in open_positions.items():\n",
    "        try:\n",
    "            current_close_price = df_ohlcv.loc[(ticker, current_date), 'Adj Close']\n",
    "        except KeyError:\n",
    "            continue # Skip if ticker has no data for the signal day\n",
    "\n",
    "        # Determine if an exit signal is triggered\n",
    "        exit_reason = None\n",
    "        if current_close_price >= pos['entry_price'] * (1 + config['profit_target']):\n",
    "            exit_reason = \"Profit Target\"\n",
    "        elif current_close_price <= pos['entry_price'] * (1 - config['stop_loss']):\n",
    "            exit_reason = \"Stop-Loss\"\n",
    "        elif (current_date.to_pydatetime().date() - pos['entry_date'].to_pydatetime().date()).days >= config['time_hold_days']:\n",
    "            exit_reason = \"Time Hold\"\n",
    "\n",
    "        if exit_reason:\n",
    "            try:\n",
    "                # Execute the sale on the NEXT DAY's low\n",
    "                exit_price = df_ohlcv.loc[(ticker, next_day_date), 'Adj Low']\n",
    "                \n",
    "                trade_return = (exit_price - pos['entry_price']) / pos['entry_price']\n",
    "                closed_trades.append({\n",
    "                    'ticker': ticker, \n",
    "                    'entry_date': pos['entry_date'], \n",
    "                    'exit_date': next_day_date,\n",
    "                    'return': trade_return, \n",
    "                    'reason': exit_reason\n",
    "                })\n",
    "                positions_to_close.append(ticker)\n",
    "            except KeyError:\n",
    "                # No data to execute exit on the next day, so hold the position\n",
    "                pass\n",
    "                \n",
    "    # Safely remove closed positions from the dictionary\n",
    "    for ticker in positions_to_close:\n",
    "        del open_positions[ticker]\n",
    "        \n",
    "    return closed_trades, open_positions\n",
    "\n",
    "def handle_entries_for_day(current_date, next_day_date, daily_signals, open_positions, df_ohlcv):\n",
    "    \"\"\"\n",
    "    Processes new entry signals for the current day and executes them on the next day.\n",
    "    \n",
    "    Returns the updated open_positions dictionary.\n",
    "    \"\"\"\n",
    "    for ticker in daily_signals:\n",
    "        if ticker not in open_positions:\n",
    "            try:\n",
    "                # Execute the buy on the NEXT DAY's high\n",
    "                entry_price = df_ohlcv.loc[(ticker, next_day_date), 'Adj High']\n",
    "                \n",
    "                open_positions[ticker] = {\n",
    "                    'entry_date': next_day_date,\n",
    "                    'entry_price': entry_price\n",
    "                }\n",
    "            except KeyError:\n",
    "                # No data to execute entry on the next day, so skip the trade\n",
    "                pass\n",
    "                \n",
    "    return open_positions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: The New, Clean Top-Level Script\n",
    "\n",
    "Your main script is now incredibly simple and readable. It's all about configuration and orchestration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting optimization for 6 combinations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computing features for this parameter set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  17%|█▋        | 1/6 [00:49<04:09, 49.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computing features for this parameter set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  33%|███▎      | 2/6 [01:34<03:06, 46.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computing features for this parameter set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  50%|█████     | 3/6 [02:19<02:18, 46.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computing features for this parameter set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  67%|██████▋   | 4/6 [03:04<01:31, 45.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computing features for this parameter set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  83%|████████▎ | 5/6 [03:48<00:44, 44.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computing features for this parameter set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress: 100%|██████████| 6/6 [04:32<00:00, 45.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Optimization Complete ---\n",
      "   lookback_days  rolling_window  num_trades  win_rate  avg_return  total_return\n",
      "1             30              20         185  0.340541   -0.026774     -0.995939\n",
      "0             30              15         511  0.354207   -0.026781     -1.000000\n",
      "5             90              20         511  0.279843   -0.047828     -1.000000\n",
      "4             90              15         575  0.292174   -0.045300     -1.000000\n",
      "3             60              20         936  0.294872   -0.033477     -1.000000\n",
      "2             60              15        1135  0.263436   -0.037324     -1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 1. DEFINE CONFIGURATION ---\n",
    "\n",
    "# Parameters to be optimized, defining the search space\n",
    "optimization_grid = {\n",
    "    'lookback_days': [30, 60, 90],\n",
    "    'rolling_window': [15, 20]\n",
    "}\n",
    "\n",
    "# Static strategy parameters that do not change during optimization\n",
    "strategy_params = {\n",
    "    'slope_thresh': 0.05,\n",
    "    'r2_thresh': 0.50,\n",
    "    'z_entry_thresh': -1.5,\n",
    "    'profit_target': 0.10,\n",
    "    'stop_loss': 0.05,\n",
    "    'time_hold_days': 20\n",
    "}\n",
    "\n",
    "\n",
    "# --- 2. RUN ORCHESTRATOR ---\n",
    "\n",
    "# The main call is now a single, descriptive function\n",
    "optimization_results = run_parameter_optimization(\n",
    "    df_train, optimization_grid, strategy_params\n",
    ")\n",
    "\n",
    "\n",
    "# --- 3. ANALYZE RESULTS ---\n",
    "\n",
    "print(\"\\n\\n--- Optimization Complete ---\")\n",
    "print(optimization_results.sort_values(by='total_return', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: The \"One-Trade\" Deep Dive\n",
    "\n",
    "The most powerful debugging technique is to isolate a single trade and follow it from signal generation to exit. If the logic holds for one trade, it's likely correct for all of them.\n",
    "\n",
    "1.  **Pick a Winning Trade and a Losing Trade:** Run one of the backtests again (e.g., the one with `lookback=30`, `rolling=20`) and save the `trade_results` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computing features for this parameter set...\n",
      "Sample winning trade:\n",
      "  ticker entry_date  exit_date    return         reason\n",
      "0    FIX 2024-10-28 2024-11-07  0.110984  Profit Target\n",
      "\n",
      "Sample losing trade:\n",
      "  ticker entry_date  exit_date  return     reason\n",
      "2    EQH 2024-11-06 2024-11-11 -0.0489  Stop-Loss\n"
     ]
    }
   ],
   "source": [
    "# Pick a configuration to analyze\n",
    "config_to_test = {**strategy_params, 'lookback_days': 30, 'rolling_window': 20}\n",
    "\n",
    "# Run a single backtest and get the detailed trade log\n",
    "single_run_trades = run_backtest(df_train, config_to_test)\n",
    "\n",
    "# Find a winning and a losing trade to investigate\n",
    "print(\"Sample winning trade:\")\n",
    "print(single_run_trades[single_run_trades['return'] > 0].head(1))\n",
    "\n",
    "print(\"\\nSample losing trade:\")\n",
    "print(single_run_trades[single_run_trades['return'] < 0].head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trends = analyze_ticker_trends_vectorized(df_train, lookback_days=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "high_slope                      7.393045\n",
       "high_r_squared                  0.018086\n",
       "low_slope                       7.150013\n",
       "low_r_squared                   0.017813\n",
       "volume_slope              -264511.524138\n",
       "volume_r_squared                0.091981\n",
       "unified_std_dev_returns         4.392628\n",
       "volume_std_dev_returns         14.814005\n",
       "low_penalty_score               4.314382\n",
       "high_penalty_score              4.313183\n",
       "volume_penalty_score           13.451396\n",
       "Name: (FIX, 2024-10-25 00:00:00), dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trends.loc['FIX', '2024-10-25']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
