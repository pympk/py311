{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank-Based Candidate Analysis\n",
    "\n",
    "This notebook identifies promising stock tickers based on their historical rank performance.\n",
    "\n",
    "**Workflow:**\n",
    "\n",
    "1.  **Load Data:** It finds the latest comprehensive Finviz data file and all recent daily rank files.\n",
    "2.  **Build Rank History:** It compiles the daily files into a single time-series DataFrame (`df_rank_history`) where each row is a ticker and each column is a date.\n",
    "3.  **Calculate Metrics:** It processes the entire rank history to compute a rich set of performance metrics (slope, peak rank, etc.) for *every ticker*. This creates a master `df_all_tickers_metrics` DataFrame.\n",
    "4.  **Filter & Sort Candidates:** The master metrics are filtered according to user-defined criteria (e.g., \"Reversal\" pattern) to find a small list of top candidates.\n",
    "5.  **Analyze & Visualize:** The top candidates are enhanced with price data, sorted, and plotted. A separate analysis is also performed on a pre-defined portfolio of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and Configuration\n",
    "\n",
    "This cell contains all imports and user-configurable parameters for the analysis pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "import inspect  # <--- ADD THIS LINE\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# --- 1. PANDAS & IPYTHON OPTIONS ---\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 3000)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# --- 2. PROJECT PATH CONFIGURATION ---\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "ROOT_DIR = NOTEBOOK_DIR.parent.parent  # Adjust if your notebook is in a 'notebooks' subdirectory\n",
    "DATA_DIR = ROOT_DIR / 'data'\n",
    "SRC_DIR = ROOT_DIR / 'src'\n",
    "\n",
    "# Add 'src' to the Python path to import custom modules\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.append(str(SRC_DIR))\n",
    "\n",
    "# --- 3. IMPORT CUSTOM MODULES ---\n",
    "import utils\n",
    "import plotting_utils\n",
    "\n",
    "# --- 4. ANALYSIS & FILTERING CONFIGURATION ---\n",
    "\n",
    "# File searching parameters\n",
    "FILE_PREFIX = '202'  # e.g., '2024'\n",
    "FILE_CONTAINS_PATTERN = 'df_finviz_merged_stocks_etfs'\n",
    "HISTORY_FILE_COUNT = 100 # Number of recent daily files to build rank history\n",
    "\n",
    "############################################\n",
    "# # Parameters defining the time windows for metric calculation\n",
    "# PERIOD_PARAMS = {\n",
    "#     'lookback_days': 20,\n",
    "#     'recent_days': 4,\n",
    "# }\n",
    "\n",
    "PERIOD_PARAMS = {\n",
    "    'lookback_days': 40,\n",
    "    'recent_days': 8,\n",
    "}\n",
    "\n",
    "############################################\n",
    "\n",
    "# This is not use for filtering, it's use to calculate metrics in SORT_ORDER\n",
    "# Parameters for filtering the calculated metrics to find candidates\n",
    "METRIC_FILTERS = {\n",
    "    'min_lookback_improvement': 0,\n",
    "    'current_rank_bracket_start': 1,\n",
    "    'current_rank_bracket_end': 1000,\n",
    "    # --- Select ONE mode by commenting out the others ---\n",
    "    # 'Reversal' Mode\n",
    "    'min_recent_bottom_to_recent_start': 0,\n",
    "    'min_recent_bottom_to_current': 0,    \n",
    "    # 'Dip' Mode\n",
    "    # 'min_current_to_recent_start': 10,\n",
    "}\n",
    "\n",
    "# Sorting is the filter to select the top tickers\n",
    "# Sorting order for final candidate list (column_name: ascending_boolean)\n",
    "SORT_ORDER = {\n",
    "    'current_to_total_peak': True,      # Lower is better (closer to all-time best rank)\n",
    "    'Change/(ATR/Price)': False,        # Higher is better (strong upside price and low volatility)   \n",
    "    'Change %': False,                  # Higher is better (stronger daily performance)    \n",
    "    'recent_bottom_to_current': False,  # Higher is better (stronger bounce from recent low)\n",
    "    'lookback_slope': True,             # Lower is better (steeper improving trend)\n",
    "}\n",
    "\n",
    "# List of tickers for a separate, focused portfolio analysis\n",
    "PORTFOLIO_TICKERS = [\n",
    "    \"JOBY\", \"SYM\", \"RKLB\", \"MSTR\", \"ORCL\",\n",
    "    \"SHOP\", \"COIN\", \"VGT\", \"AVAV\", \"META\",\n",
    "    \"NVDA\",\n",
    "    # ####### Change/(ATR/Price) > 1.5\n",
    "    \"DELL\", \"FUTU\", \"VST\",\n",
    "    #########\n",
    "     \"U\", \"IONQ\",\n",
    "    \"RBLX\",\n",
    "    # ####### Kimi pick\n",
    "    \"ASTS\", \"NET\", \"ANET\", \"CCJ\",\n",
    "]\n",
    "\n",
    "CANDIDATES_TO_PLOT = 100\n",
    "\n",
    "# --- 5. VERIFICATION ---\n",
    "print(\"--- Path Configuration ---\")\n",
    "print(f\"✅ Project Root: {ROOT_DIR}\")\n",
    "print(f\"✅ Data Dir:     {DATA_DIR}\")\n",
    "print(f\"✅ Source Dir:   {SRC_DIR}\")\n",
    "assert all([ROOT_DIR.exists(), DATA_DIR.exists(), SRC_DIR.exists()]), \"A key directory was not found!\"\n",
    "\n",
    "print(\"\\n--- Module Verification ---\")\n",
    "print(f\"✅ Successfully imported 'utils' and 'plotting_utils'.\")\n",
    "\n",
    "print(\"\\n--- Analysis Configuration ---\")\n",
    "print(\"\\n--- Analysis Configuration ---\")\n",
    "print(\"Period Parameters (for calculation):\")\n",
    "pprint.pprint(PERIOD_PARAMS)\n",
    "print(\"\\nMetric Filters (for selection):\")\n",
    "pprint.pprint(METRIC_FILTERS, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load Latest Merged Finviz Data\n",
    "\n",
    "Find and load the single most recent `df_finviz_merged` file. This DataFrame contains supplementary data like `Price` and `ATR/Price %` that will be used to enhance our final analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Step 1: Loading latest consolidated Finviz data ---\")\n",
    "\n",
    "# Find the most recent file matching the pattern\n",
    "# This function is now understood to return List[str] (filenames), not List[Path].\n",
    "latest_finviz_filepaths = utils.get_recent_files(\n",
    "    directory_path=DATA_DIR,\n",
    "    extension='parquet',\n",
    "    prefix=FILE_PREFIX,\n",
    "    contains_pattern=FILE_CONTAINS_PATTERN,\n",
    "    count=1\n",
    ")\n",
    "\n",
    "if not latest_finviz_filepaths:\n",
    "    raise FileNotFoundError(f\"No files found in '{DATA_DIR}' with prefix '{FILE_PREFIX}' and pattern '{FILE_CONTAINS_PATTERN}'\")\n",
    "\n",
    "# Get the filename string from the list\n",
    "latest_filename = latest_finviz_filepaths[0]\n",
    "\n",
    "# Manually construct the full path before loading\n",
    "full_file_path = DATA_DIR / latest_filename\n",
    "df_finviz_latest = pd.read_parquet(full_file_path, engine='pyarrow')\n",
    "\n",
    "\n",
    "# --- Robust Index Setting (this logic remains correct) ---\n",
    "if df_finviz_latest.index.name == 'Ticker':\n",
    "    print(\"Info: 'Ticker' is already the index. No action needed.\")\n",
    "elif 'Ticker' in df_finviz_latest.columns:\n",
    "    print(\"Info: 'Ticker' column found. Setting it as the DataFrame index.\")\n",
    "    df_finviz_latest.set_index('Ticker', inplace=True)\n",
    "elif 'ticker' in df_finviz_latest.columns:\n",
    "    print(\"Info: 'ticker' column found. Renaming and setting as index.\")\n",
    "    df_finviz_latest.rename(columns={'ticker': 'Ticker'}, inplace=True)\n",
    "    df_finviz_latest.set_index('Ticker', inplace=True)\n",
    "elif df_finviz_latest.index.name is None:\n",
    "    print(\"Info: Index is unnamed. Assuming it contains tickers and assigning the name 'Ticker'.\")\n",
    "    df_finviz_latest.index.name = 'Ticker'\n",
    "else:\n",
    "    print(\"ERROR: Loaded DataFrame has an unexpected format.\")\n",
    "    print(f\"Columns: {df_finviz_latest.columns.tolist()}\")\n",
    "    print(f\"Index Name: '{df_finviz_latest.index.name}'\")\n",
    "    raise ValueError(\"Could not find a 'Ticker' column or a usable index to proceed.\")\n",
    "\n",
    "\n",
    "# Correct the print statement to work with the filename string\n",
    "print(f\"✅ Successfully loaded: {latest_filename}\")\n",
    "print(f\"Shape: {df_finviz_latest.shape}\")\n",
    "print(df_finviz_latest.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Build Rank History Matrix\n",
    "\n",
    "Load the last `N` daily data files to construct a comprehensive rank history DataFrame. This matrix is the primary input for all subsequent trend and performance calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"--- Step 2: Building rank history from the latest {HISTORY_FILE_COUNT} files ---\")\n",
    "\n",
    "# Get a list of all recent daily files\n",
    "daily_files_list = utils.get_recent_files(\n",
    "    directory_path=DATA_DIR,\n",
    "    extension='parquet',\n",
    "    prefix=FILE_PREFIX,\n",
    "    contains_pattern=FILE_CONTAINS_PATTERN,\n",
    "    count=HISTORY_FILE_COUNT\n",
    ")\n",
    "\n",
    "# Use the utility function to create the rank history dataframe\n",
    "# Assumes 'create_rank_history_df' is now in utils.py\n",
    "df_rank_history = utils.create_rank_history_df(daily_files_list, DATA_DIR)\n",
    "\n",
    "print(f\"✅ Rank history matrix created successfully.\")\n",
    "print(f\"Shape: {df_rank_history.shape} (Tickers, Days)\")\n",
    "print(f\"Date Range: {df_rank_history.columns.min().strftime('%Y-%m-%d')} to {df_rank_history.columns.max().strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rank_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Print the original shape\n",
    "# df_rank_history.shape returns a tuple (number_of_rows, number_of_columns)\n",
    "print(\"\\nOriginal shape:\", df_rank_history.shape)\n",
    "\n",
    "# 3. Remove all rows with any NaN values\n",
    "# The dropna() method returns a new DataFrame by default\n",
    "df_rank_history_cleaned = df_rank_history.dropna()\n",
    "\n",
    "# 4. Print the new shape and the cleaned DataFrame\n",
    "print(\"\\nDataFrame after removing rows with any NaN values:\")\n",
    "print(df_rank_history_cleaned)\n",
    "\n",
    "print(\"\\nNew shape:\", df_rank_history_cleaned.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Calculate Metrics for All Tickers\n",
    "\n",
    "Process the rank history matrix to compute performance metrics for **every ticker**. This creates a master metrics DataFrame that serves as a single source of truth for all subsequent filtering and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Step 3: Calculating performance metrics for all tickers ---\")\n",
    "\n",
    "# Use the utility function to calculate metrics for every ticker in the history\n",
    "# The arguments are now cleanly passed from the PERIOD_PARAMS dictionary\n",
    "all_metrics_data = utils.calculate_rank_metrics(\n",
    "    df_rank_history,\n",
    "    tickers_list=df_rank_history.index.tolist(),\n",
    "    **PERIOD_PARAMS\n",
    ")\n",
    "\n",
    "# Convert the list of dicts into a DataFrame for easier analysis\n",
    "df_all_tickers_metrics = pd.DataFrame(all_metrics_data)\n",
    "if not df_all_tickers_metrics.empty:\n",
    "    df_all_tickers_metrics.set_index('ticker', inplace=True)\n",
    "    df_all_tickers_metrics.index.name = 'Ticker'\n",
    "\n",
    "print(f\"✅ Calculated metrics for {len(df_all_tickers_metrics)} tickers.\")\n",
    "display(df_all_tickers_metrics.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'PERIOD_PARAMS: {PERIOD_PARAMS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Filter for 'Reversal' Candidates\n",
    "\n",
    "Apply the predefined filtering rules from the configuration cell to the master metrics DataFrame to identify a list of promising candidates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Step 4: Filtering metrics to find candidates ---\")\n",
    "print(\"METRIC_FILTERS\")\n",
    "pprint.pprint(METRIC_FILTERS)\n",
    "\n",
    "# Use the utility function, passing only the relevant filter arguments.\n",
    "# This is now much cleaner than the previous version.\n",
    "df_filtered_candidates = utils.filter_rank_metrics(\n",
    "    df_all_tickers_metrics,\n",
    "    **METRIC_FILTERS\n",
    ")\n",
    "\n",
    "print(f\"✅ Found {len(df_filtered_candidates)} candidates matching the criteria.\")\n",
    "display(df_filtered_candidates.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Enhance, Sort, and Select Top Candidates\n",
    "\n",
    "Enrich the filtered candidates with the latest price data, sort them according to the specified rules, and select the top N for visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Step 5: Enhancing and sorting final candidates ---\")\n",
    "\n",
    "# Join with latest Finviz data to add Price, MktCap, etc.\n",
    "cols_to_add = ['Price', 'Change %', 'MktCap AUM, M', 'ATR/Price %', 'Rel Volume']\n",
    "df_candidates_enhanced = df_filtered_candidates.join(df_finviz_latest[cols_to_add])\n",
    "\n",
    "# --- Calculate New Metrics ---\n",
    "# Create a normalized change metric by dividing the daily change by its recent volatility (ATR).\n",
    "# This gives a sense of how significant the day's move is relative to its own behavior.\n",
    "df_candidates_enhanced['Change/(ATR/Price)'] = np.where(\n",
    "    df_candidates_enhanced['ATR/Price %'] != 0,\n",
    "    df_candidates_enhanced['Change %'] / df_candidates_enhanced['ATR/Price %'],\n",
    "    0  # Assign 0 if ATR/Price % is 0 to avoid division errors\n",
    ")\n",
    "\n",
    "# Sort the candidates based on the rules in the SORT_ORDER dictionary\n",
    "sort_keys = list(SORT_ORDER.keys())\n",
    "sort_ascending = list(SORT_ORDER.values())\n",
    "df_sorted_candidates = df_candidates_enhanced.sort_values(by=sort_keys, ascending=sort_ascending)\n",
    "\n",
    "# --- Define and Apply Final Column Order ---\n",
    "# Define the columns that should always appear first, including our new metric.\n",
    "leading_cols = [\n",
    "    'MktCap AUM, M', 'Price', 'Change %', 'ATR/Price %', 'Change/(ATR/Price)', 'Rel Volume', 'current',\n",
    "]\n",
    "\n",
    "# Combine the leading columns with the sort keys for the master order.\n",
    "priority_cols = list(dict.fromkeys(leading_cols + sort_keys))\n",
    "remaining_cols = [c for c in df_sorted_candidates.columns if c not in priority_cols]\n",
    "final_col_order = priority_cols + remaining_cols\n",
    "df_sorted_candidates = df_sorted_candidates[final_col_order]\n",
    "\n",
    "# --- Select Top Candidates for Plotting ---\n",
    "tickers_to_plot = df_sorted_candidates.head(CANDIDATES_TO_PLOT).index.tolist()\n",
    "\n",
    "# --- Display Final Results with Context ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"      FINAL CANDIDATE REPORT\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nPeriod Parameters (for calculation):\")\n",
    "pprint.pprint(PERIOD_PARAMS)\n",
    "\n",
    "print(\"\\nApplied Metric Filters:\")\n",
    "pprint.pprint(METRIC_FILTERS, sort_dicts=False)\n",
    "\n",
    "print(\"\\nSorting Order:\")\n",
    "pprint.pprint(SORT_ORDER, sort_dicts=False)\n",
    "\n",
    "print(f\"\\nDisplaying Top {CANDIDATES_TO_PLOT} Candidates:\")\n",
    "display(df_sorted_candidates.head(CANDIDATES_TO_PLOT))\n",
    "\n",
    "print(f\"\\nTickers selected for plotting: {tickers_to_plot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'df_finviz_latest.info():\\n{df_finviz_latest.info()}')\n",
    "# print(f'\\ndf_finviz_latest.columns:\\n{df_finviz_latest.columns}')\n",
    "print(f'\\ndf_finviz_latest.columns:\\n{list(df_finviz_latest.columns)}')\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "#     # 'display.max_rows' controls the truncation of the Index/Series representation\n",
    "#     # 'display.max_columns' is good to include for printing the full DataFrame\n",
    "#     print(f'\\ndf_finviz_latest.columns:\\n{df_finviz_latest.columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Sort the DataFrame by the index using the desired order ---\n",
    "# Use .loc with the list of valid, ordered tickers\n",
    "# df_finviz_latest_sorted = df_finviz_latest.loc[valid_tickers_in_order_unique]\n",
    "df_finviz_tickers_to_plot = df_finviz_latest.loc[tickers_to_plot]\n",
    "print(f'df_finviz_tickers_to_plot:\\n{df_finviz_tickers_to_plot}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Visualize Top Candidates\n",
    "\n",
    "Plot the rank history for the top candidates to visually verify their performance and trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Step 6: Plotting rank history for top candidates ---\")\n",
    "\n",
    "if tickers_to_plot:\n",
    "    plot_days = PERIOD_PARAMS['lookback_days'] + PERIOD_PARAMS['recent_days'] + 10\n",
    "    # Combine both dictionaries for complete context in the plot's annotation\n",
    "    full_criteria_for_plot = {**PERIOD_PARAMS, **METRIC_FILTERS}\n",
    "    \n",
    "    plotting_utils.plot_rank_with_criteria(\n",
    "        df_rank_history=df_rank_history.iloc[:, -plot_days:],\n",
    "        ticker_list=tickers_to_plot,\n",
    "        title_suffix=\"Top Filtered Candidates\",\n",
    "        filter_criteria=full_criteria_for_plot, # Pass the combined dict\n",
    "        width=1150,\n",
    "        height=700,\n",
    "    )\n",
    "else:\n",
    "    print(\"No candidates found to plot.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_sorted_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Analyze Pre-defined Portfolio\n",
    "\n",
    "Perform a detailed analysis on a specific list of tickers. This step correctly uses the master `df_all_tickers_metrics` DataFrame to ensure all portfolio tickers are included, regardless of filter outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted_candidates.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Step 7: Analyzing the pre-defined portfolio ---\")\n",
    "\n",
    "# Correctly filter the *master* metrics dataframe for the portfolio tickers\n",
    "df_portfolio_analysis  = df_sorted_candidates[df_sorted_candidates.index.isin(PORTFOLIO_TICKERS)].copy()\n",
    "\n",
    "# Calculate portfolio weights, only if the dataframe is not empty\n",
    "if not df_portfolio_analysis.empty:\n",
    "    total_aum = df_portfolio_analysis['MktCap AUM, M'].sum()\n",
    "    inv_atr = 1 / df_portfolio_analysis['ATR/Price %']\n",
    "    total_inv_atr = inv_atr.sum()\n",
    "\n",
    "    df_portfolio_analysis['MktCap AUM Weight'] = df_portfolio_analysis['MktCap AUM, M'] / total_aum\n",
    "    df_portfolio_analysis['ATR/Price INV Weight'] = (inv_atr / total_inv_atr)\n",
    "\n",
    "    total_portf = df_portfolio_analysis['MktCap AUM Weight'].sum() + df_portfolio_analysis['ATR/Price INV Weight'].sum()\n",
    "    df_portfolio_analysis['Portf Weight'] = (df_portfolio_analysis['MktCap AUM Weight'] + df_portfolio_analysis['ATR/Price INV Weight']) / total_portf\n",
    "\n",
    "    # --- Define and Apply Final Column Order ---\n",
    "    # The new columns to be inserted\n",
    "    new_cols = ['MktCap AUM Weight', 'ATR/Price INV Weight', 'Portf Weight']\n",
    "\n",
    "    # Convert the original column Index to a list for easy manipulation\n",
    "    original_cols = list(df_sorted_candidates.columns)\n",
    "\n",
    "    # Find the index of the column to insert after\n",
    "    try:\n",
    "        # Find the integer position of the 'current' column\n",
    "        insert_index = original_cols.index('current') + 1 \n",
    "    except ValueError:\n",
    "        # Handle the case where 'current' isn't in the columns, perhaps append to the end\n",
    "        print(\"Warning: 'current' column not found. Appending new columns to the end.\")\n",
    "        insert_index = len(original_cols)\n",
    "\n",
    "    # Reconstruct the list with the new columns inserted\n",
    "    PORTFOLIO_COLUMN_ORDER = original_cols[:insert_index] + new_cols + original_cols[insert_index:]\n",
    "\n",
    "    # Filter the desired order to only include columns that actually exist in the DataFrame\n",
    "    # This makes the code robust against missing data columns.\n",
    "    final_portfolio_cols = [c for c in PORTFOLIO_COLUMN_ORDER if c in df_portfolio_analysis.columns]\n",
    "    df_portfolio_analysis = df_portfolio_analysis[final_portfolio_cols]\n",
    "\n",
    "print(f\"✅ Portfolio analysis complete for {len(df_portfolio_analysis)} tickers.\")\n",
    "print(\"Portfolio metrics, sorted by final portfolio weight:\")\n",
    "print(df_portfolio_analysis.sort_values(by='Portf Weight', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Visualize Portfolio\n",
    "\n",
    "Plot the rank history for the tickers in the pre-defined portfolio to compare their recent performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Step 8: Plotting rank history for the portfolio ---\")\n",
    "\n",
    "if PORTFOLIO_TICKERS:\n",
    "    plot_days = PERIOD_PARAMS['lookback_days'] + PERIOD_PARAMS['recent_days'] + 10\n",
    "    # Combine both dictionaries for complete context in the plot's annotation\n",
    "    full_criteria_for_plot = {**PERIOD_PARAMS, **METRIC_FILTERS}\n",
    "    \n",
    "    plotting_utils.plot_rank_with_criteria(\n",
    "        df_rank_history=df_rank_history.iloc[:, -plot_days:],\n",
    "        ticker_list=PORTFOLIO_TICKERS,\n",
    "        title_suffix=\"Pre-defined Portfolio\",\n",
    "        filter_criteria=full_criteria_for_plot, # Pass the combined dict\n",
    "        width=1150,\n",
    "        height=700,\n",
    "    )\n",
    "else:\n",
    "    print(\"Portfolio ticker list is empty. Nothing to plot.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
