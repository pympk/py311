{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b8a0965",
   "metadata": {},
   "source": [
    "### Jupyter Notebook: End-to-End System Sanity Check\n",
    "\n",
    "#### Cell 1: Setup - All Functions and Imports\n",
    "\n",
    "This cell consolidates all the final, verified functions into one place. This notebook is now a self-contained, runnable script for your entire backtesting system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6baff1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All system functions are defined and ready for the sanity check.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "from tqdm.notebook import tqdm # Use notebook-friendly tqdm\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "# --- 1. FEATURE ENGINEERING FUNCTIONS ---\n",
    "def analyze_ticker_trends_log_vectorized(df_group, lookback_days=60):\n",
    "    \"\"\"\n",
    "    Final robust version of vectorized trend analysis.\n",
    "    \"\"\"\n",
    "    df_results = pd.DataFrame(index=df_group.index)\n",
    "    if len(df_group) < lookback_days:\n",
    "        return df_results \n",
    "    \n",
    "    time_index = pd.Series(np.arange(len(df_group)), index=df_group.index)\n",
    "    var_time = np.var(np.arange(lookback_days), ddof=0)\n",
    "    \n",
    "    # --- 1. TREND ANALYSIS ---\n",
    "    trend_cols = {'Adj Open': 'open', 'Adj High': 'high', 'Adj Low': 'low', 'Adj Close': 'close', 'Volume': 'volume'}\n",
    "    \n",
    "    for col_name, simple_name in trend_cols.items():\n",
    "        if col_name in df_group.columns:\n",
    "            series = df_group[col_name].astype(float)\n",
    "            log_series = np.log(series + 1) if col_name == 'Volume' else np.log(series)\n",
    "            \n",
    "            rolling_cov = time_index.rolling(window=lookback_days).cov(log_series, ddof=0)\n",
    "            rolling_var_series = log_series.rolling(window=lookback_days).var(ddof=0)\n",
    "            \n",
    "            df_results[f'{simple_name}_slope'] = rolling_cov / var_time\n",
    "            denominator = (var_time * rolling_var_series) + 1e-9\n",
    "            df_results[f'{simple_name}_r_squared'] = (rolling_cov**2) / denominator\n",
    "\n",
    "    # --- 2. VOLATILITY & PENALTY SCORES ---\n",
    "    if 'Adj Low' in df_group.columns and 'Adj High' in df_group.columns:\n",
    "        yesterday_low = df_group['Adj Low'].shift(1)\n",
    "        worst_case_returns = (df_group['Adj High'] - yesterday_low) / yesterday_low\n",
    "        unified_std_dev = worst_case_returns.rolling(window=lookback_days).std(ddof=0)\n",
    "        df_results['unified_std_dev_returns'] = unified_std_dev\n",
    "        \n",
    "        for name in ['open', 'high', 'low', 'close']:\n",
    "            r_squared_col = f'{name}_r_squared'\n",
    "            if r_squared_col in df_results.columns:\n",
    "                df_results[f'{name}_penalty_score'] = (1 - df_results[r_squared_col]) * (unified_std_dev + 1e-9)\n",
    "\n",
    "    if 'Volume' in df_group.columns:\n",
    "        volume_std_dev = df_group['Volume'].pct_change().rolling(window=lookback_days).std(ddof=0)\n",
    "        df_results['volume_std_dev_returns'] = volume_std_dev\n",
    "        if 'volume_r_squared' in df_results.columns:\n",
    "            df_results['volume_penalty_score'] = (1 - df_results['volume_r_squared']) * (volume_std_dev + 1e-9)\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "def calculate_rolling_z_scores_general(df_group, columns_to_process, rolling_window=20):\n",
    "    \"\"\"\n",
    "    Calculates rolling Z-scores for a list of specified columns.\n",
    "    \n",
    "    CORRECTED: Now properly preserves the index names from the input df_group.\n",
    "    \"\"\"\n",
    "    # --- KEY CHANGE: Initialize an empty DataFrame with the original index ---\n",
    "    # This ensures that even if we return early, the index structure is correct.\n",
    "    df_results = pd.DataFrame(index=df_group.index)\n",
    "    \n",
    "    if df_group.empty or len(df_group) < rolling_window:\n",
    "        # Now returns an empty DataFrame but with the correct index and columns.\n",
    "        for col in columns_to_process:\n",
    "            df_results[f\"z_score_{col}\"] = np.nan\n",
    "        return df_results\n",
    "\n",
    "    data_subset = df_group[columns_to_process]\n",
    "    \n",
    "    rolling_mean = data_subset.rolling(window=rolling_window).mean()\n",
    "    rolling_std = data_subset.rolling(window=rolling_window).std()\n",
    "    \n",
    "    z_scores_df = (data_subset - rolling_mean) / rolling_std\n",
    "    z_scores_df = z_scores_df.replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "    # Use the df_results DataFrame we created to hold the final values.\n",
    "    # This preserves the original index with its names.\n",
    "    df_results = z_scores_df.add_prefix('z_score_')\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "def apply_strategy_rules(features, rules, config):\n",
    "    \"\"\"\n",
    "    Applies a list of filtering rules to a features DataFrame.\n",
    "\n",
    "    Args:\n",
    "        features (pd.DataFrame): The DataFrame containing all calculated features.\n",
    "        rules (list): A list of dictionaries, where each dict defines a filtering rule.\n",
    "        config (dict): The configuration dictionary, used for dynamic thresholds.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: A boolean Series (mask) indicating which rows pass all rules.\n",
    "    \"\"\"\n",
    "    # Start with a mask that is True for all rows. We will progressively filter it.\n",
    "    final_mask = pd.Series(True, index=features.index)\n",
    "    \n",
    "    # Map operator strings to actual Python operator functions for flexibility\n",
    "    op_map = {\n",
    "        '>': operator.gt,\n",
    "        '<': operator.lt,\n",
    "        '>=': operator.ge,\n",
    "        '<=': operator.le,\n",
    "        '==': operator.eq,\n",
    "        '!=': operator.ne\n",
    "    }\n",
    "\n",
    "    for rule in rules:\n",
    "        op_func = op_map[rule['operator']]\n",
    "        \n",
    "        # --- Rule Type 1: Comparing two columns ---\n",
    "        if 'column_A' in rule and 'column_B' in rule:\n",
    "            mask = op_func(features[rule['column_A']], features[rule['column_B']])\n",
    "        \n",
    "        # --- Rule Type 2: Comparing a column to a value ---\n",
    "        elif 'column' in rule:\n",
    "            # Determine the value to compare against\n",
    "            if 'value' in rule:\n",
    "                value = rule['value']\n",
    "            elif 'value_from_config' in rule:\n",
    "                value = config[rule['value_from_config']]\n",
    "            else:\n",
    "                raise ValueError(f\"Rule missing 'value' or 'value_from_config': {rule}\")\n",
    "            \n",
    "            mask = op_func(features[rule['column']], value)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"Invalid rule format: {rule}\")\n",
    "        \n",
    "        # Combine the mask for this rule with the final mask using a logical AND\n",
    "        final_mask &= mask\n",
    "            \n",
    "    return final_mask\n",
    "\n",
    "def precompute_signals(df_ohlcv, config, rules):\n",
    "    \"\"\"\n",
    "    Pre-computes a rich feature set and then applies a dynamic set of rules\n",
    "    to generate the final trading signals.\n",
    "    \"\"\"\n",
    "    print(\"Pre-computing features for this parameter set...\")\n",
    "    \n",
    "    # --- 1. FEATURE GENERATION (No changes here) ---\n",
    "    trends = df_ohlcv.groupby(level='Ticker', group_keys=False).apply(\n",
    "        analyze_ticker_trends_log_vectorized, config['lookback_days']\n",
    "    )\n",
    "    \n",
    "    z_score_columns = ['Adj Open', 'Adj High', 'Adj Low', 'Adj Close', 'Volume']\n",
    "    z_score_columns_exist = [col for col in z_score_columns if col in df_ohlcv.columns]\n",
    "    z_scores = df_ohlcv.groupby(level='Ticker', group_keys=False).apply(\n",
    "        calculate_rolling_z_scores_general, \n",
    "        columns_to_process=z_score_columns_exist,\n",
    "        rolling_window=config['rolling_window']\n",
    "    )\n",
    "    \n",
    "    # --- DEBUG STEP ---\n",
    "    print(\"Columns in 'trends':\", trends.columns.tolist())\n",
    "    print(\"Columns in 'z_scores':\", z_scores.columns.tolist())\n",
    "    # --- END DEBUG ---\n",
    "\n",
    "    features = trends.join(z_scores).dropna()\n",
    "\n",
    "    # --- 2. DYNAMIC FILTERING (KEY CHANGE HERE) ---\n",
    "    print(\"Applying dynamic strategy rules...\")\n",
    "    # Delegate the filtering logic to our new, specialized function\n",
    "    signal_mask = apply_strategy_rules(features, rules, config)\n",
    "    \n",
    "    signals = features[signal_mask]\n",
    "\n",
    "    return signals\n",
    "\n",
    "\n",
    "# --- 2. BACKTESTING LOOP FUNCTIONS ---\n",
    "def handle_exits_for_day(current_date, next_day_date, open_positions, df_ohlcv, config):\n",
    "    \"\"\"\n",
    "    Checks for exits and logs detailed information about the exit trigger.\n",
    "    Corrected version with valid syntax for the if/elif chain.\n",
    "    \"\"\"\n",
    "    closed_trades = []\n",
    "    positions_to_close = []\n",
    "\n",
    "    for ticker, pos in open_positions.items():\n",
    "        try:\n",
    "            current_close_price = df_ohlcv.loc[(ticker, current_date), 'Adj Close']\n",
    "        except KeyError:\n",
    "            continue \n",
    "\n",
    "        exit_reason = None\n",
    "        exit_target_value = None \n",
    "        \n",
    "        # --- SYNTAX FIX: Calculate all threshold values *before* the conditional block ---\n",
    "        profit_target_price = pos['entry_price'] * (1 + config['profit_target'])\n",
    "        stop_loss_price = pos['entry_price'] * (1 - config['stop_loss'])\n",
    "        days_held = (current_date.to_pydatetime().date() - pos['entry_date'].to_pydatetime().date()).days\n",
    "        \n",
    "        # --- Now, check conditions in a contiguous if/elif/elif block ---\n",
    "        if current_close_price >= profit_target_price:\n",
    "            exit_reason = \"Profit Target\"\n",
    "            exit_target_value = profit_target_price \n",
    "\n",
    "        elif current_close_price <= stop_loss_price:\n",
    "            exit_reason = \"Stop-Loss\"\n",
    "            exit_target_value = stop_loss_price \n",
    "\n",
    "        elif days_held >= config['time_hold_days']:\n",
    "            exit_reason = \"Time Hold\"\n",
    "            exit_target_value = days_held \n",
    "\n",
    "        if exit_reason:\n",
    "            try:\n",
    "                exit_price = df_ohlcv.loc[(ticker, next_day_date), 'Adj Low']\n",
    "                trade_return = (exit_price - pos['entry_price']) / pos['entry_price']\n",
    "                \n",
    "                trade_log = {\n",
    "                    'ticker': ticker, \n",
    "                    'entry_date': pos['entry_date'], \n",
    "                    'exit_date': next_day_date,\n",
    "                    'return': trade_return, \n",
    "                    'reason': exit_reason,\n",
    "                    'signal_date': pos['signal_date'],\n",
    "                    'entry_signal_features': pos['signal_features'],\n",
    "                    'entry_price_actual': pos['entry_price'],\n",
    "                    'exit_signal_date': current_date,\n",
    "                    'exit_trigger_price': current_close_price,\n",
    "                    'exit_target_value': exit_target_value,\n",
    "                    'exit_price_actual': exit_price,\n",
    "                }\n",
    "                closed_trades.append(trade_log)\n",
    "                positions_to_close.append(ticker)\n",
    "            except KeyError:\n",
    "                pass\n",
    "                \n",
    "    for ticker in positions_to_close:\n",
    "        del open_positions[ticker]\n",
    "        \n",
    "    return closed_trades, open_positions\n",
    "\n",
    "def handle_entries_for_day(current_date, next_day_date, signals_today, open_positions, df_ohlcv):\n",
    "    \"\"\"\n",
    "    Processes entries and stores signal details in the open_positions dict.\n",
    "    \"\"\"\n",
    "    # --- KEY CHANGE: Loop through the signals DataFrame ---\n",
    "    for ticker, signal_row in signals_today.iterrows():\n",
    "        # The ticker is now in the index of signal_row, so we use its name\n",
    "        ticker_name = ticker[0] \n",
    "        \n",
    "        if ticker_name not in open_positions:\n",
    "            try:\n",
    "                entry_price = df_ohlcv.loc[(ticker_name, next_day_date), 'Adj High']\n",
    "                \n",
    "                # --- LOGGING: Store more info about the entry signal ---\n",
    "                open_positions[ticker_name] = {\n",
    "                    'entry_date': next_day_date,\n",
    "                    'entry_price': entry_price,\n",
    "                    'signal_date': current_date,\n",
    "                    'signal_features': signal_row.to_dict() # Store all features that triggered the signal\n",
    "                }\n",
    "            except KeyError:\n",
    "                pass\n",
    "                \n",
    "    return open_positions\n",
    "\n",
    "def run_backtest(df_ohlcv, config, rules): # <-- Added 'rules' as an argument\n",
    "    \"\"\"\n",
    "    Orchestrates the backtesting process and pre-flight parameter validation \n",
    "    for a single configuration and strategy.   \n",
    "    \"\"\"\n",
    "\n",
    "    # --- NEW: Pre-flight Validation Block ---\n",
    "    # Get the maximum number of data points for any single ticker in the dataset.\n",
    "    max_data_points = df_ohlcv.groupby(level='Ticker').size().max()\n",
    "    \n",
    "    # Check if the required lookback/window periods are larger than the available data.\n",
    "    required_data_points = max(config.get('lookback_days', 0), config.get('rolling_window', 0))\n",
    "    \n",
    "    if required_data_points > max_data_points:\n",
    "        # Raise a clear, informative error and stop execution immediately.\n",
    "        raise ValueError(\n",
    "            f\"Configuration invalid for the provided dataset.\\n\"\n",
    "            f\"Required data points ({required_data_points}) is greater than the \"\n",
    "            f\"maximum available data for any ticker ({max_data_points}).\\n\"\n",
    "            f\"Please reduce 'lookback_days' or 'rolling_window' in your config, \"\n",
    "            f\"or provide a larger dataset.\"\n",
    "        )\n",
    "    # --- End of Validation Block ---\n",
    "\n",
    "    # Pass the rules down to precompute_signals\n",
    "    entry_signals_features = precompute_signals(df_ohlcv, config, rules)\n",
    "    \n",
    "    trades = []\n",
    "    open_positions = {}\n",
    "    \n",
    "    all_dates = df_ohlcv.index.get_level_values('Date').unique().sort_values()\n",
    "    \n",
    "    if not entry_signals_features.empty:\n",
    "        # Avoid starting the loop if there's no data that could possibly generate a signal\n",
    "        start_date = entry_signals_features.index.get_level_values('Date').min()\n",
    "        start_index = all_dates.get_loc(start_date)\n",
    "    else:\n",
    "        start_index = len(all_dates) # No signals, loop will not run\n",
    "\n",
    "    # Use tqdm from the notebook-friendly version for better display\n",
    "    for i in tqdm(range(start_index, len(all_dates) - 1), desc=\"Backtesting\", leave=False):\n",
    "        current_date = all_dates[i]\n",
    "        next_day_date = all_dates[i+1]\n",
    "\n",
    "        closed_trades, open_positions = handle_exits_for_day(\n",
    "            current_date, next_day_date, open_positions, df_ohlcv, config\n",
    "        )\n",
    "        trades.extend(closed_trades)\n",
    "\n",
    "        signals_today = entry_signals_features[\n",
    "            entry_signals_features.index.get_level_values('Date') == current_date\n",
    "        ]\n",
    "        \n",
    "        open_positions = handle_entries_for_day(\n",
    "            current_date, next_day_date, signals_today, open_positions, df_ohlcv\n",
    "        )\n",
    "                \n",
    "    if not trades:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    final_trades_df = pd.DataFrame(trades)\n",
    "    log_columns = [\n",
    "        'ticker', 'signal_date', 'entry_date', 'exit_signal_date', 'exit_date', 'reason',\n",
    "        'return', 'entry_price_actual', 'exit_price_actual', 'exit_trigger_price', \n",
    "        'exit_target_value', 'entry_signal_features'\n",
    "    ]\n",
    "    for col in log_columns:\n",
    "        if col not in final_trades_df.columns:\n",
    "            final_trades_df[col] = None\n",
    "            \n",
    "    return final_trades_df[log_columns]\n",
    "\n",
    "# --- 3. ANALYSIS FUNCTION ---\n",
    "def analyze_performance(trade_results):\n",
    "    \"\"\"\n",
    "    Calculates performance metrics from a DataFrame of trades.\n",
    "    \n",
    "    Returns a dictionary of key metrics.\n",
    "    \"\"\"\n",
    "    if trade_results.empty:\n",
    "        return {'num_trades': 0, 'win_rate': 0, 'avg_return': 0, 'total_return': 0}\n",
    "    \n",
    "    win_rate = (trade_results['return'] > 0).mean()\n",
    "    total_return = (1 + trade_results['return']).prod() - 1\n",
    "    avg_return = trade_results['return'].mean()\n",
    "    \n",
    "    return {\n",
    "        'num_trades': len(trade_results),\n",
    "        'win_rate': win_rate,\n",
    "        'avg_return': avg_return,\n",
    "        'total_return': total_return\n",
    "    }\n",
    "\n",
    "\n",
    "# --- 4. RUN PARAMETERS ---\n",
    "def run_parameter_optimization(df, param_grid, static_params, rules):\n",
    "    \"\"\"\n",
    "    Orchestrates the entire parameter optimization process.\n",
    "    \"\"\"\n",
    "    results_log = []\n",
    "    \n",
    "    keys, values = zip(*param_grid.items())\n",
    "    param_combinations = [dict(zip(keys, v)) for v in product(*values)]\n",
    "\n",
    "    print(f\"Starting optimization for {len(param_combinations)} combinations...\")\n",
    "    \n",
    "    # Use the notebook-friendly tqdm here\n",
    "    for param_set in tqdm(param_combinations, desc=\"Optimization Progress\"):\n",
    "        current_config = {**static_params, **param_set}\n",
    "        \n",
    "        # Pass the rules down to run_backtest\n",
    "        trade_results = run_backtest(df, current_config, rules)\n",
    "        \n",
    "        performance_metrics = analyze_performance(trade_results)\n",
    "        \n",
    "        log_entry = {**param_set, **performance_metrics}\n",
    "        results_log.append(log_entry)\n",
    "        \n",
    "    return pd.DataFrame(results_log)\n",
    "\n",
    "print(\"All system functions are defined and ready for the sanity check.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b645646",
   "metadata": {},
   "source": [
    "#### Cell 2: Test Data, Config, and Strategy Rules\n",
    "\n",
    "We'll use a slightly larger version of our handcrafted data to ensure the backtest has enough history to generate signals. We'll define a simple strategy that we know will trigger a trade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "056c2f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sanity Check Setup ---\n",
      "Config: {'lookback_days': 10, 'rolling_window': 5, 'profit_target': 0.1, 'stop_loss': 0.05, 'time_hold_days': 5, 'r2_thresh': 0.5, 'z_entry_thresh': -0.5}\n",
      "\n",
      "Rules: [{'column': 'low_r_squared', 'operator': '>', 'value_from_config': 'r2_thresh'}, {'column': 'z_score_Adj Low', 'operator': '<', 'value_from_config': 'z_entry_thresh'}]\n",
      "\n",
      "Data for Ticker 'VERIFY':\n",
      "                   Adj Open  Adj High  Adj Low  Adj Close         Volume\n",
      "Ticker Date                                                             \n",
      "VERIFY 2023-01-02      97.5      99.0     97.0         98  100000.000000\n",
      "       2023-01-03      96.5      98.0     96.0         97  102631.578947\n",
      "       2023-01-04      95.5      97.0     95.0         96  105263.157895\n",
      "       2023-01-05      94.5      96.0     94.0         95  107894.736842\n",
      "       2023-01-06      97.5      99.0     97.0         98  110526.315789\n",
      "       2023-01-09      99.5     101.0     99.0        100  113157.894737\n",
      "       2023-01-10     100.5     102.0    100.0        101  115789.473684\n",
      "       2023-01-11     101.5     103.0    101.0        102  118421.052632\n",
      "       2023-01-12     102.5     104.0    102.0        103  121052.631579\n",
      "       2023-01-13     103.5     105.0    103.0        104  123684.210526\n",
      "       2023-01-16     104.5     106.0    104.0        105  126315.789474\n",
      "       2023-01-17     105.5     107.0    105.0        106  128947.368421\n",
      "       2023-01-18     107.5     109.0    107.0        108  131578.947368\n",
      "       2023-01-19     109.5     111.0    109.0        110  134210.526316\n",
      "       2023-01-20     111.5     113.0    111.0        112  136842.105263\n"
     ]
    }
   ],
   "source": [
    "# --- Sanity Check Configuration ---\n",
    "sanity_check_config = {\n",
    "    'lookback_days': 10,\n",
    "    'rolling_window': 5,\n",
    "    'profit_target': 0.10,\n",
    "    'stop_loss': 0.05,\n",
    "    'time_hold_days': 5,\n",
    "    'r2_thresh': 0.5,\n",
    "    'z_entry_thresh': -0.5\n",
    "}\n",
    "\n",
    "# --- Sanity Check Strategy Rules ---\n",
    "# A simple strategy designed to get an entry signal on our test data.\n",
    "sanity_check_rules = [\n",
    "    {'column': 'low_r_squared', 'operator': '>', 'value_from_config': 'r2_thresh'},\n",
    "    {'column': 'z_score_Adj Low', 'operator': '<', 'value_from_config': 'z_entry_thresh'}\n",
    "]\n",
    "\n",
    "# --- Sanity Check Data ---\n",
    "# A predictable story for one ticker over 20 days.\n",
    "dates = pd.to_datetime(pd.date_range(start='2023-01-01', periods=20, freq='B'))\n",
    "# Start with a dip to trigger a low Z-score, then a steady rise, then a drop.\n",
    "price_path = [98, 97, 96, 95, 98, 100, 101, 102, 103, 104, 105, 106, 108, 110, 112, 105, 104, 103, 102, 101]\n",
    "volume_path = np.linspace(100000, 150000, 20)\n",
    "sanity_df = pd.DataFrame({\n",
    "    'Ticker': 'VERIFY', 'Date': dates,\n",
    "    'Adj Open': np.array(price_path) - 0.5,\n",
    "    'Adj High': np.array(price_path) + 1.0,\n",
    "    'Adj Low': np.array(price_path) - 1.0,\n",
    "    'Adj Close': price_path,\n",
    "    'Volume': volume_path\n",
    "}).set_index(['Ticker', 'Date'])\n",
    "\n",
    "print(\"--- Sanity Check Setup ---\")\n",
    "print(\"Config:\", sanity_check_config)\n",
    "print(\"\\nRules:\", sanity_check_rules)\n",
    "print(\"\\nData for Ticker 'VERIFY':\")\n",
    "print(sanity_df.head(15)) # Print more data to see the trend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c688bc",
   "metadata": {},
   "source": [
    "#### Cell 3: Execute the End-to-End Backtest\n",
    "\n",
    "Here, we run the entire system on our small, controlled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adbc7fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running End-to-End Backtest ---\n",
      "Pre-computing features for this parameter set...\n",
      "Columns in 'trends': ['open_slope', 'open_r_squared', 'high_slope', 'high_r_squared', 'low_slope', 'low_r_squared', 'close_slope', 'close_r_squared', 'volume_slope', 'volume_r_squared', 'unified_std_dev_returns', 'open_penalty_score', 'high_penalty_score', 'low_penalty_score', 'close_penalty_score', 'volume_std_dev_returns', 'volume_penalty_score']\n",
      "Columns in 'z_scores': ['z_score_Adj Open', 'z_score_Adj High', 'z_score_Adj Low', 'z_score_Adj Close', 'z_score_Volume']\n",
      "Applying dynamic strategy rules...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Backtest complete. Found 0 trade(s).\n",
      "\n",
      "[WARNING] No trades were generated. The sanity check cannot proceed.\n",
      "This might be okay, but consider adjusting data or rules to ensure a trade is triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "print(\"--- Running End-to-End Backtest ---\")\n",
    "\n",
    "# Run the full backtest function\n",
    "trade_log_df = run_backtest(sanity_df, sanity_check_config, rules=sanity_check_rules)\n",
    "\n",
    "print(f\"\\nBacktest complete. Found {len(trade_log_df)} trade(s).\")\n",
    "\n",
    "# Display the full trade log, transposed for readability\n",
    "if not trade_log_df.empty:\n",
    "    print(\"\\n--- Full Trade Log ---\")\n",
    "    display(trade_log_df.T)\n",
    "else:\n",
    "    print(\"\\n[WARNING] No trades were generated. The sanity check cannot proceed.\")\n",
    "    print(\"This might be okay, but consider adjusting data or rules to ensure a trade is triggered.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06bde03",
   "metadata": {},
   "source": [
    "#### Cell 4: Deep Dive Verification of the First Trade\n",
    "\n",
    "This is the core of the sanity check. We'll programmatically pull all the necessary data points and verify them against the trade log with clear printouts and assertions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e43c88ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SANITY CHECK SKIPPED: No trades were generated to verify. ---\n"
     ]
    }
   ],
   "source": [
    "# --- Select the first trade for a deep dive ---\n",
    "if not trade_log_df.empty:\n",
    "    trade_to_verify = trade_log_df.iloc[0]\n",
    "    \n",
    "    print(\"--- DEEP DIVE VERIFICATION FOR THE FIRST TRADE ---\")\n",
    "    print(f\"Verifying trade for Ticker: {trade_to_verify['ticker']}\\n\")\n",
    "\n",
    "    # --- 1. Verify the Entry Signal ---\n",
    "    print(\"1. VERIFYING ENTRY SIGNAL...\")\n",
    "    signal_date = trade_to_verify['signal_date']\n",
    "    print(f\"   Signal Date: {signal_date.date()}\")\n",
    "    \n",
    "    # Re-generate the full feature set to check the values on the signal date\n",
    "    # (We need a testing version of precompute_signals for this)\n",
    "    features, _ = precompute_signals_for_testing(sanity_df, sanity_check_config, sanity_check_rules)\n",
    "    features_on_signal_date = features.loc[(trade_to_verify['ticker'], signal_date)]\n",
    "    \n",
    "    print(\"   Features on Signal Date:\")\n",
    "    print(features_on_signal_date[['low_r_squared', 'z_score_Adj Low']].to_string())\n",
    "    print(\"\\n   Checking against thresholds:\")\n",
    "    print(f\"   low_r_squared ({features_on_signal_date['low_r_squared']:.4f}) > r2_thresh ({sanity_check_config['r2_thresh']})?\")\n",
    "    assert features_on_signal_date['low_r_squared'] > sanity_check_config['r2_thresh']\n",
    "    \n",
    "    print(f\"   z_score_Adj Low ({features_on_signal_date['z_score_Adj Low']:.4f}) < z_entry_thresh ({sanity_check_config['z_entry_thresh']})?\")\n",
    "    assert features_on_signal_date['z_score_Adj Low'] < sanity_check_config['z_entry_thresh']\n",
    "    print(\"   [SUCCESS] Entry signal is valid.\\n\")\n",
    "\n",
    "    # --- 2. Verify the Entry Price ---\n",
    "    print(\"2. VERIFYING ENTRY PRICE...\")\n",
    "    entry_date = trade_to_verify['entry_date']\n",
    "    actual_entry_price = trade_to_verify['entry_price_actual']\n",
    "    expected_entry_price = sanity_df.loc[(trade_to_verify['ticker'], entry_date), 'Adj High']\n",
    "    print(f\"   Entry Date: {entry_date.date()}\")\n",
    "    print(f\"   Logged Entry Price: {actual_entry_price}\")\n",
    "    print(f\"   Expected Entry Price (High of the day): {expected_entry_price}\")\n",
    "    assert np.isclose(actual_entry_price, expected_entry_price)\n",
    "    print(\"   [SUCCESS] Entry price is correct.\\n\")\n",
    "\n",
    "    # --- 3. Verify the Exit ---\n",
    "    print(\"3. VERIFYING EXIT...\")\n",
    "    exit_signal_date = trade_to_verify['exit_signal_date']\n",
    "    exit_reason = trade_to_verify['reason']\n",
    "    trigger_price = trade_to_verify['exit_trigger_price']\n",
    "    expected_trigger_price = sanity_df.loc[(trade_to_verify['ticker'], exit_signal_date), 'Adj Close']\n",
    "    \n",
    "    print(f\"   Exit Signal Date: {exit_signal_date.date()}\")\n",
    "    print(f\"   Exit Reason: {exit_reason}\")\n",
    "    print(f\"   Logged Trigger Price: {trigger_price}\")\n",
    "    print(f\"   Expected Trigger Price (Close of the day): {expected_trigger_price}\")\n",
    "    assert np.isclose(trigger_price, expected_trigger_price)\n",
    "\n",
    "    # Verify the logic for the specific reason\n",
    "    if exit_reason == 'Stop-Loss':\n",
    "        expected_sl_price = actual_entry_price * (1 - sanity_check_config['stop_loss'])\n",
    "        print(f\"   Checking Stop-Loss: Is trigger ({trigger_price}) <= threshold ({expected_sl_price:.4f})?\")\n",
    "        assert trigger_price <= expected_sl_price\n",
    "    elif exit_reason == 'Profit Target':\n",
    "        expected_pt_price = actual_entry_price * (1 + sanity_check_config['profit_target'])\n",
    "        print(f\"   Checking Profit Target: Is trigger ({trigger_price}) >= threshold ({expected_pt_price:.4f})?\")\n",
    "        assert trigger_price >= expected_pt_price\n",
    "    elif exit_reason == 'Time Hold':\n",
    "        days_held = (exit_signal_date.date() - entry_date.date()).days\n",
    "        print(f\"   Checking Time Hold: Is days held ({days_held}) >= threshold ({sanity_check_config['time_hold_days']})?\")\n",
    "        assert days_held >= sanity_check_config['time_hold_days']\n",
    "        \n",
    "    print(\"   [SUCCESS] Exit signal logic is correct.\\n\")\n",
    "\n",
    "    # --- 4. Verify the Exit Price ---\n",
    "    print(\"4. VERIFYING EXIT PRICE...\")\n",
    "    exit_date = trade_to_verify['exit_date']\n",
    "    actual_exit_price = trade_to_verify['exit_price_actual']\n",
    "    expected_exit_price = sanity_df.loc[(trade_to_verify['ticker'], exit_date), 'Adj Low']\n",
    "    print(f\"   Exit Date: {exit_date.date()}\")\n",
    "    print(f\"   Logged Exit Price: {actual_exit_price}\")\n",
    "    print(f\"   Expected Exit Price (Low of the day): {expected_exit_price}\")\n",
    "    assert np.isclose(actual_exit_price, expected_exit_price)\n",
    "    print(\"   [SUCCESS] Exit price is correct.\\n\")\n",
    "\n",
    "    print(\"--- SANITY CHECK COMPLETE: The entire system is working as expected! ---\")\n",
    "else:\n",
    "    print(\"--- SANITY CHECK SKIPPED: No trades were generated to verify. ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf45499a",
   "metadata": {},
   "source": [
    "### `run_parameter_optimization`:\n",
    "1.  Correctly generate all combinations of parameters from the grid.\n",
    "2.  Call `run_backtest` for each combination.\n",
    "3.  Call `analyze_performance` on the results of each backtest.\n",
    "4.  Combine the parameters and the performance metrics into a final, clean DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5d971c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- FINAL VERIFICATION: Testing run_parameter_optimization ---\n",
      "\n",
      "Test Grid: {'rolling_window': [5, 10], 'lookback_days': [18]}\n",
      "Expected combinations: 2\n",
      "Starting optimization for 2 combinations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computing features for this parameter set...\n",
      "Columns in 'trends': ['open_slope', 'open_r_squared', 'high_slope', 'high_r_squared', 'low_slope', 'low_r_squared', 'close_slope', 'close_r_squared', 'volume_slope', 'volume_r_squared', 'unified_std_dev_returns', 'open_penalty_score', 'high_penalty_score', 'low_penalty_score', 'close_penalty_score', 'volume_std_dev_returns', 'volume_penalty_score']\n",
      "Columns in 'z_scores': ['z_score_Adj Open', 'z_score_Adj High', 'z_score_Adj Low', 'z_score_Adj Close', 'z_score_Volume']\n",
      "Applying dynamic strategy rules...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  50%|█████     | 1/2 [00:00<00:00,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computing features for this parameter set...\n",
      "Columns in 'trends': ['open_slope', 'open_r_squared', 'high_slope', 'high_r_squared', 'low_slope', 'low_r_squared', 'close_slope', 'close_r_squared', 'volume_slope', 'volume_r_squared', 'unified_std_dev_returns', 'open_penalty_score', 'high_penalty_score', 'low_penalty_score', 'close_penalty_score', 'volume_std_dev_returns', 'volume_penalty_score']\n",
      "Columns in 'z_scores': ['z_score_Adj Open', 'z_score_Adj High', 'z_score_Adj Low', 'z_score_Adj Close', 'z_score_Volume']\n",
      "Applying dynamic strategy rules...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress: 100%|██████████| 2/2 [00:00<00:00,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optimization Results DataFrame ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rolling_window</th>\n",
       "      <th>lookback_days</th>\n",
       "      <th>num_trades</th>\n",
       "      <th>win_rate</th>\n",
       "      <th>avg_return</th>\n",
       "      <th>total_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rolling_window  lookback_days  num_trades  win_rate  avg_return  \\\n",
       "0               5             18           0         0           0   \n",
       "1              10             18           0         0           0   \n",
       "\n",
       "   total_return  \n",
       "0             0  \n",
       "1             0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying output...\n",
      "   Checking shape: Does it have 2 rows?\n",
      "   [SUCCESS] DataFrame has the correct number of rows.\n",
      "   Checking columns: Does it contain all expected columns?\n",
      "   [SUCCESS] DataFrame has all the correct columns.\n",
      "   Spot-checking the first result...\n",
      "Pre-computing features for this parameter set...\n",
      "Columns in 'trends': ['open_slope', 'open_r_squared', 'high_slope', 'high_r_squared', 'low_slope', 'low_r_squared', 'close_slope', 'close_r_squared', 'volume_slope', 'volume_r_squared', 'unified_std_dev_returns', 'open_penalty_score', 'high_penalty_score', 'low_penalty_score', 'close_penalty_score', 'volume_std_dev_returns', 'volume_penalty_score']\n",
      "Columns in 'z_scores': ['z_score_Adj Open', 'z_score_Adj High', 'z_score_Adj Low', 'z_score_Adj Close', 'z_score_Volume']\n",
      "Applying dynamic strategy rules...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Manual num_trades: 0, Result from function: 0\n",
      "   [SUCCESS] Spot check passed.\n",
      "\n",
      "--- FULL SYSTEM VERIFIED: The run_parameter_optimization function is working correctly! ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- FINAL VERIFICATION: Testing run_parameter_optimization ---\\n\")\n",
    "\n",
    "# --- 1. ARRANGE: Define a small optimization grid ---\n",
    "sanity_check_grid = {\n",
    "    'rolling_window': [5, 10],   # Two options\n",
    "    'lookback_days': [18]        # Just one option\n",
    "}\n",
    "\n",
    "# The static params are the rest of the config\n",
    "static_params = {\n",
    "    'profit_target': 0.10,\n",
    "    'stop_loss': 0.05,\n",
    "    'time_hold_days': 5,\n",
    "    'r2_thresh': 0.5,\n",
    "    'z_entry_thresh': -0.5\n",
    "}\n",
    "\n",
    "print(\"Test Grid:\", sanity_check_grid)\n",
    "print(\"Expected combinations: 2\")\n",
    "\n",
    "# --- 2. ACT: Run the optimization function ---\n",
    "optimization_results = run_parameter_optimization(\n",
    "    sanity_df, \n",
    "    param_grid=sanity_check_grid,\n",
    "    static_params=static_params,\n",
    "    rules=sanity_check_rules\n",
    ")\n",
    "\n",
    "print(\"\\n--- Optimization Results DataFrame ---\")\n",
    "display(optimization_results)\n",
    "\n",
    "# --- 3. ASSERT: Verify the output ---\n",
    "print(\"\\nVerifying output...\")\n",
    "\n",
    "# Check the shape\n",
    "expected_rows = 2\n",
    "print(f\"   Checking shape: Does it have {expected_rows} rows?\")\n",
    "assert optimization_results.shape[0] == expected_rows, f\"FAIL: Expected {expected_rows} rows, but got {optimization_results.shape[0]}\"\n",
    "print(\"   [SUCCESS] DataFrame has the correct number of rows.\")\n",
    "\n",
    "# Check the columns\n",
    "expected_columns = list(sanity_check_grid.keys()) + ['num_trades', 'win_rate', 'avg_return', 'total_return']\n",
    "print(f\"   Checking columns: Does it contain all expected columns?\")\n",
    "assert all(col in optimization_results.columns for col in expected_columns), \"FAIL: Missing one or more expected columns.\"\n",
    "print(\"   [SUCCESS] DataFrame has all the correct columns.\")\n",
    "\n",
    "# Spot-check the first row's results by running it manually\n",
    "print(f\"   Spot-checking the first result...\")\n",
    "first_row_params = optimization_results.iloc[0]\n",
    "manual_config = {**static_params, **first_row_params}\n",
    "manual_trades = run_backtest(sanity_df, manual_config, sanity_check_rules)\n",
    "manual_performance = analyze_performance(manual_trades)\n",
    "\n",
    "print(f\"   Manual num_trades: {manual_performance['num_trades']}, Result from function: {first_row_params['num_trades']}\")\n",
    "assert manual_performance['num_trades'] == first_row_params['num_trades'], \"FAIL: Spot check for num_trades failed.\"\n",
    "print(\"   [SUCCESS] Spot check passed.\\n\")\n",
    "\n",
    "print(\"--- FULL SYSTEM VERIFIED: The run_parameter_optimization function is working correctly! ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c6f7ed",
   "metadata": {},
   "source": [
    "### *Note: This script requires a `precompute_signals_for_testing` function that returns both `features` and `signals`. You can easily create it by copying `precompute_signals` and changing its return statement.*\n",
    "\n",
    "By running this notebook, you will have a definitive, step-by-step confirmation that all the verified components are integrated correctly and that the system as a whole is executing your strategy precisely as you designed it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
