{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9091fc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, date\n",
    "from IPython.display import display, Markdown\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.width', 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c5c44f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 2115382 entries, ('A', Timestamp('2020-01-02 00:00:00')) to ('ZWS', Timestamp('2025-10-03 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   Adj Open   float64\n",
      " 1   Adj High   float64\n",
      " 2   Adj Low    float64\n",
      " 3   Adj Close  float64\n",
      " 4   Volume     int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 88.9+ MB\n",
      "df_OHLCV.info() :\n",
      "None\n",
      "\n",
      "df_OHLCV.head():\n",
      "                   Adj Open  Adj High  Adj Low  Adj Close   Volume\n",
      "Ticker Date                                                       \n",
      "A      2020-01-02   82.4973   82.9295  81.8250    82.5453  1468677\n",
      "       2020-01-03   81.3160   81.9499  81.1527    81.2200  1164425\n",
      "       2020-01-06   80.6725   81.4600  80.2884    81.4600  2075412\n",
      "       2020-01-07   80.6341   81.8826  80.6149    81.7098  1754187\n",
      "       2020-01-08   82.5549   83.0447  81.8250    82.5165  1923806\n",
      "\n",
      "df_OHLCV.tail():\n",
      "                   Adj Open  Adj High  Adj Low  Adj Close  Volume\n",
      "Ticker Date                                                      \n",
      "ZWS    2025-09-29     46.86     47.00    46.42      46.89  962300\n",
      "       2025-09-30     46.90     47.40    46.77      47.03  609500\n",
      "       2025-10-01     46.72     47.04    46.40      46.80  599400\n",
      "       2025-10-02     46.86     47.17    46.54      46.91  839900\n",
      "       2025-10-03     46.87     47.37    46.62      46.84  780500\n"
     ]
    }
   ],
   "source": [
    "download_path = Path.home() / \"Downloads\"  \n",
    "# OHLCV_file_path = r'c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_clean_stocks_etfs.parquet'\n",
    "OHLCV_file_path = r'c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet'\n",
    "\n",
    "df_OHLCV = pd.read_parquet(OHLCV_file_path, engine='pyarrow')\n",
    "print(f'df_OHLCV.info() :\\n{df_OHLCV.info()}')\n",
    "print(f'\\ndf_OHLCV.head():\\n{df_OHLCV.head()}')\n",
    "print(f'\\ndf_OHLCV.tail():\\n{df_OHLCV.tail()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03407f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_rolling_quality_metrics_obsolete1(df_ohlcv, window=252, min_periods=126):\n",
    "#     \"\"\"\n",
    "#     Calculates rolling quality metrics for OHLCV data to identify tradable tickers.\n",
    "\n",
    "#     This function enriches the input DataFrame with metrics that quantify data\n",
    "#     quality and liquidity over a specified rolling window.\n",
    "\n",
    "#     Args:\n",
    "#         df_ohlcv (pd.DataFrame): DataFrame with a ('Ticker', 'Date') MultiIndex\n",
    "#                                  and columns for OHLCV data.\n",
    "#         window (int): The lookback period in days for the rolling calculations.\n",
    "#                       Defaults to 252 (approx. one trading year).\n",
    "#         min_periods (int): The minimum number of observations in the window required\n",
    "#                            to have a value. Defaults to 126 (approx. half a year).\n",
    "\n",
    "#     Returns:\n",
    "#         pd.DataFrame: A DataFrame with the original ('Ticker', 'Date') MultiIndex\n",
    "#                       containing the calculated rolling quality metrics.\n",
    "#     \"\"\"\n",
    "#     print(f\"--- Calculating Rolling Quality Metrics (Window: {window} days) ---\")\n",
    "#     df = df_ohlcv.copy()\n",
    "\n",
    "#     # === CHANGE #1: ADD ROBUST SORTING MECHANISM ===\n",
    "#     # Ensure data is sorted chronologically for correct rolling/diff calculations.\n",
    "#     # This check is fast and avoids re-sorting if data is already sorted.\n",
    "#     if not df.index.is_monotonic_increasing:\n",
    "#         print(\"ℹ️ Data is not sorted. Sorting index chronologically...\")\n",
    "#         df.sort_index(inplace=True)\n",
    "\n",
    "#     # --- Feature Engineering: Create the base metrics for each day ---\n",
    "#     df['IsStale'] = np.where((df['Volume'] == 0) | (df['Adj High'] == df['Adj Low']), 1, 0)\n",
    "#     df['DollarVolume'] = df['Adj Close'] * df['Volume']\n",
    "#     # group by Ticker to ensure diff is calculated within each stock's timeline\n",
    "#     df['HasSameVolumeAsPrevDay'] = (df.groupby(level='Ticker')['Volume'].diff() == 0).astype(int)\n",
    "\n",
    "#     # === CHANGE #2: REFACTOR CALCULATION FOR EFFICIENCY AND INDEX CORRECTION ===\n",
    "#     # Use a single .agg() call on a rolling groupby object. This is more efficient\n",
    "#     # than three separate calls and correctly handles the index construction.\n",
    "#     grouped_by_ticker = df.groupby(level='Ticker')\n",
    "\n",
    "#     quality_df = grouped_by_ticker.rolling(window=window, min_periods=min_periods).agg(\n",
    "#         RollingStalePct=('IsStale', 'mean'),\n",
    "#         RollingMedianVolume=('DollarVolume', 'median'),\n",
    "#         RollingSameVolCount=('HasSameVolumeAsPrevDay', 'sum')\n",
    "#     )\n",
    "\n",
    "#     # The .agg() operation creates a MultiIndex from the group key ('Ticker') and the\n",
    "#     # original index ('Date'). We drop the outer 'Ticker' level to restore the\n",
    "#     # index to its original ('Ticker', 'Date') format.\n",
    "#     quality_df = quality_df.droplevel(0)\n",
    "\n",
    "#     print(\"✅ Rolling metrics calculation complete.\")\n",
    "#     return quality_df\n",
    "\n",
    "\n",
    "# def calculate_rolling_quality_metrics_obsolete0(df_ohlcv, window=252, min_periods=126):\n",
    "#     print(f\"--- Calculating Rolling Quality Metrics (Window: {window} days) ---\")\n",
    "#     df = df_ohlcv.copy()\n",
    "#     df['IsStale'] = np.where((df['Volume'] == 0) | (df['Adj High'] == df['Adj Low']), 1, 0)\n",
    "#     df['DollarVolume'] = df['Adj Close'] * df['Volume']\n",
    "#     df['HasSameVolumeAsPrevDay'] = (df.groupby(level='Ticker')['Volume'].diff() == 0).astype(int)\n",
    "#     grouped = df.groupby(level='Ticker')\n",
    "#     stale_pct = grouped['IsStale'].rolling(window=window, min_periods=min_periods).mean()\n",
    "#     median_vol = grouped['DollarVolume'].rolling(window=window, min_periods=min_periods).median()\n",
    "#     same_vol_count = grouped['HasSameVolumeAsPrevDay'].rolling(window=window, min_periods=min_periods).sum()\n",
    "#     quality_df = pd.concat([stale_pct, median_vol, same_vol_count], axis=1)\n",
    "#     quality_df.columns = ['RollingStalePct', 'RollingMedianVolume', 'RollingSameVolCount']\n",
    "#     print(\"✅ Rolling metrics calculation complete.\")\n",
    "#     return quality_df\n",
    "\n",
    "\n",
    "# def calculate_rolling_quality_metrics_obsolete3(df_ohlcv, window=252, min_periods=126, debug=False):\n",
    "#     \"\"\"\n",
    "#     Calculates rolling quality metrics for OHLCV data to identify tradable tickers.\n",
    "\n",
    "#     This function enriches the input DataFrame with metrics that quantify data\n",
    "#     quality and liquidity over a specified rolling window.\n",
    "\n",
    "#     Args:\n",
    "#         df_ohlcv (pd.DataFrame): DataFrame with a ('Ticker', 'Date') MultiIndex\n",
    "#                                  and columns for OHLCV data.\n",
    "#         window (int): The lookback period in days for the rolling calculations.\n",
    "#                       Defaults to 252 (approx. one trading year).\n",
    "#         min_periods (int): The minimum number of observations in the window required\n",
    "#                            to have a value. Defaults to 126 (approx. half a year).\n",
    "#         debug (bool): If True, returns a DataFrame with all intermediate\n",
    "#                       calculations. Defaults to False, returning only the\n",
    "#                       final quality metrics.\n",
    "\n",
    "#     Returns:\n",
    "#         pd.DataFrame: A DataFrame containing either the final quality metrics\n",
    "#                       or a full trace of calculations, based on the debug flag.\n",
    "#     \"\"\"\n",
    "#     print(f\"--- Calculating Rolling Quality Metrics (Window: {window} days) ---\")\n",
    "#     df = df_ohlcv.copy()\n",
    "\n",
    "#     if not df.index.is_monotonic_increasing:\n",
    "#         print(\"ℹ️ Data is not sorted. Sorting index chronologically...\")\n",
    "#         df.sort_index(inplace=True)\n",
    "\n",
    "#     # Intermediate calculations\n",
    "#     df['IsStale'] = np.where((df['Volume'] == 0) | (df['Adj High'] == df['Adj Low']), 1, 0)\n",
    "#     df['DollarVolume'] = df['Adj Close'] * df['Volume']\n",
    "#     df['HasSameVolumeAsPrevDay'] = (df.groupby(level='Ticker')['Volume'].diff() == 0).astype(int)\n",
    "\n",
    "#     # Rolling calculations\n",
    "#     grouped = df.groupby(level='Ticker')\n",
    "#     stale_pct = grouped['IsStale'].rolling(window=window, min_periods=min_periods).mean()\n",
    "#     median_vol = grouped['DollarVolume'].rolling(window=window, min_periods=min_periods).median()\n",
    "#     same_vol_count = grouped['HasSameVolumeAsPrevDay'].rolling(window=window, min_periods=min_periods).sum()\n",
    "\n",
    "#     quality_df = pd.concat([stale_pct, median_vol, same_vol_count], axis=1)\n",
    "#     quality_df.columns = ['RollingStalePct', 'RollingMedianVolume', 'RollingSameVolCount']\n",
    "#     quality_df.index = quality_df.index.droplevel(0)\n",
    "\n",
    "#     print(\"✅ Rolling metrics calculation complete.\")\n",
    "    \n",
    "#     # === YOUR PROPOSED LOGIC ===\n",
    "#     if debug:\n",
    "#         # For debugging, return the original data joined with intermediates and final metrics\n",
    "#         print(\"...Debug mode enabled, returning full calculation trace.\")\n",
    "#         full_df = df.join(quality_df)\n",
    "#         return full_df\n",
    "#     else:\n",
    "#         # Default production behavior: return only the final metrics\n",
    "#         return quality_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f65ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- B. DYNAMIC DATA QUALITY FILTER FUNCTIONS ---\n",
    "# FINAL RECOMMENDED VERSION v2\n",
    "def calculate_rolling_quality_metrics(df_ohlcv, window=252, min_periods=126, debug=False):\n",
    "    \"\"\"\n",
    "    Calculates rolling quality metrics for OHLCV data to identify tradable tickers.\n",
    "\n",
    "    This function enriches the input DataFrame with metrics that quantify data\n",
    "    quality and liquidity over a specified rolling window.\n",
    "\n",
    "    Args:\n",
    "        df_ohlcv (pd.DataFrame): DataFrame with a ('Ticker', 'Date') MultiIndex\n",
    "                                 and columns for OHLCV data.\n",
    "        window (int): The lookback period in days for the rolling calculations.\n",
    "                      Defaults to 252 (approx. one trading year).\n",
    "        min_periods (int): The minimum number of observations in the window required\n",
    "                           to have a value. Defaults to 126 (approx. half a year).\n",
    "        debug (bool): If True, returns a DataFrame with all intermediate\n",
    "                      calculations. Defaults to False, returning only the\n",
    "                      final quality metrics.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing either the final quality metrics\n",
    "                      or a full trace of calculations, based on the debug flag.\n",
    "    \"\"\"\n",
    "    print(f\"--- Calculating Rolling Quality Metrics (Window: {window} days) ---\")\n",
    "    df = df_ohlcv.copy()\n",
    "\n",
    "    if not df.index.is_monotonic_increasing:\n",
    "        print(\"ℹ️ Data is not sorted. Sorting index chronologically...\")\n",
    "        df.sort_index(inplace=True)\n",
    "\n",
    "    # --- Intermediate calculations ---\n",
    "    # This calculation is always the same, whether in debug mode or not.\n",
    "    df['IsStale'] = np.where((df['Volume'] == 0) | (df['Adj High'] == df['Adj Low']), 1, 0)\n",
    "    df['DollarVolume'] = df['Adj Close'] * df['Volume']\n",
    "    df['HasSameVolumeAsPrevDay'] = (df.groupby(level='Ticker')['Volume'].diff() == 0).astype(int)\n",
    "    \n",
    "    # === NEW: Add component columns ONLY if in debug mode ===\n",
    "    if debug:\n",
    "        print(\"...Adding debug component columns for 'IsStale'.\")\n",
    "        df['Debug_HasZeroVolume'] = (df['Volume'] == 0).astype(int)\n",
    "        df['Debug_IsHighEqLow'] = (df['Adj High'] == df['Adj Low']).astype(int)\n",
    "    # =========================================================\n",
    "\n",
    "    # --- Rolling calculations ---\n",
    "    grouped = df.groupby(level='Ticker')\n",
    "    stale_pct = grouped['IsStale'].rolling(window=window, min_periods=min_periods).mean()\n",
    "    median_vol = grouped['DollarVolume'].rolling(window=window, min_periods=min_periods).median()\n",
    "    same_vol_count = grouped['HasSameVolumeAsPrevDay'].rolling(window=window, min_periods=min_periods).sum()\n",
    "\n",
    "    quality_df = pd.concat([stale_pct, median_vol, same_vol_count], axis=1)\n",
    "    quality_df.columns = ['RollingStalePct', 'RollingMedianVolume', 'RollingSameVolCount']\n",
    "    quality_df.index = quality_df.index.droplevel(0)\n",
    "\n",
    "    print(\"✅ Rolling metrics calculation complete.\")\n",
    "    \n",
    "    if debug:\n",
    "        # For debugging, return the original data joined with all calculations\n",
    "        print(\"...Debug mode enabled, returning full calculation trace.\")\n",
    "        # The 'df' DataFrame now contains the extra debug columns, which will be included automatically.\n",
    "        full_df = df.join(quality_df)\n",
    "        return full_df\n",
    "    else:\n",
    "        # Default production behavior\n",
    "        return quality_df\n",
    "\n",
    "\n",
    "def get_eligible_universe(quality_metrics_df, filter_date, thresholds):\n",
    "    try:\n",
    "        metrics_on_date = quality_metrics_df.xs(filter_date, level='Date')\n",
    "    except KeyError:\n",
    "        print(f\"Warning: Filter date {filter_date.date()} not found in quality metrics index. Returning all tickers.\")\n",
    "        return quality_metrics_df.index.get_level_values('Ticker').unique().tolist()\n",
    "    mask = (\n",
    "        (metrics_on_date['RollingMedianVolume'] >= thresholds['min_median_dollar_volume']) &\n",
    "        (metrics_on_date['RollingStalePct'] <= thresholds['max_stale_pct']) &\n",
    "        (metrics_on_date['RollingSameVolCount'] <= thresholds['max_same_vol_count'])\n",
    "    )\n",
    "    eligible_tickers = metrics_on_date[mask].index.tolist()\n",
    "    all_tickers = metrics_on_date.index.tolist()\n",
    "    print(f\"Dynamic Filter ({filter_date.date()}): Kept {len(eligible_tickers)} of {len(all_tickers)} tickers.\")\n",
    "    return eligible_tickers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9278e5",
   "metadata": {},
   "source": [
    "### Code to Generate the Test DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba2a8478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating synthetic test DataFrame ---\n",
      "✅ Synthetic test DataFrame created successfully.\n",
      "\n",
      "--- Raw Test Input Data ---\n",
      "                         Adj Open  Adj High  Adj Low  Adj Close  Volume\n",
      "Ticker       Date                                                      \n",
      "GOOD         2024-01-01       100       102       98        100  100000\n",
      "             2024-01-02       101       103       99        101  101000\n",
      "             2024-01-03       102       104      100        102  102000\n",
      "             2024-01-04       103       105      101        103  103000\n",
      "             2024-01-05       104       106      102        104  104000\n",
      "             2024-01-08       105       107      103        105  105000\n",
      "             2024-01-09       106       108      104        106  106000\n",
      "             2024-01-10       107       109      105        107  107000\n",
      "             2024-01-11       108       110      106        108  108000\n",
      "             2024-01-12       109       111      107        109  109000\n",
      "VOL_0        2024-01-01       100       102       98        100  100000\n",
      "             2024-01-02       101       103       99        101  101000\n",
      "             2024-01-03       102       104      100        102  102000\n",
      "             2024-01-04       103       105      101        103       0\n",
      "             2024-01-05       104       106      102        104  104000\n",
      "             2024-01-08       105       107      103        105  105000\n",
      "             2024-01-09       106       108      104        106       0\n",
      "             2024-01-10       107       109      105        107  107000\n",
      "             2024-01-11       108       110      106        108  108000\n",
      "             2024-01-12       109       111      107        109  109000\n",
      "H_EQ_L       2024-01-01       100       102       98        100  100000\n",
      "             2024-01-02       101       103       99        101  101000\n",
      "             2024-01-03       102       104      100        102  102000\n",
      "             2024-01-04       103       105      101        103  103000\n",
      "             2024-01-05       104        50       50        104  104000\n",
      "             2024-01-08       105       107      103        105  105000\n",
      "             2024-01-09       106       108      104        106  106000\n",
      "             2024-01-10       107       109      105        107  107000\n",
      "             2024-01-11       108       110      106        108  108000\n",
      "             2024-01-12       109       111      107        109  109000\n",
      "SAME_VOL     2024-01-01       100       102       98        100  100000\n",
      "             2024-01-02       101       103       99        101  101000\n",
      "             2024-01-03       102       104      100        102  102000\n",
      "             2024-01-04       103       105      101        103  100000\n",
      "             2024-01-05       104       106      102        104  104000\n",
      "             2024-01-08       105       107      103        105  105000\n",
      "             2024-01-09       106       108      104        106  250000\n",
      "             2024-01-10       107       109      105        107  250000\n",
      "             2024-01-11       108       110      106        108  250000\n",
      "             2024-01-12       109       111      107        109  109000\n",
      "MIXED_BAD    2024-01-01       100       102       98        100  100000\n",
      "             2024-01-02       101       103       99        101  101000\n",
      "             2024-01-03       102       104      100        102  102000\n",
      "             2024-01-04       103        60       60        103       0\n",
      "             2024-01-05       104       106      102        104  104000\n",
      "             2024-01-08       105       107      103        105  104000\n",
      "             2024-01-09       106       108      104        106  106000\n",
      "             2024-01-10       107       109      105        107  107000\n",
      "             2024-01-11       108       110      106        108  108000\n",
      "             2024-01-12       109       111      107        109  109000\n",
      "AT_THE_START 2024-01-01       100       102       98        100  100000\n",
      "             2024-01-02       101       103       99        101  101000\n",
      "             2024-01-03       102       104      100        102  102000\n",
      "             2024-01-04       103       105      101        103  103000\n"
     ]
    }
   ],
   "source": [
    "def create_test_dataframe():\n",
    "    \"\"\"\n",
    "    Generates a synthetic DataFrame with specific edge cases to test the\n",
    "    quality metric calculation logic.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with a ('Ticker', 'Date') MultiIndex, ready for testing.\n",
    "    \"\"\"\n",
    "    print(\"--- Creating synthetic test DataFrame ---\")\n",
    "    \n",
    "    # Create a date range for our test data\n",
    "    dates = pd.to_datetime(pd.date_range(start='2024-01-01', periods=10, freq='B')) # 'B' for business day\n",
    "\n",
    "    # Base data dictionary\n",
    "    data = []\n",
    "    tickers = ['GOOD', 'VOL_0', 'H_EQ_L', 'SAME_VOL', 'MIXED_BAD', 'AT_THE_START']\n",
    "\n",
    "    for ticker in tickers:\n",
    "        # Ticker 'AT_THE_START' only has 4 days of data\n",
    "        num_days = 4 if ticker == 'AT_THE_START' else 10\n",
    "        for i in range(num_days):\n",
    "            day_num = i + 1\n",
    "            # Start with a clean, default row\n",
    "            row = {\n",
    "                'Ticker': ticker,\n",
    "                'Date': dates[i],\n",
    "                'Adj Open': 100 + i,\n",
    "                'Adj High': 102 + i,\n",
    "                'Adj Low': 98 + i,\n",
    "                'Adj Close': 100 + i,\n",
    "                'Volume': 100000 + (i * 1000)\n",
    "            }\n",
    "            data.append(row)\n",
    "\n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # --- Now, inject the specific edge cases as per our blueprint ---\n",
    "\n",
    "    # 2. Ticker: VOL_0\n",
    "    df.loc[(df['Ticker'] == 'VOL_0') & (df['Date'] == dates[3]), 'Volume'] = 0 # Day 4\n",
    "    df.loc[(df['Ticker'] == 'VOL_0') & (df['Date'] == dates[6]), 'Volume'] = 0 # Day 7\n",
    "\n",
    "    # 3. Ticker: H_EQ_L\n",
    "    df.loc[(df['Ticker'] == 'H_EQ_L') & (df['Date'] == dates[4]), ['Adj High', 'Adj Low']] = [50.0, 50.0] # Day 5\n",
    "\n",
    "    # 4. Ticker: SAME_VOL\n",
    "    df.loc[(df['Ticker'] == 'SAME_VOL') & (df['Date'] == dates[3]), 'Volume'] = 100000 # Day 4, matches Day 3's vol\n",
    "    df.loc[(df['Ticker'] == 'SAME_VOL') & (df['Date'] == dates[6]), 'Volume'] = 250000 # Day 7\n",
    "    df.loc[(df['Ticker'] == 'SAME_VOL') & (df['Date'] == dates[7]), 'Volume'] = 250000 # Day 8, matches Day 7\n",
    "    df.loc[(df['Ticker'] == 'SAME_VOL') & (df['Date'] == dates[8]), 'Volume'] = 250000 # Day 9, matches Day 8\n",
    "\n",
    "    # 5. Ticker: MIXED_BAD\n",
    "    df.loc[(df['Ticker'] == 'MIXED_BAD') & (df['Date'] == dates[3]), ['Volume', 'Adj High', 'Adj Low']] = [0, 60.0, 60.0] # Day 4\n",
    "    df.loc[(df['Ticker'] == 'MIXED_BAD') & (df['Date'] == dates[5]), 'Volume'] = df.loc[(df['Ticker'] == 'MIXED_BAD') & (df['Date'] == dates[4]), 'Volume'].values[0] # Day 6 vol matches Day 5\n",
    "    \n",
    "    # Set the MultiIndex\n",
    "    df.set_index(['Ticker', 'Date'], inplace=True)\n",
    "    \n",
    "    print(\"✅ Synthetic test DataFrame created successfully.\")\n",
    "    return df\n",
    "\n",
    "# --- How to use this code ---\n",
    "\n",
    "# 1. Generate the test DataFrame\n",
    "test_df_ohlcv = create_test_dataframe()\n",
    "\n",
    "# 2. Display the raw input data to see our setup\n",
    "print(\"\\n--- Raw Test Input Data ---\")\n",
    "print(test_df_ohlcv.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dc62f6",
   "metadata": {},
   "source": [
    "### How to Run the Test Tomorrow\n",
    "\n",
    "When you are ready tomorrow, you will run the `calculate_rolling_quality_metrics` function using this `test_df_ohlcv` as the input. Remember to use the small window parameters we planned on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca8b7bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Calculating Rolling Quality Metrics (Window: 5 days) ---\n",
      "ℹ️ Data is not sorted. Sorting index chronologically...\n",
      "✅ Rolling metrics calculation complete.\n",
      "--- Quality Metrics for 2024-01-12 (Last Day) ---\n",
      "           RollingStalePct  RollingMedianVolume  RollingSameVolCount\n",
      "Ticker                                                              \n",
      "GOOD                   0.0           11449000.0                  0.0\n",
      "H_EQ_L                 0.0           11449000.0                  0.0\n",
      "MIXED_BAD              0.0           11449000.0                  1.0\n",
      "SAME_VOL               0.0           26500000.0                  2.0\n",
      "VOL_0                  0.2           11449000.0                  0.0\n"
     ]
    }
   ],
   "source": [
    "test_quality_df = calculate_rolling_quality_metrics(\n",
    "    df_ohlcv=test_df_ohlcv,\n",
    "    window=5,\n",
    "    min_periods=3,\n",
    "    # debug=True  # <-- The key to our new, improved workflow    \n",
    ")\n",
    "\n",
    "# Let's look at the input for our next function (a snippet from the last day)\n",
    "print(\"--- Quality Metrics for 2024-01-12 (Last Day) ---\")\n",
    "print(test_quality_df.xs('2024-01-12', level='Date'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094bcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_quality_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f51bf3",
   "metadata": {},
   "source": [
    "#### Step 2: Define the Rules (The `thresholds`)\n",
    "\n",
    "Now, we need to create our set of inspection rules. We will choose thresholds specifically designed to include some of our test tickers and exclude others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77f0cb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our inspection rules\n",
    "my_thresholds = {\n",
    "    'min_median_dollar_volume': 10_600_000, # Must have high liquidity\n",
    "    'max_stale_pct': 0.1,                   # Allow very few stale days (max 10%)\n",
    "    'max_same_vol_count': 1                 # Allow at most 1 suspicious volume event\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a037dcd0",
   "metadata": {},
   "source": [
    "#### Step 3: Choose a Date to Inspect (The `filter_date`)\n",
    "\n",
    "The inspector only works on one day at a time. Let's pick a late date in our test series so all the rolling windows are full."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ad7d835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2024-01-12 00:00:00')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The specific day we want to create our universe for\n",
    "my_filter_date = pd.to_datetime('2024-01-12')\n",
    "my_filter_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed548c08",
   "metadata": {},
   "source": [
    "#### Step 4: Run the Inspector (`get_eligible_universe`)\n",
    "\n",
    "With all the inputs ready, we can now call the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c10b3a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic Filter (2024-01-12): Kept 3 of 5 tickers.\n",
      "\n",
      "--- Inspection Results ---\n",
      "Eligible Tickers for 2024-01-12: ['GOOD', 'H_EQ_L', 'MIXED_BAD']\n"
     ]
    }
   ],
   "source": [
    "# Get the list of tickers that pass inspection on our chosen date\n",
    "eligible_tickers = get_eligible_universe(\n",
    "    quality_metrics_df=test_quality_df,\n",
    "    filter_date=my_filter_date,\n",
    "    thresholds=my_thresholds\n",
    ")\n",
    "\n",
    "print(\"\\n--- Inspection Results ---\")\n",
    "print(f\"Eligible Tickers for {my_filter_date.date()}: {eligible_tickers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7fa1402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Full Verification Output ---\n",
      "                         RollingStalePct  RollingMedianVolume  RollingSameVolCount\n",
      "Ticker       Date                                                                 \n",
      "AT_THE_START 2024-01-01              NaN                  NaN                  NaN\n",
      "             2024-01-02              NaN                  NaN                  NaN\n",
      "             2024-01-03             0.00           10201000.0                  0.0\n",
      "             2024-01-04             0.00           10302500.0                  0.0\n",
      "GOOD         2024-01-01              NaN                  NaN                  NaN\n",
      "             2024-01-02              NaN                  NaN                  NaN\n",
      "             2024-01-03             0.00           10201000.0                  0.0\n",
      "             2024-01-04             0.00           10302500.0                  0.0\n",
      "             2024-01-05             0.00           10404000.0                  0.0\n",
      "             2024-01-08             0.00           10609000.0                  0.0\n",
      "             2024-01-09             0.00           10816000.0                  0.0\n",
      "             2024-01-10             0.00           11025000.0                  0.0\n",
      "             2024-01-11             0.00           11236000.0                  0.0\n",
      "             2024-01-12             0.00           11449000.0                  0.0\n",
      "H_EQ_L       2024-01-01              NaN                  NaN                  NaN\n",
      "             2024-01-02              NaN                  NaN                  NaN\n",
      "             2024-01-03             0.00           10201000.0                  0.0\n",
      "             2024-01-04             0.00           10302500.0                  0.0\n",
      "             2024-01-05             0.20           10404000.0                  0.0\n",
      "             2024-01-08             0.20           10609000.0                  0.0\n",
      "             2024-01-09             0.20           10816000.0                  0.0\n",
      "             2024-01-10             0.20           11025000.0                  0.0\n",
      "             2024-01-11             0.20           11236000.0                  0.0\n",
      "             2024-01-12             0.00           11449000.0                  0.0\n",
      "MIXED_BAD    2024-01-01              NaN                  NaN                  NaN\n",
      "             2024-01-02              NaN                  NaN                  NaN\n",
      "             2024-01-03             0.00           10201000.0                  0.0\n",
      "             2024-01-04             0.25           10100500.0                  0.0\n",
      "             2024-01-05             0.20           10201000.0                  0.0\n",
      "             2024-01-08             0.20           10404000.0                  1.0\n",
      "             2024-01-09             0.20           10816000.0                  1.0\n",
      "             2024-01-10             0.20           10920000.0                  1.0\n",
      "             2024-01-11             0.00           11236000.0                  1.0\n",
      "             2024-01-12             0.00           11449000.0                  1.0\n",
      "SAME_VOL     2024-01-01              NaN                  NaN                  NaN\n",
      "             2024-01-02              NaN                  NaN                  NaN\n",
      "             2024-01-03             0.00           10201000.0                  0.0\n",
      "             2024-01-04             0.00           10250500.0                  0.0\n",
      "             2024-01-05             0.00           10300000.0                  0.0\n",
      "             2024-01-08             0.00           10404000.0                  0.0\n",
      "             2024-01-09             0.00           10816000.0                  0.0\n",
      "             2024-01-10             0.00           11025000.0                  1.0\n",
      "             2024-01-11             0.00           26500000.0                  2.0\n",
      "             2024-01-12             0.00           26500000.0                  2.0\n",
      "VOL_0        2024-01-01              NaN                  NaN                  NaN\n",
      "             2024-01-02              NaN                  NaN                  NaN\n",
      "             2024-01-03             0.00           10201000.0                  0.0\n",
      "             2024-01-04             0.25           10100500.0                  0.0\n",
      "             2024-01-05             0.20           10201000.0                  0.0\n",
      "             2024-01-08             0.20           10404000.0                  0.0\n",
      "             2024-01-09             0.40           10404000.0                  0.0\n",
      "             2024-01-10             0.40           10816000.0                  0.0\n",
      "             2024-01-11             0.20           11025000.0                  0.0\n",
      "             2024-01-12             0.20           11449000.0                  0.0\n"
     ]
    }
   ],
   "source": [
    "# You can now print this or save it to a CSV to inspect.\n",
    "print(\"\\n--- Full Verification Output ---\")\n",
    "print(test_quality_df.to_string())\n",
    "\n",
    "# Optional: Save to CSV for easy viewing\n",
    "test_quality_df.to_csv(\"export_csv/full_verification_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe18f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec123aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4189156",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_df = calculate_rolling_quality_metrics(df_ohlcv=df_OHLCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac06ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'quality_df.info() :\\n{quality_df.info()}')\n",
    "print(f'\\nquality_df.head():\\n{quality_df.head()}')\n",
    "print(f'\\nquality_df.tail(50):\\n{quality_df.tail(50)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e931d98",
   "metadata": {},
   "source": [
    "### Verification Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752f4bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_ticker_rolling_quality_metrics_calculations(df_ohlcv, ticker_symbol, window=252, min_periods=126, output_filename=None):\n",
    "    \"\"\"\n",
    "    Isolates a single ticker and runs the quality metric calculations step-by-step,\n",
    "    outputting all intermediate and final results to a CSV for verification.\n",
    "\n",
    "    Args:\n",
    "        df_ohlcv (pd.DataFrame): The original, raw OHLCV DataFrame.\n",
    "        ticker_symbol (str): The symbol of the ticker you want to verify (e.g., 'A').\n",
    "        window (int): The same window size used in the main function.\n",
    "        min_periods (int): The same min_periods value used in the main function.\n",
    "        output_filename (str, optional): The name of the output CSV file. \n",
    "                                         If None, a default name is created.\n",
    "    \"\"\"\n",
    "    print(f\"--- Verifying calculations for ticker: {ticker_symbol} ---\")\n",
    "\n",
    "    # 1. Isolate the data for the single ticker\n",
    "    try:\n",
    "        # Using .loc[ticker_symbol] on the first level of the MultiIndex\n",
    "        ticker_df = df_ohlcv.loc[ticker_symbol].copy()\n",
    "    except KeyError:\n",
    "        print(f\"❌ Error: Ticker '{ticker_symbol}' not found in the DataFrame.\")\n",
    "        return\n",
    "\n",
    "    # 2. Ensure data is sorted chronologically (critical for rolling/diff)\n",
    "    ticker_df.sort_index(inplace=True)\n",
    "    \n",
    "    print(f\"Found {len(ticker_df)} data points for {ticker_symbol}.\")\n",
    "\n",
    "    # 3. Re-create the intermediate calculations (same logic as the main function)\n",
    "    # Since this is for a single ticker, we don't need groupby()\n",
    "    print(\"Step 1: Calculating intermediate values (IsStale, DollarVolume, etc.)...\")\n",
    "    ticker_df['IsStale'] = np.where((ticker_df['Volume'] == 0) | (ticker_df['Adj High'] == ticker_df['Adj Low']), 1, 0)\n",
    "    ticker_df['DollarVolume'] = ticker_df['Adj Close'] * ticker_df['Volume']\n",
    "    ticker_df['HasSameVolumeAsPrevDay'] = (ticker_df['Volume'].diff() == 0).astype(int)\n",
    "\n",
    "    # 4. Re-create the final rolling window calculations\n",
    "    print(f\"Step 2: Calculating rolling metrics (window={window}, min_periods={min_periods})...\")\n",
    "    ticker_df['RollingStalePct'] = ticker_df['IsStale'].rolling(window=window, min_periods=min_periods).mean()\n",
    "    ticker_df['RollingMedianVolume'] = ticker_df['DollarVolume'].rolling(window=window, min_periods=min_periods).median()\n",
    "    ticker_df['RollingSameVolCount'] = ticker_df['HasSameVolumeAsPrevDay'].rolling(window=window, min_periods=min_periods).sum()\n",
    "\n",
    "    # 5. Save the combined DataFrame to a CSV file\n",
    "    if output_filename is None:\n",
    "        output_filename = f\"export_csv/verification_rolling_quality_metrics_{ticker_symbol}.csv\"\n",
    "    \n",
    "    ticker_df.to_csv(output_filename)\n",
    "    \n",
    "    print(f\"✅ Verification complete. All calculations saved to '{output_filename}'\")\n",
    "    \n",
    "    return ticker_df # Optionally return the DataFrame for use in a notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15076bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_df = verify_ticker_rolling_quality_metrics_calculations( df_ohlcv=df_OHLCV, \n",
    "                                                                ticker_symbol='NVDA',\n",
    "                                                                window=252, \n",
    "                                                                min_periods=126, \n",
    "                                                                output_filename=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a87f142",
   "metadata": {},
   "source": [
    "### Step 1: Find Tickers with Triggered Flags\n",
    "\n",
    "This function will do the heavy lifting of calculating the intermediate values across your entire `df_OHLCV` and then reporting which tickers are worth investigating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fae167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tickers_with_flags(df_ohlcv):\n",
    "    \"\"\"\n",
    "    Scans the entire OHLCV DataFrame to find tickers that have at least one\n",
    "    'IsStale' or 'HasSameVolumeAsPrevDay' flag.\n",
    "\n",
    "    Args:\n",
    "        df_ohlcv (pd.DataFrame): The original, raw OHLCV DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing two lists of ticker symbols:\n",
    "              'stale_tickers' and 'same_volume_tickers'.\n",
    "    \"\"\"\n",
    "    print(\"--- Scanning for tickers with data quality flags ---\")\n",
    "    df = df_ohlcv.copy()\n",
    "\n",
    "    # We must sort the data to correctly calculate 'HasSameVolumeAsPrevDay'\n",
    "    if not df.index.is_monotonic_increasing:\n",
    "        df.sort_index(inplace=True)\n",
    "    \n",
    "    # --- Calculate the intermediate values ---\n",
    "    df['IsStale'] = np.where((df['Volume'] == 0) | (df['Adj High'] == df['Adj Low']), 1, 0)\n",
    "    df['HasSameVolumeAsPrevDay'] = (df.groupby(level='Ticker')['Volume'].diff() == 0).astype(int)\n",
    "\n",
    "    # --- Find tickers where the sum of flags is greater than zero ---\n",
    "    print(\"Finding tickers with 'IsStale' flags...\")\n",
    "    stale_counts = df.groupby(level='Ticker')['IsStale'].sum()\n",
    "    stale_tickers = stale_counts[stale_counts > 0].index.tolist()\n",
    "    print(f\"✅ Found {len(stale_tickers)} tickers with at least one stale day.\")\n",
    "\n",
    "    print(\"\\nFinding tickers with 'HasSameVolumeAsPrevDay' flags...\")\n",
    "    same_vol_counts = df.groupby(level='Ticker')['HasSameVolumeAsPrevDay'].sum()\n",
    "    same_volume_tickers = same_vol_counts[same_vol_counts > 0].index.tolist()\n",
    "    print(f\"✅ Found {len(same_volume_tickers)} tickers with at least one day of repeated volume.\")\n",
    "\n",
    "    return {\n",
    "        'stale_tickers': stale_tickers,\n",
    "        'same_volume_tickers': same_volume_tickers\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378e9386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Find the tickers that are worth inspecting.\n",
    "flagged_tickers = find_tickers_with_flags(df_OHLCV)\n",
    "\n",
    "# Step 2: Use these tickers with the verification function.\n",
    "\n",
    "# --- Verify the 'IsStale' calculation ---\n",
    "if flagged_tickers['stale_tickers']:\n",
    "    # Pick the first ticker from the list to check\n",
    "    ticker_to_check_stale = flagged_tickers['stale_tickers'][0]\n",
    "    print(f\"\\n--- Now generating verification file for a STALE ticker: {ticker_to_check_stale} ---\")\n",
    "    verify_ticker_rolling_quality_metrics_calculations(df_ohlcv=df_OHLCV, ticker_symbol=ticker_to_check_stale)\n",
    "else:\n",
    "    print(\"\\nNo tickers with stale data were found to verify.\")\n",
    "\n",
    "\n",
    "# --- Verify the 'HasSameVolumeAsPrevDay' calculation ---\n",
    "if flagged_tickers['same_volume_tickers']:\n",
    "    # Pick the first ticker from this list to check\n",
    "    ticker_to_check_same_vol = flagged_tickers['same_volume_tickers'][0]\n",
    "    print(f\"\\n--- Now generating verification file for a REPEATED VOLUME ticker: {ticker_to_check_same_vol} ---\")\n",
    "    verify_ticker_rolling_quality_metrics_calculations(df_ohlcv=df_OHLCV, ticker_symbol=ticker_to_check_same_vol)\n",
    "else:\n",
    "    print(\"\\nNo tickers with repeated volume were found to verify.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a89d987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0760f0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ticker = 'AAON'\n",
    "display(df_OHLCV.loc[_ticker].head())\n",
    "display(df_OHLCV.loc[_ticker].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c842c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible_tickers = get_eligible_universe(quality_metrics_df=quality_df, filter_date='2020-06-01', thresholds=1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86016412",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'eligible_tickers:\\n{eligible_tickers}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
