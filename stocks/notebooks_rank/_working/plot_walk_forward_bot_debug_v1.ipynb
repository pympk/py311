{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "529c108d",
   "metadata": {},
   "source": [
    "### ADD DEBUG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce038043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime, date\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "import pprint\n",
    "import io\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, date\n",
    "from IPython.display import display, Markdown\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcb7974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- COMPLETE CONTEXT AND TEST SCRIPT (v2 - ALL FUNCTIONS INCLUDED) ---\n",
    "# # This script contains the final refactored code and a self-contained test case.\n",
    "# # Running this single cell will execute the test.\n",
    "\n",
    "\n",
    "\n",
    "# # --- A. HELPER FUNCTIONS (Shared across tools) ---\n",
    "\n",
    "# def calculate_gain(price_series: pd.Series):\n",
    "#     if price_series.dropna().shape[0] < 2: return np.nan\n",
    "#     return (price_series.ffill().iloc[-1] / price_series.bfill().iloc[0]) - 1\n",
    "\n",
    "# def calculate_sharpe(return_series: pd.Series):\n",
    "#     if return_series.dropna().shape[0] < 2: return np.nan\n",
    "#     std_dev = return_series.std()\n",
    "#     if std_dev > 0 and std_dev != np.inf:\n",
    "#         return (return_series.mean() / std_dev) * np.sqrt(252)\n",
    "#     return np.nan\n",
    "\n",
    "# # --- B. THE CORE CALCULATION ENGINE, UPGRADED WITH DEBUG MODE (Headless, No UI) ---\n",
    "\n",
    "# def run_walk_forward_step_original_v0(df_close_full, df_high_full, df_low_full,\n",
    "#                           start_date, calc_period, fwd_period,\n",
    "#                           metric, rank_start, rank_end, benchmark_ticker):\n",
    "#     min_date_available = df_close_full.index.min()\n",
    "#     max_date_available = df_close_full.index.max()\n",
    "#     safe_start_date = max(start_date, min_date_available)\n",
    "#     safe_calc_end_date = min(start_date + calc_period, max_date_available)\n",
    "#     safe_viz_end_date = min(safe_calc_end_date + fwd_period, max_date_available)\n",
    "#     if safe_start_date >= safe_calc_end_date: return {'error': \"Invalid date range.\"}\n",
    "#     calc_close_raw = df_close_full.loc[safe_start_date:safe_calc_end_date]\n",
    "#     calc_close = calc_close_raw.dropna(axis=1, how='all')\n",
    "#     if calc_close.shape[1] == 0 or len(calc_close) < 2: return {'error': \"Not enough data in calc period.\"}\n",
    "\n",
    "#     metric_values = {}\n",
    "#     first_prices = calc_close.bfill().iloc[0]; last_prices = calc_close.ffill().iloc[-1]\n",
    "#     metric_values['Price'] = (last_prices / first_prices).dropna()\n",
    "#     daily_returns = calc_close.bfill().ffill().pct_change()\n",
    "#     mean_returns, std_returns = daily_returns.mean(), daily_returns.std()\n",
    "#     metric_values['Sharpe'] = (mean_returns / std_returns * np.sqrt(252)).fillna(0)\n",
    "#     valid_tickers = calc_close.columns\n",
    "#     calc_high = df_high_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "#     calc_low = df_low_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "#     tr = np.maximum(calc_high - calc_low, abs(calc_high - df_close_full[valid_tickers].shift(1)), abs(calc_low - df_close_full[valid_tickers].shift(1)))\n",
    "#     atr = tr.ewm(alpha=1/14, adjust=False).mean()\n",
    "#     atrp = (atr / calc_close).mean()\n",
    "#     metric_values['Sharpe (ATR)'] = (mean_returns / atrp).fillna(0)\n",
    "    \n",
    "#     sorted_tickers = metric_values[metric].sort_values(ascending=False)\n",
    "#     tickers_to_display = sorted_tickers.index[rank_start-1:rank_end].tolist()\n",
    "#     if not tickers_to_display: return {'error': \"No tickers found for the selected rank.\"}\n",
    "        \n",
    "#     normalized_plot_data = df_close_full[tickers_to_display].loc[safe_start_date:safe_viz_end_date]\n",
    "#     normalized_plot_data = normalized_plot_data.div(normalized_plot_data.bfill().iloc[0])\n",
    "#     actual_calc_end_ts = calc_close.index.max()\n",
    "#     portfolio_series = normalized_plot_data.mean(axis=1)\n",
    "#     portfolio_return_series = portfolio_series.pct_change()\n",
    "#     benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "#     benchmark_return_series = benchmark_price_series.loc[safe_start_date:safe_viz_end_date].bfill().ffill().pct_change() if benchmark_price_series is not None else pd.Series(dtype='float64')\n",
    "\n",
    "#     perf_data = {}\n",
    "#     perf_data['calc_p_gain'] = calculate_gain(portfolio_series.loc[:actual_calc_end_ts])\n",
    "#     perf_data['fwd_p_gain'] = calculate_gain(portfolio_series.loc[actual_calc_end_ts:])\n",
    "#     perf_data['full_p_gain'] = calculate_gain(portfolio_series)\n",
    "#     perf_data['calc_p_sharpe'] = calculate_sharpe(portfolio_return_series.loc[:actual_calc_end_ts])\n",
    "#     perf_data['fwd_p_sharpe'] = calculate_sharpe(portfolio_return_series.loc[actual_calc_end_ts:])\n",
    "#     perf_data['full_p_sharpe'] = calculate_sharpe(portfolio_return_series)\n",
    "#     perf_data['calc_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:actual_calc_end_ts]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['fwd_b_gain'] = calculate_gain(benchmark_price_series.loc[actual_calc_end_ts:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['full_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['calc_b_sharpe'] = calculate_sharpe(benchmark_return_series.loc[:actual_calc_end_ts])\n",
    "#     perf_data['fwd_b_sharpe'] = calculate_sharpe(benchmark_return_series.loc[actual_calc_end_ts:])\n",
    "#     perf_data['full_b_sharpe'] = calculate_sharpe(benchmark_return_series)\n",
    "\n",
    "#     calc_end_prices = calc_close.ffill().iloc[-1]\n",
    "#     fwd_close_slice = df_close_full.loc[actual_calc_end_ts:safe_viz_end_date]\n",
    "#     viz_end_prices = fwd_close_slice.ffill().iloc[-1] if not fwd_close_slice.empty and len(fwd_close_slice) >= 2 else calc_end_prices\n",
    "#     calc_gains = (calc_end_prices / calc_close.bfill().iloc[0]) - 1\n",
    "#     fwd_gains = (viz_end_prices / calc_end_prices) - 1\n",
    "#     results_df = pd.DataFrame({'Rank': range(rank_start, rank_start + len(tickers_to_display)), 'Metric': metric, 'MetricValue': sorted_tickers.loc[tickers_to_display].values, 'CalcPrice': calc_end_prices.loc[tickers_to_display], 'CalcGain': calc_gains.loc[tickers_to_display], 'FwdGain': fwd_gains.loc[tickers_to_display]}, index=pd.Index(tickers_to_display, name='Ticker'))\n",
    "#     if benchmark_price_series is not None and benchmark_ticker in calc_close.columns:\n",
    "#         benchmark_df_row = pd.DataFrame({'Rank': np.nan, 'Metric': metric, 'MetricValue': metric_values[metric].get(benchmark_ticker, np.nan), 'CalcPrice': calc_end_prices[benchmark_ticker], 'CalcGain': calc_gains[benchmark_ticker], 'FwdGain': fwd_gains[benchmark_ticker]}, index=pd.Index([f\"{benchmark_ticker} (BM)\"], name='Ticker'))\n",
    "#         results_df = pd.concat([results_df, benchmark_df_row])\n",
    "    \n",
    "#     return { 'tickers_to_display': tickers_to_display, 'normalized_plot_data': normalized_plot_data, 'portfolio_series': portfolio_series, 'benchmark_price_series': benchmark_price_series, 'performance_data': perf_data, 'results_df': results_df, 'actual_calc_end_ts': actual_calc_end_ts, 'safe_start_date': pd.to_datetime(df_close_full.loc[safe_start_date:safe_viz_end_date].index.min()), 'safe_viz_end_date': pd.to_datetime(df_close_full.loc[safe_start_date:safe_viz_end_date].index.max()), 'error': None }\n",
    "\n",
    "# def run_walk_forward_step(df_close_full, df_high_full, df_low_full,\n",
    "#                           start_date, calc_period, fwd_period,\n",
    "#                           metric, rank_start, rank_end, benchmark_ticker,\n",
    "#                           debug=False):  # <-- New debug argument\n",
    "#     \"\"\"\n",
    "#     Core engine for a single walk-forward step.\n",
    "#     Returns a tuple: (results_dict, debug_data_dict).\n",
    "#     If debug=False, debug_data_dict will be None.\n",
    "#     \"\"\"\n",
    "#     debug_data = {} if debug else None\n",
    "\n",
    "#     # --- Date Range Calculation (unchanged) ---\n",
    "#     min_date_available = df_close_full.index.min()\n",
    "#     max_date_available = df_close_full.index.max()\n",
    "#     safe_start_date = max(start_date, min_date_available)\n",
    "#     safe_calc_end_date = min(start_date + calc_period, max_date_available)\n",
    "#     safe_viz_end_date = min(safe_calc_end_date + fwd_period, max_date_available)\n",
    "#     if safe_start_date >= safe_calc_end_date:\n",
    "#         return ({'error': \"Invalid date range.\"}, None)\n",
    "    \n",
    "#     # --- Metric Calculation (mostly unchanged, but we capture intermediates for debug) ---\n",
    "#     calc_close_raw = df_close_full.loc[safe_start_date:safe_calc_end_date]\n",
    "#     calc_close = calc_close_raw.dropna(axis=1, how='all')\n",
    "#     if calc_close.shape[1] == 0 or len(calc_close) < 2:\n",
    "#         return ({'error': \"Not enough data in calc period.\"}, None)\n",
    "\n",
    "#     # These are the components for our metrics\n",
    "#     first_prices = calc_close.bfill().iloc[0]\n",
    "#     last_prices = calc_close.ffill().iloc[-1]\n",
    "#     daily_returns = calc_close.bfill().ffill().pct_change()\n",
    "#     mean_returns = daily_returns.mean()\n",
    "#     std_returns = daily_returns.std()\n",
    "    \n",
    "#     valid_tickers = calc_close.columns\n",
    "#     calc_high = df_high_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "#     calc_low = df_low_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "#     tr = np.maximum(calc_high - calc_low, abs(calc_high - df_close_full[valid_tickers].shift(1)), abs(calc_low - df_close_full[valid_tickers].shift(1)))\n",
    "#     atr = tr.ewm(alpha=1/14, adjust=False).mean()\n",
    "#     atrp = (atr / calc_close).mean()\n",
    "\n",
    "#     # We still build the main metric_values dict for ranking\n",
    "#     metric_values = {}\n",
    "#     metric_values['Price'] = (last_prices / first_prices).dropna()\n",
    "#     metric_values['Sharpe'] = (mean_returns / std_returns * np.sqrt(252)).fillna(0)\n",
    "#     metric_values['Sharpe (ATR)'] = (mean_returns / atrp).fillna(0)\n",
    "\n",
    "#     # --- START: DEBUG DATA GENERATION ---\n",
    "#     if debug:\n",
    "#         # 1. 'ranking_metrics' DataFrame: The \"Report Card\"\n",
    "#         df_ranking = pd.DataFrame({\n",
    "#             'FirstPrice': first_prices,\n",
    "#             'LastPrice': last_prices,\n",
    "#             'MeanDailyReturn': mean_returns,\n",
    "#             'StdDevDailyReturn': std_returns,\n",
    "#             'MeanATRP': atrp,\n",
    "#             'Metric_Price': metric_values['Price'],\n",
    "#             'Metric_Sharpe': metric_values['Sharpe'],\n",
    "#             'Metric_SharpeATR': metric_values['Sharpe (ATR)']\n",
    "#         })\n",
    "#         df_ranking.index.name = 'Ticker'\n",
    "#         debug_data['ranking_metrics'] = df_ranking.sort_values(f'Metric_{metric}', ascending=False)\n",
    "#     # --- END: DEBUG DATA GENERATION ---\n",
    "\n",
    "#     # --- Portfolio Selection (unchanged) ---\n",
    "#     sorted_tickers = metric_values[metric].sort_values(ascending=False)\n",
    "#     tickers_to_display = sorted_tickers.index[rank_start-1:rank_end].tolist()\n",
    "#     if not tickers_to_display:\n",
    "#         return ({'error': \"No tickers found for the selected rank.\"}, None)\n",
    "\n",
    "#     # --- Performance Calculation (unchanged) ---\n",
    "#     normalized_plot_data = df_close_full[tickers_to_display].loc[safe_start_date:safe_viz_end_date]\n",
    "#     normalized_plot_data = normalized_plot_data.div(normalized_plot_data.bfill().iloc[0])\n",
    "#     actual_calc_end_ts = calc_close.index.max()\n",
    "#     portfolio_series = normalized_plot_data.mean(axis=1)\n",
    "#     portfolio_return_series = portfolio_series.pct_change()\n",
    "#     benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "#     benchmark_return_series = benchmark_price_series.loc[safe_start_date:safe_viz_end_date].bfill().ffill().pct_change() if benchmark_price_series is not None else pd.Series(dtype='float64')\n",
    "\n",
    "#     perf_data = {}\n",
    "#     perf_data['calc_p_gain'] = calculate_gain(portfolio_series.loc[:actual_calc_end_ts])\n",
    "#     # ... (rest of perf_data calculations are unchanged)\n",
    "#     perf_data['fwd_p_gain'] = calculate_gain(portfolio_series.loc[actual_calc_end_ts:])\n",
    "#     perf_data['full_p_gain'] = calculate_gain(portfolio_series)\n",
    "#     perf_data['calc_p_sharpe'] = calculate_sharpe(portfolio_return_series.loc[:actual_calc_end_ts])\n",
    "#     perf_data['fwd_p_sharpe'] = calculate_sharpe(portfolio_return_series.loc[actual_calc_end_ts:])\n",
    "#     perf_data['full_p_sharpe'] = calculate_sharpe(portfolio_return_series)\n",
    "#     perf_data['calc_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:actual_calc_end_ts]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['fwd_b_gain'] = calculate_gain(benchmark_price_series.loc[actual_calc_end_ts:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['full_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['calc_b_sharpe'] = calculate_sharpe(benchmark_return_series.loc[:actual_calc_end_ts])\n",
    "#     perf_data['fwd_b_sharpe'] = calculate_sharpe(benchmark_return_series.loc[actual_calc_end_ts:])\n",
    "#     perf_data['full_b_sharpe'] = calculate_sharpe(benchmark_return_series)\n",
    "\n",
    "\n",
    "#     # --- Results DataFrame (unchanged) ---\n",
    "#     calc_end_prices = calc_close.ffill().iloc[-1]\n",
    "#     fwd_close_slice = df_close_full.loc[actual_calc_end_ts:safe_viz_end_date]\n",
    "#     viz_end_prices = fwd_close_slice.ffill().iloc[-1] if not fwd_close_slice.empty and len(fwd_close_slice) >= 2 else calc_end_prices\n",
    "#     calc_gains = (calc_end_prices / calc_close.bfill().iloc[0]) - 1\n",
    "#     fwd_gains = (viz_end_prices / calc_end_prices) - 1\n",
    "#     results_df = pd.DataFrame({'Rank': range(rank_start, rank_start + len(tickers_to_display)), 'Metric': metric, 'MetricValue': sorted_tickers.loc[tickers_to_display].values, 'CalcPrice': calc_end_prices.loc[tickers_to_display], 'CalcGain': calc_gains.loc[tickers_to_display], 'FwdGain': fwd_gains.loc[tickers_to_display]}, index=pd.Index(tickers_to_display, name='Ticker'))\n",
    "#     if benchmark_price_series is not None and benchmark_ticker in calc_close.columns:\n",
    "#         benchmark_df_row = pd.DataFrame({'Rank': np.nan, 'Metric': metric, 'MetricValue': metric_values[metric].get(benchmark_ticker, np.nan), 'CalcPrice': calc_end_prices[benchmark_ticker], 'CalcGain': calc_gains[benchmark_ticker], 'FwdGain': fwd_gains[benchmark_ticker]}, index=pd.Index([f\"{benchmark_ticker} (BM)\"], name='Ticker'))\n",
    "#         results_df = pd.concat([results_df, benchmark_df_row])\n",
    "\n",
    "#     # --- START: DEBUG DATA GENERATION ---\n",
    "#     if debug:\n",
    "#         # 2. 'portfolio_trace' DataFrame: The \"Daily Journal\"\n",
    "#         df_trace = normalized_plot_data.copy()\n",
    "#         df_trace.columns = [f'Norm_Price_{c}' for c in df_trace.columns]\n",
    "#         df_trace['Norm_Price_Portfolio'] = portfolio_series\n",
    "        \n",
    "#         if benchmark_price_series is not None and not benchmark_price_series.loc[safe_start_date:safe_viz_end_date].dropna().empty:\n",
    "#             norm_bm = benchmark_price_series.loc[safe_start_date:safe_viz_end_date] / benchmark_price_series.loc[safe_start_date:].bfill().iloc[0]\n",
    "#             df_trace[f'Norm_Price_Benchmark_{benchmark_ticker}'] = norm_bm\n",
    "\n",
    "#         # Add daily returns for easy inspection\n",
    "#         for col in df_trace.columns:\n",
    "#             if 'Norm_Price' in col:\n",
    "#                 return_col_name = col.replace('Norm_Price', 'Return')\n",
    "#                 df_trace[return_col_name] = df_trace[col].pct_change()\n",
    "        \n",
    "#         debug_data['portfolio_trace'] = df_trace\n",
    "#     # --- END: DEBUG DATA GENERATION ---\n",
    "\n",
    "#     # --- Final Return Object (packaging results and debug data) ---\n",
    "#     final_results = {\n",
    "#         'tickers_to_display': tickers_to_display,\n",
    "#         'normalized_plot_data': normalized_plot_data,\n",
    "#         'portfolio_series': portfolio_series,\n",
    "#         'benchmark_price_series': benchmark_price_series,\n",
    "#         'performance_data': perf_data,\n",
    "#         'results_df': results_df,\n",
    "#         'actual_calc_end_ts': actual_calc_end_ts,\n",
    "#         'safe_start_date': pd.to_datetime(df_close_full.loc[safe_start_date:safe_viz_end_date].index.min()),\n",
    "#         'safe_viz_end_date': pd.to_datetime(df_close_full.loc[safe_start_date:safe_viz_end_date].index.max()),\n",
    "#         'error': None\n",
    "#     }\n",
    "    \n",
    "#     return (final_results, debug_data) # <-- Return a tuple\n",
    "\n",
    "\n",
    "# # --- C. DYNAMIC DATA QUALITY FILTER FUNCTIONS (get_eligible_universe CORRECTED) ---\n",
    "\n",
    "# def calculate_rolling_quality_metrics(df_ohlcv, window=252, min_periods=126, debug=False):\n",
    "#     \"\"\"\n",
    "#     Calculates rolling quality metrics for OHLCV data to identify tradable tickers.\n",
    "\n",
    "#     This function enriches the input DataFrame with metrics that quantify data\n",
    "#     quality and liquidity over a specified rolling window.\n",
    "\n",
    "#     Args:\n",
    "#         df_ohlcv (pd.DataFrame): DataFrame with a ('Ticker', 'Date') MultiIndex\n",
    "#                                  and columns for OHLCV data.\n",
    "#         window (int): The lookback period in days for the rolling calculations.\n",
    "#                       Defaults to 252 (approx. one trading year).\n",
    "#         min_periods (int): The minimum number of observations in the window required\n",
    "#                            to have a value. Defaults to 126 (approx. half a year).\n",
    "#         debug (bool): If True, returns a DataFrame with all intermediate\n",
    "#                       calculations. Defaults to False, returning only the\n",
    "#                       final quality metrics.\n",
    "\n",
    "#     Returns:\n",
    "#         pd.DataFrame: A DataFrame containing the calculated quality metrics. See the\n",
    "#                       'Metrics Description' section below for column details. If debug is True,\n",
    "#                       the output will also include original and intermediate columns.\n",
    "\n",
    "#     Metrics Description:\n",
    "#         RollingStalePct (float):\n",
    "#             The rolling percentage (0.0 to 1.0) of days considered 'stale' within\n",
    "#             the lookback window. A day is flagged as stale if its trading volume is\n",
    "#             zero OR its high price is equal to its low price. This metric helps\n",
    "#             identify non-trading assets or assets with poor quality data feeds.\n",
    "#             **A lower value is better.**\n",
    "\n",
    "#         RollingMedianVolume (float):\n",
    "#             The rolling median of the daily dollar volume (Adj Close * Volume). The\n",
    "#             median is used to provide a robust measure of typical liquidity that is\n",
    "#             insensitive to single-day volume spikes (outliers). This metric is crucial\n",
    "#             for filtering out illiquid stocks where trades could incur significant\n",
    "#             slippage.\n",
    "#             **A higher value is better.**\n",
    "\n",
    "#         RollingSameVolCount (float):\n",
    "#             A rolling count of the number of times a day's volume was exactly equal\n",
    "#             to the previous day's volume. This is a heuristic for detecting\n",
    "#             potential low-quality data feeds, as this event is statistically rare\n",
    "#             for actively traded assets and may indicate improper forward-filling of\n",
    "#             missing data.\n",
    "#             **A lower value is better.**\n",
    "#     \"\"\"\n",
    "#     print(f\"--- Calculating Rolling Quality Metrics (Window: {window} days) ---\")\n",
    "#     df = df_ohlcv.copy()\n",
    "\n",
    "#     # Improvement 1: Ensure data is sorted for correctness\n",
    "#     if not df.index.is_monotonic_increasing:\n",
    "#         print(\"ℹ️ Data is not sorted. Sorting index chronologically...\")\n",
    "#         df.sort_index(inplace=True)\n",
    "\n",
    "#     # --- Intermediate calculations ---\n",
    "#     # This calculation is always the same, whether in debug mode or not.\n",
    "#     df['IsStale'] = np.where((df['Volume'] == 0) | (df['Adj High'] == df['Adj Low']), 1, 0)\n",
    "#     df['DollarVolume'] = df['Adj Close'] * df['Volume']\n",
    "#     df['HasSameVolumeAsPrevDay'] = (df.groupby(level='Ticker')['Volume'].diff() == 0).astype(int)\n",
    "    \n",
    "#     # === NEW: Add component columns ONLY if in debug mode ===\n",
    "#     if debug:\n",
    "#         print(\"...Adding debug component columns for 'IsStale'.\")\n",
    "#         df['Debug_HasZeroVolume'] = (df['Volume'] == 0).astype(int)\n",
    "#         df['Debug_IsHighEqLow'] = (df['Adj High'] == df['Adj Low']).astype(int)\n",
    "#     # =========================================================\n",
    "\n",
    "#     # --- Rolling calculations ---\n",
    "#     grouped = df.groupby(level='Ticker')\n",
    "#     stale_pct = grouped['IsStale'].rolling(window=window, min_periods=min_periods).mean()\n",
    "#     median_vol = grouped['DollarVolume'].rolling(window=window, min_periods=min_periods).median()\n",
    "#     same_vol_count = grouped['HasSameVolumeAsPrevDay'].rolling(window=window, min_periods=min_periods).sum()\n",
    "\n",
    "#     quality_df = pd.concat([stale_pct, median_vol, same_vol_count], axis=1)\n",
    "#     quality_df.columns = ['RollingStalePct', 'RollingMedianVolume', 'RollingSameVolCount']\n",
    "#     quality_df.index = quality_df.index.droplevel(0)\n",
    "\n",
    "#     print(\"✅ Rolling metrics calculation complete.\")\n",
    "    \n",
    "#     if debug:\n",
    "#         # For debugging, return the original data joined with all calculations\n",
    "#         print(\"...Debug mode enabled, returning full calculation trace.\")\n",
    "#         # The 'df' DataFrame now contains the extra debug columns, which will be included automatically.\n",
    "#         full_df = df.join(quality_df)\n",
    "#         return full_df\n",
    "#     else:\n",
    "#         # Default production behavior\n",
    "#         return quality_df\n",
    "\n",
    "# def get_eligible_universe_original(quality_metrics_df, filter_date, thresholds):\n",
    "#     \"\"\"\n",
    "#     Filters tickers to create an eligible universe for a specific date based on quality metrics.\n",
    "\n",
    "#     Args:\n",
    "#         quality_metrics_df (pd.DataFrame): The output from calculate_rolling_quality_metrics.\n",
    "#         filter_date (pd.Timestamp or str): The specific date to perform the filtering on.\n",
    "#         thresholds (dict): A dictionary with the filtering rules, e.g.,\n",
    "#                            {'min_median_dollar_volume': 1e6, 'max_stale_pct': 0.05, 'max_same_vol_count': 1}.\n",
    "\n",
    "#     Returns:\n",
    "#         list: A list of ticker symbols that are eligible on the filter_date.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         metrics_on_date = quality_metrics_df.xs(pd.to_datetime(filter_date), level='Date')\n",
    "#     except KeyError:\n",
    "#         print(f\"Warning: Filter date {pd.to_datetime(filter_date).date()} not found in quality metrics index. Returning all tickers.\")\n",
    "#         return quality_metrics_df.index.get_level_values('Ticker').unique().tolist()\n",
    "\n",
    "#     mask = (\n",
    "#         (metrics_on_date['RollingMedianVolume'] >= thresholds['min_median_dollar_volume']) &\n",
    "#         (metrics_on_date['RollingStalePct'] <= thresholds['max_stale_pct']) &\n",
    "#         (metrics_on_date['RollingSameVolCount'] <= thresholds['max_same_vol_count'])\n",
    "#     )\n",
    "    \n",
    "#     eligible_tickers = metrics_on_date[mask].index.tolist()\n",
    "#     all_tickers = metrics_on_date.index.tolist()\n",
    "    \n",
    "#     print(f\"Dynamic Filter ({pd.to_datetime(filter_date).date()}): Kept {len(eligible_tickers)} of {len(all_tickers)} tickers.\")\n",
    "#     return eligible_tickers    \n",
    "\n",
    "# def get_eligible_universe(quality_metrics_df, filter_date, thresholds):\n",
    "#     \"\"\"\n",
    "#     Filters tickers to create an eligible universe for a specific date based on quality metrics.\n",
    "#     If the exact filter_date is not available, it uses the most recent previous date.\n",
    "#     This version is compatible with older pandas versions.\n",
    "#     \"\"\"\n",
    "\n",
    "#     filter_date_ts = pd.to_datetime(filter_date)\n",
    "    \n",
    "#     # Get the unique dates available in the index for efficient searching\n",
    "#     # Ensure they are sorted for the logic below to work correctly\n",
    "#     date_index = quality_metrics_df.index.get_level_values('Date').unique().sort_values()\n",
    "\n",
    "#     # Handle edge case where the requested date is before any data exists\n",
    "#     if filter_date_ts < date_index[0]:\n",
    "#         print(f\"Warning: Filter date {filter_date_ts.date()} is before the earliest data point ({date_index[0].date()}). Returning empty universe.\")\n",
    "#         return []\n",
    "\n",
    "#     # --- REVISED LOGIC FOR PANDAS COMPATIBILITY ---\n",
    "#     # Find all dates that are less than or equal to the requested filter date\n",
    "#     valid_prior_dates = date_index[date_index <= filter_date_ts]\n",
    "\n",
    "#     if valid_prior_dates.empty:\n",
    "#         # This case should be rare given the edge case check above, but it's good practice\n",
    "#         print(f\"Warning: No available data found on or before {filter_date_ts.date()}. Returning empty universe.\")\n",
    "#         return []\n",
    "\n",
    "#     # The date to use is the last one in this sorted list (the most recent one)\n",
    "#     actual_date_to_use = valid_prior_dates[-1]\n",
    "#     # --- END OF REVISED LOGIC ---\n",
    "\n",
    "#     # If we had to fall back to a previous date, inform the user\n",
    "#     if actual_date_to_use.date() != filter_date_ts.date():\n",
    "#         print(f\"ℹ️ Info: Filter date {filter_date_ts.date()} not found. Using previous available date {actual_date_to_use.date()}.\")\n",
    "        \n",
    "#     # Now, we are guaranteed to have a valid date to select with .xs()\n",
    "#     metrics_on_date = quality_metrics_df.xs(actual_date_to_use, level='Date')\n",
    "\n",
    "#     mask = (\n",
    "#         (metrics_on_date['RollingMedianVolume'] >= thresholds['min_median_dollar_volume']) &\n",
    "#         (metrics_on_date['RollingStalePct'] <= thresholds['max_stale_pct']) &\n",
    "#         (metrics_on_date['RollingSameVolCount'] <= thresholds['max_same_vol_count'])\n",
    "#     )\n",
    "    \n",
    "#     eligible_tickers = metrics_on_date[mask].index.tolist()\n",
    "#     all_tickers = metrics_on_date.index.tolist()\n",
    "    \n",
    "#     # We use the *original* requested date in the message for clarity.\n",
    "#     print(f\"Dynamic Filter ({filter_date_ts.date()}): Kept {len(eligible_tickers)} of {len(all_tickers)} tickers.\")\n",
    "#     return eligible_tickers\n",
    "\n",
    "\n",
    "\n",
    "# # --- D. THE UI WRAPPER UPGRADED WITH DEBUG MODE ---\n",
    "\n",
    "# def plot_walk_forward_analyzer_original_v0(df_ohlcv, \n",
    "#                                default_start_date=None, default_calc_period='3M', default_fwd_period='1M',\n",
    "#                                default_metric='Sharpe (ATR)', default_rank_start=1, default_rank_end=10,\n",
    "#                                default_benchmark_ticker='VOO'):\n",
    "#     print(\"Initializing Walk-Forward Analyzer...\")\n",
    "#     if not isinstance(df_ohlcv.index, pd.MultiIndex): raise ValueError(\"Input DataFrame must have a (Ticker, Date) MultiIndex.\")\n",
    "#     df_ohlcv = df_ohlcv.sort_index()\n",
    "#     print(\"Pre-processing data (unstacking)...\")\n",
    "#     df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "#     df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "#     df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    \n",
    "#     start_date_picker = widgets.DatePicker(description='Start Date:', value=pd.to_datetime(default_start_date), disabled=False)\n",
    "#     calc_period_options = {'1M': pd.DateOffset(months=1), '3M': pd.DateOffset(months=3), '6M': pd.DateOffset(months=6), '1Y': pd.DateOffset(years=1)}\n",
    "#     fwd_period_options = {'0D': pd.DateOffset(days=0), '1W': pd.DateOffset(weeks=1), '2W': pd.DateOffset(weeks=2), '1M': pd.DateOffset(months=1), '3M': pd.DateOffset(months=3)}\n",
    "#     calc_period_dropdown = widgets.Dropdown(options=calc_period_options.keys(), value=default_calc_period, description='Calc Period:')\n",
    "#     fwd_period_dropdown = widgets.Dropdown(options=fwd_period_options.keys(), value=default_fwd_period, description='Fwd Period:')\n",
    "#     metrics = ['Price', 'Sharpe', 'Sharpe (ATR)']\n",
    "#     metric_dropdown = widgets.Dropdown(options=metrics, value=default_metric, description='Metric:')\n",
    "#     rank_options = [1, 5, 10, 20, 30, 40, 50, 75, 100]\n",
    "#     rank_start_dropdown = widgets.Dropdown(options=rank_options, value=default_rank_start, description='Rank Start:')\n",
    "#     rank_end_dropdown = widgets.Dropdown(options=rank_options, value=default_rank_end, description='Rank End:')\n",
    "#     benchmark_ticker_input = widgets.Text(value=default_benchmark_ticker, description='Benchmark:', placeholder='Enter Ticker')\n",
    "#     update_button = widgets.Button(description=\"Update Chart\", button_style='primary')\n",
    "#     ticker_list_output = widgets.Output()\n",
    "#     results_container = [None]\n",
    "    \n",
    "#     fig = go.FigureWidget()\n",
    "#     max_traces = 50\n",
    "#     for i in range(max_traces): fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name=f'placeholder_{i}', visible=False, showlegend=False))\n",
    "#     fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Benchmark', visible=True, showlegend=True, line=dict(color='black', width=3, dash='dash')))\n",
    "#     fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Group Portfolio', visible=True, showlegend=True, line=dict(color='green', width=3)))\n",
    "\n",
    "#     def update_plot(button_click):\n",
    "#         ticker_list_output.clear_output()\n",
    "#         start_date = pd.to_datetime(start_date_picker.value)\n",
    "#         calc_period = calc_period_options[calc_period_dropdown.value]; fwd_period = fwd_period_options[fwd_period_dropdown.value]\n",
    "#         metric = metric_dropdown.value; rank_start, rank_end = rank_start_dropdown.value, rank_end_dropdown.value\n",
    "#         benchmark_ticker = benchmark_ticker_input.value.strip().upper()\n",
    "#         if rank_start > rank_end:\n",
    "#             with ticker_list_output: print(\"Error: 'Rank Start' must be <= 'Rank End'.\"); return\n",
    "\n",
    "#         results = run_walk_forward_step_original_v0(df_close_full, df_high_full, df_low_full, start_date, calc_period, fwd_period, metric, rank_start, rank_end, benchmark_ticker)\n",
    "        \n",
    "#         if results['error']:\n",
    "#             with ticker_list_output: print(f\"Error: {results['error']}\")\n",
    "#             return\n",
    "            \n",
    "#         with fig.batch_update():\n",
    "#             for i in range(max_traces):\n",
    "#                 trace = fig.data[i]\n",
    "#                 if i < len(results['tickers_to_display']):\n",
    "#                     ticker = results['tickers_to_display'][i]\n",
    "#                     trace.x, trace.y, trace.name = results['normalized_plot_data'].index, results['normalized_plot_data'][ticker], ticker\n",
    "#                     trace.visible, trace.showlegend = True, True\n",
    "#                 else: trace.visible, trace.showlegend = False, False\n",
    "#             benchmark_trace = fig.data[max_traces]\n",
    "#             if results['benchmark_price_series'] is not None and not results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']].dropna().empty:\n",
    "#                 normalized_benchmark = results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']] / results['benchmark_price_series'].loc[results['safe_start_date']:].bfill().iloc[0]\n",
    "#                 benchmark_trace.x, benchmark_trace.y = normalized_benchmark.index, normalized_benchmark\n",
    "#                 benchmark_trace.name = f\"Benchmark ({benchmark_ticker})\"; benchmark_trace.visible = True\n",
    "#             else: benchmark_trace.visible = False\n",
    "#             portfolio_trace = fig.data[max_traces + 1]\n",
    "#             portfolio_trace.x, portfolio_trace.y = results['portfolio_series'].index, results['portfolio_series']\n",
    "#             portfolio_trace.name = 'Group Portfolio'; portfolio_trace.visible = True\n",
    "#             fig.layout.shapes = []; fig.add_shape(type=\"line\", x0=results['actual_calc_end_ts'], y0=0, x1=results['actual_calc_end_ts'], y1=1, xref='x', yref='paper', line=dict(color=\"grey\", width=2, dash=\"dash\"))\n",
    "            \n",
    "#         results_container[0] = results['results_df']\n",
    "        \n",
    "#         with ticker_list_output:\n",
    "#             print(f\"Analyzing from {results['safe_start_date'].date()} to {results['safe_viz_end_date'].date()}.\")\n",
    "#             print(f\"  - Ranking based on performance from {results['safe_start_date'].date()} to {results['actual_calc_end_ts'].date()}.\")\n",
    "#             pprint.pprint(results['tickers_to_display'], width=120, compact=True)\n",
    "            \n",
    "#             p = results['performance_data']\n",
    "#             rows = []\n",
    "#             rows.append({'Metric': 'Group Portfolio Gain', 'Full': p['full_p_gain'], 'Calc': p['calc_p_gain'], 'Fwd': p['fwd_p_gain']})\n",
    "#             if not np.isnan(p['full_b_gain']):\n",
    "#                 rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Gain', 'Full': p['full_b_gain'], 'Calc': p['calc_b_gain'], 'Fwd': p['fwd_b_gain']})\n",
    "#                 rows.append({'Metric': 'Gain Delta (vs Bm)', 'Full': p['full_p_gain'] - p['full_b_gain'], 'Calc': p['calc_p_gain'] - p['calc_b_gain'], 'Fwd': p['fwd_p_gain'] - p['fwd_b_gain']})\n",
    "#             rows.append({'Metric': 'Group Portfolio Sharpe', 'Full': p['full_p_sharpe'], 'Calc': p['calc_p_sharpe'], 'Fwd': p['fwd_p_sharpe']})\n",
    "#             if not np.isnan(p['full_b_sharpe']):\n",
    "#                 rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Sharpe', 'Full': p['full_b_sharpe'], 'Calc': p['calc_b_sharpe'], 'Fwd': p['fwd_b_sharpe']})\n",
    "#                 rows.append({'Metric': 'Sharpe Delta (vs Bm)', 'Full': p['full_p_sharpe'] - p['full_b_sharpe'], 'Calc': p['calc_p_sharpe'] - p['calc_b_sharpe'], 'Fwd': p['fwd_p_sharpe'] - p['fwd_b_sharpe']})\n",
    "#             report_df = pd.DataFrame(rows).set_index('Metric')\n",
    "#             gain_rows = [row for row in report_df.index if 'Gain' in row or 'Delta' in row]\n",
    "#             sharpe_rows = [row for row in report_df.index if 'Sharpe' in row]\n",
    "#             styled_df = report_df.style.format('{:+.2%}', na_rep='N/A', subset=(gain_rows, report_df.columns)).format('{:+.2f}', na_rep='N/A', subset=(sharpe_rows, report_df.columns)).set_properties(**{'text-align': 'right', 'width': '100px'}).set_table_styles([{'selector': 'th.col_heading', 'props': [('text-align', 'right')]}, {'selector': 'th.row_heading', 'props': [('text-align', 'left')]}])\n",
    "#             print(\"\\n--- Strategy Performance Summary ---\")\n",
    "#             display(styled_df)\n",
    "            \n",
    "#     fig.update_layout(title_text='Walk-Forward Performance Analysis', xaxis_title='Date', yaxis_title='Normalized Price (Start = 1)', hovermode='x unified', legend_title_text='Tickers (Ranked)', height=700, margin=dict(t=50))\n",
    "#     fig.add_hline(y=1, line_width=1, line_dash=\"dash\", line_color=\"grey\")\n",
    "#     update_button.on_click(update_plot)\n",
    "#     controls_row1 = widgets.HBox([start_date_picker, calc_period_dropdown, fwd_period_dropdown])\n",
    "#     controls_row2 = widgets.HBox([metric_dropdown, rank_start_dropdown, rank_end_dropdown, benchmark_ticker_input, update_button])\n",
    "#     ui_container = widgets.VBox([controls_row1, controls_row2, ticker_list_output], layout=widgets.Layout(margin='10px 0 20px 0'))\n",
    "#     display(ui_container, fig)\n",
    "#     update_plot(None)\n",
    "#     return results_container\n",
    "\n",
    "# def plot_walk_forward_analyzer_v1(df_ohlcv, \n",
    "#                                default_start_date=None, default_calc_period='3M', default_fwd_period='1M',\n",
    "#                                default_metric='Sharpe (ATR)', default_rank_start=1, default_rank_end=10,\n",
    "#                                default_benchmark_ticker='VOO',\n",
    "#                                # NEW: Add quality thresholds as an argument\n",
    "#                                quality_thresholds={'min_median_dollar_volume': 10_000_000, # $10 million median daily trade volume\n",
    "#                                                    'max_stale_pct': 0.1,                   # Allow 10% stale days (i.e. Volume=0 or High=Low)\n",
    "#                                                    'max_same_vol_count': 1                 # Allow at most 1 suspicious volume event (i.e. same Volume on consecutive day)\n",
    "#                                                   }):\n",
    "    \n",
    "#     print(\"Initializing Walk-Forward Analyzer (with Dynamic Universe Filtering)...\")\n",
    "#     if not isinstance(df_ohlcv.index, pd.MultiIndex): raise ValueError(\"Input DataFrame must have a (Ticker, Date) MultiIndex.\")\n",
    "#     df_ohlcv = df_ohlcv.sort_index()\n",
    "    \n",
    "#     # --- MODIFICATION 1: PRE-CALCULATE QUALITY METRICS (Mirrors the bot) ---\n",
    "#     print(\"Pre-calculating data quality metrics...\")\n",
    "#     quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "#     # --------------------------------------------------------------------\n",
    "    \n",
    "#     print(\"Pre-processing data (unstacking)...\")\n",
    "#     df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "#     df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "#     df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    \n",
    "#     start_date_picker = widgets.DatePicker(description='Start Date:', value=pd.to_datetime(default_start_date), disabled=False)\n",
    "#     calc_period_options = {'1M': pd.DateOffset(months=1), '3M': pd.DateOffset(months=3), '6M': pd.DateOffset(months=6), '1Y': pd.DateOffset(years=1)}\n",
    "#     fwd_period_options = {'0D': pd.DateOffset(days=0), '1W': pd.DateOffset(weeks=1), '2W': pd.DateOffset(weeks=2), '1M': pd.DateOffset(months=1), '3M': pd.DateOffset(months=3)}\n",
    "#     calc_period_dropdown = widgets.Dropdown(options=calc_period_options.keys(), value=default_calc_period, description='Calc Period:')\n",
    "#     fwd_period_dropdown = widgets.Dropdown(options=fwd_period_options.keys(), value=default_fwd_period, description='Fwd Period:')\n",
    "#     metrics = ['Price', 'Sharpe', 'Sharpe (ATR)']\n",
    "#     metric_dropdown = widgets.Dropdown(options=metrics, value=default_metric, description='Metric:')\n",
    "#     rank_options = [1, 5, 10, 20, 30, 40, 50, 75, 100]\n",
    "#     rank_start_dropdown = widgets.Dropdown(options=rank_options, value=default_rank_start, description='Rank Start:')\n",
    "#     rank_end_dropdown = widgets.Dropdown(options=rank_options, value=default_rank_end, description='Rank End:')\n",
    "#     benchmark_ticker_input = widgets.Text(value=default_benchmark_ticker, description='Benchmark:', placeholder='Enter Ticker')\n",
    "#     update_button = widgets.Button(description=\"Update Chart\", button_style='primary')\n",
    "#     ticker_list_output = widgets.Output()\n",
    "#     results_container = [None]\n",
    "    \n",
    "#     fig = go.FigureWidget()\n",
    "#     max_traces = 50\n",
    "#     for i in range(max_traces): fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name=f'placeholder_{i}', visible=False, showlegend=False))\n",
    "#     fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Benchmark', visible=True, showlegend=True, line=dict(color='black', width=3, dash='dash')))\n",
    "#     fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Group Portfolio', visible=True, showlegend=True, line=dict(color='green', width=3)))\n",
    "\n",
    "#     def update_plot(button_click):\n",
    "#         ticker_list_output.clear_output()\n",
    "#         start_date = pd.to_datetime(start_date_picker.value)\n",
    "#         calc_period = calc_period_options[calc_period_dropdown.value]; fwd_period = fwd_period_options[fwd_period_dropdown.value]\n",
    "#         metric = metric_dropdown.value; rank_start, rank_end = rank_start_dropdown.value, rank_end_dropdown.value\n",
    "#         benchmark_ticker = benchmark_ticker_input.value.strip().upper()\n",
    "#         if rank_start > rank_end:\n",
    "#             with ticker_list_output: print(\"Error: 'Rank Start' must be <= 'Rank End'.\"); return\n",
    "\n",
    "#         # --- MODIFICATION 2: DYNAMIC UNIVERSE SELECTION (Mirrors the bot) ---\n",
    "#         eligible_tickers = get_eligible_universe(\n",
    "#             quality_metrics_df,\n",
    "#             filter_date=start_date,\n",
    "#             thresholds=quality_thresholds # Use the new argument\n",
    "#         )\n",
    "\n",
    "#         if not eligible_tickers:\n",
    "#             with ticker_list_output: print(f\"Error: No eligible tickers found on {start_date.date()} with the current quality filters.\")\n",
    "#             return\n",
    "            \n",
    "#         # Filter the main dataframes to only include eligible tickers for this run\n",
    "#         df_close_step = df_close_full[eligible_tickers]\n",
    "#         df_high_step = df_high_full[eligible_tickers]\n",
    "#         df_low_step = df_low_full[eligible_tickers]\n",
    "#         # ---------------------------------------------------------------------\n",
    "\n",
    "#         # --- MODIFICATION 3: PASS THE FILTERED DATA (Mirrors the bot) ---\n",
    "#         results = run_walk_forward_step_original_v0(\n",
    "#             df_close_step, df_high_step, df_low_step, # Use the filtered dataframes\n",
    "#             start_date, calc_period, fwd_period, \n",
    "#             metric, rank_start, rank_end, benchmark_ticker\n",
    "#         )\n",
    "#         # ---------------------------------------------------------------------\n",
    "        \n",
    "#         if results['error']:\n",
    "#             with ticker_list_output: print(f\"Error: {results['error']}\")\n",
    "#             return\n",
    "            \n",
    "#         with fig.batch_update():\n",
    "#             for i in range(max_traces):\n",
    "#                 trace = fig.data[i]\n",
    "#                 if i < len(results['tickers_to_display']):\n",
    "#                     ticker = results['tickers_to_display'][i]\n",
    "#                     # IMPORTANT: Plotting uses the original full dataframe to show the price history\n",
    "#                     # even if the ticker wasn't in the universe for the whole period.\n",
    "#                     plot_data_series = df_close_full[ticker].loc[results['safe_start_date']:results['safe_viz_end_date']]\n",
    "#                     normalized_series = plot_data_series / plot_data_series.bfill().iloc[0]\n",
    "#                     trace.x, trace.y, trace.name = normalized_series.index, normalized_series.values, ticker\n",
    "#                     trace.visible, trace.showlegend = True, True\n",
    "#                 else: trace.visible, trace.showlegend = False, False\n",
    "            \n",
    "#             benchmark_trace = fig.data[max_traces]\n",
    "#             if results['benchmark_price_series'] is not None and not results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']].dropna().empty:\n",
    "#                 normalized_benchmark = results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']] / results['benchmark_price_series'].loc[results['safe_start_date']:].bfill().iloc[0]\n",
    "#                 benchmark_trace.x, benchmark_trace.y = normalized_benchmark.index, normalized_benchmark\n",
    "#                 benchmark_trace.name = f\"Benchmark ({benchmark_ticker})\"; benchmark_trace.visible = True\n",
    "#             else: benchmark_trace.visible = False\n",
    "            \n",
    "#             portfolio_trace = fig.data[max_traces + 1]\n",
    "#             portfolio_trace.x, portfolio_trace.y = results['portfolio_series'].index, results['portfolio_series']\n",
    "#             portfolio_trace.name = 'Group Portfolio'; portfolio_trace.visible = True\n",
    "            \n",
    "#             fig.layout.shapes = []; fig.add_shape(type=\"line\", x0=results['actual_calc_end_ts'], y0=0, x1=results['actual_calc_end_ts'], y1=1, xref='x', yref='paper', line=dict(color=\"grey\", width=2, dash=\"dash\"))\n",
    "            \n",
    "#         results_container[0] = results['results_df']\n",
    "        \n",
    "#         with ticker_list_output:\n",
    "#             # (The rest of the display logic is unchanged)\n",
    "#             print(f\"Analyzing from {results['safe_start_date'].date()} to {results['safe_viz_end_date'].date()}.\")\n",
    "#             print(f\"  - Ranking based on performance from {results['safe_start_date'].date()} to {results['actual_calc_end_ts'].date()}.\")\n",
    "#             pprint.pprint(results['tickers_to_display'], width=120, compact=True)\n",
    "            \n",
    "#             p = results['performance_data']\n",
    "#             rows = []\n",
    "#             rows.append({'Metric': 'Group Portfolio Gain', 'Full': p['full_p_gain'], 'Calc': p['calc_p_gain'], 'Fwd': p['fwd_p_gain']})\n",
    "#             if not np.isnan(p['full_b_gain']):\n",
    "#                 rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Gain', 'Full': p['full_b_gain'], 'Calc': p['calc_b_gain'], 'Fwd': p['fwd_b_gain']})\n",
    "#                 rows.append({'Metric': 'Gain Delta (vs Bm)', 'Full': p['full_p_gain'] - p['full_b_gain'], 'Calc': p['calc_p_gain'] - p['calc_b_gain'], 'Fwd': p['fwd_p_gain'] - p['fwd_b_gain']})\n",
    "#             rows.append({'Metric': 'Group Portfolio Sharpe', 'Full': p['full_p_sharpe'], 'Calc': p['calc_p_sharpe'], 'Fwd': p['fwd_p_sharpe']})\n",
    "#             if not np.isnan(p['full_b_sharpe']):\n",
    "#                 rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Sharpe', 'Full': p['full_b_sharpe'], 'Calc': p['calc_b_sharpe'], 'Fwd': p['fwd_b_sharpe']})\n",
    "#                 rows.append({'Metric': 'Sharpe Delta (vs Bm)', 'Full': p['full_p_sharpe'] - p['full_b_sharpe'], 'Calc': p['calc_p_sharpe'] - p['calc_b_sharpe'], 'Fwd': p['fwd_p_sharpe'] - p['fwd_b_sharpe']})\n",
    "#             report_df = pd.DataFrame(rows).set_index('Metric')\n",
    "#             gain_rows = [row for row in report_df.index if 'Gain' in row or 'Delta' in row]\n",
    "#             sharpe_rows = [row for row in report_df.index if 'Sharpe' in row]\n",
    "#             styled_df = report_df.style.format('{:+.2%}', na_rep='N/A', subset=(gain_rows, report_df.columns)).format('{:+.2f}', na_rep='N/A', subset=(sharpe_rows, report_df.columns)).set_properties(**{'text-align': 'right', 'width': '100px'}).set_table_styles([{'selector': 'th.col_heading', 'props': [('text-align', 'right')]}, {'selector': 'th.row_heading', 'props': [('text-align', 'left')]}])\n",
    "#             print(\"\\n--- Strategy Performance Summary ---\")\n",
    "#             display(styled_df)\n",
    "            \n",
    "#     fig.update_layout(title_text='Walk-Forward Performance Analysis', xaxis_title='Date', yaxis_title='Normalized Price (Start = 1)', hovermode='x unified', legend_title_text='Tickers (Ranked)', height=700, margin=dict(t=50))\n",
    "#     fig.add_hline(y=1, line_width=1, line_dash=\"dash\", line_color=\"grey\")\n",
    "#     update_button.on_click(update_plot)\n",
    "#     controls_row1 = widgets.HBox([start_date_picker, calc_period_dropdown, fwd_period_dropdown])\n",
    "#     controls_row2 = widgets.HBox([metric_dropdown, rank_start_dropdown, rank_end_dropdown, benchmark_ticker_input, update_button])\n",
    "#     ui_container = widgets.VBox([controls_row1, controls_row2, ticker_list_output], layout=widgets.Layout(margin='10px 0 20px 0'))\n",
    "#     display(ui_container, fig)\n",
    "#     update_plot(None)\n",
    "#     return results_container\n",
    "\n",
    "# def plot_walk_forward_analyzer(df_ohlcv, \n",
    "#                                default_start_date=None, default_calc_period='3M', default_fwd_period='1M',\n",
    "#                                default_metric='Sharpe (ATR)', default_rank_start=1, default_rank_end=10,\n",
    "#                                default_benchmark_ticker='VOO',\n",
    "#                                quality_thresholds={'min_median_dollar_volume': 10_000_000, # $10 million median daily trade volume\n",
    "#                                                    'max_stale_pct': 0.1,                   # Allow 10% stale days (i.e. Volume=0 or High=Low)\n",
    "#                                                    'max_same_vol_count': 1                 # Allow at most 1 suspicious volume event (i.e. same Volume on consecutive day)\n",
    "#                                                   },\n",
    "#                                debug=False): # <-- New debug argument\n",
    "    \n",
    "#     print(\"Initializing Walk-Forward Analyzer (with Dynamic Universe Filtering)...\")\n",
    "#     if not isinstance(df_ohlcv.index, pd.MultiIndex): raise ValueError(\"Input DataFrame must have a (Ticker, Date) MultiIndex.\")\n",
    "#     df_ohlcv = df_ohlcv.sort_index()\n",
    "    \n",
    "#     print(\"Pre-calculating data quality metrics...\")\n",
    "#     quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "    \n",
    "#     print(\"Pre-processing data (unstacking)...\")\n",
    "#     df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "#     df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "#     df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    \n",
    "#     # --- UI Widgets (unchanged) ---\n",
    "#     start_date_picker = widgets.DatePicker(description='Start Date:', value=pd.to_datetime(default_start_date), disabled=False)\n",
    "#     calc_period_options = {'1M': pd.DateOffset(months=1), '3M': pd.DateOffset(months=3), '6M': pd.DateOffset(months=6), '1Y': pd.DateOffset(years=1)}\n",
    "#     fwd_period_options = {'0D': pd.DateOffset(days=0), '1W': pd.DateOffset(weeks=1), '2W': pd.DateOffset(weeks=2), '1M': pd.DateOffset(months=1), '3M': pd.DateOffset(months=3)}\n",
    "#     calc_period_dropdown = widgets.Dropdown(options=calc_period_options.keys(), value=default_calc_period, description='Calc Period:')\n",
    "#     fwd_period_dropdown = widgets.Dropdown(options=fwd_period_options.keys(), value=default_fwd_period, description='Fwd Period:')\n",
    "#     metrics = ['Price', 'Sharpe', 'Sharpe (ATR)']\n",
    "#     metric_dropdown = widgets.Dropdown(options=metrics, value=default_metric, description='Metric:')\n",
    "#     rank_options = [1, 5, 10, 20, 30, 40, 50, 75, 100]\n",
    "#     rank_start_dropdown = widgets.Dropdown(options=rank_options, value=default_rank_start, description='Rank Start:')\n",
    "#     rank_end_dropdown = widgets.Dropdown(options=rank_options, value=default_rank_end, description='Rank End:')\n",
    "#     benchmark_ticker_input = widgets.Text(value=default_benchmark_ticker, description='Benchmark:', placeholder='Enter Ticker')\n",
    "#     update_button = widgets.Button(description=\"Update Chart\", button_style='primary')\n",
    "#     ticker_list_output = widgets.Output()\n",
    "    \n",
    "#     results_container = [None]\n",
    "#     debug_data_container = [None] # <-- New container for debug data\n",
    "\n",
    "#     # --- Plotly Figure (unchanged) ---\n",
    "#     fig = go.FigureWidget()\n",
    "#     max_traces = 50\n",
    "#     for i in range(max_traces): fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name=f'placeholder_{i}', visible=False, showlegend=False))\n",
    "#     fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Benchmark', visible=True, showlegend=True, line=dict(color='black', width=3, dash='dash')))\n",
    "#     fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Group Portfolio', visible=True, showlegend=True, line=dict(color='green', width=3)))\n",
    "\n",
    "#     def update_plot(button_click):\n",
    "#         ticker_list_output.clear_output()\n",
    "#         start_date = pd.to_datetime(start_date_picker.value)\n",
    "#         calc_period = calc_period_options[calc_period_dropdown.value]; fwd_period = fwd_period_options[fwd_period_dropdown.value]\n",
    "#         metric = metric_dropdown.value; rank_start, rank_end = rank_start_dropdown.value, rank_end_dropdown.value\n",
    "#         benchmark_ticker = benchmark_ticker_input.value.strip().upper()\n",
    "#         if rank_start > rank_end:\n",
    "#             with ticker_list_output: print(\"Error: 'Rank Start' must be <= 'Rank End'.\"); return\n",
    "\n",
    "#         eligible_tickers = get_eligible_universe(\n",
    "#             quality_metrics_df, filter_date=start_date, thresholds=quality_thresholds\n",
    "#         )\n",
    "#         if not eligible_tickers:\n",
    "#             with ticker_list_output: print(f\"Error: No eligible tickers found on {start_date.date()} with the current quality filters.\")\n",
    "#             return\n",
    "            \n",
    "#         df_close_step = df_close_full[eligible_tickers]\n",
    "#         df_high_step = df_high_full[eligible_tickers]\n",
    "#         df_low_step = df_low_full[eligible_tickers]\n",
    "\n",
    "#         # --- MODIFIED: Capture both results and debug data ---\n",
    "#         results, debug_output = run_walk_forward_step(\n",
    "#             df_close_step, df_high_step, df_low_step,\n",
    "#             start_date, calc_period, fwd_period, \n",
    "#             metric, rank_start, rank_end, benchmark_ticker,\n",
    "#             debug=debug # <-- Pass the debug flag through\n",
    "#         )\n",
    "        \n",
    "#         if results['error']:\n",
    "#             with ticker_list_output: print(f\"Error: {results['error']}\")\n",
    "#             return\n",
    "\n",
    "#         # --- Update plot (mostly unchanged) ---\n",
    "#         with fig.batch_update():\n",
    "#             # (Plotting logic remains the same)\n",
    "#             for i in range(max_traces):\n",
    "#                 trace = fig.data[i]\n",
    "#                 if i < len(results['tickers_to_display']):\n",
    "#                     ticker = results['tickers_to_display'][i]\n",
    "#                     plot_data_series = df_close_full[ticker].loc[results['safe_start_date']:results['safe_viz_end_date']]\n",
    "#                     normalized_series = plot_data_series / plot_data_series.bfill().iloc[0]\n",
    "#                     trace.x, trace.y, trace.name = normalized_series.index, normalized_series.values, ticker\n",
    "#                     trace.visible, trace.showlegend = True, True\n",
    "#                 else: trace.visible, trace.showlegend = False, False\n",
    "#             benchmark_trace = fig.data[max_traces]\n",
    "#             if results['benchmark_price_series'] is not None and not results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']].dropna().empty:\n",
    "#                 normalized_benchmark = results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']] / results['benchmark_price_series'].loc[results['safe_start_date']:].bfill().iloc[0]\n",
    "#                 benchmark_trace.x, benchmark_trace.y = normalized_benchmark.index, normalized_benchmark\n",
    "#                 benchmark_trace.name = f\"Benchmark ({benchmark_ticker})\"; benchmark_trace.visible = True\n",
    "#             else: benchmark_trace.visible = False\n",
    "#             portfolio_trace = fig.data[max_traces + 1]\n",
    "#             portfolio_trace.x, portfolio_trace.y = results['portfolio_series'].index, results['portfolio_series']\n",
    "#             portfolio_trace.name = 'Group Portfolio'; portfolio_trace.visible = True\n",
    "#             fig.layout.shapes = []; fig.add_shape(type=\"line\", x0=results['actual_calc_end_ts'], y0=0, x1=results['actual_calc_end_ts'], y1=1, xref='x', yref='paper', line=dict(color=\"grey\", width=2, dash=\"dash\"))\n",
    "            \n",
    "#         # --- Store results and debug data in their containers ---\n",
    "#         results_container[0] = results['results_df']\n",
    "#         debug_data_container[0] = debug_output\n",
    "        \n",
    "#         # --- Print summary (unchanged) ---\n",
    "#         with ticker_list_output:\n",
    "#             print(f\"Analyzing from {results['safe_start_date'].date()} to {results['safe_viz_end_date'].date()}.\")\n",
    "#             print(f\"  - Ranking based on performance from {results['safe_start_date'].date()} to {results['actual_calc_end_ts'].date()}.\")\n",
    "#             pprint.pprint(results['tickers_to_display'], width=120, compact=True)\n",
    "#             p = results['performance_data']\n",
    "#             rows = []\n",
    "#             rows.append({'Metric': 'Group Portfolio Gain', 'Full': p['full_p_gain'], 'Calc': p['calc_p_gain'], 'Fwd': p['fwd_p_gain']})\n",
    "#             if not np.isnan(p['full_b_gain']):\n",
    "#                 rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Gain', 'Full': p['full_b_gain'], 'Calc': p['calc_b_gain'], 'Fwd': p['fwd_b_gain']})\n",
    "#                 rows.append({'Metric': 'Gain Delta (vs Bm)', 'Full': p['full_p_gain'] - p['full_b_gain'], 'Calc': p['calc_p_gain'] - p['calc_b_gain'], 'Fwd': p['fwd_p_gain'] - p['fwd_b_gain']})\n",
    "#             rows.append({'Metric': 'Group Portfolio Sharpe', 'Full': p['full_p_sharpe'], 'Calc': p['calc_p_sharpe'], 'Fwd': p['fwd_p_sharpe']})\n",
    "#             if not np.isnan(p['full_b_sharpe']):\n",
    "#                 rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Sharpe', 'Full': p['full_b_sharpe'], 'Calc': p['calc_b_sharpe'], 'Fwd': p['fwd_b_sharpe']})\n",
    "#                 rows.append({'Metric': 'Sharpe Delta (vs Bm)', 'Full': p['full_p_sharpe'] - p['full_b_sharpe'], 'Calc': p['calc_p_sharpe'] - p['calc_b_sharpe'], 'Fwd': p['fwd_p_sharpe'] - p['fwd_b_sharpe']})\n",
    "#             report_df = pd.DataFrame(rows).set_index('Metric')\n",
    "#             gain_rows = [row for row in report_df.index if 'Gain' in row or 'Delta' in row]\n",
    "#             sharpe_rows = [row for row in report_df.index if 'Sharpe' in row]\n",
    "#             styled_df = report_df.style.format('{:+.2%}', na_rep='N/A', subset=(gain_rows, report_df.columns)).format('{:+.2f}', na_rep='N/A', subset=(sharpe_rows, report_df.columns)).set_properties(**{'text-align': 'right', 'width': '100px'}).set_table_styles([{'selector': 'th.col_heading', 'props': [('text-align', 'right')]}, {'selector': 'th.row_heading', 'props': [('text-align', 'left')]}])\n",
    "#             print(\"\\n--- Strategy Performance Summary ---\")\n",
    "#             display(styled_df)\n",
    "            \n",
    "#     fig.update_layout(title_text='Walk-Forward Performance Analysis', xaxis_title='Date', yaxis_title='Normalized Price (Start = 1)', hovermode='x unified', legend_title_text='Tickers (Ranked)', height=700, margin=dict(t=50))\n",
    "#     fig.add_hline(y=1, line_width=1, line_dash=\"dash\", line_color=\"grey\")\n",
    "#     update_button.on_click(update_plot)\n",
    "#     controls_row1 = widgets.HBox([start_date_picker, calc_period_dropdown, fwd_period_dropdown])\n",
    "#     controls_row2 = widgets.HBox([metric_dropdown, rank_start_dropdown, rank_end_dropdown, benchmark_ticker_input, update_button])\n",
    "#     ui_container = widgets.VBox([controls_row1, controls_row2, ticker_list_output], layout=widgets.Layout(margin='10px 0 20px 0'))\n",
    "#     display(ui_container, fig)\n",
    "#     update_plot(None)\n",
    "    \n",
    "#     return (results_container, debug_data_container) # <-- Return a tuple\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb5626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# FINAL PROJECT FUNCTIONS (Consolidated - Run this cell once)\n",
    "# ==============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime, date\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "import pprint\n",
    "from tqdm.auto import tqdm # For progress bars\n",
    "from pathlib import Path\n",
    "\n",
    "# --- A. HELPER FUNCTIONS ---\n",
    "\n",
    "def calculate_gain(price_series: pd.Series):\n",
    "    if price_series.dropna().shape[0] < 2: return np.nan\n",
    "    return (price_series.ffill().iloc[-1] / price_series.bfill().iloc[0]) - 1\n",
    "\n",
    "def calculate_sharpe(return_series: pd.Series):\n",
    "    if return_series.dropna().shape[0] < 2: return np.nan\n",
    "    std_dev = return_series.std()\n",
    "    if std_dev > 0 and std_dev != np.inf:\n",
    "        return (return_series.mean() / std_dev) * np.sqrt(252)\n",
    "    return np.nan\n",
    "\n",
    "# # --- B. THE CORE CALCULATION ENGINE ---\n",
    "\n",
    "# def run_walk_forward_step(df_close_full, df_high_full, df_low_full,\n",
    "#                           start_date, calc_period, fwd_period,\n",
    "#                           metric, rank_start, rank_end, benchmark_ticker,\n",
    "#                           debug=False):\n",
    "#     debug_data = {} if debug else None\n",
    "#     min_date_available = df_close_full.index.min()\n",
    "#     max_date_available = df_close_full.index.max()\n",
    "#     safe_start_date = max(start_date, min_date_available)\n",
    "#     safe_calc_end_date = min(start_date + calc_period, max_date_available)\n",
    "#     safe_viz_end_date = min(safe_calc_end_date + fwd_period, max_date_available)\n",
    "#     if safe_start_date >= safe_calc_end_date:\n",
    "#         return ({'error': \"Invalid date range.\"}, None)\n",
    "    \n",
    "#     calc_close_raw = df_close_full.loc[safe_start_date:safe_calc_end_date]\n",
    "#     calc_close = calc_close_raw.dropna(axis=1, how='all')\n",
    "#     if calc_close.shape[1] == 0 or len(calc_close) < 2:\n",
    "#         return ({'error': \"Not enough data in calc period.\"}, None)\n",
    "\n",
    "#     first_prices = calc_close.bfill().iloc[0]\n",
    "#     last_prices = calc_close.ffill().iloc[-1]\n",
    "#     daily_returns = calc_close.bfill().ffill().pct_change()\n",
    "#     mean_returns = daily_returns.mean()\n",
    "#     std_returns = daily_returns.std()\n",
    "    \n",
    "#     valid_tickers = calc_close.columns\n",
    "#     calc_high = df_high_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "#     calc_low = df_low_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "#     tr = np.maximum(calc_high - calc_low, abs(calc_high - df_close_full[valid_tickers].shift(1)), abs(calc_low - df_close_full[valid_tickers].shift(1)))\n",
    "#     atr = tr.ewm(alpha=1/14, adjust=False).mean()\n",
    "#     atrp = (atr / calc_close).mean()\n",
    "\n",
    "#     metric_values = {}\n",
    "#     metric_values['Price'] = (last_prices / first_prices).dropna()\n",
    "#     metric_values['Sharpe'] = (mean_returns / std_returns * np.sqrt(252)).fillna(0)\n",
    "#     metric_values['Sharpe (ATR)'] = (mean_returns / atrp).fillna(0)\n",
    "\n",
    "#     if debug:\n",
    "#         df_ranking = pd.DataFrame({\n",
    "#             'FirstPrice': first_prices, 'LastPrice': last_prices, 'MeanDailyReturn': mean_returns,\n",
    "#             'StdDevDailyReturn': std_returns, 'MeanATRP': atrp, 'Metric_Price': metric_values['Price'],\n",
    "#             'Metric_Sharpe': metric_values['Sharpe'], 'Metric_SharpeATR': metric_values['Sharpe (ATR)']\n",
    "#         })\n",
    "#         df_ranking.index.name = 'Ticker'\n",
    "#         debug_data['ranking_metrics'] = df_ranking.sort_values(f'Metric_{metric}', ascending=False)\n",
    "\n",
    "#     sorted_tickers = metric_values[metric].sort_values(ascending=False)\n",
    "#     tickers_to_display = sorted_tickers.index[rank_start-1:rank_end].tolist()\n",
    "#     if not tickers_to_display:\n",
    "#         return ({'error': \"No tickers found for the selected rank.\"}, None)\n",
    "\n",
    "#     normalized_plot_data = df_close_full[tickers_to_display].loc[safe_start_date:safe_viz_end_date]\n",
    "#     normalized_plot_data = normalized_plot_data.div(normalized_plot_data.bfill().iloc[0])\n",
    "#     actual_calc_end_ts = calc_close.index.max()\n",
    "#     portfolio_series = normalized_plot_data.mean(axis=1)\n",
    "#     portfolio_return_series = portfolio_series.pct_change()\n",
    "#     benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "#     benchmark_return_series = benchmark_price_series.loc[safe_start_date:safe_viz_end_date].bfill().ffill().pct_change() if benchmark_price_series is not None else pd.Series(dtype='float64')\n",
    "\n",
    "#     perf_data = {}\n",
    "#     perf_data['fwd_p_gain'] = calculate_gain(portfolio_series.loc[actual_calc_end_ts:])\n",
    "#     perf_data['full_p_gain'] = calculate_gain(portfolio_series)\n",
    "#     perf_data['fwd_p_sharpe'] = calculate_sharpe(portfolio_return_series.loc[actual_calc_end_ts:])\n",
    "#     perf_data['full_p_sharpe'] = calculate_sharpe(portfolio_return_series)\n",
    "#     perf_data['fwd_b_gain'] = calculate_gain(benchmark_price_series.loc[actual_calc_end_ts:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['full_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "\n",
    "#     calc_end_prices = calc_close.ffill().iloc[-1]\n",
    "#     fwd_close_slice = df_close_full.loc[actual_calc_end_ts:safe_viz_end_date]\n",
    "#     viz_end_prices = fwd_close_slice.ffill().iloc[-1] if not fwd_close_slice.empty and len(fwd_close_slice) >= 2 else calc_end_prices\n",
    "#     fwd_gains = (viz_end_prices / calc_end_prices) - 1\n",
    "    \n",
    "#     if debug:\n",
    "#         df_trace = normalized_plot_data.copy()\n",
    "#         df_trace.columns = [f'Norm_Price_{c}' for c in df_trace.columns]\n",
    "#         df_trace['Norm_Price_Portfolio'] = portfolio_series\n",
    "#         if benchmark_price_series is not None and not benchmark_price_series.loc[safe_start_date:safe_viz_end_date].dropna().empty:\n",
    "#             norm_bm = benchmark_price_series.loc[safe_start_date:safe_viz_end_date] / benchmark_price_series.loc[safe_start_date:].bfill().iloc[0]\n",
    "#             df_trace[f'Norm_Price_Benchmark_{benchmark_ticker}'] = norm_bm\n",
    "#         for col in df_trace.columns:\n",
    "#             if 'Norm_Price' in col:\n",
    "#                 df_trace[col.replace('Norm_Price', 'Return')] = df_trace[col].pct_change()\n",
    "#         debug_data['portfolio_trace'] = df_trace\n",
    "\n",
    "#     final_results = { 'tickers_to_display': tickers_to_display, 'normalized_plot_data': normalized_plot_data,\n",
    "#         'portfolio_series': portfolio_series, 'benchmark_price_series': benchmark_price_series, 'performance_data': perf_data,\n",
    "#         'actual_calc_end_ts': actual_calc_end_ts, 'safe_start_date': pd.to_datetime(df_close_full.loc[safe_start_date:safe_viz_end_date].index.min()),\n",
    "#         'safe_viz_end_date': pd.to_datetime(df_close_full.loc[safe_start_date:safe_viz_end_date].index.max()), 'error': None\n",
    "#     }\n",
    "#     return (final_results, debug_data)\n",
    "\n",
    "# # --- B. THE CORE CALCULATION ENGINE (CORRECTED DEBUG MODE) ---\n",
    "\n",
    "# def run_walk_forward_step(df_close_full, df_high_full, df_low_full,\n",
    "#                           start_date, calc_period, fwd_period,\n",
    "#                           metric, rank_start, rank_end, benchmark_ticker,\n",
    "#                           debug=False):\n",
    "#     # (The function signature and initial setup are the same)\n",
    "#     debug_data = {} if debug else None\n",
    "#     min_date_available = df_close_full.index.min()\n",
    "#     max_date_available = df_close_full.index.max()\n",
    "#     safe_start_date = max(start_date, min_date_available)\n",
    "#     safe_calc_end_date = min(start_date + calc_period, max_date_available)\n",
    "#     safe_viz_end_date = min(safe_calc_end_date + fwd_period, max_date_available)\n",
    "#     if safe_start_date >= safe_calc_end_date:\n",
    "#         return ({'error': \"Invalid date range.\"}, None)\n",
    "    \n",
    "#     calc_close_raw = df_close_full.loc[safe_start_date:safe_calc_end_date]\n",
    "#     calc_close = calc_close_raw.dropna(axis=1, how='all')\n",
    "#     if calc_close.shape[1] == 0 or len(calc_close) < 2:\n",
    "#         return ({'error': \"Not enough data in calc period.\"}, None)\n",
    "\n",
    "#     # (Metric component calculations are the same)\n",
    "#     first_prices = calc_close.bfill().iloc[0]\n",
    "#     last_prices = calc_close.ffill().iloc[-1]\n",
    "#     daily_returns = calc_close.bfill().ffill().pct_change()\n",
    "#     mean_returns = daily_returns.mean()\n",
    "#     std_returns = daily_returns.std()\n",
    "#     valid_tickers = calc_close.columns\n",
    "#     calc_high = df_high_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "#     calc_low = df_low_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "#     tr = np.maximum(calc_high - calc_low, abs(calc_high - df_close_full[valid_tickers].shift(1)), abs(calc_low - df_close_full[valid_tickers].shift(1)))\n",
    "#     atr = tr.ewm(alpha=1/14, adjust=False).mean()\n",
    "#     atrp = (atr / calc_close).mean()\n",
    "\n",
    "#     metric_values = {}\n",
    "#     metric_values['Price'] = (last_prices / first_prices).dropna()\n",
    "#     metric_values['Sharpe'] = (mean_returns / std_returns * np.sqrt(252)).fillna(0)\n",
    "#     metric_values['Sharpe (ATR)'] = (mean_returns / atrp).fillna(0)\n",
    "\n",
    "#     if debug:\n",
    "#         # --- THIS IS THE FIX ---\n",
    "#         # The keys in this dictionary now EXACTLY match the metric names.\n",
    "#         df_ranking = pd.DataFrame({\n",
    "#             'FirstPrice': first_prices,\n",
    "#             'LastPrice': last_prices,\n",
    "#             'MeanDailyReturn': mean_returns,\n",
    "#             'StdDevDailyReturn': std_returns,\n",
    "#             'MeanATRP': atrp,\n",
    "#             'Metric_Price': metric_values['Price'],\n",
    "#             'Metric_Sharpe': metric_values['Sharpe'],\n",
    "#             'Metric_Sharpe (ATR)': metric_values['Sharpe (ATR)'] # <-- Corrected key\n",
    "#         })\n",
    "#         # --- END OF FIX ---\n",
    "        \n",
    "#         df_ranking.index.name = 'Ticker'\n",
    "#         # Now this line will work correctly because the f-string will build a column name that exists.\n",
    "#         debug_data['ranking_metrics'] = df_ranking.sort_values(f'Metric_{metric}', ascending=False)\n",
    "\n",
    "#     # (The rest of the function continues as before)\n",
    "#     sorted_tickers = metric_values[metric].sort_values(ascending=False)\n",
    "#     tickers_to_display = sorted_tickers.index[rank_start-1:rank_end].tolist()\n",
    "#     if not tickers_to_display:\n",
    "#         return ({'error': \"No tickers found for the selected rank.\"}, None)\n",
    "\n",
    "#     normalized_plot_data = df_close_full[tickers_to_display].loc[safe_start_date:safe_viz_end_date]\n",
    "#     normalized_plot_data = normalized_plot_data.div(normalized_plot_data.bfill().iloc[0])\n",
    "#     actual_calc_end_ts = calc_close.index.max()\n",
    "#     portfolio_series = normalized_plot_data.mean(axis=1)\n",
    "#     portfolio_return_series = portfolio_series.pct_change()\n",
    "#     benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "#     benchmark_return_series = benchmark_price_series.loc[safe_start_date:safe_viz_end_date].bfill().ffill().pct_change() if benchmark_price_series is not None else pd.Series(dtype='float64')\n",
    "\n",
    "#     perf_data = {}\n",
    "#     perf_data['fwd_p_gain'] = calculate_gain(portfolio_series.loc[actual_calc_end_ts:])\n",
    "#     perf_data['full_p_gain'] = calculate_gain(portfolio_series)\n",
    "#     perf_data['fwd_p_sharpe'] = calculate_sharpe(portfolio_return_series.loc[actual_calc_end_ts:])\n",
    "#     perf_data['full_p_sharpe'] = calculate_sharpe(portfolio_return_series)\n",
    "#     perf_data['fwd_b_gain'] = calculate_gain(benchmark_price_series.loc[actual_calc_end_ts:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['full_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "\n",
    "#     if debug:\n",
    "#         df_trace = normalized_plot_data.copy()\n",
    "#         df_trace.columns = [f'Norm_Price_{c}' for c in df_trace.columns]\n",
    "#         df_trace['Norm_Price_Portfolio'] = portfolio_series\n",
    "#         if benchmark_price_series is not None and not benchmark_price_series.loc[safe_start_date:safe_viz_end_date].dropna().empty:\n",
    "#             norm_bm = benchmark_price_series.loc[safe_start_date:safe_viz_end_date] / benchmark_price_series.loc[safe_start_date:].bfill().iloc[0]\n",
    "#             df_trace[f'Norm_Price_Benchmark_{benchmark_ticker}'] = norm_bm\n",
    "#         for col in df_trace.columns:\n",
    "#             if 'Norm_Price' in col:\n",
    "#                 df_trace[col.replace('Norm_Price', 'Return')] = df_trace[col].pct_change()\n",
    "#         debug_data['portfolio_trace'] = df_trace\n",
    "\n",
    "#     final_results = {\n",
    "#         'tickers_to_display': tickers_to_display, 'normalized_plot_data': normalized_plot_data,\n",
    "#         'portfolio_series': portfolio_series, 'benchmark_price_series': benchmark_price_series,\n",
    "#         'performance_data': perf_data, 'actual_calc_end_ts': actual_calc_end_ts,\n",
    "#         'safe_start_date': pd.to_datetime(df_close_full.loc[safe_start_date:safe_viz_end_date].index.min()),\n",
    "#         'safe_viz_end_date': pd.to_datetime(df_close_full.loc[safe_start_date:safe_viz_end_date].index.max()),\n",
    "#         'error': None\n",
    "#     }\n",
    "#     return (final_results, debug_data)\n",
    "\n",
    "# --- B. THE CORE CALCULATION ENGINE (DEFINITIVELY CORRECTED) ---\n",
    "\n",
    "# def run_walk_forward_step(df_close_full, df_high_full, df_low_full,\n",
    "#                           start_date, calc_period, fwd_period,\n",
    "#                           metric, rank_start, rank_end, benchmark_ticker,\n",
    "#                           debug=False):\n",
    "#     # ... (all code at the beginning of the function is correct) ...\n",
    "#     debug_data = {} if debug else None\n",
    "#     min_date_available = df_close_full.index.min()\n",
    "#     max_date_available = df_close_full.index.max()\n",
    "#     safe_start_date = max(start_date, min_date_available)\n",
    "#     safe_calc_end_date = min(start_date + calc_period, max_date_available)\n",
    "#     safe_viz_end_date = min(safe_calc_end_date + fwd_period, max_date_available)\n",
    "#     if safe_start_date >= safe_calc_end_date:\n",
    "#         return ({'error': \"Invalid date range.\"}, None)\n",
    "#     calc_close_raw = df_close_full.loc[safe_start_date:safe_calc_end_date]\n",
    "#     calc_close = calc_close_raw.dropna(axis=1, how='all')\n",
    "#     if calc_close.shape[1] == 0 or len(calc_close) < 2:\n",
    "#         return ({'error': \"Not enough data in calc period.\"}, None)\n",
    "#     first_prices = calc_close.bfill().iloc[0]\n",
    "#     last_prices = calc_close.ffill().iloc[-1]\n",
    "#     daily_returns = calc_close.bfill().ffill().pct_change()\n",
    "#     mean_returns = daily_returns.mean()\n",
    "#     std_returns = daily_returns.std()\n",
    "#     valid_tickers = calc_close.columns\n",
    "#     calc_high = df_high_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "#     calc_low = df_low_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "#     tr = np.maximum(calc_high - calc_low, abs(calc_high - df_close_full[valid_tickers].shift(1)), abs(calc_low - df_close_full[valid_tickers].shift(1)))\n",
    "#     atr = tr.ewm(alpha=1/14, adjust=False).mean()\n",
    "#     atrp = (atr / calc_close).mean()\n",
    "#     metric_values = {}\n",
    "#     metric_values['Price'] = (last_prices / first_prices).dropna()\n",
    "#     metric_values['Sharpe'] = (mean_returns / std_returns * np.sqrt(252)).fillna(0)\n",
    "#     metric_values['Sharpe (ATR)'] = (mean_returns / atrp).fillna(0)\n",
    "#     if debug:\n",
    "#         df_ranking = pd.DataFrame({\n",
    "#             'FirstPrice': first_prices, 'LastPrice': last_prices, 'MeanDailyReturn': mean_returns,\n",
    "#             'StdDevDailyReturn': std_returns, 'MeanATRP': atrp, 'Metric_Price': metric_values['Price'],\n",
    "#             'Metric_Sharpe': metric_values['Sharpe'], 'Metric_Sharpe (ATR)': metric_values['Sharpe (ATR)']\n",
    "#         })\n",
    "#         df_ranking.index.name = 'Ticker'\n",
    "#         debug_data['ranking_metrics'] = df_ranking.sort_values(f'Metric_{metric}', ascending=False)\n",
    "#     sorted_tickers = metric_values[metric].sort_values(ascending=False)\n",
    "#     tickers_to_display = sorted_tickers.index[rank_start-1:rank_end].tolist()\n",
    "#     if not tickers_to_display:\n",
    "#         return ({'error': \"No tickers found for the selected rank.\"}, None)\n",
    "#     normalized_plot_data = df_close_full[tickers_to_display].loc[safe_start_date:safe_viz_end_date]\n",
    "#     normalized_plot_data = normalized_plot_data.div(normalized_plot_data.bfill().iloc[0])\n",
    "#     actual_calc_end_ts = calc_close.index.max()\n",
    "#     portfolio_series = normalized_plot_data.mean(axis=1)\n",
    "#     portfolio_return_series = portfolio_series.pct_change()\n",
    "#     benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "#     benchmark_return_series = benchmark_price_series.loc[safe_start_date:safe_viz_end_date].bfill().ffill().pct_change() if benchmark_price_series is not None else pd.Series(dtype='float64')\n",
    "#     perf_data = {} # (perf_data calculations are correct)\n",
    "#     perf_data['fwd_p_gain'] = calculate_gain(portfolio_series.loc[actual_calc_end_ts:])\n",
    "#     perf_data['full_p_gain'] = calculate_gain(portfolio_series)\n",
    "#     perf_data['fwd_p_sharpe'] = calculate_sharpe(portfolio_return_series.loc[actual_calc_end_ts:])\n",
    "#     perf_data['full_p_sharpe'] = calculate_sharpe(portfolio_return_series)\n",
    "#     perf_data['fwd_b_gain'] = calculate_gain(benchmark_price_series.loc[actual_calc_end_ts:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['full_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "\n",
    "#     # --- THIS PART CREATES THE DATAFRAME WE NEED ---\n",
    "#     calc_end_prices = calc_close.ffill().iloc[-1]\n",
    "#     fwd_close_slice = df_close_full.loc[actual_calc_end_ts:safe_viz_end_date]\n",
    "#     viz_end_prices = fwd_close_slice.ffill().iloc[-1] if not fwd_close_slice.empty and len(fwd_close_slice) >= 2 else calc_end_prices\n",
    "#     calc_gains = (calc_end_prices / calc_close.bfill().iloc[0]) - 1\n",
    "#     fwd_gains = (viz_end_prices / calc_end_prices) - 1\n",
    "#     results_df = pd.DataFrame({'Rank': range(rank_start, rank_start + len(tickers_to_display)), 'Metric': metric, 'MetricValue': sorted_tickers.loc[tickers_to_display].values, 'CalcPrice': calc_end_prices.loc[tickers_to_display], 'CalcGain': calc_gains.loc[tickers_to_display], 'FwdGain': fwd_gains.loc[tickers_to_display]}, index=pd.Index(tickers_to_display, name='Ticker'))\n",
    "#     if benchmark_price_series is not None and benchmark_ticker in calc_close.columns:\n",
    "#         benchmark_df_row = pd.DataFrame({'Rank': np.nan, 'Metric': metric, 'MetricValue': metric_values[metric].get(benchmark_ticker, np.nan), 'CalcPrice': calc_end_prices[benchmark_ticker], 'CalcGain': calc_gains[benchmark_ticker], 'FwdGain': fwd_gains[benchmark_ticker]}, index=pd.Index([f\"{benchmark_ticker} (BM)\"], name='Ticker'))\n",
    "#         results_df = pd.concat([results_df, benchmark_df_row])\n",
    "    \n",
    "#     # ... (debug trace generation is correct) ...\n",
    "#     if debug:\n",
    "#         df_trace = normalized_plot_data.copy()\n",
    "#         df_trace.columns = [f'Norm_Price_{c}' for c in df_trace.columns]\n",
    "#         df_trace['Norm_Price_Portfolio'] = portfolio_series\n",
    "#         if benchmark_price_series is not None and not benchmark_price_series.loc[safe_start_date:safe_viz_end_date].dropna().empty:\n",
    "#             norm_bm = benchmark_price_series.loc[safe_start_date:safe_viz_end_date] / benchmark_price_series.loc[safe_start_date:].bfill().iloc[0]\n",
    "#             df_trace[f'Norm_Price_Benchmark_{benchmark_ticker}'] = norm_bm\n",
    "#         for col in df_trace.columns:\n",
    "#             if 'Norm_Price' in col:\n",
    "#                 df_trace[col.replace('Norm_Price', 'Return')] = df_trace[col].pct_change()\n",
    "#         debug_data['portfolio_trace'] = df_trace\n",
    "\n",
    "#     # --- THIS IS THE FIX ---\n",
    "#     # The final dictionary that gets returned MUST include the 'results_df' we just created.\n",
    "#     final_results = {\n",
    "#         'tickers_to_display': tickers_to_display,\n",
    "#         'normalized_plot_data': normalized_plot_data,\n",
    "#         'portfolio_series': portfolio_series,\n",
    "#         'benchmark_price_series': benchmark_price_series,\n",
    "#         'performance_data': perf_data,\n",
    "#         'results_df': results_df,  # <-- ADDED THIS LINE\n",
    "#         'actual_calc_end_ts': actual_calc_end_ts,\n",
    "#         'safe_start_date': pd.to_datetime(df_close_full.loc[safe_start_date:safe_viz_end_date].index.min()),\n",
    "#         'safe_viz_end_date': pd.to_datetime(df_close_full.loc[safe_start_date:safe_viz_end_date].index.max()),\n",
    "#         'error': None\n",
    "#     }\n",
    "#     # --- END OF FIX ---\n",
    "    \n",
    "#     return (final_results, debug_data)\n",
    "\n",
    "def run_walk_forward_step(df_close_full, df_high_full, df_low_full,\n",
    "                          start_date, calc_period, fwd_period,\n",
    "                          metric, rank_start, rank_end, benchmark_ticker,\n",
    "                          debug=False):\n",
    "    debug_data = {} if debug else None\n",
    "    min_date_available = df_close_full.index.min()\n",
    "    max_date_available = df_close_full.index.max()\n",
    "    safe_start_date = max(start_date, min_date_available)\n",
    "    safe_calc_end_date = min(start_date + calc_period, max_date_available)\n",
    "    safe_viz_end_date = min(safe_calc_end_date + fwd_period, max_date_available)\n",
    "    if safe_start_date >= safe_calc_end_date:\n",
    "        return ({'error': \"Invalid date range.\"}, None)\n",
    "    \n",
    "    calc_close_raw = df_close_full.loc[safe_start_date:safe_calc_end_date]\n",
    "    calc_close = calc_close_raw.dropna(axis=1, how='all')\n",
    "    if calc_close.shape[1] == 0 or len(calc_close) < 2:\n",
    "        return ({'error': \"Not enough data in calc period.\"}, None)\n",
    "\n",
    "    first_prices = calc_close.bfill().iloc[0]\n",
    "    last_prices = calc_close.ffill().iloc[-1]\n",
    "    daily_returns = calc_close.bfill().ffill().pct_change()\n",
    "    mean_returns = daily_returns.mean()\n",
    "    std_returns = daily_returns.std()\n",
    "    \n",
    "    valid_tickers = calc_close.columns\n",
    "    calc_high = df_high_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "    calc_low = df_low_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "    tr = np.maximum(calc_high - calc_low, abs(calc_high - df_close_full[valid_tickers].shift(1)), abs(calc_low - df_close_full[valid_tickers].shift(1)))\n",
    "    atr = tr.ewm(alpha=1/14, adjust=False).mean()\n",
    "    atrp = (atr / calc_close).mean()\n",
    "\n",
    "    metric_values = {}\n",
    "    metric_values['Price'] = (last_prices / first_prices).dropna()\n",
    "    metric_values['Sharpe'] = (mean_returns / std_returns * np.sqrt(252)).fillna(0)\n",
    "    metric_values['Sharpe (ATR)'] = (mean_returns / atrp).fillna(0)\n",
    "\n",
    "    if debug:\n",
    "        df_ranking = pd.DataFrame({\n",
    "            'FirstPrice': first_prices, 'LastPrice': last_prices, 'MeanDailyReturn': mean_returns,\n",
    "            'StdDevDailyReturn': std_returns, 'MeanATRP': atrp, 'Metric_Price': metric_values['Price'],\n",
    "            'Metric_Sharpe': metric_values['Sharpe'], 'Metric_Sharpe (ATR)': metric_values['Sharpe (ATR)']\n",
    "        })\n",
    "        df_ranking.index.name = 'Ticker'\n",
    "        debug_data['ranking_metrics'] = df_ranking.sort_values(f'Metric_{metric}', ascending=False)\n",
    "\n",
    "    sorted_tickers = metric_values[metric].sort_values(ascending=False)\n",
    "    tickers_to_display = sorted_tickers.index[rank_start-1:rank_end].tolist()\n",
    "    if not tickers_to_display:\n",
    "        return ({'error': \"No tickers found for the selected rank.\"}, None)\n",
    "\n",
    "    normalized_plot_data = df_close_full[tickers_to_display].loc[safe_start_date:safe_viz_end_date]\n",
    "    normalized_plot_data = normalized_plot_data.div(normalized_plot_data.bfill().iloc[0])\n",
    "    actual_calc_end_ts = calc_close.index.max()\n",
    "    portfolio_series = normalized_plot_data.mean(axis=1)\n",
    "    portfolio_return_series = portfolio_series.pct_change()\n",
    "    benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "    benchmark_return_series = benchmark_price_series.loc[safe_start_date:safe_viz_end_date].bfill().ffill().pct_change() if benchmark_price_series is not None else pd.Series(dtype='float64')\n",
    "\n",
    "    # --- THIS SECTION IS NOW CORRECT AND COMPLETE ---\n",
    "    perf_data = {}\n",
    "    perf_data['calc_p_gain'] = calculate_gain(portfolio_series.loc[:actual_calc_end_ts])\n",
    "    perf_data['fwd_p_gain'] = calculate_gain(portfolio_series.loc[actual_calc_end_ts:])\n",
    "    perf_data['full_p_gain'] = calculate_gain(portfolio_series)\n",
    "    perf_data['calc_p_sharpe'] = calculate_sharpe(portfolio_return_series.loc[:actual_calc_end_ts])\n",
    "    perf_data['fwd_p_sharpe'] = calculate_sharpe(portfolio_return_series.loc[actual_calc_end_ts:])\n",
    "    perf_data['full_p_sharpe'] = calculate_sharpe(portfolio_return_series)\n",
    "    perf_data['calc_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:actual_calc_end_ts]) if benchmark_price_series is not None else np.nan\n",
    "    perf_data['fwd_b_gain'] = calculate_gain(benchmark_price_series.loc[actual_calc_end_ts:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "    perf_data['full_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "    perf_data['calc_b_sharpe'] = calculate_sharpe(benchmark_return_series.loc[:actual_calc_end_ts])\n",
    "    perf_data['fwd_b_sharpe'] = calculate_sharpe(benchmark_return_series.loc[actual_calc_end_ts:])\n",
    "    perf_data['full_b_sharpe'] = calculate_sharpe(benchmark_return_series)\n",
    "    # --- END OF CORRECTED SECTION ---\n",
    "\n",
    "    calc_end_prices = calc_close.ffill().iloc[-1]\n",
    "    fwd_close_slice = df_close_full.loc[actual_calc_end_ts:safe_viz_end_date]\n",
    "    viz_end_prices = fwd_close_slice.ffill().iloc[-1] if not fwd_close_slice.empty and len(fwd_close_slice) >= 2 else calc_end_prices\n",
    "    calc_gains = (calc_end_prices / calc_close.bfill().iloc[0]) - 1\n",
    "    fwd_gains = (viz_end_prices / calc_end_prices) - 1\n",
    "    results_df = pd.DataFrame({'Rank': range(rank_start, rank_start + len(tickers_to_display)), 'Metric': metric, 'MetricValue': sorted_tickers.loc[tickers_to_display].values, 'CalcPrice': calc_end_prices.loc[tickers_to_display], 'CalcGain': calc_gains.loc[tickers_to_display], 'FwdGain': fwd_gains.loc[tickers_to_display]}, index=pd.Index(tickers_to_display, name='Ticker'))\n",
    "    if benchmark_price_series is not None and benchmark_ticker in calc_close.columns:\n",
    "        benchmark_df_row = pd.DataFrame({'Rank': np.nan, 'Metric': metric, 'MetricValue': metric_values[metric].get(benchmark_ticker, np.nan), 'CalcPrice': calc_end_prices[benchmark_ticker], 'CalcGain': calc_gains[benchmark_ticker], 'FwdGain': fwd_gains[benchmark_ticker]}, index=pd.Index([f\"{benchmark_ticker} (BM)\"], name='Ticker'))\n",
    "        results_df = pd.concat([results_df, benchmark_df_row])\n",
    "    \n",
    "    if debug:\n",
    "        df_trace = normalized_plot_data.copy()\n",
    "        df_trace.columns = [f'Norm_Price_{c}' for c in df_trace.columns]\n",
    "        df_trace['Norm_Price_Portfolio'] = portfolio_series\n",
    "        if benchmark_price_series is not None and not benchmark_price_series.loc[safe_start_date:safe_viz_end_date].dropna().empty:\n",
    "            norm_bm = benchmark_price_series.loc[safe_start_date:safe_viz_end_date] / benchmark_price_series.loc[safe_start_date:].bfill().iloc[0]\n",
    "            df_trace[f'Norm_Price_Benchmark_{benchmark_ticker}'] = norm_bm\n",
    "        for col in df_trace.columns:\n",
    "            if 'Norm_Price' in col:\n",
    "                df_trace[col.replace('Norm_Price', 'Return')] = df_trace[col].pct_change()\n",
    "        debug_data['portfolio_trace'] = df_trace\n",
    "\n",
    "    final_results = {\n",
    "        'tickers_to_display': tickers_to_display,\n",
    "        'normalized_plot_data': normalized_plot_data,\n",
    "        'portfolio_series': portfolio_series,\n",
    "        'benchmark_price_series': benchmark_price_series,\n",
    "        'performance_data': perf_data,\n",
    "        'results_df': results_df,\n",
    "        'actual_calc_end_ts': actual_calc_end_ts,\n",
    "        'safe_start_date': pd.to_datetime(df_close_full.loc[safe_start_date:safe_viz_end_date].index.min()),\n",
    "        'safe_viz_end_date': pd.to_datetime(df_close_full.loc[safe_start_date:safe_viz_end_date].index.max()),\n",
    "        'error': None\n",
    "    }\n",
    "    \n",
    "    return (final_results, debug_data)\n",
    "\n",
    "# --- C. DYNAMIC DATA QUALITY FILTER FUNCTIONS ---\n",
    "\n",
    "def calculate_rolling_quality_metrics(df_ohlcv, window=252, min_periods=126, debug=False):\n",
    "    print(f\"--- Calculating Rolling Quality Metrics (Window: {window} days) ---\")\n",
    "    df = df_ohlcv.copy()\n",
    "    if not df.index.is_monotonic_increasing:\n",
    "        df.sort_index(inplace=True)\n",
    "    df['IsStale'] = np.where((df['Volume'] == 0) | (df['Adj High'] == df['Adj Low']), 1, 0)\n",
    "    df['DollarVolume'] = df['Adj Close'] * df['Volume']\n",
    "    df['HasSameVolumeAsPrevDay'] = (df.groupby(level='Ticker')['Volume'].diff() == 0).astype(int)\n",
    "    grouped = df.groupby(level='Ticker')\n",
    "    stale_pct = grouped['IsStale'].rolling(window=window, min_periods=min_periods).mean()\n",
    "    median_vol = grouped['DollarVolume'].rolling(window=window, min_periods=min_periods).median()\n",
    "    same_vol_count = grouped['HasSameVolumeAsPrevDay'].rolling(window=window, min_periods=min_periods).sum()\n",
    "    quality_df = pd.concat([stale_pct, median_vol, same_vol_count], axis=1)\n",
    "    quality_df.columns = ['RollingStalePct', 'RollingMedianVolume', 'RollingSameVolCount']\n",
    "    quality_df.index = quality_df.index.droplevel(0)\n",
    "    print(\"✅ Rolling metrics calculation complete.\")\n",
    "    return quality_df\n",
    "\n",
    "def get_eligible_universe(quality_metrics_df, filter_date, thresholds):\n",
    "    filter_date_ts = pd.to_datetime(filter_date)\n",
    "    date_index = quality_metrics_df.index.get_level_values('Date').unique().sort_values()\n",
    "    if filter_date_ts < date_index[0]:\n",
    "        print(f\"Warning: Filter date {filter_date_ts.date()} is before the earliest data point. Returning empty universe.\")\n",
    "        return []\n",
    "    valid_prior_dates = date_index[date_index <= filter_date_ts]\n",
    "    if valid_prior_dates.empty:\n",
    "        print(f\"Warning: No available data found on or before {filter_date_ts.date()}. Returning empty universe.\")\n",
    "        return []\n",
    "    actual_date_to_use = valid_prior_dates[-1]\n",
    "    if actual_date_to_use.date() != filter_date_ts.date():\n",
    "        print(f\"ℹ️ Info: Filter date {filter_date_ts.date()} not found. Using previous available date {actual_date_to_use.date()}.\")\n",
    "    metrics_on_date = quality_metrics_df.xs(actual_date_to_use, level='Date')\n",
    "    mask = ((metrics_on_date['RollingMedianVolume'] >= thresholds['min_median_dollar_volume']) &\n",
    "            (metrics_on_date['RollingStalePct'] <= thresholds['max_stale_pct']) &\n",
    "            (metrics_on_date['RollingSameVolCount'] <= thresholds['max_same_vol_count']))\n",
    "    eligible_tickers = metrics_on_date[mask].index.tolist()\n",
    "    all_tickers = metrics_on_date.index.tolist()\n",
    "    print(f\"Dynamic Filter ({filter_date_ts.date()}): Kept {len(eligible_tickers)} of {len(all_tickers)} tickers.\")\n",
    "    return eligible_tickers    \n",
    "\n",
    "# --- D. INTERACTIVE ANALYSIS TOOLS ---\n",
    "\n",
    "# def plot_walk_forward_analyzer(df_ohlcv, \n",
    "#                                default_start_date=None, default_calc_period='3M', default_fwd_period='1M',\n",
    "#                                default_metric='Sharpe (ATR)', default_rank_start=1, default_rank_end=10,\n",
    "#                                default_benchmark_ticker='VOO',\n",
    "#                                quality_thresholds={'min_median_dollar_volume': 10_000_000, 'max_stale_pct': 0.05, 'max_same_vol_count': 5},\n",
    "#                                debug=False):\n",
    "#     print(\"Initializing Walk-Forward Analyzer...\")\n",
    "#     df_ohlcv = df_ohlcv.sort_index()\n",
    "#     quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "#     df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "#     df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "#     df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "#     start_date_picker = widgets.DatePicker(description='Start Date:', value=pd.to_datetime(default_start_date))\n",
    "#     calc_period_options = {'3M': pd.DateOffset(months=3), '6M': pd.DateOffset(months=6), '1Y': pd.DateOffset(years=1)}\n",
    "#     fwd_period_options = {'1M': pd.DateOffset(months=1), '3M': pd.DateOffset(months=3)}\n",
    "#     calc_period_dropdown = widgets.Dropdown(options=calc_period_options.keys(), value=default_calc_period, description='Calc Period:')\n",
    "#     fwd_period_dropdown = widgets.Dropdown(options=fwd_period_options.keys(), value=default_fwd_period, description='Fwd Period:')\n",
    "#     metric_dropdown = widgets.Dropdown(options=['Price', 'Sharpe', 'Sharpe (ATR)'], value=default_metric, description='Metric:')\n",
    "#     rank_start_dropdown = widgets.Dropdown(options=[1, 5, 10, 20, 30], value=default_rank_start, description='Rank Start:')\n",
    "#     rank_end_dropdown = widgets.Dropdown(options=[10, 20, 30, 50, 100], value=default_rank_end, description='Rank End:')\n",
    "#     benchmark_ticker_input = widgets.Text(value=default_benchmark_ticker, description='Benchmark:')\n",
    "#     update_button = widgets.Button(description=\"Update Chart\", button_style='primary')\n",
    "#     ticker_list_output = widgets.Output()\n",
    "#     results_container, debug_data_container = [None], [None]\n",
    "#     fig = go.FigureWidget()\n",
    "#     for i in range(50): fig.add_trace(go.Scatter(visible=False))\n",
    "#     fig.add_trace(go.Scatter(name='Benchmark', line=dict(color='black', dash='dash')))\n",
    "#     fig.add_trace(go.Scatter(name='Group Portfolio', line=dict(color='green', width=3)))\n",
    "\n",
    "#     def update_plot(button_click):\n",
    "#         ticker_list_output.clear_output()\n",
    "#         start_date = pd.to_datetime(start_date_picker.value)\n",
    "#         # (Rest of UI parameter gathering is the same)\n",
    "#         calc_period = calc_period_options[calc_period_dropdown.value]; fwd_period = fwd_period_options[fwd_period_dropdown.value]\n",
    "#         metric = metric_dropdown.value; rank_start, rank_end = rank_start_dropdown.value, rank_end_dropdown.value\n",
    "#         benchmark_ticker = benchmark_ticker_input.value.strip().upper()\n",
    "#         if rank_start > rank_end:\n",
    "#             with ticker_list_output: print(\"Error: 'Rank Start' must be <= 'Rank End'.\"); return\n",
    "        \n",
    "#         eligible_tickers = get_eligible_universe(quality_metrics_df, start_date, quality_thresholds)\n",
    "#         if not eligible_tickers:\n",
    "#             with ticker_list_output: print(\"Error: No eligible tickers found.\"); return\n",
    "        \n",
    "#         df_close_step = df_close_full[eligible_tickers]\n",
    "#         df_high_step = df_high_full[eligible_tickers]\n",
    "#         df_low_step = df_low_full[eligible_tickers]\n",
    "\n",
    "#         results, debug_output = run_walk_forward_step(\n",
    "#             df_close_step, df_high_step, df_low_step, start_date, calc_period, fwd_period,\n",
    "#             metric, rank_start, rank_end, benchmark_ticker, debug=debug\n",
    "#         )\n",
    "        \n",
    "#         if results['error']:\n",
    "#             with ticker_list_output: print(f\"Error: {results['error']}\"); return\n",
    "        \n",
    "#         with fig.batch_update():\n",
    "#             # (Plotting logic is the same)\n",
    "#             for i in range(50):\n",
    "#                 trace = fig.data[i]\n",
    "#                 if i < len(results['tickers_to_display']):\n",
    "#                     ticker = results['tickers_to_display'][i]\n",
    "#                     plot_series = results['normalized_plot_data'][ticker]\n",
    "#                     trace.x, trace.y, trace.name, trace.visible = plot_series.index, plot_series.values, ticker, True\n",
    "#                 else: trace.visible = False\n",
    "#             benchmark_trace = fig.data[50]\n",
    "#             if not results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']].dropna().empty:\n",
    "#                 norm_bm = results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']] / results['benchmark_price_series'].loc[results['safe_start_date']:].bfill().iloc[0]\n",
    "#                 benchmark_trace.x, benchmark_trace.y, benchmark_trace.visible = norm_bm.index, norm_bm.values, True\n",
    "#             else: benchmark_trace.visible = False\n",
    "#             portfolio_trace = fig.data[51]\n",
    "#             portfolio_trace.x, portfolio_trace.y, portfolio_trace.visible = results['portfolio_series'].index, results['portfolio_series'].values, True\n",
    "#             fig.layout.shapes = []; fig.add_shape(type=\"line\", x0=results['actual_calc_end_ts'], y0=0, x1=results['actual_calc_end_ts'], y1=1, xref='x', yref='paper', line=dict(color=\"grey\", dash=\"dash\"))\n",
    "        \n",
    "#         results_container[0] = results\n",
    "#         debug_data_container[0] = debug_output\n",
    "        \n",
    "#         with ticker_list_output:\n",
    "#             # (Display logic is the same)\n",
    "#             print(f\"Analysis Period: {results['safe_start_date'].date()} to {results['safe_viz_end_date'].date()}.\")\n",
    "#             pprint.pprint(results['tickers_to_display'])\n",
    "#             p = results['performance_data']\n",
    "#             # ... (the rest of the performance summary printout)\n",
    "\n",
    "#     fig.update_layout(title_text='Walk-Forward Performance Analysis', xaxis_title='Date', yaxis_title='Normalized Price', hovermode='x unified',  legend_title_text='Tickers (Ranked)', height=500, margin=dict(t=50))\n",
    "#     update_button.on_click(update_plot)\n",
    "#     controls_row1 = widgets.HBox([start_date_picker, calc_period_dropdown, fwd_period_dropdown])\n",
    "#     controls_row2 = widgets.HBox([metric_dropdown, rank_start_dropdown, rank_end_dropdown, benchmark_ticker_input, update_button])\n",
    "#     ui_container = widgets.VBox([controls_row1, controls_row2, ticker_list_output])\n",
    "#     display(ui_container, fig)\n",
    "#     update_plot(None)\n",
    "#     return (results_container, debug_data_container)\n",
    "\n",
    "\n",
    "def plot_walk_forward_analyzer(df_ohlcv, \n",
    "                               default_start_date=None, default_calc_period='3M', default_fwd_period='1M',\n",
    "                               default_metric='Sharpe (ATR)', default_rank_start=1, default_rank_end=10,\n",
    "                               default_benchmark_ticker='VOO',\n",
    "                               quality_thresholds={'min_median_dollar_volume': 1_000_000, 'max_stale_pct': 0.05, 'max_same_vol_count': 10},\n",
    "                               debug=False):\n",
    "    \n",
    "    print(\"Initializing Walk-Forward Analyzer (with Dynamic Universe Filtering)...\")\n",
    "    if not isinstance(df_ohlcv.index, pd.MultiIndex): raise ValueError(\"Input DataFrame must have a (Ticker, Date) MultiIndex.\")\n",
    "    df_ohlcv = df_ohlcv.sort_index()\n",
    "    \n",
    "    print(\"Pre-calculating data quality metrics...\")\n",
    "    quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "    \n",
    "    print(\"Pre-processing data (unstacking)...\")\n",
    "    df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "    df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "    df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    \n",
    "    start_date_picker = widgets.DatePicker(description='Start Date:', value=pd.to_datetime(default_start_date), disabled=False)\n",
    "    calc_period_options = {'3M': pd.DateOffset(months=3), '6M': pd.DateOffset(months=6), '1Y': pd.DateOffset(years=1)}\n",
    "    fwd_period_options = {'1M': pd.DateOffset(months=1), '3M': pd.DateOffset(months=3)}\n",
    "    calc_period_dropdown = widgets.Dropdown(options=calc_period_options.keys(), value=default_calc_period, description='Calc Period:')\n",
    "    fwd_period_dropdown = widgets.Dropdown(options=fwd_period_options.keys(), value=default_fwd_period, description='Fwd Period:')\n",
    "    metrics = ['Price', 'Sharpe', 'Sharpe (ATR)']\n",
    "    metric_dropdown = widgets.Dropdown(options=metrics, value=default_metric, description='Metric:')\n",
    "    rank_options = [1, 5, 10, 20, 30, 40, 50, 75, 100]\n",
    "    rank_start_dropdown = widgets.Dropdown(options=rank_options, value=default_rank_start, description='Rank Start:')\n",
    "    rank_end_dropdown = widgets.Dropdown(options=rank_options, value=default_rank_end, description='Rank End:')\n",
    "    benchmark_ticker_input = widgets.Text(value=default_benchmark_ticker, description='Benchmark:', placeholder='Enter Ticker')\n",
    "    update_button = widgets.Button(description=\"Update Chart\", button_style='primary')\n",
    "    ticker_list_output = widgets.Output()\n",
    "    \n",
    "    results_container = [None]\n",
    "    debug_data_container = [None]\n",
    "\n",
    "    fig = go.FigureWidget()\n",
    "    max_traces = 50\n",
    "    for i in range(max_traces): fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name=f'placeholder_{i}', visible=False, showlegend=False))\n",
    "    fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Benchmark', visible=True, showlegend=True, line=dict(color='black', width=3, dash='dash')))\n",
    "    fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Group Portfolio', visible=True, showlegend=True, line=dict(color='green', width=3)))\n",
    "\n",
    "    def update_plot(button_click):\n",
    "        ticker_list_output.clear_output()\n",
    "        start_date = pd.to_datetime(start_date_picker.value)\n",
    "        calc_period = calc_period_options[calc_period_dropdown.value]; fwd_period = fwd_period_options[fwd_period_dropdown.value]\n",
    "        metric = metric_dropdown.value; rank_start, rank_end = rank_start_dropdown.value, rank_end_dropdown.value\n",
    "        benchmark_ticker = benchmark_ticker_input.value.strip().upper()\n",
    "        if rank_start > rank_end:\n",
    "            with ticker_list_output: print(\"Error: 'Rank Start' must be <= 'Rank End'.\"); return\n",
    "\n",
    "        eligible_tickers = get_eligible_universe(\n",
    "            quality_metrics_df, filter_date=start_date, thresholds=quality_thresholds\n",
    "        )\n",
    "        if not eligible_tickers:\n",
    "            with ticker_list_output: print(f\"Error: No eligible tickers found on {start_date.date()} with the current quality filters.\")\n",
    "            return\n",
    "            \n",
    "        df_close_step = df_close_full[eligible_tickers]\n",
    "        df_high_step = df_high_full[eligible_tickers]\n",
    "        df_low_step = df_low_full[eligible_tickers]\n",
    "\n",
    "        results, debug_output = run_walk_forward_step(\n",
    "            df_close_step, df_high_step, df_low_step,\n",
    "            start_date, calc_period, fwd_period, \n",
    "            metric, rank_start, rank_end, benchmark_ticker,\n",
    "            debug=debug\n",
    "        )\n",
    "        \n",
    "        if results['error']:\n",
    "            with ticker_list_output: print(f\"Error: {results['error']}\")\n",
    "            return\n",
    "\n",
    "        with fig.batch_update():\n",
    "            for i in range(max_traces):\n",
    "                trace = fig.data[i]\n",
    "                if i < len(results['tickers_to_display']):\n",
    "                    ticker = results['tickers_to_display'][i]\n",
    "                    plot_data_series = results['normalized_plot_data'][ticker]\n",
    "                    trace.x, trace.y, trace.name = plot_data_series.index, plot_data_series.values, ticker\n",
    "                    trace.visible, trace.showlegend = True, True\n",
    "                else: trace.visible, trace.showlegend = False, False\n",
    "            benchmark_trace = fig.data[max_traces]\n",
    "            if results['benchmark_price_series'] is not None and not results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']].dropna().empty:\n",
    "                normalized_benchmark = results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']] / results['benchmark_price_series'].loc[results['safe_start_date']:].bfill().iloc[0]\n",
    "                benchmark_trace.x, benchmark_trace.y = normalized_benchmark.index, normalized_benchmark\n",
    "                benchmark_trace.name = f\"Benchmark ({benchmark_ticker})\"; benchmark_trace.visible = True\n",
    "            else: benchmark_trace.visible = False\n",
    "            portfolio_trace = fig.data[max_traces + 1]\n",
    "            portfolio_trace.x, portfolio_trace.y = results['portfolio_series'].index, results['portfolio_series']\n",
    "            portfolio_trace.name = 'Group Portfolio'; portfolio_trace.visible = True\n",
    "            fig.layout.shapes = []; fig.add_shape(type=\"line\", x0=results['actual_calc_end_ts'], y0=0, x1=results['actual_calc_end_ts'], y1=1, xref='x', yref='paper', line=dict(color=\"grey\", width=2, dash=\"dash\"))\n",
    "            \n",
    "        results_container[0] = results\n",
    "        debug_data_container[0] = debug_output\n",
    "        \n",
    "        with ticker_list_output:\n",
    "            print(f\"Analysis Period: {results['safe_start_date'].date()} to {results['safe_viz_end_date'].date()}.\")\n",
    "            pprint.pprint(results['tickers_to_display'])\n",
    "            \n",
    "            # --- THIS IS THE CORRECTED, COMPLETE SECTION ---\n",
    "            p = results['performance_data']\n",
    "            rows = []\n",
    "            rows.append({'Metric': 'Group Portfolio Gain', 'Full': p['full_p_gain'], 'Calc': p['calc_p_gain'], 'Fwd': p['fwd_p_gain']})\n",
    "            if not np.isnan(p['full_b_gain']):\n",
    "                rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Gain', 'Full': p['full_b_gain'], 'Calc': p['calc_b_gain'], 'Fwd': p['fwd_b_gain']})\n",
    "                rows.append({'Metric': 'Gain Delta (vs Bm)', 'Full': p['full_p_gain'] - p['full_b_gain'], 'Calc': p['calc_p_gain'] - p['calc_b_gain'], 'Fwd': p['fwd_p_gain'] - p['fwd_b_gain']})\n",
    "            rows.append({'Metric': 'Group Portfolio Sharpe', 'Full': p['full_p_sharpe'], 'Calc': p['calc_p_sharpe'], 'Fwd': p['fwd_p_sharpe']})\n",
    "            if not np.isnan(p['full_b_sharpe']):\n",
    "                rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Sharpe', 'Full': p['full_b_sharpe'], 'Calc': p['calc_b_sharpe'], 'Fwd': p['fwd_b_sharpe']})\n",
    "                rows.append({'Metric': 'Sharpe Delta (vs Bm)', 'Full': p['full_p_sharpe'] - p['full_b_sharpe'], 'Calc': p['calc_p_sharpe'] - p['calc_b_sharpe'], 'Fwd': p['fwd_p_sharpe'] - p['fwd_b_sharpe']})\n",
    "            report_df = pd.DataFrame(rows).set_index('Metric')\n",
    "            gain_rows = [row for row in report_df.index if 'Gain' in row or 'Delta' in row]\n",
    "            sharpe_rows = [row for row in report_df.index if 'Sharpe' in row]\n",
    "            styled_df = report_df.style.format('{:+.2%}', na_rep='N/A', subset=(gain_rows, report_df.columns)).format('{:+.2f}', na_rep='N/A', subset=(sharpe_rows, report_df.columns)).set_properties(**{'text-align': 'right', 'width': '100px'}).set_table_styles([{'selector': 'th.col_heading', 'props': [('text-align', 'right')]}, {'selector': 'th.row_heading', 'props': [('text-align', 'left')]}])\n",
    "            print(\"\\n--- Strategy Performance Summary ---\")\n",
    "            display(styled_df)\n",
    "            # --- END OF CORRECTED SECTION ---\n",
    "            \n",
    "    fig.update_layout(title_text='Walk-Forward Performance Analysis', xaxis_title='Date', yaxis_title='Normalized Price (Start = 1)', hovermode='x unified', legend_title_text='Tickers (Ranked)', height=600, margin=dict(t=50))\n",
    "    fig.add_hline(y=1, line_width=1, line_dash=\"dash\", line_color=\"grey\")\n",
    "    update_button.on_click(update_plot)\n",
    "    controls_row1 = widgets.HBox([start_date_picker, calc_period_dropdown, fwd_period_dropdown])\n",
    "    controls_row2 = widgets.HBox([metric_dropdown, rank_start_dropdown, rank_end_dropdown, benchmark_ticker_input, update_button])\n",
    "    ui_container = widgets.VBox([controls_row1, controls_row2, ticker_list_output], layout=widgets.Layout(margin='10px 0 20px 0'))\n",
    "    display(ui_container, fig)\n",
    "    update_plot(None)\n",
    "    \n",
    "    return (results_container, debug_data_container)\n",
    "\n",
    "\n",
    "def run_full_backtest(df_ohlcv, strategy_params, quality_thresholds):\n",
    "    print(f\"--- Running Full Forensic Backtest ---\")\n",
    "    start_date, end_date = strategy_params['start_date'], strategy_params['end_date']\n",
    "    calc_period_str, fwd_period_str = strategy_params['calc_period'], strategy_params['fwd_period']\n",
    "    metric, rank_start, rank_end = strategy_params['metric'], strategy_params['rank_start'], strategy_params['rank_end']\n",
    "    benchmark_ticker = strategy_params['benchmark_ticker']\n",
    "    \n",
    "    quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "    df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "    df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "    df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "\n",
    "    period_options = {'3M': pd.DateOffset(months=3), '6M': pd.DateOffset(months=6), '1Y': pd.DateOffset(years=1)}\n",
    "    calc_period, fwd_period = period_options[calc_period_str], period_options[fwd_period_str]\n",
    "    \n",
    "    step_dates = pd.date_range(start=start_date, end=end_date, freq=f'{fwd_period.months}ME')\n",
    "    all_fwd_gains, period_by_period_debug = [], {}\n",
    "\n",
    "    print(f\"Simulating {len(step_dates)} periods...\")\n",
    "    for step_date in tqdm(step_dates, desc=\"Backtest Progress\"):\n",
    "        eligible_tickers = get_eligible_universe(quality_metrics_df, step_date, quality_thresholds)\n",
    "        if not eligible_tickers: continue\n",
    "        \n",
    "        df_close_step, df_high_step, df_low_step = df_close_full[eligible_tickers], df_high_full[eligible_tickers], df_low_full[eligible_tickers]\n",
    "        \n",
    "        results, debug_output = run_walk_forward_step(\n",
    "            df_close_step, df_high_step, df_low_step, step_date, calc_period, fwd_period,\n",
    "            metric, rank_start, rank_end, benchmark_ticker, debug=True\n",
    "        )\n",
    "        \n",
    "        if results['error'] is None:\n",
    "            fwd_series = results['portfolio_series'].loc[results['actual_calc_end_ts']:]\n",
    "            all_fwd_gains.append(fwd_series.pct_change().dropna())\n",
    "            period_by_period_debug[step_date.date().isoformat()] = debug_output\n",
    "            \n",
    "    if not all_fwd_gains:\n",
    "        print(\"Error: No valid periods were simulated.\"); return None\n",
    "\n",
    "    strategy_returns = pd.concat(all_fwd_gains)\n",
    "    strategy_equity_curve = (1 + strategy_returns).cumprod()\n",
    "    benchmark_returns = df_close_full[benchmark_ticker].pct_change().loc[strategy_equity_curve.index]\n",
    "    benchmark_equity_curve = (1 + benchmark_returns).cumprod()\n",
    "    \n",
    "    cumulative_equity_df = pd.DataFrame({'Strategy_Equity': strategy_equity_curve, 'Benchmark_Equity': benchmark_equity_curve})\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=cumulative_equity_df.index, y=cumulative_equity_df['Strategy_Equity'], name='Strategy', line=dict(color='green')))\n",
    "    fig.add_trace(go.Scatter(x=cumulative_equity_df.index, y=cumulative_equity_df['Benchmark_Equity'], name=f'Benchmark ({benchmark_ticker})', line=dict(color='black', dash='dash')))\n",
    "    fig.update_layout(title=f\"Cumulative Performance: '{metric}' Strategy (Top {rank_start}-{rank_end})\", xaxis_title=\"Date\", yaxis_title=\"Cumulative Growth\")\n",
    "    fig.show()\n",
    "\n",
    "    final_backtest_results = {'cumulative_performance': cumulative_equity_df, 'period_by_period_debug': period_by_period_debug}\n",
    "    print(\"\\n✅ Full backtest complete.\")\n",
    "    return final_backtest_results\n",
    "\n",
    "\n",
    "# --- E. VERIFICATION TOOLS ---\n",
    "\n",
    "def verify_group_tickers_walk_forward_calculation(df_ohlcv, tickers_to_verify, benchmark_ticker,\n",
    "                                                  start_date, calc_period, fwd_period, export_csv=False):\n",
    "    # This function is unchanged\n",
    "    display(Markdown(f\"## Verification Report for Portfolio vs. Benchmark\"))\n",
    "    display(Markdown(f\"**Portfolio Tickers:** `{tickers_to_verify}`\"))\n",
    "    display(Markdown(f\"**Benchmark Ticker:** `{benchmark_ticker}`\"))\n",
    "    period_options = { '1M': pd.DateOffset(months=1), '3M': pd.DateOffset(months=3), '6M': pd.DateOffset(months=6), '1Y': pd.DateOffset(years=1), '0D': pd.DateOffset(days=0), '1W': pd.DateOffset(weeks=1), '2W': pd.DateOffset(weeks=2) }\n",
    "    df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "    start_date_ts = pd.to_datetime(start_date)\n",
    "    calc_offset = period_options[calc_period]; fwd_offset = period_options[fwd_period]\n",
    "    calc_end_date_ts_theoretical = start_date_ts + calc_offset\n",
    "    fwd_end_date_ts_theoretical = calc_end_date_ts_theoretical + fwd_offset\n",
    "    actual_calc_end_ts = df_close_full.loc[start_date_ts:calc_end_date_ts_theoretical].index.max()\n",
    "    display(Markdown(f\"**Analysis Start Date:** `{start_date_ts.date()}`\"))\n",
    "    display(Markdown(f\"**Calculation Period End Date:** `{actual_calc_end_ts.date()}`\"))\n",
    "    display(Markdown(f\"**Forward Period End Date:** `{fwd_end_date_ts_theoretical.date()}`\"))\n",
    "    portfolio_prices_raw_slice = df_close_full[tickers_to_verify].loc[start_date_ts:fwd_end_date_ts_theoretical]\n",
    "    normalized_portfolio_prices = portfolio_prices_raw_slice.div(portfolio_prices_raw_slice.bfill().iloc[0])\n",
    "    portfolio_value_series = normalized_portfolio_prices.mean(axis=1)\n",
    "    try: benchmark_price_series = df_close_full[benchmark_ticker]\n",
    "    except KeyError as e: print(f\"---! ERROR: Ticker {e} not found !---\"); return\n",
    "\n",
    "    def print_verification_steps(title, price_series):\n",
    "        display(Markdown(f\"#### Verification for: `{title}`\"))\n",
    "        if price_series.dropna().shape[0] < 2: print(\"  - Not enough data points.\"); return {'gain': np.nan, 'sharpe': np.nan}\n",
    "        start_price = price_series.bfill().iloc[0]; end_price = price_series.ffill().iloc[-1]\n",
    "        gain = (end_price / start_price) - 1\n",
    "        print(f\"  - Start Value (on {price_series.first_valid_index().date()}): {start_price:,.4f}\\n  - End Value   (on {price_series.last_valid_index().date()}): {end_price:,.4f}\\n  - Gain = ({end_price:,.4f} / {start_price:,.4f}) - 1 = {gain:.2%}\")\n",
    "        returns = price_series.pct_change()\n",
    "        mean_return = returns.mean(); std_return = returns.std()\n",
    "        sharpe = (mean_return / std_return * np.sqrt(252)) if std_return > 0 and std_return != np.inf else np.nan\n",
    "        print(f\"\\n  - Mean Daily Return: {mean_return:.6f}\\n  - Std Dev of Daily Return: {std_return:.6f}\\n  - Sharpe = ({mean_return:.6f} / {std_return:.6f}) * sqrt(252) = {sharpe:.2f}\")\n",
    "        return {'gain': gain, 'sharpe': sharpe}\n",
    "\n",
    "    display(Markdown(\"### A. Calculation Period Analysis ('In-Sample')\"))\n",
    "    perf_calc_p = print_verification_steps(\"Group Portfolio\", portfolio_value_series.loc[start_date_ts:actual_calc_end_ts])\n",
    "    perf_calc_b = print_verification_steps(f\"Benchmark ({benchmark_ticker})\", benchmark_price_series.loc[start_date_ts:actual_calc_end_ts])\n",
    "    display(Markdown(\"\\n### B. Forward Period Analysis ('Moment of Truth')\"))\n",
    "    perf_fwd_p = print_verification_steps(\"Group Portfolio\", portfolio_value_series.loc[actual_calc_end_ts:fwd_end_date_ts_theoretical])\n",
    "    perf_fwd_b = print_verification_steps(f\"Benchmark ({benchmark_ticker})\", benchmark_price_series.loc[actual_calc_end_ts:fwd_end_date_ts_theoretical])\n",
    "    display(Markdown(\"\\n### C. Full Period Analysis (Total)\"))\n",
    "    perf_full_p = print_verification_steps(\"Group Portfolio\", portfolio_value_series)\n",
    "    perf_full_b = print_verification_steps(f\"Benchmark ({benchmark_ticker})\", benchmark_price_series.loc[start_date_ts:fwd_end_date_ts_theoretical])\n",
    "    display(Markdown(\"\\n### D. Final Summary Table (matches analyzer output)\"))\n",
    "    rows = []\n",
    "    rows.append({'Metric': 'Group Portfolio Gain', 'Full': perf_full_p['gain'], 'Calc': perf_calc_p['gain'], 'Fwd': perf_fwd_p['gain']})\n",
    "    rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Gain', 'Full': perf_full_b['gain'], 'Calc': perf_calc_b['gain'], 'Fwd': perf_fwd_b['gain']})\n",
    "    rows.append({'Metric': 'Gain Delta (vs Bm)', 'Full': perf_full_p['gain'] - perf_full_b['gain'], 'Calc': perf_calc_p['gain'] - perf_calc_b['gain'], 'Fwd': perf_fwd_p['gain'] - perf_fwd_b['gain']})\n",
    "    rows.append({'Metric': 'Group Portfolio Sharpe', 'Full': perf_full_p['sharpe'], 'Calc': perf_calc_p['sharpe'], 'Fwd': perf_fwd_p['sharpe']})\n",
    "    rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Sharpe', 'Full': perf_full_b['sharpe'], 'Calc': perf_calc_b['sharpe'], 'Fwd': perf_fwd_b['sharpe']})\n",
    "    rows.append({'Metric': 'Sharpe Delta (vs Bm)', 'Full': perf_full_p['sharpe'] - perf_full_b['sharpe'], 'Calc': perf_calc_p['sharpe'] - perf_calc_b['sharpe'], 'Fwd': perf_fwd_p['sharpe'] - perf_fwd_b['sharpe']})\n",
    "    report_df = pd.DataFrame(rows).set_index('Metric')\n",
    "    gain_rows = [row for row in report_df.index if 'Gain' in row or 'Delta' in row]\n",
    "    sharpe_rows = [row for row in report_df.index if 'Sharpe' in row]\n",
    "    styled_df = report_df.style.format('{:+.2%}', na_rep='N/A', subset=(gain_rows, report_df.columns)).format('{:+.2f}', na_rep='N/A', subset=(sharpe_rows, report_df.columns)).set_properties(**{'text-align': 'right', 'width': '100px'}).set_table_styles([{'selector': 'th.col_heading', 'props': [('text-align', 'right')]}, {'selector': 'th.row_heading', 'props': [('text-align', 'left')]}])\n",
    "    display(styled_df)\n",
    "    if export_csv:\n",
    "        export_df = pd.DataFrame({'Portfolio_Value_Normalized': portfolio_value_series, 'Portfolio_Return': portfolio_value_series.pct_change(), f'Benchmark_Price_{benchmark_ticker}': benchmark_price_series})\n",
    "        filename = f\"verification_group_tickers_{start_date_ts.strftime('%Y%m%d')}.csv\"\n",
    "        export_df.to_csv(filename, float_format='%.6f')\n",
    "        print(f\"\\n✅ Detailed group verification data exported to '{filename}'\")\n",
    "\n",
    "def verify_ticker_ranking_metrics(df_ohlcv, \n",
    "                                  ticker, \n",
    "                                  start_date, \n",
    "                                  calc_period, \n",
    "                                  fwd_period, \n",
    "                                  export_csv=False):\n",
    "    display(Markdown(f\"## Verification Report for Ticker Ranking: `{ticker}`\"))\n",
    "    period_options = { '1M': pd.DateOffset(months=1), '3M': pd.DateOffset(months=3), '6M': pd.DateOffset(months=6), '1Y': pd.DateOffset(years=1), '0D': pd.DateOffset(days=0), '1W': pd.DateOffset(weeks=1), '2W': pd.DateOffset(weeks=2) }\n",
    "    try: df_ticker = df_ohlcv.loc[ticker].sort_index()\n",
    "    except KeyError: print(f\"---! ERROR: Ticker '{ticker}' not found !---\"); return\n",
    "    start_date_ts = pd.to_datetime(start_date)\n",
    "    calc_offset = period_options[calc_period]; fwd_offset = period_options[fwd_period]\n",
    "    calc_end_date_ts = start_date_ts + calc_offset; fwd_end_date_ts = calc_end_date_ts + fwd_offset\n",
    "    display(Markdown(f\"**Analysis Start Date:** `{start_date_ts.date()}`\"))\n",
    "    display(Markdown(f\"**Requested Calculation Period:** `{start_date_ts.date()}` to `{calc_end_date_ts.date()}`\"))\n",
    "    display(Markdown(f\"**Requested Forward Period:**   `{calc_end_date_ts.date()}` to `{fwd_end_date_ts.date()}`\"))\n",
    "    display(Markdown(\"### A. Calculation Period Analysis (for Ranking Metrics)\"))\n",
    "    calc_df = df_ticker.loc[start_date_ts:calc_end_date_ts].copy()\n",
    "    if calc_df['Adj Close'].notna().sum() < 2: print(\"\\n---! ERROR: Not enough data points !---\"); return\n",
    "    actual_calc_end_date = calc_df.index.max().date()\n",
    "    display(Markdown(f\"**Actual Dates Used:** `{calc_df.index.min().date()}` to `{actual_calc_end_date}`\"))\n",
    "    calc_gain = calculate_gain(calc_df['Adj Close'])\n",
    "    calc_start_price = calc_df['Adj Close'].bfill().iloc[0]\n",
    "    calc_end_price = calc_df['Adj Close'].ffill().iloc[-1]\n",
    "    display(Markdown(\"#### `CalcGain` Verification:\"))\n",
    "    print(f\"  - Calc Start Price: ${calc_start_price:.2f}\\n  - Calc End Price:   ${calc_end_price:.2f}  <-- 'CalcPrice'\\n  - CalcGain = {calc_gain:.2%}\")\n",
    "    display(Markdown(\"#### `MetricValue` Verification:\"))\n",
    "    price_metric = (calc_end_price / calc_start_price)\n",
    "    print(f\"\\n1. Price Metric:\\n   - Formula: Last Price / First Price = {price_metric:.4f}\")\n",
    "    daily_returns = calc_df['Adj Close'].bfill().ffill().pct_change()\n",
    "    sharpe_ratio = calculate_sharpe(daily_returns)\n",
    "    print(f\"\\n2. Sharpe Metric:\\n   - Mean Daily Return: {daily_returns.mean():.6f}\\n   - Std Dev Daily Return: {daily_returns.std():.6f}\\n   - Annualized Sharpe = {sharpe_ratio:.4f}\")\n",
    "    print(f\"\\n3. Sharpe (ATR) Metric:\")\n",
    "    tr = np.maximum(calc_df['Adj High'] - calc_df['Adj Low'], abs(calc_df['Adj High'] - calc_df['Adj Close'].shift(1)), abs(calc_df['Adj Low'] - calc_df['Adj Close'].shift(1)))\n",
    "    atr = tr.ewm(alpha=1/14, adjust=False).mean()\n",
    "    atrp_series = atr / calc_df['Adj Close']\n",
    "    atrp_mean = atrp_series.mean()\n",
    "    sharpe_atr = (daily_returns.mean() / atrp_mean) if atrp_mean > 0 else 0\n",
    "    print(f\"   - Mean Daily Return: {daily_returns.mean():.6f} (same as above)\\n   - Average ATR Percent (ATRP): {atrp_mean:.6f}\\n   - Sharpe (ATR) = {sharpe_atr:.4f}\")\n",
    "    display(Markdown(\"\\n### B. Forward Period Analysis (`FwdGain`)\"))\n",
    "    fwd_df = df_ticker.loc[actual_calc_end_date:fwd_end_date_ts].copy()\n",
    "    fwd_gain = calculate_gain(fwd_df['Adj Close'])\n",
    "    fwd_end_price = fwd_df['Adj Close'].ffill().iloc[-1] if fwd_gain is not np.nan else calc_end_price\n",
    "    print(f\"  - Fwd Start Price (Calc End Price): ${calc_end_price:.2f}\\n  - Fwd End Price: ${fwd_end_price:.2f}\\n  - FwdGain = {fwd_gain:.2%}\")\n",
    "    display(Markdown(\"\\n### C. Final Summary Table\"))\n",
    "    summary_data = {'Metric': ['Price', 'Sharpe', 'Sharpe (ATR)'], 'Calculated Value': [f\"{price_metric:.4f}\", f\"{sharpe_ratio:.4f}\", f\"{sharpe_atr:.4f}\"], 'Corresponds To': ['`MetricValue`', '`MetricValue`', '`MetricValue`'], '---': ['---','---','---'], 'Gain Metric': ['Calc Period Gain', 'Forward Period Gain'], 'Gain Value': [f\"{calc_gain:.2%}\", f\"{fwd_gain:.2%}\"], 'Gain Corresponds To': ['`CalcGain`', '`FwdGain`']}\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    display(summary_df.style.hide(axis=\"index\"))\n",
    "    \n",
    "    if export_csv:\n",
    "        calc_df['Period'] = 'Calculation'; calc_df['Daily_Return'] = daily_returns; calc_df['True_Range'] = tr; calc_df['ATR_14'] = atr; calc_df['ATRP'] = atrp_series\n",
    "        fwd_df['Period'] = 'Forward'\n",
    "        combined_df = pd.concat([calc_df, fwd_df.iloc[1:]])\n",
    "        filename = f\"verification_ticker_{ticker}_{start_date_ts.strftime('%Y%m%d')}.csv\"\n",
    "        combined_df.to_csv(filename, float_format='%.6f')\n",
    "        print(f\"\\n✅ Detailed ticker data exported to '{filename}'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "916dd29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 4036635 entries, ('A', Timestamp('1999-11-18 00:00:00')) to ('ZWS', Timestamp('2025-10-06 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   Adj Open   float64\n",
      " 1   Adj High   float64\n",
      " 2   Adj Low    float64\n",
      " 3   Adj Close  float64\n",
      " 4   Volume     int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 170.0+ MB\n",
      "df_OHLCV.info() :\n",
      "None\n",
      "\n",
      "df_OHLCV.head():\n",
      "                   Adj Open  Adj High  Adj Low  Adj Close    Volume\n",
      "Ticker Date                                                        \n",
      "A      1999-11-18   27.2452   29.9398  23.9518    26.3470  74716422\n",
      "       1999-11-19   25.7108   25.7482  23.8396    24.1764  18198351\n",
      "       1999-11-22   24.7378   26.3470  23.9893    26.3470   7857767\n",
      "       1999-11-23   25.4488   26.1225  23.9518    23.9518   7138322\n",
      "       1999-11-24   24.0267   25.1120  23.9518    24.5881   5785607\n",
      "\n",
      "df_OHLCV.tail():\n",
      "                   Adj Open  Adj High  Adj Low  Adj Close  Volume\n",
      "Ticker Date                                                      \n",
      "ZWS    2025-09-30     46.90     47.40    46.77      47.03  609500\n",
      "       2025-10-01     46.72     47.04    46.40      46.80  599400\n",
      "       2025-10-02     46.86     47.17    46.54      46.91  839900\n",
      "       2025-10-03     46.87     47.37    46.62      46.84  780500\n",
      "       2025-10-06     47.16     47.37    46.67      47.29  661018\n"
     ]
    }
   ],
   "source": [
    "download_path = Path.home() / \"Downloads\"  \n",
    "# OHLCV_file_path = r'c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_clean_stocks_etfs.parquet'\n",
    "OHLCV_file_path = r'c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet'\n",
    "\n",
    "df_OHLCV = pd.read_parquet(OHLCV_file_path, engine='pyarrow')\n",
    "print(f'df_OHLCV.info() :\\n{df_OHLCV.info()}')\n",
    "print(f'\\ndf_OHLCV.head():\\n{df_OHLCV.head()}')\n",
    "print(f'\\ndf_OHLCV.tail():\\n{df_OHLCV.tail()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8de3243",
   "metadata": {},
   "source": [
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ca33d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data on: 2018-12-31\n",
      "========================================\n",
      "\n",
      "--- In-Sample (IS) 'Discovery Zone' Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 2702881 entries, ('A', Timestamp('1999-11-18 00:00:00')) to ('ZWS', Timestamp('2018-12-31 00:00:00'))\n",
      "Columns: 5 entries, Adj Open to Volume\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 114.1 MB\n",
      "IS Date Range: 1962-01-02 to 2018-12-31\n",
      "IS Shape: (2702881, 5)\n",
      "Percentage of IS data: 66.96%\n",
      "\n",
      "--- Out-of-Sample (OOS) 'Validation Zone' Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 1333754 entries, ('A', Timestamp('2019-01-02 00:00:00')) to ('ZWS', Timestamp('2025-10-06 00:00:00'))\n",
      "Columns: 5 entries, Adj Open to Volume\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 56.7 MB\n",
      "OOS Date Range: 2019-01-02 to 2025-10-06\n",
      "OOS Shape: (1333754, 5)\n",
      "Percentage of OOS data: 33.04%\n",
      "\n",
      "Verification: 2702881 (IS) + 1333754 (OOS) = 4036635 rows.\n",
      "Original total rows: 4036635 rows. Match: True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# --- 2. DEFINE THE SPLIT DATE ---\n",
    "# This is the last day of our In-Sample (IS) \"Discovery Zone\".\n",
    "split_date = pd.to_datetime('2018-12-31')\n",
    "\n",
    "print(f\"Splitting data on: {split_date.date()}\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "\n",
    "# --- 3. PERFORM THE SPLIT ---\n",
    "# We access the 'Date' level of the MultiIndex to create our boolean masks.\n",
    "\n",
    "# In-Sample (IS) DataFrame: Data for discovery and training the bot.\n",
    "df_IS = df_OHLCV[df_OHLCV.index.get_level_values('Date') <= split_date].copy()\n",
    "\n",
    "# Out-of-Sample (OOS) DataFrame: Data held back for final validation.\n",
    "df_OOS = df_OHLCV[df_OHLCV.index.get_level_values('Date') > split_date].copy()\n",
    "\n",
    "# Using .copy() is good practice to avoid SettingWithCopyWarning later on.\n",
    "\n",
    "\n",
    "# --- 4. VERIFY THE SPLIT ---\n",
    "# Always check your work to ensure the split was done correctly.\n",
    "\n",
    "print(\"\\n--- In-Sample (IS) 'Discovery Zone' Info ---\")\n",
    "df_IS.info(verbose=False, memory_usage='deep') # Use verbose=False for a cleaner summary\n",
    "print(f\"IS Date Range: {df_IS.index.get_level_values('Date').min().date()} to {df_IS.index.get_level_values('Date').max().date()}\")\n",
    "print(f\"IS Shape: {df_IS.shape}\")\n",
    "print(f\"Percentage of IS data: {df_IS.shape[0] / df_OHLCV.shape[0]:.2%}\")\n",
    "\n",
    "print(\"\\n--- Out-of-Sample (OOS) 'Validation Zone' Info ---\")\n",
    "df_OOS.info(verbose=False, memory_usage='deep')\n",
    "print(f\"OOS Date Range: {df_OOS.index.get_level_values('Date').min().date()} to {df_OOS.index.get_level_values('Date').max().date()}\")\n",
    "print(f\"OOS Shape: {df_OOS.shape}\")\n",
    "print(f\"Percentage of OOS data: {df_OOS.shape[0] / df_OHLCV.shape[0]:.2%}\")\n",
    "\n",
    "# Final check\n",
    "total_rows = df_IS.shape[0] + df_OOS.shape[0]\n",
    "print(f\"\\nVerification: {df_IS.shape[0]} (IS) + {df_OOS.shape[0]} (OOS) = {total_rows} rows.\")\n",
    "print(f\"Original total rows: {df_OHLCV.shape[0]} rows. Match: {total_rows == df_OHLCV.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf196a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Creating Development Sandbox DataFrame (Corrected) ---\n",
      "Slicing df_IS from 2014-01-01 to 2018-12-31\n",
      "============================================================\n",
      "\n",
      "--- Development Sandbox (df_dev) Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 778000 entries, ('A', Timestamp('2014-01-02 00:00:00')) to ('ZWS', Timestamp('2018-12-31 00:00:00'))\n",
      "Columns: 5 entries, Adj Open to Volume\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 33.4 MB\n",
      "df_dev Date Range: 2014-01-02 to 2018-12-31\n",
      "df_dev Shape: (778000, 5)\n",
      "df_dev as percentage of IS data: 28.78%\n",
      "============================================================\n",
      "\n",
      "Found 668 unique tickers in df_dev.\n",
      "First 10 unique tickers:\n",
      "['A', 'AAL', 'ABBV', 'ABT', 'ACM', 'ACN', 'ACWI', 'ACWX', 'ADBE', 'ADI']\n",
      "\n",
      "Last 10 unique tickers:\n",
      "['XYL', 'XYZ', 'YUM', 'Z', 'ZBH', 'ZBRA', 'ZG', 'ZS', 'ZTS', 'ZWS']\n"
     ]
    }
   ],
   "source": [
    "# This code REPLACES the previous df_dev creation snippet.\n",
    "# It should still be placed after df_IS and df_OOS are created.\n",
    "\n",
    "# --- 5. (CORRECTED) CREATE A SMALLER \"DEVELOPMENT SANDBOX\" DATAFRAME ---\n",
    "# We use a RECENT 5-year slice of our In-Sample data for rapid development.\n",
    "# This is much faster and more representative of modern data.\n",
    "\n",
    "dev_start_date = pd.to_datetime('2014-01-01')\n",
    "dev_end_date = pd.to_datetime('2018-12-31') # This is the end of our df_IS period\n",
    "\n",
    "print(\"\\n--- Creating Development Sandbox DataFrame (Corrected) ---\")\n",
    "print(f\"Slicing df_IS from {dev_start_date.date()} to {dev_end_date.date()}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create the development dataframe by slicing the main In-Sample data\n",
    "df_dev = df_IS[(df_IS.index.get_level_values('Date') >= dev_start_date) &\n",
    "               (df_IS.index.get_level_values('Date') <= dev_end_date)].copy()\n",
    "\n",
    "\n",
    "# --- 6. VERIFY THE (CORRECTED) DEVELOPMENT DATAFRAME ---\n",
    "print(\"\\n--- Development Sandbox (df_dev) Info ---\")\n",
    "df_dev.info(verbose=False, memory_usage='deep')\n",
    "print(f\"df_dev Date Range: {df_dev.index.get_level_values('Date').min().date()} to {df_dev.index.get_level_values('Date').max().date()}\")\n",
    "print(f\"df_dev Shape: {df_dev.shape}\")\n",
    "print(f\"df_dev as percentage of IS data: {df_dev.shape[0] / df_IS.shape[0]:.2%}\")\n",
    "\n",
    "# --- Get unique tickers from the 'Ticker' level of the MultiIndex ---\n",
    "\n",
    "# Get the 'Ticker' level of the index\n",
    "ticker_index = df_dev.index.get_level_values('Ticker')\n",
    "\n",
    "# Get the unique values from that level\n",
    "unique_tickers = ticker_index.unique()\n",
    "\n",
    "# Print the results\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nFound {len(unique_tickers)} unique tickers in df_dev.\")\n",
    "print(\"First 10 unique tickers:\")\n",
    "print(unique_tickers[:10].tolist()) # .tolist() gives a cleaner printout for a slice\n",
    "print(\"\\nLast 10 unique tickers:\")\n",
    "print(unique_tickers[-10:].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87a8d237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Bot Configuration Initialized ---\n",
      "Number of unique parameter combinations: 8\n",
      "Estimated number of time steps: 20\n",
      "Total simulations to run: 160\n"
     ]
    }
   ],
   "source": [
    "# --- 7. BOT CONFIGURATION MANAGER (UPDATED) ---\n",
    "\n",
    "bot_config = {\n",
    "    # --- Time Parameters ---\n",
    "    'search_start_date': '2014-01-01',\n",
    "    'search_end_date': '2018-12-31',\n",
    "    # MODIFICATION: Changed '3M' to '3ME' for Month-End frequency to resolve deprecation warning.\n",
    "    'step_frequency': '3ME',\n",
    "\n",
    "    # --- Strategy Parameters (The Search Grid) ---\n",
    "    'calc_periods': ['6M', '1Y'],\n",
    "    'fwd_periods': ['3M'], \n",
    "    'metrics': ['Sharpe', 'Sharpe (ATR)'],\n",
    "    'rank_slices': [\n",
    "        (1, 10),\n",
    "        (11, 30),\n",
    "    ],\n",
    "\n",
    "    # --- Data Quality Filter Parameters within Rolling Window---\n",
    "    'quality_thresholds': {\n",
    "        'min_median_dollar_volume': 10_000_000,  # $10 mil trading volume\n",
    "        'max_stale_pct': 0.05,  # 5% either Volume = 0, or High = Low\n",
    "        'max_same_vol_count': 1,  # max 1 day with consecutive Volume\n",
    "    },\n",
    "\n",
    "    # --- General Parameters ---\n",
    "    'benchmark_ticker': 'VOO',\n",
    "    'results_output_path': './export_csv/dev_strategy_search_results.csv'\n",
    "}\n",
    "\n",
    "\n",
    "# --- Let's quickly calculate how many simulations this configuration will run ---\n",
    "from itertools import product\n",
    "\n",
    "num_param_sets = len(list(product(\n",
    "    bot_config['calc_periods'],\n",
    "    bot_config['fwd_periods'],\n",
    "    bot_config['metrics'],\n",
    "    bot_config['rank_slices']\n",
    ")))\n",
    "\n",
    "# Estimate the number of time steps\n",
    "time_steps = pd.date_range(\n",
    "    start=bot_config['search_start_date'],\n",
    "    end=bot_config['search_end_date'],\n",
    "    freq=bot_config['step_frequency']\n",
    ")\n",
    "\n",
    "print(\"\\n--- Bot Configuration Initialized ---\")\n",
    "print(f\"Number of unique parameter combinations: {num_param_sets}\")\n",
    "print(f\"Estimated number of time steps: {len(time_steps)}\")\n",
    "print(f\"Total simulations to run: {num_param_sets * len(time_steps)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428ee7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_walk_forward_analyzer_original_v0(\n",
    "#     df_ohlcv=df_OHLCV,  # CRITICAL: Use the same df_dev as the bot\n",
    "#     default_start_date='2017-04-30',\n",
    "#     default_calc_period='6M',\n",
    "#     default_fwd_period='3M',\n",
    "#     default_metric='Sharpe (ATR)',\n",
    "#     default_rank_start=1,\n",
    "#     default_rank_end=10,\n",
    "#     default_benchmark_ticker='VOO'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92dc545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_walk_forward_analyzer_v1(\n",
    "#     df_ohlcv=df_OHLCV,  # CRITICAL: Use the same df_dev as the bot\n",
    "#     default_start_date='2017-04-30',\n",
    "#     default_calc_period='6M',\n",
    "#     default_fwd_period='3M',\n",
    "#     default_metric='Sharpe (ATR)',\n",
    "#     default_rank_start=1,\n",
    "#     default_rank_end=10,\n",
    "#     default_benchmark_ticker='VOO'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f90dd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_walk_forward_analyzer(\n",
    "#     df_ohlcv=df_OHLCV,  # CRITICAL: Use the same df_dev as the bot\n",
    "#     default_start_date='2017-04-30',\n",
    "#     default_calc_period='6M',\n",
    "#     default_fwd_period='3M',\n",
    "#     default_metric='Sharpe (ATR)',\n",
    "#     default_rank_start=1,\n",
    "#     default_rank_end=10,\n",
    "#     default_benchmark_ticker='VOO'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "136212d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Walk-Forward Analyzer (with Dynamic Universe Filtering)...\n",
      "Pre-calculating data quality metrics...\n",
      "--- Calculating Rolling Quality Metrics (Window: 252 days) ---\n",
      "✅ Rolling metrics calculation complete.\n",
      "Pre-processing data (unstacking)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c75a6a11bcd4e2198d1e40f89b19fda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(DatePicker(value=Timestamp('2017-04-30 00:00:00'), description='Start Date:', st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3084c88aa4e94162a433d1c2ba0a0a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines',\n",
       "              'name': 'placeholder_0',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f0350020-6a18-4fd8-8ee3-7757534ccbae',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_1',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '7662e5ce-bbf7-48be-abb9-966f5ba6b3ea',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_2',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'cb6b42c2-a45b-461f-b2ca-5da6141686fa',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_3',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '327276e2-f67e-40a2-a2c6-279308bcebb2',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_4',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '877a02f2-f3e9-4e38-a14d-319731f864f4',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_5',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '3e348b0d-e541-416a-816f-a1374a59cff6',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_6',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '8d056bfc-5218-4efe-b17a-7784f422e837',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_7',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4dfac3e0-f9c6-4858-8478-38e666b775f8',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_8',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd2a3bb8a-0121-4fec-98fc-db9ba4d3961b',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_9',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ef622847-76fc-406d-8072-e5985cc408ab',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_10',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '8b57347b-c86b-4b40-a426-011ada6c9605',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_11',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd549c37f-0957-4254-a1a9-eb3cb02fc365',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_12',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '9ffef497-d83b-4f2c-be3e-1d8c198831d3',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_13',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e7796eda-e022-422c-965d-00a1a1b38c00',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_14',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '5d2c4173-aadd-46b0-98c2-4ad5f73a81a7',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_15',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '0903240d-6713-4eeb-bfab-ed24753b88f5',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_16',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '3030aa68-adfa-42f5-93e2-2702ce7637ff',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_17',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '361b8286-f15e-441b-a9f6-3a1feacf006b',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_18',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c7892414-8bb8-4229-9f12-76a81175142f',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_19',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a4dd19d9-33c4-4e46-8893-df728d63fa78',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_20',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c8b24d1c-b021-4e89-9103-21aedf429255',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_21',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '938d48c6-2723-4ff9-9054-67af87359484',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_22',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '9f5872f5-9a90-4f5b-955f-abd84faa1258',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_23',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'fab73223-a988-4629-9fc3-5bc461de03f8',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_24',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '67dae467-a029-4f37-b67c-664720c24899',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_25',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '212931d5-ebcd-439a-8088-87aaec5106ee',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_26',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e8e10da7-d222-412a-9f1b-9ac49d91fcdf',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_27',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '1a02fd9b-d595-48f0-99bf-7d4878ccb896',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_28',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'bb8353da-9938-4edb-bb5e-f504c0f85c1d',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_29',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c4902b23-cd32-4942-a439-ded3f30ad200',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_30',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4cd65292-49e1-4be1-810e-60d381bcf2b1',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_31',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '900a0528-c259-4b26-be8a-ad3a45c40938',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_32',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '662b226c-5d3a-49d8-a64c-32356e3f3034',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_33',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e2c4aa84-fe71-4a59-8771-e39d7833e04d',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_34',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '1b3c13b6-103c-4653-a281-ef7aa3438d39',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_35',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'fb45d050-2d53-4083-8605-2a7c20c615d7',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_36',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '03c13162-bc57-4130-a438-01c85b6493d4',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_37',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a1e0fc2e-0abe-4fae-b6d7-a5b9272b3423',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_38',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a26cb29b-6b93-4a7b-83e4-0df88959b522',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_39',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'bf751022-6983-47eb-8713-3ad00cddd4fd',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_40',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '7e2004c1-6afe-4815-bbf4-6c4cb1083b16',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_41',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '6c951b54-2ff4-4b4d-b84f-646ae9723dcc',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_42',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c4bcfaa0-9cf1-4238-8350-2bde0f422b48',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_43',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '23b1333d-658f-4df1-a149-0b1616491438',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_44',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b888d818-3eff-44f0-957e-79b8b0373da2',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_45',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e0bc078f-b2d1-4e23-aa3d-02ebe6cb71b3',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_46',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f2dc2866-91b4-4922-ad50-ba4bdd01db39',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_47',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '102bb69a-bea6-4d7c-ad5c-b1f73e1d5352',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_48',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '6283ff81-d2f4-4272-b9d5-c641ae68fd7a',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_49',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '904491a2-1106-4abf-af32-7a7cc3637506',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': 'black', 'dash': 'dash', 'width': 3},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Benchmark',\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '152216c3-097c-49f6-938d-60577d803419',\n",
       "              'visible': True,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': 'green', 'width': 3},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Group Portfolio',\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a40a64de-8cfb-4b23-96c0-7cb3444b4308',\n",
       "              'visible': True,\n",
       "              'x': [None],\n",
       "              'y': [None]}],\n",
       "    'layout': {'height': 600,\n",
       "               'hovermode': 'x unified',\n",
       "               'legend': {'title': {'text': 'Tickers (Ranked)'}},\n",
       "               'margin': {'t': 50},\n",
       "               'shapes': [{'line': {'color': 'grey', 'dash': 'dash', 'width': 1},\n",
       "                           'type': 'line',\n",
       "                           'x0': 0,\n",
       "                           'x1': 1,\n",
       "                           'xref': 'x domain',\n",
       "                           'y0': 1,\n",
       "                           'y1': 1,\n",
       "                           'yref': 'y'}],\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Walk-Forward Performance Analysis'},\n",
       "               'xaxis': {'title': {'text': 'Date'}},\n",
       "               'yaxis': {'title': {'text': 'Normalized Price (Start = 1)'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ Info: Filter date 2017-04-30 not found. Using previous available date 2017-04-28.\n",
      "Dynamic Filter (2017-04-30): Kept 521 of 633 tickers.\n"
     ]
    }
   ],
   "source": [
    "results_container, debug_container = plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_dev,\n",
    "    default_start_date='2017-04-30',\n",
    "    default_calc_period='6M',\n",
    "    default_fwd_period='3M',\n",
    "    default_metric='Sharpe (ATR)',\n",
    "    default_rank_start=1,\n",
    "    default_rank_end=10,\n",
    "    default_benchmark_ticker='VOO',\n",
    "    quality_thresholds=bot_config['quality_thresholds'],\n",
    "    debug=True  # <-- Activate the new mode!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bacf183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Debug Data Successfully Captured ---\n",
      "\n",
      "--- [1] Ranking Metrics for all eligible stocks (Top 15 shown) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FirstPrice</th>\n",
       "      <th>LastPrice</th>\n",
       "      <th>MeanDailyReturn</th>\n",
       "      <th>StdDevDailyReturn</th>\n",
       "      <th>MeanATRP</th>\n",
       "      <th>Metric_Price</th>\n",
       "      <th>Metric_Sharpe</th>\n",
       "      <th>Metric_Sharpe (ATR)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALNY</th>\n",
       "      <td>55.36000</td>\n",
       "      <td>122.96000</td>\n",
       "      <td>0.007607</td>\n",
       "      <td>0.056048</td>\n",
       "      <td>0.042551</td>\n",
       "      <td>2.221098</td>\n",
       "      <td>2.154475</td>\n",
       "      <td>0.178770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FSLR</th>\n",
       "      <td>29.55000</td>\n",
       "      <td>60.43000</td>\n",
       "      <td>0.006114</td>\n",
       "      <td>0.031374</td>\n",
       "      <td>0.033147</td>\n",
       "      <td>2.045008</td>\n",
       "      <td>3.093505</td>\n",
       "      <td>0.184451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NTNX</th>\n",
       "      <td>14.46000</td>\n",
       "      <td>28.28000</td>\n",
       "      <td>0.005827</td>\n",
       "      <td>0.033045</td>\n",
       "      <td>0.045994</td>\n",
       "      <td>1.955740</td>\n",
       "      <td>2.799068</td>\n",
       "      <td>0.126682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XYZ</th>\n",
       "      <td>18.61000</td>\n",
       "      <td>35.75000</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>0.021781</td>\n",
       "      <td>0.030688</td>\n",
       "      <td>1.921010</td>\n",
       "      <td>3.927180</td>\n",
       "      <td>0.175588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVDA</th>\n",
       "      <td>2.62969</td>\n",
       "      <td>5.03632</td>\n",
       "      <td>0.005510</td>\n",
       "      <td>0.028149</td>\n",
       "      <td>0.031009</td>\n",
       "      <td>1.915176</td>\n",
       "      <td>3.107117</td>\n",
       "      <td>0.177678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOXL</th>\n",
       "      <td>5.00049</td>\n",
       "      <td>9.19817</td>\n",
       "      <td>0.005441</td>\n",
       "      <td>0.035272</td>\n",
       "      <td>0.043418</td>\n",
       "      <td>1.839454</td>\n",
       "      <td>2.448958</td>\n",
       "      <td>0.125327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALGN</th>\n",
       "      <td>133.68000</td>\n",
       "      <td>235.57000</td>\n",
       "      <td>0.004707</td>\n",
       "      <td>0.022377</td>\n",
       "      <td>0.021836</td>\n",
       "      <td>1.762193</td>\n",
       "      <td>3.339395</td>\n",
       "      <td>0.215572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTD</th>\n",
       "      <td>3.75900</td>\n",
       "      <td>6.42000</td>\n",
       "      <td>0.004943</td>\n",
       "      <td>0.039601</td>\n",
       "      <td>0.044826</td>\n",
       "      <td>1.707901</td>\n",
       "      <td>1.981568</td>\n",
       "      <td>0.110279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BABA</th>\n",
       "      <td>110.81000</td>\n",
       "      <td>172.44600</td>\n",
       "      <td>0.003670</td>\n",
       "      <td>0.019388</td>\n",
       "      <td>0.022177</td>\n",
       "      <td>1.556231</td>\n",
       "      <td>3.004514</td>\n",
       "      <td>0.165465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ETSY</th>\n",
       "      <td>11.06000</td>\n",
       "      <td>16.71000</td>\n",
       "      <td>0.003660</td>\n",
       "      <td>0.029454</td>\n",
       "      <td>0.032615</td>\n",
       "      <td>1.510850</td>\n",
       "      <td>1.972675</td>\n",
       "      <td>0.112226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PYPL</th>\n",
       "      <td>47.54000</td>\n",
       "      <td>71.15000</td>\n",
       "      <td>0.003272</td>\n",
       "      <td>0.013700</td>\n",
       "      <td>0.017117</td>\n",
       "      <td>1.496634</td>\n",
       "      <td>3.791929</td>\n",
       "      <td>0.191188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LITE</th>\n",
       "      <td>43.70000</td>\n",
       "      <td>64.75000</td>\n",
       "      <td>0.003618</td>\n",
       "      <td>0.032413</td>\n",
       "      <td>0.045134</td>\n",
       "      <td>1.481693</td>\n",
       "      <td>1.771740</td>\n",
       "      <td>0.080152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W</th>\n",
       "      <td>47.02000</td>\n",
       "      <td>69.66000</td>\n",
       "      <td>0.003629</td>\n",
       "      <td>0.033240</td>\n",
       "      <td>0.041999</td>\n",
       "      <td>1.481497</td>\n",
       "      <td>1.733180</td>\n",
       "      <td>0.086408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MU</th>\n",
       "      <td>27.61360</td>\n",
       "      <td>40.65420</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>0.022685</td>\n",
       "      <td>0.029110</td>\n",
       "      <td>1.472253</td>\n",
       "      <td>2.313449</td>\n",
       "      <td>0.113567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ON</th>\n",
       "      <td>14.35000</td>\n",
       "      <td>20.96000</td>\n",
       "      <td>0.003171</td>\n",
       "      <td>0.019290</td>\n",
       "      <td>0.026103</td>\n",
       "      <td>1.460627</td>\n",
       "      <td>2.609971</td>\n",
       "      <td>0.121498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        FirstPrice  LastPrice  MeanDailyReturn  StdDevDailyReturn  MeanATRP  \\\n",
       "Ticker                                                                        \n",
       "ALNY      55.36000  122.96000         0.007607           0.056048  0.042551   \n",
       "FSLR      29.55000   60.43000         0.006114           0.031374  0.033147   \n",
       "NTNX      14.46000   28.28000         0.005827           0.033045  0.045994   \n",
       "XYZ       18.61000   35.75000         0.005388           0.021781  0.030688   \n",
       "NVDA       2.62969    5.03632         0.005510           0.028149  0.031009   \n",
       "SOXL       5.00049    9.19817         0.005441           0.035272  0.043418   \n",
       "ALGN     133.68000  235.57000         0.004707           0.022377  0.021836   \n",
       "TTD        3.75900    6.42000         0.004943           0.039601  0.044826   \n",
       "BABA     110.81000  172.44600         0.003670           0.019388  0.022177   \n",
       "ETSY      11.06000   16.71000         0.003660           0.029454  0.032615   \n",
       "PYPL      47.54000   71.15000         0.003272           0.013700  0.017117   \n",
       "LITE      43.70000   64.75000         0.003618           0.032413  0.045134   \n",
       "W         47.02000   69.66000         0.003629           0.033240  0.041999   \n",
       "MU        27.61360   40.65420         0.003306           0.022685  0.029110   \n",
       "ON        14.35000   20.96000         0.003171           0.019290  0.026103   \n",
       "\n",
       "        Metric_Price  Metric_Sharpe  Metric_Sharpe (ATR)  \n",
       "Ticker                                                    \n",
       "ALNY        2.221098       2.154475             0.178770  \n",
       "FSLR        2.045008       3.093505             0.184451  \n",
       "NTNX        1.955740       2.799068             0.126682  \n",
       "XYZ         1.921010       3.927180             0.175588  \n",
       "NVDA        1.915176       3.107117             0.177678  \n",
       "SOXL        1.839454       2.448958             0.125327  \n",
       "ALGN        1.762193       3.339395             0.215572  \n",
       "TTD         1.707901       1.981568             0.110279  \n",
       "BABA        1.556231       3.004514             0.165465  \n",
       "ETSY        1.510850       1.972675             0.112226  \n",
       "PYPL        1.496634       3.791929             0.191188  \n",
       "LITE        1.481693       1.771740             0.080152  \n",
       "W           1.481497       1.733180             0.086408  \n",
       "MU          1.472253       2.313449             0.113567  \n",
       "ON          1.460627       2.609971             0.121498  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- [2] Daily Portfolio Trace for the Forward Period ---\n",
      "Showing forward trace starting from: 2017-10-30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Norm_Price_ALNY</th>\n",
       "      <th>Norm_Price_FSLR</th>\n",
       "      <th>Norm_Price_NTNX</th>\n",
       "      <th>Norm_Price_XYZ</th>\n",
       "      <th>Norm_Price_NVDA</th>\n",
       "      <th>Norm_Price_SOXL</th>\n",
       "      <th>Norm_Price_ALGN</th>\n",
       "      <th>Norm_Price_TTD</th>\n",
       "      <th>Norm_Price_BABA</th>\n",
       "      <th>Norm_Price_ETSY</th>\n",
       "      <th>...</th>\n",
       "      <th>Return_NTNX</th>\n",
       "      <th>Return_XYZ</th>\n",
       "      <th>Return_NVDA</th>\n",
       "      <th>Return_SOXL</th>\n",
       "      <th>Return_ALGN</th>\n",
       "      <th>Return_TTD</th>\n",
       "      <th>Return_BABA</th>\n",
       "      <th>Return_ETSY</th>\n",
       "      <th>Return_Portfolio</th>\n",
       "      <th>Return_Benchmark_VOO</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-10-30</th>\n",
       "      <td>2.221098</td>\n",
       "      <td>2.045008</td>\n",
       "      <td>1.955740</td>\n",
       "      <td>1.921010</td>\n",
       "      <td>1.915176</td>\n",
       "      <td>1.839454</td>\n",
       "      <td>1.762193</td>\n",
       "      <td>1.707901</td>\n",
       "      <td>1.556231</td>\n",
       "      <td>1.510850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013984</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.009809</td>\n",
       "      <td>0.009417</td>\n",
       "      <td>-0.001568</td>\n",
       "      <td>0.003595</td>\n",
       "      <td>0.030827</td>\n",
       "      <td>-0.002388</td>\n",
       "      <td>0.015808</td>\n",
       "      <td>-0.003632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-31</th>\n",
       "      <td>2.200867</td>\n",
       "      <td>1.855161</td>\n",
       "      <td>1.970954</td>\n",
       "      <td>1.998388</td>\n",
       "      <td>1.943081</td>\n",
       "      <td>1.880766</td>\n",
       "      <td>1.787702</td>\n",
       "      <td>1.753658</td>\n",
       "      <td>1.584595</td>\n",
       "      <td>1.509946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007779</td>\n",
       "      <td>0.040280</td>\n",
       "      <td>0.014570</td>\n",
       "      <td>0.022459</td>\n",
       "      <td>0.014476</td>\n",
       "      <td>0.026791</td>\n",
       "      <td>0.018226</td>\n",
       "      <td>-0.000598</td>\n",
       "      <td>0.002737</td>\n",
       "      <td>0.001146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-01</th>\n",
       "      <td>2.187319</td>\n",
       "      <td>1.936041</td>\n",
       "      <td>1.907331</td>\n",
       "      <td>1.959699</td>\n",
       "      <td>1.946747</td>\n",
       "      <td>1.863225</td>\n",
       "      <td>1.757555</td>\n",
       "      <td>1.731045</td>\n",
       "      <td>1.594793</td>\n",
       "      <td>1.512658</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032281</td>\n",
       "      <td>-0.019360</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>-0.009326</td>\n",
       "      <td>-0.016863</td>\n",
       "      <td>-0.012894</td>\n",
       "      <td>0.006435</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>-0.004799</td>\n",
       "      <td>0.001734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-02</th>\n",
       "      <td>2.413114</td>\n",
       "      <td>1.958376</td>\n",
       "      <td>1.898340</td>\n",
       "      <td>1.938205</td>\n",
       "      <td>1.934909</td>\n",
       "      <td>1.887885</td>\n",
       "      <td>1.746484</td>\n",
       "      <td>1.704177</td>\n",
       "      <td>1.583909</td>\n",
       "      <td>1.491863</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004714</td>\n",
       "      <td>-0.010968</td>\n",
       "      <td>-0.006081</td>\n",
       "      <td>0.013235</td>\n",
       "      <td>-0.006299</td>\n",
       "      <td>-0.015522</td>\n",
       "      <td>-0.006824</td>\n",
       "      <td>-0.013748</td>\n",
       "      <td>0.008743</td>\n",
       "      <td>0.000424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-03</th>\n",
       "      <td>2.390896</td>\n",
       "      <td>2.026058</td>\n",
       "      <td>1.890041</td>\n",
       "      <td>1.982268</td>\n",
       "      <td>1.960744</td>\n",
       "      <td>1.988557</td>\n",
       "      <td>1.805431</td>\n",
       "      <td>1.719074</td>\n",
       "      <td>1.570201</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004372</td>\n",
       "      <td>0.022734</td>\n",
       "      <td>0.013352</td>\n",
       "      <td>0.053325</td>\n",
       "      <td>0.033752</td>\n",
       "      <td>0.008742</td>\n",
       "      <td>-0.008655</td>\n",
       "      <td>0.005455</td>\n",
       "      <td>0.014873</td>\n",
       "      <td>0.003340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Norm_Price_ALNY  Norm_Price_FSLR  Norm_Price_NTNX  Norm_Price_XYZ  \\\n",
       "Date                                                                            \n",
       "2017-10-30         2.221098         2.045008         1.955740        1.921010   \n",
       "2017-10-31         2.200867         1.855161         1.970954        1.998388   \n",
       "2017-11-01         2.187319         1.936041         1.907331        1.959699   \n",
       "2017-11-02         2.413114         1.958376         1.898340        1.938205   \n",
       "2017-11-03         2.390896         2.026058         1.890041        1.982268   \n",
       "\n",
       "            Norm_Price_NVDA  Norm_Price_SOXL  Norm_Price_ALGN  Norm_Price_TTD  \\\n",
       "Date                                                                            \n",
       "2017-10-30         1.915176         1.839454         1.762193        1.707901   \n",
       "2017-10-31         1.943081         1.880766         1.787702        1.753658   \n",
       "2017-11-01         1.946747         1.863225         1.757555        1.731045   \n",
       "2017-11-02         1.934909         1.887885         1.746484        1.704177   \n",
       "2017-11-03         1.960744         1.988557         1.805431        1.719074   \n",
       "\n",
       "            Norm_Price_BABA  Norm_Price_ETSY  ...  Return_NTNX  Return_XYZ  \\\n",
       "Date                                          ...                            \n",
       "2017-10-30         1.556231         1.510850  ...     0.013984    0.015625   \n",
       "2017-10-31         1.584595         1.509946  ...     0.007779    0.040280   \n",
       "2017-11-01         1.594793         1.512658  ...    -0.032281   -0.019360   \n",
       "2017-11-02         1.583909         1.491863  ...    -0.004714   -0.010968   \n",
       "2017-11-03         1.570201         1.500000  ...    -0.004372    0.022734   \n",
       "\n",
       "            Return_NVDA  Return_SOXL  Return_ALGN  Return_TTD  Return_BABA  \\\n",
       "Date                                                                         \n",
       "2017-10-30     0.009809     0.009417    -0.001568    0.003595     0.030827   \n",
       "2017-10-31     0.014570     0.022459     0.014476    0.026791     0.018226   \n",
       "2017-11-01     0.001887    -0.009326    -0.016863   -0.012894     0.006435   \n",
       "2017-11-02    -0.006081     0.013235    -0.006299   -0.015522    -0.006824   \n",
       "2017-11-03     0.013352     0.053325     0.033752    0.008742    -0.008655   \n",
       "\n",
       "            Return_ETSY  Return_Portfolio  Return_Benchmark_VOO  \n",
       "Date                                                             \n",
       "2017-10-30    -0.002388          0.015808             -0.003632  \n",
       "2017-10-31    -0.000598          0.002737              0.001146  \n",
       "2017-11-01     0.001796         -0.004799              0.001734  \n",
       "2017-11-02    -0.013748          0.008743              0.000424  \n",
       "2017-11-03     0.005455          0.014873              0.003340  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- THE \"BULLETPROOF\" VERIFICATION SCRIPT (DEFINITIVELY CORRECTED) ---\n",
    "\n",
    "# (Run this cell AFTER clicking \"Update Chart\" in the cell above)\n",
    "\n",
    "# 2. Access the debug and results data\n",
    "debug_results = debug_container[0]\n",
    "results_dict = results_container[0] # The container holds the full dictionary\n",
    "\n",
    "if debug_results and results_dict:\n",
    "    print(\"--- Debug Data Successfully Captured ---\")\n",
    "\n",
    "    # Verify the Ranking (\"The Report Card\")\n",
    "    print(\"\\n--- [1] Ranking Metrics for all eligible stocks (Top 15 shown) ---\")\n",
    "    display(debug_results['ranking_metrics'].head(15))\n",
    "\n",
    "    # Verify the Daily Performance (\"The Daily Journal\")\n",
    "    print(\"\\n\\n--- [2] Daily Portfolio Trace for the Forward Period ---\")\n",
    "    \n",
    "    # --- THIS IS THE FINAL FIX ---\n",
    "    \n",
    "    # The correct start date for the forward period is stored in our main results dictionary.\n",
    "    forward_period_start_date = results_dict['actual_calc_end_ts']\n",
    "    \n",
    "    # Now we correctly slice the portfolio_trace DataFrame using a proper date.\n",
    "    fwd_trace = debug_results['portfolio_trace'].loc[forward_period_start_date:]\n",
    "\n",
    "    # --- END OF FIX ---\n",
    "    \n",
    "    print(f\"Showing forward trace starting from: {forward_period_start_date.date()}\")\n",
    "    display(fwd_trace.head())\n",
    "else:\n",
    "    print(\"Debug data not found. Did you click 'Update Chart'?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b929c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tickers_to_display': ['ALNY',\n",
       "   'FSLR',\n",
       "   'NTNX',\n",
       "   'XYZ',\n",
       "   'NVDA',\n",
       "   'SOXL',\n",
       "   'ALGN',\n",
       "   'TTD',\n",
       "   'BABA',\n",
       "   'ETSY'],\n",
       "  'normalized_plot_data': Ticker          ALNY      FSLR      NTNX       XYZ      NVDA      SOXL  \\\n",
       "  Date                                                                     \n",
       "  2017-05-01  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "  2017-05-02  0.958634  1.026058  1.094053  1.010747  0.970369  0.967839   \n",
       "  2017-05-03  0.993497  1.147547  1.058091  0.982268  0.977587  0.978516   \n",
       "  2017-05-04  0.991149  1.158714  1.067082  1.069318  0.973837  0.976102   \n",
       "  2017-05-05  0.994762  1.168866  1.126556  1.062869  0.973932  0.986525   \n",
       "  ...              ...       ...       ...       ...       ...       ...   \n",
       "  2018-01-24  2.418533  2.334349  2.517289  2.381515  2.216995  2.220202   \n",
       "  2018-01-25  2.425759  2.383756  2.296680  2.424503  2.222167  2.104694   \n",
       "  2018-01-26  2.427565  2.387817  2.281466  2.470177  2.287794  2.304294   \n",
       "  2018-01-29  2.412572  2.313029  2.239972  2.441161  2.320890  2.296915   \n",
       "  2018-01-30  2.370484  2.270389  2.216459  2.445997  2.282056  2.157109   \n",
       "  \n",
       "  Ticker          ALGN       TTD      BABA      ETSY  \n",
       "  Date                                                \n",
       "  2017-05-01  1.000000  1.000000  1.000000  1.000000  \n",
       "  2017-05-02  1.003291  1.018356  1.012084  1.029837  \n",
       "  2017-05-03  0.987208  1.012503  0.999061  0.949819  \n",
       "  2017-05-04  1.061415  1.060122  0.992979  0.960217  \n",
       "  2017-05-05  1.032540  1.065975  0.994522  1.054250  \n",
       "  ...              ...       ...       ...       ...  \n",
       "  2018-01-24  2.036804  1.298218  1.675787  1.722423  \n",
       "  2018-01-25  2.046379  1.316308  1.699783  1.730561  \n",
       "  2018-01-26  2.124252  1.363128  1.758830  1.735986  \n",
       "  2018-01-29  2.070392  1.344773  1.739897  1.714286  \n",
       "  2018-01-30  2.020347  1.295291  1.711181  1.707957  \n",
       "  \n",
       "  [190 rows x 10 columns],\n",
       "  'portfolio_series': Date\n",
       "  2017-05-01    1.000000\n",
       "  2017-05-02    1.009127\n",
       "  2017-05-03    1.008610\n",
       "  2017-05-04    1.031094\n",
       "  2017-05-05    1.046080\n",
       "                  ...   \n",
       "  2018-01-24    2.082212\n",
       "  2018-01-25    2.065059\n",
       "  2018-01-26    2.114131\n",
       "  2018-01-29    2.089389\n",
       "  2018-01-30    2.047727\n",
       "  Length: 190, dtype: float64,\n",
       "  'benchmark_price_series': Date\n",
       "  2014-01-02    137.039\n",
       "  2014-01-03    136.916\n",
       "  2014-01-06    136.573\n",
       "  2014-01-07    137.423\n",
       "  2014-01-08    137.480\n",
       "                 ...   \n",
       "  2018-12-24    193.157\n",
       "  2018-12-26    202.928\n",
       "  2018-12-27    204.814\n",
       "  2018-12-28    204.554\n",
       "  2018-12-31    206.395\n",
       "  Name: VOO, Length: 1258, dtype: float64,\n",
       "  'performance_data': {'calc_p_gain': 0.8434662586706743,\n",
       "   'fwd_p_gain': 0.11080255012273899,\n",
       "   'full_p_gain': 1.0477270211966099,\n",
       "   'calc_p_sharpe': 4.546037619438382,\n",
       "   'fwd_p_sharpe': 1.9702850778299368,\n",
       "   'full_p_sharpe': 3.6530783457203895,\n",
       "   'calc_b_gain': 0.08676027030151445,\n",
       "   'fwd_b_gain': 0.10233201332579034,\n",
       "   'full_b_gain': 0.19797063676394844,\n",
       "   'calc_b_sharpe': 2.4470599618139,\n",
       "   'fwd_b_sharpe': 5.360175556781846,\n",
       "   'full_b_sharpe': 3.5161759905224743},\n",
       "  'results_df':           Rank Metric  MetricValue  CalcPrice  CalcGain   FwdGain\n",
       "  Ticker                                                           \n",
       "  ALNY       1.0  Price     2.221098  122.96000  1.221098  0.067258\n",
       "  FSLR       2.0  Price     2.045008   60.43000  1.045008  0.110210\n",
       "  NTNX       3.0  Price     1.955740   28.28000  0.955740  0.133310\n",
       "  XYZ        4.0  Price     1.921010   35.75000  0.921010  0.273287\n",
       "  NVDA       5.0  Price     1.915176    5.03632  0.915176  0.191564\n",
       "  SOXL       6.0  Price     1.839454    9.19817  0.839454  0.172690\n",
       "  ALGN       7.0  Price     1.762193  235.57000  0.762193  0.146496\n",
       "  TTD        8.0  Price     1.707901    6.42000  0.707901 -0.241589\n",
       "  BABA       9.0  Price     1.556231  172.44600  0.556231  0.099567\n",
       "  ETSY      10.0  Price     1.510850   16.71000  0.510850  0.130461\n",
       "  VOO (BM)   NaN  Price     1.086760  206.81700  0.086760  0.102332,\n",
       "  'actual_calc_end_ts': Timestamp('2017-10-30 00:00:00'),\n",
       "  'safe_start_date': Timestamp('2017-05-01 00:00:00'),\n",
       "  'safe_viz_end_date': Timestamp('2018-01-30 00:00:00'),\n",
       "  'error': None}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# debug_results = debug_container[0]\n",
    "# results_dict = results_container[0] # The container holds the full dictionary\n",
    "# debug_results = debug_container[0]\n",
    "results_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f9f5209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ranking_metrics':         FirstPrice  LastPrice  MeanDailyReturn  StdDevDailyReturn  MeanATRP  \\\n",
       "  Ticker                                                                        \n",
       "  ALNY      55.36000  122.96000         0.007607           0.056048  0.042551   \n",
       "  FSLR      29.55000   60.43000         0.006114           0.031374  0.033147   \n",
       "  NTNX      14.46000   28.28000         0.005827           0.033045  0.045994   \n",
       "  XYZ       18.61000   35.75000         0.005388           0.021781  0.030688   \n",
       "  NVDA       2.62969    5.03632         0.005510           0.028149  0.031009   \n",
       "  ...            ...        ...              ...                ...       ...   \n",
       "  WBD       27.98000   18.98000        -0.002916           0.016380  0.026525   \n",
       "  SBSW       6.01385    4.05476        -0.002108           0.041939  0.046132   \n",
       "  CMG        9.55160    5.37400        -0.004268           0.021975  0.027152   \n",
       "  VIPS      13.14810    7.39641        -0.004189           0.025731  0.037138   \n",
       "  DKS       39.19720   19.88970        -0.004789           0.031458  0.031206   \n",
       "  \n",
       "          Metric_Price  Metric_Sharpe  Metric_Sharpe (ATR)  \n",
       "  Ticker                                                    \n",
       "  ALNY        2.221098       2.154475             0.178770  \n",
       "  FSLR        2.045008       3.093505             0.184451  \n",
       "  NTNX        1.955740       2.799068             0.126682  \n",
       "  XYZ         1.921010       3.927180             0.175588  \n",
       "  NVDA        1.915176       3.107117             0.177678  \n",
       "  ...              ...            ...                  ...  \n",
       "  WBD         0.678342      -2.826372            -0.109945  \n",
       "  SBSW        0.674237      -0.797780            -0.045688  \n",
       "  CMG         0.562628      -3.083422            -0.157203  \n",
       "  VIPS        0.562546      -2.584492            -0.112799  \n",
       "  DKS         0.507427      -2.416464            -0.153451  \n",
       "  \n",
       "  [521 rows x 8 columns],\n",
       "  'portfolio_trace':             Norm_Price_ALNY  Norm_Price_FSLR  Norm_Price_NTNX  Norm_Price_XYZ  \\\n",
       "  Date                                                                            \n",
       "  2017-05-01         1.000000         1.000000         1.000000        1.000000   \n",
       "  2017-05-02         0.958634         1.026058         1.094053        1.010747   \n",
       "  2017-05-03         0.993497         1.147547         1.058091        0.982268   \n",
       "  2017-05-04         0.991149         1.158714         1.067082        1.069318   \n",
       "  2017-05-05         0.994762         1.168866         1.126556        1.062869   \n",
       "  ...                     ...              ...              ...             ...   \n",
       "  2018-01-24         2.418533         2.334349         2.517289        2.381515   \n",
       "  2018-01-25         2.425759         2.383756         2.296680        2.424503   \n",
       "  2018-01-26         2.427565         2.387817         2.281466        2.470177   \n",
       "  2018-01-29         2.412572         2.313029         2.239972        2.441161   \n",
       "  2018-01-30         2.370484         2.270389         2.216459        2.445997   \n",
       "  \n",
       "              Norm_Price_NVDA  Norm_Price_SOXL  Norm_Price_ALGN  Norm_Price_TTD  \\\n",
       "  Date                                                                            \n",
       "  2017-05-01         1.000000         1.000000         1.000000        1.000000   \n",
       "  2017-05-02         0.970369         0.967839         1.003291        1.018356   \n",
       "  2017-05-03         0.977587         0.978516         0.987208        1.012503   \n",
       "  2017-05-04         0.973837         0.976102         1.061415        1.060122   \n",
       "  2017-05-05         0.973932         0.986525         1.032540        1.065975   \n",
       "  ...                     ...              ...              ...             ...   \n",
       "  2018-01-24         2.216995         2.220202         2.036804        1.298218   \n",
       "  2018-01-25         2.222167         2.104694         2.046379        1.316308   \n",
       "  2018-01-26         2.287794         2.304294         2.124252        1.363128   \n",
       "  2018-01-29         2.320890         2.296915         2.070392        1.344773   \n",
       "  2018-01-30         2.282056         2.157109         2.020347        1.295291   \n",
       "  \n",
       "              Norm_Price_BABA  Norm_Price_ETSY  ...  Return_NTNX  Return_XYZ  \\\n",
       "  Date                                          ...                            \n",
       "  2017-05-01         1.000000         1.000000  ...          NaN         NaN   \n",
       "  2017-05-02         1.012084         1.029837  ...     0.094053    0.010747   \n",
       "  2017-05-03         0.999061         0.949819  ...    -0.032870   -0.028177   \n",
       "  2017-05-04         0.992979         0.960217  ...     0.008497    0.088621   \n",
       "  2017-05-05         0.994522         1.054250  ...     0.055736   -0.006030   \n",
       "  ...                     ...              ...  ...          ...         ...   \n",
       "  2018-01-24         1.675787         1.722423  ...    -0.029074   -0.015330   \n",
       "  2018-01-25         1.699783         1.730561  ...    -0.087637    0.018051   \n",
       "  2018-01-26         1.758830         1.735986  ...    -0.006625    0.018839   \n",
       "  2018-01-29         1.739897         1.714286  ...    -0.018187   -0.011747   \n",
       "  2018-01-30         1.711181         1.707957  ...    -0.010497    0.001981   \n",
       "  \n",
       "              Return_NVDA  Return_SOXL  Return_ALGN  Return_TTD  Return_BABA  \\\n",
       "  Date                                                                         \n",
       "  2017-05-01          NaN          NaN          NaN         NaN          NaN   \n",
       "  2017-05-02    -0.029631    -0.032161     0.003291    0.018356     0.012084   \n",
       "  2017-05-03     0.007438     0.011032    -0.016030   -0.005747    -0.012867   \n",
       "  2017-05-04    -0.003835    -0.002467     0.075169    0.047031    -0.006088   \n",
       "  2017-05-05     0.000098     0.010678    -0.027204    0.005521     0.001554   \n",
       "  ...                 ...          ...          ...         ...          ...   \n",
       "  2018-01-24    -0.013017    -0.068835     0.000441   -0.012146     0.016905   \n",
       "  2018-01-25     0.002333    -0.052026     0.004701    0.013934     0.014319   \n",
       "  2018-01-26     0.029533     0.094836     0.038054    0.035570     0.034738   \n",
       "  2018-01-29     0.014466    -0.003202    -0.025355   -0.013466    -0.010765   \n",
       "  2018-01-30    -0.016732    -0.060867    -0.024172   -0.036795    -0.016504   \n",
       "  \n",
       "              Return_ETSY  Return_Portfolio  Return_Benchmark_VOO  \n",
       "  Date                                                             \n",
       "  2017-05-01          NaN               NaN                   NaN  \n",
       "  2017-05-02     0.029837          0.009127              0.000321  \n",
       "  2017-05-03    -0.077700         -0.000512             -0.001003  \n",
       "  2017-05-04     0.010947          0.022292              0.000915  \n",
       "  2017-05-05     0.097928          0.014534              0.004014  \n",
       "  ...                 ...               ...                   ...  \n",
       "  2018-01-24    -0.044634         -0.019463             -0.000497  \n",
       "  2018-01-25     0.004724         -0.008238              0.000458  \n",
       "  2018-01-26     0.003135          0.023763              0.011640  \n",
       "  2018-01-29    -0.012500         -0.011703             -0.006908  \n",
       "  2018-01-30    -0.003692         -0.019940             -0.010671  \n",
       "  \n",
       "  [190 rows x 24 columns]}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6cba46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ranking_metrics portfolio_trace\n"
     ]
    }
   ],
   "source": [
    "print(*debug_container[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "597a7b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FirstPrice', 'LastPrice', 'MeanDailyReturn', 'StdDevDailyReturn',\n",
       "       'MeanATRP', 'Metric_Price', 'Metric_Sharpe', 'Metric_Sharpe (ATR)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# debug_container[0]['ranking_metrics'].head(50)\n",
    "debug_container[0]['ranking_metrics'].columns\n",
    "\n",
    "# debug_container[0]['portfolio_trace'].head(50)\n",
    "# debug_container[0]['portfolio_trace'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db740c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "from IPython.display import display\n",
    "\n",
    "# --- Assume all functions from our project context are already defined ---\n",
    "# (calculate_rolling_quality_metrics, get_eligible_universe, run_walk_forward_step, etc.)\n",
    "\n",
    "# --- Assume df_dev and bot_config are already defined from previous steps ---\n",
    "\n",
    "def run_strategy_search(df_ohlcv, config):\n",
    "    \"\"\"\n",
    "    Runs the main backtesting loop based on a provided configuration dictionary.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # --- 1. PRE-PROCESSING (Run once for efficiency) ---\n",
    "    print(\"--- Phase 1: Pre-processing Data ---\")\n",
    "    \n",
    "    # Calculate quality metrics for the entire development period\n",
    "    quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "\n",
    "    # Unstack the data for fast slicing later. This is a major optimization.\n",
    "    print(\"Unstacking data for performance...\")\n",
    "    df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "    df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "    df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    print(\"✅ Pre-processing complete.\\n\")\n",
    "    \n",
    "    # --- 2. SETUP THE MAIN LOOP ---\n",
    "    print(\"--- Phase 2: Setting up Simulation Loops ---\")\n",
    "    \n",
    "    # Create all parameter combinations to test\n",
    "    param_combinations = list(product(\n",
    "        config['calc_periods'],\n",
    "        config['fwd_periods'],\n",
    "        config['metrics'],\n",
    "        config['rank_slices']\n",
    "    ))\n",
    "    \n",
    "    # Create the list of dates where the bot will re-evaluate the strategy\n",
    "    step_dates = pd.date_range(\n",
    "        start=config['search_start_date'],\n",
    "        end=config['search_end_date'],\n",
    "        freq=config['step_frequency']\n",
    "    )\n",
    "    \n",
    "    # Map string periods to pandas DateOffset objects for our core function\n",
    "    period_options = {\n",
    "        '1M': pd.DateOffset(months=1), '3M': pd.DateOffset(months=3),\n",
    "        '6M': pd.DateOffset(months=6), '1Y': pd.DateOffset(years=1)\n",
    "    }\n",
    "    \n",
    "    results_log = []\n",
    "    total_sims = len(param_combinations) * len(step_dates)\n",
    "    print(f\"Found {len(param_combinations)} parameter sets and {len(step_dates)} time steps.\")\n",
    "    print(f\"Total simulations to run: {total_sims}\")\n",
    "    print(\"✅ Setup complete. Starting main loop...\\n\")\n",
    "\n",
    "    # --- 3. RUN THE MAIN LOOP ---\n",
    "    print(\"--- Phase 3: Running Simulations ---\")\n",
    "    \n",
    "    # Use tqdm for a progress bar on the outer loop\n",
    "    pbar = tqdm(param_combinations, desc=\"Parameter Sets\")\n",
    "    for params in pbar:\n",
    "        # Unpack parameters for this run\n",
    "        calc_period_str, fwd_period_str, metric, rank_slice = params\n",
    "        calc_period = period_options[calc_period_str]\n",
    "        fwd_period = period_options[fwd_period_str]\n",
    "        rank_start, rank_end = rank_slice\n",
    "\n",
    "        # Inner loop for stepping through time\n",
    "        for step_date in step_dates:\n",
    "            # 3a. DYNAMIC UNIVERSE SELECTION\n",
    "            eligible_tickers = get_eligible_universe(\n",
    "                quality_metrics_df,\n",
    "                filter_date=step_date,\n",
    "                thresholds=config['quality_thresholds']\n",
    "            )\n",
    "\n",
    "            if not eligible_tickers:\n",
    "                # print(f\"Warning: No eligible tickers on {step_date.date()}. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            # 3b. FILTER DATA FOR THIS STEP\n",
    "            df_close_step = df_close_full[eligible_tickers]\n",
    "            df_high_step = df_high_full[eligible_tickers]\n",
    "            df_low_step = df_low_full[eligible_tickers]\n",
    "\n",
    "            # 3c. RUN THE CORE ANALYSIS\n",
    "            step_result = run_walk_forward_step(\n",
    "                df_close_full=df_close_step,\n",
    "                df_high_full=df_high_step,\n",
    "                df_low_full=df_low_step,\n",
    "                start_date=step_date,\n",
    "                calc_period=calc_period,\n",
    "                fwd_period=fwd_period,\n",
    "                metric=metric,\n",
    "                rank_start=rank_start,\n",
    "                rank_end=rank_end,\n",
    "                benchmark_ticker=config['benchmark_ticker']\n",
    "            )\n",
    "            \n",
    "            # 3d. LOG THE RESULTS\n",
    "            if step_result['error'] is None:\n",
    "                p = step_result['performance_data']\n",
    "                log_entry = {\n",
    "                    'step_date': step_date.date(),\n",
    "                    'calc_period': calc_period_str,\n",
    "                    'fwd_period': fwd_period_str,\n",
    "                    'metric': metric,\n",
    "                    'rank_start': rank_start,\n",
    "                    'rank_end': rank_end,\n",
    "                    'num_universe': len(eligible_tickers),\n",
    "                    'num_portfolio': len(step_result['tickers_to_display']),\n",
    "                    'fwd_p_gain': p['fwd_p_gain'],\n",
    "                    'fwd_b_gain': p['fwd_b_gain'],\n",
    "                    'fwd_gain_delta': p['fwd_p_gain'] - p['fwd_b_gain'] if not np.isnan(p['fwd_b_gain']) else np.nan,\n",
    "                    'fwd_p_sharpe': p['fwd_p_sharpe'],\n",
    "                }\n",
    "                results_log.append(log_entry)\n",
    "\n",
    "    print(\"✅ Main loop finished.\\n\")\n",
    "\n",
    "    # --- 4. SAVE THE RESULTS ---\n",
    "    print(\"--- Phase 4: Saving Results ---\")\n",
    "    if not results_log:\n",
    "        print(\"Warning: No results were generated. The output file will be empty.\")\n",
    "        return None\n",
    "\n",
    "    final_df = pd.DataFrame(results_log)\n",
    "    output_path = config['results_output_path']\n",
    "    final_df.to_csv(output_path, index=False, float_format='%.4f')\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"✅ Results saved to '{output_path}'\")\n",
    "    print(f\"Total execution time: {end_time - start_time:.2f} seconds.\")\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# --- Execute the Bot ---\n",
    "dev_results_df = run_strategy_search(df_dev, bot_config)\n",
    "\n",
    "# --- Display a sample of the results ---\n",
    "if dev_results_df is not None:\n",
    "    print(\"\\n--- Sample of Generated Results ---\")\n",
    "    display(dev_results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cdce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_results_df.to_csv('./export_csv/dev_results_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584c600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our inspection rules inside the rolling window\n",
    "ticker_thresholds = {\n",
    "    'min_median_dollar_volume': 10_000_000, # $10 million median daily trade volume\n",
    "    'max_stale_pct': 0.1,                   # Allow 10% stale days (i.e. Volume=0 or High=Low)\n",
    "    'max_same_vol_count': 1                 # Allow at most 1 suspicious volume event (i.e. same Volume on consecutive day)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2d172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Verification for the first row of bot results ---\n",
    "\n",
    "print(\"--- Replicating the scenario from the first CSV row ---\")\n",
    "print(\"Start Date: 2014-07-31\")\n",
    "print(\"Calc Period: 6M, Fwd Period: 3M\")\n",
    "print(\"Metric: Sharpe, Ranks: 1 to 10\")\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\"\\nInstructions: The UI will load with the correct defaults. Simply click the 'Update Chart' button.\")\n",
    "\n",
    "# Call the plotter using the parameters from the CSV row as defaults\n",
    "plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_dev,  # CRITICAL: Use the same df_dev as the bot\n",
    "    default_start_date='2017-04-30',\n",
    "    default_calc_period='6M',\n",
    "    default_fwd_period='3M',\n",
    "    default_metric='Sharpe (ATR)',\n",
    "    default_rank_start=1,\n",
    "    default_rank_end=10,\n",
    "    default_benchmark_ticker='VOO',\n",
    "    quality_thresholds=ticker_thresholds,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc9b9ad",
   "metadata": {},
   "source": [
    "### Compare bot results vs verified plot_walk_forward_analyzer_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54317ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the row\n",
    "row_index = 43\n",
    "row = dev_results_df.iloc[row_index]\n",
    "\n",
    "# convert to dict and reformat step_date\n",
    "row_dict = row.to_dict()\n",
    "row_dict['step_date'] = row_dict['step_date'].strftime('%Y-%m-%d')\n",
    "print(f'row no: {row_index}')\n",
    "print(f'row_dict: {row_dict}')\n",
    "\n",
    "_start_date=row_dict['step_date']\n",
    "_calc_period=row_dict['calc_period']\n",
    "_fwd_period=row_dict['fwd_period']\n",
    "_metric=row_dict['metric']\n",
    "_rank_start=row_dict['rank_start']\n",
    "_rank_end=row_dict['rank_end']\n",
    "_benchmark_ticker='VOO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7accff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_dev,  # CRITICAL: Use the same df_dev as the bot\n",
    "    default_start_date=_start_date,\n",
    "    default_calc_period=_calc_period,\n",
    "    default_fwd_period=_fwd_period,\n",
    "    default_metric=_metric,\n",
    "    default_rank_start=_rank_start,\n",
    "    default_rank_end=_rank_end,\n",
    "    default_benchmark_ticker=_benchmark_ticker,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01521b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_df = calculate_rolling_quality_metrics(\n",
    "    df_ohlcv=df_OHLCV,\n",
    "    window=252,\n",
    "    min_periods=126,\n",
    "    debug=False,  # <-- The key to our new, improved workflow    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4b2b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. make sure the whole frame is sorted\n",
    "df_tmp = quality_df.sort_index()\n",
    "\n",
    "# 2a. pick the exact date if it exists, otherwise the previous one\n",
    "date_needed = pd.Timestamp(_start_date)\n",
    "dates = df_tmp.index.get_level_values('Date').unique().sort_values()   # ← sorted\n",
    "# first date >= date_needed  (later)\n",
    "pos = dates.searchsorted(date_needed, side='left')\n",
    "if pos == len(dates):          # date_needed is after the last date\n",
    "    later_date = pd.NaT\n",
    "else:\n",
    "    later_date = dates[pos]\n",
    "\n",
    "print(f'_start_date: {_start_date}')\n",
    "print(f'real start date: {later_date}')\n",
    "\n",
    "# 3. slice\n",
    "# quality_df = df_tmp.xs(later_date, level='Date')\n",
    "# print(quality_df)\n",
    "print(f\"--- Quality Metrics for {later_date} ---\")\n",
    "# print(quality_df.xs('2025-10-03', level='Date'))\n",
    "print(quality_df.xs(later_date, level='Date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549894d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible_tickers = get_eligible_universe(quality_metrics_df=quality_df, \n",
    "                                        #  filter_date=_start_date, \n",
    "                                         filter_date=later_date,                                         \n",
    "                                         thresholds=ticker_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3898a28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = df_OHLCV.loc[eligible_tickers].copy()\n",
    "_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5645bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_walk_forward_analyzer_original(\n",
    "    df_ohlcv=_df,  # CRITICAL: Use the same df_dev as the bot\n",
    "    default_start_date=_start_date,\n",
    "    default_calc_period=_calc_period,\n",
    "    default_fwd_period=_fwd_period,\n",
    "    default_metric=_metric,\n",
    "    default_rank_start=_rank_start,\n",
    "    default_rank_end=_rank_end,\n",
    "    default_benchmark_ticker=_benchmark_ticker,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ffe810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Load the Bot's Output ---\n",
    "try:\n",
    "    results_df = pd.read_csv(bot_config['results_output_path'])\n",
    "    print(f\"Successfully loaded '{bot_config['results_output_path']}'. Shape: {results_df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: The results file was not found. Please run the bot first.\")\n",
    "    # In a real script, you'd exit here. For a notebook, we'll stop.\n",
    "    results_df = None\n",
    "\n",
    "if results_df is not None:\n",
    "    # --- 2. Define the Strategy Parameters for Grouping ---\n",
    "    # These are the columns that uniquely identify one strategy configuration.\n",
    "    # strategy_params = ['calc_period', 'metric', 'rank_start', 'rank_end']\n",
    "    strategy_params = ['calc_period', 'fwd_period', 'metric', 'rank_start', 'rank_end']    \n",
    "\n",
    "    # --- 3. Group and Aggregate the Results ---\n",
    "    # We group by the strategy parameters and calculate key performance metrics for each group.\n",
    "    summary_df = results_df.groupby(strategy_params).agg(\n",
    "        avg_fwd_p_gain=('fwd_p_gain', 'mean'),\n",
    "        std_fwd_p_gain=('fwd_p_gain', 'std'),\n",
    "        avg_fwd_gain_delta=('fwd_gain_delta', 'mean'),\n",
    "        # Calculate Win Rate: The percentage of periods with positive forward gain.\n",
    "        win_rate=('fwd_p_gain', lambda x: (x > 0).sum() / len(x) if len(x) > 0 else 0),\n",
    "        # Count the number of periods tested for this strategy\n",
    "        num_periods=('step_date', 'count')\n",
    "    ).sort_values(by='avg_fwd_gain_delta', ascending=False) # Sort by outperformance vs benchmark\n",
    "\n",
    "    # --- 4. Format and Display the Summary Table ---\n",
    "    print(\"\\n--- Strategy Performance Summary (2014-2018 Development Run) ---\")\n",
    "    \n",
    "    # Apply formatting for better readability\n",
    "    formatted_summary = summary_df.style.format({\n",
    "        'avg_fwd_p_gain': '{:+.2%}',\n",
    "        'std_fwd_p_gain': '{:.2%}',\n",
    "        'avg_fwd_gain_delta': '{:+.2%}',\n",
    "        'win_rate': '{:.1%}',\n",
    "    }).set_properties(**{'text-align': 'right'})\n",
    "\n",
    "    display(formatted_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b389d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_cumulative_performance(df_ohlcv, strategy_params, quality_thresholds):\n",
    "    \"\"\"\n",
    "    Plots the cumulative performance of a SINGLE strategy over a specified time range.\n",
    "\n",
    "    This function simulates rebalancing a portfolio at a fixed frequency and charts\n",
    "    the resulting equity curve against a benchmark.\n",
    "    \"\"\"\n",
    "    print(\"--- Running Cumulative Performance Simulation for the Winning Strategy ---\")\n",
    "    \n",
    "    # --- 1. Setup and Pre-processing ---\n",
    "    # Unpack strategy parameters from the dictionary\n",
    "    start_date = strategy_params['start_date']\n",
    "    end_date = strategy_params['end_date']\n",
    "    calc_period_str = strategy_params['calc_period']\n",
    "    fwd_period_str = strategy_params['fwd_period']\n",
    "    metric = strategy_params['metric']\n",
    "    rank_start = strategy_params['rank_start']\n",
    "    rank_end = strategy_params['rank_end']\n",
    "    benchmark_ticker = strategy_params['benchmark_ticker']\n",
    "    \n",
    "    # Pre-calculate quality metrics and unstack data once for efficiency\n",
    "    quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "    df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "    df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "    df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "\n",
    "    # Map string periods to pandas DateOffset objects\n",
    "    period_options = {'3M': pd.DateOffset(months=3), '6M': pd.DateOffset(months=6), '1Y': pd.DateOffset(years=1)}\n",
    "    calc_period = period_options[calc_period_str]\n",
    "    fwd_period = period_options[fwd_period_str] # This also defines our rebalancing frequency\n",
    "    \n",
    "    # --- 2. Main Simulation Loop ---\n",
    "    # Create the rebalancing dates\n",
    "    step_dates = pd.date_range(start=start_date, end=end_date, freq=f'{fwd_period.months}ME')\n",
    "    \n",
    "    all_fwd_gains = []\n",
    "    \n",
    "    print(f\"Simulating from {step_dates[0].date()} to {step_dates[-1].date()}...\")\n",
    "    \n",
    "    for step_date in step_dates:\n",
    "        # Get the eligible universe for this specific rebalancing date\n",
    "        eligible_tickers = get_eligible_universe(quality_metrics_df, step_date, quality_thresholds)\n",
    "        if not eligible_tickers: continue\n",
    "            \n",
    "        df_close_step = df_close_full[eligible_tickers]\n",
    "        df_high_step = df_high_full[eligible_tickers]\n",
    "        df_low_step = df_low_full[eligible_tickers]\n",
    "        \n",
    "        # Run the core calculation for this single step in time\n",
    "        step_result = run_walk_forward_step(\n",
    "            df_close_step, df_high_step, df_low_step,\n",
    "            step_date, calc_period, fwd_period,\n",
    "            metric, rank_start, rank_end, benchmark_ticker\n",
    "        )\n",
    "        \n",
    "        if step_result['error'] is None:\n",
    "            # Extract the forward portion of the portfolio's performance\n",
    "            fwd_series = step_result['portfolio_series'].loc[step_result['actual_calc_end_ts']:]\n",
    "            all_fwd_gains.append(fwd_series.pct_change().dropna())\n",
    "            \n",
    "    # --- 3. Stitch Together Results & Plot ---\n",
    "    if not all_fwd_gains:\n",
    "        print(\"Error: No valid periods were simulated. Cannot plot.\")\n",
    "        return\n",
    "\n",
    "    # Concatenate all the forward period returns into one long series\n",
    "    strategy_returns = pd.concat(all_fwd_gains)\n",
    "    \n",
    "    # Create the equity curve (cumulative performance)\n",
    "    # (1 + returns).cumprod() is the standard way to calculate this\n",
    "    strategy_equity_curve = (1 + strategy_returns).cumprod()\n",
    "    \n",
    "    # Get the benchmark returns for the same period\n",
    "    benchmark_returns = df_close_full[benchmark_ticker].pct_change()\n",
    "    benchmark_returns_filtered = benchmark_returns.loc[strategy_equity_curve.index]\n",
    "    benchmark_equity_curve = (1 + benchmark_returns_filtered).cumprod()\n",
    "    \n",
    "    # Create the plot\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=strategy_equity_curve.index, y=strategy_equity_curve,\n",
    "                             mode='lines', name='Winning Strategy', line=dict(color='green', width=3)))\n",
    "    fig.add_trace(go.Scatter(x=benchmark_equity_curve.index, y=benchmark_equity_curve,\n",
    "                             mode='lines', name=f'Benchmark ({benchmark_ticker})', line=dict(color='black', dash='dash')))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"Cumulative Performance: '{metric}' Strategy (Top {rank_start}-{rank_end}) vs. Benchmark\",\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=\"Cumulative Growth (Normalized to 1)\",\n",
    "        legend_title=\"Portfolio\",\n",
    "        hovermode='x unified',\n",
    "        height=600\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380f1890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define the parameters for our winning strategy ---\n",
    "winning_strategy_params = {\n",
    "    'start_date': '2014-01-31',\n",
    "    'end_date': '2018-12-31',\n",
    "    'calc_period': '6M',\n",
    "    'fwd_period': '3M',\n",
    "    'metric': 'Sharpe (ATR)',\n",
    "    'rank_start': 1,\n",
    "    'rank_end': 10,\n",
    "    'benchmark_ticker': 'VOO'\n",
    "}\n",
    "\n",
    "# Get the quality thresholds from the bot's configuration\n",
    "quality_thresholds_from_bot = bot_config['quality_thresholds']\n",
    "\n",
    "# --- Run the simulation and generate the plot ---\n",
    "plot_cumulative_performance(\n",
    "    df_ohlcv=df_dev,  # Run on our development dataset\n",
    "    strategy_params=winning_strategy_params,\n",
    "    quality_thresholds=quality_thresholds_from_bot\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
