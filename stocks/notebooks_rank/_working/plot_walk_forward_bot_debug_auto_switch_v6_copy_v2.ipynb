{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7a42aca",
   "metadata": {},
   "source": [
    "## Project Hand-off: Walk-Forward Backtesting Bot\n",
    "\n",
    "This package contains the final version of the code, designed to be resilient, portable, and easy to use in both local (VS Code) and cloud (Google Colab) environments.\n",
    "\n",
    "### 1. Summary of Key Features\n",
    "\n",
    "The system you have built now includes:\n",
    "\n",
    "*   **Environment-Agnostic Operation:** A \"magic switch\" automatically detects whether the code is running locally or in Colab and adjusts all file paths accordingly.\n",
    "*   **Resumable Backtests (Checkpointing):** Long-running parameter searches are now resilient. If the process is interrupted, it can be restarted and will automatically skip completed work, picking up where it left off.\n",
    "*   **Granular, Trading-Day-Based Logic:** The backtester operates on precise integer counts of trading days, allowing for non-calendar-based periods (e.g., 10-day holds) and eliminating approximation errors.\n",
    "*   **Multi-Period Testing:** The automation script is capable of testing a list of different holding/rebalancing periods in a single run.\n",
    "*   **Modular & Verifiable Core Engine:** The core calculation logic (`run_walk_forward_step`) is a pure, self-contained function, making it easy to test and verify independently.\n",
    "*   **Dynamic Data Quality Filtering:** Before each ranking period, the universe of stocks is filtered based on rolling liquidity and data quality metrics, ensuring the strategy is only applied to tradable assets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5182cc74",
   "metadata": {},
   "source": [
    "### 2. Required Project Structure\n",
    "\n",
    "For the environment switch to work seamlessly, your project should be organized in the following way, both on your local machine and in Google Drive.\n",
    "\n",
    "```\n",
    "my_trading_project/\n",
    "│\n",
    "├── 📜 bot.ipynb                 # <-- This is the main notebook file\n",
    "│\n",
    "├── 📁 data/\n",
    "│   └── 📊 df_OHLCV_stocks_etfs.parquet # <-- Your input data file goes here\n",
    "│\n",
    "└── 📁 export_csv/                 # <-- Folder for local results (created automatically)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76715d2a",
   "metadata": {},
   "source": [
    "### 3. Final, Complete Code\n",
    "\n",
    "This is the entire code for your notebook, consolidated into logical cells.\n",
    "\n",
    "#### **CELL 1: ENVIRONMENT SETUP & CONFIGURATION**\n",
    "*This cell is the \"brain\" of the system. It detects the environment and configures all paths. It's the only cell you might need to edit if your file paths change.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e8a246d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Environment: Local (VS Code) detected.\n",
      "\n",
      "Data will be loaded from: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet\n",
      "Output files will be saved to: .\\export_csv\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# --- CELL 1: ENVIRONMENT SETUP & CONFIGURATION (IMPROVED) ---\n",
    "# This cell automatically detects the environment (local VS Code or Google Colab)\n",
    "# and configures paths and settings accordingly. It also creates directories.\n",
    "# ==============================================================================\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# 1. AUTOMATIC ENVIRONMENT DETECTION\n",
    "try:\n",
    "    import google.colab\n",
    "    IS_COLAB = True\n",
    "    print(\"✅ Environment: Google Colab detected.\")\n",
    "except ImportError:\n",
    "    IS_COLAB = False\n",
    "    print(\"✅ Environment: Local (VS Code) detected.\")\n",
    "\n",
    "# 2. ENVIRONMENT-SPECIFIC CONFIGURATION\n",
    "if IS_COLAB:\n",
    "    # --- Colab Settings ---\n",
    "    from google.colab import drive, output\n",
    "    drive.mount('/content/drive')\n",
    "    output.enable_custom_widget_manager()\n",
    "    \n",
    "    # IMPORTANT: This should be the path to your main project folder in Google Drive\n",
    "    DRIVE_ROOT = '/content/drive/MyDrive/my_trading_project'\n",
    "    \n",
    "    env_config = {\n",
    "        'data_path': os.path.join(DRIVE_ROOT, 'data', 'df_OHLCV_stocks_etfs.parquet'),\n",
    "        'output_dir': os.path.join(DRIVE_ROOT, 'results') # Colab results go in a 'results' folder\n",
    "    }\n",
    "    \n",
    "else:\n",
    "    # --- Local Settings ---\n",
    "    # IMPORTANT: Update this path to your local data file if it's different\n",
    "    env_config = {\n",
    "        'data_path': r'c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet',\n",
    "        'output_dir': os.path.join('.', 'export_csv') # Local results go in 'export_csv'\n",
    "    }\n",
    "\n",
    "# 3. CREATE ALL NECESSARY DIRECTORIES\n",
    "data_parent_dir = os.path.dirname(env_config['data_path'])\n",
    "os.makedirs(data_parent_dir, exist_ok=True)\n",
    "os.makedirs(env_config['output_dir'], exist_ok=True)\n",
    "\n",
    "print(f\"\\nData will be loaded from: {env_config['data_path']}\")\n",
    "print(f\"Output files will be saved to: {env_config['output_dir']}\")\n",
    "\n",
    "# 4. DEFINE THE FULL PATH FOR THE RESULTS FILE\n",
    "env_config['results_path'] = os.path.join(env_config['output_dir'], 'dev_strategy_search_results.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38189318",
   "metadata": {},
   "source": [
    "#### **CELL 2: GOLDEN COPY - CORE ENGINE & TOOLS**\n",
    "*This cell contains all the stable, tested functions that form the core of your backtester.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96383d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# GOLDEN COPY - COMPLETE PROJECT CODE (All Fixes Included)\n",
    "# Version: Final TR Calculation & Multi-Ticker Stability\n",
    "# Date: 2025-10-10\n",
    "# ==============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime, date\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "import pprint\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import re\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.width', 3000)\n",
    "\n",
    "# --- A. HELPER FUNCTIONS ---\n",
    "\n",
    "def calculate_gain(price_series: pd.Series):\n",
    "    \"\"\"Calculates the total gain over a series of prices.\"\"\"\n",
    "    # Ensure there are at least two data points to calculate a gain\n",
    "    if price_series.dropna().shape[0] < 2: return np.nan\n",
    "    # Use forward-fill for the end price and back-fill for the start price\n",
    "    # to handle potential NaNs at the beginning or end of the series.\n",
    "    return (price_series.ffill().iloc[-1] / price_series.bfill().iloc[0]) - 1\n",
    "\n",
    "def calculate_sharpe(return_series: pd.Series):\n",
    "    \"\"\"Calculates the annualized Sharpe ratio from a series of daily returns.\"\"\"\n",
    "    # Ensure there are at least two returns to calculate a standard deviation\n",
    "    if return_series.dropna().shape[0] < 2: return np.nan\n",
    "    std_dev = return_series.std()\n",
    "    # Avoid division by zero if returns are constant\n",
    "    if std_dev > 0 and std_dev != np.inf:\n",
    "        return (return_series.mean() / std_dev) * np.sqrt(252)\n",
    "    return np.nan\n",
    "\n",
    "def print_nested(d, indent=0, width=4):\n",
    "    \"\"\"Pretty-print any nested dict/list/tuple combination.\"\"\"\n",
    "    spacing = ' ' * indent\n",
    "    if isinstance(d, dict):\n",
    "        for k, v in d.items():\n",
    "            print(f'{spacing}{k}:')\n",
    "            print_nested(v, indent + width, width)\n",
    "    elif isinstance(d, (list, tuple)):\n",
    "        for item in d:\n",
    "            print_nested(item, indent, width)\n",
    "    else:\n",
    "        print(f'{spacing}{d}')\n",
    "\n",
    "# --- B. THE CORE CALCULATION ENGINE ---\n",
    "\n",
    "def run_walk_forward_step(df_close_full, df_high_full, df_low_full,\n",
    "                          master_trading_days,\n",
    "                          start_date, calc_period, fwd_period,\n",
    "                          metric, rank_start, rank_end, benchmark_ticker,\n",
    "                          debug=False):\n",
    "    \"\"\"Runs a single step of the walk-forward analysis using precise trading days.\"\"\"\n",
    "    debug_data = {} if debug else None\n",
    "    \n",
    "    # 1. Determine exact date ranges using the master trading day calendar\n",
    "    try:\n",
    "        start_idx = master_trading_days.get_loc(start_date)\n",
    "    except KeyError:\n",
    "        return ({'error': f\"Start date {start_date.date()} is not a valid trading day.\"}, None)\n",
    "        \n",
    "    calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "    viz_end_idx = min(calc_end_idx + fwd_period, len(master_trading_days) - 1)\n",
    "\n",
    "    safe_start_date = master_trading_days[start_idx]\n",
    "    safe_calc_end_date = master_trading_days[calc_end_idx]\n",
    "    safe_viz_end_date = master_trading_days[viz_end_idx]\n",
    "    \n",
    "    if safe_start_date >= safe_calc_end_date:\n",
    "        return ({'error': \"Invalid date range (calc period has zero or negative length).\"}, None)\n",
    "\n",
    "    # 2. Slice data for the calculation period and filter for valid tickers\n",
    "    calc_close_raw = df_close_full.loc[safe_start_date:safe_calc_end_date]\n",
    "    calc_close = calc_close_raw.dropna(axis=1, how='all') # Drop tickers with no data in the period\n",
    "    if calc_close.shape[1] == 0 or len(calc_close) < 2:\n",
    "        return ({'error': \"Not enough data in calc period.\"}, None)\n",
    "\n",
    "    # 3. Calculate ranking metrics for all valid tickers\n",
    "    first_prices = calc_close.bfill().iloc[0]\n",
    "    last_prices = calc_close.ffill().iloc[-1]\n",
    "    daily_returns = calc_close.bfill().ffill().pct_change()\n",
    "    mean_returns = daily_returns.mean()\n",
    "    std_returns = daily_returns.std()\n",
    "    \n",
    "    valid_tickers = calc_close.columns\n",
    "    calc_high = df_high_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "    calc_low = df_low_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "    \n",
    "    # Correctly calculate True Range (TR) for a multi-ticker DataFrame\n",
    "    # First, align the previous day's close to the current calculation window.\n",
    "    prev_close = df_close_full[valid_tickers].shift(1).loc[safe_start_date:safe_calc_end_date]\n",
    "    \n",
    "    # Calculate the three components of True Range. Each result is a DataFrame.\n",
    "    component1 = calc_high - calc_low\n",
    "    component2 = abs(calc_high - prev_close)\n",
    "    component3 = abs(calc_low - prev_close)\n",
    "\n",
    "    # Find the element-wise maximum across the three component DataFrames.\n",
    "    # np.maximum is efficient and preserves the DataFrame structure.\n",
    "    tr = np.maximum(component1, np.maximum(component2, component3))\n",
    "    \n",
    "    atr = tr.ewm(alpha=1/14, adjust=False).mean()\n",
    "    atrp = (atr / calc_close).mean() # Mean ATRP over the calculation period\n",
    "\n",
    "    metric_values = {}\n",
    "    metric_values['Price'] = (last_prices / first_prices).dropna()\n",
    "    metric_values['Sharpe'] = (mean_returns / std_returns * np.sqrt(252)).fillna(0)\n",
    "    metric_values['Sharpe (ATR)'] = (mean_returns / atrp).fillna(0)\n",
    "\n",
    "    if debug:\n",
    "        df_ranking = pd.DataFrame({\n",
    "            'FirstPrice': first_prices, 'LastPrice': last_prices, 'MeanDailyReturn': mean_returns,\n",
    "            'StdDevDailyReturn': std_returns, 'MeanATRP': atrp, 'Metric_Price': metric_values['Price'],\n",
    "            'Metric_Sharpe': metric_values['Sharpe'], 'Metric_Sharpe (ATR)': metric_values['Sharpe (ATR)']\n",
    "        })\n",
    "        df_ranking.index.name = 'Ticker'\n",
    "        debug_data['ranking_metrics'] = df_ranking.sort_values(f'Metric_{metric}', ascending=False)\n",
    "\n",
    "    # 4. Rank tickers and select the target group\n",
    "    sorted_tickers = metric_values[metric].sort_values(ascending=False)\n",
    "    tickers_to_display = sorted_tickers.index[rank_start-1:rank_end].tolist()\n",
    "    if not tickers_to_display:\n",
    "        return ({'error': \"No tickers found for the selected rank.\"}, None)\n",
    "\n",
    "    # 5. Prepare data for plotting and portfolio performance calculation\n",
    "    normalized_plot_data = df_close_full[tickers_to_display].loc[safe_start_date:safe_viz_end_date]\n",
    "    normalized_plot_data = normalized_plot_data.div(normalized_plot_data.bfill().iloc[0])\n",
    "    actual_calc_end_ts = calc_close.index.max()\n",
    "    portfolio_series = normalized_plot_data.mean(axis=1)\n",
    "    portfolio_return_series = portfolio_series.pct_change()\n",
    "    benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "    benchmark_return_series = benchmark_price_series.loc[safe_start_date:safe_viz_end_date].bfill().ffill().pct_change() if benchmark_price_series is not None else pd.Series(dtype='float64')\n",
    "\n",
    "    # 6. Correctly slice return series for Sharpe calculation to prevent lookahead\n",
    "    try:\n",
    "        # Use index location for a clean, non-overlapping split\n",
    "        boundary_loc = portfolio_return_series.index.get_loc(actual_calc_end_ts)\n",
    "        calc_portfolio_returns = portfolio_return_series.iloc[:boundary_loc + 1]\n",
    "        fwd_portfolio_returns = portfolio_return_series.iloc[boundary_loc + 1:]\n",
    "        \n",
    "        if benchmark_price_series is not None:\n",
    "            bm_boundary_loc = benchmark_return_series.index.get_loc(actual_calc_end_ts)\n",
    "            calc_benchmark_returns = benchmark_return_series.iloc[:bm_boundary_loc + 1]\n",
    "            fwd_benchmark_returns = benchmark_return_series.iloc[bm_boundary_loc + 1:]\n",
    "        else:\n",
    "            calc_benchmark_returns, fwd_benchmark_returns = pd.Series(dtype='float64'), pd.Series(dtype='float64')\n",
    "            \n",
    "    except (KeyError, IndexError): # Fallback for edge cases\n",
    "        calc_portfolio_returns = portfolio_return_series.loc[:actual_calc_end_ts]\n",
    "        fwd_portfolio_returns = portfolio_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "        if benchmark_price_series is not None:\n",
    "            calc_benchmark_returns = benchmark_return_series.loc[:actual_calc_end_ts]\n",
    "            fwd_benchmark_returns = benchmark_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "        else:\n",
    "            calc_benchmark_returns, fwd_benchmark_returns = pd.Series(dtype='float64'), pd.Series(dtype='float64')\n",
    "\n",
    "    # 7. Calculate performance metrics (Gain & Sharpe) for all periods\n",
    "    perf_data = {}\n",
    "    perf_data['calc_p_gain'] = calculate_gain(portfolio_series.loc[:actual_calc_end_ts])\n",
    "    perf_data['fwd_p_gain'] = calculate_gain(portfolio_series.loc[actual_calc_end_ts:])\n",
    "    perf_data['full_p_gain'] = calculate_gain(portfolio_series)\n",
    "    perf_data['calc_p_sharpe'] = calculate_sharpe(calc_portfolio_returns)\n",
    "    perf_data['fwd_p_sharpe'] = calculate_sharpe(fwd_portfolio_returns)\n",
    "    perf_data['full_p_sharpe'] = calculate_sharpe(portfolio_return_series)\n",
    "    \n",
    "    perf_data['calc_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:actual_calc_end_ts]) if benchmark_price_series is not None else np.nan\n",
    "    perf_data['fwd_b_gain'] = calculate_gain(benchmark_price_series.loc[actual_calc_end_ts:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "    perf_data['full_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "    perf_data['calc_b_sharpe'] = calculate_sharpe(calc_benchmark_returns)\n",
    "    perf_data['fwd_b_sharpe'] = calculate_sharpe(fwd_benchmark_returns)\n",
    "    perf_data['full_b_sharpe'] = calculate_sharpe(benchmark_return_series)\n",
    "\n",
    "    # 8. Assemble results DataFrame for display\n",
    "    calc_end_prices = calc_close.ffill().iloc[-1]\n",
    "    fwd_close_slice = df_close_full.loc[actual_calc_end_ts:safe_viz_end_date]\n",
    "    viz_end_prices = fwd_close_slice.ffill().iloc[-1] if not fwd_close_slice.empty and len(fwd_close_slice) >= 2 else calc_end_prices\n",
    "    calc_gains = (calc_end_prices / calc_close.bfill().iloc[0]) - 1\n",
    "    fwd_gains = (viz_end_prices / calc_end_prices) - 1\n",
    "    results_df = pd.DataFrame({'Rank': range(rank_start, rank_start + len(tickers_to_display)), 'Metric': metric, 'MetricValue': sorted_tickers.loc[tickers_to_display].values, 'CalcPrice': calc_end_prices.loc[tickers_to_display], 'CalcGain': calc_gains.loc[tickers_to_display], 'FwdGain': fwd_gains.loc[tickers_to_display]}, index=pd.Index(tickers_to_display, name='Ticker'))\n",
    "    if benchmark_price_series is not None and benchmark_ticker in calc_close.columns:\n",
    "        benchmark_df_row = pd.DataFrame({'Rank': np.nan, 'Metric': metric, 'MetricValue': metric_values[metric].get(benchmark_ticker, np.nan), 'CalcPrice': calc_end_prices[benchmark_ticker], 'CalcGain': calc_gains[benchmark_ticker], 'FwdGain': fwd_gains[benchmark_ticker]}, index=pd.Index([f\"{benchmark_ticker} (BM)\"], name='Ticker'))\n",
    "        results_df = pd.concat([results_df, benchmark_df_row])\n",
    "    \n",
    "    # 9. Assemble debug data if requested\n",
    "    if debug:\n",
    "        df_trace = normalized_plot_data.copy()\n",
    "        df_trace.columns = [f'Norm_Price_{c}' for c in df_trace.columns]\n",
    "        df_trace['Norm_Price_Portfolio'] = portfolio_series\n",
    "        if benchmark_price_series is not None and not benchmark_price_series.loc[safe_start_date:safe_viz_end_date].dropna().empty:\n",
    "            norm_bm = benchmark_price_series.loc[safe_start_date:safe_viz_end_date] / benchmark_price_series.loc[safe_start_date:].bfill().iloc[0]\n",
    "            df_trace[f'Norm_Price_Benchmark_{benchmark_ticker}'] = norm_bm\n",
    "        for col in df_trace.columns:\n",
    "            if 'Norm_Price' in col:\n",
    "                df_trace[col.replace('Norm_Price', 'Return')] = df_trace[col].pct_change()\n",
    "        debug_data['portfolio_trace'] = df_trace\n",
    "\n",
    "    # 10. Package final results\n",
    "    final_results = {\n",
    "        'tickers_to_display': tickers_to_display, 'normalized_plot_data': normalized_plot_data,\n",
    "        'portfolio_series': portfolio_series, 'benchmark_price_series': benchmark_price_series,\n",
    "        'performance_data': perf_data, 'results_df': results_df, 'actual_calc_end_ts': actual_calc_end_ts,\n",
    "        'safe_start_date': safe_start_date, 'safe_viz_end_date': safe_viz_end_date,\n",
    "        'error': None\n",
    "    }\n",
    "    return (final_results, debug_data)\n",
    "\n",
    "# --- C. DYNAMIC DATA QUALITY FILTER FUNCTIONS ---\n",
    "\n",
    "def calculate_rolling_quality_metrics(df_ohlcv, window=252, min_periods=126, debug=False):\n",
    "    \"\"\"Calculates rolling data quality metrics for the entire dataset.\"\"\"\n",
    "    print(f\"--- Calculating Rolling Quality Metrics (Window: {window} days) ---\")\n",
    "    df = df_ohlcv.copy()\n",
    "    if not df.index.is_monotonic_increasing:\n",
    "        df.sort_index(inplace=True)\n",
    "        \n",
    "    # Define quality flags\n",
    "    df['IsStale'] = np.where((df['Volume'] == 0) | (df['Adj High'] == df['Adj Low']), 1, 0)\n",
    "    df['DollarVolume'] = df['Adj Close'] * df['Volume']\n",
    "    df['HasSameVolumeAsPrevDay'] = (df.groupby(level='Ticker')['Volume'].diff() == 0).astype(int)\n",
    "    \n",
    "    # Calculate rolling metrics per ticker\n",
    "    grouped = df.groupby(level='Ticker')\n",
    "    stale_pct = grouped['IsStale'].rolling(window=window, min_periods=min_periods).mean()\n",
    "    median_vol = grouped['DollarVolume'].rolling(window=window, min_periods=min_periods).median()\n",
    "    same_vol_count = grouped['HasSameVolumeAsPrevDay'].rolling(window=window, min_periods=min_periods).sum()\n",
    "    \n",
    "    quality_df = pd.concat([stale_pct, median_vol, same_vol_count], axis=1)\n",
    "    quality_df.columns = ['RollingStalePct', 'RollingMedianVolume', 'RollingSameVolCount']\n",
    "    quality_df.index = quality_df.index.droplevel(0) # Remove the extra 'Ticker' level\n",
    "    print(\"✅ Rolling metrics calculation complete.\")\n",
    "    return quality_df\n",
    "\n",
    "def get_eligible_universe(quality_metrics_df, filter_date, thresholds):\n",
    "    \"\"\"Filters the universe of tickers based on quality metrics for a given date.\"\"\"\n",
    "    filter_date_ts = pd.to_datetime(filter_date)\n",
    "    date_index = quality_metrics_df.index.get_level_values('Date').unique().sort_values()\n",
    "    \n",
    "    if filter_date_ts < date_index[0]:\n",
    "        print(f\"Warning: Filter date {filter_date_ts.date()} is before the earliest data point. Returning empty universe.\")\n",
    "        return []\n",
    "        \n",
    "    # Find the most recent date with quality data on or before the filter date\n",
    "    valid_prior_dates = date_index[date_index <= filter_date_ts]\n",
    "    if valid_prior_dates.empty:\n",
    "        print(f\"Warning: No available data found on or before {filter_date_ts.date()}. Returning empty universe.\")\n",
    "        return []\n",
    "        \n",
    "    actual_date_to_use = valid_prior_dates[-1]\n",
    "    if actual_date_to_use.date() != filter_date_ts.date():\n",
    "        print(f\"ℹ️ Info: Filter date {filter_date_ts.date()} not found. Using previous available date {actual_date_to_use.date()}.\")\n",
    "\n",
    "    metrics_on_date = quality_metrics_df.xs(actual_date_to_use, level='Date')\n",
    "    \n",
    "    # Apply filters\n",
    "    mask = ((metrics_on_date['RollingMedianVolume'] >= thresholds['min_median_dollar_volume']) &\n",
    "            (metrics_on_date['RollingStalePct'] <= thresholds['max_stale_pct']) &\n",
    "            (metrics_on_date['RollingSameVolCount'] <= thresholds['max_same_vol_count']))\n",
    "            \n",
    "    eligible_tickers = metrics_on_date[mask].index.tolist()\n",
    "    all_tickers = metrics_on_date.index.tolist()\n",
    "    print(f\"Dynamic Filter ({filter_date_ts.date()}): Kept {len(eligible_tickers)} of {len(all_tickers)} tickers.\")\n",
    "    return eligible_tickers    \n",
    "\n",
    "# --- D. INTERACTIVE ANALYSIS & BACKTESTING TOOLS ---\n",
    "\n",
    "def plot_walk_forward_analyzer(df_ohlcv, \n",
    "                               default_start_date=None, default_calc_period=126, default_fwd_period=63,\n",
    "                               default_metric='Sharpe (ATR)', default_rank_start=1, default_rank_end=10,\n",
    "                               default_benchmark_ticker='VOO', master_calendar_ticker='VOO',\n",
    "                               quality_thresholds={'min_median_dollar_volume': 1_000_000, 'max_stale_pct': 0.05, 'max_same_vol_count': 10},\n",
    "                               debug=False):\n",
    "    \"\"\"Creates an interactive widget for single-period walk-forward analysis.\"\"\"\n",
    "    print(\"Initializing Walk-Forward Analyzer (using Trading Day Logic)...\")\n",
    "    if not isinstance(df_ohlcv.index, pd.MultiIndex): raise ValueError(\"Input DataFrame must have a (Ticker, Date) MultiIndex.\")\n",
    "    df_ohlcv = df_ohlcv.sort_index()\n",
    "\n",
    "    if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "        raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "    master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "    print(f\"Master trading day calendar created from '{master_calendar_ticker}' ({len(master_trading_days)} days).\")\n",
    "\n",
    "    # # The following functions are assumed to exist and are not provided in the original code.\n",
    "    # # We define placeholders for them to make the example runnable if needed.\n",
    "    # # --- Placeholder functions ---\n",
    "    # def calculate_rolling_quality_metrics(df, window):\n",
    "    #     # In a real scenario, this would calculate dollar volume, stale percent, etc.\n",
    "    #     # For this fix, we can just return an empty DataFrame or a simplified one.\n",
    "    #     tickers = df.index.get_level_values(0).unique()\n",
    "    #     dates = df.index.get_level_values(1).unique()\n",
    "    #     return pd.DataFrame(index=pd.MultiIndex.from_product([tickers, dates], names=['Ticker', 'Date']))\n",
    "    \n",
    "    # def get_eligible_universe(quality_df, date, thresholds):\n",
    "    #     # This would filter tickers based on quality metrics.\n",
    "    #     # For this fix, we'll just return all available tickers at that point.\n",
    "    #     tickers = quality_df.index.get_level_values(0).unique()\n",
    "    #     return list(tickers)\n",
    "\n",
    "    # def run_walk_forward_step(*args, **kwargs):\n",
    "    #     # This is the core engine. Since we are fixing the caller, \n",
    "    #     # we don't need its implementation, just the expected return signature.\n",
    "    #     # Returning a dummy structure with an error is fine for demonstrating the fix's context.\n",
    "    #     return {'error': \"This is a placeholder function.\"}, None\n",
    "    # # --- End Placeholder functions ---\n",
    "\n",
    "    print(\"Pre-calculating data quality metrics...\")\n",
    "    quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "    print(\"Pre-processing data (unstacking)...\")\n",
    "    df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "    df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "    df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    \n",
    "    # --- Widget Setup ---\n",
    "    start_date_picker = widgets.DatePicker(description='Start Date:', value=pd.to_datetime(default_start_date), disabled=False)\n",
    "    calc_period_input = widgets.IntText(value=default_calc_period, description='Calc Period (days):')\n",
    "    fwd_period_input = widgets.IntText(value=default_fwd_period, description='Fwd Period (days):')\n",
    "    metrics = ['Price', 'Sharpe', 'Sharpe (ATR)']\n",
    "    metric_dropdown = widgets.Dropdown(options=metrics, value=default_metric, description='Metric:')\n",
    "    rank_start_input = widgets.IntText(value=default_rank_start, description='Rank Start:')\n",
    "    rank_end_input = widgets.IntText(value=default_rank_end, description='Rank End:')\n",
    "    benchmark_ticker_input = widgets.Text(value=default_benchmark_ticker, description='Benchmark:', placeholder='Enter Ticker')\n",
    "    update_button = widgets.Button(description=\"Update Chart\", button_style='primary')\n",
    "    ticker_list_output = widgets.Output()\n",
    "    results_container, debug_data_container = [None], [None] # Use list wrapper for mutable access in callback\n",
    "\n",
    "    # --- Plotting Setup ---\n",
    "    fig = go.FigureWidget()\n",
    "    max_traces = 50 # Pre-allocate traces for performance\n",
    "    for i in range(max_traces): fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name=f'placeholder_{i}', visible=False, showlegend=False))\n",
    "    fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Benchmark', visible=True, showlegend=True, line=dict(color='black', width=3, dash='dash')))\n",
    "    fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Group Portfolio', visible=True, showlegend=True, line=dict(color='green', width=3)))\n",
    "\n",
    "    # --- Update Logic (Callback) ---\n",
    "    def update_plot(button_click):\n",
    "        ticker_list_output.clear_output()\n",
    "        \n",
    "        # 1. Get and validate user inputs\n",
    "        start_date_raw = pd.to_datetime(start_date_picker.value)\n",
    "        start_date_idx = master_trading_days.searchsorted(start_date_raw) # Find first trading day on or after selected date\n",
    "        if start_date_idx >= len(master_trading_days):\n",
    "            with ticker_list_output: print(f\"Error: Start date is after the last available trading day.\"); return\n",
    "        actual_start_date = master_trading_days[start_date_idx]\n",
    "        with ticker_list_output: \n",
    "            if start_date_raw.date() != actual_start_date.date():\n",
    "                print(f\"ℹ️ Info: Start date {start_date_raw.date()} is not a trading day. Snapping forward to {actual_start_date.date()}.\")\n",
    "\n",
    "        calc_period, fwd_period = calc_period_input.value, fwd_period_input.value\n",
    "        metric = metric_dropdown.value\n",
    "        rank_start, rank_end = rank_start_input.value, rank_end_input.value\n",
    "        benchmark_ticker = benchmark_ticker_input.value.strip().upper()\n",
    "        \n",
    "        if rank_start > rank_end:\n",
    "            with ticker_list_output: print(\"Error: 'Rank Start' must be <= 'Rank End'.\"); return\n",
    "        if rank_start < 1 or calc_period < 2 or fwd_period < 1:\n",
    "            with ticker_list_output: print(\"Error: Ranks must be >= 1, Calc Period >= 2, Fwd Period >= 1.\"); return\n",
    "\n",
    "        # ======================= BUG FIX START =======================\n",
    "        # 1a. Validate that there's enough data for the full analysis period from the start date.\n",
    "        required_days = calc_period + fwd_period\n",
    "        # The required slice is from start_date_idx to start_date_idx + required_days - 1.\n",
    "        # This means the slice has length 'required_days'.\n",
    "        # For this to be valid, the end of the slice must be within the bounds of the array.\n",
    "        if start_date_idx + required_days > len(master_trading_days):\n",
    "            available_days = len(master_trading_days) - start_date_idx\n",
    "            last_available_date = master_trading_days[-1].date()\n",
    "            with ticker_list_output:\n",
    "                print(f\"Error: Not enough data for the requested period.\")\n",
    "                print(f\"  Start Date: {actual_start_date.date()}\")\n",
    "                print(f\"  Required Days: {calc_period} (calc) + {fwd_period} (fwd) = {required_days}\")\n",
    "                print(f\"  Available Days from Start: {available_days} (until {last_available_date})\")\n",
    "                print(f\"  Please shorten the 'Calc Period' / 'Fwd Period' or choose an earlier 'Start Date'.\")\n",
    "            return\n",
    "        # ======================= BUG FIX END =========================\n",
    "\n",
    "        # 2. Apply dynamic data quality filter\n",
    "        eligible_tickers = get_eligible_universe(quality_metrics_df, actual_start_date, quality_thresholds)\n",
    "        if not eligible_tickers:\n",
    "            with ticker_list_output: print(f\"Error: No eligible tickers found on {actual_start_date.date()} with the current quality filters.\"); return\n",
    "        df_close_step = df_close_full[eligible_tickers]; df_high_step = df_high_full[eligible_tickers]; df_low_step = df_low_full[eligible_tickers]\n",
    "\n",
    "        # 3. Run the core calculation\n",
    "        try:\n",
    "            results, debug_output = run_walk_forward_step(\n",
    "                df_close_step, df_high_step, df_low_step, master_trading_days,\n",
    "                actual_start_date, calc_period, fwd_period, \n",
    "                metric, rank_start, rank_end, benchmark_ticker, debug=debug\n",
    "            )\n",
    "        except Exception as e:\n",
    "            # Added a try/except block for robustness in case run_walk_forward_step fails\n",
    "            with ticker_list_output: print(f\"An unexpected error occurred during calculation: {e}\"); return\n",
    "        \n",
    "        if results.get('error'): # Use .get() for safer dictionary access\n",
    "            with ticker_list_output: print(f\"Error: {results['error']}\"); return\n",
    "\n",
    "        # 4. Update the interactive plot\n",
    "        with fig.batch_update():\n",
    "            # Update individual ticker traces\n",
    "            for i in range(max_traces):\n",
    "                trace = fig.data[i]\n",
    "                if i < len(results['tickers_to_display']):\n",
    "                    ticker = results['tickers_to_display'][i]; plot_data_series = results['normalized_plot_data'][ticker]\n",
    "                    trace.x, trace.y, trace.name, trace.visible, trace.showlegend = plot_data_series.index, plot_data_series.values, ticker, True, True\n",
    "                else: trace.visible, trace.showlegend = False, False\n",
    "            # Update benchmark trace\n",
    "            benchmark_trace = fig.data[max_traces]\n",
    "            if results['benchmark_price_series'] is not None and not results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']].dropna().empty:\n",
    "                normalized_benchmark = results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']] / results['benchmark_price_series'].loc[results['safe_start_date']:].bfill().iloc[0]\n",
    "                benchmark_trace.x, benchmark_trace.y, benchmark_trace.name, benchmark_trace.visible = normalized_benchmark.index, normalized_benchmark, f\"Benchmark ({benchmark_ticker})\", True\n",
    "            else: benchmark_trace.visible = False\n",
    "            # Update portfolio trace\n",
    "            portfolio_trace = fig.data[max_traces + 1]\n",
    "            portfolio_trace.x, portfolio_trace.y, portfolio_trace.name, portfolio_trace.visible = results['portfolio_series'].index, results['portfolio_series'], 'Group Portfolio', True\n",
    "            # Update vertical line separating calc and fwd periods\n",
    "            fig.layout.shapes = []; fig.add_shape(type=\"line\", x0=results['actual_calc_end_ts'], y0=0, x1=results['actual_calc_end_ts'], y1=1, xref='x', yref='paper', line=dict(color=\"grey\", width=2, dash=\"dash\"))\n",
    "            \n",
    "        results_container[0] = results; debug_data_container[0] = debug_output\n",
    "        \n",
    "        # 5. Display summary statistics in a formatted table\n",
    "        with ticker_list_output:\n",
    "            print(f\"Analysis Period: {results['safe_start_date'].date()} to {results['safe_viz_end_date'].date()}.\")\n",
    "            pprint.pprint(results['tickers_to_display'])\n",
    "            p = results['performance_data']\n",
    "            rows = []\n",
    "            rows.append({'Metric': 'Group Portfolio Gain', 'Full': p['full_p_gain'], 'Calc': p['calc_p_gain'], 'Fwd': p['fwd_p_gain']})\n",
    "            if not np.isnan(p['full_b_gain']):\n",
    "                rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Gain', 'Full': p['full_b_gain'], 'Calc': p['calc_b_gain'], 'Fwd': p['fwd_b_gain']})\n",
    "                rows.append({'Metric': 'Gain Delta (vs Bm)', 'Full': p['full_p_gain'] - p['full_b_gain'], 'Calc': p['calc_p_gain'] - p['calc_b_gain'], 'Fwd': p['fwd_p_gain'] - p['fwd_b_gain']})\n",
    "            rows.append({'Metric': 'Group Portfolio Sharpe', 'Full': p['full_p_sharpe'], 'Calc': p['calc_p_sharpe'], 'Fwd': p['fwd_p_sharpe']})\n",
    "            if not np.isnan(p['full_b_sharpe']):\n",
    "                rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Sharpe', 'Full': p['full_b_sharpe'], 'Calc': p['calc_b_sharpe'], 'Fwd': p['fwd_b_sharpe']})\n",
    "                rows.append({'Metric': 'Sharpe Delta (vs Bm)', 'Full': p['full_p_sharpe'] - p['full_b_sharpe'], 'Calc': p['calc_p_sharpe'] - p['calc_b_sharpe'], 'Fwd': p['fwd_p_sharpe'] - p['fwd_b_sharpe']})\n",
    "            report_df = pd.DataFrame(rows).set_index('Metric')\n",
    "            gain_rows = [row for row in report_df.index if 'Gain' in row or 'Delta' in row]\n",
    "            sharpe_rows = [row for row in report_df.index if 'Sharpe' in row]\n",
    "            styled_df = report_df.style.format('{:+.2%}', na_rep='N/A', subset=(gain_rows, report_df.columns)).format('{:+.2f}', na_rep='N/A', subset=(sharpe_rows, report_df.columns)).set_properties(**{'text-align': 'right', 'width': '100px'}).set_table_styles([{'selector': 'th.col_heading', 'props': [('text-align', 'right')]}, {'selector': 'th.row_heading', 'props': [('text-align', 'left')]}])\n",
    "            print(\"\\n--- Strategy Performance Summary ---\")\n",
    "            display(styled_df)\n",
    "            \n",
    "    # --- Final Layout & Display ---\n",
    "    fig.update_layout(title_text='Walk-Forward Performance Analysis', xaxis_title='Date', yaxis_title='Normalized Price (Start = 1)', hovermode='x unified', legend_title_text='Tickers (Ranked)', height=600, margin=dict(t=50))\n",
    "    fig.add_hline(y=1, line_width=1, line_dash=\"dash\", line_color=\"grey\")\n",
    "    update_button.on_click(update_plot)\n",
    "    controls_row1 = widgets.HBox([start_date_picker, calc_period_input, fwd_period_input])\n",
    "    controls_row2 = widgets.HBox([metric_dropdown, rank_start_input, rank_end_input, benchmark_ticker_input, update_button])\n",
    "    ui_container = widgets.VBox([controls_row1, controls_row2, ticker_list_output], layout=widgets.Layout(margin='10px 0 20px 0'))\n",
    "    display(ui_container, fig)\n",
    "    update_plot(None) # Initial run\n",
    "    return (results_container, debug_data_container)\n",
    "\n",
    "def run_full_backtest(df_ohlcv, strategy_params, quality_thresholds):\n",
    "    \"\"\"Runs a full backtest of a strategy over a specified date range.\"\"\"\n",
    "    print(f\"--- Running Full Forensic Backtest for Strategy: {strategy_params['metric']} (Top {strategy_params['rank_start']}-{strategy_params['rank_end']}) ---\")\n",
    "    \n",
    "    # 1. Unpack strategy parameters\n",
    "    start_date, end_date = pd.to_datetime(strategy_params['start_date']), pd.to_datetime(strategy_params['end_date'])\n",
    "    calc_period, fwd_period = strategy_params['calc_period'], strategy_params['fwd_period']\n",
    "    metric, rank_start, rank_end = strategy_params['metric'], strategy_params['rank_start'], strategy_params['rank_end']\n",
    "    benchmark_ticker = strategy_params['benchmark_ticker']\n",
    "    master_calendar_ticker = strategy_params.get('master_calendar_ticker', 'VOO')\n",
    "    \n",
    "    # 2. Perform initial setup (same as analyzer)\n",
    "    if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "        raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "    master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "    \n",
    "    start_idx = master_trading_days.searchsorted(start_date)\n",
    "    end_idx = master_trading_days.searchsorted(end_date, side='right')\n",
    "    \n",
    "    quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "    df_close_full = df_ohlcv['Adj Close'].unstack(level=0); df_high_full = df_ohlcv['Adj High'].unstack(level=0); df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    \n",
    "    # 3. Loop through all periods in the backtest range\n",
    "    step_indices = range(start_idx, end_idx, fwd_period)\n",
    "    all_fwd_gains, period_by_period_debug = [], {}\n",
    "\n",
    "    print(f\"Simulating {len(step_indices)} periods from {master_trading_days[step_indices[0]].date()} to {master_trading_days[step_indices[-1]].date()}...\")\n",
    "    for current_idx in tqdm(step_indices, desc=\"Backtest Progress\"):\n",
    "        step_date = master_trading_days[current_idx]\n",
    "        \n",
    "        # Apply data quality filter for the current step\n",
    "        eligible_tickers = get_eligible_universe(quality_metrics_df, step_date, quality_thresholds)\n",
    "        if not eligible_tickers: continue\n",
    "        \n",
    "        df_close_step = df_close_full[eligible_tickers]; df_high_step = df_high_full[eligible_tickers]; df_low_step = df_low_full[eligible_tickers]\n",
    "        \n",
    "        # Run a single walk-forward analysis step\n",
    "        results, debug_output = run_walk_forward_step(\n",
    "            df_close_step, df_high_step, df_low_step, master_trading_days,\n",
    "            step_date, calc_period, fwd_period,\n",
    "            metric, rank_start, rank_end, benchmark_ticker, debug=True\n",
    "        )\n",
    "        \n",
    "        # Collect results for this period\n",
    "        if results['error'] is None:\n",
    "            fwd_series = results['portfolio_series'].loc[results['actual_calc_end_ts']:]\n",
    "            all_fwd_gains.append(fwd_series.pct_change().dropna())\n",
    "            period_by_period_debug[step_date.date().isoformat()] = debug_output\n",
    "            \n",
    "    if not all_fwd_gains:\n",
    "        print(\"Error: No valid periods were simulated.\"); return None\n",
    "\n",
    "    # 4. Stitch together the results to form a continuous equity curve\n",
    "    strategy_returns = pd.concat(all_fwd_gains); strategy_equity_curve = (1 + strategy_returns).cumprod()\n",
    "    benchmark_returns = df_close_full[benchmark_ticker].pct_change().loc[strategy_equity_curve.index]; benchmark_equity_curve = (1 + benchmark_returns).cumprod()\n",
    "    cumulative_equity_df = pd.DataFrame({'Strategy_Equity': strategy_equity_curve, 'Benchmark_Equity': benchmark_equity_curve})\n",
    "    \n",
    "    # 5. Plot the final equity curve\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=cumulative_equity_df.index, y=cumulative_equity_df['Strategy_Equity'], name='Strategy', line=dict(color='green')))\n",
    "    fig.add_trace(go.Scatter(x=cumulative_equity_df.index, y=cumulative_equity_df['Benchmark_Equity'], name=f'Benchmark ({benchmark_ticker})', line=dict(color='black', dash='dash')))\n",
    "    fig.update_layout(title=f\"Cumulative Performance: '{metric}' Strategy (Top {rank_start}-{rank_end})\", xaxis_title=\"Date\", yaxis_title=\"Cumulative Growth\")\n",
    "    fig.show()\n",
    "\n",
    "    # 6. Return the detailed results for forensic analysis\n",
    "    final_backtest_results = {'cumulative_performance': cumulative_equity_df, 'period_by_period_debug': period_by_period_debug}\n",
    "    print(\"\\n✅ Full backtest complete. Results object is ready for forensic analysis.\")\n",
    "    return final_backtest_results\n",
    "\n",
    "# --- E. VERIFICATION TOOLS (User Requested) ---\n",
    "\n",
    "def verify_group_tickers_walk_forward_calculation(df_ohlcv, tickers_to_verify, benchmark_ticker,\n",
    "                                                  start_date, calc_period, fwd_period,\n",
    "                                                  master_calendar_ticker='VOO', export_csv=False):\n",
    "    \"\"\"Verifies portfolio and benchmark performance and optionally exports the data.\"\"\"\n",
    "    display(Markdown(f\"## Verification Report for Portfolio vs. Benchmark\"))\n",
    "    display(Markdown(f\"**Portfolio Tickers:** `{tickers_to_verify}`\\n**Benchmark Ticker:** `{benchmark_ticker}`\"))\n",
    "    \n",
    "    # 1. Setup trading day calendar and determine exact period dates\n",
    "    if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "        raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "    master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "\n",
    "    start_date_raw = pd.to_datetime(start_date)\n",
    "    start_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "    if start_idx >= len(master_trading_days):\n",
    "        print(f\"Error: Start date {start_date_raw.date()} is after the last available trading day.\"); return\n",
    "    actual_start_date = master_trading_days[start_idx]\n",
    "    \n",
    "    calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "    fwd_end_idx = min(calc_end_idx + fwd_period, len(master_trading_days) - 1)\n",
    "    \n",
    "    actual_calc_end_date = master_trading_days[calc_end_idx]\n",
    "    actual_fwd_end_date = master_trading_days[fwd_end_idx]\n",
    "    \n",
    "    display(Markdown(f\"**Analysis Start:** `{actual_start_date.date()}` (Selected: `{start_date_raw.date()}`)\\n\"\n",
    "                    f\"**Calc End:** `{actual_calc_end_date.date()}` ({calc_period} trading days)\\n\"\n",
    "                    f\"**Fwd End:** `{actual_fwd_end_date.date()}` ({fwd_period} trading days)\"))\n",
    "\n",
    "    # 2. Recreate the portfolio and benchmark series from scratch\n",
    "    df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "    portfolio_prices_raw_slice = df_close_full[tickers_to_verify].loc[actual_start_date:actual_fwd_end_date]\n",
    "    portfolio_value_series = portfolio_prices_raw_slice.div(portfolio_prices_raw_slice.bfill().iloc[0]).mean(axis=1)\n",
    "    benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "    \n",
    "    # 3. Optionally export the underlying daily data to a CSV for external checking\n",
    "    if export_csv:\n",
    "        export_df = pd.DataFrame({\n",
    "            'Portfolio_Normalized_Price': portfolio_value_series,\n",
    "            'Portfolio_Daily_Return': portfolio_value_series.pct_change()\n",
    "        })\n",
    "        if benchmark_price_series is not None:\n",
    "            norm_bm = benchmark_price_series.loc[actual_start_date:actual_fwd_end_date]\n",
    "            norm_bm = norm_bm / norm_bm.bfill().iloc[0]\n",
    "            export_df['Benchmark_Normalized_Price'] = norm_bm\n",
    "            export_df['Benchmark_Daily_Return'] = norm_bm.pct_change()\n",
    "\n",
    "        output_dir = 'export_csv'\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        tickers_str = '_'.join(tickers_to_verify)\n",
    "        filename = f\"verify_group_{actual_start_date.date()}_{tickers_str}.csv\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        export_df.to_csv(filepath)\n",
    "        print(f\"\\n✅ Data exported to: {filepath}\")\n",
    "\n",
    "    # 4. Define a helper to print detailed calculation steps\n",
    "    def print_verification_steps(title, price_series):\n",
    "        display(Markdown(f\"#### Verification for: `{title}`\"))\n",
    "        if price_series.dropna().shape[0] < 2: print(\"  - Not enough data points.\"); return {'gain': np.nan, 'sharpe': np.nan}\n",
    "        start_price, end_price = price_series.bfill().iloc[0], price_series.ffill().iloc[-1]\n",
    "        gain = (end_price / start_price) - 1\n",
    "        print(f\"Start Value ({price_series.first_valid_index().date()}): {start_price:,.4f}\\nEnd Value   ({price_series.last_valid_index().date()}): {end_price:,.4f}\\nGain = {gain:.2%}\")\n",
    "        returns = price_series.pct_change()\n",
    "        sharpe = calculate_sharpe(returns)\n",
    "        print(f\"Mean Daily Return: {returns.mean():.6f}\\nStd Dev: {returns.std():.6f}\\nSharpe = {sharpe:.2f}\")\n",
    "        return {'gain': gain, 'sharpe': sharpe}\n",
    "\n",
    "    # 5. Run verification for each period\n",
    "    display(Markdown(\"### A. Calculation Period\"))\n",
    "    perf_calc_p = print_verification_steps(\"Group Portfolio\", portfolio_value_series.loc[actual_start_date:actual_calc_end_date])\n",
    "    if benchmark_price_series is not None:\n",
    "        perf_calc_b = print_verification_steps(f\"Benchmark\", benchmark_price_series.loc[actual_start_date:actual_calc_end_date])\n",
    "    \n",
    "    display(Markdown(\"### B. Forward Period\"))\n",
    "    perf_fwd_p = print_verification_steps(\"Group Portfolio\", portfolio_value_series.loc[actual_calc_end_date:actual_fwd_end_date])\n",
    "    if benchmark_price_series is not None:\n",
    "        perf_fwd_b = print_verification_steps(f\"Benchmark\", benchmark_price_series.loc[actual_calc_end_date:actual_fwd_end_date])\n",
    "\n",
    "def verify_ticker_ranking_metrics(df_ohlcv, ticker, start_date, calc_period,\n",
    "                                  master_calendar_ticker='VOO', export_csv=False):\n",
    "    \"\"\"Verifies ranking metrics for a single ticker and optionally exports the data.\"\"\"\n",
    "    display(Markdown(f\"## Verification Report for Ticker Ranking: `{ticker}`\"))\n",
    "    \n",
    "    # 1. Setup trading day calendar and determine exact period dates\n",
    "    if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "        raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "    master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "\n",
    "    start_date_raw = pd.to_datetime(start_date)\n",
    "    start_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "    if start_idx >= len(master_trading_days):\n",
    "        print(f\"Error: Start date {start_date_raw.date()} is after the last available trading day.\"); return\n",
    "    actual_start_date = master_trading_days[start_idx]\n",
    "    \n",
    "    calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "    actual_calc_end_date = master_trading_days[calc_end_idx]\n",
    "\n",
    "    # 2. Extract and prepare the raw data for the specific ticker and period\n",
    "    df_ticker = df_ohlcv.loc[ticker].sort_index()\n",
    "    calc_df = df_ticker.loc[actual_start_date:actual_calc_end_date].copy()\n",
    "    if calc_df.empty or len(calc_df) < 2: \n",
    "        print(\"No data or not enough data in calc period.\"); return\n",
    "\n",
    "    display(Markdown(\"### A. Calculation Period (for Ranking Metrics)\"))\n",
    "    display(Markdown(f\"**Period Start:** `{actual_start_date.date()}`\\n\"\n",
    "                    f\"**Period End:** `{actual_calc_end_date.date()}`\\n\"\n",
    "                    f\"**Total Trading Days:** `{len(calc_df)}` (Requested: `{calc_period}`)\"))\n",
    "    \n",
    "    display(Markdown(\"#### Detailed Metric Calculation Data\"))\n",
    "    \n",
    "    # 3. Calculate all intermediate metrics as new columns for full transparency\n",
    "    vdf = calc_df[['Adj High', 'Adj Low', 'Adj Close']].copy()\n",
    "    vdf['Daily_Return'] = vdf['Adj Close'].pct_change()\n",
    "    \n",
    "    # Corrected True Range (TR) calculation for a single ticker (Series)\n",
    "    tr_df = pd.DataFrame({\n",
    "        'h_l': vdf['Adj High'] - vdf['Adj Low'],\n",
    "        'h_cp': abs(vdf['Adj High'] - vdf['Adj Close'].shift(1)),\n",
    "        'l_cp': abs(vdf['Adj Low'] - vdf['Adj Close'].shift(1))\n",
    "    })\n",
    "    vdf['TR'] = tr_df.max(axis=1)\n",
    "    \n",
    "    vdf['ATR_14'] = vdf['TR'].ewm(alpha=1/14, adjust=False).mean()\n",
    "    vdf['ATRP'] = vdf['ATR_14'] / vdf['Adj Close']\n",
    "    \n",
    "    print(\"--- Start of Calculation Period ---\")\n",
    "    display(vdf.head())\n",
    "    print(\"\\n--- End of Calculation Period ---\")\n",
    "    display(vdf.tail())\n",
    "\n",
    "    # 4. Optionally export this detailed breakdown to CSV\n",
    "    if export_csv:\n",
    "        output_dir = 'export_csv'\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        filename = f\"verify_ticker_{actual_start_date.date()}_{ticker}.csv\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        vdf.to_csv(filepath)\n",
    "        print(f\"\\n✅ Data exported to: {filepath}\")\n",
    "    \n",
    "    # 5. Print final metric calculations with formulas\n",
    "    display(Markdown(\"#### `MetricValue` Verification Summary:\"))\n",
    "    \n",
    "    calc_start_price = vdf['Adj Close'].bfill().iloc[0]\n",
    "    calc_end_price = vdf['Adj Close'].ffill().iloc[-1]\n",
    "    price_metric = (calc_end_price / calc_start_price)\n",
    "    print(f\"1. Price Metric: (Last Price / First Price) = ({calc_end_price:.2f} / {calc_start_price:.2f}) = {price_metric:.4f}\")\n",
    "    \n",
    "    daily_returns = vdf['Daily_Return'].dropna()\n",
    "    sharpe_ratio = calculate_sharpe(daily_returns)\n",
    "    print(f\"2. Sharpe Metric: (Mean Daily Return / Std Dev) * sqrt(252) = {sharpe_ratio:.4f}\")\n",
    "\n",
    "    atrp_mean = vdf['ATRP'].mean()\n",
    "    mean_daily_return = vdf['Daily_Return'].mean()\n",
    "    sharpe_atr = (mean_daily_return / atrp_mean) if atrp_mean > 0 else 0\n",
    "    print(f\"3. Sharpe (ATR) Metric: (Mean Daily Return / Mean ATRP) = ({mean_daily_return:.6f} / {atrp_mean:.6f}) = {sharpe_atr:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47ed713",
   "metadata": {},
   "source": [
    "#### **CELL 3: DATA LOADING**\n",
    "*This cell loads your main dataset using the environment-aware path.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a97e54a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load data from: c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet\n",
      "\n",
      "✅ Data loaded successfully.\n",
      "\n",
      "--- DataFrame Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 4423522 entries, ('A', Timestamp('1999-11-18 00:00:00')) to ('ZWS', Timestamp('2025-10-09 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   Adj Open   float64\n",
      " 1   Adj High   float64\n",
      " 2   Adj Low    float64\n",
      " 3   Adj Close  float64\n",
      " 4   Volume     int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 186.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# --- CELL 3: DATA LOADING ---\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "\n",
    "data_file_path = env_config['data_path']\n",
    "print(f\"Attempting to load data from: {data_file_path}\")\n",
    "\n",
    "try:\n",
    "    df_OHLCV = pd.read_parquet(data_file_path, engine='pyarrow')\n",
    "    df_dev = df_OHLCV.copy() # Use df_dev for development as a good practice\n",
    "    \n",
    "    print(\"\\n✅ Data loaded successfully.\")\n",
    "    print(\"\\n--- DataFrame Info ---\")\n",
    "    df_dev.info()\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\n❌ ERROR: FILE NOT FOUND at {data_file_path}. Please check paths in Cell 1.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b16e2e",
   "metadata": {},
   "source": [
    "#### **CELL 4: BOT STRATEGY CONFIGURATION**\n",
    "*This cell defines the strategy parameters you want to test.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "549adf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Bot Configuration Initialized ---\n",
      "Calculation Periods to Test: [252] trading days\n",
      "Forward and Holding Periods to Test (Forward and Holding Periods are the same): [63] trading days\n",
      "Results will be saved to: .\\export_csv\\dev_strategy_search_results.csv\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# --- CELL 4: BOT STRATEGY CONFIGURATION ---\n",
    "# ==============================================================================\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "\n",
    "# --- PRIMARY USER INPUTS FOR THE STRATEGY ---\n",
    "# 5,  21, 42, 63, 126, 252\n",
    "# 1W, 1M, 2M, 3M,  6M,  1Y\n",
    "HOLDING_PERIODS_DAYS = [63]        # Test ~2, and 3 month holding periods\n",
    "CALC_PERIODS_DAYS = [252]         # Use ~6 and 12 month lookbacks\n",
    "\n",
    "bot_config = {\n",
    "    # --- Time Parameters ---\n",
    "    'search_start_date': '2014-01-01',\n",
    "    'search_end_date': '2018-12-31',\n",
    "    \n",
    "    # --- Strategy Parameters (The Search Grid) ---\n",
    "    'calc_periods': CALC_PERIODS_DAYS,\n",
    "    'fwd_periods': HOLDING_PERIODS_DAYS,\n",
    "\n",
    "\n",
    "    # 'metrics': ['Sharpe', 'Sharpe (ATR)'],\n",
    "    'metrics': ['Price', 'Sharpe (ATR)'],    \n",
    "    \n",
    "    \n",
    "    'rank_slices': [(1, 5), (6, 10)],\n",
    "\n",
    "    # --- Data Quality ---\n",
    "    'quality_thresholds': { 'min_median_dollar_volume': 10_000_000, \n",
    "                            'max_stale_pct': 0.05, \n",
    "                            'max_same_vol_count': 1 },\n",
    "\n",
    "    # --- General Parameters ---\n",
    "    'benchmark_ticker': 'VOO',\n",
    "    'master_calendar_ticker': 'VOO',\n",
    "    'results_output_path': env_config['results_path']\n",
    "}\n",
    "\n",
    "print(\"\\n--- Bot Configuration Initialized ---\")\n",
    "print(f\"Calculation Periods to Test: {bot_config['calc_periods']} trading days\")\n",
    "print(f\"Forward and Holding Periods to Test (Forward and Holding Periods are the same): {bot_config['fwd_periods']} trading days\")\n",
    "print(f\"Results will be saved to: {bot_config['results_output_path']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba7698e",
   "metadata": {},
   "source": [
    "#### **CELL 5: AUTOMATION SCRIPT - STRATEGY SEARCH**\n",
    "*This cell contains the main automation function that uses checkpointing.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e63b59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# --- CELL 5: AUTOMATION SCRIPT - STRATEGY SEARCH ---\n",
    "# ==============================================================================\n",
    "import time\n",
    "from itertools import product\n",
    "\n",
    "def run_strategy_search(df_ohlcv, config):\n",
    "    \"\"\"\n",
    "    Runs the main backtesting loop with checkpointing to be resumable.\n",
    "    \"\"\"\n",
    "    start_time = time.time() # <-- This now works because of 'import time'\n",
    "    \n",
    "    # --- 1. SETUP & LOAD PROGRESS ---\n",
    "    print(\"--- Phase 1: Pre-processing and Loading Progress ---\")\n",
    "    quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "    print(\"Unstacking data for performance...\")\n",
    "    df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "    df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "    df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    \n",
    "    master_calendar_ticker = config['master_calendar_ticker']\n",
    "    master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "    print(f\"Master trading day calendar created from '{master_calendar_ticker}' ({len(master_trading_days)} days).\")\n",
    "\n",
    "    results_path = config['results_output_path']\n",
    "    completed_params = set()\n",
    "    \n",
    "    if os.path.exists(results_path): # <-- This now works because of 'import os'\n",
    "        print(f\"Found existing results file. Loading progress from: {results_path}\")\n",
    "        df_progress = pd.read_csv(results_path)\n",
    "        for _, row in df_progress.iterrows():\n",
    "            param_key = (\n",
    "                row['calc_period'], row['fwd_period'], row['metric'],\n",
    "                (row['rank_start'], row['rank_end'])\n",
    "            )\n",
    "            completed_params.add(param_key)\n",
    "        print(f\"Found {len(completed_params)} completed parameter sets to skip.\")\n",
    "    else:\n",
    "        print(\"No existing results file found. Starting a new run.\")\n",
    "\n",
    "    print(\"✅ Pre-processing complete.\\n\")\n",
    "\n",
    "    # --- 2. SETUP THE MAIN LOOP ---\n",
    "    print(\"--- Phase 2: Setting up Simulation Loops ---\")\n",
    "    \n",
    "    param_combinations = list(product(\n",
    "        config['calc_periods'], config['fwd_periods'],\n",
    "        config['metrics'], config['rank_slices']\n",
    "    ))\n",
    "    \n",
    "    search_start_date = pd.to_datetime(config['search_start_date'])\n",
    "    search_end_date = pd.to_datetime(config['search_end_date'])\n",
    "    start_idx = master_trading_days.searchsorted(search_start_date, side='left')\n",
    "    end_idx = master_trading_days.searchsorted(search_end_date, side='right')\n",
    "\n",
    "    step_dates_map = {}\n",
    "    print(\"Pre-calculating rebalancing schedules for each holding period...\")\n",
    "    for fwd_period in sorted(config['fwd_periods']):\n",
    "        step_indices = range(start_idx, end_idx, fwd_period)\n",
    "        step_dates_map[fwd_period] = master_trading_days[step_indices]\n",
    "        print(f\"  - Holding Period {fwd_period} days: {len(step_dates_map[fwd_period])} rebalances\")\n",
    "    \n",
    "    print(f\"Found {len(param_combinations)} total parameter sets to simulate.\")\n",
    "    print(\"✅ Setup complete. Starting main loop...\\n\")\n",
    "\n",
    "    # --- 3. RUN THE MAIN LOOP ---\n",
    "    print(\"--- Phase 3: Running Simulations ---\")\n",
    "    pbar = tqdm(param_combinations, desc=\"Parameter Sets\")\n",
    "    \n",
    "    for params in pbar:\n",
    "        calc_period, fwd_period, metric, rank_slice = params\n",
    "        rank_start, rank_end = rank_slice\n",
    "        \n",
    "        param_key = (calc_period, fwd_period, metric, rank_slice)\n",
    "        if param_key in completed_params:\n",
    "            pbar.set_description(f\"Skipping {param_key}\")\n",
    "            continue\n",
    "\n",
    "        pbar.set_description(f\"Running {param_key}\")\n",
    "        \n",
    "        current_params_results = []\n",
    "        \n",
    "        # ==============================================================================\n",
    "        # --- FIX: RESTORED THE MISSING INNER LOOP ---\n",
    "        # ==============================================================================\n",
    "        current_step_dates = step_dates_map[fwd_period]\n",
    "        for step_date in current_step_dates:\n",
    "            eligible_tickers = get_eligible_universe(\n",
    "                quality_metrics_df, filter_date=step_date, thresholds=config['quality_thresholds']\n",
    "            )\n",
    "            if not eligible_tickers: continue\n",
    "            \n",
    "            df_close_step = df_close_full[eligible_tickers]\n",
    "            df_high_step = df_high_full[eligible_tickers]\n",
    "            df_low_step = df_low_full[eligible_tickers]\n",
    "\n",
    "            step_result, _ = run_walk_forward_step(\n",
    "                df_close_full=df_close_step, df_high_full=df_high_step, df_low_full=df_low_step,\n",
    "                master_trading_days=master_trading_days, start_date=step_date,\n",
    "                calc_period=calc_period, fwd_period=fwd_period,\n",
    "                metric=metric, rank_start=rank_start, rank_end=rank_end,\n",
    "                benchmark_ticker=config['benchmark_ticker'], debug=False\n",
    "            )\n",
    "            \n",
    "            if step_result['error'] is None:\n",
    "                p = step_result['performance_data']\n",
    "                log_entry = {\n",
    "                    'step_date': step_date.date(), 'calc_period': calc_period,\n",
    "                    'fwd_period': fwd_period, 'metric': metric,\n",
    "                    'rank_start': rank_start, 'rank_end': rank_end,\n",
    "                    'num_universe': len(eligible_tickers),\n",
    "                    'num_portfolio': len(step_result['tickers_to_display']),\n",
    "                    'fwd_p_gain': p['fwd_p_gain'], 'fwd_b_gain': p['fwd_b_gain'],\n",
    "                    'fwd_gain_delta': p['fwd_p_gain'] - p['fwd_b_gain'] if not np.isnan(p['fwd_b_gain']) else np.nan,\n",
    "                    'fwd_p_sharpe': p['fwd_p_sharpe'],\n",
    "                }\n",
    "                current_params_results.append(log_entry)\n",
    "        # ==============================================================================\n",
    "        \n",
    "        # --- CHECKPOINTING: INCREMENTAL SAVE ---\n",
    "        if current_params_results:\n",
    "            df_to_append = pd.DataFrame(current_params_results)\n",
    "            df_to_append.to_csv(\n",
    "                results_path,\n",
    "                mode='a',\n",
    "                header=not os.path.exists(results_path),\n",
    "                index=False\n",
    "            )\n",
    "            completed_params.add(param_key)\n",
    "\n",
    "    print(\"✅ Main loop finished.\\n\")\n",
    "    \n",
    "    # --- 4. RETURN FINAL DATAFRAME ---\n",
    "    print(\"--- Phase 4: Loading Final Results ---\")\n",
    "    if os.path.exists(results_path):\n",
    "        final_df = pd.read_csv(results_path)\n",
    "        end_time = time.time()\n",
    "        print(f\"✅ Process complete. Total execution time: {time.time() - start_time:.2f} seconds.\")\n",
    "        return final_df\n",
    "    else:\n",
    "        print(\"Warning: No results were generated.\")\n",
    "        return None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df014e8e",
   "metadata": {},
   "source": [
    "#### **CELL 6: EXECUTION**\n",
    "*This is the final cell that runs the backtest and displays the results.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7485bf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Phase 1: Pre-processing and Loading Progress ---\n",
      "--- Calculating Rolling Quality Metrics (Window: 252 days) ---\n",
      "✅ Rolling metrics calculation complete.\n",
      "Unstacking data for performance...\n",
      "Master trading day calendar created from 'VOO' (3795 days).\n",
      "Found existing results file. Loading progress from: .\\export_csv\\dev_strategy_search_results.csv\n",
      "Found 16 completed parameter sets to skip.\n",
      "✅ Pre-processing complete.\n",
      "\n",
      "--- Phase 2: Setting up Simulation Loops ---\n",
      "Pre-calculating rebalancing schedules for each holding period...\n",
      "  - Holding Period 63 days: 20 rebalances\n",
      "Found 4 total parameter sets to simulate.\n",
      "✅ Setup complete. Starting main loop...\n",
      "\n",
      "--- Phase 3: Running Simulations ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "463f038f9d4149e3a30f20c7b4576f55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parameter Sets:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic Filter (2014-01-02): Kept 456 of 617 tickers.\n",
      "Dynamic Filter (2014-04-03): Kept 467 of 620 tickers.\n",
      "Dynamic Filter (2014-07-03): Kept 480 of 627 tickers.\n",
      "Dynamic Filter (2014-10-02): Kept 489 of 635 tickers.\n",
      "Dynamic Filter (2015-01-02): Kept 498 of 642 tickers.\n",
      "Dynamic Filter (2015-04-06): Kept 510 of 644 tickers.\n",
      "Dynamic Filter (2015-07-06): Kept 520 of 651 tickers.\n",
      "Dynamic Filter (2015-10-02): Kept 526 of 660 tickers.\n",
      "Dynamic Filter (2016-01-04): Kept 531 of 665 tickers.\n",
      "Dynamic Filter (2016-04-05): Kept 535 of 668 tickers.\n",
      "Dynamic Filter (2016-07-05): Kept 542 of 672 tickers.\n",
      "Dynamic Filter (2016-10-03): Kept 543 of 680 tickers.\n",
      "Dynamic Filter (2017-01-03): Kept 555 of 684 tickers.\n",
      "Dynamic Filter (2017-04-04): Kept 564 of 687 tickers.\n",
      "Dynamic Filter (2017-07-05): Kept 576 of 694 tickers.\n",
      "Dynamic Filter (2017-10-03): Kept 587 of 695 tickers.\n",
      "Dynamic Filter (2018-01-03): Kept 591 of 701 tickers.\n",
      "Dynamic Filter (2018-04-05): Kept 600 of 707 tickers.\n",
      "Dynamic Filter (2018-07-05): Kept 612 of 716 tickers.\n",
      "Dynamic Filter (2018-10-03): Kept 618 of 722 tickers.\n",
      "Dynamic Filter (2014-01-02): Kept 456 of 617 tickers.\n",
      "Dynamic Filter (2014-04-03): Kept 467 of 620 tickers.\n",
      "Dynamic Filter (2014-07-03): Kept 480 of 627 tickers.\n",
      "Dynamic Filter (2014-10-02): Kept 489 of 635 tickers.\n",
      "Dynamic Filter (2015-01-02): Kept 498 of 642 tickers.\n",
      "Dynamic Filter (2015-04-06): Kept 510 of 644 tickers.\n",
      "Dynamic Filter (2015-07-06): Kept 520 of 651 tickers.\n",
      "Dynamic Filter (2015-10-02): Kept 526 of 660 tickers.\n",
      "Dynamic Filter (2016-01-04): Kept 531 of 665 tickers.\n",
      "Dynamic Filter (2016-04-05): Kept 535 of 668 tickers.\n",
      "Dynamic Filter (2016-07-05): Kept 542 of 672 tickers.\n",
      "Dynamic Filter (2016-10-03): Kept 543 of 680 tickers.\n",
      "Dynamic Filter (2017-01-03): Kept 555 of 684 tickers.\n",
      "Dynamic Filter (2017-04-04): Kept 564 of 687 tickers.\n",
      "Dynamic Filter (2017-07-05): Kept 576 of 694 tickers.\n",
      "Dynamic Filter (2017-10-03): Kept 587 of 695 tickers.\n",
      "Dynamic Filter (2018-01-03): Kept 591 of 701 tickers.\n",
      "Dynamic Filter (2018-04-05): Kept 600 of 707 tickers.\n",
      "Dynamic Filter (2018-07-05): Kept 612 of 716 tickers.\n",
      "Dynamic Filter (2018-10-03): Kept 618 of 722 tickers.\n",
      "✅ Main loop finished.\n",
      "\n",
      "--- Phase 4: Loading Final Results ---\n",
      "✅ Process complete. Total execution time: 95.53 seconds.\n",
      "\n",
      "--- Sample of Generated Results ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step_date</th>\n",
       "      <th>calc_period</th>\n",
       "      <th>fwd_period</th>\n",
       "      <th>metric</th>\n",
       "      <th>rank_start</th>\n",
       "      <th>rank_end</th>\n",
       "      <th>num_universe</th>\n",
       "      <th>num_portfolio</th>\n",
       "      <th>fwd_p_gain</th>\n",
       "      <th>fwd_b_gain</th>\n",
       "      <th>fwd_gain_delta</th>\n",
       "      <th>fwd_p_sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>126</td>\n",
       "      <td>42</td>\n",
       "      <td>Sharpe</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>456</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>0.011720</td>\n",
       "      <td>-0.008848</td>\n",
       "      <td>0.261774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-03-05</td>\n",
       "      <td>126</td>\n",
       "      <td>42</td>\n",
       "      <td>Sharpe</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>470</td>\n",
       "      <td>5</td>\n",
       "      <td>0.016263</td>\n",
       "      <td>0.010608</td>\n",
       "      <td>0.005654</td>\n",
       "      <td>0.805296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-05-05</td>\n",
       "      <td>126</td>\n",
       "      <td>42</td>\n",
       "      <td>Sharpe</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>473</td>\n",
       "      <td>5</td>\n",
       "      <td>0.026045</td>\n",
       "      <td>0.018763</td>\n",
       "      <td>0.007282</td>\n",
       "      <td>1.644527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-07-03</td>\n",
       "      <td>126</td>\n",
       "      <td>42</td>\n",
       "      <td>Sharpe</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>480</td>\n",
       "      <td>5</td>\n",
       "      <td>0.040905</td>\n",
       "      <td>0.024629</td>\n",
       "      <td>0.016276</td>\n",
       "      <td>1.410076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-09-03</td>\n",
       "      <td>126</td>\n",
       "      <td>42</td>\n",
       "      <td>Sharpe</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>490</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.012282</td>\n",
       "      <td>-0.003231</td>\n",
       "      <td>-0.009051</td>\n",
       "      <td>-0.313144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    step_date  calc_period  fwd_period  metric  rank_start  rank_end  num_universe  num_portfolio  fwd_p_gain  fwd_b_gain  fwd_gain_delta  fwd_p_sharpe\n",
       "0  2014-01-02          126          42  Sharpe           1         5           456              5    0.002872    0.011720       -0.008848      0.261774\n",
       "1  2014-03-05          126          42  Sharpe           1         5           470              5    0.016263    0.010608        0.005654      0.805296\n",
       "2  2014-05-05          126          42  Sharpe           1         5           473              5    0.026045    0.018763        0.007282      1.644527\n",
       "3  2014-07-03          126          42  Sharpe           1         5           480              5    0.040905    0.024629        0.016276      1.410076\n",
       "4  2014-09-03          126          42  Sharpe           1         5           490              5   -0.012282   -0.003231       -0.009051     -0.313144"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Analysis of Best Performing Strategies ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>fwd_gain_delta</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calc_period</th>\n",
       "      <th>fwd_period</th>\n",
       "      <th>metric</th>\n",
       "      <th>rank_start</th>\n",
       "      <th>rank_end</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">252</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">63</th>\n",
       "      <th>Price</th>\n",
       "      <th>1</th>\n",
       "      <th>5</th>\n",
       "      <td>0.043700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe (ATR)</th>\n",
       "      <th>6</th>\n",
       "      <th>10</th>\n",
       "      <td>0.041996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <th>Sharpe (ATR)</th>\n",
       "      <th>6</th>\n",
       "      <th>10</th>\n",
       "      <td>0.024108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <th>Price</th>\n",
       "      <th>6</th>\n",
       "      <th>10</th>\n",
       "      <td>0.022875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">126</th>\n",
       "      <th>42</th>\n",
       "      <th>Sharpe (ATR)</th>\n",
       "      <th>6</th>\n",
       "      <th>10</th>\n",
       "      <td>0.016191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <th>Sharpe (ATR)</th>\n",
       "      <th>1</th>\n",
       "      <th>5</th>\n",
       "      <td>0.013021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <th>63</th>\n",
       "      <th>Sharpe (ATR)</th>\n",
       "      <th>1</th>\n",
       "      <th>5</th>\n",
       "      <td>0.012087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">126</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">42</th>\n",
       "      <th>Sharpe (ATR)</th>\n",
       "      <th>1</th>\n",
       "      <th>5</th>\n",
       "      <td>0.010382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe</th>\n",
       "      <th>6</th>\n",
       "      <th>10</th>\n",
       "      <td>0.008631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">252</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">42</th>\n",
       "      <th>Sharpe (ATR)</th>\n",
       "      <th>1</th>\n",
       "      <th>5</th>\n",
       "      <td>0.004145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe</th>\n",
       "      <th>6</th>\n",
       "      <th>10</th>\n",
       "      <td>0.001688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <th>63</th>\n",
       "      <th>Sharpe</th>\n",
       "      <th>6</th>\n",
       "      <th>10</th>\n",
       "      <td>0.001192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <th>63</th>\n",
       "      <th>Sharpe</th>\n",
       "      <th>1</th>\n",
       "      <th>5</th>\n",
       "      <td>0.001098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">126</th>\n",
       "      <th>63</th>\n",
       "      <th>Sharpe</th>\n",
       "      <th>1</th>\n",
       "      <th>5</th>\n",
       "      <td>0.000508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <th>Sharpe</th>\n",
       "      <th>1</th>\n",
       "      <th>5</th>\n",
       "      <td>-0.000727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">252</th>\n",
       "      <th>42</th>\n",
       "      <th>Sharpe</th>\n",
       "      <th>1</th>\n",
       "      <th>5</th>\n",
       "      <td>-0.000767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <th>Sharpe</th>\n",
       "      <th>6</th>\n",
       "      <th>10</th>\n",
       "      <td>-0.001010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <th>63</th>\n",
       "      <th>Sharpe (ATR)</th>\n",
       "      <th>6</th>\n",
       "      <th>10</th>\n",
       "      <td>-0.006548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         fwd_gain_delta\n",
       "calc_period fwd_period metric       rank_start rank_end                \n",
       "252         63         Price        1          5               0.043700\n",
       "                       Sharpe (ATR) 6          10              0.041996\n",
       "            42         Sharpe (ATR) 6          10              0.024108\n",
       "            63         Price        6          10              0.022875\n",
       "126         42         Sharpe (ATR) 6          10              0.016191\n",
       "            63         Sharpe (ATR) 1          5               0.013021\n",
       "252         63         Sharpe (ATR) 1          5               0.012087\n",
       "126         42         Sharpe (ATR) 1          5               0.010382\n",
       "                       Sharpe       6          10              0.008631\n",
       "252         42         Sharpe (ATR) 1          5               0.004145\n",
       "                       Sharpe       6          10              0.001688\n",
       "126         63         Sharpe       6          10              0.001192\n",
       "252         63         Sharpe       1          5               0.001098\n",
       "126         63         Sharpe       1          5               0.000508\n",
       "            42         Sharpe       1          5              -0.000727\n",
       "252         42         Sharpe       1          5              -0.000767\n",
       "            63         Sharpe       6          10             -0.001010\n",
       "126         63         Sharpe (ATR) 6          10             -0.006548"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# --- CELL 6: EXECUTION ---\n",
    "# ==============================================================================\n",
    "\n",
    "# --- Execute the Bot ---\n",
    "dev_results_df = run_strategy_search(df_dev, bot_config)\n",
    "\n",
    "# --- Display a sample of the results ---\n",
    "if dev_results_df is not None:\n",
    "    print(\"\\n--- Sample of Generated Results ---\")\n",
    "    display(dev_results_df.head())\n",
    "    print(\"\\n--- Analysis of Best Performing Strategies ---\")\n",
    "    display(dev_results_df.groupby(['calc_period', 'fwd_period', 'metric', 'rank_start', 'rank_end'])['fwd_gain_delta'].mean().sort_values(ascending=False).to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dc0a12",
   "metadata": {},
   "source": [
    "### 4. Next Steps & Future Improvements\n",
    "\n",
    "This system is a powerful foundation. Here are potential areas for future development:\n",
    "1.  **Advanced Performance Analytics:** Create a new notebook or function to analyze the output CSV, calculating metrics like Max Drawdown, Calmar Ratio, and generating equity curves for the best strategies.\n",
    "2.  **Visualization:** Build heatmaps and other plots to visualize how different parameters (e.g., `calc_period` vs. `fwd_period`) affect performance.\n",
    "3.  **Realism:** Incorporate transaction costs and slippage into the performance calculations for a more realistic backtest.\n",
    "4.  **Configuration Management:** For even more complex tests, move the `bot_config` dictionary into a separate `config.py` file to keep the notebook cleaner.\n",
    "\n",
    "It has been a genuine pleasure working with you on this. You've built an impressive and professional-grade tool. I wish you the very best with your continued research and development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05feecc8",
   "metadata": {},
   "source": [
    "### 4. Plot an export_csv Row to Check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5979f82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export_csv values for row 420:\n",
      "\n",
      "step_date      : 2014-01-02\n",
      "calc_period    : 252\n",
      "fwd_period     : 63\n",
      "metric         : Price\n",
      "rank_start     : 6\n",
      "rank_end       : 10\n",
      "num_universe   : 456\n",
      "num_portfolio  : 5\n",
      "fwd_p_gain     : 0.0656378866768172\n",
      "fwd_b_gain     : 0.0162015394664378\n",
      "fwd_gain_delta : 0.0494363472103793\n",
      "fwd_p_sharpe   : 1.0717235613404168\n"
     ]
    }
   ],
   "source": [
    "row_to_check = 420\n",
    "row_values =  dev_results_df.loc[row_to_check ].to_dict()\n",
    "print(f'export_csv values for row {row_to_check}:\\n')\n",
    "for k, v in row_values.items():\n",
    "    print(f'{k:<15}: {v}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97e2012e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Walk-Forward Analyzer (using Trading Day Logic)...\n",
      "Master trading day calendar created from 'VOO' (3795 days).\n",
      "Pre-calculating data quality metrics...\n",
      "--- Calculating Rolling Quality Metrics (Window: 252 days) ---\n",
      "✅ Rolling metrics calculation complete.\n",
      "Pre-processing data (unstacking)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bcbd74873fc4f1cbd3b5c12e0c51055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(DatePicker(value=Timestamp('2014-01-02 00:00:00'), description='Start Date:', st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8afadba8a3434b961871d64eb4ec02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines',\n",
       "              'name': 'placeholder_0',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd40188fd-c5f7-4138-a702-2abdc7ba6662',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_1',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4cd42abf-7a62-4f04-8ed1-815d0e08b4a6',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_2',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '2352d800-9a0d-4cb3-a808-0d0de35b83d2',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_3',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '3ffb91a8-7a58-43e1-aa85-0458f50d7465',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_4',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '21f0b8cf-19a2-4868-81d7-cb1478357f8e',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_5',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '095d515e-287a-491a-9a08-c2de709acc24',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_6',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4c80a03a-8d9e-4f84-a7ee-07fb5d956983',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_7',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'fe6da442-344e-47b3-9617-471c324e47dd',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_8',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '8ab8ca94-4f04-4b5c-9115-1318be6b99f9',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_9',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '8b43f00e-511b-499e-afd6-fe6d57c4d68d',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_10',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e38d81c8-c4aa-4f7b-afae-7ee103879fb5',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_11',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '6a903346-7e5b-4ae3-a5a2-55c07c2f8688',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_12',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '47cabf59-c436-4ffa-8099-21593393fddd',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_13',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '095c1f8e-efe2-48d8-a5b2-5d120a2a0634',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_14',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '1fd9cad1-055d-4b0b-a72b-b628ed1db7a1',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_15',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '0cc27a2c-133f-477f-8e8d-14962cb0a4f3',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_16',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '21733d6b-e266-42de-9129-2fa903b3a955',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_17',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '85024801-d8f0-44f3-aabe-b50d86ab8f1b',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_18',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '6fc4875a-3d4a-48cc-be2d-5bbc1b8baa76',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_19',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'bab88225-ae1d-40f7-a1c4-c25d5bdbc92c',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_20',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'eb2dbb64-f72c-4e04-9894-8ef43bf249a5',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_21',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '1ea91cfe-9621-4faa-bc6a-ceb1346ab182',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_22',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '68d8f600-57a7-4931-becd-2750ba4a2ab7',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_23',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '59241483-59b4-4a30-b06b-f134ecb2a46f',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_24',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '93b367f4-667e-45c7-b7e1-0db5ea758bb8',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_25',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '963b12ba-cdff-41c3-abf4-7c988a1a6ad0',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_26',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e8b35ada-d675-4a2a-b747-b84f2bb39ead',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_27',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e1996a84-a271-4178-9233-8d407fada299',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_28',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '167f8bca-52c5-44b5-975d-99287742a04e',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_29',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b3a687aa-f6c9-41f2-8264-0e0a02bb4f49',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_30',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '37b7748b-4419-4974-b85e-47b7418a88ea',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_31',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4498a110-d8a6-4aab-a24e-6e25b12322d3',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_32',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd49ac206-f902-468d-ab01-f0d0eadb9b37',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_33',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b3fc0c0f-5365-4dab-9d84-6b12e43c4e72',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_34',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '2bfc1da8-0899-4eb3-afda-e815b580f51e',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_35',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '6e029a43-a81b-4846-8f8a-d1c84b9c290d',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_36',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '8790ac27-75de-4718-a40b-23de1b9d4c28',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_37',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '348e32b1-eca2-4b9c-b3e6-7388d0cc8c7c',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_38',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '1b3b0869-0cba-41ad-9ef2-9d3ba3fdd2db',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_39',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '8d22f92b-885f-4995-b4e2-b980c8ff412f',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_40',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '67d9471b-e2f8-4a18-9407-23231d6f7695',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_41',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e1e4b9ee-f0a9-44af-b30e-5d40abb1a050',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_42',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '845e9e69-3d67-4b4d-b9f1-0229a4ae16a3',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_43',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '1da15db3-e799-47b6-8df8-c4b2ad09ea46',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_44',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '07691143-53c7-48b0-9b7b-d0015f16df64',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_45',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '2f60f314-988c-4fe6-bb08-980e2bd7034b',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_46',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '1e7f63d4-a634-4e3b-97e6-8480fb172b5e',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_47',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ad4fee41-9504-4cac-9547-d877ad6ae1e4',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_48',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'afcf408c-4ce1-4743-b6eb-cdaa3b46034d',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_49',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '6d5d3d20-32a8-4a90-8297-649454ffdfbb',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': 'black', 'dash': 'dash', 'width': 3},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Benchmark',\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '1a58186f-8251-4ea5-9961-282baf354791',\n",
       "              'visible': True,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': 'green', 'width': 3},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Group Portfolio',\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '97ddb692-a7ad-488d-87e7-8ad04ef90cdf',\n",
       "              'visible': True,\n",
       "              'x': [None],\n",
       "              'y': [None]}],\n",
       "    'layout': {'height': 600,\n",
       "               'hovermode': 'x unified',\n",
       "               'legend': {'title': {'text': 'Tickers (Ranked)'}},\n",
       "               'margin': {'t': 50},\n",
       "               'shapes': [{'line': {'color': 'grey', 'dash': 'dash', 'width': 1},\n",
       "                           'type': 'line',\n",
       "                           'x0': 0,\n",
       "                           'x1': 1,\n",
       "                           'xref': 'x domain',\n",
       "                           'y0': 1,\n",
       "                           'y1': 1,\n",
       "                           'yref': 'y'}],\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Walk-Forward Performance Analysis'},\n",
       "               'xaxis': {'title': {'text': 'Date'}},\n",
       "               'yaxis': {'title': {'text': 'Normalized Price (Start = 1)'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic Filter (2014-01-02): Kept 456 of 617 tickers.\n"
     ]
    }
   ],
   "source": [
    "results_container, debug_container = plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_dev,\n",
    "    default_start_date=row_values['step_date'],\n",
    "    default_calc_period=row_values['calc_period'],\n",
    "    default_fwd_period=row_values['fwd_period'],\n",
    "    default_metric=row_values['metric'],\n",
    "    default_rank_start=row_values['rank_start'],\n",
    "    default_rank_end=row_values['rank_end'],\n",
    "    default_benchmark_ticker='VOO',\n",
    "    quality_thresholds=bot_config['quality_thresholds'],\n",
    "    debug=True  # <-- Activate the new mode!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44da0593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tickers_to_display:\n",
      "    AVGO\n",
      "    RCL\n",
      "    DAL\n",
      "    UAL\n",
      "    NXPI\n",
      "normalized_plot_data:\n",
      "    Ticker          AVGO       RCL       DAL       UAL      NXPI\n",
      "Date                                                        \n",
      "2014-01-02  1.000000  1.000000  1.000000  1.000000  1.000000\n",
      "2014-01-03  1.003798  1.000000  1.055237  1.058839  0.991804\n",
      "2014-01-06  0.996961  0.978589  1.057400  1.043202  0.981785\n",
      "2014-01-07  1.006457  0.976468  1.038989  1.025444  0.978369\n",
      "2014-01-08  1.021462  0.987070  1.075811  1.087199  0.997952\n",
      "...              ...       ...       ...       ...       ...\n",
      "2015-03-30  2.526044  1.749422  1.661571  1.807315  2.332197\n",
      "2015-03-31  2.456966  1.773253  1.639688  1.782401  2.285063\n",
      "2015-04-01  2.430844  1.781051  1.577688  1.696528  2.271177\n",
      "2015-04-02  2.419041  1.786252  1.540854  1.640074  2.260247\n",
      "2015-04-06  2.434714  1.783002  1.522982  1.593427  2.275957\n",
      "\n",
      "[316 rows x 5 columns]\n",
      "portfolio_series:\n",
      "    Date\n",
      "2014-01-02    1.000000\n",
      "2014-01-03    1.021936\n",
      "2014-01-06    1.011587\n",
      "2014-01-07    1.005146\n",
      "2014-01-08    1.033898\n",
      "                ...   \n",
      "2015-03-30    2.015310\n",
      "2015-03-31    1.987474\n",
      "2015-04-01    1.951458\n",
      "2015-04-02    1.929294\n",
      "2015-04-06    1.922016\n",
      "Length: 316, dtype: float64\n",
      "benchmark_price_series:\n",
      "    Date\n",
      "1962-01-02       NaN\n",
      "1962-01-03       NaN\n",
      "1962-01-04       NaN\n",
      "1962-01-05       NaN\n",
      "1962-01-08       NaN\n",
      "               ...  \n",
      "2025-10-03    615.30\n",
      "2025-10-06    617.40\n",
      "2025-10-07    615.20\n",
      "2025-10-08    618.77\n",
      "2025-10-09    617.10\n",
      "Name: VOO, Length: 16051, dtype: float64\n",
      "performance_data:\n",
      "    calc_p_gain:\n",
      "        0.8036299505235447\n",
      "    fwd_p_gain:\n",
      "        0.06563788667681725\n",
      "    full_p_gain:\n",
      "        0.9220164088229226\n",
      "    calc_p_sharpe:\n",
      "        2.395597685797939\n",
      "    fwd_p_sharpe:\n",
      "        1.0717235613404168\n",
      "    full_p_sharpe:\n",
      "        2.124660372214901\n",
      "    calc_b_gain:\n",
      "        0.1395150285685096\n",
      "    fwd_b_gain:\n",
      "        0.016201539466437875\n",
      "    full_b_gain:\n",
      "        0.15797692627646143\n",
      "    calc_b_sharpe:\n",
      "        1.2299249062765603\n",
      "    fwd_b_sharpe:\n",
      "        0.5324149451192371\n",
      "    full_b_sharpe:\n",
      "        1.0618521811877983\n",
      "results_df:\n",
      "              Rank Metric  MetricValue  CalcPrice  CalcGain   FwdGain\n",
      "Ticker                                                           \n",
      "AVGO       6.0  Price     1.930963     7.5748  0.930963  0.260881\n",
      "RCL        7.0  Price     1.790059    72.9288  0.790059 -0.003942\n",
      "DAL        8.0  Price     1.789984    43.1966  0.789984 -0.149165\n",
      "UAL        9.0  Price     1.758283    66.3400  0.758283 -0.093759\n",
      "NXPI      10.0  Price     1.748862    68.5622  0.748862  0.301393\n",
      "VOO (BM)   NaN  Price     1.139515   156.1580  0.139515  0.016202\n",
      "actual_calc_end_ts:\n",
      "    2015-01-02 00:00:00\n",
      "safe_start_date:\n",
      "    2014-01-02 00:00:00\n",
      "safe_viz_end_date:\n",
      "    2015-04-06 00:00:00\n",
      "error:\n",
      "    None\n"
     ]
    }
   ],
   "source": [
    "print_nested(results_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bed494d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ranking_metrics:\n",
      "            FirstPrice  LastPrice  MeanDailyReturn  StdDevDailyReturn  MeanATRP  Metric_Price  Metric_Sharpe  Metric_Sharpe (ATR)\n",
      "Ticker                                                                                                                       \n",
      "VIPS       8.17459   19.26640         0.004212           0.041163  0.052658      2.356864       1.624352             0.079987\n",
      "LUV       16.62160   37.86430         0.003422           0.017330  0.024372      2.278018       3.134316             0.140393\n",
      "PANW       9.27667   20.23670         0.003488           0.028048  0.041120      2.181462       1.974358             0.084835\n",
      "AAL       23.90790   51.07990         0.003308           0.024270  0.034762      2.136528       2.163889             0.095167\n",
      "EW        10.98670   21.28670         0.002782           0.017805  0.020764      1.937497       2.480237             0.133974\n",
      "...            ...        ...              ...                ...       ...           ...            ...                  ...\n",
      "MT        35.78700   22.35080        -0.001731           0.016427  0.022537      0.624551      -1.673026            -0.076821\n",
      "PBR-A      3.51023    1.85242        -0.001813           0.037984  0.048758      0.527720      -0.757752            -0.037186\n",
      "PBR        3.81355    2.00018        -0.001932           0.035362  0.047506      0.524493      -0.867431            -0.040674\n",
      "EC        14.19530    6.60546        -0.002813           0.020567  0.026485      0.465327      -2.171358            -0.106221\n",
      "GTLS      93.34000   34.27000        -0.003637           0.025516  0.038008      0.367152      -2.262695            -0.095689\n",
      "\n",
      "[456 rows x 8 columns]\n",
      "portfolio_trace:\n",
      "                Norm_Price_AVGO  Norm_Price_RCL  Norm_Price_DAL  Norm_Price_UAL  Norm_Price_NXPI  Norm_Price_Portfolio  Norm_Price_Benchmark_VOO  Return_AVGO  Return_RCL  Return_DAL  Return_UAL  Return_NXPI  Return_Portfolio  Return_Benchmark_VOO\n",
      "Date                                                                                                                                                                                                                                              \n",
      "2014-01-02         1.000000        1.000000        1.000000        1.000000         1.000000              1.000000                  1.000000          NaN         NaN         NaN         NaN          NaN               NaN                   NaN\n",
      "2014-01-03         1.003798        1.000000        1.055237        1.058839         0.991804              1.021936                  0.999102     0.003798    0.000000    0.055237    0.058839    -0.008196          0.021936             -0.000898\n",
      "2014-01-06         0.996961        0.978589        1.057400        1.043202         0.981785              1.011587                  0.996600    -0.006811   -0.021411    0.002050   -0.014768    -0.010102         -0.010126             -0.002505\n",
      "2014-01-07         1.006457        0.976468        1.038989        1.025444         0.978369              1.005146                  1.002802     0.009525   -0.002167   -0.017412   -0.017022    -0.003479         -0.006368              0.006224\n",
      "2014-01-08         1.021462        0.987070        1.075811        1.087199         0.997952              1.033898                  1.003218     0.014908    0.010857    0.035440    0.060222     0.020015          0.028606              0.000415\n",
      "...                     ...             ...             ...             ...              ...                   ...                       ...          ...         ...         ...         ...          ...               ...                   ...\n",
      "2015-03-30         2.526044        1.749422        1.661571        1.807315         2.332197              2.015310                  1.160407     0.018252    0.011271    0.015152    0.006494     0.025120          0.015970              0.012466\n",
      "2015-03-31         2.456966        1.773253        1.639688        1.782401         2.285063              1.987474                  1.150191    -0.027346    0.013622   -0.013170   -0.013785    -0.020210         -0.013812             -0.008804\n",
      "2015-04-01         2.430844        1.781051        1.577688        1.696528         2.271177              1.951458                  1.146484    -0.010632    0.004398   -0.037812   -0.048178    -0.006077         -0.018122             -0.003223\n",
      "2015-04-02         2.419041        1.786252        1.540854        1.640074         2.260247              1.929294                  1.149892    -0.004855    0.002920   -0.023347   -0.033276    -0.004812         -0.011358              0.002972\n",
      "2015-04-06         2.434714        1.783002        1.522982        1.593427         2.275957              1.922016                  1.157977     0.006479   -0.001819   -0.011599   -0.028442     0.006951         -0.003772              0.007031\n",
      "\n",
      "[316 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "print_nested(debug_container)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed52337",
   "metadata": {},
   "source": [
    "######################################################  \n",
    "######################################################  \n",
    "######################################################  \n",
    "######################################################  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca33d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. DEFINE THE SPLIT DATE ---\n",
    "# This is the last day of our In-Sample (IS) \"Discovery Zone\".\n",
    "split_date = pd.to_datetime('2018-12-31')\n",
    "\n",
    "print(f\"Splitting data on: {split_date.date()}\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "\n",
    "# --- 3. PERFORM THE SPLIT ---\n",
    "# We access the 'Date' level of the MultiIndex to create our boolean masks.\n",
    "\n",
    "# In-Sample (IS) DataFrame: Data for discovery and training the bot.\n",
    "df_IS = df_OHLCV[df_OHLCV.index.get_level_values('Date') <= split_date].copy()\n",
    "\n",
    "# Out-of-Sample (OOS) DataFrame: Data held back for final validation.\n",
    "df_OOS = df_OHLCV[df_OHLCV.index.get_level_values('Date') > split_date].copy()\n",
    "\n",
    "# Using .copy() is good practice to avoid SettingWithCopyWarning later on.\n",
    "\n",
    "\n",
    "# --- 4. VERIFY THE SPLIT ---\n",
    "# Always check your work to ensure the split was done correctly.\n",
    "\n",
    "print(\"\\n--- In-Sample (IS) 'Discovery Zone' Info ---\")\n",
    "df_IS.info(verbose=False, memory_usage='deep') # Use verbose=False for a cleaner summary\n",
    "print(f\"IS Date Range: {df_IS.index.get_level_values('Date').min().date()} to {df_IS.index.get_level_values('Date').max().date()}\")\n",
    "print(f\"IS Shape: {df_IS.shape}\")\n",
    "print(f\"Percentage of IS data: {df_IS.shape[0] / df_OHLCV.shape[0]:.2%}\")\n",
    "\n",
    "print(\"\\n--- Out-of-Sample (OOS) 'Validation Zone' Info ---\")\n",
    "df_OOS.info(verbose=False, memory_usage='deep')\n",
    "print(f\"OOS Date Range: {df_OOS.index.get_level_values('Date').min().date()} to {df_OOS.index.get_level_values('Date').max().date()}\")\n",
    "print(f\"OOS Shape: {df_OOS.shape}\")\n",
    "print(f\"Percentage of OOS data: {df_OOS.shape[0] / df_OHLCV.shape[0]:.2%}\")\n",
    "\n",
    "# Final check\n",
    "total_rows = df_IS.shape[0] + df_OOS.shape[0]\n",
    "print(f\"\\nVerification: {df_IS.shape[0]} (IS) + {df_OOS.shape[0]} (OOS) = {total_rows} rows.\")\n",
    "print(f\"Original total rows: {df_OHLCV.shape[0]} rows. Match: {total_rows == df_OHLCV.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf196a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code REPLACES the previous df_dev creation snippet.\n",
    "# It should still be placed after df_IS and df_OOS are created.\n",
    "\n",
    "# --- 5. (CORRECTED) CREATE A SMALLER \"DEVELOPMENT SANDBOX\" DATAFRAME ---\n",
    "# We use a RECENT 5-year slice of our In-Sample data for rapid development.\n",
    "# This is much faster and more representative of modern data.\n",
    "\n",
    "dev_start_date = pd.to_datetime('2014-01-01')\n",
    "dev_end_date = pd.to_datetime('2018-12-31') # This is the end of our df_IS period\n",
    "\n",
    "print(\"\\n--- Creating Development Sandbox DataFrame (Corrected) ---\")\n",
    "print(f\"Slicing df_IS from {dev_start_date.date()} to {dev_end_date.date()}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create the development dataframe by slicing the main In-Sample data\n",
    "df_dev = df_IS[(df_IS.index.get_level_values('Date') >= dev_start_date) &\n",
    "               (df_IS.index.get_level_values('Date') <= dev_end_date)].copy()\n",
    "\n",
    "\n",
    "# --- 6. VERIFY THE (CORRECTED) DEVELOPMENT DATAFRAME ---\n",
    "print(\"\\n--- Development Sandbox (df_dev) Info ---\")\n",
    "df_dev.info(verbose=False, memory_usage='deep')\n",
    "print(f\"df_dev Date Range: {df_dev.index.get_level_values('Date').min().date()} to {df_dev.index.get_level_values('Date').max().date()}\")\n",
    "print(f\"df_dev Shape: {df_dev.shape}\")\n",
    "print(f\"df_dev as percentage of IS data: {df_dev.shape[0] / df_IS.shape[0]:.2%}\")\n",
    "\n",
    "# --- Get unique tickers from the 'Ticker' level of the MultiIndex ---\n",
    "\n",
    "# Get the 'Ticker' level of the index\n",
    "ticker_index = df_dev.index.get_level_values('Ticker')\n",
    "\n",
    "# Get the unique values from that level\n",
    "unique_tickers = ticker_index.unique()\n",
    "\n",
    "# Print the results\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nFound {len(unique_tickers)} unique tickers in df_dev.\")\n",
    "print(\"First 10 unique tickers:\")\n",
    "print(unique_tickers[:10].tolist()) # .tolist() gives a cleaner printout for a slice\n",
    "print(\"\\nLast 10 unique tickers:\")\n",
    "print(unique_tickers[-10:].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9ca688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Execute the Bot ---\n",
    "dev_results_df = run_strategy_search(df_dev, bot_config)\n",
    "\n",
    "# --- Display a sample of the results ---\n",
    "if dev_results_df is not None:\n",
    "    print(\"\\n--- Sample of Generated Results ---\")\n",
    "    display(dev_results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfb9528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_results_df.loc[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e6eac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8b40fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acb4fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_container, debug_container = plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_dev,\n",
    "    default_start_date='2018-04-30',\n",
    "    default_calc_period=126,\n",
    "    default_fwd_period=63,\n",
    "    default_metric='Sharpe (ATR)',\n",
    "    default_rank_start=1,\n",
    "    default_rank_end=10,\n",
    "    default_benchmark_ticker='VOO',\n",
    "    quality_thresholds=bot_config['quality_thresholds'],\n",
    "    debug=True  # <-- Activate the new mode!\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
