{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9ae2708",
   "metadata": {},
   "source": [
    "# Here is the refactored solution. I have separated the concerns into three distinct layers:\n",
    "1.  **The Data Contract:** explicit `dataclasses` defining exactly what goes in and comes out.\n",
    "2.  **The Engine:** A purely mathematical class (`AlphaEngine`) containing the logic, with no widget/plotting dependencies.\n",
    "3.  **The UI:** A cleaned-up dashboard function that simply sends inputs to the Engine and visualizes the Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc79d79",
   "metadata": {},
   "source": [
    "### Following is the reverse chronological fix log (most recent entry is at the top )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68b1a41",
   "metadata": {},
   "source": [
    "```\n",
    "To see the full dataframe of all tickers (both those that passed and those that failed) for a specific date, we need to capture a snapshot of the universe inside the `_get_eligible_universe` method.\n",
    "\n",
    "I have updated the **`AlphaEngine`** class below.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30d1f60",
   "metadata": {},
   "source": [
    "```\n",
    "To verify that the relative percentile logic is working, we can modify the `AlphaEngine` to report exactly **how the cutoff was calculated** for the specific start date.\n",
    "\n",
    "We want to see evidence that:\n",
    "1.  In earlier years (e.g., 2005), the volume cutoff is lower (e.g., $200k).\n",
    "2.  In later years (e.g., 2024), the volume cutoff is higher (e.g., $5M).\n",
    "\n",
    "Here is the updated `AlphaEngine` and `UI` code. I have added a **\"Audit Log\"** feature. When you run the tool, it will now print exactly what the Dollar Volume Threshold was for that specific day.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50de4e99",
   "metadata": {},
   "source": [
    "```\n",
    "The best way to solve this is to switch from a **Fixed Dollar Threshold** (e.g., \"$1 Million\") to a **Relative Percentile Threshold** (e.g., \"Top 50% of the market\").\n",
    "\n",
    "In 2004, a stock trading $200k might have been in the top 50% of liquid stocks. In 2024, that same $200k is illiquid garbage. Using a percentile automatically adjusts for inflation and market growth over time.\n",
    "\n",
    "Here is how to modify your code to support this.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e8a3b9",
   "metadata": {},
   "source": [
    "```\n",
    "To fix this, we need to pass the **actual** calculated start date (the trading day the engine \"snapped\" to) back from the `AlphaEngine` to the UI. Then, the UI can compare the *Requested Date* vs. the *Actual Date* and display the warning message if they differ.\n",
    "\n",
    "Here is the plan:\n",
    "1.  **Update `EngineOutput`**: Add a `start_date` field to the dataclass.\n",
    "2.  **Update `AlphaEngine.run`**: Populate this new field with `safe_start_date`.\n",
    "3.  **Update `plot_walk_forward_analyzer`**: Add logic to compare the user's input date with the engine's returned date and print the \"Info\" message if they are different.\n",
    "\n",
    "Here is the updated code (Sections C, D, and E have changed):\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb918f61",
   "metadata": {},
   "source": [
    "```\n",
    "I have updated the `AlphaEngine.run` method. specifically inside the `if inputs.mode == 'Manual List':` block. It now iterates through every manual ticker and performs two checks:\n",
    "1.  **Existence**: Is the ticker in the database?\n",
    "2.  **Availability**: Does the ticker have a valid price on the specific `Start Date`?\n",
    "\n",
    "If any ticker fails, it compiles a specific error message explaining why (e.g., \"No price data on start date\") and aborts the calculation immediately.  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b728a8",
   "metadata": {},
   "source": [
    "```\n",
    "The `snapshot_df` contains **every single feature** calculated by your `generate_features` function for that specific day, plus the new audit columns we added.\n",
    "\n",
    "Here is exactly what is inside that DataFrame:\n",
    "\n",
    "### 1. The Core Features (from `generate_features`)\n",
    "*   **`TR`**: True Range\n",
    "*   **`ATR`**: Average True Range\n",
    "*   **`ATRP`**: Average True Range Percent (Volatility)\n",
    "*   **`RollingStalePct`**: How often the price didn't move or volume was 0.\n",
    "*   **`RollMedDollarVol`**: Median Daily Dollar Volume (Liquidity).\n",
    "*   **`RollingSameVolCount`**: Data quality check for repeated volume numbers.\n",
    "\n",
    "### 2. The Audit Columns (Added during filtering)\n",
    "*   **`Calculated_Cutoff`**: The specific dollar amount required to pass on that day.\n",
    "*   **`Passed_Vol_Check`**: `True` if the ticker met the liquidity requirement.\n",
    "*   **`Passed_Final`**: `True` if it passed **all** checks (Liquidity + Stale + Quality).\n",
    "\n",
    "=========================================\n",
    "\n",
    "Here are the formulas translated directly into the Python `pandas` code used in your `generate_features` function.\n",
    "\n",
    "I have simplified the code slightly to assume a single ticker context (removing the `groupby` wrapper) so you can see the raw math clearly.\n",
    "\n",
    "### 1. True Range (TR)\n",
    "Calculates the maximum of the three price differences.\n",
    "\n",
    "prev_close = df_ohlcv['Adj Close'].shift(1)\n",
    "\n",
    "# The three components\n",
    "diff1 = df_ohlcv['Adj High'] - df_ohlcv['Adj Low']\n",
    "diff2 = (df_ohlcv['Adj High'] - prev_close).abs()\n",
    "diff3 = (df_ohlcv['Adj Low'] - prev_close).abs()\n",
    "\n",
    "# Taking the max of the three\n",
    "tr = pd.concat([diff1, diff2, diff3], axis=1).max(axis=1)\n",
    "\n",
    "### 2. Average True Range (ATR)\n",
    "Uses an Exponential Weighted Mean (EWM) with a specific alpha smoothing factor.\n",
    "\n",
    "# N = atr_period (e.g., 14)\n",
    "# alpha = 1 / N\n",
    "atr = tr.ewm(alpha=1/14, adjust=False).mean()\n",
    "\n",
    "### 3. ATR Percent (ATRP)\n",
    "Simple division to normalize volatility.\n",
    "\n",
    "atrp = atr / df_ohlcv['Adj Close']\n",
    "\n",
    "### 4. Rolling Stale Percentage\n",
    "Checks if volume is 0 OR if High equals Low (price didn't move), then averages that 1 or 0 signal over the window.\n",
    "\n",
    "# 1. Define the Stale Signal (1 for stale, 0 for active)\n",
    "is_stale = np.where(\n",
    "    (df_ohlcv['Volume'] == 0) | (df_ohlcv['Adj High'] == df_ohlcv['Adj Low']), \n",
    "    1,  \n",
    "    0\n",
    ")\n",
    "\n",
    "# 2. Calculate average over window (W=252)\n",
    "rolling_stale_pct = pd.Series(is_stale).rolling(window=252).mean()\n",
    "\n",
    "### 5. Rolling Median Dollar Volume\n",
    "Calculates raw dollar volume, then finds the median over the window.\n",
    "\n",
    "# 1. Calculate Daily Dollar Volume\n",
    "dollar_volume = df_ohlcv['Adj Close'] * df_ohlcv['Volume']\n",
    "\n",
    "# 2. Get Median over window (W=252)\n",
    "roll_med_dollar_vol = dollar_volume.rolling(window=252).median()\n",
    "\n",
    "### 6. Rolling Same Volume Count\n",
    "Checks if today's volume is exactly the same as yesterday's (a sign of bad data), then sums those occurrences.\n",
    "\n",
    "# 1. Check if Volume(t) - Volume(t-1) equals 0\n",
    "# .diff() calculates current row minus previous row\n",
    "has_same_volume = (df_ohlcv['Volume'].diff() == 0).astype(int)\n",
    "\n",
    "# 2. Sum the errors over window (W=252)\n",
    "rolling_same_vol_count = has_same_volume.rolling(window=252).sum()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb417c7",
   "metadata": {},
   "source": [
    "================================  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1110f2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets\n",
    "import pprint\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Optional, Any, Union\n",
    "from collections import Counter\n",
    "from datetime import datetime, date\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION A: CORE HELPER FUNCTIONS & FEATURE GENERATION\n",
    "# (Unchanged from previous version)\n",
    "# ==============================================================================\n",
    "# ... (Keep generate_features, calculate_gain, calculate_sharpe, \n",
    "#      calculate_sharpe_atr, calculate_buy_and_hold_performance as is) ...\n",
    "\n",
    "def generate_features(df_ohlcv: pd.DataFrame, atr_period: int = 14, quality_window: int = 252, quality_min_periods: int = 126) -> pd.DataFrame:\n",
    "    # (Same as before)\n",
    "    if not df_ohlcv.index.is_monotonic_increasing: df_ohlcv = df_ohlcv.sort_index()\n",
    "    grouped = df_ohlcv.groupby(level='Ticker')\n",
    "    prev_close = grouped['Adj Close'].shift(1)\n",
    "    tr = pd.concat([df_ohlcv['Adj High'] - df_ohlcv['Adj Low'], abs(df_ohlcv['Adj High'] - prev_close), abs(df_ohlcv['Adj Low'] - prev_close)], axis=1).max(axis=1, skipna=False)\n",
    "    atr = tr.groupby(level='Ticker').transform(lambda x: x.ewm(alpha=1/atr_period, adjust=False).mean())\n",
    "    atrp = (atr / df_ohlcv['Adj Close']).replace([np.inf, -np.inf], np.nan)\n",
    "    indicator_df = pd.DataFrame({'TR': tr, 'ATR': atr, 'ATRP': atrp})\n",
    "    quality_temp_df = pd.DataFrame({'IsStale': np.where((df_ohlcv['Volume'] == 0) | (df_ohlcv['Adj High'] == df_ohlcv['Adj Low']), 1, 0), 'DollarVolume': df_ohlcv['Adj Close'] * df_ohlcv['Volume'], 'HasSameVolume': (grouped['Volume'].diff() == 0).astype(int)}, index=df_ohlcv.index)\n",
    "    rolling_result = quality_temp_df.groupby(level='Ticker').rolling(window=quality_window, min_periods=quality_min_periods).agg({'IsStale': 'mean', 'DollarVolume': 'median', 'HasSameVolume': 'sum'}).rename(columns={'IsStale': 'RollingStalePct', 'DollarVolume': 'RollMedDollarVol', 'HasSameVolume': 'RollingSameVolCount'}).reset_index(level=0, drop=True)\n",
    "    return pd.concat([indicator_df, rolling_result], axis=1)\n",
    "\n",
    "def calculate_gain(price_series): \n",
    "    if price_series.dropna().shape[0] < 2: return np.nan\n",
    "    return (price_series.ffill().iloc[-1] / price_series.bfill().iloc[0]) - 1\n",
    "\n",
    "def calculate_sharpe(return_series):\n",
    "    if return_series.dropna().shape[0] < 2: return np.nan\n",
    "    std = return_series.std()\n",
    "    return (return_series.mean() / std * np.sqrt(252)) if std > 0 else 0.0\n",
    "\n",
    "def calculate_sharpe_atr(return_series, atrp_series):\n",
    "    if return_series.dropna().shape[0] < 2 or atrp_series.dropna().empty: return np.nan\n",
    "    mean_atrp = atrp_series.mean()\n",
    "    return (return_series.mean() / mean_atrp) if mean_atrp > 0 else 0.0\n",
    "\n",
    "def calculate_buy_and_hold_performance(df_close, features_df, tickers, start_date, end_date):\n",
    "    if not tickers: return pd.Series(dtype=float), pd.Series(dtype=float), pd.Series(dtype=float)\n",
    "    ticker_counts = Counter(tickers)\n",
    "    initial_weights = pd.Series({t: c / len(tickers) for t, c in ticker_counts.items()})\n",
    "    prices_raw = df_close[initial_weights.index.tolist()].loc[start_date:end_date]\n",
    "    if prices_raw.dropna(how='all').empty: return pd.Series(dtype=float), pd.Series(dtype=float), pd.Series(dtype=float)\n",
    "    prices_norm = prices_raw.div(prices_raw.bfill().iloc[0])\n",
    "    weighted_growth = prices_norm.mul(initial_weights, axis='columns')\n",
    "    value_series = weighted_growth.sum(axis=1)\n",
    "    return_series = value_series.pct_change()\n",
    "    full_idx = pd.MultiIndex.from_product([initial_weights.index.tolist(), return_series.index], names=['Ticker', 'Date'])\n",
    "    feat_subset = features_df.reindex(full_idx)['ATRP'].unstack(level='Ticker')\n",
    "    atrp_series = (weighted_growth.div(value_series, axis='index').align(feat_subset, join='inner', axis=1)[0] * weighted_growth.div(value_series, axis='index').align(feat_subset, join='inner', axis=1)[1]).sum(axis=1)\n",
    "    return value_series, return_series, atrp_series\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION B: METRIC REGISTRY\n",
    "# ==============================================================================\n",
    "\n",
    "def metric_price(d): return calculate_gain(d['calc_close'])\n",
    "def metric_sharpe(d): \n",
    "    r = d['daily_returns']\n",
    "    return (r.mean() / r.std() * np.sqrt(252)).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "def metric_sharpe_atr(d):\n",
    "    return (d['daily_returns'].mean() / d['atrp']).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "METRIC_REGISTRY = {\n",
    "    'Price': metric_price,\n",
    "    'Sharpe': metric_sharpe,\n",
    "    'Sharpe (ATR)': metric_sharpe_atr,\n",
    "}\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION C: DATA CONTRACTS (The API)\n",
    "# Updated EngineOutput to include actual start_date\n",
    "# ==============================================================================\n",
    "\n",
    "@dataclass\n",
    "class EngineInput:\n",
    "    mode: str\n",
    "    start_date: pd.Timestamp\n",
    "    calc_period: int\n",
    "    fwd_period: int\n",
    "    metric: str\n",
    "    benchmark_ticker: str\n",
    "    rank_start: int = 1\n",
    "    rank_end: int = 10\n",
    "    quality_thresholds: Dict[str, float] = field(default_factory=lambda: {'min_median_dollar_volume': 1_000_000, 'max_stale_pct': 0.05, 'max_same_vol_count': 10})\n",
    "    manual_tickers: List[str] = field(default_factory=list)\n",
    "    debug: bool = False\n",
    "\n",
    "@dataclass\n",
    "class EngineOutput:\n",
    "    portfolio_series: pd.Series\n",
    "    benchmark_series: pd.Series\n",
    "    normalized_plot_data: pd.DataFrame\n",
    "    tickers: List[str]\n",
    "    initial_weights: pd.Series\n",
    "    perf_metrics: Dict[str, float]\n",
    "    results_df: pd.DataFrame\n",
    "    start_date: pd.Timestamp # <--- NEW FIELD: The actual trading start date used\n",
    "    calc_end_date: pd.Timestamp\n",
    "    viz_end_date: pd.Timestamp\n",
    "    error_msg: Optional[str] = None\n",
    "    debug_data: Optional[Dict[str, Any]] = None\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION D: THE ALPHA ENGINE (The \"Brain\")\n",
    "# This version saves a sorted dataframe called `universe_snapshot` into the debug data. It adds columns showing exactly which tickers passed or failed the specific thresholds.\n",
    "# ==============================================================================\n",
    "\n",
    "class AlphaEngine:\n",
    "    def __init__(self, df_ohlcv: pd.DataFrame, master_ticker: str = 'SPY'):\n",
    "        print(\"--- ‚öôÔ∏è Initializing AlphaEngine ---\")\n",
    "        self.features_df = generate_features(df_ohlcv)\n",
    "        print(\"Optimizing data structures...\")\n",
    "        self.df_close = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "        \n",
    "        if master_ticker not in self.df_close.columns:\n",
    "            master_ticker = self.df_close.columns[0]\n",
    "            print(f\"Warning: Master ticker not found. Using {master_ticker}\")\n",
    "            \n",
    "        self.trading_calendar = self.df_close[master_ticker].dropna().index.unique().sort_values()\n",
    "        print(\"‚úÖ AlphaEngine Ready.\")\n",
    "\n",
    "    def run(self, inputs: EngineInput) -> EngineOutput:\n",
    "        # --- A. Validate Dates ---\n",
    "        try:\n",
    "            start_idx = self.trading_calendar.searchsorted(inputs.start_date)\n",
    "            if start_idx < 0: start_idx = 0\n",
    "        except Exception:\n",
    "            return self._error_result(\"Invalid Start Date\")\n",
    "\n",
    "        desired_end_idx = start_idx + inputs.calc_period + inputs.fwd_period\n",
    "        if desired_end_idx >= len(self.trading_calendar):\n",
    "            return self._error_result(f\"Date range exceeds history.\")\n",
    "\n",
    "        safe_start_date = self.trading_calendar[start_idx]\n",
    "        safe_calc_end_date = self.trading_calendar[start_idx + inputs.calc_period]\n",
    "        safe_viz_end_date = self.trading_calendar[start_idx + inputs.calc_period + inputs.fwd_period]\n",
    "\n",
    "        # --- B. Select Tickers ---\n",
    "        tickers_to_trade = []\n",
    "        results_table = pd.DataFrame()\n",
    "        debug_dict = {}\n",
    "        audit_info = {} \n",
    "\n",
    "        if inputs.mode == 'Manual List':\n",
    "            validation_errors = []\n",
    "            valid_tickers = []\n",
    "            for t in inputs.manual_tickers:\n",
    "                if t not in self.df_close.columns:\n",
    "                    validation_errors.append(f\"‚ùå {t}: Ticker not found.\")\n",
    "                    continue\n",
    "                if pd.isna(self.df_close.at[safe_start_date, t]):\n",
    "                    validation_errors.append(f\"‚ö†Ô∏è {t}: No price data on start date.\")\n",
    "                    continue\n",
    "                valid_tickers.append(t)\n",
    "            \n",
    "            if validation_errors: return self._error_result(\"\\n\".join(validation_errors))\n",
    "            if not valid_tickers: return self._error_result(\"No valid tickers.\")\n",
    "            tickers_to_trade = valid_tickers\n",
    "            results_table = pd.DataFrame(index=valid_tickers)\n",
    "            \n",
    "        else: # Ranking Mode\n",
    "            eligible_tickers = self._get_eligible_universe(safe_start_date, inputs.quality_thresholds, audit_info)\n",
    "            debug_dict['audit_liquidity'] = audit_info \n",
    "            \n",
    "            if not eligible_tickers: return self._error_result(\"No tickers passed quality filters.\")\n",
    "            \n",
    "            calc_close = self.df_close.loc[safe_start_date:safe_calc_end_date, eligible_tickers]\n",
    "            idx_product = pd.MultiIndex.from_product([eligible_tickers, calc_close.index], names=['Ticker', 'Date'])\n",
    "            feat_slice = self.features_df.reindex(idx_product).dropna(how='all')\n",
    "            atrp_mean = feat_slice.groupby(level='Ticker')['ATRP'].mean()\n",
    "            \n",
    "            ingredients = { 'calc_close': calc_close, 'daily_returns': calc_close.pct_change(), 'atrp': atrp_mean }\n",
    "            if inputs.metric not in METRIC_REGISTRY: return self._error_result(f\"Metric '{inputs.metric}' not found.\")\n",
    "            metric_vals = METRIC_REGISTRY[inputs.metric](ingredients)\n",
    "            sorted_tickers = metric_vals.sort_values(ascending=False)\n",
    "            \n",
    "            start_r = max(0, inputs.rank_start - 1)\n",
    "            end_r = inputs.rank_end\n",
    "            tickers_to_trade = sorted_tickers.iloc[start_r:end_r].index.tolist()\n",
    "            if not tickers_to_trade: return self._error_result(\"No tickers generated from ranking.\")\n",
    "\n",
    "            results_table = pd.DataFrame({\n",
    "                'Rank': range(inputs.rank_start, inputs.rank_start + len(tickers_to_trade)),\n",
    "                'Ticker': tickers_to_trade,\n",
    "                'Metric Value': sorted_tickers.loc[tickers_to_trade].values\n",
    "            }).set_index('Ticker')\n",
    "\n",
    "        # --- C. Performance Calculations ---\n",
    "        p_val, p_ret, p_atrp = calculate_buy_and_hold_performance(self.df_close, self.features_df, tickers_to_trade, safe_start_date, safe_viz_end_date)\n",
    "        b_val, b_ret, b_atrp = calculate_buy_and_hold_performance(self.df_close, self.features_df, [inputs.benchmark_ticker], safe_start_date, safe_viz_end_date)\n",
    "\n",
    "        # --- D. Final Metrics ---\n",
    "        plot_data = self.df_close[list(set(tickers_to_trade))].loc[safe_start_date:safe_viz_end_date]\n",
    "        if not plot_data.empty: plot_data = plot_data / plot_data.bfill().iloc[0]\n",
    "        calc_end_ts = safe_calc_end_date\n",
    "        metrics = {}\n",
    "        get_gain = lambda s: (s.iloc[-1] / s.iloc[0]) - 1 if len(s) > 0 else 0\n",
    "\n",
    "        metrics['full_p_gain'] = get_gain(p_val)\n",
    "        metrics['calc_p_gain'] = get_gain(p_val.loc[:calc_end_ts])\n",
    "        metrics['fwd_p_gain'] = get_gain(p_val.loc[calc_end_ts:])\n",
    "        metrics['full_p_sharpe_atr'] = calculate_sharpe_atr(p_ret, p_atrp)\n",
    "        metrics['calc_p_sharpe_atr'] = calculate_sharpe_atr(p_ret.loc[:calc_end_ts], p_atrp.loc[p_ret.loc[:calc_end_ts].index])\n",
    "        metrics['fwd_p_sharpe_atr'] = calculate_sharpe_atr(p_ret.loc[calc_end_ts:].iloc[1:], p_atrp.loc[p_ret.loc[calc_end_ts:].iloc[1:].index])\n",
    "        \n",
    "        if not b_ret.empty:\n",
    "            metrics['full_b_gain'] = get_gain(b_val)\n",
    "            metrics['calc_b_gain'] = get_gain(b_val.loc[:calc_end_ts])\n",
    "            metrics['fwd_b_gain'] = get_gain(b_val.loc[calc_end_ts:])\n",
    "            metrics['full_b_sharpe_atr'] = calculate_sharpe_atr(b_ret, b_atrp)\n",
    "            metrics['calc_b_sharpe_atr'] = calculate_sharpe_atr(b_ret.loc[:calc_end_ts], b_atrp.loc[b_ret.loc[:calc_end_ts].index])\n",
    "            metrics['fwd_b_sharpe_atr'] = calculate_sharpe_atr(b_ret.loc[calc_end_ts:].iloc[1:], b_atrp.loc[b_ret.loc[calc_end_ts:].iloc[1:].index])\n",
    "\n",
    "        if not plot_data.empty: results_table['Fwd Gain'] = (plot_data.iloc[-1] / plot_data.loc[calc_end_ts]) - 1\n",
    "        ticker_counts = Counter(tickers_to_trade)\n",
    "        weights = pd.Series({t: c/len(tickers_to_trade) for t, c in ticker_counts.items()})\n",
    "\n",
    "        if inputs.debug:\n",
    "            trace_df = plot_data.copy()\n",
    "            trace_df.columns = [f'Norm_Price_{c}' for c in trace_df.columns]\n",
    "            trace_df['Norm_Price_Portfolio'] = p_val\n",
    "            if not b_val.empty: trace_df[f'Norm_Price_Benchmark_{inputs.benchmark_ticker}'] = b_val\n",
    "            debug_dict['portfolio_trace'] = trace_df\n",
    "\n",
    "        return EngineOutput(\n",
    "            portfolio_series=p_val, benchmark_series=b_val, normalized_plot_data=plot_data,\n",
    "            tickers=tickers_to_trade, initial_weights=weights, perf_metrics=metrics,\n",
    "            results_df=results_table, start_date=safe_start_date,\n",
    "            calc_end_date=safe_calc_end_date, viz_end_date=safe_viz_end_date, debug_data=debug_dict\n",
    "        )\n",
    "\n",
    "    # --- UPDATED: CAPTURE SNAPSHOT ---\n",
    "    def _get_eligible_universe(self, date_ts, thresholds, audit_container=None):\n",
    "        avail_dates = self.features_df.index.get_level_values('Date').unique().sort_values()\n",
    "        valid_dates = avail_dates[avail_dates <= date_ts]\n",
    "        if valid_dates.empty: return []\n",
    "        day_features = self.features_df.xs(valid_dates[-1], level='Date')\n",
    "\n",
    "        # 1. Determine Dynamic Cutoff\n",
    "        vol_cutoff = thresholds.get('min_median_dollar_volume', 0)\n",
    "        percentile_used = \"N/A\"\n",
    "        dynamic_val = 0\n",
    "        \n",
    "        if 'min_liquidity_percentile' in thresholds:\n",
    "            percentile_used = thresholds['min_liquidity_percentile']\n",
    "            dynamic_val = day_features['RollMedDollarVol'].quantile(percentile_used)\n",
    "            vol_cutoff = max(vol_cutoff, dynamic_val)\n",
    "\n",
    "        # 2. Logic Mask\n",
    "        mask = (\n",
    "            (day_features['RollMedDollarVol'] >= vol_cutoff) &\n",
    "            (day_features['RollingStalePct'] <= thresholds['max_stale_pct']) &\n",
    "            (day_features['RollingSameVolCount'] <= thresholds['max_same_vol_count'])\n",
    "        )\n",
    "\n",
    "        # 3. Capture Detailed Audit Snapshot\n",
    "        if audit_container is not None:\n",
    "            audit_container['date'] = valid_dates[-1]\n",
    "            audit_container['total_tickers_available'] = len(day_features)\n",
    "            audit_container['percentile_setting'] = percentile_used\n",
    "            audit_container['percentile_value_usd'] = dynamic_val\n",
    "            audit_container['final_cutoff_usd'] = vol_cutoff\n",
    "            audit_container['tickers_passed'] = mask.sum()\n",
    "            \n",
    "            # Save the DataFrame!\n",
    "            snapshot = day_features.copy()\n",
    "            snapshot['Calculated_Cutoff'] = vol_cutoff\n",
    "            snapshot['Passed_Vol_Check'] = snapshot['RollMedDollarVol'] >= vol_cutoff\n",
    "            snapshot['Passed_Final'] = mask\n",
    "            # Sort by volume so user can see the cutoff point easily\n",
    "            snapshot = snapshot.sort_values('RollMedDollarVol', ascending=False)\n",
    "            audit_container['universe_snapshot'] = snapshot\n",
    "\n",
    "        return day_features[mask].index.tolist()\n",
    "\n",
    "    def _error_result(self, msg):\n",
    "        return EngineOutput(pd.Series(dtype=float), pd.Series(dtype=float), pd.DataFrame(), [], pd.Series(dtype=float), {}, pd.DataFrame(), pd.Timestamp.min, pd.Timestamp.min, pd.Timestamp.min, msg)\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION E: THE UI (Visualization)\n",
    "# Update this function to read the audit data from the `debug_data` and print it nicely.\n",
    "# Updated print logic to detect date shift\n",
    "# Fixed EngineInput argument mapping\n",
    "# ==============================================================================\n",
    "\n",
    "def plot_walk_forward_analyzer(df_ohlcv, \n",
    "                               default_start_date='2020-01-01', \n",
    "                               default_calc_period=126, \n",
    "                               default_fwd_period=63,\n",
    "                               default_metric='Sharpe (ATR)', \n",
    "                               default_rank_start=1, \n",
    "                               default_rank_end=10,\n",
    "                               default_benchmark_ticker='SPY', \n",
    "                               master_calendar_ticker='SPY', \n",
    "                               quality_thresholds=None, \n",
    "                               debug=False):\n",
    "    \n",
    "    engine = AlphaEngine(df_ohlcv, master_ticker=master_calendar_ticker)\n",
    "    results_container = [None]\n",
    "    debug_container = [None]\n",
    "\n",
    "    # --- UPDATED DEFAULT SETTINGS WITH PERCENTILE ---\n",
    "    if quality_thresholds is None:\n",
    "        quality_thresholds = {\n",
    "            'min_median_dollar_volume': 100_000, # Hard floor\n",
    "            'min_liquidity_percentile': 0.50,    # Top 50%\n",
    "            'max_stale_pct': 0.05, \n",
    "            'max_same_vol_count': 10\n",
    "        }\n",
    "\n",
    "    # (Widget setup code remains the same...)\n",
    "    mode_selector = widgets.RadioButtons(options=['Ranking', 'Manual List'], value='Ranking', description='Portfolio Mode:', layout={'width': 'max-content'})\n",
    "    start_date_picker = widgets.DatePicker(description='Start Date:', value=pd.to_datetime(default_start_date))\n",
    "    calc_period_input = widgets.IntText(value=default_calc_period, description='Calc Period:')\n",
    "    fwd_period_input = widgets.IntText(value=default_fwd_period, description='Fwd Period:')\n",
    "    metric_dropdown = widgets.Dropdown(options=list(METRIC_REGISTRY.keys()), value=default_metric, description='Metric:')\n",
    "    rank_start_input = widgets.IntText(value=default_rank_start, description='Rank Start:')\n",
    "    rank_end_input = widgets.IntText(value=default_rank_end, description='Rank End:')\n",
    "    manual_tickers_input = widgets.Textarea(value='', placeholder='Enter tickers...', description='Manual Tickers:', layout={'width': '400px', 'height': '80px'})\n",
    "    benchmark_input = widgets.Text(value=default_benchmark_ticker, description='Benchmark:', placeholder='Enter Ticker')\n",
    "    update_button = widgets.Button(description=\"Update Chart\", button_style='primary')\n",
    "    ticker_list_output = widgets.Output()\n",
    "\n",
    "    ranking_controls = widgets.HBox([metric_dropdown, rank_start_input, rank_end_input])\n",
    "    manual_controls = widgets.HBox([manual_tickers_input])\n",
    "    date_controls = widgets.HBox([start_date_picker, calc_period_input, fwd_period_input])\n",
    "    ui = widgets.VBox([mode_selector, date_controls, ranking_controls, manual_controls, widgets.HBox([benchmark_input, update_button]), ticker_list_output], layout=widgets.Layout(margin='10px 0 20px 0'))\n",
    "    \n",
    "    def on_mode_change(c):\n",
    "        ranking_controls.layout.display = 'flex' if c['new'] == 'Ranking' else 'none'\n",
    "        manual_controls.layout.display = 'none' if c['new'] == 'Ranking' else 'flex'\n",
    "    mode_selector.observe(on_mode_change, names='value')\n",
    "    on_mode_change({'new': mode_selector.value})\n",
    "\n",
    "    fig = go.FigureWidget()\n",
    "    fig.update_layout(title='Walk-Forward Performance Analysis', height=600, template=\"plotly_white\", hovermode='x unified')\n",
    "    for i in range(50): fig.add_trace(go.Scatter(visible=False, line=dict(width=2)))\n",
    "    fig.add_trace(go.Scatter(name='Benchmark', visible=True, line=dict(color='black', width=3, dash='dash')))\n",
    "    fig.add_trace(go.Scatter(name='Group Portfolio', visible=True, line=dict(color='green', width=3)))\n",
    "\n",
    "    def update_plot(b):\n",
    "        ticker_list_output.clear_output()\n",
    "        manual_list = [t.strip().upper() for t in manual_tickers_input.value.split(',') if t.strip()]\n",
    "        start_date_raw = pd.to_datetime(start_date_picker.value)\n",
    "        \n",
    "        if start_date_raw < (engine.trading_calendar[0] - pd.Timedelta(days=7)):\n",
    "            with ticker_list_output: print(f\"‚ö†Ô∏è DATE WARNING: Start date {start_date_raw.date()} is too early.\"); return\n",
    "\n",
    "        inputs = EngineInput(\n",
    "            mode=mode_selector.value,\n",
    "            start_date=start_date_raw,\n",
    "            calc_period=calc_period_input.value,\n",
    "            fwd_period=fwd_period_input.value,\n",
    "            metric=metric_dropdown.value,\n",
    "            benchmark_ticker=benchmark_input.value.strip().upper(),\n",
    "            rank_start=rank_start_input.value,\n",
    "            rank_end=rank_end_input.value,\n",
    "            quality_thresholds=quality_thresholds,\n",
    "            manual_tickers=manual_list,\n",
    "            debug=debug\n",
    "        )\n",
    "        \n",
    "        with ticker_list_output:\n",
    "            res = engine.run(inputs)\n",
    "            results_container[0] = res\n",
    "            debug_container[0] = res.debug_data\n",
    "            if res.error_msg: print(res.error_msg); return\n",
    "\n",
    "            with fig.batch_update():\n",
    "                cols = res.normalized_plot_data.columns.tolist()\n",
    "                for i in range(50):\n",
    "                    if i < len(cols): fig.data[i].update(x=res.normalized_plot_data.index, y=res.normalized_plot_data[cols[i]], name=cols[i], visible=True)\n",
    "                    else: fig.data[i].visible = False\n",
    "                \n",
    "                fig.data[50].update(x=res.benchmark_series.index, y=res.benchmark_series.values, name=f\"Benchmark ({inputs.benchmark_ticker})\", visible=not res.benchmark_series.empty)\n",
    "                fig.data[51].update(x=res.portfolio_series.index, y=res.portfolio_series.values, visible=True)\n",
    "                fig.layout.shapes = [dict(type=\"line\", x0=res.calc_end_date, y0=0, x1=res.calc_end_date, y1=1, xref='x', yref='paper', line=dict(color=\"grey\", width=2, dash=\"dash\"))]\n",
    "\n",
    "            req_date = inputs.start_date.date()\n",
    "            act_date = res.start_date.date()\n",
    "            if req_date != act_date: print(f\"‚ÑπÔ∏è Info: Start date {req_date} is not a trading day. Snapping forward to {act_date}.\")\n",
    "            \n",
    "            # --- LIQUIDITY AUDIT PRINT ---\n",
    "            if inputs.mode == 'Ranking' and res.debug_data and 'audit_liquidity' in res.debug_data:\n",
    "                audit = res.debug_data['audit_liquidity']\n",
    "                if audit:\n",
    "                    pct_str = f\"{audit.get('percentile_setting', 0)*100:.0f}%\"\n",
    "                    cut_val = audit.get('final_cutoff_usd', 0)\n",
    "                    print(\"-\" * 60)\n",
    "                    print(f\"üîç LIQUIDITY CHECK ({act_date})\")\n",
    "                    print(f\"   Universe Size: {audit.get('total_tickers_available')} tickers\")\n",
    "                    print(f\"   Filtering: Top {pct_str} of Market\")\n",
    "                    print(f\"   Calculated Cutoff: ${cut_val:,.0f} / day\")\n",
    "                    print(f\"   Tickers Remaining: {audit.get('tickers_passed')}\")\n",
    "                    print(\"-\" * 60)\n",
    "            \n",
    "            print(f\"Analysis Period: {act_date} to {res.viz_end_date.date()}.\")\n",
    "            \n",
    "            if inputs.mode == 'Ranking': print(\"Ranked Tickers:\"); pprint.pprint(res.tickers)\n",
    "            else: print(\"Manual Portfolio Tickers:\"); pprint.pprint(res.tickers)\n",
    "            \n",
    "            m = res.perf_metrics\n",
    "            rows = [\n",
    "                {'Metric': 'Group Portfolio Gain', 'Full': m.get('full_p_gain'), 'Calc': m.get('calc_p_gain'), 'Fwd': m.get('fwd_p_gain')},\n",
    "                {'Metric': f'Benchmark ({inputs.benchmark_ticker}) Gain', 'Full': m.get('full_b_gain'), 'Calc': m.get('calc_b_gain'), 'Fwd': m.get('fwd_b_gain')},\n",
    "                {'Metric': '== Gain Delta', 'Full': m.get('full_p_gain',0)-m.get('full_b_gain',0), 'Calc': m.get('calc_p_gain',0)-m.get('calc_b_gain',0), 'Fwd': m.get('fwd_p_gain',0)-m.get('fwd_b_gain',0)},\n",
    "                {'Metric': 'Group Sharpe (ATR)', 'Full': m.get('full_p_sharpe_atr'), 'Calc': m.get('calc_p_sharpe_atr'), 'Fwd': m.get('fwd_p_sharpe_atr')},\n",
    "                {'Metric': f'Benchmark Sharpe (ATR)', 'Full': m.get('full_b_sharpe_atr'), 'Calc': m.get('calc_b_sharpe_atr'), 'Fwd': m.get('fwd_b_sharpe_atr')},\n",
    "                {'Metric': '== Sharpe Delta', 'Full': m.get('full_p_sharpe_atr',0)-m.get('full_b_sharpe_atr',0), 'Calc': m.get('calc_p_sharpe_atr',0)-m.get('calc_b_sharpe_atr',0), 'Fwd': m.get('fwd_p_sharpe_atr',0)-m.get('fwd_b_sharpe_atr',0)}\n",
    "            ]\n",
    "            display(pd.DataFrame(rows).set_index('Metric').style.format(\"{:+.2%}\", na_rep=\"N/A\"))\n",
    "\n",
    "    update_button.on_click(update_plot)\n",
    "    update_plot(None)\n",
    "    display(ui, fig)\n",
    "    return results_container, debug_container\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION F: UTILITIES\n",
    "# ==============================================================================\n",
    "\n",
    "def print_nested(d, indent=0, width=4):\n",
    "    \"\"\"Pretty-print any nested dict/list/tuple combination.\"\"\"\n",
    "    spacing = ' ' * indent\n",
    "    if isinstance(d, dict):\n",
    "        for k, v in d.items():\n",
    "            print(f'{spacing}{k}:')\n",
    "            print_nested(v, indent + width, width)\n",
    "    elif isinstance(d, (list, tuple)):\n",
    "        for item in d:\n",
    "            print_nested(item, indent, width)\n",
    "    else:\n",
    "        print(f'{spacing}{d}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57b4cb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)  display all rows\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "232740e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 9657171 entries, ('A', Timestamp('1999-11-18 00:00:00')) to ('ZWS', Timestamp('2025-12-03 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   Adj Open   float64\n",
      " 1   Adj High   float64\n",
      " 2   Adj Low    float64\n",
      " 3   Adj Close  float64\n",
      " 4   Volume     int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 405.9+ MB\n",
      "df_ohlcv.info():\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Adj Open</th>\n",
       "      <th>Adj High</th>\n",
       "      <th>Adj Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">A</th>\n",
       "      <th>1999-11-18</th>\n",
       "      <td>27.2452</td>\n",
       "      <td>29.9398</td>\n",
       "      <td>23.9519</td>\n",
       "      <td>26.3470</td>\n",
       "      <td>74716395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-19</th>\n",
       "      <td>25.7108</td>\n",
       "      <td>25.7482</td>\n",
       "      <td>23.8396</td>\n",
       "      <td>24.1764</td>\n",
       "      <td>18198354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-22</th>\n",
       "      <td>24.7378</td>\n",
       "      <td>26.3470</td>\n",
       "      <td>23.9893</td>\n",
       "      <td>26.3470</td>\n",
       "      <td>7857764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-23</th>\n",
       "      <td>25.4488</td>\n",
       "      <td>26.1225</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>7138322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-24</th>\n",
       "      <td>24.0267</td>\n",
       "      <td>25.1120</td>\n",
       "      <td>23.9518</td>\n",
       "      <td>24.5881</td>\n",
       "      <td>5785610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ZWS</th>\n",
       "      <th>2025-11-26</th>\n",
       "      <td>47.5400</td>\n",
       "      <td>48.7000</td>\n",
       "      <td>47.3000</td>\n",
       "      <td>48.1300</td>\n",
       "      <td>1154100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-28</th>\n",
       "      <td>48.4600</td>\n",
       "      <td>48.4800</td>\n",
       "      <td>47.7000</td>\n",
       "      <td>47.7000</td>\n",
       "      <td>481400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-01</th>\n",
       "      <td>47.1700</td>\n",
       "      <td>48.1800</td>\n",
       "      <td>47.1500</td>\n",
       "      <td>47.7400</td>\n",
       "      <td>608100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-02</th>\n",
       "      <td>47.9800</td>\n",
       "      <td>48.3100</td>\n",
       "      <td>47.7100</td>\n",
       "      <td>47.8200</td>\n",
       "      <td>838200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-03</th>\n",
       "      <td>47.8800</td>\n",
       "      <td>48.2200</td>\n",
       "      <td>47.4200</td>\n",
       "      <td>47.4500</td>\n",
       "      <td>688255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9657171 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Adj Open  Adj High  Adj Low  Adj Close    Volume\n",
       "Ticker Date                                                        \n",
       "A      1999-11-18   27.2452   29.9398  23.9519    26.3470  74716395\n",
       "       1999-11-19   25.7108   25.7482  23.8396    24.1764  18198354\n",
       "       1999-11-22   24.7378   26.3470  23.9893    26.3470   7857764\n",
       "       1999-11-23   25.4488   26.1225  23.9518    23.9518   7138322\n",
       "       1999-11-24   24.0267   25.1120  23.9518    24.5881   5785610\n",
       "...                     ...       ...      ...        ...       ...\n",
       "ZWS    2025-11-26   47.5400   48.7000  47.3000    48.1300   1154100\n",
       "       2025-11-28   48.4600   48.4800  47.7000    47.7000    481400\n",
       "       2025-12-01   47.1700   48.1800  47.1500    47.7400    608100\n",
       "       2025-12-02   47.9800   48.3100  47.7100    47.8200    838200\n",
       "       2025-12-03   47.8800   48.2200  47.4200    47.4500    688255\n",
       "\n",
       "[9657171 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = r'c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet'\n",
    "df_ohlcv = pd.read_parquet(data_path, engine='pyarrow')\n",
    "print(f'df_ohlcv.info():\\n{df_ohlcv.info()}')\n",
    "df_ohlcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6720574b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ‚öôÔ∏è Initializing AlphaEngine ---\n",
      "Optimizing data structures...\n",
      "‚úÖ AlphaEngine Ready.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e84bd7df3014ae7ad8ef533d3501d24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(RadioButtons(description='Portfolio Mode:', layout=Layout(width='max-content'), options=('Ranki‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "105574687247417aa591a5b66f8d84bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'width': 2},\n",
       "              'name': 'JPST',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a03e9992-470b-4543-9bb1-859a87bdbafd',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 0.99980155, 1.00019645, 1.00019645, 1.0007898 , 1.00098826,\n",
       "                          1.0003949 , 1.0015796 , 1.00138316, 1.00177806, 1.00197451, 1.00197451,\n",
       "                          1.00236941, 1.00254781, 1.00294472, 1.00334163])},\n",
       "             {'line': {'width': 2},\n",
       "              'name': 'VLO',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ae7d7490-b71e-4358-a2f6-70c853705190',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 0.9975757 , 1.00477468, 1.00484859, 1.01307494, 1.03202584,\n",
       "                          1.03040718, 1.06771769, 1.08049698, 1.07932179, 1.10737858, 1.11024635,\n",
       "                          1.11648447, 1.1331589 , 1.14123743, 1.14131134])},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'b438db34-4cb4-4337-a3ff-18595285522a', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '2569cdca-0a52-47f4-bb9c-3ca11bf8092e', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'd3315198-8773-4318-9feb-c5df3123cfa1', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '0dc2911f-c0e0-47a6-b18d-40f35ef25035', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'd394b991-8746-499b-b5e4-69c87393391b', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'f8c713df-ce4d-4e64-a92c-5b960f41fb09', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '64361f76-c707-4101-b5da-f7007417f8a1', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'b0a39f71-1e45-445b-a5cb-11cfe8013da2', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '9aa22b44-dc8b-4ab2-b2ed-c9f014d274a8', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'f1d26d4d-636c-4489-95c8-75e93b0a0385', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '38b460a5-5537-434c-bf66-2b7f7450917c', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '8cabf7bf-ba66-4c7c-b893-95fa0d3a1253', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '8d842ddc-49bc-4548-862b-070824fb25b7', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '41f8d259-26ba-4703-b41a-74bc4b220504', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '2e039775-7e5d-41d8-ad3e-c16476ff95b3', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '01b733b4-fdee-4b7b-b863-289ac656c34f', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '47d2d6f5-2eea-4758-bfde-d163aa70c7a5', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '46a7e04a-1f49-4869-8cd7-e4635f97b3a1', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '5b80aa6a-b87f-4e92-855d-1e203ef9f0bf', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '9a8d7c2e-c2c8-45f6-9c23-84843fcb3e5b', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '899101dc-ae05-4e49-b735-57e190713c97', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'f7e5f254-ce68-4b25-9a89-c130cf8be781', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '76e6d43b-8e34-4f19-8e17-f189b504e4bd', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '499525f2-20a0-4e48-8a31-6c31711a12e7', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '77099ab1-0d97-44bc-a1c0-e4a655207048', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'cedb2922-5846-4b3a-b400-7f11c1b53b84', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '08a82011-60c5-467f-8889-55d150c43335', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '544826bf-3dc3-4cde-ba7a-24ca0e3222be', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'ee1727cf-fc0b-488e-be4d-a7c4be700764', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'b97e5ccf-560d-4bad-8c49-71c44cb1510c', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '8e21dd7e-8eb0-41a1-9181-a6aee1dc5681', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '61760d19-6e26-4a7c-b7f6-353ef4be0e25', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '0c533973-6281-42fe-bd59-4c3b7008a7e3', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '59e50517-1f48-4fbe-bf7a-e65048d38f89', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'ea42194a-37c0-4138-8c3a-3935203a7d79', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '388a4f70-18e8-4a3b-8814-1bafb53b29e6', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '0b9f25c0-1509-469a-847f-d045ed335d4d', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '971f63ac-b6cf-4138-be63-54b7a99f8bb4', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '37e0a443-62a7-4dae-92ed-8014991a4d41', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '175758c2-4c06-4351-b18a-ea3906c7bb34', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '913c134d-4bcc-4df1-ae41-1ae5c4fc2065', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '89706e72-aa2e-40de-bf62-8f901af99268', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'c6ef021c-0ff7-4344-8b3b-bf8fc24e70f4', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '12928e76-dc14-4e4c-a7d6-7c267f414d9d', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '0c64b601-e42e-405e-87ea-b6be4996c582', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': 'de7262e1-e95b-4a74-ab3a-6fd0b191d5b3', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '2dc9bd89-ab11-4a60-b388-4792f64cee9d', 'visible': False},\n",
       "             {'line': {'width': 2}, 'type': 'scatter', 'uid': '0b84047e-270f-4bc0-9921-942808cb5c53', 'visible': False},\n",
       "             {'line': {'color': 'black', 'dash': 'dash', 'width': 3},\n",
       "              'name': 'Benchmark (VOO)',\n",
       "              'type': 'scatter',\n",
       "              'uid': '49197026-1019-4a90-b382-a3ccf713f753',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 1.00001692, 0.99785841, 0.99750486, 0.99205615, 0.9894409 ,\n",
       "                          0.9855451 , 1.00062421, 0.99639177, 1.00037216, 1.00266599, 1.00620825,\n",
       "                          1.00040599, 0.99303391, 0.99811215, 1.00632666])},\n",
       "             {'line': {'color': 'green', 'width': 3},\n",
       "              'name': 'Group Portfolio',\n",
       "              'type': 'scatter',\n",
       "              'uid': '62891eaa-277e-4839-a891-3d5f09494ddb',\n",
       "              'visible': True,\n",
       "              'x': array([datetime.datetime(2025, 8, 13, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 14, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 15, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 18, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 19, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 20, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 21, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 22, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 25, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 26, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 27, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 28, 0, 0),\n",
       "                          datetime.datetime(2025, 8, 29, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 2, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 3, 0, 0),\n",
       "                          datetime.datetime(2025, 9, 4, 0, 0)], dtype=object),\n",
       "              'y': array([1.        , 0.99868863, 1.00248556, 1.00252252, 1.00693237, 1.01650705,\n",
       "                          1.01540104, 1.03464865, 1.04094007, 1.04054992, 1.05467654, 1.05611043,\n",
       "                          1.05942694, 1.06785336, 1.07209107, 1.07232648])}],\n",
       "    'layout': {'height': 600,\n",
       "               'hovermode': 'x unified',\n",
       "               'shapes': [{'line': {'color': 'grey', 'dash': 'dash', 'width': 2},\n",
       "                           'type': 'line',\n",
       "                           'x0': Timestamp('2025-08-27 00:00:00'),\n",
       "                           'x1': Timestamp('2025-08-27 00:00:00'),\n",
       "                           'xref': 'x',\n",
       "                           'y0': 0,\n",
       "                           'y1': 1,\n",
       "                           'yref': 'paper'}],\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Walk-Forward Performance Analysis'}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_container, debug_container = plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_ohlcv,\n",
    "    default_start_date='2025-08-13',\n",
    "    default_calc_period=10,\n",
    "    default_fwd_period=5,\n",
    "    default_metric='Sharpe (ATR)',\n",
    "    default_rank_start=15,\n",
    "    default_rank_end=16,\n",
    "    default_benchmark_ticker='VOO', \n",
    "    master_calendar_ticker='VOO',    \n",
    "    quality_thresholds = { \n",
    "        'min_median_dollar_volume': 100_000, # A low \"hard floor\" to filter absolute errors/garbage\n",
    "        # If min_liquidity_percentile is 0.8 (Top 20%), we want values > the 0.8 quantile.            \n",
    "        'min_liquidity_percentile': 0.50,    # Dynamic: Only keep the top 50% of stocks by volume\n",
    "        'max_stale_pct': 0.05, \n",
    "        'max_same_vol_count': 10\n",
    "    },\n",
    "    debug=True  # <-- Activate the new mode!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d7e2a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = generate_features(df_ohlcv=df_ohlcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca10ca0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 9657171 entries, ('A', Timestamp('1999-11-18 00:00:00')) to ('ZWS', Timestamp('2025-12-03 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   Adj Open   float64\n",
      " 1   Adj High   float64\n",
      " 2   Adj Low    float64\n",
      " 3   Adj Close  float64\n",
      " 4   Volume     int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 663.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_ohlcv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd39f841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 9657171 entries, ('A', Timestamp('1999-11-18 00:00:00')) to ('ZWS', Timestamp('2025-12-03 00:00:00'))\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Dtype  \n",
      "---  ------               -----  \n",
      " 0   TR                   float64\n",
      " 1   ATR                  float64\n",
      " 2   ATRP                 float64\n",
      " 3   RollingStalePct      float64\n",
      " 4   RollMedDollarVol     float64\n",
      " 5   RollingSameVolCount  float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 737.6+ MB\n"
     ]
    }
   ],
   "source": [
    "features_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd30b84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['VOO', 'VLO', 'JPST']\n",
    "date_start = '2025-08-13'\n",
    "date_end = '2025-09-04'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2a826a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 9657171 entries, ('A', Timestamp('1999-11-18 00:00:00')) to ('ZWS', Timestamp('2025-12-03 00:00:00'))\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Dtype  \n",
      "---  ------               -----  \n",
      " 0   TR                   float64\n",
      " 1   ATR                  float64\n",
      " 2   ATRP                 float64\n",
      " 3   RollingStalePct      float64\n",
      " 4   RollMedDollarVol     float64\n",
      " 5   RollingSameVolCount  float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 737.6+ MB\n"
     ]
    }
   ],
   "source": [
    "features_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7eedbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the same function structure but for features_df\n",
    "def get_ticker_features(\n",
    "    features_df: pd.DataFrame,\n",
    "    tickers: Union[str, List[str]],\n",
    "    date_start: str,\n",
    "    date_end: str,\n",
    "    return_format: str = \"dataframe\",\n",
    "    verbose: bool = True\n",
    ") -> Union[pd.DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    Get features data for specified tickers within a date range.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    features_df : pd.DataFrame\n",
    "        DataFrame with MultiIndex of (ticker, date) and feature columns\n",
    "    tickers : str or list of str\n",
    "        Ticker symbol(s) to retrieve\n",
    "    date_start : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    date_end : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    return_format : str, optional\n",
    "        Format to return data in. Options: \n",
    "        - 'dataframe': Single DataFrame with MultiIndex (default)\n",
    "        - 'dict': Dictionary with tickers as keys and DataFrames as values\n",
    "        - 'separate': List of separate DataFrames for each ticker\n",
    "    verbose : bool, optional\n",
    "        Whether to print summary information (default: True)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Union[pd.DataFrame, dict, list]\n",
    "        Filtered features data in specified format\n",
    "    \"\"\"\n",
    "    # Convert single ticker to list for consistent processing\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "    \n",
    "    # Filter the data using MultiIndex slicing\n",
    "    try:\n",
    "        filtered_data = features_df.loc[(tickers, slice(date_start, date_end)), :]\n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"Error filtering data: {e}\")\n",
    "        return pd.DataFrame() if return_format == \"dataframe\" else {}\n",
    "    \n",
    "    # Handle empty results\n",
    "    if filtered_data.empty:\n",
    "        if verbose:\n",
    "            print(f\"No data found for tickers {tickers} in date range {date_start} to {date_end}\")\n",
    "        return filtered_data\n",
    "    \n",
    "    # Print summary if verbose\n",
    "    if verbose:\n",
    "        print(f\"Features data retrieved for {len(tickers)} ticker(s) from {date_start} to {date_end}\")\n",
    "        print(f\"Total rows: {len(filtered_data)}\")\n",
    "        print(f\"Date range in data: {filtered_data.index.get_level_values(1).min()} to \"\n",
    "              f\"{filtered_data.index.get_level_values(1).max()}\")\n",
    "        print(f\"Available features: {', '.join(filtered_data.columns.tolist())}\")\n",
    "        \n",
    "        # Print ticker-specific counts\n",
    "        ticker_counts = filtered_data.index.get_level_values(0).value_counts()\n",
    "        for ticker in tickers:\n",
    "            count = ticker_counts.get(ticker, 0)\n",
    "            if count > 0:\n",
    "                print(f\"  {ticker}: {count} rows\")\n",
    "            else:\n",
    "                print(f\"  {ticker}: No data in range\")\n",
    "    \n",
    "    # Return in requested format\n",
    "    if return_format == \"dict\":\n",
    "        result = {}\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result[ticker] = filtered_data.xs(ticker, level=0).loc[date_start:date_end]\n",
    "            except KeyError:\n",
    "                result[ticker] = pd.DataFrame()\n",
    "        return result\n",
    "    \n",
    "    elif return_format == \"separate\":\n",
    "        result = []\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result.append(filtered_data.xs(ticker, level=0).loc[date_start:date_end])\n",
    "            except KeyError:\n",
    "                result.append(pd.DataFrame())\n",
    "        return result\n",
    "    \n",
    "    elif return_format == \"dataframe\":\n",
    "        return filtered_data\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Invalid return_format: {return_format}. \"\n",
    "                         f\"Must be 'dataframe', 'dict', or 'separate'\")\n",
    "\n",
    "# Define the get_ticker_OHLCV function\n",
    "def get_ticker_OHLCV(\n",
    "    df_ohlcv: pd.DataFrame,\n",
    "    tickers: Union[str, List[str]],\n",
    "    date_start: str,\n",
    "    date_end: str,\n",
    "    return_format: str = \"dataframe\",\n",
    "    verbose: bool = True\n",
    ") -> Union[pd.DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    Get OHLCV data for specified tickers within a date range.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_ohlcv : pd.DataFrame\n",
    "        DataFrame with MultiIndex of (ticker, date) and OHLCV columns\n",
    "    tickers : str or list of str\n",
    "        Ticker symbol(s) to retrieve\n",
    "    date_start : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    date_end : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    return_format : str, optional\n",
    "        Format to return data in. Options: \n",
    "        - 'dataframe': Single DataFrame with MultiIndex (default)\n",
    "        - 'dict': Dictionary with tickers as keys and DataFrames as values\n",
    "        - 'separate': List of separate DataFrames for each ticker\n",
    "    verbose : bool, optional\n",
    "        Whether to print summary information (default: True)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Union[pd.DataFrame, dict, list]\n",
    "        Filtered OHLCV data in specified format\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If input parameters are invalid\n",
    "    KeyError\n",
    "        If tickers not found in DataFrame\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> # Get data for single ticker\n",
    "    >>> vlo_data = get_ticker_OHLCV(df_ohlcv, 'VLO', '2025-08-13', '2025-09-04')\n",
    "    \n",
    "    >>> # Get data for multiple tickers\n",
    "    >>> multi_data = get_ticker_OHLCV(df_ohlcv, ['VLO', 'JPST'], '2025-08-13', '2025-09-04')\n",
    "    \n",
    "    >>> # Get data as dictionary\n",
    "    >>> data_dict = get_ticker_OHLCV(df_ohlcv, ['VLO', 'JPST'], '2025-08-13', \n",
    "    ...                              '2025-09-04', return_format='dict')\n",
    "    \"\"\"\n",
    "    \n",
    "    # Input validation\n",
    "    if not isinstance(df_ohlcv, pd.DataFrame):\n",
    "        raise TypeError(\"df_ohlcv must be a pandas DataFrame\")\n",
    "    \n",
    "    if not isinstance(df_ohlcv.index, pd.MultiIndex):\n",
    "        raise ValueError(\"DataFrame must have MultiIndex of (ticker, date)\")\n",
    "    \n",
    "    if len(df_ohlcv.index.levels) != 2:\n",
    "        raise ValueError(\"MultiIndex must have exactly 2 levels: (ticker, date)\")\n",
    "    \n",
    "    # Convert single ticker to list for consistent processing\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "    elif not isinstance(tickers, list):\n",
    "        raise TypeError(\"tickers must be a string or list of strings\")\n",
    "    \n",
    "    # Convert dates to Timestamps\n",
    "    try:\n",
    "        start_date = pd.Timestamp(date_start)\n",
    "        end_date = pd.Timestamp(date_end)\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"Invalid date format. Use 'YYYY-MM-DD': {e}\")\n",
    "    \n",
    "    if start_date > end_date:\n",
    "        raise ValueError(\"date_start must be before or equal to date_end\")\n",
    "    \n",
    "    # Check if tickers exist in the DataFrame\n",
    "    available_tickers = df_ohlcv.index.get_level_values(0).unique()\n",
    "    missing_tickers = [t for t in tickers if t not in available_tickers]\n",
    "    \n",
    "    if missing_tickers:\n",
    "        raise KeyError(f\"Ticker(s) not found in DataFrame: {missing_tickers}\")\n",
    "    \n",
    "    # Filter the data using MultiIndex slicing\n",
    "    try:\n",
    "        filtered_data = df_ohlcv.loc[(tickers, slice(date_start, date_end)), :]\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error filtering data: {e}\")\n",
    "    \n",
    "    # Handle empty results\n",
    "    if filtered_data.empty:\n",
    "        if verbose:\n",
    "            print(f\"No data found for tickers {tickers} in date range {date_start} to {date_end}\")\n",
    "        return filtered_data\n",
    "    \n",
    "    # Print summary if verbose\n",
    "    if verbose:\n",
    "        print(f\"Data retrieved for {len(tickers)} ticker(s) from {date_start} to {date_end}\")\n",
    "        print(f\"Total rows: {len(filtered_data)}\")\n",
    "        print(f\"Date range in data: {filtered_data.index.get_level_values(1).min()} to \"\n",
    "              f\"{filtered_data.index.get_level_values(1).max()}\")\n",
    "        \n",
    "        # Print ticker-specific counts\n",
    "        ticker_counts = filtered_data.index.get_level_values(0).value_counts()\n",
    "        for ticker in tickers:\n",
    "            count = ticker_counts.get(ticker, 0)\n",
    "            if count > 0:\n",
    "                print(f\"  {ticker}: {count} rows\")\n",
    "            else:\n",
    "                print(f\"  {ticker}: No data in range\")\n",
    "    \n",
    "    # Return in requested format\n",
    "    if return_format == \"dict\":\n",
    "        result = {}\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result[ticker] = filtered_data.xs(ticker, level=0).loc[date_start:date_end]\n",
    "            except KeyError:\n",
    "                result[ticker] = pd.DataFrame()\n",
    "        return result\n",
    "    \n",
    "    elif return_format == \"separate\":\n",
    "        result = []\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result.append(filtered_data.xs(ticker, level=0).loc[date_start:date_end])\n",
    "            except KeyError:\n",
    "                result.append(pd.DataFrame())\n",
    "        return result\n",
    "    \n",
    "    elif return_format == \"dataframe\":\n",
    "        return filtered_data\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Invalid return_format: {return_format}. \"\n",
    "                         f\"Must be 'dataframe', 'dict', or 'separate'\")\n",
    "\n",
    "# Use the function to extract data\n",
    "tickers = ['VOO', 'VLO', 'JPST']\n",
    "tickers = ['VOO']\n",
    "date_start = '2025-08-13'\n",
    "date_end = '2025-09-04'\n",
    "\n",
    "\n",
    "\n",
    "def create_combined_dict(\n",
    "    df_ohlcv: pd.DataFrame,\n",
    "    features_df: pd.DataFrame,\n",
    "    tickers: Union[str, List[str]],\n",
    "    date_start: str,\n",
    "    date_end: str,\n",
    "    verbose: bool = True\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Create a combined dictionary with both OHLCV and features data for each ticker.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_ohlcv : pd.DataFrame\n",
    "        DataFrame with OHLCV data (MultiIndex: ticker, date)\n",
    "    features_df : pd.DataFrame\n",
    "        DataFrame with features data (MultiIndex: ticker, date)\n",
    "    tickers : str or list of str\n",
    "        Ticker symbol(s) to retrieve\n",
    "    date_start : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    date_end : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    verbose : bool, optional\n",
    "        Whether to print progress information (default: True)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with tickers as keys and combined DataFrames (OHLCV + features) as values\n",
    "    \"\"\"\n",
    "    # Convert single ticker to list\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Creating combined dictionary for {len(tickers)} ticker(s)\")\n",
    "        print(f\"Date range: {date_start} to {date_end}\")\n",
    "        print(\"=\" * 60)\n",
    "    \n",
    "    # Get OHLCV data as dictionary\n",
    "    ohlcv_dict = get_ticker_OHLCV(\n",
    "        df_ohlcv, tickers, date_start, date_end, \n",
    "        return_format='dict', verbose=verbose\n",
    "    )\n",
    "    \n",
    "    # Get features data as dictionary\n",
    "    features_dict = get_ticker_features(\n",
    "        features_df, tickers, date_start, date_end,\n",
    "        return_format='dict', verbose=verbose\n",
    "    )\n",
    "    \n",
    "    # Create combined_dict\n",
    "    combined_dict = {}\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        if verbose:\n",
    "            print(f\"\\nProcessing {ticker}...\")\n",
    "        \n",
    "        # Check if ticker exists in both dictionaries\n",
    "        if ticker in ohlcv_dict and ticker in features_dict:\n",
    "            ohlcv_data = ohlcv_dict[ticker]\n",
    "            features_data = features_dict[ticker]\n",
    "            \n",
    "            # Check if both dataframes have data\n",
    "            if not ohlcv_data.empty and not features_data.empty:\n",
    "                # Combine OHLCV and features data\n",
    "                # Note: Both dataframes have the same index (dates), so we can concatenate\n",
    "                combined_df = pd.concat([ohlcv_data, features_data], axis=1)\n",
    "                \n",
    "                # Ensure proper index naming\n",
    "                combined_df.index.name = 'Date'\n",
    "                \n",
    "                # Store in combined_dict\n",
    "                combined_dict[ticker] = combined_df\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"  ‚úì Successfully combined data\")\n",
    "                    print(f\"  OHLCV shape: {ohlcv_data.shape}\")\n",
    "                    print(f\"  Features shape: {features_data.shape}\")\n",
    "                    print(f\"  Combined shape: {combined_df.shape}\")\n",
    "                    print(f\"  Date range: {combined_df.index.min()} to {combined_df.index.max()}\")\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"  ‚úó Cannot combine: One or both dataframes are empty\")\n",
    "                    print(f\"    OHLCV empty: {ohlcv_data.empty}\")\n",
    "                    print(f\"    Features empty: {features_data.empty}\")\n",
    "                combined_dict[ticker] = pd.DataFrame()\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(f\"  ‚úó Ticker not found in both dictionaries\")\n",
    "                if ticker not in ohlcv_dict:\n",
    "                    print(f\"    Not in OHLCV data\")\n",
    "                if ticker not in features_dict:\n",
    "                    print(f\"    Not in features data\")\n",
    "            combined_dict[ticker] = pd.DataFrame()\n",
    "    \n",
    "    # Print summary\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"SUMMARY\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Total tickers processed: {len(tickers)}\")\n",
    "        \n",
    "        tickers_with_data = [ticker for ticker, df in combined_dict.items() if not df.empty]\n",
    "        print(f\"Tickers with combined data: {len(tickers_with_data)}\")\n",
    "        \n",
    "        if tickers_with_data:\n",
    "            print(\"\\nTicker details:\")\n",
    "            for ticker in tickers_with_data:\n",
    "                df = combined_dict[ticker]\n",
    "                print(f\"  {ticker}: {df.shape} - {df.index.min()} to {df.index.max()}\")\n",
    "                print(f\"    Columns: {len(df.columns)}\")\n",
    "        \n",
    "        empty_tickers = [ticker for ticker, df in combined_dict.items() if df.empty]\n",
    "        if empty_tickers:\n",
    "            print(f\"\\nTickers with no data: {', '.join(empty_tickers)}\")\n",
    "    \n",
    "    return combined_dict\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Assuming df_ohlcv and features_df are already loaded\n",
    "    \n",
    "    # Define parameters\n",
    "    tickers = ['VOO', 'VLO', 'JPST']\n",
    "    date_start = '2025-08-13'\n",
    "    date_end = '2025-09-04'\n",
    "    \n",
    "    # Create combined dictionary\n",
    "    combined_dict = create_combined_dict(\n",
    "        df_ohlcv=df_ohlcv,\n",
    "        features_df=features_df,\n",
    "        tickers=tickers,\n",
    "        date_start=date_start,\n",
    "        date_end=date_end,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # Analyze the combined data\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ANALYZING COMBINED DATA\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for ticker, combined_df in combined_dict.items():\n",
    "        if not combined_df.empty:\n",
    "            print(f\"\\n{ticker}:\")\n",
    "            print(f\"  Shape: {combined_df.shape}\")\n",
    "            print(f\"  Date range: {combined_df.index.min()} to {combined_df.index.max()}\")\n",
    "            print(f\"  Columns ({len(combined_df.columns)}):\")\n",
    "            \n",
    "            # Group columns by type\n",
    "            ohlcv_cols = [col for col in combined_df.columns if 'Adj' in col or col == 'Volume']\n",
    "            feature_cols = [col for col in combined_df.columns if col not in ohlcv_cols]\n",
    "            \n",
    "            if ohlcv_cols:\n",
    "                print(f\"    OHLCV: {', '.join(ohlcv_cols)}\")\n",
    "            if feature_cols:\n",
    "                print(f\"    Features: {', '.join(feature_cols)}\")\n",
    "            \n",
    "            # Check for missing values\n",
    "            nan_count = combined_df.isna().sum().sum()\n",
    "            if nan_count > 0:\n",
    "                print(f\"  Missing values: {nan_count}\")\n",
    "            \n",
    "            # Show sample\n",
    "            print(f\"\\n  Sample (first 3 rows):\")\n",
    "            print(combined_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9589ed84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Open</th>\n",
       "      <th>Adj High</th>\n",
       "      <th>Adj Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>TR</th>\n",
       "      <th>ATR</th>\n",
       "      <th>ATRP</th>\n",
       "      <th>RollingStalePct</th>\n",
       "      <th>RollMedDollarVol</th>\n",
       "      <th>RollingSameVolCount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-08-13</th>\n",
       "      <td>591.169</td>\n",
       "      <td>592.336</td>\n",
       "      <td>589.125</td>\n",
       "      <td>591.149</td>\n",
       "      <td>5408423</td>\n",
       "      <td>3.241</td>\n",
       "      <td>5.207220</td>\n",
       "      <td>0.008809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.939980e+09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-14</th>\n",
       "      <td>589.235</td>\n",
       "      <td>591.817</td>\n",
       "      <td>588.816</td>\n",
       "      <td>591.159</td>\n",
       "      <td>6254536</td>\n",
       "      <td>3.001</td>\n",
       "      <td>5.049633</td>\n",
       "      <td>0.008542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.940885e+09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-15</th>\n",
       "      <td>592.166</td>\n",
       "      <td>592.256</td>\n",
       "      <td>588.976</td>\n",
       "      <td>589.883</td>\n",
       "      <td>7216880</td>\n",
       "      <td>3.280</td>\n",
       "      <td>4.923231</td>\n",
       "      <td>0.008346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.946086e+09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-18</th>\n",
       "      <td>589.295</td>\n",
       "      <td>590.332</td>\n",
       "      <td>588.666</td>\n",
       "      <td>589.674</td>\n",
       "      <td>5326890</td>\n",
       "      <td>1.666</td>\n",
       "      <td>4.690571</td>\n",
       "      <td>0.007955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.960129e+09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-19</th>\n",
       "      <td>589.564</td>\n",
       "      <td>590.431</td>\n",
       "      <td>585.266</td>\n",
       "      <td>586.453</td>\n",
       "      <td>6758573</td>\n",
       "      <td>5.165</td>\n",
       "      <td>4.724459</td>\n",
       "      <td>0.008056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.969911e+09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-20</th>\n",
       "      <td>586.134</td>\n",
       "      <td>586.323</td>\n",
       "      <td>580.191</td>\n",
       "      <td>584.907</td>\n",
       "      <td>7133944</td>\n",
       "      <td>6.262</td>\n",
       "      <td>4.834284</td>\n",
       "      <td>0.008265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.973949e+09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-21</th>\n",
       "      <td>583.262</td>\n",
       "      <td>584.788</td>\n",
       "      <td>580.988</td>\n",
       "      <td>582.604</td>\n",
       "      <td>4821048</td>\n",
       "      <td>3.919</td>\n",
       "      <td>4.768906</td>\n",
       "      <td>0.008186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.973949e+09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-22</th>\n",
       "      <td>584.598</td>\n",
       "      <td>592.625</td>\n",
       "      <td>584.169</td>\n",
       "      <td>591.518</td>\n",
       "      <td>6407572</td>\n",
       "      <td>10.021</td>\n",
       "      <td>5.144056</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.978218e+09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-25</th>\n",
       "      <td>590.362</td>\n",
       "      <td>591.538</td>\n",
       "      <td>588.866</td>\n",
       "      <td>589.016</td>\n",
       "      <td>6501540</td>\n",
       "      <td>2.672</td>\n",
       "      <td>4.967480</td>\n",
       "      <td>0.008434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.989747e+09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-26</th>\n",
       "      <td>588.696</td>\n",
       "      <td>591.738</td>\n",
       "      <td>588.108</td>\n",
       "      <td>591.369</td>\n",
       "      <td>4790260</td>\n",
       "      <td>3.630</td>\n",
       "      <td>4.871946</td>\n",
       "      <td>0.008238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.989747e+09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-27</th>\n",
       "      <td>590.830</td>\n",
       "      <td>593.443</td>\n",
       "      <td>590.751</td>\n",
       "      <td>592.725</td>\n",
       "      <td>6189049</td>\n",
       "      <td>2.692</td>\n",
       "      <td>4.716236</td>\n",
       "      <td>0.007957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.002742e+09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-28</th>\n",
       "      <td>593.373</td>\n",
       "      <td>595.367</td>\n",
       "      <td>591.578</td>\n",
       "      <td>594.819</td>\n",
       "      <td>5073167</td>\n",
       "      <td>3.789</td>\n",
       "      <td>4.650004</td>\n",
       "      <td>0.007818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.011246e+09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-29</th>\n",
       "      <td>593.543</td>\n",
       "      <td>593.852</td>\n",
       "      <td>589.564</td>\n",
       "      <td>591.389</td>\n",
       "      <td>7533483</td>\n",
       "      <td>5.255</td>\n",
       "      <td>4.693218</td>\n",
       "      <td>0.007936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.018711e+09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-02</th>\n",
       "      <td>584.389</td>\n",
       "      <td>587.121</td>\n",
       "      <td>582.006</td>\n",
       "      <td>587.031</td>\n",
       "      <td>11148492</td>\n",
       "      <td>9.383</td>\n",
       "      <td>5.028203</td>\n",
       "      <td>0.008565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.019993e+09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-03</th>\n",
       "      <td>589.125</td>\n",
       "      <td>590.541</td>\n",
       "      <td>587.101</td>\n",
       "      <td>590.033</td>\n",
       "      <td>8229368</td>\n",
       "      <td>3.510</td>\n",
       "      <td>4.919760</td>\n",
       "      <td>0.008338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.027491e+09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-04</th>\n",
       "      <td>590.780</td>\n",
       "      <td>595.068</td>\n",
       "      <td>589.913</td>\n",
       "      <td>594.889</td>\n",
       "      <td>8068609</td>\n",
       "      <td>5.155</td>\n",
       "      <td>4.936563</td>\n",
       "      <td>0.008298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.043364e+09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Adj Open  Adj High  Adj Low  Adj Close    Volume      TR  \\\n",
       "Date                                                                   \n",
       "2025-08-13   591.169   592.336  589.125    591.149   5408423   3.241   \n",
       "2025-08-14   589.235   591.817  588.816    591.159   6254536   3.001   \n",
       "2025-08-15   592.166   592.256  588.976    589.883   7216880   3.280   \n",
       "2025-08-18   589.295   590.332  588.666    589.674   5326890   1.666   \n",
       "2025-08-19   589.564   590.431  585.266    586.453   6758573   5.165   \n",
       "2025-08-20   586.134   586.323  580.191    584.907   7133944   6.262   \n",
       "2025-08-21   583.262   584.788  580.988    582.604   4821048   3.919   \n",
       "2025-08-22   584.598   592.625  584.169    591.518   6407572  10.021   \n",
       "2025-08-25   590.362   591.538  588.866    589.016   6501540   2.672   \n",
       "2025-08-26   588.696   591.738  588.108    591.369   4790260   3.630   \n",
       "2025-08-27   590.830   593.443  590.751    592.725   6189049   2.692   \n",
       "2025-08-28   593.373   595.367  591.578    594.819   5073167   3.789   \n",
       "2025-08-29   593.543   593.852  589.564    591.389   7533483   5.255   \n",
       "2025-09-02   584.389   587.121  582.006    587.031  11148492   9.383   \n",
       "2025-09-03   589.125   590.541  587.101    590.033   8229368   3.510   \n",
       "2025-09-04   590.780   595.068  589.913    594.889   8068609   5.155   \n",
       "\n",
       "                 ATR      ATRP  RollingStalePct  RollMedDollarVol  \\\n",
       "Date                                                                \n",
       "2025-08-13  5.207220  0.008809              0.0      2.939980e+09   \n",
       "2025-08-14  5.049633  0.008542              0.0      2.940885e+09   \n",
       "2025-08-15  4.923231  0.008346              0.0      2.946086e+09   \n",
       "2025-08-18  4.690571  0.007955              0.0      2.960129e+09   \n",
       "2025-08-19  4.724459  0.008056              0.0      2.969911e+09   \n",
       "2025-08-20  4.834284  0.008265              0.0      2.973949e+09   \n",
       "2025-08-21  4.768906  0.008186              0.0      2.973949e+09   \n",
       "2025-08-22  5.144056  0.008696              0.0      2.978218e+09   \n",
       "2025-08-25  4.967480  0.008434              0.0      2.989747e+09   \n",
       "2025-08-26  4.871946  0.008238              0.0      2.989747e+09   \n",
       "2025-08-27  4.716236  0.007957              0.0      3.002742e+09   \n",
       "2025-08-28  4.650004  0.007818              0.0      3.011246e+09   \n",
       "2025-08-29  4.693218  0.007936              0.0      3.018711e+09   \n",
       "2025-09-02  5.028203  0.008565              0.0      3.019993e+09   \n",
       "2025-09-03  4.919760  0.008338              0.0      3.027491e+09   \n",
       "2025-09-04  4.936563  0.008298              0.0      3.043364e+09   \n",
       "\n",
       "            RollingSameVolCount  \n",
       "Date                             \n",
       "2025-08-13                  0.0  \n",
       "2025-08-14                  0.0  \n",
       "2025-08-15                  0.0  \n",
       "2025-08-18                  0.0  \n",
       "2025-08-19                  0.0  \n",
       "2025-08-20                  0.0  \n",
       "2025-08-21                  0.0  \n",
       "2025-08-22                  0.0  \n",
       "2025-08-25                  0.0  \n",
       "2025-08-26                  0.0  \n",
       "2025-08-27                  0.0  \n",
       "2025-08-28                  0.0  \n",
       "2025-08-29                  0.0  \n",
       "2025-09-02                  0.0  \n",
       "2025-09-03                  0.0  \n",
       "2025-09-04                  0.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dict['VOO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bcf5aa92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features data...\n",
      "============================================================\n",
      "Features data retrieved for 1 ticker(s) from 2025-08-13 to 2025-09-04\n",
      "Total rows: 16\n",
      "Date range in data: 2025-08-13 00:00:00 to 2025-09-04 00:00:00\n",
      "Available features: TR, ATR, ATRP, RollingStalePct, RollMedDollarVol, RollingSameVolCount\n",
      "  VOO: 16 rows\n",
      "\n",
      "Features data (first 10 rows):\n",
      "                       TR       ATR      ATRP  RollingStalePct  \\\n",
      "Ticker Date                                                      \n",
      "VOO    2025-08-13   3.241  5.207220  0.008809              0.0   \n",
      "       2025-08-14   3.001  5.049633  0.008542              0.0   \n",
      "       2025-08-15   3.280  4.923231  0.008346              0.0   \n",
      "       2025-08-18   1.666  4.690571  0.007955              0.0   \n",
      "       2025-08-19   5.165  4.724459  0.008056              0.0   \n",
      "       2025-08-20   6.262  4.834284  0.008265              0.0   \n",
      "       2025-08-21   3.919  4.768906  0.008186              0.0   \n",
      "       2025-08-22  10.021  5.144056  0.008696              0.0   \n",
      "       2025-08-25   2.672  4.967480  0.008434              0.0   \n",
      "       2025-08-26   3.630  4.871946  0.008238              0.0   \n",
      "\n",
      "                   RollMedDollarVol  RollingSameVolCount  \n",
      "Ticker Date                                               \n",
      "VOO    2025-08-13      2.939980e+09                  0.0  \n",
      "       2025-08-14      2.940885e+09                  0.0  \n",
      "       2025-08-15      2.946086e+09                  0.0  \n",
      "       2025-08-18      2.960129e+09                  0.0  \n",
      "       2025-08-19      2.969911e+09                  0.0  \n",
      "       2025-08-20      2.973949e+09                  0.0  \n",
      "       2025-08-21      2.973949e+09                  0.0  \n",
      "       2025-08-22      2.978218e+09                  0.0  \n",
      "       2025-08-25      2.989747e+09                  0.0  \n",
      "       2025-08-26      2.989747e+09                  0.0  \n",
      "\n",
      "============================================================\n",
      "Option 2: Get as dictionary for easier access\n",
      "============================================================\n",
      "Features data retrieved for 1 ticker(s) from 2025-08-13 to 2025-09-04\n",
      "Total rows: 16\n",
      "Date range in data: 2025-08-13 00:00:00 to 2025-09-04 00:00:00\n",
      "Available features: TR, ATR, ATRP, RollingStalePct, RollMedDollarVol, RollingSameVolCount\n",
      "  VOO: 16 rows\n",
      "\n",
      "VOO features shape: (16, 6)\n",
      "Date range: 2025-08-13 00:00:00 to 2025-09-04 00:00:00\n",
      "First few rows:\n",
      "               TR       ATR      ATRP  RollingStalePct  RollMedDollarVol  \\\n",
      "Date                                                                       \n",
      "2025-08-13  3.241  5.207220  0.008809              0.0      2.939980e+09   \n",
      "2025-08-14  3.001  5.049633  0.008542              0.0      2.940885e+09   \n",
      "2025-08-15  3.280  4.923231  0.008346              0.0      2.946086e+09   \n",
      "2025-08-18  1.666  4.690571  0.007955              0.0      2.960129e+09   \n",
      "2025-08-19  5.165  4.724459  0.008056              0.0      2.969911e+09   \n",
      "\n",
      "            RollingSameVolCount  \n",
      "Date                             \n",
      "2025-08-13                  0.0  \n",
      "2025-08-14                  0.0  \n",
      "2025-08-15                  0.0  \n",
      "2025-08-18                  0.0  \n",
      "2025-08-19                  0.0  \n",
      "----------------------------------------\n",
      "\n",
      "============================================================\n",
      "Understanding the features:\n",
      "============================================================\n",
      "Feature descriptions:\n",
      "  TR: True Range (daily volatility measure)\n",
      "  ATR: Average True Range (smoothed volatility)\n",
      "  ATRP: Average True Range Percentage (ATR as % of price)\n",
      "  RollingStalePct: Percentage of stale prices in rolling window\n",
      "  RollMedDollarVol: Rolling median dollar volume\n",
      "  RollingSameVolCount: Count of consecutive days with same volume\n",
      "\n",
      "============================================================\n",
      "Statistical summary of extracted features:\n",
      "============================================================\n",
      "              TR        ATR       ATRP  RollingStalePct  RollMedDollarVol  \\\n",
      "count  16.000000  16.000000  16.000000             16.0      1.600000e+01   \n",
      "mean    4.540063   4.882861   0.008277              0.0      2.986634e+09   \n",
      "std     2.329348   0.169487   0.000287              0.0      3.183549e+07   \n",
      "min     1.666000   4.650004   0.007818              0.0      2.939980e+09   \n",
      "25%     3.181000   4.722403   0.008031              0.0      2.967466e+09   \n",
      "50%     3.709500   4.895853   0.008282              0.0      2.983983e+09   \n",
      "75%     5.187500   4.982661   0.008461              0.0      3.013112e+09   \n",
      "max    10.021000   5.207220   0.008809              0.0      3.043364e+09   \n",
      "\n",
      "       RollingSameVolCount  \n",
      "count                 16.0  \n",
      "mean                   0.0  \n",
      "std                    0.0  \n",
      "min                    0.0  \n",
      "25%                    0.0  \n",
      "50%                    0.0  \n",
      "75%                    0.0  \n",
      "max                    0.0  \n",
      "\n",
      "============================================================\n",
      "Alternative: Direct slicing without function\n",
      "============================================================\n",
      "Direct slicing result shape: (16, 6)\n",
      "\n",
      "Number of trading days per ticker:\n",
      "Ticker\n",
      "VOO    16\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "Analyzing specific features:\n",
      "============================================================\n",
      "\n",
      "ATR (Average True Range) statistics by ticker:\n",
      "\n",
      "VOO:\n",
      "  Mean ATR: 4.8829\n",
      "  Max ATR: 5.2072\n",
      "  Min ATR: 4.6500\n",
      "  Std Dev: 0.1695\n",
      "\n",
      "============================================================\n",
      "Combining with OHLCV data:\n",
      "============================================================\n",
      "\n",
      "OHLCV data per ticker:\n",
      "\n",
      "VOO OHLCV shape: (16, 5)\n",
      "Date range: 2025-08-13 00:00:00 to 2025-09-04 00:00:00\n",
      "Columns: ['Adj Open', 'Adj High', 'Adj Low', 'Adj Close', 'Volume']\n",
      "            Adj Open  Adj High  Adj Low  Adj Close   Volume\n",
      "Date                                                       \n",
      "2025-08-13   591.169   592.336  589.125    591.149  5408423\n",
      "2025-08-14   589.235   591.817  588.816    591.159  6254536\n",
      "2025-08-15   592.166   592.256  588.976    589.883  7216880\n",
      "2025-08-18   589.295   590.332  588.666    589.674  5326890\n",
      "2025-08-19   589.564   590.431  585.266    586.453  6758573\n",
      "\n",
      "============================================================\n",
      "Creating combined dictionary (OHLCV + Features):\n",
      "============================================================\n",
      "\n",
      "VOO - Combined data:\n",
      "  Shape: (16, 11)\n",
      "  Date range: 2025-08-13 00:00:00 to 2025-09-04 00:00:00\n",
      "  Total columns: 11\n",
      "  Columns: ['Adj Open', 'Adj High', 'Adj Low', 'Adj Close', 'Volume', 'TR', 'ATR', 'ATRP', 'RollingStalePct', 'RollMedDollarVol', 'RollingSameVolCount']\n",
      "\n",
      "  Sample data (first 5 rows):\n",
      "            Adj Open  Adj High  Adj Low  Adj Close   Volume     TR       ATR  \\\n",
      "Date                                                                           \n",
      "2025-08-13   591.169   592.336  589.125    591.149  5408423  3.241  5.207220   \n",
      "2025-08-14   589.235   591.817  588.816    591.159  6254536  3.001  5.049633   \n",
      "2025-08-15   592.166   592.256  588.976    589.883  7216880  3.280  4.923231   \n",
      "2025-08-18   589.295   590.332  588.666    589.674  5326890  1.666  4.690571   \n",
      "2025-08-19   589.564   590.431  585.266    586.453  6758573  5.165  4.724459   \n",
      "\n",
      "                ATRP  RollingStalePct  RollMedDollarVol  RollingSameVolCount  \n",
      "Date                                                                          \n",
      "2025-08-13  0.008809              0.0      2.939980e+09                  0.0  \n",
      "2025-08-14  0.008542              0.0      2.940885e+09                  0.0  \n",
      "2025-08-15  0.008346              0.0      2.946086e+09                  0.0  \n",
      "2025-08-18  0.007955              0.0      2.960129e+09                  0.0  \n",
      "2025-08-19  0.008056              0.0      2.969911e+09                  0.0  \n",
      "\n",
      "============================================================\n",
      "Analyzing combined data in combined_dict:\n",
      "============================================================\n",
      "\n",
      "VOO combined data analysis:\n",
      "  Total rows: 16\n",
      "  Columns: ['Adj Open', 'Adj High', 'Adj Low', 'Adj Close', 'Volume', 'TR', 'ATR', 'ATRP', 'RollingStalePct', 'RollMedDollarVol', 'RollingSameVolCount']\n",
      "  No NaN values found\n",
      "\n",
      "  Key statistics:\n",
      "    Adj Close - Mean: $589.91\n",
      "    Adj Close - Std: $3.33\n",
      "    Volume - Mean: 6,678,865\n",
      "    ATR - Mean: 4.8829\n",
      "    ATRP - Mean: 0.0083%\n",
      "\n",
      "  First few rows of combined data:\n",
      "            Adj Open  Adj High  Adj Low  Adj Close   Volume     TR       ATR  \\\n",
      "Date                                                                           \n",
      "2025-08-13   591.169   592.336  589.125    591.149  5408423  3.241  5.207220   \n",
      "2025-08-14   589.235   591.817  588.816    591.159  6254536  3.001  5.049633   \n",
      "2025-08-15   592.166   592.256  588.976    589.883  7216880  3.280  4.923231   \n",
      "\n",
      "                ATRP  RollingStalePct  RollMedDollarVol  RollingSameVolCount  \n",
      "Date                                                                          \n",
      "2025-08-13  0.008809              0.0      2.939980e+09                  0.0  \n",
      "2025-08-14  0.008542              0.0      2.940885e+09                  0.0  \n",
      "2025-08-15  0.008346              0.0      2.946086e+09                  0.0  \n",
      "\n",
      "============================================================\n",
      "Additional functionality: Accessing specific data from combined_dict\n",
      "============================================================\n",
      "\n",
      "Accessing VOO's combined data:\n",
      "Shape: (16, 11)\n",
      "\n",
      "VOO Daily Returns Statistics:\n",
      "  Mean Daily Return: 0.0438%\n",
      "  Std Daily Return: 0.6102%\n",
      "  Max Daily Return: 1.5300%\n",
      "  Min Daily Return: -0.7369%\n",
      "\n",
      "Correlation between Volume and ATR: 0.2401\n",
      "\n",
      "============================================================\n",
      "Exporting combined_dict data:\n",
      "============================================================\n",
      "\n",
      "Summary of combined_dict:\n",
      "Number of tickers in combined_dict: 1\n",
      "Tickers with combined data: ['VOO']\n",
      "  VOO: (16, 12)\n"
     ]
    }
   ],
   "source": [
    "# Using the same function structure but for features_df\n",
    "def get_ticker_features(\n",
    "    features_df: pd.DataFrame,\n",
    "    tickers: Union[str, List[str]],\n",
    "    date_start: str,\n",
    "    date_end: str,\n",
    "    return_format: str = \"dataframe\",\n",
    "    verbose: bool = True\n",
    ") -> Union[pd.DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    Get features data for specified tickers within a date range.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    features_df : pd.DataFrame\n",
    "        DataFrame with MultiIndex of (ticker, date) and feature columns\n",
    "    tickers : str or list of str\n",
    "        Ticker symbol(s) to retrieve\n",
    "    date_start : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    date_end : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    return_format : str, optional\n",
    "        Format to return data in. Options: \n",
    "        - 'dataframe': Single DataFrame with MultiIndex (default)\n",
    "        - 'dict': Dictionary with tickers as keys and DataFrames as values\n",
    "        - 'separate': List of separate DataFrames for each ticker\n",
    "    verbose : bool, optional\n",
    "        Whether to print summary information (default: True)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Union[pd.DataFrame, dict, list]\n",
    "        Filtered features data in specified format\n",
    "    \"\"\"\n",
    "    # Convert single ticker to list for consistent processing\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "    \n",
    "    # Filter the data using MultiIndex slicing\n",
    "    try:\n",
    "        filtered_data = features_df.loc[(tickers, slice(date_start, date_end)), :]\n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"Error filtering data: {e}\")\n",
    "        return pd.DataFrame() if return_format == \"dataframe\" else {}\n",
    "    \n",
    "    # Handle empty results\n",
    "    if filtered_data.empty:\n",
    "        if verbose:\n",
    "            print(f\"No data found for tickers {tickers} in date range {date_start} to {date_end}\")\n",
    "        return filtered_data\n",
    "    \n",
    "    # Print summary if verbose\n",
    "    if verbose:\n",
    "        print(f\"Features data retrieved for {len(tickers)} ticker(s) from {date_start} to {date_end}\")\n",
    "        print(f\"Total rows: {len(filtered_data)}\")\n",
    "        print(f\"Date range in data: {filtered_data.index.get_level_values(1).min()} to \"\n",
    "              f\"{filtered_data.index.get_level_values(1).max()}\")\n",
    "        print(f\"Available features: {', '.join(filtered_data.columns.tolist())}\")\n",
    "        \n",
    "        # Print ticker-specific counts\n",
    "        ticker_counts = filtered_data.index.get_level_values(0).value_counts()\n",
    "        for ticker in tickers:\n",
    "            count = ticker_counts.get(ticker, 0)\n",
    "            if count > 0:\n",
    "                print(f\"  {ticker}: {count} rows\")\n",
    "            else:\n",
    "                print(f\"  {ticker}: No data in range\")\n",
    "    \n",
    "    # Return in requested format\n",
    "    if return_format == \"dict\":\n",
    "        result = {}\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result[ticker] = filtered_data.xs(ticker, level=0).loc[date_start:date_end]\n",
    "            except KeyError:\n",
    "                result[ticker] = pd.DataFrame()\n",
    "        return result\n",
    "    \n",
    "    elif return_format == \"separate\":\n",
    "        result = []\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result.append(filtered_data.xs(ticker, level=0).loc[date_start:date_end])\n",
    "            except KeyError:\n",
    "                result.append(pd.DataFrame())\n",
    "        return result\n",
    "    \n",
    "    elif return_format == \"dataframe\":\n",
    "        return filtered_data\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Invalid return_format: {return_format}. \"\n",
    "                         f\"Must be 'dataframe', 'dict', or 'separate'\")\n",
    "\n",
    "# Define the get_ticker_OHLCV function (assuming it exists or define it)\n",
    "def get_ticker_OHLCV(\n",
    "    df_ohlcv: pd.DataFrame,\n",
    "    tickers: Union[str, List[str]],\n",
    "    date_start: str,\n",
    "    date_end: str,\n",
    "    return_format: str = \"dataframe\",\n",
    "    verbose: bool = True\n",
    ") -> Union[pd.DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    Get OHLCV data for specified tickers within a date range.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_ohlcv : pd.DataFrame\n",
    "        DataFrame with MultiIndex of (ticker, date) and OHLCV columns\n",
    "    tickers : str or list of str\n",
    "        Ticker symbol(s) to retrieve\n",
    "    date_start : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    date_end : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    return_format : str, optional\n",
    "        Format to return data in. Options: \n",
    "        - 'dataframe': Single DataFrame with MultiIndex (default)\n",
    "        - 'dict': Dictionary with tickers as keys and DataFrames as values\n",
    "        - 'separate': List of separate DataFrames for each ticker\n",
    "    verbose : bool, optional\n",
    "        Whether to print summary information (default: True)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Union[pd.DataFrame, dict, list]\n",
    "        Filtered OHLCV data in specified format\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If input parameters are invalid\n",
    "    KeyError\n",
    "        If tickers not found in DataFrame\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> # Get data for single ticker\n",
    "    >>> vlo_data = get_ticker_OHLCV(df_ohlcv, 'VLO', '2025-08-13', '2025-09-04')\n",
    "    \n",
    "    >>> # Get data for multiple tickers\n",
    "    >>> multi_data = get_ticker_OHLCV(df_ohlcv, ['VLO', 'JPST'], '2025-08-13', '2025-09-04')\n",
    "    \n",
    "    >>> # Get data as dictionary\n",
    "    >>> data_dict = get_ticker_OHLCV(df_ohlcv, ['VLO', 'JPST'], '2025-08-13', \n",
    "    ...                              '2025-09-04', return_format='dict')\n",
    "    \"\"\"\n",
    "    \n",
    "    # Input validation\n",
    "    if not isinstance(df_ohlcv, pd.DataFrame):\n",
    "        raise TypeError(\"df_ohlcv must be a pandas DataFrame\")\n",
    "    \n",
    "    if not isinstance(df_ohlcv.index, pd.MultiIndex):\n",
    "        raise ValueError(\"DataFrame must have MultiIndex of (ticker, date)\")\n",
    "    \n",
    "    if len(df_ohlcv.index.levels) != 2:\n",
    "        raise ValueError(\"MultiIndex must have exactly 2 levels: (ticker, date)\")\n",
    "    \n",
    "    # Convert single ticker to list for consistent processing\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "    elif not isinstance(tickers, list):\n",
    "        raise TypeError(\"tickers must be a string or list of strings\")\n",
    "    \n",
    "    # Convert dates to Timestamps\n",
    "    try:\n",
    "        start_date = pd.Timestamp(date_start)\n",
    "        end_date = pd.Timestamp(date_end)\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"Invalid date format. Use 'YYYY-MM-DD': {e}\")\n",
    "    \n",
    "    if start_date > end_date:\n",
    "        raise ValueError(\"date_start must be before or equal to date_end\")\n",
    "    \n",
    "    # Check if tickers exist in the DataFrame\n",
    "    available_tickers = df_ohlcv.index.get_level_values(0).unique()\n",
    "    missing_tickers = [t for t in tickers if t not in available_tickers]\n",
    "    \n",
    "    if missing_tickers:\n",
    "        raise KeyError(f\"Ticker(s) not found in DataFrame: {missing_tickers}\")\n",
    "    \n",
    "    # Filter the data using MultiIndex slicing\n",
    "    try:\n",
    "        filtered_data = df_ohlcv.loc[(tickers, slice(date_start, date_end)), :]\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error filtering data: {e}\")\n",
    "    \n",
    "    # Handle empty results\n",
    "    if filtered_data.empty:\n",
    "        if verbose:\n",
    "            print(f\"No data found for tickers {tickers} in date range {date_start} to {date_end}\")\n",
    "        return filtered_data\n",
    "    \n",
    "    # Print summary if verbose\n",
    "    if verbose:\n",
    "        print(f\"Data retrieved for {len(tickers)} ticker(s) from {date_start} to {date_end}\")\n",
    "        print(f\"Total rows: {len(filtered_data)}\")\n",
    "        print(f\"Date range in data: {filtered_data.index.get_level_values(1).min()} to \"\n",
    "              f\"{filtered_data.index.get_level_values(1).max()}\")\n",
    "        \n",
    "        # Print ticker-specific counts\n",
    "        ticker_counts = filtered_data.index.get_level_values(0).value_counts()\n",
    "        for ticker in tickers:\n",
    "            count = ticker_counts.get(ticker, 0)\n",
    "            if count > 0:\n",
    "                print(f\"  {ticker}: {count} rows\")\n",
    "            else:\n",
    "                print(f\"  {ticker}: No data in range\")\n",
    "    \n",
    "    # Return in requested format\n",
    "    if return_format == \"dict\":\n",
    "        result = {}\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result[ticker] = filtered_data.xs(ticker, level=0).loc[date_start:date_end]\n",
    "            except KeyError:\n",
    "                result[ticker] = pd.DataFrame()\n",
    "        return result\n",
    "    \n",
    "    elif return_format == \"separate\":\n",
    "        result = []\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result.append(filtered_data.xs(ticker, level=0).loc[date_start:date_end])\n",
    "            except KeyError:\n",
    "                result.append(pd.DataFrame())\n",
    "        return result\n",
    "    \n",
    "    elif return_format == \"dataframe\":\n",
    "        return filtered_data\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Invalid return_format: {return_format}. \"\n",
    "                         f\"Must be 'dataframe', 'dict', or 'separate'\")\n",
    "\n",
    "# Use the function to extract data\n",
    "tickers = ['VOO', 'VLO', 'JPST']\n",
    "tickers = ['VOO']\n",
    "date_start = '2025-08-13'\n",
    "date_end = '2025-09-04'\n",
    "\n",
    "print(\"Extracting features data...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Option 1: Get as DataFrame with MultiIndex\n",
    "features_data = get_ticker_features(features_df, tickers, date_start, date_end)\n",
    "print(\"\\nFeatures data (first 10 rows):\")\n",
    "print(features_data.head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Option 2: Get as dictionary for easier access\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Option 2: Get as dictionary\n",
    "features_dict = get_ticker_features(features_df, tickers, date_start, date_end, \n",
    "                                    return_format='dict')\n",
    "\n",
    "for ticker, data in features_dict.items():\n",
    "    print(f\"\\n{ticker} features shape: {data.shape}\")\n",
    "    if not data.empty:\n",
    "        print(f\"Date range: {data.index.min()} to {data.index.max()}\")\n",
    "        print(\"First few rows:\")\n",
    "        print(data.head())\n",
    "    else:\n",
    "        print(\"No data available\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Understanding the features:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Display feature descriptions\n",
    "feature_descriptions = {\n",
    "    'TR': 'True Range (daily volatility measure)',\n",
    "    'ATR': 'Average True Range (smoothed volatility)',\n",
    "    'ATRP': 'Average True Range Percentage (ATR as % of price)',\n",
    "    'RollingStalePct': 'Percentage of stale prices in rolling window',\n",
    "    'RollMedDollarVol': 'Rolling median dollar volume',\n",
    "    'RollingSameVolCount': 'Count of consecutive days with same volume'\n",
    "}\n",
    "\n",
    "print(\"Feature descriptions:\")\n",
    "for feature, description in feature_descriptions.items():\n",
    "    print(f\"  {feature}: {description}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Statistical summary of extracted features:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Statistical summary\n",
    "if not features_data.empty:\n",
    "    print(features_data.describe())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Alternative: Direct slicing without function\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Direct slicing (alternative method)\n",
    "direct_result = features_df.loc[(tickers, slice(date_start, date_end)), :]\n",
    "print(f\"Direct slicing result shape: {direct_result.shape}\")\n",
    "print(f\"\\nNumber of trading days per ticker:\")\n",
    "print(direct_result.index.get_level_values(0).value_counts())\n",
    "\n",
    "# If you want to analyze specific features\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Analyzing specific features:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if not features_data.empty:\n",
    "    # Example: Look at ATR (Average True Range) across tickers\n",
    "    print(\"\\nATR (Average True Range) statistics by ticker:\")\n",
    "    for ticker in tickers:\n",
    "        if ticker in features_data.index.get_level_values(0):\n",
    "            ticker_atr = features_data.xs(ticker, level=0)['ATR']\n",
    "            if not ticker_atr.empty:\n",
    "                print(f\"\\n{ticker}:\")\n",
    "                print(f\"  Mean ATR: {ticker_atr.mean():.4f}\")\n",
    "                print(f\"  Max ATR: {ticker_atr.max():.4f}\")\n",
    "                print(f\"  Min ATR: {ticker_atr.min():.4f}\")\n",
    "                print(f\"  Std Dev: {ticker_atr.std():.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Combining with OHLCV data:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get OHLCV data for same tickers and date range\n",
    "ohlcv_data = get_ticker_OHLCV(df_ohlcv, tickers, date_start, date_end, verbose=False)\n",
    "\n",
    "# Get OHLCV data as dictionary\n",
    "ohlcv_dict = get_ticker_OHLCV(df_ohlcv, tickers, date_start, date_end, \n",
    "                              return_format='dict', verbose=False)\n",
    "\n",
    "print(\"\\nOHLCV data per ticker:\")\n",
    "for ticker, data in ohlcv_dict.items():\n",
    "    print(f\"\\n{ticker} OHLCV shape: {data.shape}\")\n",
    "    if not data.empty:\n",
    "        print(f\"Date range: {data.index.min()} to {data.index.max()}\")\n",
    "        print(\"Columns:\", data.columns.tolist())\n",
    "        print(data.head())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Creating combined dictionary (OHLCV + Features):\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create combined_dict with both OHLCV and features for each ticker\n",
    "combined_dict = {}\n",
    "for ticker in tickers:\n",
    "    if ticker in ohlcv_dict and ticker in features_dict:\n",
    "        # Check if both dataframes have data\n",
    "        if not ohlcv_dict[ticker].empty and not features_dict[ticker].empty:\n",
    "            # Combine OHLCV and features data\n",
    "            # Use concat to join along columns (axis=1)\n",
    "            combined_df = pd.concat([ohlcv_dict[ticker], features_dict[ticker]], axis=1)\n",
    "            \n",
    "            # Ensure the index is proper (dates)\n",
    "            combined_df.index.name = 'Date'\n",
    "            \n",
    "            # Add to combined_dict\n",
    "            combined_dict[ticker] = combined_df\n",
    "            \n",
    "            print(f\"\\n{ticker} - Combined data:\")\n",
    "            print(f\"  Shape: {combined_df.shape}\")\n",
    "            print(f\"  Date range: {combined_df.index.min()} to {combined_df.index.max()}\")\n",
    "            print(f\"  Total columns: {len(combined_df.columns)}\")\n",
    "            print(f\"  Columns: {combined_df.columns.tolist()}\")\n",
    "            print(f\"\\n  Sample data (first 5 rows):\")\n",
    "            print(combined_df.head())\n",
    "        else:\n",
    "            print(f\"\\n{ticker} - Cannot combine: One or both dataframes are empty\")\n",
    "            print(f\"  OHLCV empty: {ohlcv_dict[ticker].empty}\")\n",
    "            print(f\"  Features empty: {features_dict[ticker].empty}\")\n",
    "            combined_dict[ticker] = pd.DataFrame()\n",
    "    else:\n",
    "        print(f\"\\n{ticker} - Not found in both dictionaries\")\n",
    "        combined_dict[ticker] = pd.DataFrame()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Analyzing combined data in combined_dict:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Analyze the combined data\n",
    "for ticker, combined_df in combined_dict.items():\n",
    "    if not combined_df.empty:\n",
    "        print(f\"\\n{ticker} combined data analysis:\")\n",
    "        print(f\"  Total rows: {len(combined_df)}\")\n",
    "        print(f\"  Columns: {combined_df.columns.tolist()}\")\n",
    "        \n",
    "        # Check for any NaN values\n",
    "        nan_counts = combined_df.isna().sum()\n",
    "        if nan_counts.sum() > 0:\n",
    "            print(f\"  NaN values by column:\")\n",
    "            for col, count in nan_counts.items():\n",
    "                if count > 0:\n",
    "                    print(f\"    {col}: {count} NaN values ({count/len(combined_df)*100:.2f}%)\")\n",
    "        else:\n",
    "            print(f\"  No NaN values found\")\n",
    "        \n",
    "        # Basic statistics for key columns\n",
    "        print(f\"\\n  Key statistics:\")\n",
    "        if 'Adj Close' in combined_df.columns:\n",
    "            print(f\"    Adj Close - Mean: ${combined_df['Adj Close'].mean():.2f}\")\n",
    "            print(f\"    Adj Close - Std: ${combined_df['Adj Close'].std():.2f}\")\n",
    "        if 'Volume' in combined_df.columns:\n",
    "            print(f\"    Volume - Mean: {combined_df['Volume'].mean():,.0f}\")\n",
    "        if 'ATR' in combined_df.columns:\n",
    "            print(f\"    ATR - Mean: {combined_df['ATR'].mean():.4f}\")\n",
    "        if 'ATRP' in combined_df.columns:\n",
    "            print(f\"    ATRP - Mean: {combined_df['ATRP'].mean():.4f}%\")\n",
    "        \n",
    "        print(f\"\\n  First few rows of combined data:\")\n",
    "        print(combined_df.head(3))\n",
    "    else:\n",
    "        print(f\"\\n{ticker}: No combined data available\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Additional functionality: Accessing specific data from combined_dict\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Example: Access specific ticker's combined data\n",
    "if 'VOO' in combined_dict and not combined_dict['VOO'].empty:\n",
    "    print(\"\\nAccessing VOO's combined data:\")\n",
    "    voo_data = combined_dict['VOO']\n",
    "    print(f\"Shape: {voo_data.shape}\")\n",
    "    \n",
    "    # Calculate daily returns\n",
    "    if 'Adj Close' in voo_data.columns:\n",
    "        voo_data['Daily_Return'] = voo_data['Adj Close'].pct_change()\n",
    "        print(f\"\\nVOO Daily Returns Statistics:\")\n",
    "        print(f\"  Mean Daily Return: {voo_data['Daily_Return'].mean()*100:.4f}%\")\n",
    "        print(f\"  Std Daily Return: {voo_data['Daily_Return'].std()*100:.4f}%\")\n",
    "        print(f\"  Max Daily Return: {voo_data['Daily_Return'].max()*100:.4f}%\")\n",
    "        print(f\"  Min Daily Return: {voo_data['Daily_Return'].min()*100:.4f}%\")\n",
    "    \n",
    "    # Check correlation between volume and ATR\n",
    "    if 'Volume' in voo_data.columns and 'ATR' in voo_data.columns:\n",
    "        correlation = voo_data['Volume'].corr(voo_data['ATR'])\n",
    "        print(f\"\\nCorrelation between Volume and ATR: {correlation:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Exporting combined_dict data:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Option to export each ticker's combined data to CSV\n",
    "export_to_csv = False  # Set to True if you want to export\n",
    "if export_to_csv:\n",
    "    for ticker, combined_df in combined_dict.items():\n",
    "        if not combined_df.empty:\n",
    "            filename = f\"{ticker}_combined_{date_start}_{date_end}.csv\"\n",
    "            combined_df.to_csv(filename)\n",
    "            print(f\"Exported {ticker} data to {filename}\")\n",
    "\n",
    "print(\"\\nSummary of combined_dict:\")\n",
    "print(f\"Number of tickers in combined_dict: {len(combined_dict)}\")\n",
    "tickers_with_data = [ticker for ticker, df in combined_dict.items() if not df.empty]\n",
    "print(f\"Tickers with combined data: {tickers_with_data}\")\n",
    "if tickers_with_data:\n",
    "    for ticker in tickers_with_data:\n",
    "        print(f\"  {ticker}: {combined_dict[ticker].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca5c1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3e8bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the same function structure but for features_df\n",
    "def get_ticker_features(\n",
    "    features_df: pd.DataFrame,\n",
    "    tickers: Union[str, List[str]],\n",
    "    date_start: str,\n",
    "    date_end: str,\n",
    "    return_format: str = \"dataframe\",\n",
    "    verbose: bool = True\n",
    ") -> Union[pd.DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    Get features data for specified tickers within a date range.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    features_df : pd.DataFrame\n",
    "        DataFrame with MultiIndex of (ticker, date) and feature columns\n",
    "    tickers : str or list of str\n",
    "        Ticker symbol(s) to retrieve\n",
    "    date_start : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    date_end : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    return_format : str, optional\n",
    "        Format to return data in. Options: \n",
    "        - 'dataframe': Single DataFrame with MultiIndex (default)\n",
    "        - 'dict': Dictionary with tickers as keys and DataFrames as values\n",
    "        - 'separate': List of separate DataFrames for each ticker\n",
    "    verbose : bool, optional\n",
    "        Whether to print summary information (default: True)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Union[pd.DataFrame, dict, list]\n",
    "        Filtered features data in specified format\n",
    "    \"\"\"\n",
    "    # Convert single ticker to list for consistent processing\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "    \n",
    "    # Filter the data using MultiIndex slicing\n",
    "    try:\n",
    "        filtered_data = features_df.loc[(tickers, slice(date_start, date_end)), :]\n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"Error filtering data: {e}\")\n",
    "        return pd.DataFrame() if return_format == \"dataframe\" else {}\n",
    "    \n",
    "    # Handle empty results\n",
    "    if filtered_data.empty:\n",
    "        if verbose:\n",
    "            print(f\"No data found for tickers {tickers} in date range {date_start} to {date_end}\")\n",
    "        return filtered_data\n",
    "    \n",
    "    # Print summary if verbose\n",
    "    if verbose:\n",
    "        print(f\"Features data retrieved for {len(tickers)} ticker(s) from {date_start} to {date_end}\")\n",
    "        print(f\"Total rows: {len(filtered_data)}\")\n",
    "        print(f\"Date range in data: {filtered_data.index.get_level_values(1).min()} to \"\n",
    "              f\"{filtered_data.index.get_level_values(1).max()}\")\n",
    "        print(f\"Available features: {', '.join(filtered_data.columns.tolist())}\")\n",
    "        \n",
    "        # Print ticker-specific counts\n",
    "        ticker_counts = filtered_data.index.get_level_values(0).value_counts()\n",
    "        for ticker in tickers:\n",
    "            count = ticker_counts.get(ticker, 0)\n",
    "            if count > 0:\n",
    "                print(f\"  {ticker}: {count} rows\")\n",
    "            else:\n",
    "                print(f\"  {ticker}: No data in range\")\n",
    "    \n",
    "    # Return in requested format\n",
    "    if return_format == \"dict\":\n",
    "        result = {}\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result[ticker] = filtered_data.xs(ticker, level=0).loc[date_start:date_end]\n",
    "            except KeyError:\n",
    "                result[ticker] = pd.DataFrame()\n",
    "        return result\n",
    "    \n",
    "    elif return_format == \"separate\":\n",
    "        result = []\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result.append(filtered_data.xs(ticker, level=0).loc[date_start:date_end])\n",
    "            except KeyError:\n",
    "                result.append(pd.DataFrame())\n",
    "        return result\n",
    "    \n",
    "    elif return_format == \"dataframe\":\n",
    "        return filtered_data\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Invalid return_format: {return_format}. \"\n",
    "                         f\"Must be 'dataframe', 'dict', or 'separate'\")\n",
    "\n",
    "# Use the function to extract data\n",
    "tickers = ['VOO', 'VLO', 'JPST']\n",
    "date_start = '2025-08-13'\n",
    "date_end = '2025-09-04'\n",
    "\n",
    "print(\"Extracting features data...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Option 1: Get as DataFrame with MultiIndex\n",
    "features_data = get_ticker_features(features_df, tickers, date_start, date_end)\n",
    "print(\"\\nFeatures data (first 10 rows):\")\n",
    "print(features_data.head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Option 2: Get as dictionary for easier access\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Option 2: Get as dictionary\n",
    "features_dict = get_ticker_features(features_df, tickers, date_start, date_end, \n",
    "                                    return_format='dict')\n",
    "\n",
    "for ticker, data in features_dict.items():\n",
    "    print(f\"\\n{ticker} features shape: {data.shape}\")\n",
    "    if not data.empty:\n",
    "        print(f\"Date range: {data.index.min()} to {data.index.max()}\")\n",
    "        print(\"First few rows:\")\n",
    "        print(data.head())\n",
    "    else:\n",
    "        print(\"No data available\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Understanding the features:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Display feature descriptions\n",
    "feature_descriptions = {\n",
    "    'TR': 'True Range (daily volatility measure)',\n",
    "    'ATR': 'Average True Range (smoothed volatility)',\n",
    "    'ATRP': 'Average True Range Percentage (ATR as % of price)',\n",
    "    'RollingStalePct': 'Percentage of stale prices in rolling window',\n",
    "    'RollMedDollarVol': 'Rolling median dollar volume',\n",
    "    'RollingSameVolCount': 'Count of consecutive days with same volume'\n",
    "}\n",
    "\n",
    "print(\"Feature descriptions:\")\n",
    "for feature, description in feature_descriptions.items():\n",
    "    print(f\"  {feature}: {description}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Statistical summary of extracted features:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Statistical summary\n",
    "if not features_data.empty:\n",
    "    print(features_data.describe())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Alternative: Direct slicing without function\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Direct slicing (alternative method)\n",
    "direct_result = features_df.loc[(tickers, slice(date_start, date_end)), :]\n",
    "print(f\"Direct slicing result shape: {direct_result.shape}\")\n",
    "print(f\"\\nNumber of trading days per ticker:\")\n",
    "print(direct_result.index.get_level_values(0).value_counts())\n",
    "\n",
    "# If you want to analyze specific features\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Analyzing specific features:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if not features_data.empty:\n",
    "    # Example: Look at ATR (Average True Range) across tickers\n",
    "    print(\"\\nATR (Average True Range) statistics by ticker:\")\n",
    "    for ticker in tickers:\n",
    "        if ticker in features_data.index.get_level_values(0):\n",
    "            ticker_atr = features_data.xs(ticker, level=0)['ATR']\n",
    "            if not ticker_atr.empty:\n",
    "                print(f\"\\n{ticker}:\")\n",
    "                print(f\"  Mean ATR: {ticker_atr.mean():.4f}\")\n",
    "                print(f\"  Max ATR: {ticker_atr.max():.4f}\")\n",
    "                print(f\"  Min ATR: {ticker_atr.min():.4f}\")\n",
    "                print(f\"  Std Dev: {ticker_atr.std():.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Combining with OHLCV data:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# If you also have OHLCV data, you can combine them\n",
    "# (Assuming you have the get_ticker_OHLCV function from earlier)\n",
    "\n",
    "try:\n",
    "    # Get OHLCV data for same tickers and date range\n",
    "    ohlcv_data = get_ticker_OHLCV(df_ohlcv, tickers, date_start, date_end, verbose=False)\n",
    "    \n",
    "    # Combine features with OHLCV data\n",
    "    if not ohlcv_data.empty and not features_data.empty:\n",
    "        # Since both have the same MultiIndex, we can combine them\n",
    "        combined_data = pd.concat([ohlcv_data, features_data], axis=1)\n",
    "        print(f\"\\nCombined data shape: {combined_data.shape}\")\n",
    "        print(f\"Total columns: {len(combined_data.columns)}\")\n",
    "        print(f\"Columns: {combined_data.columns.tolist()}\")\n",
    "        \n",
    "        # Show combined data for a specific ticker\n",
    "        if 'VOO' in combined_data.index.get_level_values(0):\n",
    "            print(f\"\\nSample of combined data for VOO:\")\n",
    "            print(combined_data.xs('VOO', level=0).head())\n",
    "except NameError:\n",
    "    print(\"Note: OHLCV data not available in current context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4234fa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4f54be",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550212b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple one-liner to extract the data\n",
    "features_subset = features_df.loc[(['VOO', 'VLO', 'JPST'], slice('2025-08-13', '2025-09-04')), :]\n",
    "print(features_subset)\n",
    "\n",
    "# Save to CSV\n",
    "features_subset.to_csv('extracted_features.csv')\n",
    "\n",
    "# # Save to Excel\n",
    "# features_subset.to_excel('extracted_features.xlsx')\n",
    "\n",
    "# # Save to pickle (preserves MultiIndex)\n",
    "# features_subset.to_pickle('extracted_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5b286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Union, List\n",
    "\n",
    "def get_ticker_OHLCV(\n",
    "    df_ohlcv: pd.DataFrame,\n",
    "    tickers: Union[str, List[str]],\n",
    "    date_start: str,\n",
    "    date_end: str,\n",
    "    return_format: str = \"dataframe\",\n",
    "    verbose: bool = True\n",
    ") -> Union[pd.DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    Get OHLCV data for specified tickers within a date range.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_ohlcv : pd.DataFrame\n",
    "        DataFrame with MultiIndex of (ticker, date) and OHLCV columns\n",
    "    tickers : str or list of str\n",
    "        Ticker symbol(s) to retrieve\n",
    "    date_start : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    date_end : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    return_format : str, optional\n",
    "        Format to return data in. Options: \n",
    "        - 'dataframe': Single DataFrame with MultiIndex (default)\n",
    "        - 'dict': Dictionary with tickers as keys and DataFrames as values\n",
    "        - 'separate': List of separate DataFrames for each ticker\n",
    "    verbose : bool, optional\n",
    "        Whether to print summary information (default: True)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Union[pd.DataFrame, dict, list]\n",
    "        Filtered OHLCV data in specified format\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If input parameters are invalid\n",
    "    KeyError\n",
    "        If tickers not found in DataFrame\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> # Get data for single ticker\n",
    "    >>> vlo_data = get_ticker_OHLCV(df_ohlcv, 'VLO', '2025-08-13', '2025-09-04')\n",
    "    \n",
    "    >>> # Get data for multiple tickers\n",
    "    >>> multi_data = get_ticker_OHLCV(df_ohlcv, ['VLO', 'JPST'], '2025-08-13', '2025-09-04')\n",
    "    \n",
    "    >>> # Get data as dictionary\n",
    "    >>> data_dict = get_ticker_OHLCV(df_ohlcv, ['VLO', 'JPST'], '2025-08-13', \n",
    "    ...                              '2025-09-04', return_format='dict')\n",
    "    \"\"\"\n",
    "    \n",
    "    # Input validation\n",
    "    if not isinstance(df_ohlcv, pd.DataFrame):\n",
    "        raise TypeError(\"df_ohlcv must be a pandas DataFrame\")\n",
    "    \n",
    "    if not isinstance(df_ohlcv.index, pd.MultiIndex):\n",
    "        raise ValueError(\"DataFrame must have MultiIndex of (ticker, date)\")\n",
    "    \n",
    "    if len(df_ohlcv.index.levels) != 2:\n",
    "        raise ValueError(\"MultiIndex must have exactly 2 levels: (ticker, date)\")\n",
    "    \n",
    "    # Convert single ticker to list for consistent processing\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "    elif not isinstance(tickers, list):\n",
    "        raise TypeError(\"tickers must be a string or list of strings\")\n",
    "    \n",
    "    # Convert dates to Timestamps\n",
    "    try:\n",
    "        start_date = pd.Timestamp(date_start)\n",
    "        end_date = pd.Timestamp(date_end)\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"Invalid date format. Use 'YYYY-MM-DD': {e}\")\n",
    "    \n",
    "    if start_date > end_date:\n",
    "        raise ValueError(\"date_start must be before or equal to date_end\")\n",
    "    \n",
    "    # Check if tickers exist in the DataFrame\n",
    "    available_tickers = df_ohlcv.index.get_level_values(0).unique()\n",
    "    missing_tickers = [t for t in tickers if t not in available_tickers]\n",
    "    \n",
    "    if missing_tickers:\n",
    "        raise KeyError(f\"Ticker(s) not found in DataFrame: {missing_tickers}\")\n",
    "    \n",
    "    # Filter the data using MultiIndex slicing\n",
    "    try:\n",
    "        filtered_data = df_ohlcv.loc[(tickers, slice(date_start, date_end)), :]\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error filtering data: {e}\")\n",
    "    \n",
    "    # Handle empty results\n",
    "    if filtered_data.empty:\n",
    "        if verbose:\n",
    "            print(f\"No data found for tickers {tickers} in date range {date_start} to {date_end}\")\n",
    "        return filtered_data\n",
    "    \n",
    "    # Print summary if verbose\n",
    "    if verbose:\n",
    "        print(f\"Data retrieved for {len(tickers)} ticker(s) from {date_start} to {date_end}\")\n",
    "        print(f\"Total rows: {len(filtered_data)}\")\n",
    "        print(f\"Date range in data: {filtered_data.index.get_level_values(1).min()} to \"\n",
    "              f\"{filtered_data.index.get_level_values(1).max()}\")\n",
    "        \n",
    "        # Print ticker-specific counts\n",
    "        ticker_counts = filtered_data.index.get_level_values(0).value_counts()\n",
    "        for ticker in tickers:\n",
    "            count = ticker_counts.get(ticker, 0)\n",
    "            if count > 0:\n",
    "                print(f\"  {ticker}: {count} rows\")\n",
    "            else:\n",
    "                print(f\"  {ticker}: No data in range\")\n",
    "    \n",
    "    # Return in requested format\n",
    "    if return_format == \"dict\":\n",
    "        result = {}\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result[ticker] = filtered_data.xs(ticker, level=0).loc[date_start:date_end]\n",
    "            except KeyError:\n",
    "                result[ticker] = pd.DataFrame()\n",
    "        return result\n",
    "    \n",
    "    elif return_format == \"separate\":\n",
    "        result = []\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                result.append(filtered_data.xs(ticker, level=0).loc[date_start:date_end])\n",
    "            except KeyError:\n",
    "                result.append(pd.DataFrame())\n",
    "        return result\n",
    "    \n",
    "    elif return_format == \"dataframe\":\n",
    "        return filtered_data\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Invalid return_format: {return_format}. \"\n",
    "                         f\"Must be 'dataframe', 'dict', or 'separate'\")\n",
    "\n",
    "\n",
    "# Example usage with your data\n",
    "if __name__ == \"__main__\":\n",
    "    # Your example data\n",
    "    tickers = ['VLO', 'JPST']\n",
    "    date_start = '2025-08-13'\n",
    "    date_end = '2025-09-04'\n",
    "    \n",
    "    print(\"Example 1: Default usage (returns DataFrame)\")\n",
    "    print(\"=\" * 60)\n",
    "    result1 = get_ticker_OHLCV(df_ohlcv, tickers, date_start, date_end)\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    print(result1.head())\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Example 2: Return as dictionary\")\n",
    "    print(\"=\" * 60)\n",
    "    result2 = get_ticker_OHLCV(df_ohlcv, tickers, date_start, date_end, \n",
    "                               return_format='dict', verbose=True)\n",
    "    \n",
    "    for ticker, data in result2.items():\n",
    "        print(f\"\\n{ticker} data shape: {data.shape}\")\n",
    "        print(data.head() if not data.empty else \"Empty DataFrame\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Example 3: Single ticker\")\n",
    "    print(\"=\" * 60)\n",
    "    vlo_data = get_ticker_OHLCV(df_ohlcv, 'VLO', date_start, date_end, verbose=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Example 4: With error handling\")\n",
    "    print(\"=\" * 60)\n",
    "    try:\n",
    "        # This should raise an error if 'INVALID' is not in your DataFrame\n",
    "        invalid_data = get_ticker_OHLCV(df_ohlcv, ['VLO', 'INVALID'], date_start, date_end)\n",
    "    except KeyError as e:\n",
    "        print(f\"Error caught: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Example 5: Silent mode (verbose=False)\")\n",
    "    print(\"=\" * 60)\n",
    "    silent_result = get_ticker_OHLCV(df_ohlcv, tickers, date_start, date_end, verbose=False)\n",
    "    print(f\"Returned DataFrame shape: {silent_result.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f710fd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the date range filter\n",
    "date_filter = (df_ohlcv.index.get_level_values(1) >= pd.Timestamp(date_start)) & \\\n",
    "              (df_ohlcv.index.get_level_values(1) <= pd.Timestamp(date_end))\n",
    "\n",
    "# Filter by tickers AND date range\n",
    "filtered_df = df_ohlcv.loc[(tickers, slice(date_start, date_end)), :]\n",
    "\n",
    "# Alternative method using boolean indexing\n",
    "# filtered_df = df_ohlcv[df_ohlcv.index.get_level_values(0).isin(tickers) & date_filter]\n",
    "\n",
    "# Print the filtered data\n",
    "print(f\"Data for tickers {tickers} from {date_start} to {date_end}:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for ticker in tickers:\n",
    "    print(f\"\\nTicker: {ticker}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Extract data for current ticker\n",
    "    ticker_data = filtered_df.xs(ticker, level=0)\n",
    "    \n",
    "    if not ticker_data.empty:\n",
    "        print(ticker_data)\n",
    "        print(f\"\\nNumber of rows for {ticker}: {len(ticker_data)}\")\n",
    "    else:\n",
    "        print(f\"No data found for {ticker} in the specified date range\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "# If you want a summary\n",
    "print(\"=\" * 50)\n",
    "print(\"SUMMARY:\")\n",
    "print(f\"Total rows in filtered data: {len(filtered_df)}\")\n",
    "print(f\"Date range: {date_start} to {date_end}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551b239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_nested(results_container)\n",
    "print('='*20)\n",
    "print_nested(debug_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a082cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e7267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tickers = ['SPY', 'AAPL', 'IWM', 'QQQ', 'META', 'EEM', 'BABA']\n",
    "my_tickers = ['NTES', 'LII',]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4206b269",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in my_tickers:\n",
    "  if ticker in features_df.index.get_level_values('Ticker'):\n",
    "    ticker_features = features_df.loc[ticker]\n",
    "    ticker_features.to_csv(f'./export_csv/features_{ticker}.csv')\n",
    "    print(f\"‚úÖ {ticker} features exported to: ./export_csv/features_{ticker}.csv\")\n",
    "  else:\n",
    "    print(f\"‚ö†Ô∏è {ticker} not found in features_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719425da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in my_tickers:\n",
    "  if ticker in df_ohlcv.index.get_level_values('Ticker'):\n",
    "    ticker_features = df_ohlcv.loc[ticker]\n",
    "    ticker_features.to_csv(f'./export_csv/ohlcv_{ticker}.csv')\n",
    "    print(f\"‚úÖ {ticker} OHLCV exported to: ./export_csv/ohlcv_{ticker}.csv\")\n",
    "  else:\n",
    "    print(f\"‚ö†Ô∏è {ticker} not found in df_ohlcv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e0c43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have run the variables setup from the previous step\n",
    "snapshot_df = debug_container[0]['audit_liquidity']['universe_snapshot']\n",
    "\n",
    "if 'AAPL' in snapshot_df.index:\n",
    "    display(snapshot_df.loc[['AAPL']])\n",
    "else:\n",
    "    print(\"AAPL was not present in the data for this date.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32da9680",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "snapshot_df.to_csv('./export_csv/snapshot_df.csv')\n",
    "print(f\"‚úÖ Snapshot exported to: ./export_csv/snapshot_df.csv\")\n",
    "print(f\"   Shape: {snapshot_df.shape}\")\n",
    "print(f\"   Columns: {list(snapshot_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5e1e53",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Access the data inside the container list\n",
    "current_debug_data = debug_container[0]\n",
    "\n",
    "# 2. Check if the audit data exists (it is created only in 'Ranking' mode)\n",
    "if current_debug_data and 'audit_liquidity' in current_debug_data:\n",
    "    audit = current_debug_data['audit_liquidity']\n",
    "    snapshot_df = audit['universe_snapshot']\n",
    "    \n",
    "    print(f\"üìÖ Date: {audit['date'].date()}\")\n",
    "    print(f\"üí∞ Calculated Cutoff: ${audit['final_cutoff_usd']:,.0f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# 3. View the tickers right around the cutoff point\n",
    "# Find the index where 'Passed_Vol_Check' switches from True to False\n",
    "    try:\n",
    "        # Get the integer location (iloc) of the last True value\n",
    "        last_pass_iloc = np.where(snapshot_df['Passed_Vol_Check'])[0][-1]\n",
    "        \n",
    "        # Show 5 rows before and 5 rows after the cutoff\n",
    "        start = max(0, last_pass_iloc - 5)\n",
    "        end = min(len(snapshot_df), last_pass_iloc + 6)\n",
    "        \n",
    "        display(snapshot_df.iloc[start:end].style.format({\n",
    "            'RollMedDollarVol': '${:,.0f}',\n",
    "            'Calculated_Cutoff': '${:,.0f}',\n",
    "            'RollingStalePct': '{:.1%}'\n",
    "        }))\n",
    "    except IndexError:\n",
    "        print(\"Could not determine cutoff boundary (maybe all passed or all failed).\")\n",
    "        display(snapshot_df.head())\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No audit data found. Make sure you are in 'Ranking' mode and have clicked 'Update Chart'.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b6b19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(snapshot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d210b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "================================  \n",
    "================================  \n",
    "================================  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05cafb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
