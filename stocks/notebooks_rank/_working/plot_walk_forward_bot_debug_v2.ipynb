{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "529c108d",
   "metadata": {},
   "source": [
    "### ADD DEBUG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce038043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import plotly.graph_objects as go\n",
    "# from datetime import datetime, date\n",
    "# import numpy as np\n",
    "# import ipywidgets as widgets\n",
    "# from IPython.display import display, Markdown\n",
    "# import pprint\n",
    "# import io\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# from datetime import datetime, date\n",
    "# from IPython.display import display, Markdown\n",
    "# from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcb5626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ==============================================================================\n",
    "# # FINAL PROJECT FUNCTIONS (Consolidated - Run this cell once)\n",
    "# # ==============================================================================\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import plotly.graph_objects as go\n",
    "# import ipywidgets as widgets\n",
    "# import pprint\n",
    "# import re\n",
    "\n",
    "# from datetime import datetime, date\n",
    "# from IPython.display import display, Markdown\n",
    "# from tqdm.auto import tqdm # For progress bars\n",
    "# from pathlib import Path\n",
    "\n",
    "# # --- A. HELPER FUNCTIONS ---\n",
    "\n",
    "# def calculate_gain(price_series: pd.Series):\n",
    "#     if price_series.dropna().shape[0] < 2: return np.nan\n",
    "#     return (price_series.ffill().iloc[-1] / price_series.bfill().iloc[0]) - 1\n",
    "\n",
    "# def calculate_sharpe(return_series: pd.Series):\n",
    "#     if return_series.dropna().shape[0] < 2: return np.nan\n",
    "#     std_dev = return_series.std()\n",
    "#     if std_dev > 0 and std_dev != np.inf:\n",
    "#         return (return_series.mean() / std_dev) * np.sqrt(252)\n",
    "#     return np.nan\n",
    "\n",
    "# def parse_period_string(period_str: str) -> pd.DateOffset:\n",
    "#     \"\"\"\n",
    "#     Parses a string like '90D', '13W', '6M', or '1Y' into a pandas DateOffset.\n",
    "    \n",
    "#     Args:\n",
    "#         period_str (str): The period string to parse.\n",
    "    \n",
    "#     Returns:\n",
    "#         pd.DateOffset: The corresponding DateOffset object.\n",
    "        \n",
    "#     Raises:\n",
    "#         ValueError: If the string format is invalid.\n",
    "#     \"\"\"\n",
    "#     # <<< NEW: This is the new helper function for decoupling.\n",
    "#     match = re.match(r\"(\\d+)([DWMY])\", period_str.strip().upper())\n",
    "#     if not match:\n",
    "#         raise ValueError(f\"Invalid period format: '{period_str}'. Use format like '90D', '6M', '1Y'.\")\n",
    "    \n",
    "#     quantity, unit = int(match.group(1)), match.group(2)\n",
    "    \n",
    "#     if unit == 'D':\n",
    "#         return pd.DateOffset(days=quantity)\n",
    "#     elif unit == 'W':\n",
    "#         return pd.DateOffset(weeks=quantity)\n",
    "#     elif unit == 'M':\n",
    "#         return pd.DateOffset(months=quantity)\n",
    "#     elif unit == 'Y':\n",
    "#         return pd.DateOffset(years=quantity)\n",
    "#     return None # Should not be reached\n",
    "\n",
    "# # # --- B. THE CORE CALCULATION ENGINE ---\n",
    "\n",
    "# def run_walk_forward_step(df_close_full, df_high_full, df_low_full,\n",
    "#                           start_date, calc_period, fwd_period,\n",
    "#                           metric, rank_start, rank_end, benchmark_ticker,\n",
    "#                           debug=False):\n",
    "#     debug_data = {} if debug else None\n",
    "#     min_date_available = df_close_full.index.min()\n",
    "#     max_date_available = df_close_full.index.max()\n",
    "#     safe_start_date = max(start_date, min_date_available)\n",
    "#     safe_calc_end_date = min(start_date + calc_period, max_date_available)\n",
    "#     safe_viz_end_date = min(safe_calc_end_date + fwd_period, max_date_available)\n",
    "#     if safe_start_date >= safe_calc_end_date:\n",
    "#         return ({'error': \"Invalid date range.\"}, None)\n",
    "    \n",
    "#     calc_close_raw = df_close_full.loc[safe_start_date:safe_calc_end_date]\n",
    "#     calc_close = calc_close_raw.dropna(axis=1, how='all')\n",
    "#     if calc_close.shape[1] == 0 or len(calc_close) < 2:\n",
    "#         return ({'error': \"Not enough data in calc period.\"}, None)\n",
    "\n",
    "#     first_prices = calc_close.bfill().iloc[0]\n",
    "#     last_prices = calc_close.ffill().iloc[-1]\n",
    "#     daily_returns = calc_close.bfill().ffill().pct_change()\n",
    "#     mean_returns = daily_returns.mean()\n",
    "#     std_returns = daily_returns.std()\n",
    "    \n",
    "#     valid_tickers = calc_close.columns\n",
    "#     calc_high = df_high_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "#     calc_low = df_low_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "#     tr = np.maximum(calc_high - calc_low, abs(calc_high - df_close_full[valid_tickers].shift(1)), abs(calc_low - df_close_full[valid_tickers].shift(1)))\n",
    "#     atr = tr.ewm(alpha=1/14, adjust=False).mean()\n",
    "#     atrp = (atr / calc_close).mean()\n",
    "\n",
    "#     metric_values = {}\n",
    "#     metric_values['Price'] = (last_prices / first_prices).dropna()\n",
    "#     metric_values['Sharpe'] = (mean_returns / std_returns * np.sqrt(252)).fillna(0)\n",
    "#     metric_values['Sharpe (ATR)'] = (mean_returns / atrp).fillna(0)\n",
    "\n",
    "#     if debug:\n",
    "#         df_ranking = pd.DataFrame({\n",
    "#             'FirstPrice': first_prices, 'LastPrice': last_prices, 'MeanDailyReturn': mean_returns,\n",
    "#             'StdDevDailyReturn': std_returns, 'MeanATRP': atrp, 'Metric_Price': metric_values['Price'],\n",
    "#             'Metric_Sharpe': metric_values['Sharpe'], 'Metric_Sharpe (ATR)': metric_values['Sharpe (ATR)']\n",
    "#         })\n",
    "#         df_ranking.index.name = 'Ticker'\n",
    "#         debug_data['ranking_metrics'] = df_ranking.sort_values(f'Metric_{metric}', ascending=False)\n",
    "\n",
    "#     sorted_tickers = metric_values[metric].sort_values(ascending=False)\n",
    "#     tickers_to_display = sorted_tickers.index[rank_start-1:rank_end].tolist()\n",
    "#     if not tickers_to_display:\n",
    "#         return ({'error': \"No tickers found for the selected rank.\"}, None)\n",
    "\n",
    "#     normalized_plot_data = df_close_full[tickers_to_display].loc[safe_start_date:safe_viz_end_date]\n",
    "#     normalized_plot_data = normalized_plot_data.div(normalized_plot_data.bfill().iloc[0])\n",
    "#     actual_calc_end_ts = calc_close.index.max()\n",
    "#     portfolio_series = normalized_plot_data.mean(axis=1)\n",
    "#     portfolio_return_series = portfolio_series.pct_change()\n",
    "#     benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "#     benchmark_return_series = benchmark_price_series.loc[safe_start_date:safe_viz_end_date].bfill().ffill().pct_change() if benchmark_price_series is not None else pd.Series(dtype='float64')\n",
    "\n",
    "#     # --- THIS SECTION IS NOW CORRECT AND COMPLETE ---\n",
    "#     perf_data = {}\n",
    "#     perf_data['calc_p_gain'] = calculate_gain(portfolio_series.loc[:actual_calc_end_ts])\n",
    "#     perf_data['fwd_p_gain'] = calculate_gain(portfolio_series.loc[actual_calc_end_ts:])\n",
    "#     perf_data['full_p_gain'] = calculate_gain(portfolio_series)\n",
    "#     perf_data['calc_p_sharpe'] = calculate_sharpe(portfolio_return_series.loc[:actual_calc_end_ts])\n",
    "#     perf_data['fwd_p_sharpe'] = calculate_sharpe(portfolio_return_series.loc[actual_calc_end_ts:])\n",
    "#     perf_data['full_p_sharpe'] = calculate_sharpe(portfolio_return_series)\n",
    "#     perf_data['calc_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:actual_calc_end_ts]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['fwd_b_gain'] = calculate_gain(benchmark_price_series.loc[actual_calc_end_ts:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['full_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['calc_b_sharpe'] = calculate_sharpe(benchmark_return_series.loc[:actual_calc_end_ts])\n",
    "#     perf_data['fwd_b_sharpe'] = calculate_sharpe(benchmark_return_series.loc[actual_calc_end_ts:])\n",
    "#     perf_data['full_b_sharpe'] = calculate_sharpe(benchmark_return_series)\n",
    "#     # --- END OF CORRECTED SECTION ---\n",
    "\n",
    "#     calc_end_prices = calc_close.ffill().iloc[-1]\n",
    "#     fwd_close_slice = df_close_full.loc[actual_calc_end_ts:safe_viz_end_date]\n",
    "#     viz_end_prices = fwd_close_slice.ffill().iloc[-1] if not fwd_close_slice.empty and len(fwd_close_slice) >= 2 else calc_end_prices\n",
    "#     calc_gains = (calc_end_prices / calc_close.bfill().iloc[0]) - 1\n",
    "#     fwd_gains = (viz_end_prices / calc_end_prices) - 1\n",
    "#     results_df = pd.DataFrame({'Rank': range(rank_start, rank_start + len(tickers_to_display)), 'Metric': metric, 'MetricValue': sorted_tickers.loc[tickers_to_display].values, 'CalcPrice': calc_end_prices.loc[tickers_to_display], 'CalcGain': calc_gains.loc[tickers_to_display], 'FwdGain': fwd_gains.loc[tickers_to_display]}, index=pd.Index(tickers_to_display, name='Ticker'))\n",
    "#     if benchmark_price_series is not None and benchmark_ticker in calc_close.columns:\n",
    "#         benchmark_df_row = pd.DataFrame({'Rank': np.nan, 'Metric': metric, 'MetricValue': metric_values[metric].get(benchmark_ticker, np.nan), 'CalcPrice': calc_end_prices[benchmark_ticker], 'CalcGain': calc_gains[benchmark_ticker], 'FwdGain': fwd_gains[benchmark_ticker]}, index=pd.Index([f\"{benchmark_ticker} (BM)\"], name='Ticker'))\n",
    "#         results_df = pd.concat([results_df, benchmark_df_row])\n",
    "    \n",
    "#     if debug:\n",
    "#         df_trace = normalized_plot_data.copy()\n",
    "#         df_trace.columns = [f'Norm_Price_{c}' for c in df_trace.columns]\n",
    "#         df_trace['Norm_Price_Portfolio'] = portfolio_series\n",
    "#         if benchmark_price_series is not None and not benchmark_price_series.loc[safe_start_date:safe_viz_end_date].dropna().empty:\n",
    "#             norm_bm = benchmark_price_series.loc[safe_start_date:safe_viz_end_date] / benchmark_price_series.loc[safe_start_date:].bfill().iloc[0]\n",
    "#             df_trace[f'Norm_Price_Benchmark_{benchmark_ticker}'] = norm_bm\n",
    "#         for col in df_trace.columns:\n",
    "#             if 'Norm_Price' in col:\n",
    "#                 df_trace[col.replace('Norm_Price', 'Return')] = df_trace[col].pct_change()\n",
    "#         debug_data['portfolio_trace'] = df_trace\n",
    "\n",
    "#     final_results = {\n",
    "#         'tickers_to_display': tickers_to_display,\n",
    "#         'normalized_plot_data': normalized_plot_data,\n",
    "#         'portfolio_series': portfolio_series,\n",
    "#         'benchmark_price_series': benchmark_price_series,\n",
    "#         'performance_data': perf_data,\n",
    "#         'results_df': results_df,\n",
    "#         'actual_calc_end_ts': actual_calc_end_ts,\n",
    "#         'safe_start_date': pd.to_datetime(df_close_full.loc[safe_start_date:safe_viz_end_date].index.min()),\n",
    "#         'safe_viz_end_date': pd.to_datetime(df_close_full.loc[safe_start_date:safe_viz_end_date].index.max()),\n",
    "#         'error': None\n",
    "#     }\n",
    "    \n",
    "#     return (final_results, debug_data)\n",
    "\n",
    "# def plot_walk_forward_analyzer(df_ohlcv, \n",
    "#                                default_start_date=None, default_calc_period='3M', default_fwd_period='1M',\n",
    "#                                default_metric='Sharpe (ATR)', default_rank_start=1, default_rank_end=10,\n",
    "#                                default_benchmark_ticker='VOO',\n",
    "#                                quality_thresholds={'min_median_dollar_volume': 1_000_000, 'max_stale_pct': 0.05, 'max_same_vol_count': 10},\n",
    "#                                debug=False):\n",
    "#     print(\"Initializing Walk-Forward Analyzer (with Dynamic Universe Filtering)...\")\n",
    "#     if not isinstance(df_ohlcv.index, pd.MultiIndex): raise ValueError(\"Input DataFrame must have a (Ticker, Date) MultiIndex.\")\n",
    "#     df_ohlcv = df_ohlcv.sort_index()\n",
    "#     print(\"Pre-calculating data quality metrics...\")\n",
    "#     quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "#     print(\"Pre-processing data (unstacking)...\")\n",
    "#     df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "#     df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "#     df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    \n",
    "#     start_date_picker = widgets.DatePicker(description='Start Date:', value=pd.to_datetime(default_start_date), disabled=False)\n",
    "    \n",
    "#     # <<< CHANGED: Replaced Dropdowns with Text widgets for flexible period input.\n",
    "#     calc_period_input = widgets.Text(value=default_calc_period, description='Calc Period:', placeholder=\"e.g., '6M', '90D'\")\n",
    "#     fwd_period_input = widgets.Text(value=default_fwd_period, description='Fwd Period:', placeholder=\"e.g., '3M', '26W'\")\n",
    "\n",
    "#     metrics = ['Price', 'Sharpe', 'Sharpe (ATR)']\n",
    "#     metric_dropdown = widgets.Dropdown(options=metrics, value=default_metric, description='Metric:')\n",
    "    \n",
    "#     # <<< CHANGED: Replaced Dropdowns with IntText widgets for flexible rank input.\n",
    "#     rank_start_input = widgets.IntText(value=default_rank_start, description='Rank Start:')\n",
    "#     rank_end_input = widgets.IntText(value=default_rank_end, description='Rank End:')\n",
    "    \n",
    "#     benchmark_ticker_input = widgets.Text(value=default_benchmark_ticker, description='Benchmark:', placeholder='Enter Ticker')\n",
    "#     update_button = widgets.Button(description=\"Update Chart\", button_style='primary')\n",
    "#     ticker_list_output = widgets.Output()\n",
    "#     results_container, debug_data_container = [None], [None]\n",
    "\n",
    "#     fig = go.FigureWidget()\n",
    "#     max_traces = 50\n",
    "#     for i in range(max_traces): fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name=f'placeholder_{i}', visible=False, showlegend=False))\n",
    "#     fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Benchmark', visible=True, showlegend=True, line=dict(color='black', width=3, dash='dash')))\n",
    "#     fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Group Portfolio', visible=True, showlegend=True, line=dict(color='green', width=3)))\n",
    "\n",
    "#     def update_plot(button_click):\n",
    "#         ticker_list_output.clear_output()\n",
    "#         start_date = pd.to_datetime(start_date_picker.value)\n",
    "        \n",
    "#         # <<< CHANGED: Parse period strings and handle potential errors.\n",
    "#         try:\n",
    "#             calc_period = parse_period_string(calc_period_input.value)\n",
    "#             fwd_period = parse_period_string(fwd_period_input.value)\n",
    "#         except ValueError as e:\n",
    "#             with ticker_list_output:\n",
    "#                 print(f\"Error: {e}\")\n",
    "#             return\n",
    "\n",
    "#         metric = metric_dropdown.value\n",
    "#         # <<< CHANGED: Read values from IntText widgets.\n",
    "#         rank_start, rank_end = rank_start_input.value, rank_end_input.value\n",
    "#         benchmark_ticker = benchmark_ticker_input.value.strip().upper()\n",
    "#         if rank_start > rank_end:\n",
    "#             with ticker_list_output: print(\"Error: 'Rank Start' must be <= 'Rank End'.\"); return\n",
    "#         if rank_start < 1:\n",
    "#             with ticker_list_output: print(\"Error: 'Rank Start' must be >= 1.\"); return\n",
    "\n",
    "#         eligible_tickers = get_eligible_universe(quality_metrics_df, start_date, quality_thresholds)\n",
    "#         if not eligible_tickers:\n",
    "#             with ticker_list_output: print(f\"Error: No eligible tickers found on {start_date.date()} with the current quality filters.\"); return\n",
    "#         df_close_step = df_close_full[eligible_tickers]; df_high_step = df_high_full[eligible_tickers]; df_low_step = df_low_full[eligible_tickers]\n",
    "\n",
    "#         results, debug_output = run_walk_forward_step(\n",
    "#             df_close_step, df_high_step, df_low_step, start_date, calc_period, fwd_period, \n",
    "#             metric, rank_start, rank_end, benchmark_ticker, debug=debug\n",
    "#         )\n",
    "#         if results['error']:\n",
    "#             with ticker_list_output: print(f\"Error: {results['error']}\"); return\n",
    "\n",
    "#         with fig.batch_update():\n",
    "#             for i in range(max_traces):\n",
    "#                 trace = fig.data[i]\n",
    "#                 if i < len(results['tickers_to_display']):\n",
    "#                     ticker = results['tickers_to_display'][i]; plot_data_series = results['normalized_plot_data'][ticker]\n",
    "#                     trace.x, trace.y, trace.name, trace.visible, trace.showlegend = plot_data_series.index, plot_data_series.values, ticker, True, True\n",
    "#                 else: trace.visible, trace.showlegend = False, False\n",
    "#             benchmark_trace = fig.data[max_traces]\n",
    "#             if results['benchmark_price_series'] is not None and not results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']].dropna().empty:\n",
    "#                 normalized_benchmark = results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']] / results['benchmark_price_series'].loc[results['safe_start_date']:].bfill().iloc[0]\n",
    "#                 benchmark_trace.x, benchmark_trace.y, benchmark_trace.name, benchmark_trace.visible = normalized_benchmark.index, normalized_benchmark, f\"Benchmark ({benchmark_ticker})\", True\n",
    "#             else: benchmark_trace.visible = False\n",
    "#             portfolio_trace = fig.data[max_traces + 1]\n",
    "#             portfolio_trace.x, portfolio_trace.y, portfolio_trace.name, portfolio_trace.visible = results['portfolio_series'].index, results['portfolio_series'], 'Group Portfolio', True\n",
    "#             fig.layout.shapes = []; fig.add_shape(type=\"line\", x0=results['actual_calc_end_ts'], y0=0, x1=results['actual_calc_end_ts'], y1=1, xref='x', yref='paper', line=dict(color=\"grey\", width=2, dash=\"dash\"))\n",
    "            \n",
    "#         results_container[0] = results; debug_data_container[0] = debug_output\n",
    "        \n",
    "#         with ticker_list_output:\n",
    "#             print(f\"Analysis Period: {results['safe_start_date'].date()} to {results['safe_viz_end_date'].date()}.\")\n",
    "#             pprint.pprint(results['tickers_to_display'])\n",
    "#             p = results['performance_data']\n",
    "#             rows = []\n",
    "#             rows.append({'Metric': 'Group Portfolio Gain', 'Full': p['full_p_gain'], 'Calc': p['calc_p_gain'], 'Fwd': p['fwd_p_gain']})\n",
    "#             if not np.isnan(p['full_b_gain']):\n",
    "#                 rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Gain', 'Full': p['full_b_gain'], 'Calc': p['calc_b_gain'], 'Fwd': p['fwd_b_gain']})\n",
    "#                 rows.append({'Metric': 'Gain Delta (vs Bm)', 'Full': p['full_p_gain'] - p['full_b_gain'], 'Calc': p['calc_p_gain'] - p['calc_b_gain'], 'Fwd': p['fwd_p_gain'] - p['fwd_b_gain']})\n",
    "#             rows.append({'Metric': 'Group Portfolio Sharpe', 'Full': p['full_p_sharpe'], 'Calc': p['calc_p_sharpe'], 'Fwd': p['fwd_p_sharpe']})\n",
    "#             if not np.isnan(p['full_b_sharpe']):\n",
    "#                 rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Sharpe', 'Full': p['full_b_sharpe'], 'Calc': p['calc_b_sharpe'], 'Fwd': p['fwd_b_sharpe']})\n",
    "#                 rows.append({'Metric': 'Sharpe Delta (vs Bm)', 'Full': p['full_p_sharpe'] - p['full_b_sharpe'], 'Calc': p['calc_p_sharpe'] - p['calc_b_sharpe'], 'Fwd': p['fwd_p_sharpe'] - p['fwd_b_sharpe']})\n",
    "#             report_df = pd.DataFrame(rows).set_index('Metric')\n",
    "#             gain_rows = [row for row in report_df.index if 'Gain' in row or 'Delta' in row]\n",
    "#             sharpe_rows = [row for row in report_df.index if 'Sharpe' in row]\n",
    "#             styled_df = report_df.style.format('{:+.2%}', na_rep='N/A', subset=(gain_rows, report_df.columns)).format('{:+.2f}', na_rep='N/A', subset=(sharpe_rows, report_df.columns)).set_properties(**{'text-align': 'right', 'width': '100px'}).set_table_styles([{'selector': 'th.col_heading', 'props': [('text-align', 'right')]}, {'selector': 'th.row_heading', 'props': [('text-align', 'left')]}])\n",
    "#             print(\"\\n--- Strategy Performance Summary ---\")\n",
    "#             display(styled_df)\n",
    "            \n",
    "#     fig.update_layout(title_text='Walk-Forward Performance Analysis', xaxis_title='Date', yaxis_title='Normalized Price (Start = 1)', hovermode='x unified', legend_title_text='Tickers (Ranked)', height=600, margin=dict(t=50))\n",
    "#     fig.add_hline(y=1, line_width=1, line_dash=\"dash\", line_color=\"grey\")\n",
    "#     update_button.on_click(update_plot)\n",
    "#     # <<< CHANGED: Updated HBox to use the new input widgets.\n",
    "#     controls_row1 = widgets.HBox([start_date_picker, calc_period_input, fwd_period_input])\n",
    "#     controls_row2 = widgets.HBox([metric_dropdown, rank_start_input, rank_end_input, benchmark_ticker_input, update_button])\n",
    "#     ui_container = widgets.VBox([controls_row1, controls_row2, ticker_list_output], layout=widgets.Layout(margin='10px 0 20px 0'))\n",
    "#     display(ui_container, fig)\n",
    "#     update_plot(None)\n",
    "#     return (results_container, debug_data_container)\n",
    "\n",
    "# # --- C. DYNAMIC DATA QUALITY FILTER FUNCTIONS ---\n",
    "\n",
    "# def calculate_rolling_quality_metrics(df_ohlcv, window=252, min_periods=126, debug=False):\n",
    "#     print(f\"--- Calculating Rolling Quality Metrics (Window: {window} days) ---\")\n",
    "#     df = df_ohlcv.copy()\n",
    "#     if not df.index.is_monotonic_increasing:\n",
    "#         df.sort_index(inplace=True)\n",
    "#     df['IsStale'] = np.where((df['Volume'] == 0) | (df['Adj High'] == df['Adj Low']), 1, 0)\n",
    "#     df['DollarVolume'] = df['Adj Close'] * df['Volume']\n",
    "#     df['HasSameVolumeAsPrevDay'] = (df.groupby(level='Ticker')['Volume'].diff() == 0).astype(int)\n",
    "#     grouped = df.groupby(level='Ticker')\n",
    "#     stale_pct = grouped['IsStale'].rolling(window=window, min_periods=min_periods).mean()\n",
    "#     median_vol = grouped['DollarVolume'].rolling(window=window, min_periods=min_periods).median()\n",
    "#     same_vol_count = grouped['HasSameVolumeAsPrevDay'].rolling(window=window, min_periods=min_periods).sum()\n",
    "#     quality_df = pd.concat([stale_pct, median_vol, same_vol_count], axis=1)\n",
    "#     quality_df.columns = ['RollingStalePct', 'RollingMedianVolume', 'RollingSameVolCount']\n",
    "#     quality_df.index = quality_df.index.droplevel(0)\n",
    "#     print(\"✅ Rolling metrics calculation complete.\")\n",
    "#     return quality_df\n",
    "\n",
    "# def get_eligible_universe(quality_metrics_df, filter_date, thresholds):\n",
    "#     filter_date_ts = pd.to_datetime(filter_date)\n",
    "#     date_index = quality_metrics_df.index.get_level_values('Date').unique().sort_values()\n",
    "#     if filter_date_ts < date_index[0]:\n",
    "#         print(f\"Warning: Filter date {filter_date_ts.date()} is before the earliest data point. Returning empty universe.\")\n",
    "#         return []\n",
    "#     valid_prior_dates = date_index[date_index <= filter_date_ts]\n",
    "#     if valid_prior_dates.empty:\n",
    "#         print(f\"Warning: No available data found on or before {filter_date_ts.date()}. Returning empty universe.\")\n",
    "#         return []\n",
    "#     actual_date_to_use = valid_prior_dates[-1]\n",
    "#     if actual_date_to_use.date() != filter_date_ts.date():\n",
    "#         print(f\"ℹ️ Info: Filter date {filter_date_ts.date()} not found. Using previous available date {actual_date_to_use.date()}.\")\n",
    "#     metrics_on_date = quality_metrics_df.xs(actual_date_to_use, level='Date')\n",
    "#     mask = ((metrics_on_date['RollingMedianVolume'] >= thresholds['min_median_dollar_volume']) &\n",
    "#             (metrics_on_date['RollingStalePct'] <= thresholds['max_stale_pct']) &\n",
    "#             (metrics_on_date['RollingSameVolCount'] <= thresholds['max_same_vol_count']))\n",
    "#     eligible_tickers = metrics_on_date[mask].index.tolist()\n",
    "#     all_tickers = metrics_on_date.index.tolist()\n",
    "#     print(f\"Dynamic Filter ({filter_date_ts.date()}): Kept {len(eligible_tickers)} of {len(all_tickers)} tickers.\")\n",
    "#     return eligible_tickers    \n",
    "\n",
    "# # --- D. INTERACTIVE ANALYSIS TOOLS ---\n",
    "\n",
    "# def plot_walk_forward_analyzer(df_ohlcv, \n",
    "#                                default_start_date=None, default_calc_period='3M', default_fwd_period='1M',\n",
    "#                                default_metric='Sharpe (ATR)', default_rank_start=1, default_rank_end=10,\n",
    "#                                default_benchmark_ticker='VOO',\n",
    "#                                quality_thresholds={'min_median_dollar_volume': 1_000_000, 'max_stale_pct': 0.05, 'max_same_vol_count': 10},\n",
    "#                                debug=False):\n",
    "    \n",
    "#     print(\"Initializing Walk-Forward Analyzer (with Dynamic Universe Filtering)...\")\n",
    "#     if not isinstance(df_ohlcv.index, pd.MultiIndex): raise ValueError(\"Input DataFrame must have a (Ticker, Date) MultiIndex.\")\n",
    "#     df_ohlcv = df_ohlcv.sort_index()\n",
    "    \n",
    "#     print(\"Pre-calculating data quality metrics...\")\n",
    "#     quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "    \n",
    "#     print(\"Pre-processing data (unstacking)...\")\n",
    "#     df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "#     df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "#     df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    \n",
    "#     start_date_picker = widgets.DatePicker(description='Start Date:', value=pd.to_datetime(default_start_date), disabled=False)\n",
    "#     calc_period_options = {'3M': pd.DateOffset(months=3), '6M': pd.DateOffset(months=6), '1Y': pd.DateOffset(years=1)}\n",
    "#     fwd_period_options = {'1M': pd.DateOffset(months=1), '3M': pd.DateOffset(months=3)}\n",
    "#     calc_period_dropdown = widgets.Dropdown(options=calc_period_options.keys(), value=default_calc_period, description='Calc Period:')\n",
    "#     fwd_period_dropdown = widgets.Dropdown(options=fwd_period_options.keys(), value=default_fwd_period, description='Fwd Period:')\n",
    "#     metrics = ['Price', 'Sharpe', 'Sharpe (ATR)']\n",
    "#     metric_dropdown = widgets.Dropdown(options=metrics, value=default_metric, description='Metric:')\n",
    "#     rank_options = [1, 5, 10, 20, 30, 40, 50, 75, 100]\n",
    "#     rank_start_dropdown = widgets.Dropdown(options=rank_options, value=default_rank_start, description='Rank Start:')\n",
    "#     rank_end_dropdown = widgets.Dropdown(options=rank_options, value=default_rank_end, description='Rank End:')\n",
    "#     benchmark_ticker_input = widgets.Text(value=default_benchmark_ticker, description='Benchmark:', placeholder='Enter Ticker')\n",
    "#     update_button = widgets.Button(description=\"Update Chart\", button_style='primary')\n",
    "#     ticker_list_output = widgets.Output()\n",
    "    \n",
    "#     results_container = [None]\n",
    "#     debug_data_container = [None]\n",
    "\n",
    "#     fig = go.FigureWidget()\n",
    "#     max_traces = 50\n",
    "#     for i in range(max_traces): fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name=f'placeholder_{i}', visible=False, showlegend=False))\n",
    "#     fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Benchmark', visible=True, showlegend=True, line=dict(color='black', width=3, dash='dash')))\n",
    "#     fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Group Portfolio', visible=True, showlegend=True, line=dict(color='green', width=3)))\n",
    "\n",
    "#     def update_plot(button_click):\n",
    "#         ticker_list_output.clear_output()\n",
    "#         start_date = pd.to_datetime(start_date_picker.value)\n",
    "#         calc_period = calc_period_options[calc_period_dropdown.value]; fwd_period = fwd_period_options[fwd_period_dropdown.value]\n",
    "#         metric = metric_dropdown.value; rank_start, rank_end = rank_start_dropdown.value, rank_end_dropdown.value\n",
    "#         benchmark_ticker = benchmark_ticker_input.value.strip().upper()\n",
    "#         if rank_start > rank_end:\n",
    "#             with ticker_list_output: print(\"Error: 'Rank Start' must be <= 'Rank End'.\"); return\n",
    "\n",
    "#         eligible_tickers = get_eligible_universe(\n",
    "#             quality_metrics_df, filter_date=start_date, thresholds=quality_thresholds\n",
    "#         )\n",
    "#         if not eligible_tickers:\n",
    "#             with ticker_list_output: print(f\"Error: No eligible tickers found on {start_date.date()} with the current quality filters.\")\n",
    "#             return\n",
    "            \n",
    "#         df_close_step = df_close_full[eligible_tickers]\n",
    "#         df_high_step = df_high_full[eligible_tickers]\n",
    "#         df_low_step = df_low_full[eligible_tickers]\n",
    "\n",
    "#         results, debug_output = run_walk_forward_step(\n",
    "#             df_close_step, df_high_step, df_low_step,\n",
    "#             start_date, calc_period, fwd_period, \n",
    "#             metric, rank_start, rank_end, benchmark_ticker,\n",
    "#             debug=debug\n",
    "#         )\n",
    "        \n",
    "#         if results['error']:\n",
    "#             with ticker_list_output: print(f\"Error: {results['error']}\")\n",
    "#             return\n",
    "\n",
    "#         with fig.batch_update():\n",
    "#             for i in range(max_traces):\n",
    "#                 trace = fig.data[i]\n",
    "#                 if i < len(results['tickers_to_display']):\n",
    "#                     ticker = results['tickers_to_display'][i]\n",
    "#                     plot_data_series = results['normalized_plot_data'][ticker]\n",
    "#                     trace.x, trace.y, trace.name = plot_data_series.index, plot_data_series.values, ticker\n",
    "#                     trace.visible, trace.showlegend = True, True\n",
    "#                 else: trace.visible, trace.showlegend = False, False\n",
    "#             benchmark_trace = fig.data[max_traces]\n",
    "#             if results['benchmark_price_series'] is not None and not results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']].dropna().empty:\n",
    "#                 normalized_benchmark = results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']] / results['benchmark_price_series'].loc[results['safe_start_date']:].bfill().iloc[0]\n",
    "#                 benchmark_trace.x, benchmark_trace.y = normalized_benchmark.index, normalized_benchmark\n",
    "#                 benchmark_trace.name = f\"Benchmark ({benchmark_ticker})\"; benchmark_trace.visible = True\n",
    "#             else: benchmark_trace.visible = False\n",
    "#             portfolio_trace = fig.data[max_traces + 1]\n",
    "#             portfolio_trace.x, portfolio_trace.y = results['portfolio_series'].index, results['portfolio_series']\n",
    "#             portfolio_trace.name = 'Group Portfolio'; portfolio_trace.visible = True\n",
    "#             fig.layout.shapes = []; fig.add_shape(type=\"line\", x0=results['actual_calc_end_ts'], y0=0, x1=results['actual_calc_end_ts'], y1=1, xref='x', yref='paper', line=dict(color=\"grey\", width=2, dash=\"dash\"))\n",
    "            \n",
    "#         results_container[0] = results\n",
    "#         debug_data_container[0] = debug_output\n",
    "        \n",
    "#         with ticker_list_output:\n",
    "#             print(f\"Analysis Period: {results['safe_start_date'].date()} to {results['safe_viz_end_date'].date()}.\")\n",
    "#             pprint.pprint(results['tickers_to_display'])\n",
    "            \n",
    "#             # --- THIS IS THE CORRECTED, COMPLETE SECTION ---\n",
    "#             p = results['performance_data']\n",
    "#             rows = []\n",
    "#             rows.append({'Metric': 'Group Portfolio Gain', 'Full': p['full_p_gain'], 'Calc': p['calc_p_gain'], 'Fwd': p['fwd_p_gain']})\n",
    "#             if not np.isnan(p['full_b_gain']):\n",
    "#                 rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Gain', 'Full': p['full_b_gain'], 'Calc': p['calc_b_gain'], 'Fwd': p['fwd_b_gain']})\n",
    "#                 rows.append({'Metric': 'Gain Delta (vs Bm)', 'Full': p['full_p_gain'] - p['full_b_gain'], 'Calc': p['calc_p_gain'] - p['calc_b_gain'], 'Fwd': p['fwd_p_gain'] - p['fwd_b_gain']})\n",
    "#             rows.append({'Metric': 'Group Portfolio Sharpe', 'Full': p['full_p_sharpe'], 'Calc': p['calc_p_sharpe'], 'Fwd': p['fwd_p_sharpe']})\n",
    "#             if not np.isnan(p['full_b_sharpe']):\n",
    "#                 rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Sharpe', 'Full': p['full_b_sharpe'], 'Calc': p['calc_b_sharpe'], 'Fwd': p['fwd_b_sharpe']})\n",
    "#                 rows.append({'Metric': 'Sharpe Delta (vs Bm)', 'Full': p['full_p_sharpe'] - p['full_b_sharpe'], 'Calc': p['calc_p_sharpe'] - p['calc_b_sharpe'], 'Fwd': p['fwd_p_sharpe'] - p['fwd_b_sharpe']})\n",
    "#             report_df = pd.DataFrame(rows).set_index('Metric')\n",
    "#             gain_rows = [row for row in report_df.index if 'Gain' in row or 'Delta' in row]\n",
    "#             sharpe_rows = [row for row in report_df.index if 'Sharpe' in row]\n",
    "#             styled_df = report_df.style.format('{:+.2%}', na_rep='N/A', subset=(gain_rows, report_df.columns)).format('{:+.2f}', na_rep='N/A', subset=(sharpe_rows, report_df.columns)).set_properties(**{'text-align': 'right', 'width': '100px'}).set_table_styles([{'selector': 'th.col_heading', 'props': [('text-align', 'right')]}, {'selector': 'th.row_heading', 'props': [('text-align', 'left')]}])\n",
    "#             print(\"\\n--- Strategy Performance Summary ---\")\n",
    "#             display(styled_df)\n",
    "#             # --- END OF CORRECTED SECTION ---\n",
    "            \n",
    "#     fig.update_layout(title_text='Walk-Forward Performance Analysis', xaxis_title='Date', yaxis_title='Normalized Price (Start = 1)', hovermode='x unified', legend_title_text='Tickers (Ranked)', height=600, margin=dict(t=50))\n",
    "#     fig.add_hline(y=1, line_width=1, line_dash=\"dash\", line_color=\"grey\")\n",
    "#     update_button.on_click(update_plot)\n",
    "#     controls_row1 = widgets.HBox([start_date_picker, calc_period_dropdown, fwd_period_dropdown])\n",
    "#     controls_row2 = widgets.HBox([metric_dropdown, rank_start_dropdown, rank_end_dropdown, benchmark_ticker_input, update_button])\n",
    "#     ui_container = widgets.VBox([controls_row1, controls_row2, ticker_list_output], layout=widgets.Layout(margin='10px 0 20px 0'))\n",
    "#     display(ui_container, fig)\n",
    "#     update_plot(None)\n",
    "    \n",
    "#     return (results_container, debug_data_container)\n",
    "\n",
    "# # def run_full_backtest(df_ohlcv, strategy_params, quality_thresholds):\n",
    "# #     print(f\"--- Running Full Forensic Backtest ---\")\n",
    "# #     start_date, end_date = strategy_params['start_date'], strategy_params['end_date']\n",
    "# #     calc_period_str, fwd_period_str = strategy_params['calc_period'], strategy_params['fwd_period']\n",
    "# #     metric, rank_start, rank_end = strategy_params['metric'], strategy_params['rank_start'], strategy_params['rank_end']\n",
    "# #     benchmark_ticker = strategy_params['benchmark_ticker']\n",
    "    \n",
    "# #     quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "# #     df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "# #     df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "# #     df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "\n",
    "# #     period_options = {'3M': pd.DateOffset(months=3), '6M': pd.DateOffset(months=6), '1Y': pd.DateOffset(years=1)}\n",
    "# #     calc_period, fwd_period = period_options[calc_period_str], period_options[fwd_period_str]\n",
    "    \n",
    "# #     step_dates = pd.date_range(start=start_date, end=end_date, freq=f'{fwd_period.months}ME')\n",
    "# #     all_fwd_gains, period_by_period_debug = [], {}\n",
    "\n",
    "# #     print(f\"Simulating {len(step_dates)} periods...\")\n",
    "# #     for step_date in tqdm(step_dates, desc=\"Backtest Progress\"):\n",
    "# #         eligible_tickers = get_eligible_universe(quality_metrics_df, step_date, quality_thresholds)\n",
    "# #         if not eligible_tickers: continue\n",
    "        \n",
    "# #         df_close_step, df_high_step, df_low_step = df_close_full[eligible_tickers], df_high_full[eligible_tickers], df_low_full[eligible_tickers]\n",
    "        \n",
    "# #         results, debug_output = run_walk_forward_step(\n",
    "# #             df_close_step, df_high_step, df_low_step, step_date, calc_period, fwd_period,\n",
    "# #             metric, rank_start, rank_end, benchmark_ticker, debug=True\n",
    "# #         )\n",
    "        \n",
    "# #         if results['error'] is None:\n",
    "# #             fwd_series = results['portfolio_series'].loc[results['actual_calc_end_ts']:]\n",
    "# #             all_fwd_gains.append(fwd_series.pct_change().dropna())\n",
    "# #             period_by_period_debug[step_date.date().isoformat()] = debug_output\n",
    "            \n",
    "# #     if not all_fwd_gains:\n",
    "# #         print(\"Error: No valid periods were simulated.\"); return None\n",
    "\n",
    "# #     strategy_returns = pd.concat(all_fwd_gains)\n",
    "# #     strategy_equity_curve = (1 + strategy_returns).cumprod()\n",
    "# #     benchmark_returns = df_close_full[benchmark_ticker].pct_change().loc[strategy_equity_curve.index]\n",
    "# #     benchmark_equity_curve = (1 + benchmark_returns).cumprod()\n",
    "    \n",
    "# #     cumulative_equity_df = pd.DataFrame({'Strategy_Equity': strategy_equity_curve, 'Benchmark_Equity': benchmark_equity_curve})\n",
    "    \n",
    "# #     fig = go.Figure()\n",
    "# #     fig.add_trace(go.Scatter(x=cumulative_equity_df.index, y=cumulative_equity_df['Strategy_Equity'], name='Strategy', line=dict(color='green')))\n",
    "# #     fig.add_trace(go.Scatter(x=cumulative_equity_df.index, y=cumulative_equity_df['Benchmark_Equity'], name=f'Benchmark ({benchmark_ticker})', line=dict(color='black', dash='dash')))\n",
    "# #     fig.update_layout(title=f\"Cumulative Performance: '{metric}' Strategy (Top {rank_start}-{rank_end})\", xaxis_title=\"Date\", yaxis_title=\"Cumulative Growth\")\n",
    "# #     fig.show()\n",
    "\n",
    "# #     final_backtest_results = {'cumulative_performance': cumulative_equity_df, 'period_by_period_debug': period_by_period_debug}\n",
    "# #     print(\"\\n✅ Full backtest complete.\")\n",
    "# #     return final_backtest_results\n",
    "\n",
    "# def run_full_backtest(df_ohlcv, strategy_params, quality_thresholds):\n",
    "#     print(f\"--- Running Full Forensic Backtest for Strategy: {strategy_params['metric']} (Top {strategy_params['rank_start']}-{strategy_params['rank_end']}) ---\")\n",
    "#     start_date, end_date = strategy_params['start_date'], strategy_params['end_date']\n",
    "#     calc_period_str, fwd_period_str = strategy_params['calc_period'], strategy_params['fwd_period']\n",
    "#     metric, rank_start, rank_end = strategy_params['metric'], strategy_params['rank_start'], strategy_params['rank_end']\n",
    "#     benchmark_ticker = strategy_params['benchmark_ticker']\n",
    "#     quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "#     df_close_full = df_ohlcv['Adj Close'].unstack(level=0); df_high_full = df_ohlcv['Adj High'].unstack(level=0); df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    \n",
    "#     # <<< CHANGED: Now using the parse_period_string helper.\n",
    "#     try:\n",
    "#         calc_period = parse_period_string(calc_period_str)\n",
    "#         fwd_period = parse_period_string(fwd_period_str)\n",
    "#     except ValueError as e:\n",
    "#         print(f\"Error in strategy_params: {e}\"); return None\n",
    "\n",
    "#     # <<< CHANGED: More robust frequency determination for date range generation.\n",
    "#     match = re.match(r\"(\\d+)([DWMY])\", fwd_period_str.strip().upper())\n",
    "#     quantity, unit = int(match.group(1)), match.group(2)\n",
    "#     freq_map = {'D': 'D', 'W': 'W', 'M': 'ME', 'Y': 'YE'} # ME for Month-End\n",
    "#     freq_str = f\"{quantity}{freq_map[unit]}\"\n",
    "#     step_dates = pd.date_range(start=start_date, end=end_date, freq=freq_str)\n",
    "\n",
    "#     all_fwd_gains, period_by_period_debug = [], {}\n",
    "\n",
    "#     print(f\"Simulating {len(step_dates)} periods from {step_dates[0].date()} to {step_dates[-1].date()}...\")\n",
    "#     for step_date in tqdm(step_dates, desc=\"Backtest Progress\"):\n",
    "#         eligible_tickers = get_eligible_universe(quality_metrics_df, step_date, quality_thresholds)\n",
    "#         if not eligible_tickers: continue\n",
    "#         df_close_step = df_close_full[eligible_tickers]; df_high_step = df_high_full[eligible_tickers]; df_low_step = df_low_full[eligible_tickers]\n",
    "#         results, debug_output = run_walk_forward_step(\n",
    "#             df_close_step, df_high_step, df_low_step, step_date, calc_period, fwd_period,\n",
    "#             metric, rank_start, rank_end, benchmark_ticker, debug=True\n",
    "#         )\n",
    "#         if results['error'] is None:\n",
    "#             fwd_series = results['portfolio_series'].loc[results['actual_calc_end_ts']:]\n",
    "#             all_fwd_gains.append(fwd_series.pct_change().dropna())\n",
    "#             period_by_period_debug[step_date.date().isoformat()] = debug_output\n",
    "            \n",
    "#     if not all_fwd_gains:\n",
    "#         print(\"Error: No valid periods were simulated.\"); return None\n",
    "\n",
    "#     strategy_returns = pd.concat(all_fwd_gains); strategy_equity_curve = (1 + strategy_returns).cumprod()\n",
    "#     benchmark_returns = df_close_full[benchmark_ticker].pct_change().loc[strategy_equity_curve.index]; benchmark_equity_curve = (1 + benchmark_returns).cumprod()\n",
    "#     cumulative_equity_df = pd.DataFrame({'Strategy_Equity': strategy_equity_curve, 'Benchmark_Equity': benchmark_equity_curve})\n",
    "    \n",
    "#     fig = go.Figure()\n",
    "#     fig.add_trace(go.Scatter(x=cumulative_equity_df.index, y=cumulative_equity_df['Strategy_Equity'], name='Strategy', line=dict(color='green')))\n",
    "#     fig.add_trace(go.Scatter(x=cumulative_equity_df.index, y=cumulative_equity_df['Benchmark_Equity'], name=f'Benchmark ({benchmark_ticker})', line=dict(color='black', dash='dash')))\n",
    "#     fig.update_layout(title=f\"Cumulative Performance: '{metric}' Strategy (Top {rank_start}-{rank_end})\", xaxis_title=\"Date\", yaxis_title=\"Cumulative Growth\")\n",
    "#     fig.show()\n",
    "\n",
    "#     final_backtest_results = {'cumulative_performance': cumulative_equity_df, 'period_by_period_debug': period_by_period_debug}\n",
    "#     print(\"\\n✅ Full backtest complete. Results object is ready for forensic analysis.\")\n",
    "#     return final_backtest_results\n",
    "\n",
    "# # --- E. VERIFICATION TOOLS ---\n",
    "\n",
    "# # def verify_group_tickers_walk_forward_calculation(df_ohlcv, tickers_to_verify, benchmark_ticker,\n",
    "# #                                                   start_date, calc_period, fwd_period, export_csv=False):\n",
    "# #     # This function is unchanged\n",
    "# #     display(Markdown(f\"## Verification Report for Portfolio vs. Benchmark\"))\n",
    "# #     display(Markdown(f\"**Portfolio Tickers:** `{tickers_to_verify}`\"))\n",
    "# #     display(Markdown(f\"**Benchmark Ticker:** `{benchmark_ticker}`\"))\n",
    "# #     period_options = { '1M': pd.DateOffset(months=1), '3M': pd.DateOffset(months=3), '6M': pd.DateOffset(months=6), '1Y': pd.DateOffset(years=1), '0D': pd.DateOffset(days=0), '1W': pd.DateOffset(weeks=1), '2W': pd.DateOffset(weeks=2) }\n",
    "# #     df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "# #     start_date_ts = pd.to_datetime(start_date)\n",
    "# #     calc_offset = period_options[calc_period]; fwd_offset = period_options[fwd_period]\n",
    "# #     calc_end_date_ts_theoretical = start_date_ts + calc_offset\n",
    "# #     fwd_end_date_ts_theoretical = calc_end_date_ts_theoretical + fwd_offset\n",
    "# #     actual_calc_end_ts = df_close_full.loc[start_date_ts:calc_end_date_ts_theoretical].index.max()\n",
    "# #     display(Markdown(f\"**Analysis Start Date:** `{start_date_ts.date()}`\"))\n",
    "# #     display(Markdown(f\"**Calculation Period End Date:** `{actual_calc_end_ts.date()}`\"))\n",
    "# #     display(Markdown(f\"**Forward Period End Date:** `{fwd_end_date_ts_theoretical.date()}`\"))\n",
    "# #     portfolio_prices_raw_slice = df_close_full[tickers_to_verify].loc[start_date_ts:fwd_end_date_ts_theoretical]\n",
    "# #     normalized_portfolio_prices = portfolio_prices_raw_slice.div(portfolio_prices_raw_slice.bfill().iloc[0])\n",
    "# #     portfolio_value_series = normalized_portfolio_prices.mean(axis=1)\n",
    "# #     try: benchmark_price_series = df_close_full[benchmark_ticker]\n",
    "# #     except KeyError as e: print(f\"---! ERROR: Ticker {e} not found !---\"); return\n",
    "\n",
    "# #     def print_verification_steps(title, price_series):\n",
    "# #         display(Markdown(f\"#### Verification for: `{title}`\"))\n",
    "# #         if price_series.dropna().shape[0] < 2: print(\"  - Not enough data points.\"); return {'gain': np.nan, 'sharpe': np.nan}\n",
    "# #         start_price = price_series.bfill().iloc[0]; end_price = price_series.ffill().iloc[-1]\n",
    "# #         gain = (end_price / start_price) - 1\n",
    "# #         print(f\"  - Start Value (on {price_series.first_valid_index().date()}): {start_price:,.4f}\\n  - End Value   (on {price_series.last_valid_index().date()}): {end_price:,.4f}\\n  - Gain = ({end_price:,.4f} / {start_price:,.4f}) - 1 = {gain:.2%}\")\n",
    "# #         returns = price_series.pct_change()\n",
    "# #         mean_return = returns.mean(); std_return = returns.std()\n",
    "# #         sharpe = (mean_return / std_return * np.sqrt(252)) if std_return > 0 and std_return != np.inf else np.nan\n",
    "# #         print(f\"\\n  - Mean Daily Return: {mean_return:.6f}\\n  - Std Dev of Daily Return: {std_return:.6f}\\n  - Sharpe = ({mean_return:.6f} / {std_return:.6f}) * sqrt(252) = {sharpe:.2f}\")\n",
    "# #         return {'gain': gain, 'sharpe': sharpe}\n",
    "\n",
    "# #     display(Markdown(\"### A. Calculation Period Analysis ('In-Sample')\"))\n",
    "# #     perf_calc_p = print_verification_steps(\"Group Portfolio\", portfolio_value_series.loc[start_date_ts:actual_calc_end_ts])\n",
    "# #     perf_calc_b = print_verification_steps(f\"Benchmark ({benchmark_ticker})\", benchmark_price_series.loc[start_date_ts:actual_calc_end_ts])\n",
    "# #     display(Markdown(\"\\n### B. Forward Period Analysis ('Moment of Truth')\"))\n",
    "# #     perf_fwd_p = print_verification_steps(\"Group Portfolio\", portfolio_value_series.loc[actual_calc_end_ts:fwd_end_date_ts_theoretical])\n",
    "# #     perf_fwd_b = print_verification_steps(f\"Benchmark ({benchmark_ticker})\", benchmark_price_series.loc[actual_calc_end_ts:fwd_end_date_ts_theoretical])\n",
    "# #     display(Markdown(\"\\n### C. Full Period Analysis (Total)\"))\n",
    "# #     perf_full_p = print_verification_steps(\"Group Portfolio\", portfolio_value_series)\n",
    "# #     perf_full_b = print_verification_steps(f\"Benchmark ({benchmark_ticker})\", benchmark_price_series.loc[start_date_ts:fwd_end_date_ts_theoretical])\n",
    "# #     display(Markdown(\"\\n### D. Final Summary Table (matches analyzer output)\"))\n",
    "# #     rows = []\n",
    "# #     rows.append({'Metric': 'Group Portfolio Gain', 'Full': perf_full_p['gain'], 'Calc': perf_calc_p['gain'], 'Fwd': perf_fwd_p['gain']})\n",
    "# #     rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Gain', 'Full': perf_full_b['gain'], 'Calc': perf_calc_b['gain'], 'Fwd': perf_fwd_b['gain']})\n",
    "# #     rows.append({'Metric': 'Gain Delta (vs Bm)', 'Full': perf_full_p['gain'] - perf_full_b['gain'], 'Calc': perf_calc_p['gain'] - perf_calc_b['gain'], 'Fwd': perf_fwd_p['gain'] - perf_fwd_b['gain']})\n",
    "# #     rows.append({'Metric': 'Group Portfolio Sharpe', 'Full': perf_full_p['sharpe'], 'Calc': perf_calc_p['sharpe'], 'Fwd': perf_fwd_p['sharpe']})\n",
    "# #     rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Sharpe', 'Full': perf_full_b['sharpe'], 'Calc': perf_calc_b['sharpe'], 'Fwd': perf_fwd_b['sharpe']})\n",
    "# #     rows.append({'Metric': 'Sharpe Delta (vs Bm)', 'Full': perf_full_p['sharpe'] - perf_full_b['sharpe'], 'Calc': perf_calc_p['sharpe'] - perf_calc_b['sharpe'], 'Fwd': perf_fwd_p['sharpe'] - perf_fwd_b['sharpe']})\n",
    "# #     report_df = pd.DataFrame(rows).set_index('Metric')\n",
    "# #     gain_rows = [row for row in report_df.index if 'Gain' in row or 'Delta' in row]\n",
    "# #     sharpe_rows = [row for row in report_df.index if 'Sharpe' in row]\n",
    "# #     styled_df = report_df.style.format('{:+.2%}', na_rep='N/A', subset=(gain_rows, report_df.columns)).format('{:+.2f}', na_rep='N/A', subset=(sharpe_rows, report_df.columns)).set_properties(**{'text-align': 'right', 'width': '100px'}).set_table_styles([{'selector': 'th.col_heading', 'props': [('text-align', 'right')]}, {'selector': 'th.row_heading', 'props': [('text-align', 'left')]}])\n",
    "# #     display(styled_df)\n",
    "# #     if export_csv:\n",
    "# #         export_df = pd.DataFrame({'Portfolio_Value_Normalized': portfolio_value_series, 'Portfolio_Return': portfolio_value_series.pct_change(), f'Benchmark_Price_{benchmark_ticker}': benchmark_price_series})\n",
    "# #         filename = f\"verification_group_tickers_{start_date_ts.strftime('%Y%m%d')}.csv\"\n",
    "# #         export_df.to_csv(filename, float_format='%.6f')\n",
    "# #         print(f\"\\n✅ Detailed group verification data exported to '{filename}'\")\n",
    "\n",
    "# # def verify_ticker_ranking_metrics(df_ohlcv, \n",
    "# #                                   ticker, \n",
    "# #                                   start_date, \n",
    "# #                                   calc_period, \n",
    "# #                                   fwd_period, \n",
    "# #                                   export_csv=False):\n",
    "# #     display(Markdown(f\"## Verification Report for Ticker Ranking: `{ticker}`\"))\n",
    "# #     period_options = { '1M': pd.DateOffset(months=1), '3M': pd.DateOffset(months=3), '6M': pd.DateOffset(months=6), '1Y': pd.DateOffset(years=1), '0D': pd.DateOffset(days=0), '1W': pd.DateOffset(weeks=1), '2W': pd.DateOffset(weeks=2) }\n",
    "# #     try: df_ticker = df_ohlcv.loc[ticker].sort_index()\n",
    "# #     except KeyError: print(f\"---! ERROR: Ticker '{ticker}' not found !---\"); return\n",
    "# #     start_date_ts = pd.to_datetime(start_date)\n",
    "# #     calc_offset = period_options[calc_period]; fwd_offset = period_options[fwd_period]\n",
    "# #     calc_end_date_ts = start_date_ts + calc_offset; fwd_end_date_ts = calc_end_date_ts + fwd_offset\n",
    "# #     display(Markdown(f\"**Analysis Start Date:** `{start_date_ts.date()}`\"))\n",
    "# #     display(Markdown(f\"**Requested Calculation Period:** `{start_date_ts.date()}` to `{calc_end_date_ts.date()}`\"))\n",
    "# #     display(Markdown(f\"**Requested Forward Period:**   `{calc_end_date_ts.date()}` to `{fwd_end_date_ts.date()}`\"))\n",
    "# #     display(Markdown(\"### A. Calculation Period Analysis (for Ranking Metrics)\"))\n",
    "# #     calc_df = df_ticker.loc[start_date_ts:calc_end_date_ts].copy()\n",
    "# #     if calc_df['Adj Close'].notna().sum() < 2: print(\"\\n---! ERROR: Not enough data points !---\"); return\n",
    "# #     actual_calc_end_date = calc_df.index.max().date()\n",
    "# #     display(Markdown(f\"**Actual Dates Used:** `{calc_df.index.min().date()}` to `{actual_calc_end_date}`\"))\n",
    "# #     calc_gain = calculate_gain(calc_df['Adj Close'])\n",
    "# #     calc_start_price = calc_df['Adj Close'].bfill().iloc[0]\n",
    "# #     calc_end_price = calc_df['Adj Close'].ffill().iloc[-1]\n",
    "# #     display(Markdown(\"#### `CalcGain` Verification:\"))\n",
    "# #     print(f\"  - Calc Start Price: ${calc_start_price:.2f}\\n  - Calc End Price:   ${calc_end_price:.2f}  <-- 'CalcPrice'\\n  - CalcGain = {calc_gain:.2%}\")\n",
    "# #     display(Markdown(\"#### `MetricValue` Verification:\"))\n",
    "# #     price_metric = (calc_end_price / calc_start_price)\n",
    "# #     print(f\"\\n1. Price Metric:\\n   - Formula: Last Price / First Price = {price_metric:.4f}\")\n",
    "# #     daily_returns = calc_df['Adj Close'].bfill().ffill().pct_change()\n",
    "# #     sharpe_ratio = calculate_sharpe(daily_returns)\n",
    "# #     print(f\"\\n2. Sharpe Metric:\\n   - Mean Daily Return: {daily_returns.mean():.6f}\\n   - Std Dev Daily Return: {daily_returns.std():.6f}\\n   - Annualized Sharpe = {sharpe_ratio:.4f}\")\n",
    "# #     print(f\"\\n3. Sharpe (ATR) Metric:\")\n",
    "# #     tr = np.maximum(calc_df['Adj High'] - calc_df['Adj Low'], abs(calc_df['Adj High'] - calc_df['Adj Close'].shift(1)), abs(calc_df['Adj Low'] - calc_df['Adj Close'].shift(1)))\n",
    "# #     atr = tr.ewm(alpha=1/14, adjust=False).mean()\n",
    "# #     atrp_series = atr / calc_df['Adj Close']\n",
    "# #     atrp_mean = atrp_series.mean()\n",
    "# #     sharpe_atr = (daily_returns.mean() / atrp_mean) if atrp_mean > 0 else 0\n",
    "# #     print(f\"   - Mean Daily Return: {daily_returns.mean():.6f} (same as above)\\n   - Average ATR Percent (ATRP): {atrp_mean:.6f}\\n   - Sharpe (ATR) = {sharpe_atr:.4f}\")\n",
    "# #     display(Markdown(\"\\n### B. Forward Period Analysis (`FwdGain`)\"))\n",
    "# #     fwd_df = df_ticker.loc[actual_calc_end_date:fwd_end_date_ts].copy()\n",
    "# #     fwd_gain = calculate_gain(fwd_df['Adj Close'])\n",
    "# #     fwd_end_price = fwd_df['Adj Close'].ffill().iloc[-1] if fwd_gain is not np.nan else calc_end_price\n",
    "# #     print(f\"  - Fwd Start Price (Calc End Price): ${calc_end_price:.2f}\\n  - Fwd End Price: ${fwd_end_price:.2f}\\n  - FwdGain = {fwd_gain:.2%}\")\n",
    "# #     display(Markdown(\"\\n### C. Final Summary Table\"))\n",
    "# #     summary_data = {'Metric': ['Price', 'Sharpe', 'Sharpe (ATR)'], 'Calculated Value': [f\"{price_metric:.4f}\", f\"{sharpe_ratio:.4f}\", f\"{sharpe_atr:.4f}\"], 'Corresponds To': ['`MetricValue`', '`MetricValue`', '`MetricValue`'], '---': ['---','---','---'], 'Gain Metric': ['Calc Period Gain', 'Forward Period Gain'], 'Gain Value': [f\"{calc_gain:.2%}\", f\"{fwd_gain:.2%}\"], 'Gain Corresponds To': ['`CalcGain`', '`FwdGain`']}\n",
    "# #     summary_df = pd.DataFrame(summary_data)\n",
    "# #     display(summary_df.style.hide(axis=\"index\"))\n",
    "    \n",
    "# #     if export_csv:\n",
    "# #         calc_df['Period'] = 'Calculation'; calc_df['Daily_Return'] = daily_returns; calc_df['True_Range'] = tr; calc_df['ATR_14'] = atr; calc_df['ATRP'] = atrp_series\n",
    "# #         fwd_df['Period'] = 'Forward'\n",
    "# #         combined_df = pd.concat([calc_df, fwd_df.iloc[1:]])\n",
    "# #         filename = f\"verification_ticker_{ticker}_{start_date_ts.strftime('%Y%m%d')}.csv\"\n",
    "# #         combined_df.to_csv(filename, float_format='%.6f')\n",
    "# #         print(f\"\\n✅ Detailed ticker data exported to '{filename}'\")\n",
    "\n",
    "\n",
    "# # --- E. VERIFICATION TOOLS (User Requested) ---\n",
    "\n",
    "# def verify_group_tickers_walk_forward_calculation(df_ohlcv, tickers_to_verify, benchmark_ticker,\n",
    "#                                                   start_date, calc_period, fwd_period, export_csv=False):\n",
    "#     display(Markdown(f\"## Verification Report for Portfolio vs. Benchmark\"))\n",
    "#     display(Markdown(f\"**Portfolio Tickers:** `{tickers_to_verify}`\\n**Benchmark Ticker:** `{benchmark_ticker}`\"))\n",
    "    \n",
    "#     # <<< CHANGED: Removed hardcoded period_options dict, now using the parser.\n",
    "#     try:\n",
    "#         calc_offset = parse_period_string(calc_period)\n",
    "#         fwd_offset = parse_period_string(fwd_period)\n",
    "#     except ValueError as e:\n",
    "#         print(f\"Error: {e}\"); return\n",
    "        \n",
    "#     df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "#     start_date_ts = pd.to_datetime(start_date)\n",
    "#     calc_end_date_ts_theoretical = start_date_ts + calc_offset\n",
    "#     fwd_end_date_ts_theoretical = calc_end_date_ts_theoretical + fwd_offset\n",
    "#     actual_calc_end_ts = df_close_full.loc[start_date_ts:calc_end_date_ts_theoretical].index.max()\n",
    "#     display(Markdown(f\"**Analysis Start:** `{start_date_ts.date()}`\\n**Calc End:** `{actual_calc_end_ts.date()}`\\n**Fwd End:** `{fwd_end_date_ts_theoretical.date()}`\"))\n",
    "    \n",
    "#     portfolio_prices_raw_slice = df_close_full[tickers_to_verify].loc[start_date_ts:fwd_end_date_ts_theoretical]\n",
    "#     portfolio_value_series = portfolio_prices_raw_slice.div(portfolio_prices_raw_slice.bfill().iloc[0]).mean(axis=1)\n",
    "#     benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "\n",
    "#     def print_verification_steps(title, price_series):\n",
    "#         display(Markdown(f\"#### Verification for: `{title}`\"))\n",
    "#         if price_series.dropna().shape[0] < 2: print(\"  - Not enough data points.\"); return {'gain': np.nan, 'sharpe': np.nan}\n",
    "#         start_price, end_price = price_series.bfill().iloc[0], price_series.ffill().iloc[-1]\n",
    "#         gain = (end_price / start_price) - 1\n",
    "#         print(f\"Start Value ({price_series.first_valid_index().date()}): {start_price:,.4f}\\nEnd Value   ({price_series.last_valid_index().date()}): {end_price:,.4f}\\nGain = {gain:.2%}\")\n",
    "#         returns = price_series.pct_change()\n",
    "#         sharpe = calculate_sharpe(returns)\n",
    "#         print(f\"Mean Daily Return: {returns.mean():.6f}\\nStd Dev: {returns.std():.6f}\\nSharpe = {sharpe:.2f}\")\n",
    "#         return {'gain': gain, 'sharpe': sharpe}\n",
    "\n",
    "#     display(Markdown(\"### A. Calculation Period\"))\n",
    "#     perf_calc_p = print_verification_steps(\"Group Portfolio\", portfolio_value_series.loc[start_date_ts:actual_calc_end_ts])\n",
    "#     perf_calc_b = print_verification_steps(f\"Benchmark\", benchmark_price_series.loc[start_date_ts:actual_calc_end_ts])\n",
    "#     display(Markdown(\"### B. Forward Period\"))\n",
    "#     perf_fwd_p = print_verification_steps(\"Group Portfolio\", portfolio_value_series.loc[actual_calc_end_ts:fwd_end_date_ts_theoretical])\n",
    "#     perf_fwd_b = print_verification_steps(f\"Benchmark\", benchmark_price_series.loc[actual_calc_end_ts:fwd_end_date_ts_theoretical])\n",
    "    \n",
    "# def verify_ticker_ranking_metrics(df_ohlcv, ticker, start_date, calc_period, fwd_period, export_csv=False):\n",
    "#     display(Markdown(f\"## Verification Report for Ticker Ranking: `{ticker}`\"))\n",
    "    \n",
    "#     # <<< CHANGED: Removed hardcoded period_options dict, now using the parser.\n",
    "#     try:\n",
    "#         calc_offset = parse_period_string(calc_period)\n",
    "#         fwd_offset = parse_period_string(fwd_period)\n",
    "#     except ValueError as e:\n",
    "#         print(f\"Error: {e}\"); return\n",
    "        \n",
    "#     df_ticker = df_ohlcv.loc[ticker].sort_index()\n",
    "#     start_date_ts = pd.to_datetime(start_date)\n",
    "#     calc_end_date_ts = start_date_ts + calc_offset; fwd_end_date_ts = calc_end_date_ts + fwd_offset\n",
    "#     calc_df = df_ticker.loc[start_date_ts:calc_end_date_ts].copy()\n",
    "#     if calc_df.empty: print(\"No data in calc period.\"); return\n",
    "\n",
    "#     display(Markdown(\"### A. Calculation Period (for Ranking Metrics)\"))\n",
    "#     calc_gain = calculate_gain(calc_df['Adj Close'])\n",
    "#     calc_start_price, calc_end_price = calc_df['Adj Close'].bfill().iloc[0], calc_df['Adj Close'].ffill().iloc[-1]\n",
    "#     print(f\"CalcGain = {calc_gain:.2%}\")\n",
    "#     display(Markdown(\"#### `MetricValue` Verification:\"))\n",
    "#     price_metric = (calc_end_price / calc_start_price)\n",
    "#     print(f\"1. Price Metric: {price_metric:.4f}\")\n",
    "#     daily_returns = calc_df['Adj Close'].bfill().ffill().pct_change()\n",
    "#     sharpe_ratio = calculate_sharpe(daily_returns)\n",
    "#     print(f\"2. Sharpe Metric: {sharpe_ratio:.4f}\")\n",
    "#     tr = np.maximum(calc_df['Adj High'] - calc_df['Adj Low'], abs(calc_df['Adj High'] - calc_df['Adj Close'].shift(1)), abs(calc_df['Adj Low'] - calc_df['Adj Close'].shift(1)))\n",
    "#     atr = tr.ewm(alpha=1/14, adjust=False).mean()\n",
    "#     atrp_mean = (atr / calc_df['Adj Close']).mean()\n",
    "#     sharpe_atr = (daily_returns.mean() / atrp_mean) if atrp_mean > 0 else 0\n",
    "#     print(f\"3. Sharpe (ATR) Metric: {sharpe_atr:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b2ca3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ==============================================================================\n",
    "# # FINAL PROJECT FUNCTIONS (Golden Copy - Updated for Flexibility)\n",
    "# # ==============================================================================\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import plotly.graph_objects as go\n",
    "# from datetime import datetime, date\n",
    "# import ipywidgets as widgets\n",
    "# from IPython.display import display, Markdown\n",
    "# import pprint\n",
    "# from tqdm.auto import tqdm\n",
    "# import re # <-- Added for the new parser function\n",
    "# from pathlib import Path\n",
    "\n",
    "# # --- A. HELPER FUNCTIONS ---\n",
    "\n",
    "# def parse_period_string(period_str: str) -> pd.DateOffset:\n",
    "#     \"\"\"\n",
    "#     Parses a string like '90D', '13W', '6M', or '1Y' into a pandas DateOffset.\n",
    "#     \"\"\"\n",
    "#     match = re.match(r\"(\\d+)([DWMY])\", period_str.strip().upper())\n",
    "#     if not match:\n",
    "#         raise ValueError(f\"Invalid period format: '{period_str}'. Use format like '90D', '6M', '1Y'.\")\n",
    "    \n",
    "#     quantity, unit = int(match.group(1)), match.group(2)\n",
    "    \n",
    "#     if unit == 'D':\n",
    "#         return pd.DateOffset(days=quantity)\n",
    "#     elif unit == 'W':\n",
    "#         return pd.DateOffset(weeks=quantity)\n",
    "#     elif unit == 'M':\n",
    "#         return pd.DateOffset(months=quantity)\n",
    "#     elif unit == 'Y':\n",
    "#         return pd.DateOffset(years=quantity)\n",
    "#     return None\n",
    "\n",
    "# def calculate_gain(price_series: pd.Series):\n",
    "#     if price_series.dropna().shape[0] < 2: return np.nan\n",
    "#     return (price_series.ffill().iloc[-1] / price_series.bfill().iloc[0]) - 1\n",
    "\n",
    "# def calculate_sharpe(return_series: pd.Series):\n",
    "#     if return_series.dropna().shape[0] < 2: return np.nan\n",
    "#     std_dev = return_series.std()\n",
    "#     if std_dev > 0 and std_dev != np.inf:\n",
    "#         return (return_series.mean() / std_dev) * np.sqrt(252)\n",
    "#     return np.nan\n",
    "\n",
    "# # --- B. THE CORE CALCULATION ENGINE ---\n",
    "\n",
    "# def run_walk_forward_step(df_close_full, df_high_full, df_low_full,\n",
    "#                           start_date, calc_period, fwd_period,\n",
    "#                           metric, rank_start, rank_end, benchmark_ticker,\n",
    "#                           debug=False):\n",
    "#     debug_data = {} if debug else None\n",
    "#     min_date_available = df_close_full.index.min()\n",
    "#     max_date_available = df_close_full.index.max()\n",
    "#     safe_start_date = max(start_date, min_date_available)\n",
    "#     safe_calc_end_date = min(start_date + calc_period, max_date_available)\n",
    "#     safe_viz_end_date = min(safe_calc_end_date + fwd_period, max_date_available)\n",
    "#     if safe_start_date >= safe_calc_end_date:\n",
    "#         return ({'error': \"Invalid date range.\"}, None)\n",
    "    \n",
    "#     calc_close_raw = df_close_full.loc[safe_start_date:safe_calc_end_date]\n",
    "#     calc_close = calc_close_raw.dropna(axis=1, how='all')\n",
    "#     if calc_close.shape[1] == 0 or len(calc_close) < 2:\n",
    "#         return ({'error': \"Not enough data in calc period.\"}, None)\n",
    "\n",
    "#     first_prices = calc_close.bfill().iloc[0]\n",
    "#     last_prices = calc_close.ffill().iloc[-1]\n",
    "#     daily_returns = calc_close.bfill().ffill().pct_change()\n",
    "#     mean_returns = daily_returns.mean()\n",
    "#     std_returns = daily_returns.std()\n",
    "    \n",
    "#     valid_tickers = calc_close.columns\n",
    "#     calc_high = df_high_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "#     calc_low = df_low_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "#     tr = np.maximum(calc_high - calc_low, abs(calc_high - df_close_full[valid_tickers].shift(1)), abs(calc_low - df_close_full[valid_tickers].shift(1)))\n",
    "#     atr = tr.ewm(alpha=1/14, adjust=False).mean()\n",
    "#     atrp = (atr / calc_close).mean()\n",
    "\n",
    "#     metric_values = {}\n",
    "#     metric_values['Price'] = (last_prices / first_prices).dropna()\n",
    "#     metric_values['Sharpe'] = (mean_returns / std_returns * np.sqrt(252)).fillna(0)\n",
    "#     metric_values['Sharpe (ATR)'] = (mean_returns / atrp).fillna(0)\n",
    "\n",
    "#     if debug:\n",
    "#         df_ranking = pd.DataFrame({\n",
    "#             'FirstPrice': first_prices, 'LastPrice': last_prices, 'MeanDailyReturn': mean_returns,\n",
    "#             'StdDevDailyReturn': std_returns, 'MeanATRP': atrp, 'Metric_Price': metric_values['Price'],\n",
    "#             'Metric_Sharpe': metric_values['Sharpe'], 'Metric_Sharpe (ATR)': metric_values['Sharpe (ATR)']\n",
    "#         })\n",
    "#         df_ranking.index.name = 'Ticker'\n",
    "#         debug_data['ranking_metrics'] = df_ranking.sort_values(f'Metric_{metric}', ascending=False)\n",
    "\n",
    "#     sorted_tickers = metric_values[metric].sort_values(ascending=False)\n",
    "#     tickers_to_display = sorted_tickers.index[rank_start-1:rank_end].tolist()\n",
    "#     if not tickers_to_display:\n",
    "#         return ({'error': \"No tickers found for the selected rank.\"}, None)\n",
    "\n",
    "#     normalized_plot_data = df_close_full[tickers_to_display].loc[safe_start_date:safe_viz_end_date]\n",
    "#     normalized_plot_data = normalized_plot_data.div(normalized_plot_data.bfill().iloc[0])\n",
    "#     actual_calc_end_ts = calc_close.index.max()\n",
    "#     portfolio_series = normalized_plot_data.mean(axis=1)\n",
    "#     portfolio_return_series = portfolio_series.pct_change()\n",
    "#     benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "#     benchmark_return_series = benchmark_price_series.loc[safe_start_date:safe_viz_end_date].bfill().ffill().pct_change() if benchmark_price_series is not None else pd.Series(dtype='float64')\n",
    "\n",
    "#     perf_data = {}\n",
    "#     perf_data['calc_p_gain'] = calculate_gain(portfolio_series.loc[:actual_calc_end_ts])\n",
    "#     perf_data['fwd_p_gain'] = calculate_gain(portfolio_series.loc[actual_calc_end_ts:])\n",
    "#     perf_data['full_p_gain'] = calculate_gain(portfolio_series)\n",
    "#     perf_data['calc_p_sharpe'] = calculate_sharpe(portfolio_return_series.loc[:actual_calc_end_ts])\n",
    "#     perf_data['fwd_p_sharpe'] = calculate_sharpe(portfolio_return_series.loc[actual_calc_end_ts:])\n",
    "#     perf_data['full_p_sharpe'] = calculate_sharpe(portfolio_return_series)\n",
    "#     perf_data['calc_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:actual_calc_end_ts]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['fwd_b_gain'] = calculate_gain(benchmark_price_series.loc[actual_calc_end_ts:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['full_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['calc_b_sharpe'] = calculate_sharpe(benchmark_return_series.loc[:actual_calc_end_ts])\n",
    "#     perf_data['fwd_b_sharpe'] = calculate_sharpe(benchmark_return_series.loc[actual_calc_end_ts:])\n",
    "#     perf_data['full_b_sharpe'] = calculate_sharpe(benchmark_return_series)\n",
    "\n",
    "#     calc_end_prices = calc_close.ffill().iloc[-1]\n",
    "#     fwd_close_slice = df_close_full.loc[actual_calc_end_ts:safe_viz_end_date]\n",
    "#     viz_end_prices = fwd_close_slice.ffill().iloc[-1] if not fwd_close_slice.empty and len(fwd_close_slice) >= 2 else calc_end_prices\n",
    "#     calc_gains = (calc_end_prices / calc_close.bfill().iloc[0]) - 1\n",
    "#     fwd_gains = (viz_end_prices / calc_end_prices) - 1\n",
    "#     results_df = pd.DataFrame({'Rank': range(rank_start, rank_start + len(tickers_to_display)), 'Metric': metric, 'MetricValue': sorted_tickers.loc[tickers_to_display].values, 'CalcPrice': calc_end_prices.loc[tickers_to_display], 'CalcGain': calc_gains.loc[tickers_to_display], 'FwdGain': fwd_gains.loc[tickers_to_display]}, index=pd.Index(tickers_to_display, name='Ticker'))\n",
    "#     if benchmark_price_series is not None and benchmark_ticker in calc_close.columns:\n",
    "#         benchmark_df_row = pd.DataFrame({'Rank': np.nan, 'Metric': metric, 'MetricValue': metric_values[metric].get(benchmark_ticker, np.nan), 'CalcPrice': calc_end_prices[benchmark_ticker], 'CalcGain': calc_gains[benchmark_ticker], 'FwdGain': fwd_gains[benchmark_ticker]}, index=pd.Index([f\"{benchmark_ticker} (BM)\"], name='Ticker'))\n",
    "#         results_df = pd.concat([results_df, benchmark_df_row])\n",
    "    \n",
    "#     if debug:\n",
    "#         df_trace = normalized_plot_data.copy()\n",
    "#         df_trace.columns = [f'Norm_Price_{c}' for c in df_trace.columns]\n",
    "#         df_trace['Norm_Price_Portfolio'] = portfolio_series\n",
    "#         if benchmark_price_series is not None and not benchmark_price_series.loc[safe_start_date:safe_viz_end_date].dropna().empty:\n",
    "#             norm_bm = benchmark_price_series.loc[safe_start_date:safe_viz_end_date] / benchmark_price_series.loc[safe_start_date:].bfill().iloc[0]\n",
    "#             df_trace[f'Norm_Price_Benchmark_{benchmark_ticker}'] = norm_bm\n",
    "#         for col in df_trace.columns:\n",
    "#             if 'Norm_Price' in col:\n",
    "#                 df_trace[col.replace('Norm_Price', 'Return')] = df_trace[col].pct_change()\n",
    "#         debug_data['portfolio_trace'] = df_trace\n",
    "\n",
    "#     final_results = {\n",
    "#         'tickers_to_display': tickers_to_display, 'normalized_plot_data': normalized_plot_data,\n",
    "#         'portfolio_series': portfolio_series, 'benchmark_price_series': benchmark_price_series,\n",
    "#         'performance_data': perf_data, 'results_df': results_df, 'actual_calc_end_ts': actual_calc_end_ts,\n",
    "#         'safe_start_date': pd.to_datetime(df_close_full.loc[safe_start_date:safe_viz_end_date].index.min()),\n",
    "#         'safe_viz_end_date': pd.to_datetime(df_close_full.loc[safe_start_date:safe_viz_end_date].index.max()),\n",
    "#         'error': None\n",
    "#     }\n",
    "#     return (final_results, debug_data)\n",
    "\n",
    "# # --- C. DYNAMIC DATA QUALITY FILTER FUNCTIONS ---\n",
    "\n",
    "# def calculate_rolling_quality_metrics(df_ohlcv, window=252, min_periods=126, debug=False):\n",
    "#     print(f\"--- Calculating Rolling Quality Metrics (Window: {window} days) ---\")\n",
    "#     df = df_ohlcv.copy()\n",
    "#     if not df.index.is_monotonic_increasing:\n",
    "#         df.sort_index(inplace=True)\n",
    "#     df['IsStale'] = np.where((df['Volume'] == 0) | (df['Adj High'] == df['Adj Low']), 1, 0)\n",
    "#     df['DollarVolume'] = df['Adj Close'] * df['Volume']\n",
    "#     df['HasSameVolumeAsPrevDay'] = (df.groupby(level='Ticker')['Volume'].diff() == 0).astype(int)\n",
    "#     grouped = df.groupby(level='Ticker')\n",
    "#     stale_pct = grouped['IsStale'].rolling(window=window, min_periods=min_periods).mean()\n",
    "#     median_vol = grouped['DollarVolume'].rolling(window=window, min_periods=min_periods).median()\n",
    "#     same_vol_count = grouped['HasSameVolumeAsPrevDay'].rolling(window=window, min_periods=min_periods).sum()\n",
    "#     quality_df = pd.concat([stale_pct, median_vol, same_vol_count], axis=1)\n",
    "#     quality_df.columns = ['RollingStalePct', 'RollingMedianVolume', 'RollingSameVolCount']\n",
    "#     quality_df.index = quality_df.index.droplevel(0)\n",
    "#     print(\"✅ Rolling metrics calculation complete.\")\n",
    "#     return quality_df\n",
    "\n",
    "# def get_eligible_universe(quality_metrics_df, filter_date, thresholds):\n",
    "#     filter_date_ts = pd.to_datetime(filter_date)\n",
    "#     date_index = quality_metrics_df.index.get_level_values('Date').unique().sort_values()\n",
    "#     if filter_date_ts < date_index[0]:\n",
    "#         print(f\"Warning: Filter date {filter_date_ts.date()} is before the earliest data point. Returning empty universe.\")\n",
    "#         return []\n",
    "#     valid_prior_dates = date_index[date_index <= filter_date_ts]\n",
    "#     if valid_prior_dates.empty:\n",
    "#         print(f\"Warning: No available data found on or before {filter_date_ts.date()}. Returning empty universe.\")\n",
    "#         return []\n",
    "#     actual_date_to_use = valid_prior_dates[-1]\n",
    "#     if actual_date_to_use.date() != filter_date_ts.date():\n",
    "#         print(f\"ℹ️ Info: Filter date {filter_date_ts.date()} not found. Using previous available date {actual_date_to_use.date()}.\")\n",
    "#     metrics_on_date = quality_metrics_df.xs(actual_date_to_use, level='Date')\n",
    "#     mask = ((metrics_on_date['RollingMedianVolume'] >= thresholds['min_median_dollar_volume']) &\n",
    "#             (metrics_on_date['RollingStalePct'] <= thresholds['max_stale_pct']) &\n",
    "#             (metrics_on_date['RollingSameVolCount'] <= thresholds['max_same_vol_count']))\n",
    "#     eligible_tickers = metrics_on_date[mask].index.tolist()\n",
    "#     all_tickers = metrics_on_date.index.tolist()\n",
    "#     print(f\"Dynamic Filter ({filter_date_ts.date()}): Kept {len(eligible_tickers)} of {len(all_tickers)} tickers.\")\n",
    "#     return eligible_tickers    \n",
    "\n",
    "# # --- D. INTERACTIVE ANALYSIS & BACKTESTING TOOLS ---\n",
    "\n",
    "# def plot_walk_forward_analyzer(df_ohlcv, \n",
    "#                                default_start_date=None, default_calc_period='3M', default_fwd_period='1M',\n",
    "#                                default_metric='Sharpe (ATR)', default_rank_start=1, default_rank_end=10,\n",
    "#                                default_benchmark_ticker='VOO',\n",
    "#                                quality_thresholds={'min_median_dollar_volume': 1_000_000, 'max_stale_pct': 0.05, 'max_same_vol_count': 10},\n",
    "#                                debug=False):\n",
    "#     print(\"Initializing Walk-Forward Analyzer (with Dynamic Universe Filtering)...\")\n",
    "#     if not isinstance(df_ohlcv.index, pd.MultiIndex): raise ValueError(\"Input DataFrame must have a (Ticker, Date) MultiIndex.\")\n",
    "#     df_ohlcv = df_ohlcv.sort_index()\n",
    "#     print(\"Pre-calculating data quality metrics...\")\n",
    "#     quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "#     print(\"Pre-processing data (unstacking)...\")\n",
    "#     df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "#     df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "#     df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    \n",
    "#     start_date_picker = widgets.DatePicker(description='Start Date:', value=pd.to_datetime(default_start_date), disabled=False)\n",
    "#     calc_period_input = widgets.Text(value=default_calc_period, description='Calc Period:', placeholder=\"e.g., '6M', '90D'\")\n",
    "#     fwd_period_input = widgets.Text(value=default_fwd_period, description='Fwd Period:', placeholder=\"e.g., '3M', '26W'\")\n",
    "#     metrics = ['Price', 'Sharpe', 'Sharpe (ATR)']\n",
    "#     metric_dropdown = widgets.Dropdown(options=metrics, value=default_metric, description='Metric:')\n",
    "#     rank_start_input = widgets.IntText(value=default_rank_start, description='Rank Start:')\n",
    "#     rank_end_input = widgets.IntText(value=default_rank_end, description='Rank End:')\n",
    "#     benchmark_ticker_input = widgets.Text(value=default_benchmark_ticker, description='Benchmark:', placeholder='Enter Ticker')\n",
    "#     update_button = widgets.Button(description=\"Update Chart\", button_style='primary')\n",
    "#     ticker_list_output = widgets.Output()\n",
    "#     results_container, debug_data_container = [None], [None]\n",
    "\n",
    "#     fig = go.FigureWidget()\n",
    "#     max_traces = 50\n",
    "#     for i in range(max_traces): fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name=f'placeholder_{i}', visible=False, showlegend=False))\n",
    "#     fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Benchmark', visible=True, showlegend=True, line=dict(color='black', width=3, dash='dash')))\n",
    "#     fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Group Portfolio', visible=True, showlegend=True, line=dict(color='green', width=3)))\n",
    "\n",
    "#     def update_plot(button_click):\n",
    "#         ticker_list_output.clear_output()\n",
    "#         start_date = pd.to_datetime(start_date_picker.value)\n",
    "#         try:\n",
    "#             calc_period = parse_period_string(calc_period_input.value)\n",
    "#             fwd_period = parse_period_string(fwd_period_input.value)\n",
    "#         except ValueError as e:\n",
    "#             with ticker_list_output:\n",
    "#                 print(f\"Error: {e}\")\n",
    "#             return\n",
    "#         metric = metric_dropdown.value\n",
    "#         rank_start, rank_end = rank_start_input.value, rank_end_input.value\n",
    "#         benchmark_ticker = benchmark_ticker_input.value.strip().upper()\n",
    "#         if rank_start > rank_end:\n",
    "#             with ticker_list_output: print(\"Error: 'Rank Start' must be <= 'Rank End'.\"); return\n",
    "#         if rank_start < 1:\n",
    "#             with ticker_list_output: print(\"Error: 'Rank Start' must be >= 1.\"); return\n",
    "\n",
    "#         eligible_tickers = get_eligible_universe(quality_metrics_df, start_date, quality_thresholds)\n",
    "#         if not eligible_tickers:\n",
    "#             with ticker_list_output: print(f\"Error: No eligible tickers found on {start_date.date()} with the current quality filters.\"); return\n",
    "#         df_close_step = df_close_full[eligible_tickers]; df_high_step = df_high_full[eligible_tickers]; df_low_step = df_low_full[eligible_tickers]\n",
    "\n",
    "#         results, debug_output = run_walk_forward_step(\n",
    "#             df_close_step, df_high_step, df_low_step, start_date, calc_period, fwd_period, \n",
    "#             metric, rank_start, rank_end, benchmark_ticker, debug=debug\n",
    "#         )\n",
    "#         if results['error']:\n",
    "#             with ticker_list_output: print(f\"Error: {results['error']}\"); return\n",
    "\n",
    "#         with fig.batch_update():\n",
    "#             for i in range(max_traces):\n",
    "#                 trace = fig.data[i]\n",
    "#                 if i < len(results['tickers_to_display']):\n",
    "#                     ticker = results['tickers_to_display'][i]; plot_data_series = results['normalized_plot_data'][ticker]\n",
    "#                     trace.x, trace.y, trace.name, trace.visible, trace.showlegend = plot_data_series.index, plot_data_series.values, ticker, True, True\n",
    "#                 else: trace.visible, trace.showlegend = False, False\n",
    "#             benchmark_trace = fig.data[max_traces]\n",
    "#             if results['benchmark_price_series'] is not None and not results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']].dropna().empty:\n",
    "#                 normalized_benchmark = results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']] / results['benchmark_price_series'].loc[results['safe_start_date']:].bfill().iloc[0]\n",
    "#                 benchmark_trace.x, benchmark_trace.y, benchmark_trace.name, benchmark_trace.visible = normalized_benchmark.index, normalized_benchmark, f\"Benchmark ({benchmark_ticker})\", True\n",
    "#             else: benchmark_trace.visible = False\n",
    "#             portfolio_trace = fig.data[max_traces + 1]\n",
    "#             portfolio_trace.x, portfolio_trace.y, portfolio_trace.name, portfolio_trace.visible = results['portfolio_series'].index, results['portfolio_series'], 'Group Portfolio', True\n",
    "#             fig.layout.shapes = []; fig.add_shape(type=\"line\", x0=results['actual_calc_end_ts'], y0=0, x1=results['actual_calc_end_ts'], y1=1, xref='x', yref='paper', line=dict(color=\"grey\", width=2, dash=\"dash\"))\n",
    "            \n",
    "#         results_container[0] = results; debug_data_container[0] = debug_output\n",
    "        \n",
    "#         with ticker_list_output:\n",
    "#             print(f\"Analysis Period: {results['safe_start_date'].date()} to {results['safe_viz_end_date'].date()}.\")\n",
    "#             pprint.pprint(results['tickers_to_display'])\n",
    "#             p = results['performance_data']\n",
    "#             rows = []\n",
    "#             rows.append({'Metric': 'Group Portfolio Gain', 'Full': p['full_p_gain'], 'Calc': p['calc_p_gain'], 'Fwd': p['fwd_p_gain']})\n",
    "#             if not np.isnan(p['full_b_gain']):\n",
    "#                 rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Gain', 'Full': p['full_b_gain'], 'Calc': p['calc_b_gain'], 'Fwd': p['fwd_b_gain']})\n",
    "#                 rows.append({'Metric': 'Gain Delta (vs Bm)', 'Full': p['full_p_gain'] - p['full_b_gain'], 'Calc': p['calc_p_gain'] - p['calc_b_gain'], 'Fwd': p['fwd_p_gain'] - p['fwd_b_gain']})\n",
    "#             rows.append({'Metric': 'Group Portfolio Sharpe', 'Full': p['full_p_sharpe'], 'Calc': p['calc_p_sharpe'], 'Fwd': p['fwd_p_sharpe']})\n",
    "#             if not np.isnan(p['full_b_sharpe']):\n",
    "#                 rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Sharpe', 'Full': p['full_b_sharpe'], 'Calc': p['calc_b_sharpe'], 'Fwd': p['fwd_b_sharpe']})\n",
    "#                 rows.append({'Metric': 'Sharpe Delta (vs Bm)', 'Full': p['full_p_sharpe'] - p['full_b_sharpe'], 'Calc': p['calc_p_sharpe'] - p['calc_b_sharpe'], 'Fwd': p['fwd_p_sharpe'] - p['fwd_b_sharpe']})\n",
    "#             report_df = pd.DataFrame(rows).set_index('Metric')\n",
    "#             gain_rows = [row for row in report_df.index if 'Gain' in row or 'Delta' in row]\n",
    "#             sharpe_rows = [row for row in report_df.index if 'Sharpe' in row]\n",
    "#             styled_df = report_df.style.format('{:+.2%}', na_rep='N/A', subset=(gain_rows, report_df.columns)).format('{:+.2f}', na_rep='N/A', subset=(sharpe_rows, report_df.columns)).set_properties(**{'text-align': 'right', 'width': '100px'}).set_table_styles([{'selector': 'th.col_heading', 'props': [('text-align', 'right')]}, {'selector': 'th.row_heading', 'props': [('text-align', 'left')]}])\n",
    "#             print(\"\\n--- Strategy Performance Summary ---\")\n",
    "#             display(styled_df)\n",
    "            \n",
    "#     fig.update_layout(title_text='Walk-Forward Performance Analysis', xaxis_title='Date', yaxis_title='Normalized Price (Start = 1)', hovermode='x unified', legend_title_text='Tickers (Ranked)', height=600, margin=dict(t=50))\n",
    "#     fig.add_hline(y=1, line_width=1, line_dash=\"dash\", line_color=\"grey\")\n",
    "#     update_button.on_click(update_plot)\n",
    "#     controls_row1 = widgets.HBox([start_date_picker, calc_period_input, fwd_period_input])\n",
    "#     controls_row2 = widgets.HBox([metric_dropdown, rank_start_input, rank_end_input, benchmark_ticker_input, update_button])\n",
    "#     ui_container = widgets.VBox([controls_row1, controls_row2, ticker_list_output], layout=widgets.Layout(margin='10px 0 20px 0'))\n",
    "#     display(ui_container, fig)\n",
    "#     update_plot(None)\n",
    "#     return (results_container, debug_data_container)\n",
    "\n",
    "# def run_full_backtest(df_ohlcv, strategy_params, quality_thresholds):\n",
    "#     print(f\"--- Running Full Forensic Backtest for Strategy: {strategy_params['metric']} (Top {strategy_params['rank_start']}-{strategy_params['rank_end']}) ---\")\n",
    "#     start_date, end_date = strategy_params['start_date'], strategy_params['end_date']\n",
    "#     calc_period_str, fwd_period_str = strategy_params['calc_period'], strategy_params['fwd_period']\n",
    "#     metric, rank_start, rank_end = strategy_params['metric'], strategy_params['rank_start'], strategy_params['rank_end']\n",
    "#     benchmark_ticker = strategy_params['benchmark_ticker']\n",
    "#     quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "#     df_close_full = df_ohlcv['Adj Close'].unstack(level=0); df_high_full = df_ohlcv['Adj High'].unstack(level=0); df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "#     try:\n",
    "#         calc_period = parse_period_string(calc_period_str)\n",
    "#         fwd_period = parse_period_string(fwd_period_str)\n",
    "#     except ValueError as e:\n",
    "#         print(f\"Error in strategy_params: {e}\"); return None\n",
    "#     match = re.match(r\"(\\d+)([DWMY])\", fwd_period_str.strip().upper())\n",
    "#     quantity, unit = int(match.group(1)), match.group(2)\n",
    "#     freq_map = {'D': 'D', 'W': 'W', 'M': 'ME', 'Y': 'YE'}\n",
    "#     freq_str = f\"{quantity}{freq_map[unit]}\"\n",
    "#     step_dates = pd.date_range(start=start_date, end=end_date, freq=freq_str)\n",
    "#     all_fwd_gains, period_by_period_debug = [], {}\n",
    "\n",
    "#     print(f\"Simulating {len(step_dates)} periods from {step_dates[0].date()} to {step_dates[-1].date()}...\")\n",
    "#     for step_date in tqdm(step_dates, desc=\"Backtest Progress\"):\n",
    "#         eligible_tickers = get_eligible_universe(quality_metrics_df, step_date, quality_thresholds)\n",
    "#         if not eligible_tickers: continue\n",
    "#         df_close_step = df_close_full[eligible_tickers]; df_high_step = df_high_full[eligible_tickers]; df_low_step = df_low_full[eligible_tickers]\n",
    "#         results, debug_output = run_walk_forward_step(\n",
    "#             df_close_step, df_high_step, df_low_step, step_date, calc_period, fwd_period,\n",
    "#             metric, rank_start, rank_end, benchmark_ticker, debug=True\n",
    "#         )\n",
    "#         if results['error'] is None:\n",
    "#             fwd_series = results['portfolio_series'].loc[results['actual_calc_end_ts']:]\n",
    "#             all_fwd_gains.append(fwd_series.pct_change().dropna())\n",
    "#             period_by_period_debug[step_date.date().isoformat()] = debug_output\n",
    "            \n",
    "#     if not all_fwd_gains:\n",
    "#         print(\"Error: No valid periods were simulated.\"); return None\n",
    "\n",
    "#     strategy_returns = pd.concat(all_fwd_gains); strategy_equity_curve = (1 + strategy_returns).cumprod()\n",
    "#     benchmark_returns = df_close_full[benchmark_ticker].pct_change().loc[strategy_equity_curve.index]; benchmark_equity_curve = (1 + benchmark_returns).cumprod()\n",
    "#     cumulative_equity_df = pd.DataFrame({'Strategy_Equity': strategy_equity_curve, 'Benchmark_Equity': benchmark_equity_curve})\n",
    "    \n",
    "#     fig = go.Figure()\n",
    "#     fig.add_trace(go.Scatter(x=cumulative_equity_df.index, y=cumulative_equity_df['Strategy_Equity'], name='Strategy', line=dict(color='green')))\n",
    "#     fig.add_trace(go.Scatter(x=cumulative_equity_df.index, y=cumulative_equity_df['Benchmark_Equity'], name=f'Benchmark ({benchmark_ticker})', line=dict(color='black', dash='dash')))\n",
    "#     fig.update_layout(title=f\"Cumulative Performance: '{metric}' Strategy (Top {rank_start}-{rank_end})\", xaxis_title=\"Date\", yaxis_title=\"Cumulative Growth\")\n",
    "#     fig.show()\n",
    "\n",
    "#     final_backtest_results = {'cumulative_performance': cumulative_equity_df, 'period_by_period_debug': period_by_period_debug}\n",
    "#     print(\"\\n✅ Full backtest complete. Results object is ready for forensic analysis.\")\n",
    "#     return final_backtest_results\n",
    "\n",
    "# # --- E. VERIFICATION TOOLS (User Requested) ---\n",
    "\n",
    "# def verify_group_tickers_walk_forward_calculation(df_ohlcv, tickers_to_verify, benchmark_ticker,\n",
    "#                                                   start_date, calc_period, fwd_period, export_csv=False):\n",
    "#     display(Markdown(f\"## Verification Report for Portfolio vs. Benchmark\"))\n",
    "#     display(Markdown(f\"**Portfolio Tickers:** `{tickers_to_verify}`\\n**Benchmark Ticker:** `{benchmark_ticker}`\"))\n",
    "#     try:\n",
    "#         calc_offset = parse_period_string(calc_period)\n",
    "#         fwd_offset = parse_period_string(fwd_period)\n",
    "#     except ValueError as e:\n",
    "#         print(f\"Error: {e}\"); return\n",
    "#     df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "#     start_date_ts = pd.to_datetime(start_date)\n",
    "#     calc_end_date_ts_theoretical = start_date_ts + calc_offset\n",
    "#     fwd_end_date_ts_theoretical = calc_end_date_ts_theoretical + fwd_offset\n",
    "#     actual_calc_end_ts = df_close_full.loc[start_date_ts:calc_end_date_ts_theoretical].index.max()\n",
    "#     display(Markdown(f\"**Analysis Start:** `{start_date_ts.date()}`\\n**Calc End:** `{actual_calc_end_ts.date()}`\\n**Fwd End:** `{fwd_end_date_ts_theoretical.date()}`\"))\n",
    "    \n",
    "#     portfolio_prices_raw_slice = df_close_full[tickers_to_verify].loc[start_date_ts:fwd_end_date_ts_theoretical]\n",
    "#     portfolio_value_series = portfolio_prices_raw_slice.div(portfolio_prices_raw_slice.bfill().iloc[0]).mean(axis=1)\n",
    "#     benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "\n",
    "#     def print_verification_steps(title, price_series):\n",
    "#         display(Markdown(f\"#### Verification for: `{title}`\"))\n",
    "#         if price_series.dropna().shape[0] < 2: print(\"  - Not enough data points.\"); return {'gain': np.nan, 'sharpe': np.nan}\n",
    "#         start_price, end_price = price_series.bfill().iloc[0], price_series.ffill().iloc[-1]\n",
    "#         gain = (end_price / start_price) - 1\n",
    "#         print(f\"Start Value ({price_series.first_valid_index().date()}): {start_price:,.4f}\\nEnd Value   ({price_series.last_valid_index().date()}): {end_price:,.4f}\\nGain = {gain:.2%}\")\n",
    "#         returns = price_series.pct_change()\n",
    "#         sharpe = calculate_sharpe(returns)\n",
    "#         print(f\"Mean Daily Return: {returns.mean():.6f}\\nStd Dev: {returns.std():.6f}\\nSharpe = {sharpe:.2f}\")\n",
    "#         return {'gain': gain, 'sharpe': sharpe}\n",
    "\n",
    "#     display(Markdown(\"### A. Calculation Period\"))\n",
    "#     perf_calc_p = print_verification_steps(\"Group Portfolio\", portfolio_value_series.loc[start_date_ts:actual_calc_end_ts])\n",
    "#     perf_calc_b = print_verification_steps(f\"Benchmark\", benchmark_price_series.loc[start_date_ts:actual_calc_end_ts])\n",
    "#     display(Markdown(\"### B. Forward Period\"))\n",
    "#     perf_fwd_p = print_verification_steps(\"Group Portfolio\", portfolio_value_series.loc[actual_calc_end_ts:fwd_end_date_ts_theoretical])\n",
    "#     perf_fwd_b = print_verification_steps(f\"Benchmark\", benchmark_price_series.loc[actual_calc_end_ts:fwd_end_date_ts_theoretical])\n",
    "    \n",
    "# def verify_ticker_ranking_metrics(df_ohlcv, ticker, start_date, calc_period, fwd_period, export_csv=False):\n",
    "#     display(Markdown(f\"## Verification Report for Ticker Ranking: `{ticker}`\"))\n",
    "#     try:\n",
    "#         calc_offset = parse_period_string(calc_period)\n",
    "#         fwd_offset = parse_period_string(fwd_period)\n",
    "#     except ValueError as e:\n",
    "#         print(f\"Error: {e}\"); return\n",
    "#     df_ticker = df_ohlcv.loc[ticker].sort_index()\n",
    "#     start_date_ts = pd.to_datetime(start_date)\n",
    "#     calc_end_date_ts = start_date_ts + calc_offset; fwd_end_date_ts = calc_end_date_ts + fwd_offset\n",
    "#     calc_df = df_ticker.loc[start_date_ts:calc_end_date_ts].copy()\n",
    "#     if calc_df.empty: print(\"No data in calc period.\"); return\n",
    "\n",
    "#     display(Markdown(\"### A. Calculation Period (for Ranking Metrics)\"))\n",
    "#     calc_gain = calculate_gain(calc_df['Adj Close'])\n",
    "#     calc_start_price, calc_end_price = calc_df['Adj Close'].bfill().iloc[0], calc_df['Adj Close'].ffill().iloc[-1]\n",
    "#     print(f\"CalcGain = {calc_gain:.2%}\")\n",
    "#     display(Markdown(\"#### `MetricValue` Verification:\"))\n",
    "#     price_metric = (calc_end_price / calc_start_price)\n",
    "#     print(f\"1. Price Metric: {price_metric:.4f}\")\n",
    "#     daily_returns = calc_df['Adj Close'].bfill().ffill().pct_change()\n",
    "#     sharpe_ratio = calculate_sharpe(daily_returns)\n",
    "#     print(f\"2. Sharpe Metric: {sharpe_ratio:.4f}\")\n",
    "#     tr = np.maximum(calc_df['Adj High'] - calc_df['Adj Low'], abs(calc_df['Adj High'] - calc_df['Adj Close'].shift(1)), abs(calc_df['Adj Low'] - calc_df['Adj Close'].shift(1)))\n",
    "#     atr = tr.ewm(alpha=1/14, adjust=False).mean()\n",
    "#     atrp_mean = (atr / calc_df['Adj Close']).mean()\n",
    "#     sharpe_atr = (daily_returns.mean() / atrp_mean) if atrp_mean > 0 else 0\n",
    "#     print(f\"3. Sharpe (ATR) Metric: {sharpe_atr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "474945cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets\n",
    "import pprint\n",
    "import os \n",
    "\n",
    "from datetime import datetime, date\n",
    "from IPython.display import display, Markdown\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d12fd93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.width', 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4a8fe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ==============================================================================\n",
    "# # FINAL PROJECT FUNCTIONS (Golden Copy - Updated for Trading Day Logic)\n",
    "# # ==============================================================================\n",
    "\n",
    "# # --- A. HELPER FUNCTIONS ---\n",
    "\n",
    "# def calculate_gain(price_series: pd.Series):\n",
    "#     if price_series.dropna().shape[0] < 2: return np.nan\n",
    "#     return (price_series.ffill().iloc[-1] / price_series.bfill().iloc[0]) - 1\n",
    "\n",
    "# def calculate_sharpe(return_series: pd.Series):\n",
    "#     if return_series.dropna().shape[0] < 2: return np.nan\n",
    "#     std_dev = return_series.std()\n",
    "#     if std_dev > 0 and std_dev != np.inf:\n",
    "#         return (return_series.mean() / std_dev) * np.sqrt(252)\n",
    "#     return np.nan\n",
    "\n",
    "# # def calculate_true_range(high: pd.Series, low: pd.Series, close: pd.Series) -> pd.Series:\n",
    "# #     \"\"\"\n",
    "# #     Calculates the True Range for a given set of price series.\n",
    "# #     This function contains the robust, corrected logic.\n",
    "\n",
    "# #     Args:\n",
    "# #         high (pd.Series): Series of high prices.\n",
    "# #         low (pd.Series): Series of low prices.\n",
    "# #         close (pd.Series): Series of close prices. NOTE: This should be the full\n",
    "# #                            series before slicing to allow for a correct shift(-1).\n",
    "\n",
    "# #     Returns:\n",
    "# #         pd.Series: A series containing the True Range values.\n",
    "# #     \"\"\"\n",
    "# #     # <<< NEW: This is the centralized, robust True Range calculation function.\n",
    "# #     prev_close = close.shift(1)\n",
    "    \n",
    "# #     tr_df = pd.DataFrame({\n",
    "# #         'h_l': high - low,          # High - Low\n",
    "# #         'h_pc': abs(high - prev_close), # abs(High - Previous Close)\n",
    "# #         'l_pc': abs(low - prev_close)   # abs(Low - Previous Close)\n",
    "# #     })\n",
    "    \n",
    "# #     return tr_df.max(axis=1)\n",
    "\n",
    "# def calculate_true_range(high: pd.Series, low: pd.Series, close: pd.Series) -> pd.Series:\n",
    "#     \"\"\"\n",
    "#     Calculates the True Range for a given set of price series.\n",
    "#     This version is robust against index misalignments.\n",
    "\n",
    "#     Args:\n",
    "#         high (pd.Series): Series/DataFrame of high prices for the target period.\n",
    "#         low (pd.Series): Series/DataFrame of low prices for the target period.\n",
    "#         close (pd.Series): Series/DataFrame of close prices. Must contain data for at least\n",
    "#                            one day prior to the start of the 'high'/'low' series.\n",
    "\n",
    "#     Returns:\n",
    "#         pd.Series: A series containing the True Range values, indexed identically to 'high'.\n",
    "#     \"\"\"\n",
    "#     # <<< BUG FIX: Make the function robust by explicitly aligning indices.\n",
    "    \n",
    "#     # Calculate previous close using the potentially longer 'close' series\n",
    "#     prev_close = close.shift(1)\n",
    "    \n",
    "#     # Explicitly reindex prev_close to match the exact index of the 'high' series.\n",
    "#     # This is the key step to prevent alignment errors.\n",
    "#     prev_close_aligned = prev_close.reindex(high.index)\n",
    "\n",
    "#     # Now all three components are guaranteed to have the same index.\n",
    "#     tr_df = pd.DataFrame({\n",
    "#         'h_l': high - low,                      # High - Low\n",
    "#         'h_pc': abs(high - prev_close_aligned), # abs(High - Previous Close)\n",
    "#         'l_pc': abs(low - prev_close_aligned)   # abs(Low - Previous Close)\n",
    "#     })\n",
    "    \n",
    "#     return tr_df.max(axis=1)\n",
    "\n",
    "\n",
    "# # --- B. THE CORE CALCULATION ENGINE ---\n",
    "\n",
    "# # def run_walk_forward_step(df_close_full, df_high_full, df_low_full,\n",
    "# #                           master_trading_days,\n",
    "# #                           start_date, calc_period, fwd_period,\n",
    "# #                           metric, rank_start, rank_end, benchmark_ticker,\n",
    "# #                           debug=False):\n",
    "# #     debug_data = {} if debug else None\n",
    "    \n",
    "# #     # <<< CHANGED: All date calculations are now based on the master_trading_days index.\n",
    "# #     try:\n",
    "# #         start_idx = master_trading_days.get_loc(start_date)\n",
    "# #     except KeyError:\n",
    "# #         return ({'error': f\"Start date {start_date.date()} is not a valid trading day.\"}, None)\n",
    "        \n",
    "# #     # Calculate end dates based on index locations\n",
    "# #     calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "# #     viz_end_idx = min(calc_end_idx + fwd_period, len(master_trading_days) - 1)\n",
    "\n",
    "# #     safe_start_date = master_trading_days[start_idx]\n",
    "# #     safe_calc_end_date = master_trading_days[calc_end_idx]\n",
    "# #     safe_viz_end_date = master_trading_days[viz_end_idx]\n",
    "    \n",
    "# #     if safe_start_date >= safe_calc_end_date:\n",
    "# #         return ({'error': \"Invalid date range (calc period has zero or negative length).\"}, None)\n",
    "\n",
    "# #     calc_close_raw = df_close_full.loc[safe_start_date:safe_calc_end_date]\n",
    "# #     calc_close = calc_close_raw.dropna(axis=1, how='all')\n",
    "# #     if calc_close.shape[1] == 0 or len(calc_close) < 2:\n",
    "# #         return ({'error': \"Not enough data in calc period.\"}, None)\n",
    "\n",
    "# #     # --- The rest of the calculation logic remains largely the same ---\n",
    "# #     first_prices = calc_close.bfill().iloc[0]\n",
    "# #     last_prices = calc_close.ffill().iloc[-1]\n",
    "# #     daily_returns = calc_close.bfill().ffill().pct_change()\n",
    "# #     mean_returns = daily_returns.mean()\n",
    "# #     std_returns = daily_returns.std()\n",
    "    \n",
    "# #     valid_tickers = calc_close.columns\n",
    "# #     calc_high = df_high_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "# #     calc_low = df_low_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "# #     tr = np.maximum(calc_high - calc_low, abs(calc_high - df_close_full[valid_tickers].shift(1)), abs(calc_low - df_close_full[valid_tickers].shift(1)))\n",
    "# #     atr = tr.ewm(alpha=1/14, adjust=False).mean()\n",
    "# #     atrp = (atr / calc_close).mean()\n",
    "\n",
    "# #     metric_values = {}\n",
    "# #     metric_values['Price'] = (last_prices / first_prices).dropna()\n",
    "# #     metric_values['Sharpe'] = (mean_returns / std_returns * np.sqrt(252)).fillna(0)\n",
    "# #     metric_values['Sharpe (ATR)'] = (mean_returns / atrp).fillna(0)\n",
    "\n",
    "# #     if debug:\n",
    "# #         df_ranking = pd.DataFrame({\n",
    "# #             'FirstPrice': first_prices, 'LastPrice': last_prices, 'MeanDailyReturn': mean_returns,\n",
    "# #             'StdDevDailyReturn': std_returns, 'MeanATRP': atrp, 'Metric_Price': metric_values['Price'],\n",
    "# #             'Metric_Sharpe': metric_values['Sharpe'], 'Metric_Sharpe (ATR)': metric_values['Sharpe (ATR)']\n",
    "# #         })\n",
    "# #         df_ranking.index.name = 'Ticker'\n",
    "# #         debug_data['ranking_metrics'] = df_ranking.sort_values(f'Metric_{metric}', ascending=False)\n",
    "\n",
    "# #     sorted_tickers = metric_values[metric].sort_values(ascending=False)\n",
    "# #     tickers_to_display = sorted_tickers.index[rank_start-1:rank_end].tolist()\n",
    "# #     if not tickers_to_display:\n",
    "# #         return ({'error': \"No tickers found for the selected rank.\"}, None)\n",
    "\n",
    "# #     normalized_plot_data = df_close_full[tickers_to_display].loc[safe_start_date:safe_viz_end_date]\n",
    "# #     normalized_plot_data = normalized_plot_data.div(normalized_plot_data.bfill().iloc[0])\n",
    "# #     actual_calc_end_ts = calc_close.index.max()\n",
    "# #     portfolio_series = normalized_plot_data.mean(axis=1)\n",
    "# #     portfolio_return_series = portfolio_series.pct_change()\n",
    "# #     benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "# #     benchmark_return_series = benchmark_price_series.loc[safe_start_date:safe_viz_end_date].bfill().ffill().pct_change() if benchmark_price_series is not None else pd.Series(dtype='float64')\n",
    "\n",
    "# #     perf_data = {}\n",
    "# #     perf_data['calc_p_gain'] = calculate_gain(portfolio_series.loc[:actual_calc_end_ts])\n",
    "# #     perf_data['fwd_p_gain'] = calculate_gain(portfolio_series.loc[actual_calc_end_ts:])\n",
    "# #     perf_data['full_p_gain'] = calculate_gain(portfolio_series)\n",
    "# #     perf_data['calc_p_sharpe'] = calculate_sharpe(portfolio_return_series.loc[:actual_calc_end_ts])\n",
    "# #     perf_data['fwd_p_sharpe'] = calculate_sharpe(portfolio_return_series.loc[actual_calc_end_ts:])\n",
    "# #     perf_data['full_p_sharpe'] = calculate_sharpe(portfolio_return_series)\n",
    "# #     perf_data['calc_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:actual_calc_end_ts]) if benchmark_price_series is not None else np.nan\n",
    "# #     perf_data['fwd_b_gain'] = calculate_gain(benchmark_price_series.loc[actual_calc_end_ts:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "# #     perf_data['full_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "# #     perf_data['calc_b_sharpe'] = calculate_sharpe(benchmark_return_series.loc[:actual_calc_end_ts])\n",
    "# #     perf_data['fwd_b_sharpe'] = calculate_sharpe(benchmark_return_series.loc[actual_calc_end_ts:])\n",
    "# #     perf_data['full_b_sharpe'] = calculate_sharpe(benchmark_return_series)\n",
    "\n",
    "# #     calc_end_prices = calc_close.ffill().iloc[-1]\n",
    "# #     fwd_close_slice = df_close_full.loc[actual_calc_end_ts:safe_viz_end_date]\n",
    "# #     viz_end_prices = fwd_close_slice.ffill().iloc[-1] if not fwd_close_slice.empty and len(fwd_close_slice) >= 2 else calc_end_prices\n",
    "# #     calc_gains = (calc_end_prices / calc_close.bfill().iloc[0]) - 1\n",
    "# #     fwd_gains = (viz_end_prices / calc_end_prices) - 1\n",
    "# #     results_df = pd.DataFrame({'Rank': range(rank_start, rank_start + len(tickers_to_display)), 'Metric': metric, 'MetricValue': sorted_tickers.loc[tickers_to_display].values, 'CalcPrice': calc_end_prices.loc[tickers_to_display], 'CalcGain': calc_gains.loc[tickers_to_display], 'FwdGain': fwd_gains.loc[tickers_to_display]}, index=pd.Index(tickers_to_display, name='Ticker'))\n",
    "# #     if benchmark_price_series is not None and benchmark_ticker in calc_close.columns:\n",
    "# #         benchmark_df_row = pd.DataFrame({'Rank': np.nan, 'Metric': metric, 'MetricValue': metric_values[metric].get(benchmark_ticker, np.nan), 'CalcPrice': calc_end_prices[benchmark_ticker], 'CalcGain': calc_gains[benchmark_ticker], 'FwdGain': fwd_gains[benchmark_ticker]}, index=pd.Index([f\"{benchmark_ticker} (BM)\"], name='Ticker'))\n",
    "# #         results_df = pd.concat([results_df, benchmark_df_row])\n",
    "    \n",
    "# #     if debug:\n",
    "# #         df_trace = normalized_plot_data.copy()\n",
    "# #         df_trace.columns = [f'Norm_Price_{c}' for c in df_trace.columns]\n",
    "# #         df_trace['Norm_Price_Portfolio'] = portfolio_series\n",
    "# #         if benchmark_price_series is not None and not benchmark_price_series.loc[safe_start_date:safe_viz_end_date].dropna().empty:\n",
    "# #             norm_bm = benchmark_price_series.loc[safe_start_date:safe_viz_end_date] / benchmark_price_series.loc[safe_start_date:].bfill().iloc[0]\n",
    "# #             df_trace[f'Norm_Price_Benchmark_{benchmark_ticker}'] = norm_bm\n",
    "# #         for col in df_trace.columns:\n",
    "# #             if 'Norm_Price' in col:\n",
    "# #                 df_trace[col.replace('Norm_Price', 'Return')] = df_trace[col].pct_change()\n",
    "# #         debug_data['portfolio_trace'] = df_trace\n",
    "\n",
    "# #     final_results = {\n",
    "# #         'tickers_to_display': tickers_to_display, 'normalized_plot_data': normalized_plot_data,\n",
    "# #         'portfolio_series': portfolio_series, 'benchmark_price_series': benchmark_price_series,\n",
    "# #         'performance_data': perf_data, 'results_df': results_df, 'actual_calc_end_ts': actual_calc_end_ts,\n",
    "# #         'safe_start_date': safe_start_date, 'safe_viz_end_date': safe_viz_end_date,\n",
    "# #         'error': None\n",
    "# #     }\n",
    "# #     return (final_results, debug_data)\n",
    "\n",
    "# # def run_walk_forward_step(df_close_full, df_high_full, df_low_full,\n",
    "# #                           master_trading_days,\n",
    "# #                           start_date, calc_period, fwd_period,\n",
    "# #                           metric, rank_start, rank_end, benchmark_ticker,\n",
    "# #                           debug=False):\n",
    "# #     debug_data = {} if debug else None\n",
    "    \n",
    "# #     try:\n",
    "# #         start_idx = master_trading_days.get_loc(start_date)\n",
    "# #     except KeyError:\n",
    "# #         return ({'error': f\"Start date {start_date.date()} is not a valid trading day.\"}, None)\n",
    "        \n",
    "# #     calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "# #     viz_end_idx = min(calc_end_idx + fwd_period, len(master_trading_days) - 1)\n",
    "\n",
    "# #     safe_start_date = master_trading_days[start_idx]\n",
    "# #     safe_calc_end_date = master_trading_days[calc_end_idx]\n",
    "# #     safe_viz_end_date = master_trading_days[viz_end_idx]\n",
    "    \n",
    "# #     if safe_start_date >= safe_calc_end_date:\n",
    "# #         return ({'error': \"Invalid date range (calc period has zero or negative length).\"}, None)\n",
    "\n",
    "# #     calc_close_raw = df_close_full.loc[safe_start_date:safe_calc_end_date]\n",
    "# #     calc_close = calc_close_raw.dropna(axis=1, how='all')\n",
    "# #     if calc_close.shape[1] == 0 or len(calc_close) < 2:\n",
    "# #         return ({'error': \"Not enough data in calc period.\"}, None)\n",
    "\n",
    "# #     first_prices = calc_close.bfill().iloc[0]\n",
    "# #     last_prices = calc_close.ffill().iloc[-1]\n",
    "# #     daily_returns = calc_close.bfill().ffill().pct_change()\n",
    "# #     mean_returns = daily_returns.mean()\n",
    "# #     std_returns = daily_returns.std()\n",
    "    \n",
    "# #     valid_tickers = calc_close.columns\n",
    "# #     calc_high = df_high_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "# #     calc_low = df_low_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "    \n",
    "# #     # <<< REFACTORED: Replaced the block of TR logic with a single call to the new helper function.\n",
    "# #     tr = calculate_true_range(calc_high, calc_low, df_close_full[valid_tickers])\n",
    "# #     atr = tr.ewm(alpha=1/14, adjust=False).mean()\n",
    "# #     atrp = (atr / calc_close).mean()\n",
    "\n",
    "# #     metric_values = {}\n",
    "# #     metric_values['Price'] = (last_prices / first_prices).dropna()\n",
    "# #     metric_values['Sharpe'] = (mean_returns / std_returns * np.sqrt(252)).fillna(0)\n",
    "# #     metric_values['Sharpe (ATR)'] = (mean_returns / atrp).fillna(0)\n",
    "\n",
    "# #     if debug:\n",
    "# #         df_ranking = pd.DataFrame({\n",
    "# #             'FirstPrice': first_prices, 'LastPrice': last_prices, 'MeanDailyReturn': mean_returns,\n",
    "# #             'StdDevDailyReturn': std_returns, 'MeanATRP': atrp, 'Metric_Price': metric_values['Price'],\n",
    "# #             'Metric_Sharpe': metric_values['Sharpe'], 'Metric_Sharpe (ATR)': metric_values['Sharpe (ATR)']\n",
    "# #         })\n",
    "# #         df_ranking.index.name = 'Ticker'\n",
    "# #         debug_data['ranking_metrics'] = df_ranking.sort_values(f'Metric_{metric}', ascending=False)\n",
    "\n",
    "# #     sorted_tickers = metric_values[metric].sort_values(ascending=False)\n",
    "# #     tickers_to_display = sorted_tickers.index[rank_start-1:rank_end].tolist()\n",
    "# #     if not tickers_to_display:\n",
    "# #         return ({'error': \"No tickers found for the selected rank.\"}, None)\n",
    "\n",
    "# #     normalized_plot_data = df_close_full[tickers_to_display].loc[safe_start_date:safe_viz_end_date]\n",
    "# #     normalized_plot_data = normalized_plot_data.div(normalized_plot_data.bfill().iloc[0])\n",
    "# #     actual_calc_end_ts = calc_close.index.max()\n",
    "# #     portfolio_series = normalized_plot_data.mean(axis=1)\n",
    "# #     portfolio_return_series = portfolio_series.pct_change()\n",
    "# #     benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "# #     benchmark_return_series = benchmark_price_series.loc[safe_start_date:safe_viz_end_date].bfill().ffill().pct_change() if benchmark_price_series is not None else pd.Series(dtype='float64')\n",
    "\n",
    "# #     # <<< BUG FIX: Slicing the return series correctly to prevent overlap.\n",
    "# #     try:\n",
    "# #         # Find the integer location of the calculation end date\n",
    "# #         boundary_loc = portfolio_return_series.index.get_loc(actual_calc_end_ts)\n",
    "        \n",
    "# #         # Calc period includes the boundary date\n",
    "# #         calc_portfolio_returns = portfolio_return_series.iloc[:boundary_loc + 1]\n",
    "# #         # Fwd period starts the day AFTER the boundary date\n",
    "# #         fwd_portfolio_returns = portfolio_return_series.iloc[boundary_loc + 1:]\n",
    "\n",
    "# #         # Do the same for the benchmark\n",
    "# #         bm_boundary_loc = benchmark_return_series.index.get_loc(actual_calc_end_ts)\n",
    "# #         calc_benchmark_returns = benchmark_return_series.iloc[:bm_boundary_loc + 1]\n",
    "# #         fwd_benchmark_returns = benchmark_return_series.iloc[bm_boundary_loc + 1:]\n",
    "\n",
    "# #     except (KeyError, IndexError):\n",
    "# #         # Fallback for cases where the index might not align perfectly\n",
    "# #         calc_portfolio_returns = portfolio_return_series.loc[:actual_calc_end_ts]\n",
    "# #         fwd_portfolio_returns = portfolio_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "# #         calc_benchmark_returns = benchmark_return_series.loc[:actual_calc_end_ts]\n",
    "# #         fwd_benchmark_returns = benchmark_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "\n",
    "\n",
    "# #     perf_data = {}\n",
    "# #     perf_data['calc_p_gain'] = calculate_gain(portfolio_series.loc[:actual_calc_end_ts])\n",
    "# #     perf_data['fwd_p_gain'] = calculate_gain(portfolio_series.loc[actual_calc_end_ts:])\n",
    "# #     perf_data['full_p_gain'] = calculate_gain(portfolio_series)\n",
    "    \n",
    "# #     # <<< BUG FIX: Use the corrected, non-overlapping return series for Sharpe calculations.\n",
    "# #     perf_data['calc_p_sharpe'] = calculate_sharpe(calc_portfolio_returns)\n",
    "# #     perf_data['fwd_p_sharpe'] = calculate_sharpe(fwd_portfolio_returns)\n",
    "# #     perf_data['full_p_sharpe'] = calculate_sharpe(portfolio_return_series)\n",
    "    \n",
    "# #     perf_data['calc_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:actual_calc_end_ts]) if benchmark_price_series is not None else np.nan\n",
    "# #     perf_data['fwd_b_gain'] = calculate_gain(benchmark_price_series.loc[actual_calc_end_ts:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "# #     perf_data['full_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "\n",
    "# #     perf_data['calc_b_sharpe'] = calculate_sharpe(calc_benchmark_returns)\n",
    "# #     perf_data['fwd_b_sharpe'] = calculate_sharpe(fwd_benchmark_returns)\n",
    "# #     perf_data['full_b_sharpe'] = calculate_sharpe(benchmark_return_series)\n",
    "\n",
    "# #     calc_end_prices = calc_close.ffill().iloc[-1]\n",
    "# #     fwd_close_slice = df_close_full.loc[actual_calc_end_ts:safe_viz_end_date]\n",
    "# #     viz_end_prices = fwd_close_slice.ffill().iloc[-1] if not fwd_close_slice.empty and len(fwd_close_slice) >= 2 else calc_end_prices\n",
    "# #     calc_gains = (calc_end_prices / calc_close.bfill().iloc[0]) - 1\n",
    "# #     fwd_gains = (viz_end_prices / calc_end_prices) - 1\n",
    "# #     results_df = pd.DataFrame({'Rank': range(rank_start, rank_start + len(tickers_to_display)), 'Metric': metric, 'MetricValue': sorted_tickers.loc[tickers_to_display].values, 'CalcPrice': calc_end_prices.loc[tickers_to_display], 'CalcGain': calc_gains.loc[tickers_to_display], 'FwdGain': fwd_gains.loc[tickers_to_display]}, index=pd.Index(tickers_to_display, name='Ticker'))\n",
    "# #     if benchmark_price_series is not None and benchmark_ticker in calc_close.columns:\n",
    "# #         benchmark_df_row = pd.DataFrame({'Rank': np.nan, 'Metric': metric, 'MetricValue': metric_values[metric].get(benchmark_ticker, np.nan), 'CalcPrice': calc_end_prices[benchmark_ticker], 'CalcGain': calc_gains[benchmark_ticker], 'FwdGain': fwd_gains[benchmark_ticker]}, index=pd.Index([f\"{benchmark_ticker} (BM)\"], name='Ticker'))\n",
    "# #         results_df = pd.concat([results_df, benchmark_df_row])\n",
    "    \n",
    "# #     if debug:\n",
    "# #         df_trace = normalized_plot_data.copy()\n",
    "# #         df_trace.columns = [f'Norm_Price_{c}' for c in df_trace.columns]\n",
    "# #         df_trace['Norm_Price_Portfolio'] = portfolio_series\n",
    "# #         if benchmark_price_series is not None and not benchmark_price_series.loc[safe_start_date:safe_viz_end_date].dropna().empty:\n",
    "# #             norm_bm = benchmark_price_series.loc[safe_start_date:safe_viz_end_date] / benchmark_price_series.loc[safe_start_date:].bfill().iloc[0]\n",
    "# #             df_trace[f'Norm_Price_Benchmark_{benchmark_ticker}'] = norm_bm\n",
    "# #         for col in df_trace.columns:\n",
    "# #             if 'Norm_Price' in col:\n",
    "# #                 df_trace[col.replace('Norm_Price', 'Return')] = df_trace[col].pct_change()\n",
    "# #         debug_data['portfolio_trace'] = df_trace\n",
    "\n",
    "# #     final_results = {\n",
    "# #         'tickers_to_display': tickers_to_display, 'normalized_plot_data': normalized_plot_data,\n",
    "# #         'portfolio_series': portfolio_series, 'benchmark_price_series': benchmark_price_series,\n",
    "# #         'performance_data': perf_data, 'results_df': results_df, 'actual_calc_end_ts': actual_calc_end_ts,\n",
    "# #         'safe_start_date': safe_start_date, 'safe_viz_end_date': safe_viz_end_date,\n",
    "# #         'error': None\n",
    "# #     }\n",
    "# #     return (final_results, debug_data)\n",
    "\n",
    "# def run_walk_forward_step(df_close_full, df_high_full, df_low_full,\n",
    "#                           master_trading_days,\n",
    "#                           start_date, calc_period, fwd_period,\n",
    "#                           metric, rank_start, rank_end, benchmark_ticker,\n",
    "#                           debug=False):\n",
    "#     debug_data = {} if debug else None\n",
    "    \n",
    "#     try:\n",
    "#         start_idx = master_trading_days.get_loc(start_date)\n",
    "#     except KeyError:\n",
    "#         return ({'error': f\"Start date {start_date.date()} is not a valid trading day.\"}, None)\n",
    "        \n",
    "#     calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "#     viz_end_idx = min(calc_end_idx + fwd_period, len(master_trading_days) - 1)\n",
    "\n",
    "#     safe_start_date = master_trading_days[start_idx]\n",
    "#     safe_calc_end_date = master_trading_days[calc_end_idx]\n",
    "#     safe_viz_end_date = master_trading_days[viz_end_idx]\n",
    "    \n",
    "#     if safe_start_date >= safe_calc_end_date:\n",
    "#         return ({'error': \"Invalid date range (calc period has zero or negative length).\"}, None)\n",
    "\n",
    "#     calc_close_raw = df_close_full.loc[safe_start_date:safe_calc_end_date]\n",
    "#     calc_close = calc_close_raw.dropna(axis=1, how='all')\n",
    "#     if calc_close.shape[1] == 0 or len(calc_close) < 2:\n",
    "#         return ({'error': \"Not enough data in calc period.\"}, None)\n",
    "\n",
    "#     first_prices = calc_close.bfill().iloc[0]\n",
    "#     last_prices = calc_close.ffill().iloc[-1]\n",
    "#     daily_returns = calc_close.bfill().ffill().pct_change()\n",
    "#     mean_returns = daily_returns.mean()\n",
    "#     std_returns = daily_returns.std()\n",
    "    \n",
    "#     valid_tickers = calc_close.columns\n",
    "#     calc_high = df_high_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "#     calc_low = df_low_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "    \n",
    "#     # <<< BUG FIX: Prepare a correctly sliced close series for the TR calculation.\n",
    "#     # We need to include one extra day at the start for the shift() to work.\n",
    "#     extended_start_idx = max(0, start_idx - 1)\n",
    "#     extended_start_date = master_trading_days[extended_start_idx]\n",
    "#     calc_close_for_tr = df_close_full[valid_tickers].loc[extended_start_date:safe_calc_end_date]\n",
    "    \n",
    "#     # Now, call the helper with correctly aligned data.\n",
    "#     tr = calculate_true_range(calc_high, calc_low, calc_close_for_tr)\n",
    "    \n",
    "#     atr = tr.ewm(alpha=1/14, adjust=False).mean()\n",
    "#     atrp = (atr / calc_close).mean()\n",
    "\n",
    "#     metric_values = {}\n",
    "#     metric_values['Price'] = (last_prices / first_prices).dropna()\n",
    "#     metric_values['Sharpe'] = (mean_returns / std_returns * np.sqrt(252)).fillna(0)\n",
    "#     metric_values['Sharpe (ATR)'] = (mean_returns / atrp).fillna(0)\n",
    "    \n",
    "#     # ... (the rest of the function is unchanged) ...\n",
    "#     if debug:\n",
    "#         df_ranking = pd.DataFrame({\n",
    "#             'FirstPrice': first_prices, 'LastPrice': last_prices, 'MeanDailyReturn': mean_returns,\n",
    "#             'StdDevDailyReturn': std_returns, 'MeanATRP': atrp, 'Metric_Price': metric_values['Price'],\n",
    "#             'Metric_Sharpe': metric_values['Sharpe'], 'Metric_Sharpe (ATR)': metric_values['Sharpe (ATR)']\n",
    "#         })\n",
    "#         df_ranking.index.name = 'Ticker'\n",
    "#         debug_data['ranking_metrics'] = df_ranking.sort_values(f'Metric_{metric}', ascending=False)\n",
    "\n",
    "#     sorted_tickers = metric_values[metric].sort_values(ascending=False)\n",
    "#     tickers_to_display = sorted_tickers.index[rank_start-1:rank_end].tolist()\n",
    "#     if not tickers_to_display:\n",
    "#         return ({'error': \"No tickers found for the selected rank.\"}, None)\n",
    "\n",
    "#     normalized_plot_data = df_close_full[tickers_to_display].loc[safe_start_date:safe_viz_end_date]\n",
    "#     normalized_plot_data = normalized_plot_data.div(normalized_plot_data.bfill().iloc[0])\n",
    "#     actual_calc_end_ts = calc_close.index.max()\n",
    "#     portfolio_series = normalized_plot_data.mean(axis=1)\n",
    "#     portfolio_return_series = portfolio_series.pct_change()\n",
    "#     benchmark_price_series = df_close_full.get( benchmark_ticker)\n",
    "#     benchmark_return_series = benchmark_price_series.loc[safe_start_date:safe_viz_end_date].bfill().ffill().pct_change() if benchmark_price_series is not None else pd.Series(dtype='float64')\n",
    "\n",
    "#     try:\n",
    "#         boundary_loc = portfolio_return_series.index.get_loc(actual_calc_end_ts)\n",
    "#         calc_portfolio_returns = portfolio_return_series.iloc[:boundary_loc + 1]\n",
    "#         fwd_portfolio_returns = portfolio_return_series.iloc[boundary_loc + 1:]\n",
    "#         bm_boundary_loc = benchmark_return_series.index.get_loc(actual_calc_end_ts)\n",
    "#         calc_benchmark_returns = benchmark_return_series.iloc[:bm_boundary_loc + 1]\n",
    "#         fwd_benchmark_returns = benchmark_return_series.iloc[bm_boundary_loc + 1:]\n",
    "#     except (KeyError, IndexError):\n",
    "#         calc_portfolio_returns = portfolio_return_series.loc[:actual_calc_end_ts]\n",
    "#         fwd_portfolio_returns = portfolio_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "#         calc_benchmark_returns = benchmark_return_series.loc[:actual_calc_end_ts]\n",
    "#         fwd_benchmark_returns = benchmark_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "\n",
    "#     perf_data = {}\n",
    "#     perf_data['calc_p_gain'] = calculate_gain(portfolio_series.loc[:actual_calc_end_ts])\n",
    "#     perf_data['fwd_p_gain'] = calculate_gain(portfolio_series.loc[actual_calc_end_ts:])\n",
    "#     perf_data['full_p_gain'] = calculate_gain(portfolio_series)\n",
    "#     perf_data['calc_p_sharpe'] = calculate_sharpe(calc_portfolio_returns)\n",
    "#     perf_data['fwd_p_sharpe'] = calculate_sharpe(fwd_portfolio_returns)\n",
    "#     perf_data['full_p_sharpe'] = calculate_sharpe(portfolio_return_series)\n",
    "#     perf_data['calc_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:actual_calc_end_ts]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['fwd_b_gain'] = calculate_gain(benchmark_price_series.loc[actual_calc_end_ts:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['full_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['calc_b_sharpe'] = calculate_sharpe(calc_benchmark_returns)\n",
    "#     perf_data['fwd_b_sharpe'] = calculate_sharpe(fwd_benchmark_returns)\n",
    "#     perf_data['full_b_sharpe'] = calculate_sharpe(benchmark_return_series)\n",
    "\n",
    "#     calc_end_prices = calc_close.ffill().iloc[-1]\n",
    "#     fwd_close_slice = df_close_full.loc[actual_calc_end_ts:safe_viz_end_date]\n",
    "#     viz_end_prices = fwd_close_slice.ffill().iloc[-1] if not fwd_close_slice.empty and len(fwd_close_slice) >= 2 else calc_end_prices\n",
    "#     calc_gains = (calc_end_prices / calc_close.bfill().iloc[0]) - 1\n",
    "#     fwd_gains = (viz_end_prices / calc_end_prices) - 1\n",
    "#     results_df = pd.DataFrame({'Rank': range(rank_start, rank_start + len(tickers_to_display)), 'Metric': metric, 'MetricValue': sorted_tickers.loc[tickers_to_display].values, 'CalcPrice': calc_end_prices.loc[tickers_to_display], 'CalcGain': calc_gains.loc[tickers_to_display], 'FwdGain': fwd_gains.loc[tickers_to_display]}, index=pd.Index(tickers_to_display, name='Ticker'))\n",
    "#     if benchmark_price_series is not None and benchmark_ticker in calc_close.columns:\n",
    "#         benchmark_df_row = pd.DataFrame({'Rank': np.nan, 'Metric': metric, 'MetricValue': metric_values[metric].get(benchmark_ticker, np.nan), 'CalcPrice': calc_end_prices[benchmark_ticker], 'CalcGain': calc_gains[benchmark_ticker], 'FwdGain': fwd_gains[benchmark_ticker]}, index=pd.Index([f\"{benchmark_ticker} (BM)\"], name='Ticker'))\n",
    "#         results_df = pd.concat([results_df, benchmark_df_row])\n",
    "    \n",
    "#     if debug:\n",
    "#         df_trace = normalized_plot_data.copy()\n",
    "#         df_trace.columns = [f'Norm_Price_{c}' for c in df_trace.columns]\n",
    "#         df_trace['Norm_Price_Portfolio'] = portfolio_series\n",
    "#         if benchmark_price_series is not None and not benchmark_price_series.loc[safe_start_date:safe_viz_end_date].dropna().empty:\n",
    "#             norm_bm = benchmark_price_series.loc[safe_start_date:safe_viz_end_date] / benchmark_price_series.loc[safe_start_date:].bfill().iloc[0]\n",
    "#             df_trace[f'Norm_Price_Benchmark_{benchmark_ticker}'] = norm_bm\n",
    "#         for col in df_trace.columns:\n",
    "#             if 'Norm_Price' in col:\n",
    "#                 df_trace[col.replace('Norm_Price', 'Return')] = df_trace[col].pct_change()\n",
    "#         debug_data['portfolio_trace'] = df_trace\n",
    "\n",
    "#     final_results = {\n",
    "#         'tickers_to_display': tickers_to_display, 'normalized_plot_data': normalized_plot_data,\n",
    "#         'portfolio_series': portfolio_series, 'benchmark_price_series': benchmark_price_series,\n",
    "#         'performance_data': perf_data, 'results_df': results_df, 'actual_calc_end_ts': actual_calc_end_ts,\n",
    "#         'safe_start_date': safe_start_date, 'safe_viz_end_date': safe_viz_end_date,\n",
    "#         'error': None\n",
    "#     }\n",
    "#     return (final_results, debug_data)\n",
    "\n",
    "# # --- C. DYNAMIC DATA QUALITY FILTER FUNCTIONS ---\n",
    "\n",
    "# def calculate_rolling_quality_metrics(df_ohlcv, window=252, min_periods=126, debug=False):\n",
    "#     # This function does not need changes, it is independent of the period logic.\n",
    "#     print(f\"--- Calculating Rolling Quality Metrics (Window: {window} days) ---\")\n",
    "#     df = df_ohlcv.copy()\n",
    "#     if not df.index.is_monotonic_increasing:\n",
    "#         df.sort_index(inplace=True)\n",
    "#     df['IsStale'] = np.where((df['Volume'] == 0) | (df['Adj High'] == df['Adj Low']), 1, 0)\n",
    "#     df['DollarVolume'] = df['Adj Close'] * df['Volume']\n",
    "#     df['HasSameVolumeAsPrevDay'] = (df.groupby(level='Ticker')['Volume'].diff() == 0).astype(int)\n",
    "#     grouped = df.groupby(level='Ticker')\n",
    "#     stale_pct = grouped['IsStale'].rolling(window=window, min_periods=min_periods).mean()\n",
    "#     median_vol = grouped['DollarVolume'].rolling(window=window, min_periods=min_periods).median()\n",
    "#     same_vol_count = grouped['HasSameVolumeAsPrevDay'].rolling(window=window, min_periods=min_periods).sum()\n",
    "#     quality_df = pd.concat([stale_pct, median_vol, same_vol_count], axis=1)\n",
    "#     quality_df.columns = ['RollingStalePct', 'RollingMedianVolume', 'RollingSameVolCount']\n",
    "#     quality_df.index = quality_df.index.droplevel(0)\n",
    "#     print(\"✅ Rolling metrics calculation complete.\")\n",
    "#     return quality_df\n",
    "\n",
    "# def get_eligible_universe(quality_metrics_df, filter_date, thresholds):\n",
    "#     # This function does not need changes.\n",
    "#     filter_date_ts = pd.to_datetime(filter_date)\n",
    "#     date_index = quality_metrics_df.index.get_level_values('Date').unique().sort_values()\n",
    "#     if filter_date_ts < date_index[0]:\n",
    "#         print(f\"Warning: Filter date {filter_date_ts.date()} is before the earliest data point. Returning empty universe.\")\n",
    "#         return []\n",
    "#     valid_prior_dates = date_index[date_index <= filter_date_ts]\n",
    "#     if valid_prior_dates.empty:\n",
    "#         print(f\"Warning: No available data found on or before {filter_date_ts.date()}. Returning empty universe.\")\n",
    "#         return []\n",
    "#     actual_date_to_use = valid_prior_dates[-1]\n",
    "#     if actual_date_to_use.date() != filter_date_ts.date():\n",
    "#         print(f\"ℹ️ Info: Filter date {filter_date_ts.date()} not found. Using previous available date {actual_date_to_use.date()}.\")\n",
    "#     metrics_on_date = quality_metrics_df.xs(actual_date_to_use, level='Date')\n",
    "#     mask = ((metrics_on_date['RollingMedianVolume'] >= thresholds['min_median_dollar_volume']) &\n",
    "#             (metrics_on_date['RollingStalePct'] <= thresholds['max_stale_pct']) &\n",
    "#             (metrics_on_date['RollingSameVolCount'] <= thresholds['max_same_vol_count']))\n",
    "#     eligible_tickers = metrics_on_date[mask].index.tolist()\n",
    "#     all_tickers = metrics_on_date.index.tolist()\n",
    "#     print(f\"Dynamic Filter ({filter_date_ts.date()}): Kept {len(eligible_tickers)} of {len(all_tickers)} tickers.\")\n",
    "#     return eligible_tickers    \n",
    "\n",
    "# # --- D. INTERACTIVE ANALYSIS & BACKTESTING TOOLS ---\n",
    "\n",
    "# def plot_walk_forward_analyzer(df_ohlcv, \n",
    "#                                default_start_date=None, default_calc_period=126, default_fwd_period=63,\n",
    "#                                default_metric='Sharpe (ATR)', default_rank_start=1, default_rank_end=10,\n",
    "#                                default_benchmark_ticker='VOO', master_calendar_ticker='VOO',\n",
    "#                                quality_thresholds={'min_median_dollar_volume': 1_000_000, 'max_stale_pct': 0.05, 'max_same_vol_count': 10},\n",
    "#                                debug=False):\n",
    "#     print(\"Initializing Walk-Forward Analyzer (using Trading Day Logic)...\")\n",
    "#     if not isinstance(df_ohlcv.index, pd.MultiIndex): raise ValueError(\"Input DataFrame must have a (Ticker, Date) MultiIndex.\")\n",
    "#     df_ohlcv = df_ohlcv.sort_index()\n",
    "\n",
    "#     # <<< NEW: Create the master trading day calendar.\n",
    "#     if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "#         raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "#     master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "#     print(f\"Master trading day calendar created from '{master_calendar_ticker}' ({len(master_trading_days)} days).\")\n",
    "\n",
    "#     print(\"Pre-calculating data quality metrics...\")\n",
    "#     quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "#     print(\"Pre-processing data (unstacking)...\")\n",
    "#     df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "#     df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "#     df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    \n",
    "#     start_date_picker = widgets.DatePicker(description='Start Date:', value=pd.to_datetime(default_start_date), disabled=False)\n",
    "    \n",
    "#     # <<< CHANGED: Using IntText for precise trading day counts.\n",
    "#     calc_period_input = widgets.IntText(value=default_calc_period, description='Calc Period (days):')\n",
    "#     fwd_period_input = widgets.IntText(value=default_fwd_period, description='Fwd Period (days):')\n",
    "\n",
    "#     metrics = ['Price', 'Sharpe', 'Sharpe (ATR)']\n",
    "#     metric_dropdown = widgets.Dropdown(options=metrics, value=default_metric, description='Metric:')\n",
    "#     rank_start_input = widgets.IntText(value=default_rank_start, description='Rank Start:')\n",
    "#     rank_end_input = widgets.IntText(value=default_rank_end, description='Rank End:')\n",
    "#     benchmark_ticker_input = widgets.Text(value=default_benchmark_ticker, description='Benchmark:', placeholder='Enter Ticker')\n",
    "#     update_button = widgets.Button(description=\"Update Chart\", button_style='primary')\n",
    "#     ticker_list_output = widgets.Output()\n",
    "#     results_container, debug_data_container = [None], [None]\n",
    "\n",
    "#     fig = go.FigureWidget()\n",
    "#     max_traces = 50\n",
    "#     for i in range(max_traces): fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name=f'placeholder_{i}', visible=False, showlegend=False))\n",
    "#     fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Benchmark', visible=True, showlegend=True, line=dict(color='black', width=3, dash='dash')))\n",
    "#     fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Group Portfolio', visible=True, showlegend=True, line=dict(color='green', width=3)))\n",
    "\n",
    "#     def update_plot(button_click):\n",
    "#         ticker_list_output.clear_output()\n",
    "        \n",
    "#         # <<< CHANGED: \"Snap-forward\" logic for the start date.\n",
    "#         start_date_raw = pd.to_datetime(start_date_picker.value)\n",
    "#         start_date_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "#         if start_date_idx >= len(master_trading_days):\n",
    "#             with ticker_list_output: print(f\"Error: Start date is after the last available trading day.\"); return\n",
    "#         actual_start_date = master_trading_days[start_date_idx]\n",
    "#         with ticker_list_output: \n",
    "#             if start_date_raw.date() != actual_start_date.date():\n",
    "#                 print(f\"ℹ️ Info: Start date {start_date_raw.date()} is not a trading day. Snapping forward to {actual_start_date.date()}.\")\n",
    "\n",
    "#         calc_period, fwd_period = calc_period_input.value, fwd_period_input.value\n",
    "#         metric = metric_dropdown.value\n",
    "#         rank_start, rank_end = rank_start_input.value, rank_end_input.value\n",
    "#         benchmark_ticker = benchmark_ticker_input.value.strip().upper()\n",
    "        \n",
    "#         # Input validation\n",
    "#         if rank_start > rank_end:\n",
    "#             with ticker_list_output: print(\"Error: 'Rank Start' must be <= 'Rank End'.\"); return\n",
    "#         if rank_start < 1 or calc_period < 2 or fwd_period < 1:\n",
    "#             with ticker_list_output: print(\"Error: Ranks must be >= 1, Calc Period >= 2, Fwd Period >= 1.\"); return\n",
    "\n",
    "#         eligible_tickers = get_eligible_universe(quality_metrics_df, actual_start_date, quality_thresholds)\n",
    "#         if not eligible_tickers:\n",
    "#             with ticker_list_output: print(f\"Error: No eligible tickers found on {actual_start_date.date()} with the current quality filters.\"); return\n",
    "#         df_close_step = df_close_full[eligible_tickers]; df_high_step = df_high_full[eligible_tickers]; df_low_step = df_low_full[eligible_tickers]\n",
    "\n",
    "#         # <<< CHANGED: Passing master_trading_days to the core engine.\n",
    "#         results, debug_output = run_walk_forward_step(\n",
    "#             df_close_step, df_high_step, df_low_step, master_trading_days,\n",
    "#             actual_start_date, calc_period, fwd_period, \n",
    "#             metric, rank_start, rank_end, benchmark_ticker, debug=debug\n",
    "#         )\n",
    "#         if results['error']:\n",
    "#             with ticker_list_output: print(f\"Error: {results['error']}\"); return\n",
    "\n",
    "#         # --- The rest of the plotting/reporting logic remains the same ---\n",
    "#         with fig.batch_update():\n",
    "#             for i in range(max_traces):\n",
    "#                 trace = fig.data[i]\n",
    "#                 if i < len(results['tickers_to_display']):\n",
    "#                     ticker = results['tickers_to_display'][i]; plot_data_series = results['normalized_plot_data'][ticker]\n",
    "#                     trace.x, trace.y, trace.name, trace.visible, trace.showlegend = plot_data_series.index, plot_data_series.values, ticker, True, True\n",
    "#                 else: trace.visible, trace.showlegend = False, False\n",
    "#             benchmark_trace = fig.data[max_traces]\n",
    "#             if results['benchmark_price_series'] is not None and not results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']].dropna().empty:\n",
    "#                 normalized_benchmark = results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']] / results['benchmark_price_series'].loc[results['safe_start_date']:].bfill().iloc[0]\n",
    "#                 benchmark_trace.x, benchmark_trace.y, benchmark_trace.name, benchmark_trace.visible = normalized_benchmark.index, normalized_benchmark, f\"Benchmark ({benchmark_ticker})\", True\n",
    "#             else: benchmark_trace.visible = False\n",
    "#             portfolio_trace = fig.data[max_traces + 1]\n",
    "#             portfolio_trace.x, portfolio_trace.y, portfolio_trace.name, portfolio_trace.visible = results['portfolio_series'].index, results['portfolio_series'], 'Group Portfolio', True\n",
    "#             fig.layout.shapes = []; fig.add_shape(type=\"line\", x0=results['actual_calc_end_ts'], y0=0, x1=results['actual_calc_end_ts'], y1=1, xref='x', yref='paper', line=dict(color=\"grey\", width=2, dash=\"dash\"))\n",
    "            \n",
    "#         results_container[0] = results; debug_data_container[0] = debug_output\n",
    "        \n",
    "#         with ticker_list_output:\n",
    "#             print(f\"Analysis Period: {results['safe_start_date'].date()} to {results['safe_viz_end_date'].date()}.\")\n",
    "#             pprint.pprint(results['tickers_to_display'])\n",
    "#             p = results['performance_data']\n",
    "#             rows = []\n",
    "#             rows.append({'Metric': 'Group Portfolio Gain', 'Full': p['full_p_gain'], 'Calc': p['calc_p_gain'], 'Fwd': p['fwd_p_gain']})\n",
    "#             if not np.isnan(p['full_b_gain']):\n",
    "#                 rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Gain', 'Full': p['full_b_gain'], 'Calc': p['calc_b_gain'], 'Fwd': p['fwd_b_gain']})\n",
    "#                 rows.append({'Metric': 'Gain Delta (vs Bm)', 'Full': p['full_p_gain'] - p['full_b_gain'], 'Calc': p['calc_p_gain'] - p['calc_b_gain'], 'Fwd': p['fwd_p_gain'] - p['fwd_b_gain']})\n",
    "#             rows.append({'Metric': 'Group Portfolio Sharpe', 'Full': p['full_p_sharpe'], 'Calc': p['calc_p_sharpe'], 'Fwd': p['fwd_p_sharpe']})\n",
    "#             if not np.isnan(p['full_b_sharpe']):\n",
    "#                 rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Sharpe', 'Full': p['full_b_sharpe'], 'Calc': p['calc_b_sharpe'], 'Fwd': p['fwd_b_sharpe']})\n",
    "#                 rows.append({'Metric': 'Sharpe Delta (vs Bm)', 'Full': p['full_p_sharpe'] - p['full_b_sharpe'], 'Calc': p['calc_p_sharpe'] - p['calc_b_sharpe'], 'Fwd': p['fwd_p_sharpe'] - p['fwd_b_sharpe']})\n",
    "#             report_df = pd.DataFrame(rows).set_index('Metric')\n",
    "#             gain_rows = [row for row in report_df.index if 'Gain' in row or 'Delta' in row]\n",
    "#             sharpe_rows = [row for row in report_df.index if 'Sharpe' in row]\n",
    "#             styled_df = report_df.style.format('{:+.2%}', na_rep='N/A', subset=(gain_rows, report_df.columns)).format('{:+.2f}', na_rep='N/A', subset=(sharpe_rows, report_df.columns)).set_properties(**{'text-align': 'right', 'width': '100px'}).set_table_styles([{'selector': 'th.col_heading', 'props': [('text-align', 'right')]}, {'selector': 'th.row_heading', 'props': [('text-align', 'left')]}])\n",
    "#             print(\"\\n--- Strategy Performance Summary ---\")\n",
    "#             display(styled_df)\n",
    "            \n",
    "#     fig.update_layout(title_text='Walk-Forward Performance Analysis', xaxis_title='Date', yaxis_title='Normalized Price (Start = 1)', hovermode='x unified', legend_title_text='Tickers (Ranked)', height=600, margin=dict(t=50))\n",
    "#     fig.add_hline(y=1, line_width=1, line_dash=\"dash\", line_color=\"grey\")\n",
    "#     update_button.on_click(update_plot)\n",
    "#     controls_row1 = widgets.HBox([start_date_picker, calc_period_input, fwd_period_input])\n",
    "#     controls_row2 = widgets.HBox([metric_dropdown, rank_start_input, rank_end_input, benchmark_ticker_input, update_button])\n",
    "#     ui_container = widgets.VBox([controls_row1, controls_row2, ticker_list_output], layout=widgets.Layout(margin='10px 0 20px 0'))\n",
    "#     display(ui_container, fig)\n",
    "#     update_plot(None)\n",
    "#     return (results_container, debug_data_container)\n",
    "\n",
    "\n",
    "# def run_full_backtest(df_ohlcv, strategy_params, quality_thresholds):\n",
    "#     print(f\"--- Running Full Forensic Backtest for Strategy: {strategy_params['metric']} (Top {strategy_params['rank_start']}-{strategy_params['rank_end']}) ---\")\n",
    "    \n",
    "#     # <<< CHANGED: Parameters are now integer trading days.\n",
    "#     start_date, end_date = pd.to_datetime(strategy_params['start_date']), pd.to_datetime(strategy_params['end_date'])\n",
    "#     calc_period, fwd_period = strategy_params['calc_period'], strategy_params['fwd_period']\n",
    "#     metric, rank_start, rank_end = strategy_params['metric'], strategy_params['rank_start'], strategy_params['rank_end']\n",
    "#     benchmark_ticker = strategy_params['benchmark_ticker']\n",
    "#     master_calendar_ticker = strategy_params.get('master_calendar_ticker', 'VOO')\n",
    "    \n",
    "#     # <<< NEW: Create master calendar and find start/end indices for the whole backtest.\n",
    "#     if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "#         raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "#     master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "    \n",
    "#     start_idx = master_trading_days.searchsorted(start_date)\n",
    "#     end_idx = master_trading_days.searchsorted(end_date, side='right')\n",
    "    \n",
    "#     quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "#     df_close_full = df_ohlcv['Adj Close'].unstack(level=0); df_high_full = df_ohlcv['Adj High'].unstack(level=0); df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    \n",
    "#     # <<< CHANGED: The main loop now iterates through indices of the master calendar.\n",
    "#     step_indices = range(start_idx, end_idx, fwd_period)\n",
    "#     all_fwd_gains, period_by_period_debug = [], {}\n",
    "\n",
    "#     print(f\"Simulating {len(step_indices)} periods from {master_trading_days[step_indices[0]].date()} to {master_trading_days[step_indices[-1]].date()}...\")\n",
    "#     for current_idx in tqdm(step_indices, desc=\"Backtest Progress\"):\n",
    "#         step_date = master_trading_days[current_idx]\n",
    "#         eligible_tickers = get_eligible_universe(quality_metrics_df, step_date, quality_thresholds)\n",
    "#         if not eligible_tickers: continue\n",
    "        \n",
    "#         df_close_step = df_close_full[eligible_tickers]; df_high_step = df_high_full[eligible_tickers]; df_low_step = df_low_full[eligible_tickers]\n",
    "        \n",
    "#         results, debug_output = run_walk_forward_step(\n",
    "#             df_close_step, df_high_step, df_low_step, master_trading_days,\n",
    "#             step_date, calc_period, fwd_period,\n",
    "#             metric, rank_start, rank_end, benchmark_ticker, debug=True\n",
    "#         )\n",
    "#         if results['error'] is None:\n",
    "#             fwd_series = results['portfolio_series'].loc[results['actual_calc_end_ts']:]\n",
    "#             all_fwd_gains.append(fwd_series.pct_change().dropna())\n",
    "#             period_by_period_debug[step_date.date().isoformat()] = debug_output\n",
    "            \n",
    "#     if not all_fwd_gains:\n",
    "#         print(\"Error: No valid periods were simulated.\"); return None\n",
    "\n",
    "#     strategy_returns = pd.concat(all_fwd_gains); strategy_equity_curve = (1 + strategy_returns).cumprod()\n",
    "#     benchmark_returns = df_close_full[benchmark_ticker].pct_change().loc[strategy_equity_curve.index]; benchmark_equity_curve = (1 + benchmark_returns).cumprod()\n",
    "#     cumulative_equity_df = pd.DataFrame({'Strategy_Equity': strategy_equity_curve, 'Benchmark_Equity': benchmark_equity_curve})\n",
    "    \n",
    "#     fig = go.Figure()\n",
    "#     fig.add_trace(go.Scatter(x=cumulative_equity_df.index, y=cumulative_equity_df['Strategy_Equity'], name='Strategy', line=dict(color='green')))\n",
    "#     fig.add_trace(go.Scatter(x=cumulative_equity_df.index, y=cumulative_equity_df['Benchmark_Equity'], name=f'Benchmark ({benchmark_ticker})', line=dict(color='black', dash='dash')))\n",
    "#     fig.update_layout(title=f\"Cumulative Performance: '{metric}' Strategy (Top {rank_start}-{rank_end})\", xaxis_title=\"Date\", yaxis_title=\"Cumulative Growth\")\n",
    "#     fig.show()\n",
    "\n",
    "#     final_backtest_results = {'cumulative_performance': cumulative_equity_df, 'period_by_period_debug': period_by_period_debug}\n",
    "#     print(\"\\n✅ Full backtest complete. Results object is ready for forensic analysis.\")\n",
    "#     return final_backtest_results\n",
    "\n",
    "\n",
    "# # --- E. VERIFICATION TOOLS (Updated for Trading Day Logic & Detailed Metrics) ---\n",
    "# ### Updated `E. VERIFICATION TOOLS` with CSV Export\n",
    "\n",
    "# # def verify_group_tickers_walk_forward_calculation(df_ohlcv, tickers_to_verify, benchmark_ticker,\n",
    "# #                                                   start_date, calc_period, fwd_period,\n",
    "# #                                                   master_calendar_ticker='VOO', export_csv=False):\n",
    "# #     \"\"\"\n",
    "# #     Verifies portfolio and benchmark performance using precise trading day periods.\n",
    "# #     \"\"\"\n",
    "# #     display(Markdown(f\"## Verification Report for Portfolio vs. Benchmark\"))\n",
    "# #     display(Markdown(f\"**Portfolio Tickers:** `{tickers_to_verify}`\\n**Benchmark Ticker:** `{benchmark_ticker}`\"))\n",
    "    \n",
    "# #     # --- Date Calculation using Master Calendar ---\n",
    "# #     if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "# #         raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "# #     master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "\n",
    "# #     start_date_raw = pd.to_datetime(start_date)\n",
    "# #     start_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "# #     if start_idx >= len(master_trading_days):\n",
    "# #         print(f\"Error: Start date {start_date_raw.date()} is after the last available trading day.\"); return\n",
    "# #     actual_start_date = master_trading_days[start_idx]\n",
    "    \n",
    "# #     calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "# #     fwd_end_idx = min(calc_end_idx + fwd_period, len(master_trading_days) - 1)\n",
    "    \n",
    "# #     actual_calc_end_date = master_trading_days[calc_end_idx]\n",
    "# #     actual_fwd_end_date = master_trading_days[fwd_end_idx]\n",
    "    \n",
    "# #     display(Markdown(f\"**Analysis Start:** `{actual_start_date.date()}` (Selected: `{start_date_raw.date()}`)\\n\"\n",
    "# #                     f\"**Calc End:** `{actual_calc_end_date.date()}` ({calc_period} trading days)\\n\"\n",
    "# #                     f\"**Fwd End:** `{actual_fwd_end_date.date()}` ({fwd_period} trading days)\"))\n",
    "\n",
    "# #     # --- Verification Logic ---\n",
    "# #     df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "# #     portfolio_prices_raw_slice = df_close_full[tickers_to_verify].loc[actual_start_date:actual_fwd_end_date]\n",
    "# #     portfolio_value_series = portfolio_prices_raw_slice.div(portfolio_prices_raw_slice.bfill().iloc[0]).mean(axis=1)\n",
    "# #     benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "\n",
    "# #     def print_verification_steps(title, price_series):\n",
    "# #         display(Markdown(f\"#### Verification for: `{title}`\"))\n",
    "# #         if price_series.dropna().shape[0] < 2: print(\"  - Not enough data points.\"); return {'gain': np.nan, 'sharpe': np.nan}\n",
    "# #         start_price, end_price = price_series.bfill().iloc[0], price_series.ffill().iloc[-1]\n",
    "# #         gain = (end_price / start_price) - 1\n",
    "# #         print(f\"Start Value ({price_series.first_valid_index().date()}): {start_price:,.4f}\\nEnd Value   ({price_series.last_valid_index().date()}): {end_price:,.4f}\\nGain = {gain:.2%}\")\n",
    "# #         returns = price_series.pct_change()\n",
    "# #         sharpe = calculate_sharpe(returns)\n",
    "# #         print(f\"Mean Daily Return: {returns.mean():.6f}\\nStd Dev: {returns.std():.6f}\\nSharpe = {sharpe:.2f}\")\n",
    "# #         return {'gain': gain, 'sharpe': sharpe}\n",
    "\n",
    "# #     display(Markdown(\"### A. Calculation Period\"))\n",
    "# #     perf_calc_p = print_verification_steps(\"Group Portfolio\", portfolio_value_series.loc[actual_start_date:actual_calc_end_date])\n",
    "# #     perf_calc_b = print_verification_steps(f\"Benchmark\", benchmark_price_series.loc[actual_start_date:actual_calc_end_date])\n",
    "# #     display(Markdown(\"### B. Forward Period\"))\n",
    "# #     perf_fwd_p = print_verification_steps(\"Group Portfolio\", portfolio_value_series.loc[actual_calc_end_date:actual_fwd_end_date])\n",
    "# #     perf_fwd_b = print_verification_steps(f\"Benchmark\", benchmark_price_series.loc[actual_calc_end_date:actual_fwd_end_date])\n",
    "\n",
    "# # def verify_ticker_ranking_metrics(df_ohlcv, ticker, start_date, calc_period,\n",
    "# #                                   master_calendar_ticker='VOO', export_csv=False):\n",
    "# #     \"\"\"\n",
    "# #     Verifies ranking metrics for a single ticker using precise trading day periods,\n",
    "# #     and displays detailed intermediate calculations for ATR and ATRP.\n",
    "# #     \"\"\"\n",
    "# #     display(Markdown(f\"## Verification Report for Ticker Ranking: `{ticker}`\"))\n",
    "    \n",
    "# #     # --- Date Calculation using Master Calendar ---\n",
    "# #     if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "# #         raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "# #     master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "\n",
    "# #     start_date_raw = pd.to_datetime(start_date)\n",
    "# #     start_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "# #     if start_idx >= len(master_trading_days):\n",
    "# #         print(f\"Error: Start date {start_date_raw.date()} is after the last available trading day.\"); return\n",
    "# #     actual_start_date = master_trading_days[start_idx]\n",
    "    \n",
    "# #     calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "# #     actual_calc_end_date = master_trading_days[calc_end_idx]\n",
    "\n",
    "# #     df_ticker = df_ohlcv.loc[ticker].sort_index()\n",
    "# #     calc_df = df_ticker.loc[actual_start_date:actual_calc_end_date].copy()\n",
    "# #     if calc_df.empty or len(calc_df) < 2: \n",
    "# #         print(\"No data or not enough data in calc period.\"); return\n",
    "\n",
    "# #     display(Markdown(\"### A. Calculation Period (for Ranking Metrics)\"))\n",
    "# #     display(Markdown(f\"**Period Start:** `{actual_start_date.date()}`\\n\"\n",
    "# #                     f\"**Period End:** `{actual_calc_end_date.date()}`\\n\"\n",
    "# #                     f\"**Total Trading Days:** `{len(calc_df)}` (Requested: `{calc_period}`)\"))\n",
    "    \n",
    "# #     # --- Detailed Calculation Breakdown ---\n",
    "# #     display(Markdown(\"#### Detailed Metric Calculation Data\"))\n",
    "    \n",
    "# #     # Use a temporary DataFrame for clarity\n",
    "# #     vdf = calc_df[['Adj High', 'Adj Low', 'Adj Close']].copy()\n",
    "    \n",
    "# #     # 1. Daily Return\n",
    "# #     vdf['Daily_Return'] = vdf['Adj Close'].pct_change()\n",
    "    \n",
    "# #     # 2. True Range (TR)\n",
    "# #     vdf['TR'] = np.maximum(vdf['Adj High'] - vdf['Adj Low'], \n",
    "# #                            abs(vdf['Adj High'] - vdf['Adj Close'].shift(1)),\n",
    "# #                            abs(vdf['Adj Low'] - vdf['Adj Close'].shift(1)))\n",
    "                           \n",
    "# #     # 3. Average True Range (ATR) - 14 period exponential moving average\n",
    "# #     vdf['ATR_14'] = vdf['TR'].ewm(alpha=1/14, adjust=False).mean()\n",
    "    \n",
    "# #     # 4. ATR Percent (ATRP)\n",
    "# #     vdf['ATRP'] = vdf['ATR_14'] / vdf['Adj Close']\n",
    "    \n",
    "# #     # Display the first and last few rows of the calculation\n",
    "# #     print(\"--- Start of Calculation Period ---\")\n",
    "# #     display(vdf.head())\n",
    "# #     print(\"\\n--- End of Calculation Period ---\")\n",
    "# #     display(vdf.tail())\n",
    "    \n",
    "# #     # --- Final Metric Summary ---\n",
    "# #     display(Markdown(\"#### `MetricValue` Verification Summary:\"))\n",
    "    \n",
    "# #     # 1. Price Metric\n",
    "# #     calc_start_price = vdf['Adj Close'].bfill().iloc[0]\n",
    "# #     calc_end_price = vdf['Adj Close'].ffill().iloc[-1]\n",
    "# #     price_metric = (calc_end_price / calc_start_price)\n",
    "# #     print(f\"1. Price Metric: (Last Price / First Price) = ({calc_end_price:.2f} / {calc_start_price:.2f}) = {price_metric:.4f}\")\n",
    "    \n",
    "# #     # 2. Sharpe Metric\n",
    "# #     daily_returns = vdf['Daily_Return'].dropna()\n",
    "# #     sharpe_ratio = calculate_sharpe(daily_returns)\n",
    "# #     print(f\"2. Sharpe Metric: (Mean Daily Return / Std Dev) * sqrt(252) = {sharpe_ratio:.4f}\")\n",
    "\n",
    "# #     # 3. Sharpe (ATR) Metric\n",
    "# #     atrp_mean = vdf['ATRP'].mean()\n",
    "# #     mean_daily_return = vdf['Daily_Return'].mean()\n",
    "# #     sharpe_atr = (mean_daily_return / atrp_mean) if atrp_mean > 0 else 0\n",
    "# #     print(f\"3. Sharpe (ATR) Metric: (Mean Daily Return / Mean ATRP) = ({mean_daily_return:.6f} / {atrp_mean:.6f}) = {sharpe_atr:.4f}\")\n",
    "\n",
    "\n",
    "# def verify_group_tickers_walk_forward_calculation(df_ohlcv, tickers_to_verify, benchmark_ticker,\n",
    "#                                                   start_date, calc_period, fwd_period,\n",
    "#                                                   master_calendar_ticker='VOO', export_csv=False):\n",
    "#     \"\"\"\n",
    "#     Verifies portfolio and benchmark performance using precise trading day periods.\n",
    "#     \"\"\"\n",
    "#     display(Markdown(f\"## Verification Report for Portfolio vs. Benchmark\"))\n",
    "#     display(Markdown(f\"**Portfolio Tickers:** `{tickers_to_verify}`\\n**Benchmark Ticker:** `{benchmark_ticker}`\"))\n",
    "    \n",
    "#     # --- Date Calculation using Master Calendar ---\n",
    "#     if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "#         raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "#     master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "\n",
    "#     start_date_raw = pd.to_datetime(start_date)\n",
    "#     start_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "#     if start_idx >= len(master_trading_days):\n",
    "#         print(f\"Error: Start date {start_date_raw.date()} is after the last available trading day.\"); return\n",
    "#     actual_start_date = master_trading_days[start_idx]\n",
    "    \n",
    "#     calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "#     fwd_end_idx = min(calc_end_idx + fwd_period, len(master_trading_days) - 1)\n",
    "    \n",
    "#     actual_calc_end_date = master_trading_days[calc_end_idx]\n",
    "#     actual_fwd_end_date = master_trading_days[fwd_end_idx]\n",
    "    \n",
    "#     display(Markdown(f\"**Analysis Start:** `{actual_start_date.date()}` (Selected: `{start_date_raw.date()}`)\\n\"\n",
    "#                     f\"**Calc End:** `{actual_calc_end_date.date()}` ({calc_period} trading days)\\n\"\n",
    "#                     f\"**Fwd End:** `{actual_fwd_end_date.date()}` ({fwd_period} trading days)\"))\n",
    "\n",
    "#     # --- Verification Logic ---\n",
    "#     df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "#     portfolio_prices_raw_slice = df_close_full[tickers_to_verify].loc[actual_start_date:actual_fwd_end_date]\n",
    "#     portfolio_value_series = portfolio_prices_raw_slice.div(portfolio_prices_raw_slice.bfill().iloc[0]).mean(axis=1)\n",
    "#     benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "    \n",
    "#     # <<< NEW: CSV Export Logic Added Here ---\n",
    "#     if export_csv:\n",
    "#         # Prepare a detailed DataFrame for export\n",
    "#         export_df = pd.DataFrame({\n",
    "#             'Portfolio_Normalized_Price': portfolio_value_series,\n",
    "#             'Portfolio_Daily_Return': portfolio_value_series.pct_change()\n",
    "#         })\n",
    "#         if benchmark_price_series is not None:\n",
    "#             norm_bm = benchmark_price_series.loc[actual_start_date:actual_fwd_end_date]\n",
    "#             norm_bm = norm_bm / norm_bm.bfill().iloc[0]\n",
    "#             export_df['Benchmark_Normalized_Price'] = norm_bm\n",
    "#             export_df['Benchmark_Daily_Return'] = norm_bm.pct_change()\n",
    "\n",
    "#         # Create directory and save file\n",
    "#         output_dir = 'export_csv'\n",
    "#         os.makedirs(output_dir, exist_ok=True)\n",
    "#         tickers_str = '_'.join(tickers_to_verify)\n",
    "#         filename = f\"verify_group_{actual_start_date.date()}_{tickers_str}.csv\"\n",
    "#         filepath = os.path.join(output_dir, filename)\n",
    "#         export_df.to_csv(filepath)\n",
    "#         print(f\"\\n✅ Data exported to: {filepath}\")\n",
    "#     # --- End of New CSV Logic ---\n",
    "\n",
    "#     def print_verification_steps(title, price_series):\n",
    "#         display(Markdown(f\"#### Verification for: `{title}`\"))\n",
    "#         if price_series.dropna().shape[0] < 2: print(\"  - Not enough data points.\"); return {'gain': np.nan, 'sharpe': np.nan}\n",
    "#         start_price, end_price = price_series.bfill().iloc[0], price_series.ffill().iloc[-1]\n",
    "#         gain = (end_price / start_price) - 1\n",
    "#         print(f\"Start Value ({price_series.first_valid_index().date()}): {start_price:,.4f}\\nEnd Value   ({price_series.last_valid_index().date()}): {end_price:,.4f}\\nGain = {gain:.2%}\")\n",
    "#         returns = price_series.pct_change()\n",
    "#         sharpe = calculate_sharpe(returns)\n",
    "#         print(f\"Mean Daily Return: {returns.mean():.6f}\\nStd Dev: {returns.std():.6f}\\nSharpe = {sharpe:.2f}\")\n",
    "#         return {'gain': gain, 'sharpe': sharpe}\n",
    "\n",
    "#     display(Markdown(\"### A. Calculation Period\"))\n",
    "#     perf_calc_p = print_verification_steps(\"Group Portfolio\", portfolio_value_series.loc[actual_start_date:actual_calc_end_date])\n",
    "#     perf_calc_b = print_verification_steps(f\"Benchmark\", benchmark_price_series.loc[actual_start_date:actual_calc_end_date])\n",
    "#     display(Markdown(\"### B. Forward Period\"))\n",
    "#     perf_fwd_p = print_verification_steps(\"Group Portfolio\", portfolio_value_series.loc[actual_calc_end_date:actual_fwd_end_date])\n",
    "#     perf_fwd_b = print_verification_steps(f\"Benchmark\", benchmark_price_series.loc[actual_calc_end_date:actual_fwd_end_date])\n",
    "\n",
    "\n",
    "# def verify_ticker_ranking_metrics(df_ohlcv, ticker, start_date, calc_period,\n",
    "#                                   master_calendar_ticker='VOO', export_csv=False):\n",
    "#     \"\"\"\n",
    "#     Verifies ranking metrics for a single ticker using precise trading day periods,\n",
    "#     and displays detailed intermediate calculations for ATR and ATRP.\n",
    "#     \"\"\"\n",
    "#     display(Markdown(f\"## Verification Report for Ticker Ranking: `{ticker}`\"))\n",
    "    \n",
    "#     # --- Date Calculation using Master Calendar ---\n",
    "#     if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "#         raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "#     master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "\n",
    "#     start_date_raw = pd.to_datetime(start_date)\n",
    "#     start_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "#     if start_idx >= len(master_trading_days):\n",
    "#         print(f\"Error: Start date {start_date_raw.date()} is after the last available trading day.\"); return\n",
    "#     actual_start_date = master_trading_days[start_idx]\n",
    "    \n",
    "#     calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "#     actual_calc_end_date = master_trading_days[calc_end_idx]\n",
    "\n",
    "#     df_ticker = df_ohlcv.loc[ticker].sort_index()\n",
    "#     calc_df = df_ticker.loc[actual_start_date:actual_calc_end_date].copy()\n",
    "#     if calc_df.empty or len(calc_df) < 2: \n",
    "#         print(\"No data or not enough data in calc period.\"); return\n",
    "\n",
    "#     display(Markdown(\"### A. Calculation Period (for Ranking Metrics)\"))\n",
    "#     display(Markdown(f\"**Period Start:** `{actual_start_date.date()}`\\n\"\n",
    "#                     f\"**Period End:** `{actual_calc_end_date.date()}`\\n\"\n",
    "#                     f\"**Total Trading Days:** `{len(calc_df)}` (Requested: `{calc_period}`)\"))\n",
    "    \n",
    "#     # --- Detailed Calculation Breakdown ---\n",
    "#     display(Markdown(\"#### Detailed Metric Calculation Data\"))\n",
    "    \n",
    "#     vdf = calc_df[['Adj High', 'Adj Low', 'Adj Close']].copy()\n",
    "#     vdf['Daily_Return'] = vdf['Adj Close'].pct_change()\n",
    "#     # <<< REFACTORED: Replaced the block of TR logic with a single call to the new helper function.\n",
    "#     vdf['TR'] = calculate_true_range(vdf['Adj High'], vdf['Adj Low'], vdf['Adj Close'])\n",
    "#     vdf['ATR_14'] = vdf['TR'].ewm(alpha=1/14, adjust=False).mean()\n",
    "#     vdf['ATRP'] = vdf['ATR_14'] / vdf['Adj Close']\n",
    "    \n",
    "#     print(\"--- Start of Calculation Period ---\")\n",
    "#     display(vdf.head())\n",
    "#     print(\"\\n--- End of Calculation Period ---\")\n",
    "#     display(vdf.tail())\n",
    "\n",
    "#     # <<< NEW: CSV Export Logic Added Here ---\n",
    "#     if export_csv:\n",
    "#         output_dir = 'export_csv'\n",
    "#         os.makedirs(output_dir, exist_ok=True)\n",
    "#         filename = f\"verify_ticker_{actual_start_date.date()}_{ticker}.csv\"\n",
    "#         filepath = os.path.join(output_dir, filename)\n",
    "#         vdf.to_csv(filepath)\n",
    "#         print(f\"\\n✅ Data exported to: {filepath}\")\n",
    "#     # --- End of New CSV Logic ---\n",
    "    \n",
    "#     # --- Final Metric Summary ---\n",
    "#     display(Markdown(\"#### `MetricValue` Verification Summary:\"))\n",
    "    \n",
    "#     calc_start_price = vdf['Adj Close'].bfill().iloc[0]\n",
    "#     calc_end_price = vdf['Adj Close'].ffill().iloc[-1]\n",
    "#     price_metric = (calc_end_price / calc_start_price)\n",
    "#     print(f\"1. Price Metric: (Last Price / First Price) = ({calc_end_price:.2f} / {calc_start_price:.2f}) = {price_metric:.4f}\")\n",
    "    \n",
    "#     daily_returns = vdf['Daily_Return'].dropna()\n",
    "#     sharpe_ratio = calculate_sharpe(daily_returns)\n",
    "#     print(f\"2. Sharpe Metric: (Mean Daily Return / Std Dev) * sqrt(252) = {sharpe_ratio:.4f}\")\n",
    "\n",
    "#     atrp_mean = vdf['ATRP'].mean()\n",
    "#     mean_daily_return = vdf['Daily_Return'].mean()\n",
    "#     sharpe_atr = (mean_daily_return / atrp_mean) if atrp_mean > 0 else 0\n",
    "#     print(f\"3. Sharpe (ATR) Metric: (Mean Daily Return / Mean ATRP) = ({mean_daily_return:.6f} / {atrp_mean:.6f}) = {sharpe_atr:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6b78fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ==============================================================================\n",
    "# # FINAL PROJECT FUNCTIONS (Golden Copy - TR Calculation Fixed)\n",
    "# # ==============================================================================\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import plotly.graph_objects as go\n",
    "# from datetime import datetime, date\n",
    "# import ipywidgets as widgets\n",
    "# from IPython.display import display, Markdown\n",
    "# import pprint\n",
    "# from tqdm.auto import tqdm\n",
    "# import re\n",
    "# import os\n",
    "\n",
    "# # --- A. HELPER FUNCTIONS ---\n",
    "\n",
    "# def calculate_gain(price_series: pd.Series):\n",
    "#     if price_series.dropna().shape[0] < 2: return np.nan\n",
    "#     return (price_series.ffill().iloc[-1] / price_series.bfill().iloc[0]) - 1\n",
    "\n",
    "# def calculate_sharpe(return_series: pd.Series):\n",
    "#     if return_series.dropna().shape[0] < 2: return np.nan\n",
    "#     std_dev = return_series.std()\n",
    "#     if std_dev > 0 and std_dev != np.inf:\n",
    "#         return (return_series.mean() / std_dev) * np.sqrt(252)\n",
    "#     return np.nan\n",
    "\n",
    "# # --- B. THE CORE CALCULATION ENGINE ---\n",
    "\n",
    "# def run_walk_forward_step(df_close_full, df_high_full, df_low_full,\n",
    "#                           master_trading_days,\n",
    "#                           start_date, calc_period, fwd_period,\n",
    "#                           metric, rank_start, rank_end, benchmark_ticker,\n",
    "#                           debug=False):\n",
    "#     debug_data = {} if debug else None\n",
    "    \n",
    "#     try:\n",
    "#         start_idx = master_trading_days.get_loc(start_date)\n",
    "#     except KeyError:\n",
    "#         return ({'error': f\"Start date {start_date.date()} is not a valid trading day.\"}, None)\n",
    "        \n",
    "#     calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "#     viz_end_idx = min(calc_end_idx + fwd_period, len(master_trading_days) - 1)\n",
    "\n",
    "#     safe_start_date = master_trading_days[start_idx]\n",
    "#     safe_calc_end_date = master_trading_days[calc_end_idx]\n",
    "#     safe_viz_end_date = master_trading_days[viz_end_idx]\n",
    "    \n",
    "#     if safe_start_date >= safe_calc_end_date:\n",
    "#         return ({'error': \"Invalid date range (calc period has zero or negative length).\"}, None)\n",
    "\n",
    "#     calc_close_raw = df_close_full.loc[safe_start_date:safe_calc_end_date]\n",
    "#     calc_close = calc_close_raw.dropna(axis=1, how='all')\n",
    "#     if calc_close.shape[1] == 0 or len(calc_close) < 2:\n",
    "#         return ({'error': \"Not enough data in calc period.\"}, None)\n",
    "\n",
    "#     first_prices = calc_close.bfill().iloc[0]\n",
    "#     last_prices = calc_close.ffill().iloc[-1]\n",
    "#     daily_returns = calc_close.bfill().ffill().pct_change()\n",
    "#     mean_returns = daily_returns.mean()\n",
    "#     std_returns = daily_returns.std()\n",
    "    \n",
    "#     valid_tickers = calc_close.columns\n",
    "#     calc_high = df_high_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "#     calc_low = df_low_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "    \n",
    "#     # <<< BUG FIX: Reverted to a robust, in-place True Range calculation to prevent index errors.\n",
    "#     # This logic is now self-contained and guaranteed to be aligned.\n",
    "#     prev_close = df_close_full[valid_tickers].shift(1).loc[safe_start_date:safe_calc_end_date]\n",
    "    \n",
    "#     tr_df = pd.DataFrame({\n",
    "#         'h_l': calc_high - calc_low,\n",
    "#         'h_pc': abs(calc_high - prev_close),\n",
    "#         'l_pc': abs(calc_low - prev_close)\n",
    "#     })\n",
    "#     tr = tr_df.max(axis=1)\n",
    "    \n",
    "#     atr = tr.ewm(alpha=1/14, adjust=False).mean()\n",
    "#     atrp = (atr / calc_close).mean()\n",
    "\n",
    "#     metric_values = {}\n",
    "#     metric_values['Price'] = (last_prices / first_prices).dropna()\n",
    "#     metric_values['Sharpe'] = (mean_returns / std_returns * np.sqrt(252)).fillna(0)\n",
    "#     metric_values['Sharpe (ATR)'] = (mean_returns / atrp).fillna(0)\n",
    "    \n",
    "#     if debug:\n",
    "#         df_ranking = pd.DataFrame({\n",
    "#             'FirstPrice': first_prices, 'LastPrice': last_prices, 'MeanDailyReturn': mean_returns,\n",
    "#             'StdDevDailyReturn': std_returns, 'MeanATRP': atrp, 'Metric_Price': metric_values['Price'],\n",
    "#             'Metric_Sharpe': metric_values['Sharpe'], 'Metric_Sharpe (ATR)': metric_values['Sharpe (ATR)']\n",
    "#         })\n",
    "#         df_ranking.index.name = 'Ticker'\n",
    "#         debug_data['ranking_metrics'] = df_ranking.sort_values(f'Metric_{metric}', ascending=False)\n",
    "\n",
    "#     sorted_tickers = metric_values[metric].sort_values(ascending=False)\n",
    "#     tickers_to_display = sorted_tickers.index[rank_start-1:rank_end].tolist()\n",
    "#     if not tickers_to_display:\n",
    "#         return ({'error': \"No tickers found for the selected rank.\"}, None)\n",
    "\n",
    "#     normalized_plot_data = df_close_full[tickers_to_display].loc[safe_start_date:safe_viz_end_date]\n",
    "#     normalized_plot_data = normalized_plot_data.div(normalized_plot_data.bfill().iloc[0])\n",
    "#     actual_calc_end_ts = calc_close.index.max()\n",
    "#     portfolio_series = normalized_plot_data.mean(axis=1)\n",
    "#     portfolio_return_series = portfolio_series.pct_change()\n",
    "#     benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "#     benchmark_return_series = benchmark_price_series.loc[safe_start_date:safe_viz_end_date].bfill().ffill().pct_change() if benchmark_price_series is not None else pd.Series(dtype='float64')\n",
    "\n",
    "#     try:\n",
    "#         boundary_loc = portfolio_return_series.index.get_loc(actual_calc_end_ts)\n",
    "#         calc_portfolio_returns = portfolio_return_series.iloc[:boundary_loc + 1]\n",
    "#         fwd_portfolio_returns = portfolio_return_series.iloc[boundary_loc + 1:]\n",
    "#         bm_boundary_loc = benchmark_return_series.index.get_loc(actual_calc_end_ts)\n",
    "#         calc_benchmark_returns = benchmark_return_series.iloc[:bm_boundary_loc + 1]\n",
    "#         fwd_benchmark_returns = benchmark_return_series.iloc[bm_boundary_loc + 1:]\n",
    "#     except (KeyError, IndexError):\n",
    "#         calc_portfolio_returns = portfolio_return_series.loc[:actual_calc_end_ts]\n",
    "#         fwd_portfolio_returns = portfolio_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "#         calc_benchmark_returns = benchmark_return_series.loc[:actual_calc_end_ts]\n",
    "#         fwd_benchmark_returns = benchmark_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "\n",
    "#     perf_data = {}\n",
    "#     perf_data['calc_p_gain'] = calculate_gain(portfolio_series.loc[:actual_calc_end_ts])\n",
    "#     perf_data['fwd_p_gain'] = calculate_gain(portfolio_series.loc[actual_calc_end_ts:])\n",
    "#     perf_data['full_p_gain'] = calculate_gain(portfolio_series)\n",
    "#     perf_data['calc_p_sharpe'] = calculate_sharpe(calc_portfolio_returns)\n",
    "#     perf_data['fwd_p_sharpe'] = calculate_sharpe(fwd_portfolio_returns)\n",
    "#     perf_data['full_p_sharpe'] = calculate_sharpe(portfolio_return_series)\n",
    "#     perf_data['calc_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:actual_calc_end_ts]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['fwd_b_gain'] = calculate_gain(benchmark_price_series.loc[actual_calc_end_ts:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['full_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['calc_b_sharpe'] = calculate_sharpe(calc_benchmark_returns)\n",
    "#     perf_data['fwd_b_sharpe'] = calculate_sharpe(fwd_benchmark_returns)\n",
    "#     perf_data['full_b_sharpe'] = calculate_sharpe(benchmark_return_series)\n",
    "\n",
    "#     calc_end_prices = calc_close.ffill().iloc[-1]\n",
    "#     fwd_close_slice = df_close_full.loc[actual_calc_end_ts:safe_viz_end_date]\n",
    "#     viz_end_prices = fwd_close_slice.ffill().iloc[-1] if not fwd_close_slice.empty and len(fwd_close_slice) >= 2 else calc_end_prices\n",
    "#     calc_gains = (calc_end_prices / calc_close.bfill().iloc[0]) - 1\n",
    "#     fwd_gains = (viz_end_prices / calc_end_prices) - 1\n",
    "#     results_df = pd.DataFrame({'Rank': range(rank_start, rank_start + len(tickers_to_display)), 'Metric': metric, 'MetricValue': sorted_tickers.loc[tickers_to_display].values, 'CalcPrice': calc_end_prices.loc[tickers_to_display], 'CalcGain': calc_gains.loc[tickers_to_display], 'FwdGain': fwd_gains.loc[tickers_to_display]}, index=pd.Index(tickers_to_display, name='Ticker'))\n",
    "#     if benchmark_price_series is not None and benchmark_ticker in calc_close.columns:\n",
    "#         benchmark_df_row = pd.DataFrame({'Rank': np.nan, 'Metric': metric, 'MetricValue': metric_values[metric].get(benchmark_ticker, np.nan), 'CalcPrice': calc_end_prices[benchmark_ticker], 'CalcGain': calc_gains[benchmark_ticker], 'FwdGain': fwd_gains[benchmark_ticker]}, index=pd.Index([f\"{benchmark_ticker} (BM)\"], name='Ticker'))\n",
    "#         results_df = pd.concat([results_df, benchmark_df_row])\n",
    "    \n",
    "#     if debug:\n",
    "#         df_trace = normalized_plot_data.copy()\n",
    "#         df_trace.columns = [f'Norm_Price_{c}' for c in df_trace.columns]\n",
    "#         df_trace['Norm_Price_Portfolio'] = portfolio_series\n",
    "#         if benchmark_price_series is not None and not benchmark_price_series.loc[safe_start_date:safe_viz_end_date].dropna().empty:\n",
    "#             norm_bm = benchmark_price_series.loc[safe_start_date:safe_viz_end_date] / benchmark_price_series.loc[safe_start_date:].bfill().iloc[0]\n",
    "#             df_trace[f'Norm_Price_Benchmark_{benchmark_ticker}'] = norm_bm\n",
    "#         for col in df_trace.columns:\n",
    "#             if 'Norm_Price' in col:\n",
    "#                 df_trace[col.replace('Norm_Price', 'Return')] = df_trace[col].pct_change()\n",
    "#         debug_data['portfolio_trace'] = df_trace\n",
    "\n",
    "#     final_results = {\n",
    "#         'tickers_to_display': tickers_to_display, 'normalized_plot_data': normalized_plot_data,\n",
    "#         'portfolio_series': portfolio_series, 'benchmark_price_series': benchmark_price_series,\n",
    "#         'performance_data': perf_data, 'results_df': results_df, 'actual_calc_end_ts': actual_calc_end_ts,\n",
    "#         'safe_start_date': safe_start_date, 'safe_viz_end_date': safe_viz_end_date,\n",
    "#         'error': None\n",
    "#     }\n",
    "#     return (final_results, debug_data)\n",
    "\n",
    "# # --- C. DYNAMIC DATA QUALITY FILTER FUNCTIONS ---\n",
    "\n",
    "# def calculate_rolling_quality_metrics(df_ohlcv, window=252, min_periods=126, debug=False):\n",
    "#     print(f\"--- Calculating Rolling Quality Metrics (Window: {window} days) ---\")\n",
    "#     df = df_ohlcv.copy()\n",
    "#     if not df.index.is_monotonic_increasing:\n",
    "#         df.sort_index(inplace=True)\n",
    "#     df['IsStale'] = np.where((df['Volume'] == 0) | (df['Adj High'] == df['Adj Low']), 1, 0)\n",
    "#     df['DollarVolume'] = df['Adj Close'] * df['Volume']\n",
    "#     df['HasSameVolumeAsPrevDay'] = (df.groupby(level='Ticker')['Volume'].diff() == 0).astype(int)\n",
    "#     grouped = df.groupby(level='Ticker')\n",
    "#     stale_pct = grouped['IsStale'].rolling(window=window, min_periods=min_periods).mean()\n",
    "#     median_vol = grouped['DollarVolume'].rolling(window=window, min_periods=min_periods).median()\n",
    "#     same_vol_count = grouped['HasSameVolumeAsPrevDay'].rolling(window=window, min_periods=min_periods).sum()\n",
    "#     quality_df = pd.concat([stale_pct, median_vol, same_vol_count], axis=1)\n",
    "#     quality_df.columns = ['RollingStalePct', 'RollingMedianVolume', 'RollingSameVolCount']\n",
    "#     quality_df.index = quality_df.index.droplevel(0)\n",
    "#     print(\"✅ Rolling metrics calculation complete.\")\n",
    "#     return quality_df\n",
    "\n",
    "# def get_eligible_universe(quality_metrics_df, filter_date, thresholds):\n",
    "#     filter_date_ts = pd.to_datetime(filter_date)\n",
    "#     date_index = quality_metrics_df.index.get_level_values('Date').unique().sort_values()\n",
    "#     if filter_date_ts < date_index[0]:\n",
    "#         print(f\"Warning: Filter date {filter_date_ts.date()} is before the earliest data point. Returning empty universe.\")\n",
    "#         return []\n",
    "#     valid_prior_dates = date_index[date_index <= filter_date_ts]\n",
    "#     if valid_prior_dates.empty:\n",
    "#         print(f\"Warning: No available data found on or before {filter_date_ts.date()}. Returning empty universe.\")\n",
    "#         return []\n",
    "#     actual_date_to_use = valid_prior_dates[-1]\n",
    "#     if actual_date_to_use.date() != filter_date_ts.date():\n",
    "#         print(f\"ℹ️ Info: Filter date {filter_date_ts.date()} not found. Using previous available date {actual_date_to_use.date()}.\")\n",
    "#     metrics_on_date = quality_metrics_df.xs(actual_date_to_use, level='Date')\n",
    "#     mask = ((metrics_on_date['RollingMedianVolume'] >= thresholds['min_median_dollar_volume']) &\n",
    "#             (metrics_on_date['RollingStalePct'] <= thresholds['max_stale_pct']) &\n",
    "#             (metrics_on_date['RollingSameVolCount'] <= thresholds['max_same_vol_count']))\n",
    "#     eligible_tickers = metrics_on_date[mask].index.tolist()\n",
    "#     all_tickers = metrics_on_date.index.tolist()\n",
    "#     print(f\"Dynamic Filter ({filter_date_ts.date()}): Kept {len(eligible_tickers)} of {len(all_tickers)} tickers.\")\n",
    "#     return eligible_tickers    \n",
    "\n",
    "# # --- D. INTERACTIVE ANALYSIS & BACKTESTING TOOLS ---\n",
    "\n",
    "# def plot_walk_forward_analyzer(df_ohlcv, \n",
    "#                                default_start_date=None, default_calc_period=126, default_fwd_period=63,\n",
    "#                                default_metric='Sharpe (ATR)', default_rank_start=1, default_rank_end=10,\n",
    "#                                default_benchmark_ticker='VOO', master_calendar_ticker='VOO',\n",
    "#                                quality_thresholds={'min_median_dollar_volume': 1_000_000, 'max_stale_pct': 0.05, 'max_same_vol_count': 10},\n",
    "#                                debug=False):\n",
    "#     print(\"Initializing Walk-Forward Analyzer (using Trading Day Logic)...\")\n",
    "#     if not isinstance(df_ohlcv.index, pd.MultiIndex): raise ValueError(\"Input DataFrame must have a (Ticker, Date) MultiIndex.\")\n",
    "#     df_ohlcv = df_ohlcv.sort_index()\n",
    "\n",
    "#     if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "#         raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "#     master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "#     print(f\"Master trading day calendar created from '{master_calendar_ticker}' ({len(master_trading_days)} days).\")\n",
    "\n",
    "#     print(\"Pre-calculating data quality metrics...\")\n",
    "#     quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "#     print(\"Pre-processing data (unstacking)...\")\n",
    "#     df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "#     df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "#     df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    \n",
    "#     start_date_picker = widgets.DatePicker(description='Start Date:', value=pd.to_datetime(default_start_date), disabled=False)\n",
    "#     calc_period_input = widgets.IntText(value=default_calc_period, description='Calc Period (days):')\n",
    "#     fwd_period_input = widgets.IntText(value=default_fwd_period, description='Fwd Period (days):')\n",
    "#     metrics = ['Price', 'Sharpe', 'Sharpe (ATR)']\n",
    "#     metric_dropdown = widgets.Dropdown(options=metrics, value=default_metric, description='Metric:')\n",
    "#     rank_start_input = widgets.IntText(value=default_rank_start, description='Rank Start:')\n",
    "#     rank_end_input = widgets.IntText(value=default_rank_end, description='Rank End:')\n",
    "#     benchmark_ticker_input = widgets.Text(value=default_benchmark_ticker, description='Benchmark:', placeholder='Enter Ticker')\n",
    "#     update_button = widgets.Button(description=\"Update Chart\", button_style='primary')\n",
    "#     ticker_list_output = widgets.Output()\n",
    "#     results_container, debug_data_container = [None], [None]\n",
    "\n",
    "#     fig = go.FigureWidget()\n",
    "#     max_traces = 50\n",
    "#     for i in range(max_traces): fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name=f'placeholder_{i}', visible=False, showlegend=False))\n",
    "#     fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Benchmark', visible=True, showlegend=True, line=dict(color='black', width=3, dash='dash')))\n",
    "#     fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Group Portfolio', visible=True, showlegend=True, line=dict(color='green', width=3)))\n",
    "\n",
    "#     def update_plot(button_click):\n",
    "#         ticker_list_output.clear_output()\n",
    "#         start_date_raw = pd.to_datetime(start_date_picker.value)\n",
    "#         start_date_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "#         if start_date_idx >= len(master_trading_days):\n",
    "#             with ticker_list_output: print(f\"Error: Start date is after the last available trading day.\"); return\n",
    "#         actual_start_date = master_trading_days[start_date_idx]\n",
    "#         with ticker_list_output: \n",
    "#             if start_date_raw.date() != actual_start_date.date():\n",
    "#                 print(f\"ℹ️ Info: Start date {start_date_raw.date()} is not a trading day. Snapping forward to {actual_start_date.date()}.\")\n",
    "\n",
    "#         calc_period, fwd_period = calc_period_input.value, fwd_period_input.value\n",
    "#         metric = metric_dropdown.value\n",
    "#         rank_start, rank_end = rank_start_input.value, rank_end_input.value\n",
    "#         benchmark_ticker = benchmark_ticker_input.value.strip().upper()\n",
    "        \n",
    "#         if rank_start > rank_end:\n",
    "#             with ticker_list_output: print(\"Error: 'Rank Start' must be <= 'Rank End'.\"); return\n",
    "#         if rank_start < 1 or calc_period < 2 or fwd_period < 1:\n",
    "#             with ticker_list_output: print(\"Error: Ranks must be >= 1, Calc Period >= 2, Fwd Period >= 1.\"); return\n",
    "\n",
    "#         eligible_tickers = get_eligible_universe(quality_metrics_df, actual_start_date, quality_thresholds)\n",
    "#         if not eligible_tickers:\n",
    "#             with ticker_list_output: print(f\"Error: No eligible tickers found on {actual_start_date.date()} with the current quality filters.\"); return\n",
    "#         df_close_step = df_close_full[eligible_tickers]; df_high_step = df_high_full[eligible_tickers]; df_low_step = df_low_full[eligible_tickers]\n",
    "\n",
    "#         results, debug_output = run_walk_forward_step(\n",
    "#             df_close_step, df_high_step, df_low_step, master_trading_days,\n",
    "#             actual_start_date, calc_period, fwd_period, \n",
    "#             metric, rank_start, rank_end, benchmark_ticker, debug=debug\n",
    "#         )\n",
    "#         if results['error']:\n",
    "#             with ticker_list_output: print(f\"Error: {results['error']}\"); return\n",
    "\n",
    "#         with fig.batch_update():\n",
    "#             for i in range(max_traces):\n",
    "#                 trace = fig.data[i]\n",
    "#                 if i < len(results['tickers_to_display']):\n",
    "#                     ticker = results['tickers_to_display'][i]; plot_data_series = results['normalized_plot_data'][ticker]\n",
    "#                     trace.x, trace.y, trace.name, trace.visible, trace.showlegend = plot_data_series.index, plot_data_series.values, ticker, True, True\n",
    "#                 else: trace.visible, trace.showlegend = False, False\n",
    "#             benchmark_trace = fig.data[max_traces]\n",
    "#             if results['benchmark_price_series'] is not None and not results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']].dropna().empty:\n",
    "#                 normalized_benchmark = results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']] / results['benchmark_price_series'].loc[results['safe_start_date']:].bfill().iloc[0]\n",
    "#                 benchmark_trace.x, benchmark_trace.y, benchmark_trace.name, benchmark_trace.visible = normalized_benchmark.index, normalized_benchmark, f\"Benchmark ({benchmark_ticker})\", True\n",
    "#             else: benchmark_trace.visible = False\n",
    "#             portfolio_trace = fig.data[max_traces + 1]\n",
    "#             portfolio_trace.x, portfolio_trace.y, portfolio_trace.name, portfolio_trace.visible = results['portfolio_series'].index, results['portfolio_series'], 'Group Portfolio', True\n",
    "#             fig.layout.shapes = []; fig.add_shape(type=\"line\", x0=results['actual_calc_end_ts'], y0=0, x1=results['actual_calc_end_ts'], y1=1, xref='x', yref='paper', line=dict(color=\"grey\", width=2, dash=\"dash\"))\n",
    "            \n",
    "#         results_container[0] = results; debug_data_container[0] = debug_output\n",
    "        \n",
    "#         with ticker_list_output:\n",
    "#             print(f\"Analysis Period: {results['safe_start_date'].date()} to {results['safe_viz_end_date'].date()}.\")\n",
    "#             pprint.pprint(results['tickers_to_display'])\n",
    "#             p = results['performance_data']\n",
    "#             rows = []\n",
    "#             rows.append({'Metric': 'Group Portfolio Gain', 'Full': p['full_p_gain'], 'Calc': p['calc_p_gain'], 'Fwd': p['fwd_p_gain']})\n",
    "#             if not np.isnan(p['full_b_gain']):\n",
    "#                 rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Gain', 'Full': p['full_b_gain'], 'Calc': p['calc_b_gain'], 'Fwd': p['fwd_b_gain']})\n",
    "#                 rows.append({'Metric': 'Gain Delta (vs Bm)', 'Full': p['full_p_gain'] - p['full_b_gain'], 'Calc': p['calc_p_gain'] - p['calc_b_gain'], 'Fwd': p['fwd_p_gain'] - p['fwd_b_gain']})\n",
    "#             rows.append({'Metric': 'Group Portfolio Sharpe', 'Full': p['full_p_sharpe'], 'Calc': p['calc_p_sharpe'], 'Fwd': p['fwd_p_sharpe']})\n",
    "#             if not np.isnan(p['full_b_sharpe']):\n",
    "#                 rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Sharpe', 'Full': p['full_b_sharpe'], 'Calc': p['calc_b_sharpe'], 'Fwd': p['fwd_b_sharpe']})\n",
    "#                 rows.append({'Metric': 'Sharpe Delta (vs Bm)', 'Full': p['full_p_sharpe'] - p['full_b_sharpe'], 'Calc': p['calc_p_sharpe'] - p['calc_b_sharpe'], 'Fwd': p['fwd_p_sharpe'] - p['fwd_b_sharpe']})\n",
    "#             report_df = pd.DataFrame(rows).set_index('Metric')\n",
    "#             gain_rows = [row for row in report_df.index if 'Gain' in row or 'Delta' in row]\n",
    "#             sharpe_rows = [row for row in report_df.index if 'Sharpe' in row]\n",
    "#             styled_df = report_df.style.format('{:+.2%}', na_rep='N/A', subset=(gain_rows, report_df.columns)).format('{:+.2f}', na_rep='N/A', subset=(sharpe_rows, report_df.columns)).set_properties(**{'text-align': 'right', 'width': '100px'}).set_table_styles([{'selector': 'th.col_heading', 'props': [('text-align', 'right')]}, {'selector': 'th.row_heading', 'props': [('text-align', 'left')]}])\n",
    "#             print(\"\\n--- Strategy Performance Summary ---\")\n",
    "#             display(styled_df)\n",
    "            \n",
    "#     fig.update_layout(title_text='Walk-Forward Performance Analysis', xaxis_title='Date', yaxis_title='Normalized Price (Start = 1)', hovermode='x unified', legend_title_text='Tickers (Ranked)', height=600, margin=dict(t=50))\n",
    "#     fig.add_hline(y=1, line_width=1, line_dash=\"dash\", line_color=\"grey\")\n",
    "#     update_button.on_click(update_plot)\n",
    "#     controls_row1 = widgets.HBox([start_date_picker, calc_period_input, fwd_period_input])\n",
    "#     controls_row2 = widgets.HBox([metric_dropdown, rank_start_input, rank_end_input, benchmark_ticker_input, update_button])\n",
    "#     ui_container = widgets.VBox([controls_row1, controls_row2, ticker_list_output], layout=widgets.Layout(margin='10px 0 20px 0'))\n",
    "#     display(ui_container, fig)\n",
    "#     update_plot(None)\n",
    "#     return (results_container, debug_data_container)\n",
    "\n",
    "# def run_full_backtest(df_ohlcv, strategy_params, quality_thresholds):\n",
    "#     print(f\"--- Running Full Forensic Backtest for Strategy: {strategy_params['metric']} (Top {strategy_params['rank_start']}-{strategy_params['rank_end']}) ---\")\n",
    "    \n",
    "#     start_date, end_date = pd.to_datetime(strategy_params['start_date']), pd.to_datetime(strategy_params['end_date'])\n",
    "#     calc_period, fwd_period = strategy_params['calc_period'], strategy_params['fwd_period']\n",
    "#     metric, rank_start, rank_end = strategy_params['metric'], strategy_params['rank_start'], strategy_params['rank_end']\n",
    "#     benchmark_ticker = strategy_params['benchmark_ticker']\n",
    "#     master_calendar_ticker = strategy_params.get('master_calendar_ticker', 'VOO')\n",
    "    \n",
    "#     if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "#         raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "#     master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "    \n",
    "#     start_idx = master_trading_days.searchsorted(start_date)\n",
    "#     end_idx = master_trading_days.searchsorted(end_date, side='right')\n",
    "    \n",
    "#     quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "#     df_close_full = df_ohlcv['Adj Close'].unstack(level=0); df_high_full = df_ohlcv['Adj High'].unstack(level=0); df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    \n",
    "#     step_indices = range(start_idx, end_idx, fwd_period)\n",
    "#     all_fwd_gains, period_by_period_debug = [], {}\n",
    "\n",
    "#     print(f\"Simulating {len(step_indices)} periods from {master_trading_days[step_indices[0]].date()} to {master_trading_days[step_indices[-1]].date()}...\")\n",
    "#     for current_idx in tqdm(step_indices, desc=\"Backtest Progress\"):\n",
    "#         step_date = master_trading_days[current_idx]\n",
    "#         eligible_tickers = get_eligible_universe(quality_metrics_df, step_date, quality_thresholds)\n",
    "#         if not eligible_tickers: continue\n",
    "        \n",
    "#         df_close_step = df_close_full[eligible_tickers]; df_high_step = df_high_full[eligible_tickers]; df_low_step = df_low_full[eligible_tickers]\n",
    "        \n",
    "#         results, debug_output = run_walk_forward_step(\n",
    "#             df_close_step, df_high_step, df_low_step, master_trading_days,\n",
    "#             step_date, calc_period, fwd_period,\n",
    "#             metric, rank_start, rank_end, benchmark_ticker, debug=True\n",
    "#         )\n",
    "#         if results['error'] is None:\n",
    "#             fwd_series = results['portfolio_series'].loc[results['actual_calc_end_ts']:]\n",
    "#             all_fwd_gains.append(fwd_series.pct_change().dropna())\n",
    "#             period_by_period_debug[step_date.date().isoformat()] = debug_output\n",
    "            \n",
    "#     if not all_fwd_gains:\n",
    "#         print(\"Error: No valid periods were simulated.\"); return None\n",
    "\n",
    "#     strategy_returns = pd.concat(all_fwd_gains); strategy_equity_curve = (1 + strategy_returns).cumprod()\n",
    "#     benchmark_returns = df_close_full[benchmark_ticker].pct_change().loc[strategy_equity_curve.index]; benchmark_equity_curve = (1 + benchmark_returns).cumprod()\n",
    "#     cumulative_equity_df = pd.DataFrame({'Strategy_Equity': strategy_equity_curve, 'Benchmark_Equity': benchmark_equity_curve})\n",
    "    \n",
    "#     fig = go.Figure()\n",
    "#     fig.add_trace(go.Scatter(x=cumulative_equity_df.index, y=cumulative_equity_df['Strategy_Equity'], name='Strategy', line=dict(color='green')))\n",
    "#     fig.add_trace(go.Scatter(x=cumulative_equity_df.index, y=cumulative_equity_df['Benchmark_Equity'], name=f'Benchmark ({benchmark_ticker})', line=dict(color='black', dash='dash')))\n",
    "#     fig.update_layout(title=f\"Cumulative Performance: '{metric}' Strategy (Top {rank_start}-{rank_end})\", xaxis_title=\"Date\", yaxis_title=\"Cumulative Growth\")\n",
    "#     fig.show()\n",
    "\n",
    "#     final_backtest_results = {'cumulative_performance': cumulative_equity_df, 'period_by_period_debug': period_by_period_debug}\n",
    "#     print(\"\\n✅ Full backtest complete. Results object is ready for forensic analysis.\")\n",
    "#     return final_backtest_results\n",
    "\n",
    "# # --- E. VERIFICATION TOOLS (User Requested) ---\n",
    "\n",
    "# def verify_group_tickers_walk_forward_calculation(df_ohlcv, tickers_to_verify, benchmark_ticker,\n",
    "#                                                   start_date, calc_period, fwd_period,\n",
    "#                                                   master_calendar_ticker='VOO', export_csv=False):\n",
    "#     display(Markdown(f\"## Verification Report for Portfolio vs. Benchmark\"))\n",
    "#     display(Markdown(f\"**Portfolio Tickers:** `{tickers_to_verify}`\\n**Benchmark Ticker:** `{benchmark_ticker}`\"))\n",
    "    \n",
    "#     if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "#         raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "#     master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "\n",
    "#     start_date_raw = pd.to_datetime(start_date)\n",
    "#     start_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "#     if start_idx >= len(master_trading_days):\n",
    "#         print(f\"Error: Start date {start_date_raw.date()} is after the last available trading day.\"); return\n",
    "#     actual_start_date = master_trading_days[start_idx]\n",
    "    \n",
    "#     calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "#     fwd_end_idx = min(calc_end_idx + fwd_period, len(master_trading_days) - 1)\n",
    "    \n",
    "#     actual_calc_end_date = master_trading_days[calc_end_idx]\n",
    "#     actual_fwd_end_date = master_trading_days[fwd_end_idx]\n",
    "    \n",
    "#     display(Markdown(f\"**Analysis Start:** `{actual_start_date.date()}` (Selected: `{start_date_raw.date()}`)\\n\"\n",
    "#                     f\"**Calc End:** `{actual_calc_end_date.date()}` ({calc_period} trading days)\\n\"\n",
    "#                     f\"**Fwd End:** `{actual_fwd_end_date.date()}` ({fwd_period} trading days)\"))\n",
    "\n",
    "#     df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "#     portfolio_prices_raw_slice = df_close_full[tickers_to_verify].loc[actual_start_date:actual_fwd_end_date]\n",
    "#     portfolio_value_series = portfolio_prices_raw_slice.div(portfolio_prices_raw_slice.bfill().iloc[0]).mean(axis=1)\n",
    "#     benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "    \n",
    "#     if export_csv:\n",
    "#         export_df = pd.DataFrame({\n",
    "#             'Portfolio_Normalized_Price': portfolio_value_series,\n",
    "#             'Portfolio_Daily_Return': portfolio_value_series.pct_change()\n",
    "#         })\n",
    "#         if benchmark_price_series is not None:\n",
    "#             norm_bm = benchmark_price_series.loc[actual_start_date:actual_fwd_end_date]\n",
    "#             norm_bm = norm_bm / norm_bm.bfill().iloc[0]\n",
    "#             export_df['Benchmark_Normalized_Price'] = norm_bm\n",
    "#             export_df['Benchmark_Daily_Return'] = norm_bm.pct_change()\n",
    "\n",
    "#         output_dir = 'export_csv'\n",
    "#         os.makedirs(output_dir, exist_ok=True)\n",
    "#         tickers_str = '_'.join(tickers_to_verify)\n",
    "#         filename = f\"verify_group_{actual_start_date.date()}_{tickers_str}.csv\"\n",
    "#         filepath = os.path.join(output_dir, filename)\n",
    "#         export_df.to_csv(filepath)\n",
    "#         print(f\"\\n✅ Data exported to: {filepath}\")\n",
    "\n",
    "#     def print_verification_steps(title, price_series):\n",
    "#         display(Markdown(f\"#### Verification for: `{title}`\"))\n",
    "#         if price_series.dropna().shape[0] < 2: print(\"  - Not enough data points.\"); return {'gain': np.nan, 'sharpe': np.nan}\n",
    "#         start_price, end_price = price_series.bfill().iloc[0], price_series.ffill().iloc[-1]\n",
    "#         gain = (end_price / start_price) - 1\n",
    "#         print(f\"Start Value ({price_series.first_valid_index().date()}): {start_price:,.4f}\\nEnd Value   ({price_series.last_valid_index().date()}): {end_price:,.4f}\\nGain = {gain:.2%}\")\n",
    "#         returns = price_series.pct_change()\n",
    "#         sharpe = calculate_sharpe(returns)\n",
    "#         print(f\"Mean Daily Return: {returns.mean():.6f}\\nStd Dev: {returns.std():.6f}\\nSharpe = {sharpe:.2f}\")\n",
    "#         return {'gain': gain, 'sharpe': sharpe}\n",
    "\n",
    "#     display(Markdown(\"### A. Calculation Period\"))\n",
    "#     perf_calc_p = print_verification_steps(\"Group Portfolio\", portfolio_value_series.loc[actual_start_date:actual_calc_end_date])\n",
    "#     perf_calc_b = print_verification_steps(f\"Benchmark\", benchmark_price_series.loc[actual_start_date:actual_calc_end_date])\n",
    "#     display(Markdown(\"### B. Forward Period\"))\n",
    "#     perf_fwd_p = print_verification_steps(\"Group Portfolio\", portfolio_value_series.loc[actual_calc_end_date:actual_fwd_end_date])\n",
    "#     perf_fwd_b = print_verification_steps(f\"Benchmark\", benchmark_price_series.loc[actual_calc_end_date:actual_fwd_end_date])\n",
    "    \n",
    "\n",
    "# def verify_ticker_ranking_metrics(df_ohlcv, ticker, start_date, calc_period,\n",
    "#                                   master_calendar_ticker='VOO', export_csv=False):\n",
    "#     display(Markdown(f\"## Verification Report for Ticker Ranking: `{ticker}`\"))\n",
    "    \n",
    "#     if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "#         raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "#     master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "\n",
    "#     start_date_raw = pd.to_datetime(start_date)\n",
    "#     start_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "#     if start_idx >= len(master_trading_days):\n",
    "#         print(f\"Error: Start date {start_date_raw.date()} is after the last available trading day.\"); return\n",
    "#     actual_start_date = master_trading_days[start_idx]\n",
    "    \n",
    "#     calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "#     actual_calc_end_date = master_trading_days[calc_end_idx]\n",
    "\n",
    "#     df_ticker = df_ohlcv.loc[ticker].sort_index()\n",
    "#     calc_df = df_ticker.loc[actual_start_date:actual_calc_end_date].copy()\n",
    "#     if calc_df.empty or len(calc_df) < 2: \n",
    "#         print(\"No data or not enough data in calc period.\"); return\n",
    "\n",
    "#     display(Markdown(\"### A. Calculation Period (for Ranking Metrics)\"))\n",
    "#     display(Markdown(f\"**Period Start:** `{actual_start_date.date()}`\\n\"\n",
    "#                     f\"**Period End:** `{actual_calc_end_date.date()}`\\n\"\n",
    "#                     f\"**Total Trading Days:** `{len(calc_df)}` (Requested: `{calc_period}`)\"))\n",
    "    \n",
    "#     display(Markdown(\"#### Detailed Metric Calculation Data\"))\n",
    "    \n",
    "#     vdf = calc_df[['Adj High', 'Adj Low', 'Adj Close']].copy()\n",
    "#     vdf['Daily_Return'] = vdf['Adj Close'].pct_change()\n",
    "    \n",
    "#     # <<< BUG FIX: Reverted to a robust, in-place True Range calculation to prevent index errors.\n",
    "#     prev_close = df_ticker['Adj Close'].shift(1).loc[actual_start_date:actual_calc_end_date]\n",
    "#     tr_df = pd.DataFrame({\n",
    "#         'h_l': vdf['Adj High'] - vdf['Adj Low'],\n",
    "#         'h_pc': abs(vdf['Adj High'] - prev_close),\n",
    "#         'l_pc': abs(vdf['Adj Low'] - prev_close)\n",
    "#     })\n",
    "#     vdf['TR'] = tr_df.max(axis=1)\n",
    "    \n",
    "#     vdf['ATR_14'] = vdf['TR'].ewm(alpha=1/14, adjust=False).mean()\n",
    "#     vdf['ATRP'] = vdf['ATR_14'] / vdf['Adj Close']\n",
    "    \n",
    "#     print(\"--- Start of Calculation Period ---\")\n",
    "#     display(vdf.head())\n",
    "#     print(\"\\n--- End of Calculation Period ---\")\n",
    "#     display(vdf.tail())\n",
    "\n",
    "#     if export_csv:\n",
    "#         output_dir = 'export_csv'\n",
    "#         os.makedirs(output_dir, exist_ok=True)\n",
    "#         filename = f\"verify_ticker_{actual_start_date.date()}_{ticker}.csv\"\n",
    "#         filepath = os.path.join(output_dir, filename)\n",
    "#         vdf.to_csv(filepath)\n",
    "#         print(f\"\\n✅ Data exported to: {filepath}\")\n",
    "    \n",
    "#     display(Markdown(\"#### `MetricValue` Verification Summary:\"))\n",
    "    \n",
    "#     calc_start_price = vdf['Adj Close'].bfill().iloc[0]\n",
    "#     calc_end_price = vdf['Adj Close'].ffill().iloc[-1]\n",
    "#     price_metric = (calc_end_price / calc_start_price)\n",
    "#     print(f\"1. Price Metric: (Last Price / First Price) = ({calc_end_price:.2f} / {calc_start_price:.2f}) = {price_metric:.4f}\")\n",
    "    \n",
    "#     daily_returns = vdf['Daily_Return'].dropna()\n",
    "#     sharpe_ratio = calculate_sharpe(daily_returns)\n",
    "#     print(f\"2. Sharpe Metric: (Mean Daily Return / Std Dev) * sqrt(252) = {sharpe_ratio:.4f}\")\n",
    "\n",
    "#     atrp_mean = vdf['ATRP'].mean()\n",
    "#     mean_daily_return = vdf['Daily_Return'].mean()\n",
    "#     sharpe_atr = (mean_daily_return / atrp_mean) if atrp_mean > 0 else 0\n",
    "#     print(f\"3. Sharpe (ATR) Metric: (Mean Daily Return / Mean ATRP) = ({mean_daily_return:.6f} / {atrp_mean:.6f}) = {sharpe_atr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b390a0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ==============================================================================\n",
    "# # FINAL PROJECT FUNCTIONS (Golden Copy - Definitive TR Bug Fix)\n",
    "# # ==============================================================================\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import plotly.graph_objects as go\n",
    "# from datetime import datetime, date\n",
    "# import ipywidgets as widgets\n",
    "# from IPython.display import display, Markdown\n",
    "# import pprint\n",
    "# from tqdm.auto import tqdm\n",
    "# import re\n",
    "# import os\n",
    "\n",
    "# # --- A. HELPER FUNCTIONS ---\n",
    "\n",
    "# def calculate_gain(price_series: pd.Series):\n",
    "#     if price_series.dropna().shape[0] < 2: return np.nan\n",
    "#     return (price_series.ffill().iloc[-1] / price_series.bfill().iloc[0]) - 1\n",
    "\n",
    "# def calculate_sharpe(return_series: pd.Series):\n",
    "#     if return_series.dropna().shape[0] < 2: return np.nan\n",
    "#     std_dev = return_series.std()\n",
    "#     if std_dev > 0 and std_dev != np.inf:\n",
    "#         return (return_series.mean() / std_dev) * np.sqrt(252)\n",
    "#     return np.nan\n",
    "\n",
    "# # --- B. THE CORE CALCULATION ENGINE ---\n",
    "\n",
    "# def run_walk_forward_step(df_close_full, df_high_full, df_low_full,\n",
    "#                           master_trading_days,\n",
    "#                           start_date, calc_period, fwd_period,\n",
    "#                           metric, rank_start, rank_end, benchmark_ticker,\n",
    "#                           debug=False):\n",
    "#     debug_data = {} if debug else None\n",
    "    \n",
    "#     try:\n",
    "#         start_idx = master_trading_days.get_loc(start_date)\n",
    "#     except KeyError:\n",
    "#         return ({'error': f\"Start date {start_date.date()} is not a valid trading day.\"}, None)\n",
    "        \n",
    "#     calc_end_idx = min(start_idx + calc_period -1, len(master_trading_days) - 1) # -1 because period is inclusive\n",
    "#     viz_end_idx = min(calc_end_idx + fwd_period, len(master_trading_days) - 1)\n",
    "\n",
    "#     safe_start_date = master_trading_days[start_idx]\n",
    "#     safe_calc_end_date = master_trading_days[calc_end_idx]\n",
    "#     safe_viz_end_date = master_trading_days[viz_end_idx]\n",
    "    \n",
    "#     if safe_start_date >= safe_calc_end_date:\n",
    "#         return ({'error': \"Invalid date range (calc period has zero or negative length).\"}, None)\n",
    "\n",
    "#     calc_close_raw = df_close_full.loc[safe_start_date:safe_calc_end_date]\n",
    "#     calc_close = calc_close_raw.dropna(axis=1, how='all')\n",
    "#     if calc_close.shape[1] == 0 or len(calc_close) < 2:\n",
    "#         return ({'error': \"Not enough data in calc period.\"}, None)\n",
    "\n",
    "#     first_prices = calc_close.bfill().iloc[0]\n",
    "#     last_prices = calc_close.ffill().iloc[-1]\n",
    "#     daily_returns = calc_close.bfill().ffill().pct_change()\n",
    "#     mean_returns = daily_returns.mean()\n",
    "#     std_returns = daily_returns.std()\n",
    "    \n",
    "#     valid_tickers = calc_close.columns\n",
    "#     calc_high = df_high_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "#     calc_low = df_low_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "    \n",
    "#     # <<< DEFINITIVE BUG FIX: Robust, explicit slicing for previous close calculation.\n",
    "#     # 1. Get the index position of the start date\n",
    "#     prev_day_idx = max(0, start_idx - 1)\n",
    "#     prev_day_date = master_trading_days[prev_day_idx]\n",
    "#     # 2. Select close data over an extended range (one extra day at the start)\n",
    "#     extended_close = df_close_full[valid_tickers].loc[prev_day_date:safe_calc_end_date]\n",
    "#     # 3. Shift this smaller DataFrame, then slice it to the final exact window\n",
    "#     prev_close = extended_close.shift(1).loc[safe_start_date:safe_calc_end_date]\n",
    "\n",
    "#     tr_df = pd.DataFrame({\n",
    "#         'h_l': calc_high - calc_low,\n",
    "#         'h_pc': abs(calc_high - prev_close),\n",
    "#         'l_pc': abs(calc_low - prev_close)\n",
    "#     })\n",
    "#     tr = tr_df.max(axis=1)\n",
    "    \n",
    "#     atr = tr.ewm(alpha=1/14, adjust=False).mean()\n",
    "#     atrp = (atr / calc_close).mean()\n",
    "\n",
    "#     metric_values = {}\n",
    "#     metric_values['Price'] = (last_prices / first_prices).dropna()\n",
    "#     metric_values['Sharpe'] = (mean_returns / std_returns * np.sqrt(252)).fillna(0)\n",
    "#     metric_values['Sharpe (ATR)'] = (mean_returns / atrp).fillna(0)\n",
    "    \n",
    "#     if debug:\n",
    "#         df_ranking = pd.DataFrame({\n",
    "#             'FirstPrice': first_prices, 'LastPrice': last_prices, 'MeanDailyReturn': mean_returns,\n",
    "#             'StdDevDailyReturn': std_returns, 'MeanATRP': atrp, 'Metric_Price': metric_values['Price'],\n",
    "#             'Metric_Sharpe': metric_values['Sharpe'], 'Metric_Sharpe (ATR)': metric_values['Sharpe (ATR)']\n",
    "#         })\n",
    "#         df_ranking.index.name = 'Ticker'\n",
    "#         debug_data['ranking_metrics'] = df_ranking.sort_values(f'Metric_{metric}', ascending=False)\n",
    "\n",
    "#     sorted_tickers = metric_values[metric].sort_values(ascending=False)\n",
    "#     tickers_to_display = sorted_tickers.index[rank_start-1:rank_end].tolist()\n",
    "#     if not tickers_to_display:\n",
    "#         return ({'error': \"No tickers found for the selected rank.\"}, None)\n",
    "\n",
    "#     normalized_plot_data = df_close_full[tickers_to_display].loc[safe_start_date:safe_viz_end_date]\n",
    "#     normalized_plot_data = normalized_plot_data.div(normalized_plot_data.bfill().iloc[0])\n",
    "#     actual_calc_end_ts = calc_close.index.max()\n",
    "#     portfolio_series = normalized_plot_data.mean(axis=1)\n",
    "#     portfolio_return_series = portfolio_series.pct_change()\n",
    "#     benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "#     benchmark_return_series = benchmark_price_series.loc[safe_start_date:safe_viz_end_date].bfill().ffill().pct_change() if benchmark_price_series is not None else pd.Series(dtype='float64')\n",
    "\n",
    "#     try:\n",
    "#         boundary_loc = portfolio_return_series.index.get_loc(actual_calc_end_ts)\n",
    "#         calc_portfolio_returns = portfolio_return_series.iloc[:boundary_loc + 1]\n",
    "#         fwd_portfolio_returns = portfolio_return_series.iloc[boundary_loc + 1:]\n",
    "#         bm_boundary_loc = benchmark_return_series.index.get_loc(actual_calc_end_ts)\n",
    "#         calc_benchmark_returns = benchmark_return_series.iloc[:bm_boundary_loc + 1]\n",
    "#         fwd_benchmark_returns = benchmark_return_series.iloc[bm_boundary_loc + 1:]\n",
    "#     except (KeyError, IndexError):\n",
    "#         calc_portfolio_returns = portfolio_return_series.loc[:actual_calc_end_ts]\n",
    "#         fwd_portfolio_returns = portfolio_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "#         calc_benchmark_returns = benchmark_return_series.loc[:actual_calc_end_ts]\n",
    "#         fwd_benchmark_returns = benchmark_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "\n",
    "#     perf_data = {}\n",
    "#     perf_data['calc_p_gain'] = calculate_gain(portfolio_series.loc[:actual_calc_end_ts])\n",
    "#     perf_data['fwd_p_gain'] = calculate_gain(portfolio_series.loc[actual_calc_end_ts:])\n",
    "#     perf_data['full_p_gain'] = calculate_gain(portfolio_series)\n",
    "#     perf_data['calc_p_sharpe'] = calculate_sharpe(calc_portfolio_returns)\n",
    "#     perf_data['fwd_p_sharpe'] = calculate_sharpe(fwd_portfolio_returns)\n",
    "#     perf_data['full_p_sharpe'] = calculate_sharpe(portfolio_return_series)\n",
    "#     perf_data['calc_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:actual_calc_end_ts]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['fwd_b_gain'] = calculate_gain(benchmark_price_series.loc[actual_calc_end_ts:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['full_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['calc_b_sharpe'] = calculate_sharpe(calc_benchmark_returns)\n",
    "#     perf_data['fwd_b_sharpe'] = calculate_sharpe(fwd_benchmark_returns)\n",
    "#     perf_data['full_b_sharpe'] = calculate_sharpe(benchmark_return_series)\n",
    "\n",
    "#     calc_end_prices = calc_close.ffill().iloc[-1]\n",
    "#     fwd_close_slice = df_close_full.loc[actual_calc_end_ts:safe_viz_end_date]\n",
    "#     viz_end_prices = fwd_close_slice.ffill().iloc[-1] if not fwd_close_slice.empty and len(fwd_close_slice) >= 2 else calc_end_prices\n",
    "#     calc_gains = (calc_end_prices / calc_close.bfill().iloc[0]) - 1\n",
    "#     fwd_gains = (viz_end_prices / calc_end_prices) - 1\n",
    "#     results_df = pd.DataFrame({'Rank': range(rank_start, rank_start + len(tickers_to_display)), 'Metric': metric, 'MetricValue': sorted_tickers.loc[tickers_to_display].values, 'CalcPrice': calc_end_prices.loc[tickers_to_display], 'CalcGain': calc_gains.loc[tickers_to_display], 'FwdGain': fwd_gains.loc[tickers_to_display]}, index=pd.Index(tickers_to_display, name='Ticker'))\n",
    "#     if benchmark_price_series is not None and benchmark_ticker in calc_close.columns:\n",
    "#         benchmark_df_row = pd.DataFrame({'Rank': np.nan, 'Metric': metric, 'MetricValue': metric_values[metric].get(benchmark_ticker, np.nan), 'CalcPrice': calc_end_prices[benchmark_ticker], 'CalcGain': calc_gains[benchmark_ticker], 'FwdGain': fwd_gains[benchmark_ticker]}, index=pd.Index([f\"{benchmark_ticker} (BM)\"], name='Ticker'))\n",
    "#         results_df = pd.concat([results_df, benchmark_df_row])\n",
    "    \n",
    "#     if debug:\n",
    "#         df_trace = normalized_plot_data.copy()\n",
    "#         df_trace.columns = [f'Norm_Price_{c}' for c in df_trace.columns]\n",
    "#         df_trace['Norm_Price_Portfolio'] = portfolio_series\n",
    "#         if benchmark_price_series is not None and not benchmark_price_series.loc[safe_start_date:safe_viz_end_date].dropna().empty:\n",
    "#             norm_bm = benchmark_price_series.loc[safe_start_date:safe_viz_end_date] / benchmark_price_series.loc[safe_start_date:].bfill().iloc[0]\n",
    "#             df_trace[f'Norm_Price_Benchmark_{benchmark_ticker}'] = norm_bm\n",
    "#         for col in df_trace.columns:\n",
    "#             if 'Norm_Price' in col:\n",
    "#                 df_trace[col.replace('Norm_Price', 'Return')] = df_trace[col].pct_change()\n",
    "#         debug_data['portfolio_trace'] = df_trace\n",
    "\n",
    "#     final_results = {\n",
    "#         'tickers_to_display': tickers_to_display, 'normalized_plot_data': normalized_plot_data,\n",
    "#         'portfolio_series': portfolio_series, 'benchmark_price_series': benchmark_price_series,\n",
    "#         'performance_data': perf_data, 'results_df': results_df, 'actual_calc_end_ts': actual_calc_end_ts,\n",
    "#         'safe_start_date': safe_start_date, 'safe_viz_end_date': safe_viz_end_date,\n",
    "#         'error': None\n",
    "#     }\n",
    "#     return (final_results, debug_data)\n",
    "\n",
    "# # --- C. DYNAMIC DATA QUALITY FILTER FUNCTIONS ---\n",
    "\n",
    "# def calculate_rolling_quality_metrics(df_ohlcv, window=252, min_periods=126, debug=False):\n",
    "#     print(f\"--- Calculating Rolling Quality Metrics (Window: {window} days) ---\")\n",
    "#     df = df_ohlcv.copy()\n",
    "#     if not df.index.is_monotonic_increasing:\n",
    "#         df.sort_index(inplace=True)\n",
    "#     df['IsStale'] = np.where((df['Volume'] == 0) | (df['Adj High'] == df['Adj Low']), 1, 0)\n",
    "#     df['DollarVolume'] = df['Adj Close'] * df['Volume']\n",
    "#     df['HasSameVolumeAsPrevDay'] = (df.groupby(level='Ticker')['Volume'].diff() == 0).astype(int)\n",
    "#     grouped = df.groupby(level='Ticker')\n",
    "#     stale_pct = grouped['IsStale'].rolling(window=window, min_periods=min_periods).mean()\n",
    "#     median_vol = grouped['DollarVolume'].rolling(window=window, min_periods=min_periods).median()\n",
    "#     same_vol_count = grouped['HasSameVolumeAsPrevDay'].rolling(window=window, min_periods=min_periods).sum()\n",
    "#     quality_df = pd.concat([stale_pct, median_vol, same_vol_count], axis=1)\n",
    "#     quality_df.columns = ['RollingStalePct', 'RollingMedianVolume', 'RollingSameVolCount']\n",
    "#     quality_df.index = quality_df.index.droplevel(0)\n",
    "#     print(\"✅ Rolling metrics calculation complete.\")\n",
    "#     return quality_df\n",
    "\n",
    "# def get_eligible_universe(quality_metrics_df, filter_date, thresholds):\n",
    "#     filter_date_ts = pd.to_datetime(filter_date)\n",
    "#     date_index = quality_metrics_df.index.get_level_values('Date').unique().sort_values()\n",
    "#     if filter_date_ts < date_index[0]:\n",
    "#         print(f\"Warning: Filter date {filter_date_ts.date()} is before the earliest data point. Returning empty universe.\")\n",
    "#         return []\n",
    "#     valid_prior_dates = date_index[date_index <= filter_date_ts]\n",
    "#     if valid_prior_dates.empty:\n",
    "#         print(f\"Warning: No available data found on or before {filter_date_ts.date()}. Returning empty universe.\")\n",
    "#         return []\n",
    "#     actual_date_to_use = valid_prior_dates[-1]\n",
    "#     if actual_date_to_use.date() != filter_date_ts.date():\n",
    "#         print(f\"ℹ️ Info: Filter date {filter_date_ts.date()} not found. Using previous available date {actual_date_to_use.date()}.\")\n",
    "#     metrics_on_date = quality_metrics_df.xs(actual_date_to_use, level='Date')\n",
    "#     mask = ((metrics_on_date['RollingMedianVolume'] >= thresholds['min_median_dollar_volume']) &\n",
    "#             (metrics_on_date['RollingStalePct'] <= thresholds['max_stale_pct']) &\n",
    "#             (metrics_on_date['RollingSameVolCount'] <= thresholds['max_same_vol_count']))\n",
    "#     eligible_tickers = metrics_on_date[mask].index.tolist()\n",
    "#     all_tickers = metrics_on_date.index.tolist()\n",
    "#     print(f\"Dynamic Filter ({filter_date_ts.date()}): Kept {len(eligible_tickers)} of {len(all_tickers)} tickers.\")\n",
    "#     return eligible_tickers    \n",
    "\n",
    "# # --- D. INTERACTIVE ANALYSIS & BACKTESTING TOOLS ---\n",
    "\n",
    "# def plot_walk_forward_analyzer(df_ohlcv, \n",
    "#                                default_start_date=None, default_calc_period=126, default_fwd_period=63,\n",
    "#                                default_metric='Sharpe (ATR)', default_rank_start=1, default_rank_end=10,\n",
    "#                                default_benchmark_ticker='VOO', master_calendar_ticker='VOO',\n",
    "#                                quality_thresholds={'min_median_dollar_volume': 1_000_000, 'max_stale_pct': 0.05, 'max_same_vol_count': 10},\n",
    "#                                debug=False):\n",
    "#     print(\"Initializing Walk-Forward Analyzer (using Trading Day Logic)...\")\n",
    "#     if not isinstance(df_ohlcv.index, pd.MultiIndex): raise ValueError(\"Input DataFrame must have a (Ticker, Date) MultiIndex.\")\n",
    "#     df_ohlcv = df_ohlcv.sort_index()\n",
    "\n",
    "#     if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "#         raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "#     master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "#     print(f\"Master trading day calendar created from '{master_calendar_ticker}' ({len(master_trading_days)} days).\")\n",
    "\n",
    "#     print(\"Pre-calculating data quality metrics...\")\n",
    "#     quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "#     print(\"Pre-processing data (unstacking)...\")\n",
    "#     df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "#     df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "#     df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    \n",
    "#     start_date_picker = widgets.DatePicker(description='Start Date:', value=pd.to_datetime(default_start_date), disabled=False)\n",
    "#     calc_period_input = widgets.IntText(value=default_calc_period, description='Calc Period (days):')\n",
    "#     fwd_period_input = widgets.IntText(value=default_fwd_period, description='Fwd Period (days):')\n",
    "#     metrics = ['Price', 'Sharpe', 'Sharpe (ATR)']\n",
    "#     metric_dropdown = widgets.Dropdown(options=metrics, value=default_metric, description='Metric:')\n",
    "#     rank_start_input = widgets.IntText(value=default_rank_start, description='Rank Start:')\n",
    "#     rank_end_input = widgets.IntText(value=default_rank_end, description='Rank End:')\n",
    "#     benchmark_ticker_input = widgets.Text(value=default_benchmark_ticker, description='Benchmark:', placeholder='Enter Ticker')\n",
    "#     update_button = widgets.Button(description=\"Update Chart\", button_style='primary')\n",
    "#     ticker_list_output = widgets.Output()\n",
    "#     results_container, debug_data_container = [None], [None]\n",
    "\n",
    "#     fig = go.FigureWidget()\n",
    "#     max_traces = 50\n",
    "#     for i in range(max_traces): fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name=f'placeholder_{i}', visible=False, showlegend=False))\n",
    "#     fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Benchmark', visible=True, showlegend=True, line=dict(color='black', width=3, dash='dash')))\n",
    "#     fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Group Portfolio', visible=True, showlegend=True, line=dict(color='green', width=3)))\n",
    "\n",
    "#     def update_plot(button_click):\n",
    "#         ticker_list_output.clear_output()\n",
    "#         start_date_raw = pd.to_datetime(start_date_picker.value)\n",
    "#         start_date_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "#         if start_date_idx >= len(master_trading_days):\n",
    "#             with ticker_list_output: print(f\"Error: Start date is after the last available trading day.\"); return\n",
    "#         actual_start_date = master_trading_days[start_date_idx]\n",
    "#         with ticker_list_output: \n",
    "#             if start_date_raw.date() != actual_start_date.date():\n",
    "#                 print(f\"ℹ️ Info: Start date {start_date_raw.date()} is not a trading day. Snapping forward to {actual_start_date.date()}.\")\n",
    "\n",
    "#         calc_period, fwd_period = calc_period_input.value, fwd_period_input.value\n",
    "#         metric = metric_dropdown.value\n",
    "#         rank_start, rank_end = rank_start_input.value, rank_end_input.value\n",
    "#         benchmark_ticker = benchmark_ticker_input.value.strip().upper()\n",
    "        \n",
    "#         if rank_start > rank_end:\n",
    "#             with ticker_list_output: print(\"Error: 'Rank Start' must be <= 'Rank End'.\"); return\n",
    "#         if rank_start < 1 or calc_period < 2 or fwd_period < 1:\n",
    "#             with ticker_list_output: print(\"Error: Ranks must be >= 1, Calc Period >= 2, Fwd Period >= 1.\"); return\n",
    "\n",
    "#         eligible_tickers = get_eligible_universe(quality_metrics_df, actual_start_date, quality_thresholds)\n",
    "#         if not eligible_tickers:\n",
    "#             with ticker_list_output: print(f\"Error: No eligible tickers found on {actual_start_date.date()} with the current quality filters.\"); return\n",
    "#         df_close_step = df_close_full[eligible_tickers]; df_high_step = df_high_full[eligible_tickers]; df_low_step = df_low_full[eligible_tickers]\n",
    "\n",
    "#         results, debug_output = run_walk_forward_step(\n",
    "#             df_close_step, df_high_step, df_low_step, master_trading_days,\n",
    "#             actual_start_date, calc_period, fwd_period, \n",
    "#             metric, rank_start, rank_end, benchmark_ticker, debug=debug\n",
    "#         )\n",
    "#         if results['error']:\n",
    "#             with ticker_list_output: print(f\"Error: {results['error']}\"); return\n",
    "\n",
    "#         with fig.batch_update():\n",
    "#             for i in range(max_traces):\n",
    "#                 trace = fig.data[i]\n",
    "#                 if i < len(results['tickers_to_display']):\n",
    "#                     ticker = results['tickers_to_display'][i]; plot_data_series = results['normalized_plot_data'][ticker]\n",
    "#                     trace.x, trace.y, trace.name, trace.visible, trace.showlegend = plot_data_series.index, plot_data_series.values, ticker, True, True\n",
    "#                 else: trace.visible, trace.showlegend = False, False\n",
    "#             benchmark_trace = fig.data[max_traces]\n",
    "#             if results['benchmark_price_series'] is not None and not results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']].dropna().empty:\n",
    "#                 normalized_benchmark = results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']] / results['benchmark_price_series'].loc[results['safe_start_date']:].bfill().iloc[0]\n",
    "#                 benchmark_trace.x, benchmark_trace.y, benchmark_trace.name, benchmark_trace.visible = normalized_benchmark.index, normalized_benchmark, f\"Benchmark ({benchmark_ticker})\", True\n",
    "#             else: benchmark_trace.visible = False\n",
    "#             portfolio_trace = fig.data[max_traces + 1]\n",
    "#             portfolio_trace.x, portfolio_trace.y, portfolio_trace.name, portfolio_trace.visible = results['portfolio_series'].index, results['portfolio_series'], 'Group Portfolio', True\n",
    "#             fig.layout.shapes = []; fig.add_shape(type=\"line\", x0=results['actual_calc_end_ts'], y0=0, x1=results['actual_calc_end_ts'], y1=1, xref='x', yref='paper', line=dict(color=\"grey\", width=2, dash=\"dash\"))\n",
    "            \n",
    "#         results_container[0] = results; debug_data_container[0] = debug_output\n",
    "        \n",
    "#         with ticker_list_output:\n",
    "#             print(f\"Analysis Period: {results['safe_start_date'].date()} to {results['safe_viz_end_date'].date()}.\")\n",
    "#             pprint.pprint(results['tickers_to_display'])\n",
    "#             p = results['performance_data']\n",
    "#             rows = []\n",
    "#             rows.append({'Metric': 'Group Portfolio Gain', 'Full': p['full_p_gain'], 'Calc': p['calc_p_gain'], 'Fwd': p['fwd_p_gain']})\n",
    "#             if not np.isnan(p['full_b_gain']):\n",
    "#                 rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Gain', 'Full': p['full_b_gain'], 'Calc': p['calc_b_gain'], 'Fwd': p['fwd_b_gain']})\n",
    "#                 rows.append({'Metric': 'Gain Delta (vs Bm)', 'Full': p['full_p_gain'] - p['full_b_gain'], 'Calc': p['calc_p_gain'] - p['calc_b_gain'], 'Fwd': p['fwd_p_gain'] - p['fwd_b_gain']})\n",
    "#             rows.append({'Metric': 'Group Portfolio Sharpe', 'Full': p['full_p_sharpe'], 'Calc': p['calc_p_sharpe'], 'Fwd': p['fwd_p_sharpe']})\n",
    "#             if not np.isnan(p['full_b_sharpe']):\n",
    "#                 rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Sharpe', 'Full': p['full_b_sharpe'], 'Calc': p['calc_b_sharpe'], 'Fwd': p['fwd_b_sharpe']})\n",
    "#                 rows.append({'Metric': 'Sharpe Delta (vs Bm)', 'Full': p['full_p_sharpe'] - p['full_b_sharpe'], 'Calc': p['calc_p_sharpe'] - p['calc_b_sharpe'], 'Fwd': p['fwd_p_sharpe'] - p['fwd_b_sharpe']})\n",
    "#             report_df = pd.DataFrame(rows).set_index('Metric')\n",
    "#             gain_rows = [row for row in report_df.index if 'Gain' in row or 'Delta' in row]\n",
    "#             sharpe_rows = [row for row in report_df.index if 'Sharpe' in row]\n",
    "#             styled_df = report_df.style.format('{:+.2%}', na_rep='N/A', subset=(gain_rows, report_df.columns)).format('{:+.2f}', na_rep='N/A', subset=(sharpe_rows, report_df.columns)).set_properties(**{'text-align': 'right', 'width': '100px'}).set_table_styles([{'selector': 'th.col_heading', 'props': [('text-align', 'right')]}, {'selector': 'th.row_heading', 'props': [('text-align', 'left')]}])\n",
    "#             print(\"\\n--- Strategy Performance Summary ---\")\n",
    "#             display(styled_df)\n",
    "            \n",
    "#     fig.update_layout(title_text='Walk-Forward Performance Analysis', xaxis_title='Date', yaxis_title='Normalized Price (Start = 1)', hovermode='x unified', legend_title_text='Tickers (Ranked)', height=600, margin=dict(t=50))\n",
    "#     fig.add_hline(y=1, line_width=1, line_dash=\"dash\", line_color=\"grey\")\n",
    "#     update_button.on_click(update_plot)\n",
    "#     controls_row1 = widgets.HBox([start_date_picker, calc_period_input, fwd_period_input])\n",
    "#     controls_row2 = widgets.HBox([metric_dropdown, rank_start_input, rank_end_input, benchmark_ticker_input, update_button])\n",
    "#     ui_container = widgets.VBox([controls_row1, controls_row2, ticker_list_output], layout=widgets.Layout(margin='10px 0 20px 0'))\n",
    "#     display(ui_container, fig)\n",
    "#     update_plot(None)\n",
    "#     return (results_container, debug_data_container)\n",
    "\n",
    "# def run_full_backtest(df_ohlcv, strategy_params, quality_thresholds):\n",
    "#     print(f\"--- Running Full Forensic Backtest for Strategy: {strategy_params['metric']} (Top {strategy_params['rank_start']}-{strategy_params['rank_end']}) ---\")\n",
    "    \n",
    "#     start_date, end_date = pd.to_datetime(strategy_params['start_date']), pd.to_datetime(strategy_params['end_date'])\n",
    "#     calc_period, fwd_period = strategy_params['calc_period'], strategy_params['fwd_period']\n",
    "#     metric, rank_start, rank_end = strategy_params['metric'], strategy_params['rank_start'], strategy_params['rank_end']\n",
    "#     benchmark_ticker = strategy_params['benchmark_ticker']\n",
    "#     master_calendar_ticker = strategy_params.get('master_calendar_ticker', 'VOO')\n",
    "    \n",
    "#     if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "#         raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "#     master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "    \n",
    "#     start_idx = master_trading_days.searchsorted(start_date)\n",
    "#     end_idx = master_trading_days.searchsorted(end_date, side='right')\n",
    "    \n",
    "#     quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "#     df_close_full = df_ohlcv['Adj Close'].unstack(level=0); df_high_full = df_ohlcv['Adj High'].unstack(level=0); df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    \n",
    "#     step_indices = range(start_idx, end_idx, fwd_period)\n",
    "#     all_fwd_gains, period_by_period_debug = [], {}\n",
    "\n",
    "#     print(f\"Simulating {len(step_indices)} periods from {master_trading_days[step_indices[0]].date()} to {master_trading_days[step_indices[-1]].date()}...\")\n",
    "#     for current_idx in tqdm(step_indices, desc=\"Backtest Progress\"):\n",
    "#         step_date = master_trading_days[current_idx]\n",
    "#         eligible_tickers = get_eligible_universe(quality_metrics_df, step_date, quality_thresholds)\n",
    "#         if not eligible_tickers: continue\n",
    "        \n",
    "#         df_close_step = df_close_full[eligible_tickers]; df_high_step = df_high_full[eligible_tickers]; df_low_step = df_low_full[eligible_tickers]\n",
    "        \n",
    "#         results, debug_output = run_walk_forward_step(\n",
    "#             df_close_step, df_high_step, df_low_step, master_trading_days,\n",
    "#             step_date, calc_period, fwd_period,\n",
    "#             metric, rank_start, rank_end, benchmark_ticker, debug=True\n",
    "#         )\n",
    "#         if results['error'] is None:\n",
    "#             fwd_series = results['portfolio_series'].loc[results['actual_calc_end_ts']:]\n",
    "#             all_fwd_gains.append(fwd_series.pct_change().dropna())\n",
    "#             period_by_period_debug[step_date.date().isoformat()] = debug_output\n",
    "            \n",
    "#     if not all_fwd_gains:\n",
    "#         print(\"Error: No valid periods were simulated.\"); return None\n",
    "\n",
    "#     strategy_returns = pd.concat(all_fwd_gains); strategy_equity_curve = (1 + strategy_returns).cumprod()\n",
    "#     benchmark_returns = df_close_full[benchmark_ticker].pct_change().loc[strategy_equity_curve.index]; benchmark_equity_curve = (1 + benchmark_returns).cumprod()\n",
    "#     cumulative_equity_df = pd.DataFrame({'Strategy_Equity': strategy_equity_curve, 'Benchmark_Equity': benchmark_equity_curve})\n",
    "    \n",
    "#     fig = go.Figure()\n",
    "#     fig.add_trace(go.Scatter(x=cumulative_equity_df.index, y=cumulative_equity_df['Strategy_Equity'], name='Strategy', line=dict(color='green')))\n",
    "#     fig.add_trace(go.Scatter(x=cumulative_equity_df.index, y=cumulative_equity_df['Benchmark_Equity'], name=f'Benchmark ({benchmark_ticker})', line=dict(color='black', dash='dash')))\n",
    "#     fig.update_layout(title=f\"Cumulative Performance: '{metric}' Strategy (Top {rank_start}-{rank_end})\", xaxis_title=\"Date\", yaxis_title=\"Cumulative Growth\")\n",
    "#     fig.show()\n",
    "\n",
    "#     final_backtest_results = {'cumulative_performance': cumulative_equity_df, 'period_by_period_debug': period_by_period_debug}\n",
    "#     print(\"\\n✅ Full backtest complete. Results object is ready for forensic analysis.\")\n",
    "#     return final_backtest_results\n",
    "\n",
    "# # --- E. VERIFICATION TOOLS (User Requested) ---\n",
    "\n",
    "# def verify_group_tickers_walk_forward_calculation(df_ohlcv, tickers_to_verify, benchmark_ticker,\n",
    "#                                                   start_date, calc_period, fwd_period,\n",
    "#                                                   master_calendar_ticker='VOO', export_csv=False):\n",
    "#     display(Markdown(f\"## Verification Report for Portfolio vs. Benchmark\"))\n",
    "#     display(Markdown(f\"**Portfolio Tickers:** `{tickers_to_verify}`\\n**Benchmark Ticker:** `{benchmark_ticker}`\"))\n",
    "    \n",
    "#     if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "#         raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "#     master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "\n",
    "#     start_date_raw = pd.to_datetime(start_date)\n",
    "#     start_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "#     if start_idx >= len(master_trading_days):\n",
    "#         print(f\"Error: Start date {start_date_raw.date()} is after the last available trading day.\"); return\n",
    "#     actual_start_date = master_trading_days[start_idx]\n",
    "    \n",
    "#     calc_end_idx = min(start_idx + calc_period - 1, len(master_trading_days) - 1)\n",
    "#     fwd_end_idx = min(calc_end_idx + fwd_period, len(master_trading_days) - 1)\n",
    "    \n",
    "#     actual_calc_end_date = master_trading_days[calc_end_idx]\n",
    "#     actual_fwd_end_date = master_trading_days[fwd_end_idx]\n",
    "    \n",
    "#     display(Markdown(f\"**Analysis Start:** `{actual_start_date.date()}` (Selected: `{start_date_raw.date()}`)\\n\"\n",
    "#                     f\"**Calc End:** `{actual_calc_end_date.date()}` ({calc_period} trading days)\\n\"\n",
    "#                     f\"**Fwd End:** `{actual_fwd_end_date.date()}` ({fwd_period} trading days)\"))\n",
    "\n",
    "#     df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "#     portfolio_prices_raw_slice = df_close_full[tickers_to_verify].loc[actual_start_date:actual_fwd_end_date]\n",
    "#     portfolio_value_series = portfolio_prices_raw_slice.div(portfolio_prices_raw_slice.bfill().iloc[0]).mean(axis=1)\n",
    "#     benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "    \n",
    "#     if export_csv:\n",
    "#         export_df = pd.DataFrame({\n",
    "#             'Portfolio_Normalized_Price': portfolio_value_series,\n",
    "#             'Portfolio_Daily_Return': portfolio_value_series.pct_change()\n",
    "#         })\n",
    "#         if benchmark_price_series is not None:\n",
    "#             norm_bm = benchmark_price_series.loc[actual_start_date:actual_fwd_end_date]\n",
    "#             norm_bm = norm_bm / norm_bm.bfill().iloc[0]\n",
    "#             export_df['Benchmark_Normalized_Price'] = norm_bm\n",
    "#             export_df['Benchmark_Daily_Return'] = norm_bm.pct_change()\n",
    "\n",
    "#         output_dir = 'export_csv'\n",
    "#         os.makedirs(output_dir, exist_ok=True)\n",
    "#         tickers_str = '_'.join(tickers_to_verify)\n",
    "#         filename = f\"verify_group_{actual_start_date.date()}_{tickers_str}.csv\"\n",
    "#         filepath = os.path.join(output_dir, filename)\n",
    "#         export_df.to_csv(filepath)\n",
    "#         print(f\"\\n✅ Data exported to: {filepath}\")\n",
    "\n",
    "#     def print_verification_steps(title, price_series):\n",
    "#         display(Markdown(f\"#### Verification for: `{title}`\"))\n",
    "#         if price_series.dropna().shape[0] < 2: print(\"  - Not enough data points.\"); return {'gain': np.nan, 'sharpe': np.nan}\n",
    "#         start_price, end_price = price_series.bfill().iloc[0], price_series.ffill().iloc[-1]\n",
    "#         gain = (end_price / start_price) - 1\n",
    "#         print(f\"Start Value ({price_series.first_valid_index().date()}): {start_price:,.4f}\\nEnd Value   ({price_series.last_valid_index().date()}): {end_price:,.4f}\\nGain = {gain:.2%}\")\n",
    "#         returns = price_series.pct_change()\n",
    "#         sharpe = calculate_sharpe(returns)\n",
    "#         print(f\"Mean Daily Return: {returns.mean():.6f}\\nStd Dev: {returns.std():.6f}\\nSharpe = {sharpe:.2f}\")\n",
    "#         return {'gain': gain, 'sharpe': sharpe}\n",
    "\n",
    "#     display(Markdown(\"### A. Calculation Period\"))\n",
    "#     perf_calc_p = print_verification_steps(\"Group Portfolio\", portfolio_value_series.loc[actual_start_date:actual_calc_end_date])\n",
    "#     perf_calc_b = print_verification_steps(f\"Benchmark\", benchmark_price_series.loc[actual_start_date:actual_calc_end_date])\n",
    "#     display(Markdown(\"### B. Forward Period\"))\n",
    "#     perf_fwd_p = print_verification_steps(\"Group Portfolio\", portfolio_value_series.loc[actual_calc_end_date:actual_fwd_end_date])\n",
    "#     perf_fwd_b = print_verification_steps(f\"Benchmark\", benchmark_price_series.loc[actual_calc_end_date:actual_fwd_end_date])\n",
    "    \n",
    "\n",
    "# def verify_ticker_ranking_metrics(df_ohlcv, ticker, start_date, calc_period,\n",
    "#                                   master_calendar_ticker='VOO', export_csv=False):\n",
    "#     display(Markdown(f\"## Verification Report for Ticker Ranking: `{ticker}`\"))\n",
    "    \n",
    "#     if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "#         raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "#     master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "\n",
    "#     start_date_raw = pd.to_datetime(start_date)\n",
    "#     start_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "#     if start_idx >= len(master_trading_days):\n",
    "#         print(f\"Error: Start date {start_date_raw.date()} is after the last available trading day.\"); return\n",
    "#     actual_start_date = master_trading_days[start_idx]\n",
    "    \n",
    "#     calc_end_idx = min(start_idx + calc_period - 1, len(master_trading_days) - 1)\n",
    "#     actual_calc_end_date = master_trading_days[calc_end_idx]\n",
    "\n",
    "#     df_ticker = df_ohlcv.loc[ticker].sort_index()\n",
    "#     calc_df = df_ticker.loc[actual_start_date:actual_calc_end_date].copy()\n",
    "#     if calc_df.empty or len(calc_df) < 2: \n",
    "#         print(\"No data or not enough data in calc period.\"); return\n",
    "\n",
    "#     display(Markdown(\"### A. Calculation Period (for Ranking Metrics)\"))\n",
    "#     display(Markdown(f\"**Period Start:** `{actual_start_date.date()}`\\n\"\n",
    "#                     f\"**Period End:** `{actual_calc_end_date.date()}`\\n\"\n",
    "#                     f\"**Total Trading Days:** `{len(calc_df)}` (Requested: `{calc_period}`)\"))\n",
    "    \n",
    "#     display(Markdown(\"#### Detailed Metric Calculation Data\"))\n",
    "    \n",
    "#     vdf = calc_df[['Adj High', 'Adj Low', 'Adj Close']].copy()\n",
    "#     vdf['Daily_Return'] = vdf['Adj Close'].pct_change()\n",
    "    \n",
    "#     # <<< DEFINITIVE BUG FIX: Robust, explicit slicing for previous close calculation.\n",
    "#     # 1. Get the index position of the start date in the single ticker's index\n",
    "#     ticker_index = df_ticker.index\n",
    "#     ticker_start_idx = ticker_index.get_loc(actual_start_date)\n",
    "#     # 2. Go back one day\n",
    "#     prev_day_idx = max(0, ticker_start_idx - 1)\n",
    "#     prev_day_date = ticker_index[prev_day_idx]\n",
    "#     # 3. Select close data over the extended range\n",
    "#     extended_close = df_ticker['Adj Close'].loc[prev_day_date:actual_calc_end_date]\n",
    "#     # 4. Shift and slice to get the perfectly aligned previous close\n",
    "#     prev_close = extended_close.shift(1).loc[actual_start_date:actual_calc_end_date]\n",
    "\n",
    "#     tr_df = pd.DataFrame({\n",
    "#         'h_l': vdf['Adj High'] - vdf['Adj Low'],\n",
    "#         'h_pc': abs(vdf['Adj High'] - prev_close),\n",
    "#         'l_pc': abs(vdf['Adj Low'] - prev_close)\n",
    "#     })\n",
    "#     vdf['TR'] = tr_df.max(axis=1)\n",
    "    \n",
    "#     vdf['ATR_14'] = vdf['TR'].ewm(alpha=1/14, adjust=False).mean()\n",
    "#     vdf['ATRP'] = vdf['ATR_14'] / vdf['Adj Close']\n",
    "    \n",
    "#     print(\"--- Start of Calculation Period ---\")\n",
    "#     display(vdf.head())\n",
    "#     print(\"\\n--- End of Calculation Period ---\")\n",
    "#     display(vdf.tail())\n",
    "\n",
    "#     if export_csv:\n",
    "#         output_dir = 'export_csv'\n",
    "#         os.makedirs(output_dir, exist_ok=True)\n",
    "#         filename = f\"verify_ticker_{actual_start_date.date()}_{ticker}.csv\"\n",
    "#         filepath = os.path.join(output_dir, filename)\n",
    "#         vdf.to_csv(filepath)\n",
    "#         print(f\"\\n✅ Data exported to: {filepath}\")\n",
    "    \n",
    "#     display(Markdown(\"#### `MetricValue` Verification Summary:\"))\n",
    "    \n",
    "#     calc_start_price = vdf['Adj Close'].bfill().iloc[0]\n",
    "#     calc_end_price = vdf['Adj Close'].ffill().iloc[-1]\n",
    "#     price_metric = (calc_end_price / calc_start_price)\n",
    "#     print(f\"1. Price Metric: (Last Price / First Price) = ({calc_end_price:.2f} / {calc_start_price:.2f}) = {price_metric:.4f}\")\n",
    "    \n",
    "#     daily_returns = vdf['Daily_Return'].dropna()\n",
    "#     sharpe_ratio = calculate_sharpe(daily_returns)\n",
    "#     print(f\"2. Sharpe Metric: (Mean Daily Return / Std Dev) * sqrt(252) = {sharpe_ratio:.4f}\")\n",
    "\n",
    "#     atrp_mean = vdf['ATRP'].mean()\n",
    "#     mean_daily_return = vdf['Daily_Return'].mean()\n",
    "#     sharpe_atr = (mean_daily_return / atrp_mean) if atrp_mean > 0 else 0\n",
    "#     print(f\"3. Sharpe (ATR) Metric: (Mean Daily Return / Mean ATRP) = ({mean_daily_return:.6f} / {atrp_mean:.6f}) = {sharpe_atr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16930134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# GOLDEN COPY - COMPLETE PROJECT CODE (All Fixes Included)\n",
    "# Version: Trading Day Logic with Sharpe and TR Bug Fixes\n",
    "# ==============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime, date\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "import pprint\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "import os\n",
    "\n",
    "# --- A. HELPER FUNCTIONS ---\n",
    "\n",
    "def calculate_gain(price_series: pd.Series):\n",
    "    \"\"\"Calculates the total gain over a series of prices.\"\"\"\n",
    "    if price_series.dropna().shape[0] < 2: return np.nan\n",
    "    return (price_series.ffill().iloc[-1] / price_series.bfill().iloc[0]) - 1\n",
    "\n",
    "def calculate_sharpe(return_series: pd.Series):\n",
    "    \"\"\"Calculates the annualized Sharpe ratio from a series of daily returns.\"\"\"\n",
    "    if return_series.dropna().shape[0] < 2: return np.nan\n",
    "    std_dev = return_series.std()\n",
    "    if std_dev > 0 and std_dev != np.inf:\n",
    "        return (return_series.mean() / std_dev) * np.sqrt(252)\n",
    "    return np.nan\n",
    "\n",
    "# --- B. THE CORE CALCULATION ENGINE ---\n",
    "\n",
    "# def run_walk_forward_step(df_close_full, df_high_full, df_low_full,\n",
    "#                           master_trading_days,\n",
    "#                           start_date, calc_period, fwd_period,\n",
    "#                           metric, rank_start, rank_end, benchmark_ticker,\n",
    "#                           debug=False):\n",
    "#     \"\"\"Runs a single step of the walk-forward analysis using precise trading days.\"\"\"\n",
    "#     debug_data = {} if debug else None\n",
    "    \n",
    "#     try:\n",
    "#         start_idx = master_trading_days.get_loc(start_date)\n",
    "#     except KeyError:\n",
    "#         return ({'error': f\"Start date {start_date.date()} is not a valid trading day.\"}, None)\n",
    "        \n",
    "#     calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "#     viz_end_idx = min(calc_end_idx + fwd_period, len(master_trading_days) - 1)\n",
    "\n",
    "#     safe_start_date = master_trading_days[start_idx]\n",
    "#     safe_calc_end_date = master_trading_days[calc_end_idx]\n",
    "#     safe_viz_end_date = master_trading_days[viz_end_idx]\n",
    "    \n",
    "#     if safe_start_date >= safe_calc_end_date:\n",
    "#         return ({'error': \"Invalid date range (calc period has zero or negative length).\"}, None)\n",
    "\n",
    "#     calc_close_raw = df_close_full.loc[safe_start_date:safe_calc_end_date]\n",
    "#     calc_close = calc_close_raw.dropna(axis=1, how='all')\n",
    "#     if calc_close.shape[1] == 0 or len(calc_close) < 2:\n",
    "#         return ({'error': \"Not enough data in calc period.\"}, None)\n",
    "\n",
    "#     first_prices = calc_close.bfill().iloc[0]\n",
    "#     last_prices = calc_close.ffill().iloc[-1]\n",
    "#     daily_returns = calc_close.bfill().ffill().pct_change()\n",
    "#     mean_returns = daily_returns.mean()\n",
    "#     std_returns = daily_returns.std()\n",
    "    \n",
    "#     valid_tickers = calc_close.columns\n",
    "#     calc_high = df_high_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "#     calc_low = df_low_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "    \n",
    "#     # Corrected True Range calculation\n",
    "#     tr_df = pd.DataFrame({\n",
    "#         'h_l': calc_high - calc_low,\n",
    "#         'h_cp': abs(calc_high - df_close_full[valid_tickers].shift(1)),\n",
    "#         'l_cp': abs(calc_low - df_close_full[valid_tickers].shift(1))\n",
    "#     })\n",
    "#     tr = tr_df.max(axis=1)\n",
    "    \n",
    "#     atr = tr.ewm(alpha=1/14, adjust=False).mean()\n",
    "#     atrp = (atr / calc_close).mean()\n",
    "\n",
    "#     metric_values = {}\n",
    "#     metric_values['Price'] = (last_prices / first_prices).dropna()\n",
    "#     metric_values['Sharpe'] = (mean_returns / std_returns * np.sqrt(252)).fillna(0)\n",
    "#     metric_values['Sharpe (ATR)'] = (mean_returns / atrp).fillna(0)\n",
    "\n",
    "#     if debug:\n",
    "#         df_ranking = pd.DataFrame({\n",
    "#             'FirstPrice': first_prices, 'LastPrice': last_prices, 'MeanDailyReturn': mean_returns,\n",
    "#             'StdDevDailyReturn': std_returns, 'MeanATRP': atrp, 'Metric_Price': metric_values['Price'],\n",
    "#             'Metric_Sharpe': metric_values['Sharpe'], 'Metric_Sharpe (ATR)': metric_values['Sharpe (ATR)']\n",
    "#         })\n",
    "#         df_ranking.index.name = 'Ticker'\n",
    "#         debug_data['ranking_metrics'] = df_ranking.sort_values(f'Metric_{metric}', ascending=False)\n",
    "\n",
    "#     sorted_tickers = metric_values[metric].sort_values(ascending=False)\n",
    "#     tickers_to_display = sorted_tickers.index[rank_start-1:rank_end].tolist()\n",
    "#     if not tickers_to_display:\n",
    "#         return ({'error': \"No tickers found for the selected rank.\"}, None)\n",
    "\n",
    "#     normalized_plot_data = df_close_full[tickers_to_display].loc[safe_start_date:safe_viz_end_date]\n",
    "#     normalized_plot_data = normalized_plot_data.div(normalized_plot_data.bfill().iloc[0])\n",
    "#     actual_calc_end_ts = calc_close.index.max()\n",
    "#     portfolio_series = normalized_plot_data.mean(axis=1)\n",
    "#     portfolio_return_series = portfolio_series.pct_change()\n",
    "#     benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "#     benchmark_return_series = benchmark_price_series.loc[safe_start_date:safe_viz_end_date].bfill().ffill().pct_change() if benchmark_price_series is not None else pd.Series(dtype='float64')\n",
    "\n",
    "#     # Corrected slicing for Sharpe calculation to prevent overlap\n",
    "#     try:\n",
    "#         boundary_loc = portfolio_return_series.index.get_loc(actual_calc_end_ts)\n",
    "#         calc_portfolio_returns = portfolio_return_series.iloc[:boundary_loc + 1]\n",
    "#         fwd_portfolio_returns = portfolio_return_series.iloc[boundary_loc + 1:]\n",
    "        \n",
    "#         bm_boundary_loc = benchmark_return_series.index.get_loc(actual_calc_end_ts)\n",
    "#         calc_benchmark_returns = benchmark_return_series.iloc[:bm_boundary_loc + 1]\n",
    "#         fwd_benchmark_returns = benchmark_return_series.iloc[bm_boundary_loc + 1:]\n",
    "#     except (KeyError, IndexError):\n",
    "#         calc_portfolio_returns = portfolio_return_series.loc[:actual_calc_end_ts]\n",
    "#         fwd_portfolio_returns = portfolio_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "#         calc_benchmark_returns = benchmark_return_series.loc[:actual_calc_end_ts]\n",
    "#         fwd_benchmark_returns = benchmark_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "\n",
    "#     perf_data = {}\n",
    "#     perf_data['calc_p_gain'] = calculate_gain(portfolio_series.loc[:actual_calc_end_ts])\n",
    "#     perf_data['fwd_p_gain'] = calculate_gain(portfolio_series.loc[actual_calc_end_ts:])\n",
    "#     perf_data['full_p_gain'] = calculate_gain(portfolio_series)\n",
    "#     perf_data['calc_p_sharpe'] = calculate_sharpe(calc_portfolio_returns)\n",
    "#     perf_data['fwd_p_sharpe'] = calculate_sharpe(fwd_portfolio_returns)\n",
    "#     perf_data['full_p_sharpe'] = calculate_sharpe(portfolio_return_series)\n",
    "    \n",
    "#     perf_data['calc_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:actual_calc_end_ts]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['fwd_b_gain'] = calculate_gain(benchmark_price_series.loc[actual_calc_end_ts:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['full_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['calc_b_sharpe'] = calculate_sharpe(calc_benchmark_returns)\n",
    "#     perf_data['fwd_b_sharpe'] = calculate_sharpe(fwd_benchmark_returns)\n",
    "#     perf_data['full_b_sharpe'] = calculate_sharpe(benchmark_return_series)\n",
    "\n",
    "#     calc_end_prices = calc_close.ffill().iloc[-1]\n",
    "#     fwd_close_slice = df_close_full.loc[actual_calc_end_ts:safe_viz_end_date]\n",
    "#     viz_end_prices = fwd_close_slice.ffill().iloc[-1] if not fwd_close_slice.empty and len(fwd_close_slice) >= 2 else calc_end_prices\n",
    "#     calc_gains = (calc_end_prices / calc_close.bfill().iloc[0]) - 1\n",
    "#     fwd_gains = (viz_end_prices / calc_end_prices) - 1\n",
    "#     results_df = pd.DataFrame({'Rank': range(rank_start, rank_start + len(tickers_to_display)), 'Metric': metric, 'MetricValue': sorted_tickers.loc[tickers_to_display].values, 'CalcPrice': calc_end_prices.loc[tickers_to_display], 'CalcGain': calc_gains.loc[tickers_to_display], 'FwdGain': fwd_gains.loc[tickers_to_display]}, index=pd.Index(tickers_to_display, name='Ticker'))\n",
    "#     if benchmark_price_series is not None and benchmark_ticker in calc_close.columns:\n",
    "#         benchmark_df_row = pd.DataFrame({'Rank': np.nan, 'Metric': metric, 'MetricValue': metric_values[metric].get(benchmark_ticker, np.nan), 'CalcPrice': calc_end_prices[benchmark_ticker], 'CalcGain': calc_gains[benchmark_ticker], 'FwdGain': fwd_gains[benchmark_ticker]}, index=pd.Index([f\"{benchmark_ticker} (BM)\"], name='Ticker'))\n",
    "#         results_df = pd.concat([results_df, benchmark_df_row])\n",
    "    \n",
    "#     if debug:\n",
    "#         df_trace = normalized_plot_data.copy()\n",
    "#         df_trace.columns = [f'Norm_Price_{c}' for c in df_trace.columns]\n",
    "#         df_trace['Norm_Price_Portfolio'] = portfolio_series\n",
    "#         if benchmark_price_series is not None and not benchmark_price_series.loc[safe_start_date:safe_viz_end_date].dropna().empty:\n",
    "#             norm_bm = benchmark_price_series.loc[safe_start_date:safe_viz_end_date] / benchmark_price_series.loc[safe_start_date:].bfill().iloc[0]\n",
    "#             df_trace[f'Norm_Price_Benchmark_{benchmark_ticker}'] = norm_bm\n",
    "#         for col in df_trace.columns:\n",
    "#             if 'Norm_Price' in col:\n",
    "#                 df_trace[col.replace('Norm_Price', 'Return')] = df_trace[col].pct_change()\n",
    "#         debug_data['portfolio_trace'] = df_trace\n",
    "\n",
    "#     final_results = {\n",
    "#         'tickers_to_display': tickers_to_display, 'normalized_plot_data': normalized_plot_data,\n",
    "#         'portfolio_series': portfolio_series, 'benchmark_price_series': benchmark_price_series,\n",
    "#         'performance_data': perf_data, 'results_df': results_df, 'actual_calc_end_ts': actual_calc_end_ts,\n",
    "#         'safe_start_date': safe_start_date, 'safe_viz_end_date': safe_viz_end_date,\n",
    "#         'error': None\n",
    "#     }\n",
    "#     return (final_results, debug_data)\n",
    "\n",
    "# def run_walk_forward_step(df_close_full, df_high_full, df_low_full,\n",
    "#                           master_trading_days,\n",
    "#                           start_date, calc_period, fwd_period,\n",
    "#                           metric, rank_start, rank_end, benchmark_ticker,\n",
    "#                           debug=False):\n",
    "#     \"\"\"Runs a single step of the walk-forward analysis using precise trading days.\"\"\"\n",
    "#     debug_data = {} if debug else None\n",
    "    \n",
    "#     try:\n",
    "#         start_idx = master_trading_days.get_loc(start_date)\n",
    "#     except KeyError:\n",
    "#         return ({'error': f\"Start date {start_date.date()} is not a valid trading day.\"}, None)\n",
    "        \n",
    "#     calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "#     viz_end_idx = min(calc_end_idx + fwd_period, len(master_trading_days) - 1)\n",
    "\n",
    "#     safe_start_date = master_trading_days[start_idx]\n",
    "#     safe_calc_end_date = master_trading_days[calc_end_idx]\n",
    "#     safe_viz_end_date = master_trading_days[viz_end_idx]\n",
    "    \n",
    "#     if safe_start_date >= safe_calc_end_date:\n",
    "#         return ({'error': \"Invalid date range (calc period has zero or negative length).\"}, None)\n",
    "\n",
    "#     calc_close_raw = df_close_full.loc[safe_start_date:safe_calc_end_date]\n",
    "#     calc_close = calc_close_raw.dropna(axis=1, how='all')\n",
    "#     if calc_close.shape[1] == 0 or len(calc_close) < 2:\n",
    "#         return ({'error': \"Not enough data in calc period.\"}, None)\n",
    "\n",
    "#     first_prices = calc_close.bfill().iloc[0]\n",
    "#     last_prices = calc_close.ffill().iloc[-1]\n",
    "#     daily_returns = calc_close.bfill().ffill().pct_change()\n",
    "#     mean_returns = daily_returns.mean()\n",
    "#     std_returns = daily_returns.std()\n",
    "    \n",
    "#     valid_tickers = calc_close.columns\n",
    "#     calc_high = df_high_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "#     calc_low = df_low_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "    \n",
    "#     # ==============================================================================\n",
    "#     # --- BUG FIX: Explicitly align previous day's close before subtraction ---\n",
    "#     # ==============================================================================\n",
    "#     # Create a DataFrame of previous day's close prices that EXACTLY matches the\n",
    "#     # index of the calc_high and calc_low DataFrames.\n",
    "#     prev_close = df_close_full[valid_tickers].shift(1).loc[safe_start_date:safe_calc_end_date]\n",
    "    \n",
    "#     # Now, all DataFrames in this calculation have the same shape and index.\n",
    "#     tr_df = pd.DataFrame({\n",
    "#         'h_l': calc_high - calc_low,\n",
    "#         'h_cp': abs(calc_high - prev_close),\n",
    "#         'l_cp': abs(calc_low - prev_close)\n",
    "#     })\n",
    "#     # ==============================================================================\n",
    "#     # --- END OF FIX ---\n",
    "#     # ==============================================================================\n",
    "    \n",
    "#     tr = tr_df.max(axis=1)\n",
    "    \n",
    "#     atr = tr.ewm(alpha=1/14, adjust=False).mean()\n",
    "#     atrp = (atr / calc_close).mean()\n",
    "\n",
    "#     metric_values = {}\n",
    "#     metric_values['Price'] = (last_prices / first_prices).dropna()\n",
    "#     metric_values['Sharpe'] = (mean_returns / std_returns * np.sqrt(252)).fillna(0)\n",
    "#     metric_values['Sharpe (ATR)'] = (mean_returns / atrp).fillna(0)\n",
    "\n",
    "#     if debug:\n",
    "#         df_ranking = pd.DataFrame({\n",
    "#             'FirstPrice': first_prices, 'LastPrice': last_prices, 'MeanDailyReturn': mean_returns,\n",
    "#             'StdDevDailyReturn': std_returns, 'MeanATRP': atrp, 'Metric_Price': metric_values['Price'],\n",
    "#             'Metric_Sharpe': metric_values['Sharpe'], 'Metric_Sharpe (ATR)': metric_values['Sharpe (ATR)']\n",
    "#         })\n",
    "#         df_ranking.index.name = 'Ticker'\n",
    "#         debug_data['ranking_metrics'] = df_ranking.sort_values(f'Metric_{metric}', ascending=False)\n",
    "\n",
    "#     sorted_tickers = metric_values[metric].sort_values(ascending=False)\n",
    "#     tickers_to_display = sorted_tickers.index[rank_start-1:rank_end].tolist()\n",
    "#     if not tickers_to_display:\n",
    "#         return ({'error': \"No tickers found for the selected rank.\"}, None)\n",
    "\n",
    "#     normalized_plot_data = df_close_full[tickers_to_display].loc[safe_start_date:safe_viz_end_date]\n",
    "#     normalized_plot_data = normalized_plot_data.div(normalized_plot_data.bfill().iloc[0])\n",
    "#     actual_calc_end_ts = calc_close.index.max()\n",
    "#     portfolio_series = normalized_plot_data.mean(axis=1)\n",
    "#     portfolio_return_series = portfolio_series.pct_change()\n",
    "#     benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "#     benchmark_return_series = benchmark_price_series.loc[safe_start_date:safe_viz_end_date].bfill().ffill().pct_change() if benchmark_price_series is not None else pd.Series(dtype='float64')\n",
    "\n",
    "#     # Corrected slicing for Sharpe calculation to prevent overlap\n",
    "#     try:\n",
    "#         boundary_loc = portfolio_return_series.index.get_loc(actual_calc_end_ts)\n",
    "#         calc_portfolio_returns = portfolio_return_series.iloc[:boundary_loc + 1]\n",
    "#         fwd_portfolio_returns = portfolio_return_series.iloc[boundary_loc + 1:]\n",
    "        \n",
    "#         bm_boundary_loc = benchmark_return_series.index.get_loc(actual_calc_end_ts)\n",
    "#         calc_benchmark_returns = benchmark_return_series.iloc[:bm_boundary_loc + 1]\n",
    "#         fwd_benchmark_returns = benchmark_return_series.iloc[bm_boundary_loc + 1:]\n",
    "#     except (KeyError, IndexError):\n",
    "#         calc_portfolio_returns = portfolio_return_series.loc[:actual_calc_end_ts]\n",
    "#         fwd_portfolio_returns = portfolio_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "#         calc_benchmark_returns = benchmark_return_series.loc[:actual_calc_end_ts]\n",
    "#         fwd_benchmark_returns = benchmark_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "\n",
    "#     perf_data = {}\n",
    "#     perf_data['calc_p_gain'] = calculate_gain(portfolio_series.loc[:actual_calc_end_ts])\n",
    "#     perf_data['fwd_p_gain'] = calculate_gain(portfolio_series.loc[actual_calc_end_ts:])\n",
    "#     perf_data['full_p_gain'] = calculate_gain(portfolio_series)\n",
    "#     perf_data['calc_p_sharpe'] = calculate_sharpe(calc_portfolio_returns)\n",
    "#     perf_data['fwd_p_sharpe'] = calculate_sharpe(fwd_portfolio_returns)\n",
    "#     perf_data['full_p_sharpe'] = calculate_sharpe(portfolio_return_series)\n",
    "    \n",
    "#     perf_data['calc_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:actual_calc_end_ts]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['fwd_b_gain'] = calculate_gain(benchmark_price_series.loc[actual_calc_end_ts:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['full_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "#     perf_data['calc_b_sharpe'] = calculate_sharpe(calc_benchmark_returns)\n",
    "#     perf_data['fwd_b_sharpe'] = calculate_sharpe(fwd_benchmark_returns)\n",
    "#     perf_data['full_b_sharpe'] = calculate_sharpe(benchmark_return_series)\n",
    "\n",
    "#     calc_end_prices = calc_close.ffill().iloc[-1]\n",
    "#     fwd_close_slice = df_close_full.loc[actual_calc_end_ts:safe_viz_end_date]\n",
    "#     viz_end_prices = fwd_close_slice.ffill().iloc[-1] if not fwd_close_slice.empty and len(fwd_close_slice) >= 2 else calc_end_prices\n",
    "#     calc_gains = (calc_end_prices / calc_close.bfill().iloc[0]) - 1\n",
    "#     fwd_gains = (viz_end_prices / calc_end_prices) - 1\n",
    "#     results_df = pd.DataFrame({'Rank': range(rank_start, rank_start + len(tickers_to_display)), 'Metric': metric, 'MetricValue': sorted_tickers.loc[tickers_to_display].values, 'CalcPrice': calc_end_prices.loc[tickers_to_display], 'CalcGain': calc_gains.loc[tickers_to_display], 'FwdGain': fwd_gains.loc[tickers_to_display]}, index=pd.Index(tickers_to_display, name='Ticker'))\n",
    "#     if benchmark_price_series is not None and benchmark_ticker in calc_close.columns:\n",
    "#         benchmark_df_row = pd.DataFrame({'Rank': np.nan, 'Metric': metric, 'MetricValue': metric_values[metric].get(benchmark_ticker, np.nan), 'CalcPrice': calc_end_prices[benchmark_ticker], 'CalcGain': calc_gains[benchmark_ticker], 'FwdGain': fwd_gains[benchmark_ticker]}, index=pd.Index([f\"{benchmark_ticker} (BM)\"], name='Ticker'))\n",
    "#         results_df = pd.concat([results_df, benchmark_df_row])\n",
    "    \n",
    "#     if debug:\n",
    "#         df_trace = normalized_plot_data.copy()\n",
    "#         df_trace.columns = [f'Norm_Price_{c}' for c in df_trace.columns]\n",
    "#         df_trace['Norm_Price_Portfolio'] = portfolio_series\n",
    "#         if benchmark_price_series is not None and not benchmark_price_series.loc[safe_start_date:safe_viz_end_date].dropna().empty:\n",
    "#             norm_bm = benchmark_price_series.loc[safe_start_date:safe_viz_end_date] / benchmark_price_series.loc[safe_start_date:].bfill().iloc[0]\n",
    "#             df_trace[f'Norm_Price_Benchmark_{benchmark_ticker}'] = norm_bm\n",
    "#         for col in df_trace.columns:\n",
    "#             if 'Norm_Price' in col:\n",
    "#                 df_trace[col.replace('Norm_Price', 'Return')] = df_trace[col].pct_change()\n",
    "#         debug_data['portfolio_trace'] = df_trace\n",
    "\n",
    "#     final_results = {\n",
    "#         'tickers_to_display': tickers_to_display, 'normalized_plot_data': normalized_plot_data,\n",
    "#         'portfolio_series': portfolio_series, 'benchmark_price_series': benchmark_price_series,\n",
    "#         'performance_data': perf_data, 'results_df': results_df, 'actual_calc_end_ts': actual_calc_end_ts,\n",
    "#         'safe_start_date': safe_start_date, 'safe_viz_end_date': safe_viz_end_date,\n",
    "#         'error': None\n",
    "#     }\n",
    "#     return (final_results, debug_data)\n",
    "\n",
    "\n",
    "def run_walk_forward_step(df_close_full, df_high_full, df_low_full,\n",
    "                          master_trading_days,\n",
    "                          start_date, calc_period, fwd_period,\n",
    "                          metric, rank_start, rank_end, benchmark_ticker,\n",
    "                          debug=False):\n",
    "    \"\"\"Runs a single step of the walk-forward analysis using precise trading days.\"\"\"\n",
    "    debug_data = {} if debug else None\n",
    "    \n",
    "    try:\n",
    "        start_idx = master_trading_days.get_loc(start_date)\n",
    "    except KeyError:\n",
    "        return ({'error': f\"Start date {start_date.date()} is not a valid trading day.\"}, None)\n",
    "        \n",
    "    calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "    viz_end_idx = min(calc_end_idx + fwd_period, len(master_trading_days) - 1)\n",
    "\n",
    "    safe_start_date = master_trading_days[start_idx]\n",
    "    safe_calc_end_date = master_trading_days[calc_end_idx]\n",
    "    safe_viz_end_date = master_trading_days[viz_end_idx]\n",
    "    \n",
    "    if safe_start_date >= safe_calc_end_date:\n",
    "        return ({'error': \"Invalid date range (calc period has zero or negative length).\"}, None)\n",
    "\n",
    "    calc_close_raw = df_close_full.loc[safe_start_date:safe_calc_end_date]\n",
    "    calc_close = calc_close_raw.dropna(axis=1, how='all')\n",
    "    if calc_close.shape[1] == 0 or len(calc_close) < 2:\n",
    "        return ({'error': \"Not enough data in calc period.\"}, None)\n",
    "\n",
    "    first_prices = calc_close.bfill().iloc[0]\n",
    "    last_prices = calc_close.ffill().iloc[-1]\n",
    "    daily_returns = calc_close.bfill().ffill().pct_change()\n",
    "    mean_returns = daily_returns.mean()\n",
    "    std_returns = daily_returns.std()\n",
    "    \n",
    "    valid_tickers = calc_close.columns\n",
    "    calc_high = df_high_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "    calc_low = df_low_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "    \n",
    "    # ==============================================================================\n",
    "    # --- FINAL BUG FIX: Correctly calculate element-wise True Range ---\n",
    "    # ==============================================================================\n",
    "    # Create a DataFrame of previous day's close prices that EXACTLY matches the\n",
    "    # index and columns of the calc_high and calc_low DataFrames.\n",
    "    prev_close = df_close_full[valid_tickers].shift(1).loc[safe_start_date:safe_calc_end_date]\n",
    "    \n",
    "    # Calculate the three components of True Range. Each of these is a DataFrame\n",
    "    # with the same shape (days x tickers).\n",
    "    component1 = calc_high - calc_low\n",
    "    component2 = abs(calc_high - prev_close)\n",
    "    component3 = abs(calc_low - prev_close)\n",
    "\n",
    "    # Find the element-wise maximum across the three component DataFrames.\n",
    "    # np.maximum is efficient and preserves the DataFrame structure.\n",
    "    # We chain it to handle the three components.\n",
    "    tr = np.maximum(component1, np.maximum(component2, component3))\n",
    "    # ==============================================================================\n",
    "    # --- END OF FIX ---\n",
    "    # ==============================================================================\n",
    "    \n",
    "    atr = tr.ewm(alpha=1/14, adjust=False).mean()\n",
    "    atrp = (atr / calc_close).mean()\n",
    "\n",
    "    metric_values = {}\n",
    "    metric_values['Price'] = (last_prices / first_prices).dropna()\n",
    "    metric_values['Sharpe'] = (mean_returns / std_returns * np.sqrt(252)).fillna(0)\n",
    "    metric_values['Sharpe (ATR)'] = (mean_returns / atrp).fillna(0)\n",
    "\n",
    "    if debug:\n",
    "        df_ranking = pd.DataFrame({\n",
    "            'FirstPrice': first_prices, 'LastPrice': last_prices, 'MeanDailyReturn': mean_returns,\n",
    "            'StdDevDailyReturn': std_returns, 'MeanATRP': atrp, 'Metric_Price': metric_values['Price'],\n",
    "            'Metric_Sharpe': metric_values['Sharpe'], 'Metric_Sharpe (ATR)': metric_values['Sharpe (ATR)']\n",
    "        })\n",
    "        df_ranking.index.name = 'Ticker'\n",
    "        debug_data['ranking_metrics'] = df_ranking.sort_values(f'Metric_{metric}', ascending=False)\n",
    "\n",
    "    sorted_tickers = metric_values[metric].sort_values(ascending=False)\n",
    "    tickers_to_display = sorted_tickers.index[rank_start-1:rank_end].tolist()\n",
    "    if not tickers_to_display:\n",
    "        return ({'error': \"No tickers found for the selected rank.\"}, None)\n",
    "\n",
    "    normalized_plot_data = df_close_full[tickers_to_display].loc[safe_start_date:safe_viz_end_date]\n",
    "    normalized_plot_data = normalized_plot_data.div(normalized_plot_data.bfill().iloc[0])\n",
    "    actual_calc_end_ts = calc_close.index.max()\n",
    "    portfolio_series = normalized_plot_data.mean(axis=1)\n",
    "    portfolio_return_series = portfolio_series.pct_change()\n",
    "    benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "    benchmark_return_series = benchmark_price_series.loc[safe_start_date:safe_viz_end_date].bfill().ffill().pct_change() if benchmark_price_series is not None else pd.Series(dtype='float64')\n",
    "\n",
    "    # Corrected slicing for Sharpe calculation to prevent overlap\n",
    "    try:\n",
    "        boundary_loc = portfolio_return_series.index.get_loc(actual_calc_end_ts)\n",
    "        calc_portfolio_returns = portfolio_return_series.iloc[:boundary_loc + 1]\n",
    "        fwd_portfolio_returns = portfolio_return_series.iloc[boundary_loc + 1:]\n",
    "        \n",
    "        bm_boundary_loc = benchmark_return_series.index.get_loc(actual_calc_end_ts)\n",
    "        calc_benchmark_returns = benchmark_return_series.iloc[:bm_boundary_loc + 1]\n",
    "        fwd_benchmark_returns = benchmark_return_series.iloc[bm_boundary_loc + 1:]\n",
    "    except (KeyError, IndexError):\n",
    "        calc_portfolio_returns = portfolio_return_series.loc[:actual_calc_end_ts]\n",
    "        fwd_portfolio_returns = portfolio_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "        calc_benchmark_returns = benchmark_return_series.loc[:actual_calc_end_ts]\n",
    "        fwd_benchmark_returns = benchmark_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "\n",
    "    perf_data = {}\n",
    "    perf_data['calc_p_gain'] = calculate_gain(portfolio_series.loc[:actual_calc_end_ts])\n",
    "    perf_data['fwd_p_gain'] = calculate_gain(portfolio_series.loc[actual_calc_end_ts:])\n",
    "    perf_data['full_p_gain'] = calculate_gain(portfolio_series)\n",
    "    perf_data['calc_p_sharpe'] = calculate_sharpe(calc_portfolio_returns)\n",
    "    perf_data['fwd_p_sharpe'] = calculate_sharpe(fwd_portfolio_returns)\n",
    "    perf_data['full_p_sharpe'] = calculate_sharpe(portfolio_return_series)\n",
    "    \n",
    "    perf_data['calc_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:actual_calc_end_ts]) if benchmark_price_series is not None else np.nan\n",
    "    perf_data['fwd_b_gain'] = calculate_gain(benchmark_price_series.loc[actual_calc_end_ts:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "    perf_data['full_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "    perf_data['calc_b_sharpe'] = calculate_sharpe(calc_benchmark_returns)\n",
    "    perf_data['fwd_b_sharpe'] = calculate_sharpe(fwd_benchmark_returns)\n",
    "    perf_data['full_b_sharpe'] = calculate_sharpe(benchmark_return_series)\n",
    "\n",
    "    calc_end_prices = calc_close.ffill().iloc[-1]\n",
    "    fwd_close_slice = df_close_full.loc[actual_calc_end_ts:safe_viz_end_date]\n",
    "    viz_end_prices = fwd_close_slice.ffill().iloc[-1] if not fwd_close_slice.empty and len(fwd_close_slice) >= 2 else calc_end_prices\n",
    "    calc_gains = (calc_end_prices / calc_close.bfill().iloc[0]) - 1\n",
    "    fwd_gains = (viz_end_prices / calc_end_prices) - 1\n",
    "    results_df = pd.DataFrame({'Rank': range(rank_start, rank_start + len(tickers_to_display)), 'Metric': metric, 'MetricValue': sorted_tickers.loc[tickers_to_display].values, 'CalcPrice': calc_end_prices.loc[tickers_to_display], 'CalcGain': calc_gains.loc[tickers_to_display], 'FwdGain': fwd_gains.loc[tickers_to_display]}, index=pd.Index(tickers_to_display, name='Ticker'))\n",
    "    if benchmark_price_series is not None and benchmark_ticker in calc_close.columns:\n",
    "        benchmark_df_row = pd.DataFrame({'Rank': np.nan, 'Metric': metric, 'MetricValue': metric_values[metric].get(benchmark_ticker, np.nan), 'CalcPrice': calc_end_prices[benchmark_ticker], 'CalcGain': calc_gains[benchmark_ticker], 'FwdGain': fwd_gains[benchmark_ticker]}, index=pd.Index([f\"{benchmark_ticker} (BM)\"], name='Ticker'))\n",
    "        results_df = pd.concat([results_df, benchmark_df_row])\n",
    "    \n",
    "    if debug:\n",
    "        df_trace = normalized_plot_data.copy()\n",
    "        df_trace.columns = [f'Norm_Price_{c}' for c in df_trace.columns]\n",
    "        df_trace['Norm_Price_Portfolio'] = portfolio_series\n",
    "        if benchmark_price_series is not None and not benchmark_price_series.loc[safe_start_date:safe_viz_end_date].dropna().empty:\n",
    "            norm_bm = benchmark_price_series.loc[safe_start_date:safe_viz_end_date] / benchmark_price_series.loc[safe_start_date:].bfill().iloc[0]\n",
    "            df_trace[f'Norm_Price_Benchmark_{benchmark_ticker}'] = norm_bm\n",
    "        for col in df_trace.columns:\n",
    "            if 'Norm_Price' in col:\n",
    "                df_trace[col.replace('Norm_Price', 'Return')] = df_trace[col].pct_change()\n",
    "        debug_data['portfolio_trace'] = df_trace\n",
    "\n",
    "    final_results = {\n",
    "        'tickers_to_display': tickers_to_display, 'normalized_plot_data': normalized_plot_data,\n",
    "        'portfolio_series': portfolio_series, 'benchmark_price_series': benchmark_price_series,\n",
    "        'performance_data': perf_data, 'results_df': results_df, 'actual_calc_end_ts': actual_calc_end_ts,\n",
    "        'safe_start_date': safe_start_date, 'safe_viz_end_date': safe_viz_end_date,\n",
    "        'error': None\n",
    "    }\n",
    "    return (final_results, debug_data)\n",
    "\n",
    "# --- C. DYNAMIC DATA QUALITY FILTER FUNCTIONS ---\n",
    "\n",
    "def calculate_rolling_quality_metrics(df_ohlcv, window=252, min_periods=126, debug=False):\n",
    "    \"\"\"Calculates rolling data quality metrics for the entire dataset.\"\"\"\n",
    "    print(f\"--- Calculating Rolling Quality Metrics (Window: {window} days) ---\")\n",
    "    df = df_ohlcv.copy()\n",
    "    if not df.index.is_monotonic_increasing:\n",
    "        df.sort_index(inplace=True)\n",
    "    df['IsStale'] = np.where((df['Volume'] == 0) | (df['Adj High'] == df['Adj Low']), 1, 0)\n",
    "    df['DollarVolume'] = df['Adj Close'] * df['Volume']\n",
    "    df['HasSameVolumeAsPrevDay'] = (df.groupby(level='Ticker')['Volume'].diff() == 0).astype(int)\n",
    "    grouped = df.groupby(level='Ticker')\n",
    "    stale_pct = grouped['IsStale'].rolling(window=window, min_periods=min_periods).mean()\n",
    "    median_vol = grouped['DollarVolume'].rolling(window=window, min_periods=min_periods).median()\n",
    "    same_vol_count = grouped['HasSameVolumeAsPrevDay'].rolling(window=window, min_periods=min_periods).sum()\n",
    "    quality_df = pd.concat([stale_pct, median_vol, same_vol_count], axis=1)\n",
    "    quality_df.columns = ['RollingStalePct', 'RollingMedianVolume', 'RollingSameVolCount']\n",
    "    quality_df.index = quality_df.index.droplevel(0)\n",
    "    print(\"✅ Rolling metrics calculation complete.\")\n",
    "    return quality_df\n",
    "\n",
    "def get_eligible_universe(quality_metrics_df, filter_date, thresholds):\n",
    "    \"\"\"Filters the universe of tickers based on quality metrics for a given date.\"\"\"\n",
    "    filter_date_ts = pd.to_datetime(filter_date)\n",
    "    date_index = quality_metrics_df.index.get_level_values('Date').unique().sort_values()\n",
    "    if filter_date_ts < date_index[0]:\n",
    "        print(f\"Warning: Filter date {filter_date_ts.date()} is before the earliest data point. Returning empty universe.\")\n",
    "        return []\n",
    "    valid_prior_dates = date_index[date_index <= filter_date_ts]\n",
    "    if valid_prior_dates.empty:\n",
    "        print(f\"Warning: No available data found on or before {filter_date_ts.date()}. Returning empty universe.\")\n",
    "        return []\n",
    "    actual_date_to_use = valid_prior_dates[-1]\n",
    "    if actual_date_to_use.date() != filter_date_ts.date():\n",
    "        print(f\"ℹ️ Info: Filter date {filter_date_ts.date()} not found. Using previous available date {actual_date_to_use.date()}.\")\n",
    "    metrics_on_date = quality_metrics_df.xs(actual_date_to_use, level='Date')\n",
    "    mask = ((metrics_on_date['RollingMedianVolume'] >= thresholds['min_median_dollar_volume']) &\n",
    "            (metrics_on_date['RollingStalePct'] <= thresholds['max_stale_pct']) &\n",
    "            (metrics_on_date['RollingSameVolCount'] <= thresholds['max_same_vol_count']))\n",
    "    eligible_tickers = metrics_on_date[mask].index.tolist()\n",
    "    all_tickers = metrics_on_date.index.tolist()\n",
    "    print(f\"Dynamic Filter ({filter_date_ts.date()}): Kept {len(eligible_tickers)} of {len(all_tickers)} tickers.\")\n",
    "    return eligible_tickers    \n",
    "\n",
    "# --- D. INTERACTIVE ANALYSIS & BACKTESTING TOOLS ---\n",
    "\n",
    "def plot_walk_forward_analyzer(df_ohlcv, \n",
    "                               default_start_date=None, default_calc_period=126, default_fwd_period=63,\n",
    "                               default_metric='Sharpe (ATR)', default_rank_start=1, default_rank_end=10,\n",
    "                               default_benchmark_ticker='VOO', master_calendar_ticker='VOO',\n",
    "                               quality_thresholds={'min_median_dollar_volume': 1_000_000, 'max_stale_pct': 0.05, 'max_same_vol_count': 10},\n",
    "                               debug=False):\n",
    "    \"\"\"Creates an interactive widget for single-period walk-forward analysis.\"\"\"\n",
    "    print(\"Initializing Walk-Forward Analyzer (using Trading Day Logic)...\")\n",
    "    if not isinstance(df_ohlcv.index, pd.MultiIndex): raise ValueError(\"Input DataFrame must have a (Ticker, Date) MultiIndex.\")\n",
    "    df_ohlcv = df_ohlcv.sort_index()\n",
    "\n",
    "    if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "        raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "    master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "    print(f\"Master trading day calendar created from '{master_calendar_ticker}' ({len(master_trading_days)} days).\")\n",
    "\n",
    "    print(\"Pre-calculating data quality metrics...\")\n",
    "    quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "    print(\"Pre-processing data (unstacking)...\")\n",
    "    df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "    df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "    df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    \n",
    "    start_date_picker = widgets.DatePicker(description='Start Date:', value=pd.to_datetime(default_start_date), disabled=False)\n",
    "    calc_period_input = widgets.IntText(value=default_calc_period, description='Calc Period (days):')\n",
    "    fwd_period_input = widgets.IntText(value=default_fwd_period, description='Fwd Period (days):')\n",
    "    metrics = ['Price', 'Sharpe', 'Sharpe (ATR)']\n",
    "    metric_dropdown = widgets.Dropdown(options=metrics, value=default_metric, description='Metric:')\n",
    "    rank_start_input = widgets.IntText(value=default_rank_start, description='Rank Start:')\n",
    "    rank_end_input = widgets.IntText(value=default_rank_end, description='Rank End:')\n",
    "    benchmark_ticker_input = widgets.Text(value=default_benchmark_ticker, description='Benchmark:', placeholder='Enter Ticker')\n",
    "    update_button = widgets.Button(description=\"Update Chart\", button_style='primary')\n",
    "    ticker_list_output = widgets.Output()\n",
    "    results_container, debug_data_container = [None], [None]\n",
    "\n",
    "    fig = go.FigureWidget()\n",
    "    max_traces = 50\n",
    "    for i in range(max_traces): fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name=f'placeholder_{i}', visible=False, showlegend=False))\n",
    "    fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Benchmark', visible=True, showlegend=True, line=dict(color='black', width=3, dash='dash')))\n",
    "    fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Group Portfolio', visible=True, showlegend=True, line=dict(color='green', width=3)))\n",
    "\n",
    "    def update_plot(button_click):\n",
    "        ticker_list_output.clear_output()\n",
    "        \n",
    "        start_date_raw = pd.to_datetime(start_date_picker.value)\n",
    "        start_date_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "        if start_date_idx >= len(master_trading_days):\n",
    "            with ticker_list_output: print(f\"Error: Start date is after the last available trading day.\"); return\n",
    "        actual_start_date = master_trading_days[start_date_idx]\n",
    "        with ticker_list_output: \n",
    "            if start_date_raw.date() != actual_start_date.date():\n",
    "                print(f\"ℹ️ Info: Start date {start_date_raw.date()} is not a trading day. Snapping forward to {actual_start_date.date()}.\")\n",
    "\n",
    "        calc_period, fwd_period = calc_period_input.value, fwd_period_input.value\n",
    "        metric = metric_dropdown.value\n",
    "        rank_start, rank_end = rank_start_input.value, rank_end_input.value\n",
    "        benchmark_ticker = benchmark_ticker_input.value.strip().upper()\n",
    "        \n",
    "        if rank_start > rank_end:\n",
    "            with ticker_list_output: print(\"Error: 'Rank Start' must be <= 'Rank End'.\"); return\n",
    "        if rank_start < 1 or calc_period < 2 or fwd_period < 1:\n",
    "            with ticker_list_output: print(\"Error: Ranks must be >= 1, Calc Period >= 2, Fwd Period >= 1.\"); return\n",
    "\n",
    "        eligible_tickers = get_eligible_universe(quality_metrics_df, actual_start_date, quality_thresholds)\n",
    "        if not eligible_tickers:\n",
    "            with ticker_list_output: print(f\"Error: No eligible tickers found on {actual_start_date.date()} with the current quality filters.\"); return\n",
    "        df_close_step = df_close_full[eligible_tickers]; df_high_step = df_high_full[eligible_tickers]; df_low_step = df_low_full[eligible_tickers]\n",
    "\n",
    "        results, debug_output = run_walk_forward_step(\n",
    "            df_close_step, df_high_step, df_low_step, master_trading_days,\n",
    "            actual_start_date, calc_period, fwd_period, \n",
    "            metric, rank_start, rank_end, benchmark_ticker, debug=debug\n",
    "        )\n",
    "        if results['error']:\n",
    "            with ticker_list_output: print(f\"Error: {results['error']}\"); return\n",
    "\n",
    "        with fig.batch_update():\n",
    "            for i in range(max_traces):\n",
    "                trace = fig.data[i]\n",
    "                if i < len(results['tickers_to_display']):\n",
    "                    ticker = results['tickers_to_display'][i]; plot_data_series = results['normalized_plot_data'][ticker]\n",
    "                    trace.x, trace.y, trace.name, trace.visible, trace.showlegend = plot_data_series.index, plot_data_series.values, ticker, True, True\n",
    "                else: trace.visible, trace.showlegend = False, False\n",
    "            benchmark_trace = fig.data[max_traces]\n",
    "            if results['benchmark_price_series'] is not None and not results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']].dropna().empty:\n",
    "                normalized_benchmark = results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']] / results['benchmark_price_series'].loc[results['safe_start_date']:].bfill().iloc[0]\n",
    "                benchmark_trace.x, benchmark_trace.y, benchmark_trace.name, benchmark_trace.visible = normalized_benchmark.index, normalized_benchmark, f\"Benchmark ({benchmark_ticker})\", True\n",
    "            else: benchmark_trace.visible = False\n",
    "            portfolio_trace = fig.data[max_traces + 1]\n",
    "            portfolio_trace.x, portfolio_trace.y, portfolio_trace.name, portfolio_trace.visible = results['portfolio_series'].index, results['portfolio_series'], 'Group Portfolio', True\n",
    "            fig.layout.shapes = []; fig.add_shape(type=\"line\", x0=results['actual_calc_end_ts'], y0=0, x1=results['actual_calc_end_ts'], y1=1, xref='x', yref='paper', line=dict(color=\"grey\", width=2, dash=\"dash\"))\n",
    "            \n",
    "        results_container[0] = results; debug_data_container[0] = debug_output\n",
    "        \n",
    "        with ticker_list_output:\n",
    "            print(f\"Analysis Period: {results['safe_start_date'].date()} to {results['safe_viz_end_date'].date()}.\")\n",
    "            pprint.pprint(results['tickers_to_display'])\n",
    "            p = results['performance_data']\n",
    "            rows = []\n",
    "            rows.append({'Metric': 'Group Portfolio Gain', 'Full': p['full_p_gain'], 'Calc': p['calc_p_gain'], 'Fwd': p['fwd_p_gain']})\n",
    "            if not np.isnan(p['full_b_gain']):\n",
    "                rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Gain', 'Full': p['full_b_gain'], 'Calc': p['calc_b_gain'], 'Fwd': p['fwd_b_gain']})\n",
    "                rows.append({'Metric': 'Gain Delta (vs Bm)', 'Full': p['full_p_gain'] - p['full_b_gain'], 'Calc': p['calc_p_gain'] - p['calc_b_gain'], 'Fwd': p['fwd_p_gain'] - p['fwd_b_gain']})\n",
    "            rows.append({'Metric': 'Group Portfolio Sharpe', 'Full': p['full_p_sharpe'], 'Calc': p['calc_p_sharpe'], 'Fwd': p['fwd_p_sharpe']})\n",
    "            if not np.isnan(p['full_b_sharpe']):\n",
    "                rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Sharpe', 'Full': p['full_b_sharpe'], 'Calc': p['calc_b_sharpe'], 'Fwd': p['fwd_b_sharpe']})\n",
    "                rows.append({'Metric': 'Sharpe Delta (vs Bm)', 'Full': p['full_p_sharpe'] - p['full_b_sharpe'], 'Calc': p['calc_p_sharpe'] - p['calc_b_sharpe'], 'Fwd': p['fwd_p_sharpe'] - p['fwd_b_sharpe']})\n",
    "            report_df = pd.DataFrame(rows).set_index('Metric')\n",
    "            gain_rows = [row for row in report_df.index if 'Gain' in row or 'Delta' in row]\n",
    "            sharpe_rows = [row for row in report_df.index if 'Sharpe' in row]\n",
    "            styled_df = report_df.style.format('{:+.2%}', na_rep='N/A', subset=(gain_rows, report_df.columns)).format('{:+.2f}', na_rep='N/A', subset=(sharpe_rows, report_df.columns)).set_properties(**{'text-align': 'right', 'width': '100px'}).set_table_styles([{'selector': 'th.col_heading', 'props': [('text-align', 'right')]}, {'selector': 'th.row_heading', 'props': [('text-align', 'left')]}])\n",
    "            print(\"\\n--- Strategy Performance Summary ---\")\n",
    "            display(styled_df)\n",
    "            \n",
    "    fig.update_layout(title_text='Walk-Forward Performance Analysis', xaxis_title='Date', yaxis_title='Normalized Price (Start = 1)', hovermode='x unified', legend_title_text='Tickers (Ranked)', height=600, margin=dict(t=50))\n",
    "    fig.add_hline(y=1, line_width=1, line_dash=\"dash\", line_color=\"grey\")\n",
    "    update_button.on_click(update_plot)\n",
    "    controls_row1 = widgets.HBox([start_date_picker, calc_period_input, fwd_period_input])\n",
    "    controls_row2 = widgets.HBox([metric_dropdown, rank_start_input, rank_end_input, benchmark_ticker_input, update_button])\n",
    "    ui_container = widgets.VBox([controls_row1, controls_row2, ticker_list_output], layout=widgets.Layout(margin='10px 0 20px 0'))\n",
    "    display(ui_container, fig)\n",
    "    update_plot(None)\n",
    "    return (results_container, debug_data_container)\n",
    "\n",
    "def run_full_backtest(df_ohlcv, strategy_params, quality_thresholds):\n",
    "    \"\"\"Runs a full backtest of a strategy over a specified date range.\"\"\"\n",
    "    print(f\"--- Running Full Forensic Backtest for Strategy: {strategy_params['metric']} (Top {strategy_params['rank_start']}-{strategy_params['rank_end']}) ---\")\n",
    "    \n",
    "    start_date, end_date = pd.to_datetime(strategy_params['start_date']), pd.to_datetime(strategy_params['end_date'])\n",
    "    calc_period, fwd_period = strategy_params['calc_period'], strategy_params['fwd_period']\n",
    "    metric, rank_start, rank_end = strategy_params['metric'], strategy_params['rank_start'], strategy_params['rank_end']\n",
    "    benchmark_ticker = strategy_params['benchmark_ticker']\n",
    "    master_calendar_ticker = strategy_params.get('master_calendar_ticker', 'VOO')\n",
    "    \n",
    "    if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "        raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "    master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "    \n",
    "    start_idx = master_trading_days.searchsorted(start_date)\n",
    "    end_idx = master_trading_days.searchsorted(end_date, side='right')\n",
    "    \n",
    "    quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "    df_close_full = df_ohlcv['Adj Close'].unstack(level=0); df_high_full = df_ohlcv['Adj High'].unstack(level=0); df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    \n",
    "    step_indices = range(start_idx, end_idx, fwd_period)\n",
    "    all_fwd_gains, period_by_period_debug = [], {}\n",
    "\n",
    "    print(f\"Simulating {len(step_indices)} periods from {master_trading_days[step_indices[0]].date()} to {master_trading_days[step_indices[-1]].date()}...\")\n",
    "    for current_idx in tqdm(step_indices, desc=\"Backtest Progress\"):\n",
    "        step_date = master_trading_days[current_idx]\n",
    "        eligible_tickers = get_eligible_universe(quality_metrics_df, step_date, quality_thresholds)\n",
    "        if not eligible_tickers: continue\n",
    "        \n",
    "        df_close_step = df_close_full[eligible_tickers]; df_high_step = df_high_full[eligible_tickers]; df_low_step = df_low_full[eligible_tickers]\n",
    "        \n",
    "        results, debug_output = run_walk_forward_step(\n",
    "            df_close_step, df_high_step, df_low_step, master_trading_days,\n",
    "            step_date, calc_period, fwd_period,\n",
    "            metric, rank_start, rank_end, benchmark_ticker, debug=True\n",
    "        )\n",
    "        if results['error'] is None:\n",
    "            fwd_series = results['portfolio_series'].loc[results['actual_calc_end_ts']:]\n",
    "            all_fwd_gains.append(fwd_series.pct_change().dropna())\n",
    "            period_by_period_debug[step_date.date().isoformat()] = debug_output\n",
    "            \n",
    "    if not all_fwd_gains:\n",
    "        print(\"Error: No valid periods were simulated.\"); return None\n",
    "\n",
    "    strategy_returns = pd.concat(all_fwd_gains); strategy_equity_curve = (1 + strategy_returns).cumprod()\n",
    "    benchmark_returns = df_close_full[benchmark_ticker].pct_change().loc[strategy_equity_curve.index]; benchmark_equity_curve = (1 + benchmark_returns).cumprod()\n",
    "    cumulative_equity_df = pd.DataFrame({'Strategy_Equity': strategy_equity_curve, 'Benchmark_Equity': benchmark_equity_curve})\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=cumulative_equity_df.index, y=cumulative_equity_df['Strategy_Equity'], name='Strategy', line=dict(color='green')))\n",
    "    fig.add_trace(go.Scatter(x=cumulative_equity_df.index, y=cumulative_equity_df['Benchmark_Equity'], name=f'Benchmark ({benchmark_ticker})', line=dict(color='black', dash='dash')))\n",
    "    fig.update_layout(title=f\"Cumulative Performance: '{metric}' Strategy (Top {rank_start}-{rank_end})\", xaxis_title=\"Date\", yaxis_title=\"Cumulative Growth\")\n",
    "    fig.show()\n",
    "\n",
    "    final_backtest_results = {'cumulative_performance': cumulative_equity_df, 'period_by_period_debug': period_by_period_debug}\n",
    "    print(\"\\n✅ Full backtest complete. Results object is ready for forensic analysis.\")\n",
    "    return final_backtest_results\n",
    "\n",
    "# --- E. VERIFICATION TOOLS (User Requested) ---\n",
    "\n",
    "def verify_group_tickers_walk_forward_calculation(df_ohlcv, tickers_to_verify, benchmark_ticker,\n",
    "                                                  start_date, calc_period, fwd_period,\n",
    "                                                  master_calendar_ticker='VOO', export_csv=False):\n",
    "    \"\"\"Verifies portfolio and benchmark performance and optionally exports the data.\"\"\"\n",
    "    display(Markdown(f\"## Verification Report for Portfolio vs. Benchmark\"))\n",
    "    display(Markdown(f\"**Portfolio Tickers:** `{tickers_to_verify}`\\n**Benchmark Ticker:** `{benchmark_ticker}`\"))\n",
    "    \n",
    "    if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "        raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "    master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "\n",
    "    start_date_raw = pd.to_datetime(start_date)\n",
    "    start_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "    if start_idx >= len(master_trading_days):\n",
    "        print(f\"Error: Start date {start_date_raw.date()} is after the last available trading day.\"); return\n",
    "    actual_start_date = master_trading_days[start_idx]\n",
    "    \n",
    "    calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "    fwd_end_idx = min(calc_end_idx + fwd_period, len(master_trading_days) - 1)\n",
    "    \n",
    "    actual_calc_end_date = master_trading_days[calc_end_idx]\n",
    "    actual_fwd_end_date = master_trading_days[fwd_end_idx]\n",
    "    \n",
    "    display(Markdown(f\"**Analysis Start:** `{actual_start_date.date()}` (Selected: `{start_date_raw.date()}`)\\n\"\n",
    "                    f\"**Calc End:** `{actual_calc_end_date.date()}` ({calc_period} trading days)\\n\"\n",
    "                    f\"**Fwd End:** `{actual_fwd_end_date.date()}` ({fwd_period} trading days)\"))\n",
    "\n",
    "    df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "    portfolio_prices_raw_slice = df_close_full[tickers_to_verify].loc[actual_start_date:actual_fwd_end_date]\n",
    "    portfolio_value_series = portfolio_prices_raw_slice.div(portfolio_prices_raw_slice.bfill().iloc[0]).mean(axis=1)\n",
    "    benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "    \n",
    "    if export_csv:\n",
    "        export_df = pd.DataFrame({\n",
    "            'Portfolio_Normalized_Price': portfolio_value_series,\n",
    "            'Portfolio_Daily_Return': portfolio_value_series.pct_change()\n",
    "        })\n",
    "        if benchmark_price_series is not None:\n",
    "            norm_bm = benchmark_price_series.loc[actual_start_date:actual_fwd_end_date]\n",
    "            norm_bm = norm_bm / norm_bm.bfill().iloc[0]\n",
    "            export_df['Benchmark_Normalized_Price'] = norm_bm\n",
    "            export_df['Benchmark_Daily_Return'] = norm_bm.pct_change()\n",
    "\n",
    "        output_dir = 'export_csv'\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        tickers_str = '_'.join(tickers_to_verify)\n",
    "        filename = f\"verify_group_{actual_start_date.date()}_{tickers_str}.csv\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        export_df.to_csv(filepath)\n",
    "        print(f\"\\n✅ Data exported to: {filepath}\")\n",
    "\n",
    "    def print_verification_steps(title, price_series):\n",
    "        display(Markdown(f\"#### Verification for: `{title}`\"))\n",
    "        if price_series.dropna().shape[0] < 2: print(\"  - Not enough data points.\"); return {'gain': np.nan, 'sharpe': np.nan}\n",
    "        start_price, end_price = price_series.bfill().iloc[0], price_series.ffill().iloc[-1]\n",
    "        gain = (end_price / start_price) - 1\n",
    "        print(f\"Start Value ({price_series.first_valid_index().date()}): {start_price:,.4f}\\nEnd Value   ({price_series.last_valid_index().date()}): {end_price:,.4f}\\nGain = {gain:.2%}\")\n",
    "        returns = price_series.pct_change()\n",
    "        sharpe = calculate_sharpe(returns)\n",
    "        print(f\"Mean Daily Return: {returns.mean():.6f}\\nStd Dev: {returns.std():.6f}\\nSharpe = {sharpe:.2f}\")\n",
    "        return {'gain': gain, 'sharpe': sharpe}\n",
    "\n",
    "    display(Markdown(\"### A. Calculation Period\"))\n",
    "    perf_calc_p = print_verification_steps(\"Group Portfolio\", portfolio_value_series.loc[actual_start_date:actual_calc_end_date])\n",
    "    perf_calc_b = print_verification_steps(f\"Benchmark\", benchmark_price_series.loc[actual_start_date:actual_calc_end_date])\n",
    "    display(Markdown(\"### B. Forward Period\"))\n",
    "    perf_fwd_p = print_verification_steps(\"Group Portfolio\", portfolio_value_series.loc[actual_calc_end_date:actual_fwd_end_date])\n",
    "    perf_fwd_b = print_verification_steps(f\"Benchmark\", benchmark_price_series.loc[actual_calc_end_date:actual_fwd_end_date])\n",
    "\n",
    "def verify_ticker_ranking_metrics(df_ohlcv, ticker, start_date, calc_period,\n",
    "                                  master_calendar_ticker='VOO', export_csv=False):\n",
    "    \"\"\"Verifies ranking metrics for a single ticker and optionally exports the data.\"\"\"\n",
    "    display(Markdown(f\"## Verification Report for Ticker Ranking: `{ticker}`\"))\n",
    "    \n",
    "    if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "        raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "    master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "\n",
    "    start_date_raw = pd.to_datetime(start_date)\n",
    "    start_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "    if start_idx >= len(master_trading_days):\n",
    "        print(f\"Error: Start date {start_date_raw.date()} is after the last available trading day.\"); return\n",
    "    actual_start_date = master_trading_days[start_idx]\n",
    "    \n",
    "    calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "    actual_calc_end_date = master_trading_days[calc_end_idx]\n",
    "\n",
    "    df_ticker = df_ohlcv.loc[ticker].sort_index()\n",
    "    calc_df = df_ticker.loc[actual_start_date:actual_calc_end_date].copy()\n",
    "    if calc_df.empty or len(calc_df) < 2: \n",
    "        print(\"No data or not enough data in calc period.\"); return\n",
    "\n",
    "    display(Markdown(\"### A. Calculation Period (for Ranking Metrics)\"))\n",
    "    display(Markdown(f\"**Period Start:** `{actual_start_date.date()}`\\n\"\n",
    "                    f\"**Period End:** `{actual_calc_end_date.date()}`\\n\"\n",
    "                    f\"**Total Trading Days:** `{len(calc_df)}` (Requested: `{calc_period}`)\"))\n",
    "    \n",
    "    display(Markdown(\"#### Detailed Metric Calculation Data\"))\n",
    "    \n",
    "    vdf = calc_df[['Adj High', 'Adj Low', 'Adj Close']].copy()\n",
    "    vdf['Daily_Return'] = vdf['Adj Close'].pct_change()\n",
    "    \n",
    "    # Corrected True Range calculation\n",
    "    tr_df = pd.DataFrame({\n",
    "        'h_l': vdf['Adj High'] - vdf['Adj Low'],\n",
    "        'h_cp': abs(vdf['Adj High'] - vdf['Adj Close'].shift(1)),\n",
    "        'l_cp': abs(vdf['Adj Low'] - vdf['Adj Close'].shift(1))\n",
    "    })\n",
    "    vdf['TR'] = tr_df.max(axis=1)\n",
    "    \n",
    "    vdf['ATR_14'] = vdf['TR'].ewm(alpha=1/14, adjust=False).mean()\n",
    "    vdf['ATRP'] = vdf['ATR_14'] / vdf['Adj Close']\n",
    "    \n",
    "    print(\"--- Start of Calculation Period ---\")\n",
    "    display(vdf.head())\n",
    "    print(\"\\n--- End of Calculation Period ---\")\n",
    "    display(vdf.tail())\n",
    "\n",
    "    if export_csv:\n",
    "        output_dir = 'export_csv'\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        filename = f\"verify_ticker_{actual_start_date.date()}_{ticker}.csv\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        vdf.to_csv(filepath)\n",
    "        print(f\"\\n✅ Data exported to: {filepath}\")\n",
    "    \n",
    "    display(Markdown(\"#### `MetricValue` Verification Summary:\"))\n",
    "    \n",
    "    calc_start_price = vdf['Adj Close'].bfill().iloc[0]\n",
    "    calc_end_price = vdf['Adj Close'].ffill().iloc[-1]\n",
    "    price_metric = (calc_end_price / calc_start_price)\n",
    "    print(f\"1. Price Metric: (Last Price / First Price) = ({calc_end_price:.2f} / {calc_start_price:.2f}) = {price_metric:.4f}\")\n",
    "    \n",
    "    daily_returns = vdf['Daily_Return'].dropna()\n",
    "    sharpe_ratio = calculate_sharpe(daily_returns)\n",
    "    print(f\"2. Sharpe Metric: (Mean Daily Return / Std Dev) * sqrt(252) = {sharpe_ratio:.4f}\")\n",
    "\n",
    "    atrp_mean = vdf['ATRP'].mean()\n",
    "    mean_daily_return = vdf['Daily_Return'].mean()\n",
    "    sharpe_atr = (mean_daily_return / atrp_mean) if atrp_mean > 0 else 0\n",
    "    print(f\"3. Sharpe (ATR) Metric: (Mean Daily Return / Mean ATRP) = ({mean_daily_return:.6f} / {atrp_mean:.6f}) = {sharpe_atr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f7824f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "916dd29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 4036635 entries, ('A', Timestamp('1999-11-18 00:00:00')) to ('ZWS', Timestamp('2025-10-06 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   Adj Open   float64\n",
      " 1   Adj High   float64\n",
      " 2   Adj Low    float64\n",
      " 3   Adj Close  float64\n",
      " 4   Volume     int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 170.0+ MB\n",
      "df_OHLCV.info() :\n",
      "None\n",
      "\n",
      "df_OHLCV.head():\n",
      "                   Adj Open  Adj High  Adj Low  Adj Close    Volume\n",
      "Ticker Date                                                        \n",
      "A      1999-11-18   27.2452   29.9398  23.9518    26.3470  74716422\n",
      "       1999-11-19   25.7108   25.7482  23.8396    24.1764  18198351\n",
      "       1999-11-22   24.7378   26.3470  23.9893    26.3470   7857767\n",
      "       1999-11-23   25.4488   26.1225  23.9518    23.9518   7138322\n",
      "       1999-11-24   24.0267   25.1120  23.9518    24.5881   5785607\n",
      "\n",
      "df_OHLCV.tail():\n",
      "                   Adj Open  Adj High  Adj Low  Adj Close  Volume\n",
      "Ticker Date                                                      \n",
      "ZWS    2025-09-30     46.90     47.40    46.77      47.03  609500\n",
      "       2025-10-01     46.72     47.04    46.40      46.80  599400\n",
      "       2025-10-02     46.86     47.17    46.54      46.91  839900\n",
      "       2025-10-03     46.87     47.37    46.62      46.84  780500\n",
      "       2025-10-06     47.16     47.37    46.67      47.29  661018\n"
     ]
    }
   ],
   "source": [
    "download_path = Path.home() / \"Downloads\"  \n",
    "# OHLCV_file_path = r'c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_clean_stocks_etfs.parquet'\n",
    "OHLCV_file_path = r'c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet'\n",
    "\n",
    "df_OHLCV = pd.read_parquet(OHLCV_file_path, engine='pyarrow')\n",
    "print(f'df_OHLCV.info() :\\n{df_OHLCV.info()}')\n",
    "print(f'\\ndf_OHLCV.head():\\n{df_OHLCV.head()}')\n",
    "print(f'\\ndf_OHLCV.tail():\\n{df_OHLCV.tail()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ca33d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data on: 2018-12-31\n",
      "========================================\n",
      "\n",
      "--- In-Sample (IS) 'Discovery Zone' Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 2702881 entries, ('A', Timestamp('1999-11-18 00:00:00')) to ('ZWS', Timestamp('2018-12-31 00:00:00'))\n",
      "Columns: 5 entries, Adj Open to Volume\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 114.1 MB\n",
      "IS Date Range: 1962-01-02 to 2018-12-31\n",
      "IS Shape: (2702881, 5)\n",
      "Percentage of IS data: 66.96%\n",
      "\n",
      "--- Out-of-Sample (OOS) 'Validation Zone' Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 1333754 entries, ('A', Timestamp('2019-01-02 00:00:00')) to ('ZWS', Timestamp('2025-10-06 00:00:00'))\n",
      "Columns: 5 entries, Adj Open to Volume\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 56.7 MB\n",
      "OOS Date Range: 2019-01-02 to 2025-10-06\n",
      "OOS Shape: (1333754, 5)\n",
      "Percentage of OOS data: 33.04%\n",
      "\n",
      "Verification: 2702881 (IS) + 1333754 (OOS) = 4036635 rows.\n",
      "Original total rows: 4036635 rows. Match: True\n"
     ]
    }
   ],
   "source": [
    "# --- 2. DEFINE THE SPLIT DATE ---\n",
    "# This is the last day of our In-Sample (IS) \"Discovery Zone\".\n",
    "split_date = pd.to_datetime('2018-12-31')\n",
    "\n",
    "print(f\"Splitting data on: {split_date.date()}\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "\n",
    "# --- 3. PERFORM THE SPLIT ---\n",
    "# We access the 'Date' level of the MultiIndex to create our boolean masks.\n",
    "\n",
    "# In-Sample (IS) DataFrame: Data for discovery and training the bot.\n",
    "df_IS = df_OHLCV[df_OHLCV.index.get_level_values('Date') <= split_date].copy()\n",
    "\n",
    "# Out-of-Sample (OOS) DataFrame: Data held back for final validation.\n",
    "df_OOS = df_OHLCV[df_OHLCV.index.get_level_values('Date') > split_date].copy()\n",
    "\n",
    "# Using .copy() is good practice to avoid SettingWithCopyWarning later on.\n",
    "\n",
    "\n",
    "# --- 4. VERIFY THE SPLIT ---\n",
    "# Always check your work to ensure the split was done correctly.\n",
    "\n",
    "print(\"\\n--- In-Sample (IS) 'Discovery Zone' Info ---\")\n",
    "df_IS.info(verbose=False, memory_usage='deep') # Use verbose=False for a cleaner summary\n",
    "print(f\"IS Date Range: {df_IS.index.get_level_values('Date').min().date()} to {df_IS.index.get_level_values('Date').max().date()}\")\n",
    "print(f\"IS Shape: {df_IS.shape}\")\n",
    "print(f\"Percentage of IS data: {df_IS.shape[0] / df_OHLCV.shape[0]:.2%}\")\n",
    "\n",
    "print(\"\\n--- Out-of-Sample (OOS) 'Validation Zone' Info ---\")\n",
    "df_OOS.info(verbose=False, memory_usage='deep')\n",
    "print(f\"OOS Date Range: {df_OOS.index.get_level_values('Date').min().date()} to {df_OOS.index.get_level_values('Date').max().date()}\")\n",
    "print(f\"OOS Shape: {df_OOS.shape}\")\n",
    "print(f\"Percentage of OOS data: {df_OOS.shape[0] / df_OHLCV.shape[0]:.2%}\")\n",
    "\n",
    "# Final check\n",
    "total_rows = df_IS.shape[0] + df_OOS.shape[0]\n",
    "print(f\"\\nVerification: {df_IS.shape[0]} (IS) + {df_OOS.shape[0]} (OOS) = {total_rows} rows.\")\n",
    "print(f\"Original total rows: {df_OHLCV.shape[0]} rows. Match: {total_rows == df_OHLCV.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf196a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Creating Development Sandbox DataFrame (Corrected) ---\n",
      "Slicing df_IS from 2014-01-01 to 2018-12-31\n",
      "============================================================\n",
      "\n",
      "--- Development Sandbox (df_dev) Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 778000 entries, ('A', Timestamp('2014-01-02 00:00:00')) to ('ZWS', Timestamp('2018-12-31 00:00:00'))\n",
      "Columns: 5 entries, Adj Open to Volume\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 33.4 MB\n",
      "df_dev Date Range: 2014-01-02 to 2018-12-31\n",
      "df_dev Shape: (778000, 5)\n",
      "df_dev as percentage of IS data: 28.78%\n",
      "============================================================\n",
      "\n",
      "Found 668 unique tickers in df_dev.\n",
      "First 10 unique tickers:\n",
      "['A', 'AAL', 'ABBV', 'ABT', 'ACM', 'ACN', 'ACWI', 'ACWX', 'ADBE', 'ADI']\n",
      "\n",
      "Last 10 unique tickers:\n",
      "['XYL', 'XYZ', 'YUM', 'Z', 'ZBH', 'ZBRA', 'ZG', 'ZS', 'ZTS', 'ZWS']\n"
     ]
    }
   ],
   "source": [
    "# This code REPLACES the previous df_dev creation snippet.\n",
    "# It should still be placed after df_IS and df_OOS are created.\n",
    "\n",
    "# --- 5. (CORRECTED) CREATE A SMALLER \"DEVELOPMENT SANDBOX\" DATAFRAME ---\n",
    "# We use a RECENT 5-year slice of our In-Sample data for rapid development.\n",
    "# This is much faster and more representative of modern data.\n",
    "\n",
    "dev_start_date = pd.to_datetime('2014-01-01')\n",
    "dev_end_date = pd.to_datetime('2018-12-31') # This is the end of our df_IS period\n",
    "\n",
    "print(\"\\n--- Creating Development Sandbox DataFrame (Corrected) ---\")\n",
    "print(f\"Slicing df_IS from {dev_start_date.date()} to {dev_end_date.date()}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create the development dataframe by slicing the main In-Sample data\n",
    "df_dev = df_IS[(df_IS.index.get_level_values('Date') >= dev_start_date) &\n",
    "               (df_IS.index.get_level_values('Date') <= dev_end_date)].copy()\n",
    "\n",
    "\n",
    "# --- 6. VERIFY THE (CORRECTED) DEVELOPMENT DATAFRAME ---\n",
    "print(\"\\n--- Development Sandbox (df_dev) Info ---\")\n",
    "df_dev.info(verbose=False, memory_usage='deep')\n",
    "print(f\"df_dev Date Range: {df_dev.index.get_level_values('Date').min().date()} to {df_dev.index.get_level_values('Date').max().date()}\")\n",
    "print(f\"df_dev Shape: {df_dev.shape}\")\n",
    "print(f\"df_dev as percentage of IS data: {df_dev.shape[0] / df_IS.shape[0]:.2%}\")\n",
    "\n",
    "# --- Get unique tickers from the 'Ticker' level of the MultiIndex ---\n",
    "\n",
    "# Get the 'Ticker' level of the index\n",
    "ticker_index = df_dev.index.get_level_values('Ticker')\n",
    "\n",
    "# Get the unique values from that level\n",
    "unique_tickers = ticker_index.unique()\n",
    "\n",
    "# Print the results\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nFound {len(unique_tickers)} unique tickers in df_dev.\")\n",
    "print(\"First 10 unique tickers:\")\n",
    "print(unique_tickers[:10].tolist()) # .tolist() gives a cleaner printout for a slice\n",
    "print(\"\\nLast 10 unique tickers:\")\n",
    "print(unique_tickers[-10:].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87a8d237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Bot Configuration Initialized ---\n",
      "Number of unique parameter combinations: 8\n",
      "Estimated number of time steps: 20\n",
      "Total simulations to run: 160\n"
     ]
    }
   ],
   "source": [
    "# --- 7. BOT CONFIGURATION MANAGER (UPDATED) ---\n",
    "\n",
    "bot_config = {\n",
    "    # --- Time Parameters ---\n",
    "    'search_start_date': '2014-01-01',\n",
    "    'search_end_date': '2018-12-31',\n",
    "    # MODIFICATION: Changed '3M' to '3ME' for Month-End frequency to resolve deprecation warning.\n",
    "    'step_frequency': '3ME',\n",
    "\n",
    "    # --- Strategy Parameters (The Search Grid) ---\n",
    "    'calc_periods': ['6M', '1Y'],\n",
    "    'fwd_periods': ['3M'], \n",
    "    'metrics': ['Sharpe', 'Sharpe (ATR)'],\n",
    "    'rank_slices': [\n",
    "        (1, 10),\n",
    "        (11, 30),\n",
    "    ],\n",
    "\n",
    "    # --- Data Quality Filter Parameters within Rolling Window---\n",
    "    'quality_thresholds': {\n",
    "        'min_median_dollar_volume': 10_000_000,  # $10 mil trading volume\n",
    "        'max_stale_pct': 0.05,  # 5% either Volume = 0, or High = Low\n",
    "        'max_same_vol_count': 1,  # max 1 day with consecutive Volume\n",
    "    },\n",
    "\n",
    "    # --- General Parameters ---\n",
    "    'benchmark_ticker': 'VOO',\n",
    "    'results_output_path': './export_csv/dev_strategy_search_results.csv'\n",
    "}\n",
    "\n",
    "\n",
    "# --- Let's quickly calculate how many simulations this configuration will run ---\n",
    "from itertools import product\n",
    "\n",
    "num_param_sets = len(list(product(\n",
    "    bot_config['calc_periods'],\n",
    "    bot_config['fwd_periods'],\n",
    "    bot_config['metrics'],\n",
    "    bot_config['rank_slices']\n",
    ")))\n",
    "\n",
    "# Estimate the number of time steps\n",
    "time_steps = pd.date_range(\n",
    "    start=bot_config['search_start_date'],\n",
    "    end=bot_config['search_end_date'],\n",
    "    freq=bot_config['step_frequency']\n",
    ")\n",
    "\n",
    "print(\"\\n--- Bot Configuration Initialized ---\")\n",
    "print(f\"Number of unique parameter combinations: {num_param_sets}\")\n",
    "print(f\"Estimated number of time steps: {len(time_steps)}\")\n",
    "print(f\"Total simulations to run: {num_param_sets * len(time_steps)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "428ee7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_walk_forward_analyzer_original_v0(\n",
    "#     df_ohlcv=df_OHLCV,  # CRITICAL: Use the same df_dev as the bot\n",
    "#     default_start_date='2017-04-30',\n",
    "#     default_calc_period='6M',\n",
    "#     default_fwd_period='3M',\n",
    "#     default_metric='Sharpe (ATR)',\n",
    "#     default_rank_start=1,\n",
    "#     default_rank_end=10,\n",
    "#     default_benchmark_ticker='VOO'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e92dc545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_walk_forward_analyzer_v1(\n",
    "#     df_ohlcv=df_OHLCV,  # CRITICAL: Use the same df_dev as the bot\n",
    "#     default_start_date='2017-04-30',\n",
    "#     default_calc_period='6M',\n",
    "#     default_fwd_period='3M',\n",
    "#     default_metric='Sharpe (ATR)',\n",
    "#     default_rank_start=1,\n",
    "#     default_rank_end=10,\n",
    "#     default_benchmark_ticker='VOO'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f90dd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_walk_forward_analyzer(\n",
    "#     df_ohlcv=df_OHLCV,  # CRITICAL: Use the same df_dev as the bot\n",
    "#     default_start_date='2017-04-30',\n",
    "#     default_calc_period='6M',\n",
    "#     default_fwd_period='3M',\n",
    "#     default_metric='Sharpe (ATR)',\n",
    "#     default_rank_start=1,\n",
    "#     default_rank_end=10,\n",
    "#     default_benchmark_ticker='VOO'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "136212d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Walk-Forward Analyzer (using Trading Day Logic)...\n",
      "Master trading day calendar created from 'VOO' (1258 days).\n",
      "Pre-calculating data quality metrics...\n",
      "--- Calculating Rolling Quality Metrics (Window: 252 days) ---\n",
      "✅ Rolling metrics calculation complete.\n",
      "Pre-processing data (unstacking)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0c2d4f7f5cb49399f12522fceea07a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(DatePicker(value=Timestamp('2017-04-30 00:00:00'), description='Start Date:', st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ebbc5fa58934e238766ed26887bb8d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines',\n",
       "              'name': 'placeholder_0',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'dd0dd86a-eee7-4ff8-8551-6d0ec53a6de2',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_1',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '59d0ec59-ad04-4b96-bcde-3ddfb8bbde7b',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_2',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '971c939c-8575-467a-83a8-9b83be0bbec2',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_3',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c3227d39-35f1-44fd-bf09-420c2601ab8b',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_4',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '6d2671e0-8f33-4ce6-aae4-a45b845274e4',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_5',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4ccba153-0364-4560-b173-316b03edb501',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_6',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '103052c7-dad2-42bb-9dba-f89952a1f061',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_7',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f8770e3c-b3ef-4f32-8aec-b4dc85b0a4c2',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_8',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e8bdc0dd-9576-4696-a895-3a6038452043',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_9',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '30af3885-7863-4615-8a53-22bc3d346854',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_10',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '02ce2730-b4e1-4512-8464-c83a59cf6aba',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_11',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '2a178ba3-bc9a-4b13-9675-c0f7bd387bc0',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_12',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '6d4025fc-42e1-4022-8a29-d791c8ad40da',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_13',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '2eeabfcd-1a0b-4afe-a42c-57fed524269e',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_14',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '1937cf13-2d8d-4a1e-ad04-0603b41688c1',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_15',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a9c30355-65e5-481f-88a1-2a93b37039ea',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_16',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '3e15a973-d96f-466b-b1bf-a20b3f55d126',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_17',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '3cbc4c1c-027f-4ed8-b32b-e23fc1a7fd19',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_18',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a55f2a03-0f92-4ed8-8290-0f20bdacf1f2',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_19',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '24689ebd-3c50-40ca-ada4-5b5522bcc476',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_20',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '2a7f323d-4293-49ca-873e-5393cdf810ab',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_21',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b5604504-69c2-4f85-9116-154468bdb000',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_22',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '11f5a174-555a-4ecc-86db-3e79abdf6d0b',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_23',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '31507d05-24ab-4eee-8e97-799697994d65',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_24',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'fe5425c1-369c-45e9-8ba6-3d5360a08b52',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_25',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '612615ed-3384-4cf7-8232-cd22ba82b523',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_26',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd8ffd7e8-4ffb-4cb7-a161-568b697e805a',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_27',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b48e2b6d-2940-40c2-a7ef-0b33aa3e6185',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_28',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f5c8ea29-336f-4c40-a52a-1b179a8203fb',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_29',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'eed5cf7a-a109-4468-acbe-e1d01d3751ef',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_30',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '83fc4dcc-b76f-4065-be09-c3de790ef0ba',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_31',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4d5fffce-4a30-495e-920a-e04916c538f0',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_32',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4b5f1a4a-d89b-4f63-9054-f6b6cb9be6fe',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_33',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '3b7adf37-e60f-4382-a2a0-c60e5b1de01f',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_34',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b72f8b35-25bb-4013-8016-4c7e16eab54d',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_35',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '019eafeb-3e87-41e0-b04e-ae440bcccbcb',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_36',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '681db0da-7271-4f84-9de8-31bc2e258317',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_37',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '65886adb-6a65-46f6-b8d9-7e1df2bf5ef9',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_38',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b58ee9a6-559b-4209-b952-c26c7fb248e7',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_39',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'bc69f7ff-21e7-4840-bc9f-88e371d01219',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_40',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '6d3801fd-d838-4c0e-a013-a2e9ee335cb7',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_41',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'aa681bf2-7a15-455c-9bb9-85c55bc4de4a',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_42',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '692f40b8-5ba1-474a-b580-70841d18ee8a',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_43',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd8f76cde-2bb1-42d1-87f2-f8edb08a2922',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_44',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '92d78869-3970-4fb1-80d5-8901a3e24d3e',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_45',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '48eb949d-2e79-44ea-b817-0084266a20ba',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_46',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '805c0595-0625-475c-90f5-c316f6d6fde0',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_47',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '67b5a61e-c88e-4f7c-a297-49ac619be224',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_48',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '2ea559d3-15f9-4a41-8eaf-ed60fc2b1287',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_49',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '2e2384ab-1f95-4f76-8370-7fd6c9443859',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': 'black', 'dash': 'dash', 'width': 3},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Benchmark',\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c6da6d08-bf00-427c-9a89-df30998b2bf8',\n",
       "              'visible': True,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': 'green', 'width': 3},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Group Portfolio',\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e7546ceb-5e22-42b5-9059-18553f142de1',\n",
       "              'visible': True,\n",
       "              'x': [None],\n",
       "              'y': [None]}],\n",
       "    'layout': {'height': 600,\n",
       "               'hovermode': 'x unified',\n",
       "               'legend': {'title': {'text': 'Tickers (Ranked)'}},\n",
       "               'margin': {'t': 50},\n",
       "               'shapes': [{'line': {'color': 'grey', 'dash': 'dash', 'width': 1},\n",
       "                           'type': 'line',\n",
       "                           'x0': 0,\n",
       "                           'x1': 1,\n",
       "                           'xref': 'x domain',\n",
       "                           'y0': 1,\n",
       "                           'y1': 1,\n",
       "                           'yref': 'y'}],\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Walk-Forward Performance Analysis'},\n",
       "               'xaxis': {'title': {'text': 'Date'}},\n",
       "               'yaxis': {'title': {'text': 'Normalized Price (Start = 1)'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic Filter (2017-05-01): Kept 521 of 633 tickers.\n"
     ]
    }
   ],
   "source": [
    "results_container, debug_container = plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_dev,\n",
    "    default_start_date='2017-04-30',\n",
    "    default_calc_period=20,\n",
    "    default_fwd_period=5,\n",
    "    default_metric='Sharpe (ATR)',\n",
    "    default_rank_start=1,\n",
    "    default_rank_end=5,\n",
    "    default_benchmark_ticker='VOO',\n",
    "    quality_thresholds=bot_config['quality_thresholds'],\n",
    "    debug=True  # <-- Activate the new mode!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bacf183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Debug Data Successfully Captured ---\n",
      "\n",
      "--- [1] Ranking Metrics for all eligible stocks (Top 15 shown) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FirstPrice</th>\n",
       "      <th>LastPrice</th>\n",
       "      <th>MeanDailyReturn</th>\n",
       "      <th>StdDevDailyReturn</th>\n",
       "      <th>MeanATRP</th>\n",
       "      <th>Metric_Price</th>\n",
       "      <th>Metric_Sharpe</th>\n",
       "      <th>Metric_Sharpe (ATR)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VOD</th>\n",
       "      <td>14.59920</td>\n",
       "      <td>16.63220</td>\n",
       "      <td>0.006593</td>\n",
       "      <td>0.010672</td>\n",
       "      <td>0.008555</td>\n",
       "      <td>1.139254</td>\n",
       "      <td>9.807357</td>\n",
       "      <td>0.770707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTU</th>\n",
       "      <td>118.32200</td>\n",
       "      <td>132.01800</td>\n",
       "      <td>0.005610</td>\n",
       "      <td>0.016061</td>\n",
       "      <td>0.009419</td>\n",
       "      <td>1.115752</td>\n",
       "      <td>5.544830</td>\n",
       "      <td>0.595607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YUM</th>\n",
       "      <td>56.63230</td>\n",
       "      <td>62.36870</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.008219</td>\n",
       "      <td>0.008865</td>\n",
       "      <td>1.101292</td>\n",
       "      <td>9.401147</td>\n",
       "      <td>0.549064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVDA</th>\n",
       "      <td>2.62969</td>\n",
       "      <td>3.57619</td>\n",
       "      <td>0.016445</td>\n",
       "      <td>0.046372</td>\n",
       "      <td>0.030067</td>\n",
       "      <td>1.359928</td>\n",
       "      <td>5.629597</td>\n",
       "      <td>0.546952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DPZ</th>\n",
       "      <td>165.93100</td>\n",
       "      <td>189.91500</td>\n",
       "      <td>0.006841</td>\n",
       "      <td>0.011984</td>\n",
       "      <td>0.012532</td>\n",
       "      <td>1.144542</td>\n",
       "      <td>9.062244</td>\n",
       "      <td>0.545867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBY</th>\n",
       "      <td>38.19850</td>\n",
       "      <td>44.00320</td>\n",
       "      <td>0.008176</td>\n",
       "      <td>0.050486</td>\n",
       "      <td>0.015149</td>\n",
       "      <td>1.151961</td>\n",
       "      <td>2.570896</td>\n",
       "      <td>0.539721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PM</th>\n",
       "      <td>71.46520</td>\n",
       "      <td>77.54190</td>\n",
       "      <td>0.004108</td>\n",
       "      <td>0.006353</td>\n",
       "      <td>0.007754</td>\n",
       "      <td>1.085030</td>\n",
       "      <td>10.264892</td>\n",
       "      <td>0.529758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCK</th>\n",
       "      <td>129.33000</td>\n",
       "      <td>151.41000</td>\n",
       "      <td>0.008115</td>\n",
       "      <td>0.021043</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>1.170726</td>\n",
       "      <td>6.121860</td>\n",
       "      <td>0.510313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTD</th>\n",
       "      <td>3.75900</td>\n",
       "      <td>5.34900</td>\n",
       "      <td>0.020118</td>\n",
       "      <td>0.074669</td>\n",
       "      <td>0.039954</td>\n",
       "      <td>1.422985</td>\n",
       "      <td>4.277000</td>\n",
       "      <td>0.503521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISRG</th>\n",
       "      <td>93.28560</td>\n",
       "      <td>101.60300</td>\n",
       "      <td>0.004308</td>\n",
       "      <td>0.007711</td>\n",
       "      <td>0.008737</td>\n",
       "      <td>1.089161</td>\n",
       "      <td>8.867488</td>\n",
       "      <td>0.493043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>22.22510</td>\n",
       "      <td>24.71870</td>\n",
       "      <td>0.005351</td>\n",
       "      <td>0.006592</td>\n",
       "      <td>0.011516</td>\n",
       "      <td>1.112197</td>\n",
       "      <td>12.887399</td>\n",
       "      <td>0.464716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VEEV</th>\n",
       "      <td>54.24000</td>\n",
       "      <td>64.90000</td>\n",
       "      <td>0.009314</td>\n",
       "      <td>0.025518</td>\n",
       "      <td>0.020048</td>\n",
       "      <td>1.196534</td>\n",
       "      <td>5.794186</td>\n",
       "      <td>0.464586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOK</th>\n",
       "      <td>4.73960</td>\n",
       "      <td>5.35688</td>\n",
       "      <td>0.006261</td>\n",
       "      <td>0.016040</td>\n",
       "      <td>0.013591</td>\n",
       "      <td>1.130239</td>\n",
       "      <td>6.195913</td>\n",
       "      <td>0.460653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RYAAY</th>\n",
       "      <td>35.43120</td>\n",
       "      <td>41.55040</td>\n",
       "      <td>0.008046</td>\n",
       "      <td>0.010123</td>\n",
       "      <td>0.017623</td>\n",
       "      <td>1.172707</td>\n",
       "      <td>12.617144</td>\n",
       "      <td>0.456546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUB</th>\n",
       "      <td>88.70280</td>\n",
       "      <td>90.05470</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>1.015241</td>\n",
       "      <td>14.526225</td>\n",
       "      <td>0.453701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        FirstPrice  LastPrice  MeanDailyReturn  StdDevDailyReturn  MeanATRP  Metric_Price  Metric_Sharpe  Metric_Sharpe (ATR)\n",
       "Ticker                                                                                                                       \n",
       "VOD       14.59920   16.63220         0.006593           0.010672  0.008555      1.139254       9.807357             0.770707\n",
       "INTU     118.32200  132.01800         0.005610           0.016061  0.009419      1.115752       5.544830             0.595607\n",
       "YUM       56.63230   62.36870         0.004868           0.008219  0.008865      1.101292       9.401147             0.549064\n",
       "NVDA       2.62969    3.57619         0.016445           0.046372  0.030067      1.359928       5.629597             0.546952\n",
       "DPZ      165.93100  189.91500         0.006841           0.011984  0.012532      1.144542       9.062244             0.545867\n",
       "BBY       38.19850   44.00320         0.008176           0.050486  0.015149      1.151961       2.570896             0.539721\n",
       "PM        71.46520   77.54190         0.004108           0.006353  0.007754      1.085030      10.264892             0.529758\n",
       "MCK      129.33000  151.41000         0.008115           0.021043  0.015902      1.170726       6.121860             0.510313\n",
       "TTD        3.75900    5.34900         0.020118           0.074669  0.039954      1.422985       4.277000             0.503521\n",
       "ISRG      93.28560  101.60300         0.004308           0.007711  0.008737      1.089161       8.867488             0.493043\n",
       "G         22.22510   24.71870         0.005351           0.006592  0.011516      1.112197      12.887399             0.464716\n",
       "VEEV      54.24000   64.90000         0.009314           0.025518  0.020048      1.196534       5.794186             0.464586\n",
       "NOK        4.73960    5.35688         0.006261           0.016040  0.013591      1.130239       6.195913             0.460653\n",
       "RYAAY     35.43120   41.55040         0.008046           0.010123  0.017623      1.172707      12.617144             0.456546\n",
       "MUB       88.70280   90.05470         0.000757           0.000827  0.001668      1.015241      14.526225             0.453701"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- [2] Daily Portfolio Trace for the Forward Period ---\n",
      "Showing forward trace starting from: 2017-05-30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Norm_Price_VOD</th>\n",
       "      <th>Norm_Price_INTU</th>\n",
       "      <th>Norm_Price_YUM</th>\n",
       "      <th>Norm_Price_NVDA</th>\n",
       "      <th>Norm_Price_DPZ</th>\n",
       "      <th>Norm_Price_Portfolio</th>\n",
       "      <th>Norm_Price_Benchmark_VOO</th>\n",
       "      <th>Return_VOD</th>\n",
       "      <th>Return_INTU</th>\n",
       "      <th>Return_YUM</th>\n",
       "      <th>Return_NVDA</th>\n",
       "      <th>Return_DPZ</th>\n",
       "      <th>Return_Portfolio</th>\n",
       "      <th>Return_Benchmark_VOO</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-05-30</th>\n",
       "      <td>1.139254</td>\n",
       "      <td>1.115752</td>\n",
       "      <td>1.101292</td>\n",
       "      <td>1.359928</td>\n",
       "      <td>1.144542</td>\n",
       "      <td>1.172154</td>\n",
       "      <td>1.011818</td>\n",
       "      <td>-0.004006</td>\n",
       "      <td>0.010749</td>\n",
       "      <td>0.004438</td>\n",
       "      <td>0.021363</td>\n",
       "      <td>0.006951</td>\n",
       "      <td>0.008344</td>\n",
       "      <td>-0.000949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-31</th>\n",
       "      <td>1.154515</td>\n",
       "      <td>1.120459</td>\n",
       "      <td>1.104790</td>\n",
       "      <td>1.355046</td>\n",
       "      <td>1.162272</td>\n",
       "      <td>1.179417</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.013396</td>\n",
       "      <td>0.004219</td>\n",
       "      <td>0.003176</td>\n",
       "      <td>-0.003590</td>\n",
       "      <td>0.015491</td>\n",
       "      <td>0.006196</td>\n",
       "      <td>-0.000223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-01</th>\n",
       "      <td>1.147652</td>\n",
       "      <td>1.125953</td>\n",
       "      <td>1.122889</td>\n",
       "      <td>1.355141</td>\n",
       "      <td>1.182148</td>\n",
       "      <td>1.186757</td>\n",
       "      <td>1.019484</td>\n",
       "      <td>-0.005945</td>\n",
       "      <td>0.004903</td>\n",
       "      <td>0.016382</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.017101</td>\n",
       "      <td>0.006223</td>\n",
       "      <td>0.007802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-02</th>\n",
       "      <td>1.151851</td>\n",
       "      <td>1.137743</td>\n",
       "      <td>1.125322</td>\n",
       "      <td>1.348379</td>\n",
       "      <td>1.197028</td>\n",
       "      <td>1.192065</td>\n",
       "      <td>1.022679</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.010471</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>-0.004989</td>\n",
       "      <td>0.012587</td>\n",
       "      <td>0.004473</td>\n",
       "      <td>0.003134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-05</th>\n",
       "      <td>1.151467</td>\n",
       "      <td>1.136467</td>\n",
       "      <td>1.128517</td>\n",
       "      <td>1.389403</td>\n",
       "      <td>1.191809</td>\n",
       "      <td>1.199533</td>\n",
       "      <td>1.021996</td>\n",
       "      <td>-0.000333</td>\n",
       "      <td>-0.001122</td>\n",
       "      <td>0.002839</td>\n",
       "      <td>0.030425</td>\n",
       "      <td>-0.004360</td>\n",
       "      <td>0.006265</td>\n",
       "      <td>-0.000668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Norm_Price_VOD  Norm_Price_INTU  Norm_Price_YUM  Norm_Price_NVDA  Norm_Price_DPZ  Norm_Price_Portfolio  Norm_Price_Benchmark_VOO  Return_VOD  Return_INTU  Return_YUM  Return_NVDA  Return_DPZ  Return_Portfolio  Return_Benchmark_VOO\n",
       "Date                                                                                                                                                                                                                                              \n",
       "2017-05-30        1.139254         1.115752        1.101292         1.359928        1.144542              1.172154                  1.011818   -0.004006     0.010749    0.004438     0.021363    0.006951          0.008344             -0.000949\n",
       "2017-05-31        1.154515         1.120459        1.104790         1.355046        1.162272              1.179417                  1.011592    0.013396     0.004219    0.003176    -0.003590    0.015491          0.006196             -0.000223\n",
       "2017-06-01        1.147652         1.125953        1.122889         1.355141        1.182148              1.186757                  1.019484   -0.005945     0.004903    0.016382     0.000070    0.017101          0.006223              0.007802\n",
       "2017-06-02        1.151851         1.137743        1.125322         1.348379        1.197028              1.192065                  1.022679    0.003659     0.010471    0.002167    -0.004989    0.012587          0.004473              0.003134\n",
       "2017-06-05        1.151467         1.136467        1.128517         1.389403        1.191809              1.199533                  1.021996   -0.000333    -0.001122    0.002839     0.030425   -0.004360          0.006265             -0.000668"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- THE \"BULLETPROOF\" VERIFICATION SCRIPT (DEFINITIVELY CORRECTED) ---\n",
    "\n",
    "# (Run this cell AFTER clicking \"Update Chart\" in the cell above)\n",
    "\n",
    "# 2. Access the debug and results data\n",
    "debug_results = debug_container[0]\n",
    "results_dict = results_container[0] # The container holds the full dictionary\n",
    "\n",
    "if debug_results and results_dict:\n",
    "    print(\"--- Debug Data Successfully Captured ---\")\n",
    "\n",
    "    # Verify the Ranking (\"The Report Card\")\n",
    "    print(\"\\n--- [1] Ranking Metrics for all eligible stocks (Top 15 shown) ---\")\n",
    "    display(debug_results['ranking_metrics'].head(15))\n",
    "\n",
    "    # Verify the Daily Performance (\"The Daily Journal\")\n",
    "    print(\"\\n\\n--- [2] Daily Portfolio Trace for the Forward Period ---\")\n",
    "    \n",
    "    # --- THIS IS THE FINAL FIX ---\n",
    "    \n",
    "    # The correct start date for the forward period is stored in our main results dictionary.\n",
    "    forward_period_start_date = results_dict['actual_calc_end_ts']\n",
    "    \n",
    "    # Now we correctly slice the portfolio_trace DataFrame using a proper date.\n",
    "    fwd_trace = debug_results['portfolio_trace'].loc[forward_period_start_date:]\n",
    "\n",
    "    # --- END OF FIX ---\n",
    "    \n",
    "    print(f\"Showing forward trace starting from: {forward_period_start_date.date()}\")\n",
    "    display(fwd_trace.head())\n",
    "else:\n",
    "    print(\"Debug data not found. Did you click 'Update Chart'?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28c86d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user.name:\n",
      "Alice\n",
      "\n",
      "user.age:\n",
      "30\n",
      "\n",
      "user.address.city:\n",
      "Paris\n",
      "\n",
      "user.address.zip:\n",
      "75001\n",
      "\n",
      "server.host:\n",
      "localhost\n",
      "\n",
      "server.port:\n",
      "8080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_nested_dict(d, prefix=\"\"):\n",
    "    \"\"\"Recursively print every key→value in a (possibly) nested dict.\"\"\"\n",
    "    for k, v in d.items():\n",
    "        full_key = f\"{prefix}.{k}\" if prefix else str(k)\n",
    "        if isinstance(v, dict):\n",
    "            print_nested_dict(v, full_key)          # dive deeper\n",
    "        else:\n",
    "            print(f'{full_key}:\\n{v}\\n')\n",
    "\n",
    "# demo\n",
    "nested = {\n",
    "    'user': {\n",
    "        'name': 'Alice',\n",
    "        'age': 30,\n",
    "        'address': {\n",
    "            'city': 'Paris',\n",
    "            'zip': 75001\n",
    "        }\n",
    "    },\n",
    "    'server': {\n",
    "        'host': 'localhost',\n",
    "        'port': 8080\n",
    "    }\n",
    "}\n",
    "\n",
    "print_nested_dict(nested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37b46fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tickers_to_display:\n",
      "['VOD', 'INTU', 'YUM', 'NVDA', 'DPZ']\n",
      "\n",
      "normalized_plot_data:\n",
      "Ticker           VOD      INTU       YUM      NVDA       DPZ\n",
      "Date                                                        \n",
      "2017-05-01  1.000000  1.000000  1.000000  1.000000  1.000000\n",
      "2017-05-02  1.011062  1.003102  1.008972  0.970369  1.012355\n",
      "2017-05-03  1.012590  1.000634  1.038022  0.977587  1.026957\n",
      "2017-05-04  1.020604  1.003423  1.049124  0.973837  1.045181\n",
      "2017-05-05  1.030522  1.004936  1.053992  0.973932  1.060170\n",
      "2017-05-08  1.028611  1.005172  1.051559  0.963711  1.055613\n",
      "2017-05-09  1.028234  1.009635  1.045780  0.965304  1.072464\n",
      "2017-05-10  1.035098  1.012508  1.047604  1.137377  1.074163\n",
      "2017-05-11  1.027851  1.010835  1.051407  1.186235  1.072572\n",
      "2017-05-12  1.052270  1.007885  1.047907  1.199271  1.072024\n",
      "2017-05-15  1.052270  1.016810  1.052776  1.259472  1.078834\n",
      "2017-05-16  1.094615  1.015771  1.054753  1.282915  1.077243\n",
      "2017-05-17  1.100341  0.998639  1.051863  1.197673  1.051057\n",
      "2017-05-18  1.106828  0.997050  1.050950  1.247843  1.068896\n",
      "2017-05-19  1.113314  0.998884  1.065703  1.276664  1.074881\n",
      "2017-05-22  1.130103  1.013066  1.079999  1.303888  1.091460\n",
      "2017-05-23  1.125521  1.028921  1.078630  1.286330  1.093816\n",
      "2017-05-24  1.130480  1.098071  1.094296  1.300788  1.130711\n",
      "2017-05-25  1.141165  1.102289  1.097033  1.297879  1.142071\n",
      "2017-05-26  1.143837  1.103886  1.096426  1.331484  1.136641\n",
      "2017-05-30  1.139254  1.115752  1.101292  1.359928  1.144542\n",
      "2017-05-31  1.154515  1.120459  1.104790  1.355046  1.162272\n",
      "2017-06-01  1.147652  1.125953  1.122889  1.355141  1.182148\n",
      "2017-06-02  1.151851  1.137743  1.125322  1.348379  1.197028\n",
      "2017-06-05  1.151467  1.136467  1.128517  1.389403  1.191809\n",
      "2017-06-06  1.149556  1.128345  1.130341  1.383114  1.195925\n",
      "\n",
      "portfolio_series:\n",
      "Date\n",
      "2017-05-01    1.000000\n",
      "2017-05-02    1.001172\n",
      "2017-05-03    1.011158\n",
      "2017-05-04    1.018434\n",
      "2017-05-05    1.024710\n",
      "2017-05-08    1.020933\n",
      "2017-05-09    1.024283\n",
      "2017-05-10    1.061350\n",
      "2017-05-11    1.069780\n",
      "2017-05-12    1.075871\n",
      "2017-05-15    1.092032\n",
      "2017-05-16    1.105059\n",
      "2017-05-17    1.079915\n",
      "2017-05-18    1.094313\n",
      "2017-05-19    1.105889\n",
      "2017-05-22    1.123703\n",
      "2017-05-23    1.122644\n",
      "2017-05-24    1.150869\n",
      "2017-05-25    1.156087\n",
      "2017-05-26    1.162455\n",
      "2017-05-30    1.172154\n",
      "2017-05-31    1.179417\n",
      "2017-06-01    1.186757\n",
      "2017-06-02    1.192065\n",
      "2017-06-05    1.199533\n",
      "2017-06-06    1.197456\n",
      "dtype: float64\n",
      "\n",
      "benchmark_price_series:\n",
      "Date\n",
      "2014-01-02    137.039\n",
      "2014-01-03    136.916\n",
      "2014-01-06    136.573\n",
      "2014-01-07    137.423\n",
      "2014-01-08    137.480\n",
      "               ...   \n",
      "2018-12-24    193.157\n",
      "2018-12-26    202.928\n",
      "2018-12-27    204.814\n",
      "2018-12-28    204.554\n",
      "2018-12-31    206.395\n",
      "Name: VOO, Length: 1258, dtype: float64\n",
      "\n",
      "performance_data.calc_p_gain:\n",
      "0.1721537041491743\n",
      "\n",
      "performance_data.fwd_p_gain:\n",
      "0.021586167247402477\n",
      "\n",
      "performance_data.full_p_gain:\n",
      "0.19745601004660074\n",
      "\n",
      "performance_data.calc_p_sharpe:\n",
      "11.084308450887484\n",
      "\n",
      "performance_data.fwd_p_sharpe:\n",
      "19.728299379941888\n",
      "\n",
      "performance_data.full_p_sharpe:\n",
      "11.068680275334664\n",
      "\n",
      "performance_data.calc_b_gain:\n",
      "0.011817809212531394\n",
      "\n",
      "performance_data.fwd_b_gain:\n",
      "0.007171976837786698\n",
      "\n",
      "performance_data.full_b_gain:\n",
      "0.019074543104263597\n",
      "\n",
      "performance_data.calc_b_sharpe:\n",
      "1.8979270567678082\n",
      "\n",
      "performance_data.fwd_b_sharpe:\n",
      "5.491719084636405\n",
      "\n",
      "performance_data.full_b_sharpe:\n",
      "2.5444264290857923\n",
      "\n",
      "results_df:\n",
      "          Rank        Metric  MetricValue  CalcPrice  CalcGain   FwdGain\n",
      "Ticker                                                                  \n",
      "VOD        1.0  Sharpe (ATR)     0.770707   16.63220  0.139254  0.009043\n",
      "INTU       2.0  Sharpe (ATR)     0.595607  132.01800  0.115752  0.011286\n",
      "YUM        3.0  Sharpe (ATR)     0.549064   62.36870  0.101292  0.026377\n",
      "NVDA       4.0  Sharpe (ATR)     0.546952    3.57619  0.359928  0.017049\n",
      "DPZ        5.0  Sharpe (ATR)     0.545867  189.91500  0.144542  0.044894\n",
      "VOO (BM)   NaN  Sharpe (ATR)     0.122861  192.55500  0.011818  0.007172\n",
      "\n",
      "actual_calc_end_ts:\n",
      "2017-05-30 00:00:00\n",
      "\n",
      "safe_start_date:\n",
      "2017-05-01 00:00:00\n",
      "\n",
      "safe_viz_end_date:\n",
      "2017-06-06 00:00:00\n",
      "\n",
      "error:\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_nested_dict(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7237d87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ranking_metrics:\n",
      "        FirstPrice  LastPrice  MeanDailyReturn  StdDevDailyReturn  MeanATRP  Metric_Price  Metric_Sharpe  Metric_Sharpe (ATR)\n",
      "Ticker                                                                                                                       \n",
      "VOD       14.59920   16.63220         0.006593           0.010672  0.008555      1.139254       9.807357             0.770707\n",
      "INTU     118.32200  132.01800         0.005610           0.016061  0.009419      1.115752       5.544830             0.595607\n",
      "YUM       56.63230   62.36870         0.004868           0.008219  0.008865      1.101292       9.401147             0.549064\n",
      "NVDA       2.62969    3.57619         0.016445           0.046372  0.030067      1.359928       5.629597             0.546952\n",
      "DPZ      165.93100  189.91500         0.006841           0.011984  0.012532      1.144542       9.062244             0.545867\n",
      "...            ...        ...              ...                ...       ...           ...            ...                  ...\n",
      "BLDR      16.21000   13.52000        -0.008854           0.019246  0.027477      0.834053      -7.302582            -0.322228\n",
      "PRI       75.80340   64.90350        -0.007484           0.022584  0.022258      0.856208      -5.260322            -0.336223\n",
      "DKS       39.19720   32.72000        -0.008411           0.033554  0.024150      0.834754      -3.979420            -0.348294\n",
      "KMI       13.05190   11.70480        -0.005346           0.013395  0.014150      0.896789      -6.335313            -0.377778\n",
      "AKAM      61.48000   47.43000        -0.012197           0.036397  0.027137      0.771470      -5.319677            -0.449465\n",
      "\n",
      "[521 rows x 8 columns]\n",
      "\n",
      "portfolio_trace:\n",
      "            Norm_Price_VOD  Norm_Price_INTU  Norm_Price_YUM  Norm_Price_NVDA  Norm_Price_DPZ  Norm_Price_Portfolio  Norm_Price_Benchmark_VOO  Return_VOD  Return_INTU  Return_YUM  Return_NVDA  Return_DPZ  Return_Portfolio  Return_Benchmark_VOO\n",
      "Date                                                                                                                                                                                                                                              \n",
      "2017-05-01        1.000000         1.000000        1.000000         1.000000        1.000000              1.000000                  1.000000         NaN          NaN         NaN          NaN         NaN               NaN                   NaN\n",
      "2017-05-02        1.011062         1.003102        1.008972         0.970369        1.012355              1.001172                  1.000321    0.011062     0.003102    0.008972    -0.029631    0.012355          0.001172              0.000321\n",
      "2017-05-03        1.012590         1.000634        1.038022         0.977587        1.026957              1.011158                  0.999317    0.001511    -0.002460    0.028792     0.007438    0.014424          0.009974             -0.001003\n",
      "2017-05-04        1.020604         1.003423        1.049124         0.973837        1.045181              1.018434                  1.000231    0.007914     0.002787    0.010695    -0.003835    0.017746          0.007196              0.000915\n",
      "2017-05-05        1.030522         1.004936        1.053992         0.973932        1.060170              1.024710                  1.004246    0.009718     0.001508    0.004640     0.000098    0.014340          0.006163              0.004014\n",
      "2017-05-08        1.028611         1.005172        1.051559         0.963711        1.055613              1.020933                  1.004288   -0.001854     0.000235   -0.002309    -0.010495   -0.004298         -0.003686              0.000042\n",
      "2017-05-09        1.028234         1.009635        1.045780         0.965304        1.072464              1.024283                  1.003011   -0.000366     0.004439   -0.005496     0.001653    0.015963          0.003281             -0.001271\n",
      "2017-05-10        1.035098         1.012508        1.047604         1.137377        1.074163              1.061350                  1.004882    0.006675     0.002846    0.001744     0.178258    0.001585          0.036188              0.001865\n",
      "2017-05-11        1.027851         1.010835        1.051407         1.186235        1.072572              1.069780                  1.002832   -0.007001    -0.001653    0.003631     0.042956   -0.001481          0.007943             -0.002039\n",
      "2017-05-12        1.052270         1.007885        1.047907         1.199271        1.072024              1.075871                  1.001277    0.023757    -0.002918   -0.003329     0.010989   -0.000511          0.005694             -0.001551\n",
      "2017-05-15        1.052270         1.016810        1.052776         1.259472        1.078834              1.092032                  1.006342    0.000000     0.008855    0.004646     0.050198    0.006353          0.015021              0.005059\n",
      "2017-05-16        1.094615         1.015771        1.054753         1.282915        1.077243              1.105059                  1.006164    0.040241    -0.001022    0.001879     0.018614   -0.001475          0.011929             -0.000178\n",
      "2017-05-17        1.100341         0.998639        1.051863         1.197673        1.051057              1.079915                  0.988319    0.005231    -0.016865   -0.002741    -0.066444   -0.024308         -0.022754             -0.017736\n",
      "2017-05-18        1.106828         0.997050        1.050950         1.247843        1.068896              1.094313                  0.991924    0.005895    -0.001591   -0.000868     0.041889    0.016972          0.013333              0.003647\n",
      "2017-05-19        1.113314         0.998884        1.065703         1.276664        1.074881              1.105889                  0.998082    0.005861     0.001839    0.014038     0.023097    0.005599          0.010578              0.006209\n",
      "2017-05-22        1.130103         1.013066        1.079999         1.303888        1.091460              1.123703                  1.003652    0.015080     0.014197    0.013414     0.021324    0.015424          0.016108              0.005581\n",
      "2017-05-23        1.125521         1.028921        1.078630         1.286330        1.093816              1.122644                  1.005612   -0.004055     0.015651   -0.001267    -0.013465    0.002159         -0.000943              0.001953\n",
      "2017-05-24        1.130480         1.098071        1.094296         1.300788        1.130711              1.150869                  1.008034    0.004406     0.067207    0.014524     0.011240    0.033730          0.025142              0.002409\n",
      "2017-05-25        1.141165         1.102289        1.097033         1.297879        1.142071              1.156087                  1.012732    0.009452     0.003841    0.002501    -0.002236    0.010047          0.004534              0.004660\n",
      "2017-05-26        1.143837         1.103886        1.096426         1.331484        1.136641              1.162455                  1.012779    0.002341     0.001449   -0.000554     0.025892   -0.004754          0.005508              0.000047\n",
      "2017-05-30        1.139254         1.115752        1.101292         1.359928        1.144542              1.172154                  1.011818   -0.004006     0.010749    0.004438     0.021363    0.006951          0.008344             -0.000949\n",
      "2017-05-31        1.154515         1.120459        1.104790         1.355046        1.162272              1.179417                  1.011592    0.013396     0.004219    0.003176    -0.003590    0.015491          0.006196             -0.000223\n",
      "2017-06-01        1.147652         1.125953        1.122889         1.355141        1.182148              1.186757                  1.019484   -0.005945     0.004903    0.016382     0.000070    0.017101          0.006223              0.007802\n",
      "2017-06-02        1.151851         1.137743        1.125322         1.348379        1.197028              1.192065                  1.022679    0.003659     0.010471    0.002167    -0.004989    0.012587          0.004473              0.003134\n",
      "2017-06-05        1.151467         1.136467        1.128517         1.389403        1.191809              1.199533                  1.021996   -0.000333    -0.001122    0.002839     0.030425   -0.004360          0.006265             -0.000668\n",
      "2017-06-06        1.149556         1.128345        1.130341         1.383114        1.195925              1.197456                  1.019075   -0.001660    -0.007147    0.001616    -0.004527    0.003454         -0.001731             -0.002859\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_nested_dict(debug_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94950cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VOO'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict['benchmark_price_series'].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "513f5003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tickers_to_verify: ['VOD', 'INTU', 'YUM', 'NVDA', 'DPZ']\n",
      "benchmark_ticker: VOO\n",
      "start_date: 2017-05-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "tickers_to_verify = results_dict['tickers_to_display']\n",
    "benchmark_ticker = results_dict['benchmark_price_series'].name\n",
    "start_date = results_dict['safe_start_date']\n",
    "\n",
    "print(f'tickers_to_verify: {tickers_to_verify}')\n",
    "print(f'benchmark_ticker: {benchmark_ticker}')\n",
    "print(f'start_date: {start_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c775b207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Verification Report for Portfolio vs. Benchmark"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Portfolio Tickers:** `['VOD', 'INTU', 'YUM', 'NVDA', 'DPZ']`\n",
       "**Benchmark Ticker:** `VOO`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Analysis Start:** `2017-05-01` (Selected: `2017-05-01`)\n",
       "**Calc End:** `2017-05-30` (20 trading days)\n",
       "**Fwd End:** `2017-06-06` (5 trading days)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Data exported to: export_csv\\verify_group_2017-05-01_VOD_INTU_YUM_NVDA_DPZ.csv\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### A. Calculation Period"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Verification for: `Group Portfolio`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Value (2017-05-01): 1.0000\n",
      "End Value   (2017-05-30): 1.1722\n",
      "Gain = 17.22%\n",
      "Mean Daily Return: 0.008036\n",
      "Std Dev: 0.011509\n",
      "Sharpe = 11.08\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Verification for: `Benchmark`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Value (2017-05-01): 190.3060\n",
      "End Value   (2017-05-30): 192.5550\n",
      "Gain = 1.18%\n",
      "Mean Daily Return: 0.000600\n",
      "Std Dev: 0.005015\n",
      "Sharpe = 1.90\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### B. Forward Period"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Verification for: `Group Portfolio`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Value (2017-05-30): 1.1722\n",
      "End Value   (2017-06-06): 1.1975\n",
      "Gain = 2.16%\n",
      "Mean Daily Return: 0.004285\n",
      "Std Dev: 0.003448\n",
      "Sharpe = 19.73\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Verification for: `Benchmark`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Value (2017-05-30): 192.5550\n",
      "End Value   (2017-06-06): 193.9360\n",
      "Gain = 0.72%\n",
      "Mean Daily Return: 0.001437\n",
      "Std Dev: 0.004154\n",
      "Sharpe = 5.49\n"
     ]
    }
   ],
   "source": [
    "verify_group_tickers_walk_forward_calculation(df_ohlcv=df_dev, \n",
    "                                              tickers_to_verify=tickers_to_verify, \n",
    "                                              benchmark_ticker=benchmark_ticker,\n",
    "                                              start_date=start_date, \n",
    "                                              calc_period=20, \n",
    "                                              fwd_period=5,\n",
    "                                              master_calendar_ticker=benchmark_ticker, \n",
    "                                              export_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Verification Report for Ticker Ranking: `VOD`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### A. Calculation Period (for Ranking Metrics)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Period Start:** `2017-05-01`\n",
       "**Period End:** `2017-05-30`\n",
       "**Total Trading Days:** `21` (Requested: `20`)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Detailed Metric Calculation Data"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Start of Calculation Period ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj High</th>\n",
       "      <th>Adj Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Daily_Return</th>\n",
       "      <th>TR</th>\n",
       "      <th>ATR_14</th>\n",
       "      <th>ATRP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-05-01</th>\n",
       "      <td>14.6214</td>\n",
       "      <td>14.5546</td>\n",
       "      <td>14.5992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0668</td>\n",
       "      <td>0.066800</td>\n",
       "      <td>0.004576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-02</th>\n",
       "      <td>14.7886</td>\n",
       "      <td>14.6883</td>\n",
       "      <td>14.7607</td>\n",
       "      <td>0.011062</td>\n",
       "      <td>0.1894</td>\n",
       "      <td>0.075557</td>\n",
       "      <td>0.005119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-03</th>\n",
       "      <td>14.8888</td>\n",
       "      <td>14.7551</td>\n",
       "      <td>14.7830</td>\n",
       "      <td>0.001511</td>\n",
       "      <td>0.1337</td>\n",
       "      <td>0.079710</td>\n",
       "      <td>0.005392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-04</th>\n",
       "      <td>14.9111</td>\n",
       "      <td>14.7329</td>\n",
       "      <td>14.9000</td>\n",
       "      <td>0.007914</td>\n",
       "      <td>0.1782</td>\n",
       "      <td>0.086745</td>\n",
       "      <td>0.005822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-05</th>\n",
       "      <td>15.0503</td>\n",
       "      <td>14.9668</td>\n",
       "      <td>15.0448</td>\n",
       "      <td>0.009718</td>\n",
       "      <td>0.1503</td>\n",
       "      <td>0.091285</td>\n",
       "      <td>0.006068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Adj High  Adj Low  Adj Close  Daily_Return      TR    ATR_14      ATRP\n",
       "Date                                                                              \n",
       "2017-05-01   14.6214  14.5546    14.5992           NaN  0.0668  0.066800  0.004576\n",
       "2017-05-02   14.7886  14.6883    14.7607      0.011062  0.1894  0.075557  0.005119\n",
       "2017-05-03   14.8888  14.7551    14.7830      0.001511  0.1337  0.079710  0.005392\n",
       "2017-05-04   14.9111  14.7329    14.9000      0.007914  0.1782  0.086745  0.005822\n",
       "2017-05-05   15.0503  14.9668    15.0448      0.009718  0.1503  0.091285  0.006068"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- End of Calculation Period ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj High</th>\n",
       "      <th>Adj Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Daily_Return</th>\n",
       "      <th>TR</th>\n",
       "      <th>ATR_14</th>\n",
       "      <th>ATRP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-05-23</th>\n",
       "      <td>16.5208</td>\n",
       "      <td>16.4206</td>\n",
       "      <td>16.4317</td>\n",
       "      <td>-0.004055</td>\n",
       "      <td>0.1002</td>\n",
       "      <td>0.180192</td>\n",
       "      <td>0.010966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-24</th>\n",
       "      <td>16.5264</td>\n",
       "      <td>16.4429</td>\n",
       "      <td>16.5041</td>\n",
       "      <td>0.004406</td>\n",
       "      <td>0.0947</td>\n",
       "      <td>0.174085</td>\n",
       "      <td>0.010548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-25</th>\n",
       "      <td>16.6991</td>\n",
       "      <td>16.6155</td>\n",
       "      <td>16.6601</td>\n",
       "      <td>0.009452</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0.175579</td>\n",
       "      <td>0.010539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-26</th>\n",
       "      <td>16.7047</td>\n",
       "      <td>16.5431</td>\n",
       "      <td>16.6991</td>\n",
       "      <td>0.002341</td>\n",
       "      <td>0.1616</td>\n",
       "      <td>0.174580</td>\n",
       "      <td>0.010454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-30</th>\n",
       "      <td>16.6879</td>\n",
       "      <td>16.5765</td>\n",
       "      <td>16.6322</td>\n",
       "      <td>-0.004006</td>\n",
       "      <td>0.1226</td>\n",
       "      <td>0.170868</td>\n",
       "      <td>0.010273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Adj High  Adj Low  Adj Close  Daily_Return      TR    ATR_14      ATRP\n",
       "Date                                                                              \n",
       "2017-05-23   16.5208  16.4206    16.4317     -0.004055  0.1002  0.180192  0.010966\n",
       "2017-05-24   16.5264  16.4429    16.5041      0.004406  0.0947  0.174085  0.010548\n",
       "2017-05-25   16.6991  16.6155    16.6601      0.009452  0.1950  0.175579  0.010539\n",
       "2017-05-26   16.7047  16.5431    16.6991      0.002341  0.1616  0.174580  0.010454\n",
       "2017-05-30   16.6879  16.5765    16.6322     -0.004006  0.1226  0.170868  0.010273"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Data exported to: export_csv\\verify_ticker_2017-05-01_VOD.csv\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### `MetricValue` Verification Summary:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Price Metric: (Last Price / First Price) = (16.63 / 14.60) = 1.1393\n",
      "2. Sharpe Metric: (Mean Daily Return / Std Dev) * sqrt(252) = 9.8074\n",
      "3. Sharpe (ATR) Metric: (Mean Daily Return / Mean ATRP) = (0.006593 / 0.008555) = 0.7707\n"
     ]
    }
   ],
   "source": [
    "verify_ticker_ranking_metrics(df_ohlcv=df_dev, \n",
    "                              ticker='VOD', \n",
    "                              start_date=start_date, \n",
    "                              calc_period=20,\n",
    "                              master_calendar_ticker='VOO', \n",
    "                              export_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5825fdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.loc['VOD'][\"2017-05-01\":\"2017-05-30\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9f5209",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cba46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*debug_container[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597a7b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug_container[0]['ranking_metrics'].head(50)\n",
    "debug_container[0]['ranking_metrics'].columns\n",
    "\n",
    "# debug_container[0]['portfolio_trace'].head(50)\n",
    "# debug_container[0]['portfolio_trace'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db740c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "from IPython.display import display\n",
    "\n",
    "# --- Assume all functions from our project context are already defined ---\n",
    "# (calculate_rolling_quality_metrics, get_eligible_universe, run_walk_forward_step, etc.)\n",
    "\n",
    "# --- Assume df_dev and bot_config are already defined from previous steps ---\n",
    "\n",
    "def run_strategy_search(df_ohlcv, config):\n",
    "    \"\"\"\n",
    "    Runs the main backtesting loop based on a provided configuration dictionary.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # --- 1. PRE-PROCESSING (Run once for efficiency) ---\n",
    "    print(\"--- Phase 1: Pre-processing Data ---\")\n",
    "    \n",
    "    # Calculate quality metrics for the entire development period\n",
    "    quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "\n",
    "    # Unstack the data for fast slicing later. This is a major optimization.\n",
    "    print(\"Unstacking data for performance...\")\n",
    "    df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "    df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "    df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    print(\"✅ Pre-processing complete.\\n\")\n",
    "    \n",
    "    # --- 2. SETUP THE MAIN LOOP ---\n",
    "    print(\"--- Phase 2: Setting up Simulation Loops ---\")\n",
    "    \n",
    "    # Create all parameter combinations to test\n",
    "    param_combinations = list(product(\n",
    "        config['calc_periods'],\n",
    "        config['fwd_periods'],\n",
    "        config['metrics'],\n",
    "        config['rank_slices']\n",
    "    ))\n",
    "    \n",
    "    # Create the list of dates where the bot will re-evaluate the strategy\n",
    "    step_dates = pd.date_range(\n",
    "        start=config['search_start_date'],\n",
    "        end=config['search_end_date'],\n",
    "        freq=config['step_frequency']\n",
    "    )\n",
    "    \n",
    "    # Map string periods to pandas DateOffset objects for our core function\n",
    "    period_options = {\n",
    "        '1M': pd.DateOffset(months=1), '3M': pd.DateOffset(months=3),\n",
    "        '6M': pd.DateOffset(months=6), '1Y': pd.DateOffset(years=1)\n",
    "    }\n",
    "    \n",
    "    results_log = []\n",
    "    total_sims = len(param_combinations) * len(step_dates)\n",
    "    print(f\"Found {len(param_combinations)} parameter sets and {len(step_dates)} time steps.\")\n",
    "    print(f\"Total simulations to run: {total_sims}\")\n",
    "    print(\"✅ Setup complete. Starting main loop...\\n\")\n",
    "\n",
    "    # --- 3. RUN THE MAIN LOOP ---\n",
    "    print(\"--- Phase 3: Running Simulations ---\")\n",
    "    \n",
    "    # Use tqdm for a progress bar on the outer loop\n",
    "    pbar = tqdm(param_combinations, desc=\"Parameter Sets\")\n",
    "    for params in pbar:\n",
    "        # Unpack parameters for this run\n",
    "        calc_period_str, fwd_period_str, metric, rank_slice = params\n",
    "        calc_period = period_options[calc_period_str]\n",
    "        fwd_period = period_options[fwd_period_str]\n",
    "        rank_start, rank_end = rank_slice\n",
    "\n",
    "        # Inner loop for stepping through time\n",
    "        for step_date in step_dates:\n",
    "            # 3a. DYNAMIC UNIVERSE SELECTION\n",
    "            eligible_tickers = get_eligible_universe(\n",
    "                quality_metrics_df,\n",
    "                filter_date=step_date,\n",
    "                thresholds=config['quality_thresholds']\n",
    "            )\n",
    "\n",
    "            if not eligible_tickers:\n",
    "                # print(f\"Warning: No eligible tickers on {step_date.date()}. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            # 3b. FILTER DATA FOR THIS STEP\n",
    "            df_close_step = df_close_full[eligible_tickers]\n",
    "            df_high_step = df_high_full[eligible_tickers]\n",
    "            df_low_step = df_low_full[eligible_tickers]\n",
    "\n",
    "            # 3c. RUN THE CORE ANALYSIS\n",
    "            step_result = run_walk_forward_step(\n",
    "                df_close_full=df_close_step,\n",
    "                df_high_full=df_high_step,\n",
    "                df_low_full=df_low_step,\n",
    "                start_date=step_date,\n",
    "                calc_period=calc_period,\n",
    "                fwd_period=fwd_period,\n",
    "                metric=metric,\n",
    "                rank_start=rank_start,\n",
    "                rank_end=rank_end,\n",
    "                benchmark_ticker=config['benchmark_ticker']\n",
    "            )\n",
    "            \n",
    "            # 3d. LOG THE RESULTS\n",
    "            if step_result['error'] is None:\n",
    "                p = step_result['performance_data']\n",
    "                log_entry = {\n",
    "                    'step_date': step_date.date(),\n",
    "                    'calc_period': calc_period_str,\n",
    "                    'fwd_period': fwd_period_str,\n",
    "                    'metric': metric,\n",
    "                    'rank_start': rank_start,\n",
    "                    'rank_end': rank_end,\n",
    "                    'num_universe': len(eligible_tickers),\n",
    "                    'num_portfolio': len(step_result['tickers_to_display']),\n",
    "                    'fwd_p_gain': p['fwd_p_gain'],\n",
    "                    'fwd_b_gain': p['fwd_b_gain'],\n",
    "                    'fwd_gain_delta': p['fwd_p_gain'] - p['fwd_b_gain'] if not np.isnan(p['fwd_b_gain']) else np.nan,\n",
    "                    'fwd_p_sharpe': p['fwd_p_sharpe'],\n",
    "                }\n",
    "                results_log.append(log_entry)\n",
    "\n",
    "    print(\"✅ Main loop finished.\\n\")\n",
    "\n",
    "    # --- 4. SAVE THE RESULTS ---\n",
    "    print(\"--- Phase 4: Saving Results ---\")\n",
    "    if not results_log:\n",
    "        print(\"Warning: No results were generated. The output file will be empty.\")\n",
    "        return None\n",
    "\n",
    "    final_df = pd.DataFrame(results_log)\n",
    "    output_path = config['results_output_path']\n",
    "    final_df.to_csv(output_path, index=False, float_format='%.4f')\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"✅ Results saved to '{output_path}'\")\n",
    "    print(f\"Total execution time: {end_time - start_time:.2f} seconds.\")\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# --- Execute the Bot ---\n",
    "dev_results_df = run_strategy_search(df_dev, bot_config)\n",
    "\n",
    "# --- Display a sample of the results ---\n",
    "if dev_results_df is not None:\n",
    "    print(\"\\n--- Sample of Generated Results ---\")\n",
    "    display(dev_results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cdce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_results_df.to_csv('./export_csv/dev_results_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584c600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our inspection rules inside the rolling window\n",
    "ticker_thresholds = {\n",
    "    'min_median_dollar_volume': 10_000_000, # $10 million median daily trade volume\n",
    "    'max_stale_pct': 0.1,                   # Allow 10% stale days (i.e. Volume=0 or High=Low)\n",
    "    'max_same_vol_count': 1                 # Allow at most 1 suspicious volume event (i.e. same Volume on consecutive day)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2d172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Verification for the first row of bot results ---\n",
    "\n",
    "print(\"--- Replicating the scenario from the first CSV row ---\")\n",
    "print(\"Start Date: 2014-07-31\")\n",
    "print(\"Calc Period: 6M, Fwd Period: 3M\")\n",
    "print(\"Metric: Sharpe, Ranks: 1 to 10\")\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\"\\nInstructions: The UI will load with the correct defaults. Simply click the 'Update Chart' button.\")\n",
    "\n",
    "# Call the plotter using the parameters from the CSV row as defaults\n",
    "plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_dev,  # CRITICAL: Use the same df_dev as the bot\n",
    "    default_start_date='2017-04-30',\n",
    "    default_calc_period='6M',\n",
    "    default_fwd_period='3M',\n",
    "    default_metric='Sharpe (ATR)',\n",
    "    default_rank_start=1,\n",
    "    default_rank_end=10,\n",
    "    default_benchmark_ticker='VOO',\n",
    "    quality_thresholds=ticker_thresholds,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc9b9ad",
   "metadata": {},
   "source": [
    "### Compare bot results vs verified plot_walk_forward_analyzer_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54317ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the row\n",
    "row_index = 43\n",
    "row = dev_results_df.iloc[row_index]\n",
    "\n",
    "# convert to dict and reformat step_date\n",
    "row_dict = row.to_dict()\n",
    "row_dict['step_date'] = row_dict['step_date'].strftime('%Y-%m-%d')\n",
    "print(f'row no: {row_index}')\n",
    "print(f'row_dict: {row_dict}')\n",
    "\n",
    "_start_date=row_dict['step_date']\n",
    "_calc_period=row_dict['calc_period']\n",
    "_fwd_period=row_dict['fwd_period']\n",
    "_metric=row_dict['metric']\n",
    "_rank_start=row_dict['rank_start']\n",
    "_rank_end=row_dict['rank_end']\n",
    "_benchmark_ticker='VOO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7accff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_dev,  # CRITICAL: Use the same df_dev as the bot\n",
    "    default_start_date=_start_date,\n",
    "    default_calc_period=_calc_period,\n",
    "    default_fwd_period=_fwd_period,\n",
    "    default_metric=_metric,\n",
    "    default_rank_start=_rank_start,\n",
    "    default_rank_end=_rank_end,\n",
    "    default_benchmark_ticker=_benchmark_ticker,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01521b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_df = calculate_rolling_quality_metrics(\n",
    "    df_ohlcv=df_OHLCV,\n",
    "    window=252,\n",
    "    min_periods=126,\n",
    "    debug=False,  # <-- The key to our new, improved workflow    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4b2b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. make sure the whole frame is sorted\n",
    "df_tmp = quality_df.sort_index()\n",
    "\n",
    "# 2a. pick the exact date if it exists, otherwise the previous one\n",
    "date_needed = pd.Timestamp(_start_date)\n",
    "dates = df_tmp.index.get_level_values('Date').unique().sort_values()   # ← sorted\n",
    "# first date >= date_needed  (later)\n",
    "pos = dates.searchsorted(date_needed, side='left')\n",
    "if pos == len(dates):          # date_needed is after the last date\n",
    "    later_date = pd.NaT\n",
    "else:\n",
    "    later_date = dates[pos]\n",
    "\n",
    "print(f'_start_date: {_start_date}')\n",
    "print(f'real start date: {later_date}')\n",
    "\n",
    "# 3. slice\n",
    "# quality_df = df_tmp.xs(later_date, level='Date')\n",
    "# print(quality_df)\n",
    "print(f\"--- Quality Metrics for {later_date} ---\")\n",
    "# print(quality_df.xs('2025-10-03', level='Date'))\n",
    "print(quality_df.xs(later_date, level='Date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549894d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible_tickers = get_eligible_universe(quality_metrics_df=quality_df, \n",
    "                                        #  filter_date=_start_date, \n",
    "                                         filter_date=later_date,                                         \n",
    "                                         thresholds=ticker_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3898a28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = df_OHLCV.loc[eligible_tickers].copy()\n",
    "_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5645bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_walk_forward_analyzer_original(\n",
    "    df_ohlcv=_df,  # CRITICAL: Use the same df_dev as the bot\n",
    "    default_start_date=_start_date,\n",
    "    default_calc_period=_calc_period,\n",
    "    default_fwd_period=_fwd_period,\n",
    "    default_metric=_metric,\n",
    "    default_rank_start=_rank_start,\n",
    "    default_rank_end=_rank_end,\n",
    "    default_benchmark_ticker=_benchmark_ticker,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ffe810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Load the Bot's Output ---\n",
    "try:\n",
    "    results_df = pd.read_csv(bot_config['results_output_path'])\n",
    "    print(f\"Successfully loaded '{bot_config['results_output_path']}'. Shape: {results_df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: The results file was not found. Please run the bot first.\")\n",
    "    # In a real script, you'd exit here. For a notebook, we'll stop.\n",
    "    results_df = None\n",
    "\n",
    "if results_df is not None:\n",
    "    # --- 2. Define the Strategy Parameters for Grouping ---\n",
    "    # These are the columns that uniquely identify one strategy configuration.\n",
    "    # strategy_params = ['calc_period', 'metric', 'rank_start', 'rank_end']\n",
    "    strategy_params = ['calc_period', 'fwd_period', 'metric', 'rank_start', 'rank_end']    \n",
    "\n",
    "    # --- 3. Group and Aggregate the Results ---\n",
    "    # We group by the strategy parameters and calculate key performance metrics for each group.\n",
    "    summary_df = results_df.groupby(strategy_params).agg(\n",
    "        avg_fwd_p_gain=('fwd_p_gain', 'mean'),\n",
    "        std_fwd_p_gain=('fwd_p_gain', 'std'),\n",
    "        avg_fwd_gain_delta=('fwd_gain_delta', 'mean'),\n",
    "        # Calculate Win Rate: The percentage of periods with positive forward gain.\n",
    "        win_rate=('fwd_p_gain', lambda x: (x > 0).sum() / len(x) if len(x) > 0 else 0),\n",
    "        # Count the number of periods tested for this strategy\n",
    "        num_periods=('step_date', 'count')\n",
    "    ).sort_values(by='avg_fwd_gain_delta', ascending=False) # Sort by outperformance vs benchmark\n",
    "\n",
    "    # --- 4. Format and Display the Summary Table ---\n",
    "    print(\"\\n--- Strategy Performance Summary (2014-2018 Development Run) ---\")\n",
    "    \n",
    "    # Apply formatting for better readability\n",
    "    formatted_summary = summary_df.style.format({\n",
    "        'avg_fwd_p_gain': '{:+.2%}',\n",
    "        'std_fwd_p_gain': '{:.2%}',\n",
    "        'avg_fwd_gain_delta': '{:+.2%}',\n",
    "        'win_rate': '{:.1%}',\n",
    "    }).set_properties(**{'text-align': 'right'})\n",
    "\n",
    "    display(formatted_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b389d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_cumulative_performance(df_ohlcv, strategy_params, quality_thresholds):\n",
    "    \"\"\"\n",
    "    Plots the cumulative performance of a SINGLE strategy over a specified time range.\n",
    "\n",
    "    This function simulates rebalancing a portfolio at a fixed frequency and charts\n",
    "    the resulting equity curve against a benchmark.\n",
    "    \"\"\"\n",
    "    print(\"--- Running Cumulative Performance Simulation for the Winning Strategy ---\")\n",
    "    \n",
    "    # --- 1. Setup and Pre-processing ---\n",
    "    # Unpack strategy parameters from the dictionary\n",
    "    start_date = strategy_params['start_date']\n",
    "    end_date = strategy_params['end_date']\n",
    "    calc_period_str = strategy_params['calc_period']\n",
    "    fwd_period_str = strategy_params['fwd_period']\n",
    "    metric = strategy_params['metric']\n",
    "    rank_start = strategy_params['rank_start']\n",
    "    rank_end = strategy_params['rank_end']\n",
    "    benchmark_ticker = strategy_params['benchmark_ticker']\n",
    "    \n",
    "    # Pre-calculate quality metrics and unstack data once for efficiency\n",
    "    quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "    df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "    df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "    df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "\n",
    "    # Map string periods to pandas DateOffset objects\n",
    "    period_options = {'3M': pd.DateOffset(months=3), '6M': pd.DateOffset(months=6), '1Y': pd.DateOffset(years=1)}\n",
    "    calc_period = period_options[calc_period_str]\n",
    "    fwd_period = period_options[fwd_period_str] # This also defines our rebalancing frequency\n",
    "    \n",
    "    # --- 2. Main Simulation Loop ---\n",
    "    # Create the rebalancing dates\n",
    "    step_dates = pd.date_range(start=start_date, end=end_date, freq=f'{fwd_period.months}ME')\n",
    "    \n",
    "    all_fwd_gains = []\n",
    "    \n",
    "    print(f\"Simulating from {step_dates[0].date()} to {step_dates[-1].date()}...\")\n",
    "    \n",
    "    for step_date in step_dates:\n",
    "        # Get the eligible universe for this specific rebalancing date\n",
    "        eligible_tickers = get_eligible_universe(quality_metrics_df, step_date, quality_thresholds)\n",
    "        if not eligible_tickers: continue\n",
    "            \n",
    "        df_close_step = df_close_full[eligible_tickers]\n",
    "        df_high_step = df_high_full[eligible_tickers]\n",
    "        df_low_step = df_low_full[eligible_tickers]\n",
    "        \n",
    "        # Run the core calculation for this single step in time\n",
    "        step_result = run_walk_forward_step(\n",
    "            df_close_step, df_high_step, df_low_step,\n",
    "            step_date, calc_period, fwd_period,\n",
    "            metric, rank_start, rank_end, benchmark_ticker\n",
    "        )\n",
    "        \n",
    "        if step_result['error'] is None:\n",
    "            # Extract the forward portion of the portfolio's performance\n",
    "            fwd_series = step_result['portfolio_series'].loc[step_result['actual_calc_end_ts']:]\n",
    "            all_fwd_gains.append(fwd_series.pct_change().dropna())\n",
    "            \n",
    "    # --- 3. Stitch Together Results & Plot ---\n",
    "    if not all_fwd_gains:\n",
    "        print(\"Error: No valid periods were simulated. Cannot plot.\")\n",
    "        return\n",
    "\n",
    "    # Concatenate all the forward period returns into one long series\n",
    "    strategy_returns = pd.concat(all_fwd_gains)\n",
    "    \n",
    "    # Create the equity curve (cumulative performance)\n",
    "    # (1 + returns).cumprod() is the standard way to calculate this\n",
    "    strategy_equity_curve = (1 + strategy_returns).cumprod()\n",
    "    \n",
    "    # Get the benchmark returns for the same period\n",
    "    benchmark_returns = df_close_full[benchmark_ticker].pct_change()\n",
    "    benchmark_returns_filtered = benchmark_returns.loc[strategy_equity_curve.index]\n",
    "    benchmark_equity_curve = (1 + benchmark_returns_filtered).cumprod()\n",
    "    \n",
    "    # Create the plot\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=strategy_equity_curve.index, y=strategy_equity_curve,\n",
    "                             mode='lines', name='Winning Strategy', line=dict(color='green', width=3)))\n",
    "    fig.add_trace(go.Scatter(x=benchmark_equity_curve.index, y=benchmark_equity_curve,\n",
    "                             mode='lines', name=f'Benchmark ({benchmark_ticker})', line=dict(color='black', dash='dash')))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"Cumulative Performance: '{metric}' Strategy (Top {rank_start}-{rank_end}) vs. Benchmark\",\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=\"Cumulative Growth (Normalized to 1)\",\n",
    "        legend_title=\"Portfolio\",\n",
    "        hovermode='x unified',\n",
    "        height=600\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380f1890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define the parameters for our winning strategy ---\n",
    "winning_strategy_params = {\n",
    "    'start_date': '2014-01-31',\n",
    "    'end_date': '2018-12-31',\n",
    "    'calc_period': '6M',\n",
    "    'fwd_period': '3M',\n",
    "    'metric': 'Sharpe (ATR)',\n",
    "    'rank_start': 1,\n",
    "    'rank_end': 10,\n",
    "    'benchmark_ticker': 'VOO'\n",
    "}\n",
    "\n",
    "# Get the quality thresholds from the bot's configuration\n",
    "quality_thresholds_from_bot = bot_config['quality_thresholds']\n",
    "\n",
    "# --- Run the simulation and generate the plot ---\n",
    "plot_cumulative_performance(\n",
    "    df_ohlcv=df_dev,  # Run on our development dataset\n",
    "    strategy_params=winning_strategy_params,\n",
    "    quality_thresholds=quality_thresholds_from_bot\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
