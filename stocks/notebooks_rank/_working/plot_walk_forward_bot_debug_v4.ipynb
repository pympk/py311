{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7f7824f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# GOLDEN COPY - COMPLETE PROJECT CODE (All Fixes Included)\n",
    "# Version: Final TR Calculation & Multi-Ticker Stability\n",
    "# Date: 2023-10-27\n",
    "# ==============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime, date\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "import pprint\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import re\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.width', 3000)\n",
    "\n",
    "# --- A. HELPER FUNCTIONS ---\n",
    "\n",
    "def calculate_gain(price_series: pd.Series):\n",
    "    \"\"\"Calculates the total gain over a series of prices.\"\"\"\n",
    "    # Ensure there are at least two data points to calculate a gain\n",
    "    if price_series.dropna().shape[0] < 2: return np.nan\n",
    "    # Use forward-fill for the end price and back-fill for the start price\n",
    "    # to handle potential NaNs at the beginning or end of the series.\n",
    "    return (price_series.ffill().iloc[-1] / price_series.bfill().iloc[0]) - 1\n",
    "\n",
    "def calculate_sharpe(return_series: pd.Series):\n",
    "    \"\"\"Calculates the annualized Sharpe ratio from a series of daily returns.\"\"\"\n",
    "    # Ensure there are at least two returns to calculate a standard deviation\n",
    "    if return_series.dropna().shape[0] < 2: return np.nan\n",
    "    std_dev = return_series.std()\n",
    "    # Avoid division by zero if returns are constant\n",
    "    if std_dev > 0 and std_dev != np.inf:\n",
    "        return (return_series.mean() / std_dev) * np.sqrt(252)\n",
    "    return np.nan\n",
    "\n",
    "# --- B. THE CORE CALCULATION ENGINE ---\n",
    "\n",
    "def run_walk_forward_step(df_close_full, df_high_full, df_low_full,\n",
    "                          master_trading_days,\n",
    "                          start_date, calc_period, fwd_period,\n",
    "                          metric, rank_start, rank_end, benchmark_ticker,\n",
    "                          debug=False):\n",
    "    \"\"\"Runs a single step of the walk-forward analysis using precise trading days.\"\"\"\n",
    "    debug_data = {} if debug else None\n",
    "    \n",
    "    # 1. Determine exact date ranges using the master trading day calendar\n",
    "    try:\n",
    "        start_idx = master_trading_days.get_loc(start_date)\n",
    "    except KeyError:\n",
    "        return ({'error': f\"Start date {start_date.date()} is not a valid trading day.\"}, None)\n",
    "        \n",
    "    calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "    viz_end_idx = min(calc_end_idx + fwd_period, len(master_trading_days) - 1)\n",
    "\n",
    "    safe_start_date = master_trading_days[start_idx]\n",
    "    safe_calc_end_date = master_trading_days[calc_end_idx]\n",
    "    safe_viz_end_date = master_trading_days[viz_end_idx]\n",
    "    \n",
    "    if safe_start_date >= safe_calc_end_date:\n",
    "        return ({'error': \"Invalid date range (calc period has zero or negative length).\"}, None)\n",
    "\n",
    "    # 2. Slice data for the calculation period and filter for valid tickers\n",
    "    calc_close_raw = df_close_full.loc[safe_start_date:safe_calc_end_date]\n",
    "    calc_close = calc_close_raw.dropna(axis=1, how='all') # Drop tickers with no data in the period\n",
    "    if calc_close.shape[1] == 0 or len(calc_close) < 2:\n",
    "        return ({'error': \"Not enough data in calc period.\"}, None)\n",
    "\n",
    "    # 3. Calculate ranking metrics for all valid tickers\n",
    "    first_prices = calc_close.bfill().iloc[0]\n",
    "    last_prices = calc_close.ffill().iloc[-1]\n",
    "    daily_returns = calc_close.bfill().ffill().pct_change()\n",
    "    mean_returns = daily_returns.mean()\n",
    "    std_returns = daily_returns.std()\n",
    "    \n",
    "    valid_tickers = calc_close.columns\n",
    "    calc_high = df_high_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "    calc_low = df_low_full[valid_tickers].loc[safe_start_date:safe_calc_end_date]\n",
    "    \n",
    "    # Correctly calculate True Range (TR) for a multi-ticker DataFrame\n",
    "    # First, align the previous day's close to the current calculation window.\n",
    "    prev_close = df_close_full[valid_tickers].shift(1).loc[safe_start_date:safe_calc_end_date]\n",
    "    \n",
    "    # Calculate the three components of True Range. Each result is a DataFrame.\n",
    "    component1 = calc_high - calc_low\n",
    "    component2 = abs(calc_high - prev_close)\n",
    "    component3 = abs(calc_low - prev_close)\n",
    "\n",
    "    # Find the element-wise maximum across the three component DataFrames.\n",
    "    # np.maximum is efficient and preserves the DataFrame structure.\n",
    "    tr = np.maximum(component1, np.maximum(component2, component3))\n",
    "    \n",
    "    atr = tr.ewm(alpha=1/14, adjust=False).mean()\n",
    "    atrp = (atr / calc_close).mean() # Mean ATRP over the calculation period\n",
    "\n",
    "    metric_values = {}\n",
    "    metric_values['Price'] = (last_prices / first_prices).dropna()\n",
    "    metric_values['Sharpe'] = (mean_returns / std_returns * np.sqrt(252)).fillna(0)\n",
    "    metric_values['Sharpe (ATR)'] = (mean_returns / atrp).fillna(0)\n",
    "\n",
    "    if debug:\n",
    "        df_ranking = pd.DataFrame({\n",
    "            'FirstPrice': first_prices, 'LastPrice': last_prices, 'MeanDailyReturn': mean_returns,\n",
    "            'StdDevDailyReturn': std_returns, 'MeanATRP': atrp, 'Metric_Price': metric_values['Price'],\n",
    "            'Metric_Sharpe': metric_values['Sharpe'], 'Metric_Sharpe (ATR)': metric_values['Sharpe (ATR)']\n",
    "        })\n",
    "        df_ranking.index.name = 'Ticker'\n",
    "        debug_data['ranking_metrics'] = df_ranking.sort_values(f'Metric_{metric}', ascending=False)\n",
    "\n",
    "    # 4. Rank tickers and select the target group\n",
    "    sorted_tickers = metric_values[metric].sort_values(ascending=False)\n",
    "    tickers_to_display = sorted_tickers.index[rank_start-1:rank_end].tolist()\n",
    "    if not tickers_to_display:\n",
    "        return ({'error': \"No tickers found for the selected rank.\"}, None)\n",
    "\n",
    "    # 5. Prepare data for plotting and portfolio performance calculation\n",
    "    normalized_plot_data = df_close_full[tickers_to_display].loc[safe_start_date:safe_viz_end_date]\n",
    "    normalized_plot_data = normalized_plot_data.div(normalized_plot_data.bfill().iloc[0])\n",
    "    actual_calc_end_ts = calc_close.index.max()\n",
    "    portfolio_series = normalized_plot_data.mean(axis=1)\n",
    "    portfolio_return_series = portfolio_series.pct_change()\n",
    "    benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "    benchmark_return_series = benchmark_price_series.loc[safe_start_date:safe_viz_end_date].bfill().ffill().pct_change() if benchmark_price_series is not None else pd.Series(dtype='float64')\n",
    "\n",
    "    # 6. Correctly slice return series for Sharpe calculation to prevent lookahead\n",
    "    try:\n",
    "        # Use index location for a clean, non-overlapping split\n",
    "        boundary_loc = portfolio_return_series.index.get_loc(actual_calc_end_ts)\n",
    "        calc_portfolio_returns = portfolio_return_series.iloc[:boundary_loc + 1]\n",
    "        fwd_portfolio_returns = portfolio_return_series.iloc[boundary_loc + 1:]\n",
    "        \n",
    "        if benchmark_price_series is not None:\n",
    "            bm_boundary_loc = benchmark_return_series.index.get_loc(actual_calc_end_ts)\n",
    "            calc_benchmark_returns = benchmark_return_series.iloc[:bm_boundary_loc + 1]\n",
    "            fwd_benchmark_returns = benchmark_return_series.iloc[bm_boundary_loc + 1:]\n",
    "        else:\n",
    "            calc_benchmark_returns, fwd_benchmark_returns = pd.Series(dtype='float64'), pd.Series(dtype='float64')\n",
    "            \n",
    "    except (KeyError, IndexError): # Fallback for edge cases\n",
    "        calc_portfolio_returns = portfolio_return_series.loc[:actual_calc_end_ts]\n",
    "        fwd_portfolio_returns = portfolio_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "        if benchmark_price_series is not None:\n",
    "            calc_benchmark_returns = benchmark_return_series.loc[:actual_calc_end_ts]\n",
    "            fwd_benchmark_returns = benchmark_return_series.loc[actual_calc_end_ts:].iloc[1:]\n",
    "        else:\n",
    "            calc_benchmark_returns, fwd_benchmark_returns = pd.Series(dtype='float64'), pd.Series(dtype='float64')\n",
    "\n",
    "    # 7. Calculate performance metrics (Gain & Sharpe) for all periods\n",
    "    perf_data = {}\n",
    "    perf_data['calc_p_gain'] = calculate_gain(portfolio_series.loc[:actual_calc_end_ts])\n",
    "    perf_data['fwd_p_gain'] = calculate_gain(portfolio_series.loc[actual_calc_end_ts:])\n",
    "    perf_data['full_p_gain'] = calculate_gain(portfolio_series)\n",
    "    perf_data['calc_p_sharpe'] = calculate_sharpe(calc_portfolio_returns)\n",
    "    perf_data['fwd_p_sharpe'] = calculate_sharpe(fwd_portfolio_returns)\n",
    "    perf_data['full_p_sharpe'] = calculate_sharpe(portfolio_return_series)\n",
    "    \n",
    "    perf_data['calc_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:actual_calc_end_ts]) if benchmark_price_series is not None else np.nan\n",
    "    perf_data['fwd_b_gain'] = calculate_gain(benchmark_price_series.loc[actual_calc_end_ts:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "    perf_data['full_b_gain'] = calculate_gain(benchmark_price_series.loc[safe_start_date:safe_viz_end_date]) if benchmark_price_series is not None else np.nan\n",
    "    perf_data['calc_b_sharpe'] = calculate_sharpe(calc_benchmark_returns)\n",
    "    perf_data['fwd_b_sharpe'] = calculate_sharpe(fwd_benchmark_returns)\n",
    "    perf_data['full_b_sharpe'] = calculate_sharpe(benchmark_return_series)\n",
    "\n",
    "    # 8. Assemble results DataFrame for display\n",
    "    calc_end_prices = calc_close.ffill().iloc[-1]\n",
    "    fwd_close_slice = df_close_full.loc[actual_calc_end_ts:safe_viz_end_date]\n",
    "    viz_end_prices = fwd_close_slice.ffill().iloc[-1] if not fwd_close_slice.empty and len(fwd_close_slice) >= 2 else calc_end_prices\n",
    "    calc_gains = (calc_end_prices / calc_close.bfill().iloc[0]) - 1\n",
    "    fwd_gains = (viz_end_prices / calc_end_prices) - 1\n",
    "    results_df = pd.DataFrame({'Rank': range(rank_start, rank_start + len(tickers_to_display)), 'Metric': metric, 'MetricValue': sorted_tickers.loc[tickers_to_display].values, 'CalcPrice': calc_end_prices.loc[tickers_to_display], 'CalcGain': calc_gains.loc[tickers_to_display], 'FwdGain': fwd_gains.loc[tickers_to_display]}, index=pd.Index(tickers_to_display, name='Ticker'))\n",
    "    if benchmark_price_series is not None and benchmark_ticker in calc_close.columns:\n",
    "        benchmark_df_row = pd.DataFrame({'Rank': np.nan, 'Metric': metric, 'MetricValue': metric_values[metric].get(benchmark_ticker, np.nan), 'CalcPrice': calc_end_prices[benchmark_ticker], 'CalcGain': calc_gains[benchmark_ticker], 'FwdGain': fwd_gains[benchmark_ticker]}, index=pd.Index([f\"{benchmark_ticker} (BM)\"], name='Ticker'))\n",
    "        results_df = pd.concat([results_df, benchmark_df_row])\n",
    "    \n",
    "    # 9. Assemble debug data if requested\n",
    "    if debug:\n",
    "        df_trace = normalized_plot_data.copy()\n",
    "        df_trace.columns = [f'Norm_Price_{c}' for c in df_trace.columns]\n",
    "        df_trace['Norm_Price_Portfolio'] = portfolio_series\n",
    "        if benchmark_price_series is not None and not benchmark_price_series.loc[safe_start_date:safe_viz_end_date].dropna().empty:\n",
    "            norm_bm = benchmark_price_series.loc[safe_start_date:safe_viz_end_date] / benchmark_price_series.loc[safe_start_date:].bfill().iloc[0]\n",
    "            df_trace[f'Norm_Price_Benchmark_{benchmark_ticker}'] = norm_bm\n",
    "        for col in df_trace.columns:\n",
    "            if 'Norm_Price' in col:\n",
    "                df_trace[col.replace('Norm_Price', 'Return')] = df_trace[col].pct_change()\n",
    "        debug_data['portfolio_trace'] = df_trace\n",
    "\n",
    "    # 10. Package final results\n",
    "    final_results = {\n",
    "        'tickers_to_display': tickers_to_display, 'normalized_plot_data': normalized_plot_data,\n",
    "        'portfolio_series': portfolio_series, 'benchmark_price_series': benchmark_price_series,\n",
    "        'performance_data': perf_data, 'results_df': results_df, 'actual_calc_end_ts': actual_calc_end_ts,\n",
    "        'safe_start_date': safe_start_date, 'safe_viz_end_date': safe_viz_end_date,\n",
    "        'error': None\n",
    "    }\n",
    "    return (final_results, debug_data)\n",
    "\n",
    "# --- C. DYNAMIC DATA QUALITY FILTER FUNCTIONS ---\n",
    "\n",
    "\n",
    "def calculate_rolling_quality_metrics(df_ohlcv, window=252, min_periods=126, debug=False):\n",
    "    \"\"\"Calculates rolling data quality metrics for the entire dataset.\"\"\"\n",
    "    print(f\"--- Calculating Rolling Quality Metrics (Window: {window} days) ---\")\n",
    "    df = df_ohlcv.copy()\n",
    "    if not df.index.is_monotonic_increasing:\n",
    "        df.sort_index(inplace=True)\n",
    "        \n",
    "    # Define quality flags\n",
    "    df['IsStale'] = np.where((df['Volume'] == 0) | (df['Adj High'] == df['Adj Low']), 1, 0)\n",
    "    df['DollarVolume'] = df['Adj Close'] * df['Volume']\n",
    "    df['HasSameVolumeAsPrevDay'] = (df.groupby(level='Ticker')['Volume'].diff() == 0).astype(int)\n",
    "    \n",
    "    # Calculate rolling metrics per ticker\n",
    "    grouped = df.groupby(level='Ticker')\n",
    "    stale_pct = grouped['IsStale'].rolling(window=window, min_periods=min_periods).mean()\n",
    "    median_vol = grouped['DollarVolume'].rolling(window=window, min_periods=min_periods).median()\n",
    "    same_vol_count = grouped['HasSameVolumeAsPrevDay'].rolling(window=window, min_periods=min_periods).sum()\n",
    "    \n",
    "    quality_df = pd.concat([stale_pct, median_vol, same_vol_count], axis=1)\n",
    "    quality_df.columns = ['RollingStalePct', 'RollingMedianVolume', 'RollingSameVolCount']\n",
    "    quality_df.index = quality_df.index.droplevel(0) # Remove the extra 'Ticker' level\n",
    "    print(\"✅ Rolling metrics calculation complete.\")\n",
    "    return quality_df\n",
    "\n",
    "def get_eligible_universe(quality_metrics_df, filter_date, thresholds):\n",
    "    \"\"\"Filters the universe of tickers based on quality metrics for a given date.\"\"\"\n",
    "    filter_date_ts = pd.to_datetime(filter_date)\n",
    "    date_index = quality_metrics_df.index.get_level_values('Date').unique().sort_values()\n",
    "    \n",
    "    if filter_date_ts < date_index[0]:\n",
    "        print(f\"Warning: Filter date {filter_date_ts.date()} is before the earliest data point. Returning empty universe.\")\n",
    "        return []\n",
    "        \n",
    "    # Find the most recent date with quality data on or before the filter date\n",
    "    valid_prior_dates = date_index[date_index <= filter_date_ts]\n",
    "    if valid_prior_dates.empty:\n",
    "        print(f\"Warning: No available data found on or before {filter_date_ts.date()}. Returning empty universe.\")\n",
    "        return []\n",
    "        \n",
    "    actual_date_to_use = valid_prior_dates[-1]\n",
    "    if actual_date_to_use.date() != filter_date_ts.date():\n",
    "        print(f\"ℹ️ Info: Filter date {filter_date_ts.date()} not found. Using previous available date {actual_date_to_use.date()}.\")\n",
    "\n",
    "    metrics_on_date = quality_metrics_df.xs(actual_date_to_use, level='Date')\n",
    "    \n",
    "    # Apply filters\n",
    "    mask = ((metrics_on_date['RollingMedianVolume'] >= thresholds['min_median_dollar_volume']) &\n",
    "            (metrics_on_date['RollingStalePct'] <= thresholds['max_stale_pct']) &\n",
    "            (metrics_on_date['RollingSameVolCount'] <= thresholds['max_same_vol_count']))\n",
    "            \n",
    "    eligible_tickers = metrics_on_date[mask].index.tolist()\n",
    "    all_tickers = metrics_on_date.index.tolist()\n",
    "    print(f\"Dynamic Filter ({filter_date_ts.date()}): Kept {len(eligible_tickers)} of {len(all_tickers)} tickers.\")\n",
    "    return eligible_tickers    \n",
    "\n",
    "# --- D. INTERACTIVE ANALYSIS & BACKTESTING TOOLS ---\n",
    "\n",
    "def plot_walk_forward_analyzer(df_ohlcv, \n",
    "                               default_start_date=None, default_calc_period=126, default_fwd_period=63,\n",
    "                               default_metric='Sharpe (ATR)', default_rank_start=1, default_rank_end=10,\n",
    "                               default_benchmark_ticker='VOO', master_calendar_ticker='VOO',\n",
    "                               quality_thresholds={'min_median_dollar_volume': 1_000_000, 'max_stale_pct': 0.05, 'max_same_vol_count': 10},\n",
    "                               debug=False):\n",
    "    \"\"\"Creates an interactive widget for single-period walk-forward analysis.\"\"\"\n",
    "    print(\"Initializing Walk-Forward Analyzer (using Trading Day Logic)...\")\n",
    "    if not isinstance(df_ohlcv.index, pd.MultiIndex): raise ValueError(\"Input DataFrame must have a (Ticker, Date) MultiIndex.\")\n",
    "    df_ohlcv = df_ohlcv.sort_index()\n",
    "\n",
    "    if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "        raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "    master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "    print(f\"Master trading day calendar created from '{master_calendar_ticker}' ({len(master_trading_days)} days).\")\n",
    "\n",
    "    print(\"Pre-calculating data quality metrics...\")\n",
    "    quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "    print(\"Pre-processing data (unstacking)...\")\n",
    "    df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "    df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "    df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    \n",
    "    # --- Widget Setup ---\n",
    "    start_date_picker = widgets.DatePicker(description='Start Date:', value=pd.to_datetime(default_start_date), disabled=False)\n",
    "    calc_period_input = widgets.IntText(value=default_calc_period, description='Calc Period (days):')\n",
    "    fwd_period_input = widgets.IntText(value=default_fwd_period, description='Fwd Period (days):')\n",
    "    metrics = ['Price', 'Sharpe', 'Sharpe (ATR)']\n",
    "    metric_dropdown = widgets.Dropdown(options=metrics, value=default_metric, description='Metric:')\n",
    "    rank_start_input = widgets.IntText(value=default_rank_start, description='Rank Start:')\n",
    "    rank_end_input = widgets.IntText(value=default_rank_end, description='Rank End:')\n",
    "    benchmark_ticker_input = widgets.Text(value=default_benchmark_ticker, description='Benchmark:', placeholder='Enter Ticker')\n",
    "    update_button = widgets.Button(description=\"Update Chart\", button_style='primary')\n",
    "    ticker_list_output = widgets.Output()\n",
    "    results_container, debug_data_container = [None], [None] # Use list wrapper for mutable access in callback\n",
    "\n",
    "    # --- Plotting Setup ---\n",
    "    fig = go.FigureWidget()\n",
    "    max_traces = 50 # Pre-allocate traces for performance\n",
    "    for i in range(max_traces): fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name=f'placeholder_{i}', visible=False, showlegend=False))\n",
    "    fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Benchmark', visible=True, showlegend=True, line=dict(color='black', width=3, dash='dash')))\n",
    "    fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', name='Group Portfolio', visible=True, showlegend=True, line=dict(color='green', width=3)))\n",
    "\n",
    "    # --- Update Logic (Callback) ---\n",
    "    def update_plot(button_click):\n",
    "        ticker_list_output.clear_output()\n",
    "        \n",
    "        # 1. Get and validate user inputs\n",
    "        start_date_raw = pd.to_datetime(start_date_picker.value)\n",
    "        start_date_idx = master_trading_days.searchsorted(start_date_raw) # Find first trading day on or after selected date\n",
    "        if start_date_idx >= len(master_trading_days):\n",
    "            with ticker_list_output: print(f\"Error: Start date is after the last available trading day.\"); return\n",
    "        actual_start_date = master_trading_days[start_date_idx]\n",
    "        with ticker_list_output: \n",
    "            if start_date_raw.date() != actual_start_date.date():\n",
    "                print(f\"ℹ️ Info: Start date {start_date_raw.date()} is not a trading day. Snapping forward to {actual_start_date.date()}.\")\n",
    "\n",
    "        calc_period, fwd_period = calc_period_input.value, fwd_period_input.value\n",
    "        metric = metric_dropdown.value\n",
    "        rank_start, rank_end = rank_start_input.value, rank_end_input.value\n",
    "        benchmark_ticker = benchmark_ticker_input.value.strip().upper()\n",
    "        \n",
    "        if rank_start > rank_end:\n",
    "            with ticker_list_output: print(\"Error: 'Rank Start' must be <= 'Rank End'.\"); return\n",
    "        if rank_start < 1 or calc_period < 2 or fwd_period < 1:\n",
    "            with ticker_list_output: print(\"Error: Ranks must be >= 1, Calc Period >= 2, Fwd Period >= 1.\"); return\n",
    "\n",
    "        # 2. Apply dynamic data quality filter\n",
    "        eligible_tickers = get_eligible_universe(quality_metrics_df, actual_start_date, quality_thresholds)\n",
    "        if not eligible_tickers:\n",
    "            with ticker_list_output: print(f\"Error: No eligible tickers found on {actual_start_date.date()} with the current quality filters.\"); return\n",
    "        df_close_step = df_close_full[eligible_tickers]; df_high_step = df_high_full[eligible_tickers]; df_low_step = df_low_full[eligible_tickers]\n",
    "\n",
    "        # 3. Run the core calculation\n",
    "        results, debug_output = run_walk_forward_step(\n",
    "            df_close_step, df_high_step, df_low_step, master_trading_days,\n",
    "            actual_start_date, calc_period, fwd_period, \n",
    "            metric, rank_start, rank_end, benchmark_ticker, debug=debug\n",
    "        )\n",
    "        if results['error']:\n",
    "            with ticker_list_output: print(f\"Error: {results['error']}\"); return\n",
    "\n",
    "        # 4. Update the interactive plot\n",
    "        with fig.batch_update():\n",
    "            # Update individual ticker traces\n",
    "            for i in range(max_traces):\n",
    "                trace = fig.data[i]\n",
    "                if i < len(results['tickers_to_display']):\n",
    "                    ticker = results['tickers_to_display'][i]; plot_data_series = results['normalized_plot_data'][ticker]\n",
    "                    trace.x, trace.y, trace.name, trace.visible, trace.showlegend = plot_data_series.index, plot_data_series.values, ticker, True, True\n",
    "                else: trace.visible, trace.showlegend = False, False\n",
    "            # Update benchmark trace\n",
    "            benchmark_trace = fig.data[max_traces]\n",
    "            if results['benchmark_price_series'] is not None and not results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']].dropna().empty:\n",
    "                normalized_benchmark = results['benchmark_price_series'].loc[results['safe_start_date']:results['safe_viz_end_date']] / results['benchmark_price_series'].loc[results['safe_start_date']:].bfill().iloc[0]\n",
    "                benchmark_trace.x, benchmark_trace.y, benchmark_trace.name, benchmark_trace.visible = normalized_benchmark.index, normalized_benchmark, f\"Benchmark ({benchmark_ticker})\", True\n",
    "            else: benchmark_trace.visible = False\n",
    "            # Update portfolio trace\n",
    "            portfolio_trace = fig.data[max_traces + 1]\n",
    "            portfolio_trace.x, portfolio_trace.y, portfolio_trace.name, portfolio_trace.visible = results['portfolio_series'].index, results['portfolio_series'], 'Group Portfolio', True\n",
    "            # Update vertical line separating calc and fwd periods\n",
    "            fig.layout.shapes = []; fig.add_shape(type=\"line\", x0=results['actual_calc_end_ts'], y0=0, x1=results['actual_calc_end_ts'], y1=1, xref='x', yref='paper', line=dict(color=\"grey\", width=2, dash=\"dash\"))\n",
    "            \n",
    "        results_container[0] = results; debug_data_container[0] = debug_output\n",
    "        \n",
    "        # 5. Display summary statistics in a formatted table\n",
    "        with ticker_list_output:\n",
    "            print(f\"Analysis Period: {results['safe_start_date'].date()} to {results['safe_viz_end_date'].date()}.\")\n",
    "            pprint.pprint(results['tickers_to_display'])\n",
    "            p = results['performance_data']\n",
    "            rows = []\n",
    "            rows.append({'Metric': 'Group Portfolio Gain', 'Full': p['full_p_gain'], 'Calc': p['calc_p_gain'], 'Fwd': p['fwd_p_gain']})\n",
    "            if not np.isnan(p['full_b_gain']):\n",
    "                rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Gain', 'Full': p['full_b_gain'], 'Calc': p['calc_b_gain'], 'Fwd': p['fwd_b_gain']})\n",
    "                rows.append({'Metric': 'Gain Delta (vs Bm)', 'Full': p['full_p_gain'] - p['full_b_gain'], 'Calc': p['calc_p_gain'] - p['calc_b_gain'], 'Fwd': p['fwd_p_gain'] - p['fwd_b_gain']})\n",
    "            rows.append({'Metric': 'Group Portfolio Sharpe', 'Full': p['full_p_sharpe'], 'Calc': p['calc_p_sharpe'], 'Fwd': p['fwd_p_sharpe']})\n",
    "            if not np.isnan(p['full_b_sharpe']):\n",
    "                rows.append({'Metric': f'Benchmark ({benchmark_ticker}) Sharpe', 'Full': p['full_b_sharpe'], 'Calc': p['calc_b_sharpe'], 'Fwd': p['fwd_b_sharpe']})\n",
    "                rows.append({'Metric': 'Sharpe Delta (vs Bm)', 'Full': p['full_p_sharpe'] - p['full_b_sharpe'], 'Calc': p['calc_p_sharpe'] - p['calc_b_sharpe'], 'Fwd': p['fwd_p_sharpe'] - p['fwd_b_sharpe']})\n",
    "            report_df = pd.DataFrame(rows).set_index('Metric')\n",
    "            gain_rows = [row for row in report_df.index if 'Gain' in row or 'Delta' in row]\n",
    "            sharpe_rows = [row for row in report_df.index if 'Sharpe' in row]\n",
    "            styled_df = report_df.style.format('{:+.2%}', na_rep='N/A', subset=(gain_rows, report_df.columns)).format('{:+.2f}', na_rep='N/A', subset=(sharpe_rows, report_df.columns)).set_properties(**{'text-align': 'right', 'width': '100px'}).set_table_styles([{'selector': 'th.col_heading', 'props': [('text-align', 'right')]}, {'selector': 'th.row_heading', 'props': [('text-align', 'left')]}])\n",
    "            print(\"\\n--- Strategy Performance Summary ---\")\n",
    "            display(styled_df)\n",
    "            \n",
    "    # --- Final Layout & Display ---\n",
    "    fig.update_layout(title_text='Walk-Forward Performance Analysis', xaxis_title='Date', yaxis_title='Normalized Price (Start = 1)', hovermode='x unified', legend_title_text='Tickers (Ranked)', height=600, margin=dict(t=50))\n",
    "    fig.add_hline(y=1, line_width=1, line_dash=\"dash\", line_color=\"grey\")\n",
    "    update_button.on_click(update_plot)\n",
    "    controls_row1 = widgets.HBox([start_date_picker, calc_period_input, fwd_period_input])\n",
    "    controls_row2 = widgets.HBox([metric_dropdown, rank_start_input, rank_end_input, benchmark_ticker_input, update_button])\n",
    "    ui_container = widgets.VBox([controls_row1, controls_row2, ticker_list_output], layout=widgets.Layout(margin='10px 0 20px 0'))\n",
    "    display(ui_container, fig)\n",
    "    update_plot(None) # Initial run\n",
    "    return (results_container, debug_data_container)\n",
    "\n",
    "def run_full_backtest(df_ohlcv, strategy_params, quality_thresholds):\n",
    "    \"\"\"Runs a full backtest of a strategy over a specified date range.\"\"\"\n",
    "    print(f\"--- Running Full Forensic Backtest for Strategy: {strategy_params['metric']} (Top {strategy_params['rank_start']}-{strategy_params['rank_end']}) ---\")\n",
    "    \n",
    "    # 1. Unpack strategy parameters\n",
    "    start_date, end_date = pd.to_datetime(strategy_params['start_date']), pd.to_datetime(strategy_params['end_date'])\n",
    "    calc_period, fwd_period = strategy_params['calc_period'], strategy_params['fwd_period']\n",
    "    metric, rank_start, rank_end = strategy_params['metric'], strategy_params['rank_start'], strategy_params['rank_end']\n",
    "    benchmark_ticker = strategy_params['benchmark_ticker']\n",
    "    master_calendar_ticker = strategy_params.get('master_calendar_ticker', 'VOO')\n",
    "    \n",
    "    # 2. Perform initial setup (same as analyzer)\n",
    "    if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "        raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "    master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "    \n",
    "    start_idx = master_trading_days.searchsorted(start_date)\n",
    "    end_idx = master_trading_days.searchsorted(end_date, side='right')\n",
    "    \n",
    "    quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "    df_close_full = df_ohlcv['Adj Close'].unstack(level=0); df_high_full = df_ohlcv['Adj High'].unstack(level=0); df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    \n",
    "    # 3. Loop through all periods in the backtest range\n",
    "    step_indices = range(start_idx, end_idx, fwd_period)\n",
    "    all_fwd_gains, period_by_period_debug = [], {}\n",
    "\n",
    "    print(f\"Simulating {len(step_indices)} periods from {master_trading_days[step_indices[0]].date()} to {master_trading_days[step_indices[-1]].date()}...\")\n",
    "    for current_idx in tqdm(step_indices, desc=\"Backtest Progress\"):\n",
    "        step_date = master_trading_days[current_idx]\n",
    "        \n",
    "        # Apply data quality filter for the current step\n",
    "        eligible_tickers = get_eligible_universe(quality_metrics_df, step_date, quality_thresholds)\n",
    "        if not eligible_tickers: continue\n",
    "        \n",
    "        df_close_step = df_close_full[eligible_tickers]; df_high_step = df_high_full[eligible_tickers]; df_low_step = df_low_full[eligible_tickers]\n",
    "        \n",
    "        # Run a single walk-forward analysis step\n",
    "        results, debug_output = run_walk_forward_step(\n",
    "            df_close_step, df_high_step, df_low_step, master_trading_days,\n",
    "            step_date, calc_period, fwd_period,\n",
    "            metric, rank_start, rank_end, benchmark_ticker, debug=True\n",
    "        )\n",
    "        \n",
    "        # Collect results for this period\n",
    "        if results['error'] is None:\n",
    "            fwd_series = results['portfolio_series'].loc[results['actual_calc_end_ts']:]\n",
    "            all_fwd_gains.append(fwd_series.pct_change().dropna())\n",
    "            period_by_period_debug[step_date.date().isoformat()] = debug_output\n",
    "            \n",
    "    if not all_fwd_gains:\n",
    "        print(\"Error: No valid periods were simulated.\"); return None\n",
    "\n",
    "    # 4. Stitch together the results to form a continuous equity curve\n",
    "    strategy_returns = pd.concat(all_fwd_gains); strategy_equity_curve = (1 + strategy_returns).cumprod()\n",
    "    benchmark_returns = df_close_full[benchmark_ticker].pct_change().loc[strategy_equity_curve.index]; benchmark_equity_curve = (1 + benchmark_returns).cumprod()\n",
    "    cumulative_equity_df = pd.DataFrame({'Strategy_Equity': strategy_equity_curve, 'Benchmark_Equity': benchmark_equity_curve})\n",
    "    \n",
    "    # 5. Plot the final equity curve\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=cumulative_equity_df.index, y=cumulative_equity_df['Strategy_Equity'], name='Strategy', line=dict(color='green')))\n",
    "    fig.add_trace(go.Scatter(x=cumulative_equity_df.index, y=cumulative_equity_df['Benchmark_Equity'], name=f'Benchmark ({benchmark_ticker})', line=dict(color='black', dash='dash')))\n",
    "    fig.update_layout(title=f\"Cumulative Performance: '{metric}' Strategy (Top {rank_start}-{rank_end})\", xaxis_title=\"Date\", yaxis_title=\"Cumulative Growth\")\n",
    "    fig.show()\n",
    "\n",
    "    # 6. Return the detailed results for forensic analysis\n",
    "    final_backtest_results = {'cumulative_performance': cumulative_equity_df, 'period_by_period_debug': period_by_period_debug}\n",
    "    print(\"\\n✅ Full backtest complete. Results object is ready for forensic analysis.\")\n",
    "    return final_backtest_results\n",
    "\n",
    "# --- E. VERIFICATION TOOLS (User Requested) ---\n",
    "\n",
    "def verify_group_tickers_walk_forward_calculation(df_ohlcv, tickers_to_verify, benchmark_ticker,\n",
    "                                                  start_date, calc_period, fwd_period,\n",
    "                                                  master_calendar_ticker='VOO', export_csv=False):\n",
    "    \"\"\"Verifies portfolio and benchmark performance and optionally exports the data.\"\"\"\n",
    "    display(Markdown(f\"## Verification Report for Portfolio vs. Benchmark\"))\n",
    "    display(Markdown(f\"**Portfolio Tickers:** `{tickers_to_verify}`\\n**Benchmark Ticker:** `{benchmark_ticker}`\"))\n",
    "    \n",
    "    # 1. Setup trading day calendar and determine exact period dates\n",
    "    if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "        raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "    master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "\n",
    "    start_date_raw = pd.to_datetime(start_date)\n",
    "    start_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "    if start_idx >= len(master_trading_days):\n",
    "        print(f\"Error: Start date {start_date_raw.date()} is after the last available trading day.\"); return\n",
    "    actual_start_date = master_trading_days[start_idx]\n",
    "    \n",
    "    calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "    fwd_end_idx = min(calc_end_idx + fwd_period, len(master_trading_days) - 1)\n",
    "    \n",
    "    actual_calc_end_date = master_trading_days[calc_end_idx]\n",
    "    actual_fwd_end_date = master_trading_days[fwd_end_idx]\n",
    "    \n",
    "    display(Markdown(f\"**Analysis Start:** `{actual_start_date.date()}` (Selected: `{start_date_raw.date()}`)\\n\"\n",
    "                    f\"**Calc End:** `{actual_calc_end_date.date()}` ({calc_period} trading days)\\n\"\n",
    "                    f\"**Fwd End:** `{actual_fwd_end_date.date()}` ({fwd_period} trading days)\"))\n",
    "\n",
    "    # 2. Recreate the portfolio and benchmark series from scratch\n",
    "    df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "    portfolio_prices_raw_slice = df_close_full[tickers_to_verify].loc[actual_start_date:actual_fwd_end_date]\n",
    "    portfolio_value_series = portfolio_prices_raw_slice.div(portfolio_prices_raw_slice.bfill().iloc[0]).mean(axis=1)\n",
    "    benchmark_price_series = df_close_full.get(benchmark_ticker)\n",
    "    \n",
    "    # 3. Optionally export the underlying daily data to a CSV for external checking\n",
    "    if export_csv:\n",
    "        export_df = pd.DataFrame({\n",
    "            'Portfolio_Normalized_Price': portfolio_value_series,\n",
    "            'Portfolio_Daily_Return': portfolio_value_series.pct_change()\n",
    "        })\n",
    "        if benchmark_price_series is not None:\n",
    "            norm_bm = benchmark_price_series.loc[actual_start_date:actual_fwd_end_date]\n",
    "            norm_bm = norm_bm / norm_bm.bfill().iloc[0]\n",
    "            export_df['Benchmark_Normalized_Price'] = norm_bm\n",
    "            export_df['Benchmark_Daily_Return'] = norm_bm.pct_change()\n",
    "\n",
    "        output_dir = 'export_csv'\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        tickers_str = '_'.join(tickers_to_verify)\n",
    "        filename = f\"verify_group_{actual_start_date.date()}_{tickers_str}.csv\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        export_df.to_csv(filepath)\n",
    "        print(f\"\\n✅ Data exported to: {filepath}\")\n",
    "\n",
    "    # 4. Define a helper to print detailed calculation steps\n",
    "    def print_verification_steps(title, price_series):\n",
    "        display(Markdown(f\"#### Verification for: `{title}`\"))\n",
    "        if price_series.dropna().shape[0] < 2: print(\"  - Not enough data points.\"); return {'gain': np.nan, 'sharpe': np.nan}\n",
    "        start_price, end_price = price_series.bfill().iloc[0], price_series.ffill().iloc[-1]\n",
    "        gain = (end_price / start_price) - 1\n",
    "        print(f\"Start Value ({price_series.first_valid_index().date()}): {start_price:,.4f}\\nEnd Value   ({price_series.last_valid_index().date()}): {end_price:,.4f}\\nGain = {gain:.2%}\")\n",
    "        returns = price_series.pct_change()\n",
    "        sharpe = calculate_sharpe(returns)\n",
    "        print(f\"Mean Daily Return: {returns.mean():.6f}\\nStd Dev: {returns.std():.6f}\\nSharpe = {sharpe:.2f}\")\n",
    "        return {'gain': gain, 'sharpe': sharpe}\n",
    "\n",
    "    # 5. Run verification for each period\n",
    "    display(Markdown(\"### A. Calculation Period\"))\n",
    "    perf_calc_p = print_verification_steps(\"Group Portfolio\", portfolio_value_series.loc[actual_start_date:actual_calc_end_date])\n",
    "    if benchmark_price_series is not None:\n",
    "        perf_calc_b = print_verification_steps(f\"Benchmark\", benchmark_price_series.loc[actual_start_date:actual_calc_end_date])\n",
    "    \n",
    "    display(Markdown(\"### B. Forward Period\"))\n",
    "    perf_fwd_p = print_verification_steps(\"Group Portfolio\", portfolio_value_series.loc[actual_calc_end_date:actual_fwd_end_date])\n",
    "    if benchmark_price_series is not None:\n",
    "        perf_fwd_b = print_verification_steps(f\"Benchmark\", benchmark_price_series.loc[actual_calc_end_date:actual_fwd_end_date])\n",
    "\n",
    "def verify_ticker_ranking_metrics(df_ohlcv, ticker, start_date, calc_period,\n",
    "                                  master_calendar_ticker='VOO', export_csv=False):\n",
    "    \"\"\"Verifies ranking metrics for a single ticker and optionally exports the data.\"\"\"\n",
    "    display(Markdown(f\"## Verification Report for Ticker Ranking: `{ticker}`\"))\n",
    "    \n",
    "    # 1. Setup trading day calendar and determine exact period dates\n",
    "    if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "        raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "    master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "\n",
    "    start_date_raw = pd.to_datetime(start_date)\n",
    "    start_idx = master_trading_days.searchsorted(start_date_raw)\n",
    "    if start_idx >= len(master_trading_days):\n",
    "        print(f\"Error: Start date {start_date_raw.date()} is after the last available trading day.\"); return\n",
    "    actual_start_date = master_trading_days[start_idx]\n",
    "    \n",
    "    calc_end_idx = min(start_idx + calc_period, len(master_trading_days) - 1)\n",
    "    actual_calc_end_date = master_trading_days[calc_end_idx]\n",
    "\n",
    "    # 2. Extract and prepare the raw data for the specific ticker and period\n",
    "    df_ticker = df_ohlcv.loc[ticker].sort_index()\n",
    "    calc_df = df_ticker.loc[actual_start_date:actual_calc_end_date].copy()\n",
    "    if calc_df.empty or len(calc_df) < 2: \n",
    "        print(\"No data or not enough data in calc period.\"); return\n",
    "\n",
    "    display(Markdown(\"### A. Calculation Period (for Ranking Metrics)\"))\n",
    "    display(Markdown(f\"**Period Start:** `{actual_start_date.date()}`\\n\"\n",
    "                    f\"**Period End:** `{actual_calc_end_date.date()}`\\n\"\n",
    "                    f\"**Total Trading Days:** `{len(calc_df)}` (Requested: `{calc_period}`)\"))\n",
    "    \n",
    "    display(Markdown(\"#### Detailed Metric Calculation Data\"))\n",
    "    \n",
    "    # 3. Calculate all intermediate metrics as new columns for full transparency\n",
    "    vdf = calc_df[['Adj High', 'Adj Low', 'Adj Close']].copy()\n",
    "    vdf['Daily_Return'] = vdf['Adj Close'].pct_change()\n",
    "    \n",
    "    # Corrected True Range (TR) calculation for a single ticker (Series)\n",
    "    tr_df = pd.DataFrame({\n",
    "        'h_l': vdf['Adj High'] - vdf['Adj Low'],\n",
    "        'h_cp': abs(vdf['Adj High'] - vdf['Adj Close'].shift(1)),\n",
    "        'l_cp': abs(vdf['Adj Low'] - vdf['Adj Close'].shift(1))\n",
    "    })\n",
    "    vdf['TR'] = tr_df.max(axis=1)\n",
    "    \n",
    "    vdf['ATR_14'] = vdf['TR'].ewm(alpha=1/14, adjust=False).mean()\n",
    "    vdf['ATRP'] = vdf['ATR_14'] / vdf['Adj Close']\n",
    "    \n",
    "    print(\"--- Start of Calculation Period ---\")\n",
    "    display(vdf.head())\n",
    "    print(\"\\n--- End of Calculation Period ---\")\n",
    "    display(vdf.tail())\n",
    "\n",
    "    # 4. Optionally export this detailed breakdown to CSV\n",
    "    if export_csv:\n",
    "        output_dir = 'export_csv'\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        filename = f\"verify_ticker_{actual_start_date.date()}_{ticker}.csv\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        vdf.to_csv(filepath)\n",
    "        print(f\"\\n✅ Data exported to: {filepath}\")\n",
    "    \n",
    "    # 5. Print final metric calculations with formulas\n",
    "    display(Markdown(\"#### `MetricValue` Verification Summary:\"))\n",
    "    \n",
    "    calc_start_price = vdf['Adj Close'].bfill().iloc[0]\n",
    "    calc_end_price = vdf['Adj Close'].ffill().iloc[-1]\n",
    "    price_metric = (calc_end_price / calc_start_price)\n",
    "    print(f\"1. Price Metric: (Last Price / First Price) = ({calc_end_price:.2f} / {calc_start_price:.2f}) = {price_metric:.4f}\")\n",
    "    \n",
    "    daily_returns = vdf['Daily_Return'].dropna()\n",
    "    sharpe_ratio = calculate_sharpe(daily_returns)\n",
    "    print(f\"2. Sharpe Metric: (Mean Daily Return / Std Dev) * sqrt(252) = {sharpe_ratio:.4f}\")\n",
    "\n",
    "    atrp_mean = vdf['ATRP'].mean()\n",
    "    mean_daily_return = vdf['Daily_Return'].mean()\n",
    "    sharpe_atr = (mean_daily_return / atrp_mean) if atrp_mean > 0 else 0\n",
    "    print(f\"3. Sharpe (ATR) Metric: (Mean Daily Return / Mean ATRP) = ({mean_daily_return:.6f} / {atrp_mean:.6f}) = {sharpe_atr:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "916dd29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 4036635 entries, ('A', Timestamp('1999-11-18 00:00:00')) to ('ZWS', Timestamp('2025-10-06 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   Adj Open   float64\n",
      " 1   Adj High   float64\n",
      " 2   Adj Low    float64\n",
      " 3   Adj Close  float64\n",
      " 4   Volume     int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 170.0+ MB\n",
      "df_OHLCV.info() :\n",
      "None\n",
      "\n",
      "df_OHLCV.head():\n",
      "                   Adj Open  Adj High  Adj Low  Adj Close    Volume\n",
      "Ticker Date                                                        \n",
      "A      1999-11-18   27.2452   29.9398  23.9518    26.3470  74716422\n",
      "       1999-11-19   25.7108   25.7482  23.8396    24.1764  18198351\n",
      "       1999-11-22   24.7378   26.3470  23.9893    26.3470   7857767\n",
      "       1999-11-23   25.4488   26.1225  23.9518    23.9518   7138322\n",
      "       1999-11-24   24.0267   25.1120  23.9518    24.5881   5785607\n",
      "\n",
      "df_OHLCV.tail():\n",
      "                   Adj Open  Adj High  Adj Low  Adj Close  Volume\n",
      "Ticker Date                                                      \n",
      "ZWS    2025-09-30     46.90     47.40    46.77      47.03  609500\n",
      "       2025-10-01     46.72     47.04    46.40      46.80  599400\n",
      "       2025-10-02     46.86     47.17    46.54      46.91  839900\n",
      "       2025-10-03     46.87     47.37    46.62      46.84  780500\n",
      "       2025-10-06     47.16     47.37    46.67      47.29  661018\n"
     ]
    }
   ],
   "source": [
    "download_path = Path.home() / \"Downloads\"  \n",
    "# OHLCV_file_path = r'c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_clean_stocks_etfs.parquet'\n",
    "OHLCV_file_path = r'c:\\Users\\ping\\Files_win10\\python\\py311\\stocks\\data\\df_OHLCV_stocks_etfs.parquet'\n",
    "\n",
    "df_OHLCV = pd.read_parquet(OHLCV_file_path, engine='pyarrow')\n",
    "print(f'df_OHLCV.info() :\\n{df_OHLCV.info()}')\n",
    "print(f'\\ndf_OHLCV.head():\\n{df_OHLCV.head()}')\n",
    "print(f'\\ndf_OHLCV.tail():\\n{df_OHLCV.tail()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ca33d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data on: 2018-12-31\n",
      "========================================\n",
      "\n",
      "--- In-Sample (IS) 'Discovery Zone' Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 2702881 entries, ('A', Timestamp('1999-11-18 00:00:00')) to ('ZWS', Timestamp('2018-12-31 00:00:00'))\n",
      "Columns: 5 entries, Adj Open to Volume\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 114.1 MB\n",
      "IS Date Range: 1962-01-02 to 2018-12-31\n",
      "IS Shape: (2702881, 5)\n",
      "Percentage of IS data: 66.96%\n",
      "\n",
      "--- Out-of-Sample (OOS) 'Validation Zone' Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 1333754 entries, ('A', Timestamp('2019-01-02 00:00:00')) to ('ZWS', Timestamp('2025-10-06 00:00:00'))\n",
      "Columns: 5 entries, Adj Open to Volume\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 56.7 MB\n",
      "OOS Date Range: 2019-01-02 to 2025-10-06\n",
      "OOS Shape: (1333754, 5)\n",
      "Percentage of OOS data: 33.04%\n",
      "\n",
      "Verification: 2702881 (IS) + 1333754 (OOS) = 4036635 rows.\n",
      "Original total rows: 4036635 rows. Match: True\n"
     ]
    }
   ],
   "source": [
    "# --- 2. DEFINE THE SPLIT DATE ---\n",
    "# This is the last day of our In-Sample (IS) \"Discovery Zone\".\n",
    "split_date = pd.to_datetime('2018-12-31')\n",
    "\n",
    "print(f\"Splitting data on: {split_date.date()}\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "\n",
    "# --- 3. PERFORM THE SPLIT ---\n",
    "# We access the 'Date' level of the MultiIndex to create our boolean masks.\n",
    "\n",
    "# In-Sample (IS) DataFrame: Data for discovery and training the bot.\n",
    "df_IS = df_OHLCV[df_OHLCV.index.get_level_values('Date') <= split_date].copy()\n",
    "\n",
    "# Out-of-Sample (OOS) DataFrame: Data held back for final validation.\n",
    "df_OOS = df_OHLCV[df_OHLCV.index.get_level_values('Date') > split_date].copy()\n",
    "\n",
    "# Using .copy() is good practice to avoid SettingWithCopyWarning later on.\n",
    "\n",
    "\n",
    "# --- 4. VERIFY THE SPLIT ---\n",
    "# Always check your work to ensure the split was done correctly.\n",
    "\n",
    "print(\"\\n--- In-Sample (IS) 'Discovery Zone' Info ---\")\n",
    "df_IS.info(verbose=False, memory_usage='deep') # Use verbose=False for a cleaner summary\n",
    "print(f\"IS Date Range: {df_IS.index.get_level_values('Date').min().date()} to {df_IS.index.get_level_values('Date').max().date()}\")\n",
    "print(f\"IS Shape: {df_IS.shape}\")\n",
    "print(f\"Percentage of IS data: {df_IS.shape[0] / df_OHLCV.shape[0]:.2%}\")\n",
    "\n",
    "print(\"\\n--- Out-of-Sample (OOS) 'Validation Zone' Info ---\")\n",
    "df_OOS.info(verbose=False, memory_usage='deep')\n",
    "print(f\"OOS Date Range: {df_OOS.index.get_level_values('Date').min().date()} to {df_OOS.index.get_level_values('Date').max().date()}\")\n",
    "print(f\"OOS Shape: {df_OOS.shape}\")\n",
    "print(f\"Percentage of OOS data: {df_OOS.shape[0] / df_OHLCV.shape[0]:.2%}\")\n",
    "\n",
    "# Final check\n",
    "total_rows = df_IS.shape[0] + df_OOS.shape[0]\n",
    "print(f\"\\nVerification: {df_IS.shape[0]} (IS) + {df_OOS.shape[0]} (OOS) = {total_rows} rows.\")\n",
    "print(f\"Original total rows: {df_OHLCV.shape[0]} rows. Match: {total_rows == df_OHLCV.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf196a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Creating Development Sandbox DataFrame (Corrected) ---\n",
      "Slicing df_IS from 2014-01-01 to 2018-12-31\n",
      "============================================================\n",
      "\n",
      "--- Development Sandbox (df_dev) Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 778000 entries, ('A', Timestamp('2014-01-02 00:00:00')) to ('ZWS', Timestamp('2018-12-31 00:00:00'))\n",
      "Columns: 5 entries, Adj Open to Volume\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 33.4 MB\n",
      "df_dev Date Range: 2014-01-02 to 2018-12-31\n",
      "df_dev Shape: (778000, 5)\n",
      "df_dev as percentage of IS data: 28.78%\n",
      "============================================================\n",
      "\n",
      "Found 668 unique tickers in df_dev.\n",
      "First 10 unique tickers:\n",
      "['A', 'AAL', 'ABBV', 'ABT', 'ACM', 'ACN', 'ACWI', 'ACWX', 'ADBE', 'ADI']\n",
      "\n",
      "Last 10 unique tickers:\n",
      "['XYL', 'XYZ', 'YUM', 'Z', 'ZBH', 'ZBRA', 'ZG', 'ZS', 'ZTS', 'ZWS']\n"
     ]
    }
   ],
   "source": [
    "# This code REPLACES the previous df_dev creation snippet.\n",
    "# It should still be placed after df_IS and df_OOS are created.\n",
    "\n",
    "# --- 5. (CORRECTED) CREATE A SMALLER \"DEVELOPMENT SANDBOX\" DATAFRAME ---\n",
    "# We use a RECENT 5-year slice of our In-Sample data for rapid development.\n",
    "# This is much faster and more representative of modern data.\n",
    "\n",
    "dev_start_date = pd.to_datetime('2014-01-01')\n",
    "dev_end_date = pd.to_datetime('2018-12-31') # This is the end of our df_IS period\n",
    "\n",
    "print(\"\\n--- Creating Development Sandbox DataFrame (Corrected) ---\")\n",
    "print(f\"Slicing df_IS from {dev_start_date.date()} to {dev_end_date.date()}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create the development dataframe by slicing the main In-Sample data\n",
    "df_dev = df_IS[(df_IS.index.get_level_values('Date') >= dev_start_date) &\n",
    "               (df_IS.index.get_level_values('Date') <= dev_end_date)].copy()\n",
    "\n",
    "\n",
    "# --- 6. VERIFY THE (CORRECTED) DEVELOPMENT DATAFRAME ---\n",
    "print(\"\\n--- Development Sandbox (df_dev) Info ---\")\n",
    "df_dev.info(verbose=False, memory_usage='deep')\n",
    "print(f\"df_dev Date Range: {df_dev.index.get_level_values('Date').min().date()} to {df_dev.index.get_level_values('Date').max().date()}\")\n",
    "print(f\"df_dev Shape: {df_dev.shape}\")\n",
    "print(f\"df_dev as percentage of IS data: {df_dev.shape[0] / df_IS.shape[0]:.2%}\")\n",
    "\n",
    "# --- Get unique tickers from the 'Ticker' level of the MultiIndex ---\n",
    "\n",
    "# Get the 'Ticker' level of the index\n",
    "ticker_index = df_dev.index.get_level_values('Ticker')\n",
    "\n",
    "# Get the unique values from that level\n",
    "unique_tickers = ticker_index.unique()\n",
    "\n",
    "# Print the results\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nFound {len(unique_tickers)} unique tickers in df_dev.\")\n",
    "print(\"First 10 unique tickers:\")\n",
    "print(unique_tickers[:10].tolist()) # .tolist() gives a cleaner printout for a slice\n",
    "print(\"\\nLast 10 unique tickers:\")\n",
    "print(unique_tickers[-10:].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87a8d237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- 7. BOT CONFIGURATION MANAGER (UPDATED) ---\n",
    "\n",
    "# bot_config = {\n",
    "#     # --- Time Parameters ---\n",
    "#     'search_start_date': '2014-01-01',\n",
    "#     'search_end_date': '2018-12-31',\n",
    "#     # MODIFICATION: Changed '3M' to '3ME' for Month-End frequency to resolve deprecation warning.\n",
    "#     'step_frequency': '3ME',\n",
    "\n",
    "#     # --- Strategy Parameters (The Search Grid) ---\n",
    "#     'calc_periods': ['6M', '1Y'],\n",
    "#     'fwd_periods': ['3M'], \n",
    "#     'metrics': ['Sharpe', 'Sharpe (ATR)'],\n",
    "#     'rank_slices': [\n",
    "#         (1, 10),\n",
    "#         (11, 30),\n",
    "#     ],\n",
    "\n",
    "#     # --- Data Quality Filter Parameters within Rolling Window---\n",
    "#     'quality_thresholds': {\n",
    "#         'min_median_dollar_volume': 10_000_000,  # $10 mil trading volume\n",
    "#         'max_stale_pct': 0.05,  # 5% either Volume = 0, or High = Low\n",
    "#         'max_same_vol_count': 1,  # max 1 day with consecutive Volume\n",
    "#     },\n",
    "\n",
    "#     # --- General Parameters ---\n",
    "#     'benchmark_ticker': 'VOO',\n",
    "#     'results_output_path': './export_csv/dev_strategy_search_results.csv'\n",
    "# }\n",
    "\n",
    "\n",
    "# # --- Let's quickly calculate how many simulations this configuration will run ---\n",
    "# from itertools import product\n",
    "\n",
    "# num_param_sets = len(list(product(\n",
    "#     bot_config['calc_periods'],\n",
    "#     bot_config['fwd_periods'],\n",
    "#     bot_config['metrics'],\n",
    "#     bot_config['rank_slices']\n",
    "# )))\n",
    "\n",
    "# # Estimate the number of time steps\n",
    "# time_steps = pd.date_range(\n",
    "#     start=bot_config['search_start_date'],\n",
    "#     end=bot_config['search_end_date'],\n",
    "#     freq=bot_config['step_frequency']\n",
    "# )\n",
    "\n",
    "# print(\"\\n--- Bot Configuration Initialized ---\")\n",
    "# print(f\"Number of unique parameter combinations: {num_param_sets}\")\n",
    "# print(f\"Estimated number of time steps: {len(time_steps)}\")\n",
    "# print(f\"Total simulations to run: {num_param_sets * len(time_steps)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9db740c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from itertools import product\n",
    "# from tqdm.auto import tqdm\n",
    "# import time\n",
    "# from IPython.display import display\n",
    "\n",
    "# # --- Assume all functions from our project context are already defined ---\n",
    "# # (calculate_rolling_quality_metrics, get_eligible_universe, run_walk_forward_step, etc.)\n",
    "\n",
    "# # --- Assume df_dev and bot_config are already defined from previous steps ---\n",
    "\n",
    "# def run_strategy_search(df_ohlcv, config):\n",
    "#     \"\"\"\n",
    "#     Runs the main backtesting loop based on a provided configuration dictionary.\n",
    "#     \"\"\"\n",
    "#     start_time = time.time()\n",
    "    \n",
    "#     # --- 1. PRE-PROCESSING (Run once for efficiency) ---\n",
    "#     print(\"--- Phase 1: Pre-processing Data ---\")\n",
    "    \n",
    "#     # Calculate quality metrics for the entire development period\n",
    "#     quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "\n",
    "#     # Unstack the data for fast slicing later. This is a major optimization.\n",
    "#     print(\"Unstacking data for performance...\")\n",
    "#     df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "#     df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "#     df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "#     print(\"✅ Pre-processing complete.\\n\")\n",
    "    \n",
    "#     # --- 2. SETUP THE MAIN LOOP ---\n",
    "#     print(\"--- Phase 2: Setting up Simulation Loops ---\")\n",
    "    \n",
    "#     # Create all parameter combinations to test\n",
    "#     param_combinations = list(product(\n",
    "#         config['calc_periods'],\n",
    "#         config['fwd_periods'],\n",
    "#         config['metrics'],\n",
    "#         config['rank_slices']\n",
    "#     ))\n",
    "    \n",
    "#     # Create the list of dates where the bot will re-evaluate the strategy\n",
    "#     step_dates = pd.date_range(\n",
    "#         start=config['search_start_date'],\n",
    "#         end=config['search_end_date'],\n",
    "#         freq=config['step_frequency']\n",
    "#     )\n",
    "    \n",
    "#     # Map string periods to pandas DateOffset objects for our core function\n",
    "#     period_options = {\n",
    "#         '1M': pd.DateOffset(months=1), '3M': pd.DateOffset(months=3),\n",
    "#         '6M': pd.DateOffset(months=6), '1Y': pd.DateOffset(years=1)\n",
    "#     }\n",
    "    \n",
    "#     results_log = []\n",
    "#     total_sims = len(param_combinations) * len(step_dates)\n",
    "#     print(f\"Found {len(param_combinations)} parameter sets and {len(step_dates)} time steps.\")\n",
    "#     print(f\"Total simulations to run: {total_sims}\")\n",
    "#     print(\"✅ Setup complete. Starting main loop...\\n\")\n",
    "\n",
    "#     # --- 3. RUN THE MAIN LOOP ---\n",
    "#     print(\"--- Phase 3: Running Simulations ---\")\n",
    "    \n",
    "#     # Use tqdm for a progress bar on the outer loop\n",
    "#     pbar = tqdm(param_combinations, desc=\"Parameter Sets\")\n",
    "#     for params in pbar:\n",
    "#         # Unpack parameters for this run\n",
    "#         calc_period_str, fwd_period_str, metric, rank_slice = params\n",
    "#         calc_period = period_options[calc_period_str]\n",
    "#         fwd_period = period_options[fwd_period_str]\n",
    "#         rank_start, rank_end = rank_slice\n",
    "\n",
    "#         # Inner loop for stepping through time\n",
    "#         for step_date in step_dates:\n",
    "#             # 3a. DYNAMIC UNIVERSE SELECTION\n",
    "#             eligible_tickers = get_eligible_universe(\n",
    "#                 quality_metrics_df,\n",
    "#                 filter_date=step_date,\n",
    "#                 thresholds=config['quality_thresholds']\n",
    "#             )\n",
    "\n",
    "#             if not eligible_tickers:\n",
    "#                 # print(f\"Warning: No eligible tickers on {step_date.date()}. Skipping.\")\n",
    "#                 continue\n",
    "            \n",
    "#             # 3b. FILTER DATA FOR THIS STEP\n",
    "#             df_close_step = df_close_full[eligible_tickers]\n",
    "#             df_high_step = df_high_full[eligible_tickers]\n",
    "#             df_low_step = df_low_full[eligible_tickers]\n",
    "\n",
    "#             # 3c. RUN THE CORE ANALYSIS\n",
    "#             step_result = run_walk_forward_step(\n",
    "#                 df_close_full=df_close_step,\n",
    "#                 df_high_full=df_high_step,\n",
    "#                 df_low_full=df_low_step,\n",
    "#                 start_date=step_date,\n",
    "#                 calc_period=calc_period,\n",
    "#                 fwd_period=fwd_period,\n",
    "#                 metric=metric,\n",
    "#                 rank_start=rank_start,\n",
    "#                 rank_end=rank_end,\n",
    "#                 benchmark_ticker=config['benchmark_ticker']\n",
    "#             )\n",
    "            \n",
    "#             # 3d. LOG THE RESULTS\n",
    "#             if step_result['error'] is None:\n",
    "#                 p = step_result['performance_data']\n",
    "#                 log_entry = {\n",
    "#                     'step_date': step_date.date(),\n",
    "#                     'calc_period': calc_period_str,\n",
    "#                     'fwd_period': fwd_period_str,\n",
    "#                     'metric': metric,\n",
    "#                     'rank_start': rank_start,\n",
    "#                     'rank_end': rank_end,\n",
    "#                     'num_universe': len(eligible_tickers),\n",
    "#                     'num_portfolio': len(step_result['tickers_to_display']),\n",
    "#                     'fwd_p_gain': p['fwd_p_gain'],\n",
    "#                     'fwd_b_gain': p['fwd_b_gain'],\n",
    "#                     'fwd_gain_delta': p['fwd_p_gain'] - p['fwd_b_gain'] if not np.isnan(p['fwd_b_gain']) else np.nan,\n",
    "#                     'fwd_p_sharpe': p['fwd_p_sharpe'],\n",
    "#                 }\n",
    "#                 results_log.append(log_entry)\n",
    "\n",
    "#     print(\"✅ Main loop finished.\\n\")\n",
    "\n",
    "#     # --- 4. SAVE THE RESULTS ---\n",
    "#     print(\"--- Phase 4: Saving Results ---\")\n",
    "#     if not results_log:\n",
    "#         print(\"Warning: No results were generated. The output file will be empty.\")\n",
    "#         return None\n",
    "\n",
    "#     final_df = pd.DataFrame(results_log)\n",
    "#     output_path = config['results_output_path']\n",
    "#     final_df.to_csv(output_path, index=False, float_format='%.4f')\n",
    "\n",
    "#     end_time = time.time()\n",
    "#     print(f\"✅ Results saved to '{output_path}'\")\n",
    "#     print(f\"Total execution time: {end_time - start_time:.2f} seconds.\")\n",
    "    \n",
    "#     return final_df\n",
    "\n",
    "\n",
    "\n",
    "# # --- Execute the Bot ---\n",
    "# dev_results_df = run_strategy_search(df_dev, bot_config)\n",
    "\n",
    "# # --- Display a sample of the results ---\n",
    "# if dev_results_df is not None:\n",
    "#     print(\"\\n--- Sample of Generated Results ---\")\n",
    "#     display(dev_results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23a305e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ==============================================================================\n",
    "# # --- 7. BOT CONFIGURATION MANAGER (REVISED & IMPROVED) ---\n",
    "# # This version enforces logical consistency between holding periods and rebalancing frequency.\n",
    "# # ==============================================================================\n",
    "\n",
    "# from itertools import product\n",
    "# import pandas as pd\n",
    "\n",
    "# # --- Define period mappings in ONE central place for consistency ---\n",
    "# # We map human-readable strings to both integer trading days and Pandas frequency strings.\n",
    "# PERIOD_MAP = {\n",
    "#     '3M': {'days': 63,  'freq': '3ME'},\n",
    "#     '6M': {'days': 126, 'freq': '6ME'},\n",
    "#     '1Y': {'days': 252, 'freq': '12ME'}, # Using '12ME' is more robust than 'YE'\n",
    "# }\n",
    "\n",
    "# # --- This is the primary parameter to change for different backtests ---\n",
    "# # Let's test a strategy that rebalances every 3 months.\n",
    "# HOLDING_PERIOD = '3M'\n",
    "\n",
    "# bot_config = {\n",
    "#     # --- Time Parameters ---\n",
    "#     'search_start_date': '2014-01-01',\n",
    "#     'search_end_date': '2018-12-31',\n",
    "    \n",
    "#     # --- LOGICAL IMPROVEMENT ---\n",
    "#     # The rebalancing frequency is now DIRECTLY tied to the holding period.\n",
    "#     # This prevents logical errors like gaps or overlaps in the backtest.\n",
    "#     'step_frequency': PERIOD_MAP[HOLDING_PERIOD]['freq'],\n",
    "\n",
    "#     # --- Strategy Parameters (The Search Grid) ---\n",
    "#     'calc_periods': ['6M', '1Y'],\n",
    "#     'fwd_periods': [HOLDING_PERIOD], # This is now fixed to match the step_frequency\n",
    "#     'metrics': ['Sharpe', 'Sharpe (ATR)'],\n",
    "#     'rank_slices': [\n",
    "#         (1, 10),\n",
    "#         (11, 30),\n",
    "#     ],\n",
    "\n",
    "#     # --- Data Quality Filter Parameters within Rolling Window---\n",
    "#     'quality_thresholds': {\n",
    "#         'min_median_dollar_volume': 10_000_000,\n",
    "#         'max_stale_pct': 0.05,\n",
    "#         'max_same_vol_count': 1,\n",
    "#     },\n",
    "\n",
    "#     # --- General Parameters ---\n",
    "#     'benchmark_ticker': 'VOO',\n",
    "#     'master_calendar_ticker': 'VOO', # It's good practice to be explicit\n",
    "#     'results_output_path': './export_csv/dev_strategy_search_results.csv'\n",
    "# }\n",
    "\n",
    "\n",
    "# # --- Let's quickly calculate how many simulations this configuration will run ---\n",
    "# num_param_sets = len(list(product(\n",
    "#     bot_config['calc_periods'],\n",
    "#     bot_config['fwd_periods'],\n",
    "#     bot_config['metrics'],\n",
    "#     bot_config['rank_slices']\n",
    "# )))\n",
    "\n",
    "# # Estimate the number of time steps\n",
    "# time_steps = pd.date_range(\n",
    "#     start=bot_config['search_start_date'],\n",
    "#     end=bot_config['search_end_date'],\n",
    "#     freq=bot_config['step_frequency']\n",
    "# )\n",
    "\n",
    "# print(\"\\n--- Bot Configuration Initialized (Revised Logic) ---\")\n",
    "# print(f\"Holding Period / Rebalance Frequency: {HOLDING_PERIOD}\")\n",
    "# print(f\"Number of unique parameter combinations: {num_param_sets}\")\n",
    "# print(f\"Estimated number of time steps: {len(time_steps)}\")\n",
    "# print(f\"Total simulations to run: {num_param_sets * len(time_steps)}\")\n",
    "\n",
    "# # We also need to update the automation script to use this new map.\n",
    "# # The following dictionary will be passed into the 'run_strategy_search' function.\n",
    "# bot_config['period_map_days'] = {k: v['days'] for k, v in PERIOD_MAP.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf8161b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from itertools import product\n",
    "# from tqdm.auto import tqdm\n",
    "# import time\n",
    "# from IPython.display import display\n",
    "\n",
    "# # --- Assume all functions from our project context are already defined ---\n",
    "# # (calculate_rolling_quality_metrics, get_eligible_universe, run_walk_forward_step, etc.)\n",
    "\n",
    "# # --- Assume df_dev and bot_config are already defined from previous steps ---\n",
    "\n",
    "# def run_strategy_search(df_ohlcv, config):\n",
    "#     \"\"\"\n",
    "#     Runs the main backtesting loop based on a provided configuration dictionary.\n",
    "#     \"\"\"\n",
    "#     start_time = time.time()\n",
    "    \n",
    "#     # --- 1. PRE-PROCESSING (Run once for efficiency) ---\n",
    "#     print(\"--- Phase 1: Pre-processing Data ---\")\n",
    "    \n",
    "#     # Calculate quality metrics for the entire development period\n",
    "#     quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "\n",
    "#     # Unstack the data for fast slicing later. This is a major optimization.\n",
    "#     print(\"Unstacking data for performance...\")\n",
    "#     df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "#     df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "#     df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    \n",
    "#     # ==============================================================================\n",
    "#     # --- FIX 1: Generate the Master Trading Day Calendar ---\n",
    "#     # ==============================================================================\n",
    "#     master_calendar_ticker = config.get('master_calendar_ticker', config['benchmark_ticker'])\n",
    "#     if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "#         raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "#     master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "#     print(f\"Master trading day calendar created from '{master_calendar_ticker}'.\")\n",
    "#     # ==============================================================================\n",
    "    \n",
    "#     print(\"✅ Pre-processing complete.\\n\")\n",
    "    \n",
    "#     # --- 2. SETUP THE MAIN LOOP ---\n",
    "#     print(\"--- Phase 2: Setting up Simulation Loops ---\")\n",
    "    \n",
    "#     # Create all parameter combinations to test\n",
    "#     param_combinations = list(product(\n",
    "#         config['calc_periods'],\n",
    "#         config['fwd_periods'],\n",
    "#         config['metrics'],\n",
    "#         config['rank_slices']\n",
    "#     ))\n",
    "    \n",
    "#     # Create the list of dates where the bot will re-evaluate the strategy\n",
    "#     step_dates = pd.date_range(\n",
    "#         start=config['search_start_date'],\n",
    "#         end=config['search_end_date'],\n",
    "#         freq=config['step_frequency']\n",
    "#     )\n",
    "    \n",
    "#     # ==============================================================================\n",
    "#     # --- FIX 2: Map period strings to INTEGER trading days ---\n",
    "#     # ==============================================================================\n",
    "#     # # Our core function expects an integer number of days, not a DateOffset.\n",
    "#     # period_options = {\n",
    "#     #     '1M': 21, '3M': 63,\n",
    "#     #     '6M': 126, '1Y': 252\n",
    "#     # }\n",
    "#     # Use the period map passed directly from the configuration\n",
    "#     period_options = config['period_map_days']\n",
    "#     # ==============================================================================\n",
    "    \n",
    "#     results_log = []\n",
    "#     total_sims = len(param_combinations) * len(step_dates)\n",
    "#     print(f\"Found {len(param_combinations)} parameter sets and {len(step_dates)} time steps.\")\n",
    "#     print(f\"Total simulations to run: {total_sims}\")\n",
    "#     print(\"✅ Setup complete. Starting main loop...\\n\")\n",
    "\n",
    "#     # --- 3. RUN THE MAIN LOOP ---\n",
    "#     print(\"--- Phase 3: Running Simulations ---\")\n",
    "    \n",
    "#     pbar = tqdm(param_combinations, desc=\"Parameter Sets\")\n",
    "#     for params in pbar:\n",
    "#         # Unpack parameters for this run\n",
    "#         calc_period_str, fwd_period_str, metric, rank_slice = params\n",
    "#         calc_period = period_options[calc_period_str]\n",
    "#         fwd_period = period_options[fwd_period_str]\n",
    "#         rank_start, rank_end = rank_slice\n",
    "\n",
    "#         for step_date in step_dates:\n",
    "#             eligible_tickers = get_eligible_universe(\n",
    "#                 quality_metrics_df,\n",
    "#                 filter_date=step_date,\n",
    "#                 thresholds=config['quality_thresholds']\n",
    "#             )\n",
    "\n",
    "#             if not eligible_tickers:\n",
    "#                 continue\n",
    "            \n",
    "#             df_close_step = df_close_full[eligible_tickers]\n",
    "#             df_high_step = df_high_full[eligible_tickers]\n",
    "#             df_low_step = df_low_full[eligible_tickers]\n",
    "\n",
    "#             # ==============================================================================\n",
    "#             # --- FIX 3: Pass master_trading_days and handle tuple return ---\n",
    "#             # ==============================================================================\n",
    "#             step_result, _ = run_walk_forward_step(\n",
    "#                 df_close_full=df_close_step,\n",
    "#                 df_high_full=df_high_step,\n",
    "#                 df_low_full=df_low_step,\n",
    "#                 master_trading_days=master_trading_days, # <-- PASS IT HERE\n",
    "#                 start_date=step_date,\n",
    "#                 calc_period=calc_period,\n",
    "#                 fwd_period=fwd_period,\n",
    "#                 metric=metric,\n",
    "#                 rank_start=rank_start,\n",
    "#                 rank_end=rank_end,\n",
    "#                 benchmark_ticker=config['benchmark_ticker'],\n",
    "#                 debug=False # No need for detailed debug data in the search loop\n",
    "#             )\n",
    "#             # ==============================================================================\n",
    "            \n",
    "#             if step_result['error'] is None:\n",
    "#                 p = step_result['performance_data']\n",
    "#                 log_entry = {\n",
    "#                     'step_date': step_date.date(),\n",
    "#                     'calc_period': calc_period_str,\n",
    "#                     'fwd_period': fwd_period_str,\n",
    "#                     'metric': metric,\n",
    "#                     'rank_start': rank_start,\n",
    "#                     'rank_end': rank_end,\n",
    "#                     'num_universe': len(eligible_tickers),\n",
    "#                     'num_portfolio': len(step_result['tickers_to_display']),\n",
    "#                     'fwd_p_gain': p['fwd_p_gain'],\n",
    "#                     'fwd_b_gain': p['fwd_b_gain'],\n",
    "#                     'fwd_gain_delta': p['fwd_p_gain'] - p['fwd_b_gain'] if not np.isnan(p['fwd_b_gain']) else np.nan,\n",
    "#                     'fwd_p_sharpe': p['fwd_p_sharpe'],\n",
    "#                 }\n",
    "#                 results_log.append(log_entry)\n",
    "\n",
    "#     print(\"✅ Main loop finished.\\n\")\n",
    "\n",
    "#     # --- 4. SAVE THE RESULTS ---\n",
    "#     print(\"--- Phase 4: Saving Results ---\")\n",
    "#     if not results_log:\n",
    "#         print(\"Warning: No results were generated. The output file will be empty.\")\n",
    "#         return None\n",
    "\n",
    "#     final_df = pd.DataFrame(results_log)\n",
    "#     output_path = config['results_output_path']\n",
    "#     final_df.to_csv(output_path, index=False, float_format='%.4f')\n",
    "\n",
    "#     end_time = time.time()\n",
    "#     print(f\"✅ Results saved to '{output_path}'\")\n",
    "#     print(f\"Total execution time: {end_time - start_time:.2f} seconds.\")\n",
    "    \n",
    "#     return final_df\n",
    "\n",
    "# # --- Execute the Bot ---\n",
    "# dev_results_df = run_strategy_search(df_dev, bot_config)\n",
    "\n",
    "# # --- Display a sample of the results ---\n",
    "# if dev_results_df is not None:\n",
    "#     print(\"\\n--- Sample of Generated Results ---\")\n",
    "#     display(dev_results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76bc9cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ==============================================================================\n",
    "# # --- 7. BOT CONFIGURATION MANAGER (INTEGER-BASED GRANULAR CONTROL) ---\n",
    "# # This version uses integer trading days for all periods, allowing for precise,\n",
    "# # non-calendar-based strategy testing.\n",
    "# # ==============================================================================\n",
    "\n",
    "# from itertools import product\n",
    "# import pandas as pd\n",
    "\n",
    "# # ==============================================================================\n",
    "# # --- PRIMARY USER INPUTS ---\n",
    "# # Define the holding period in TRADING DAYS. This is now the key parameter.\n",
    "# # This value also serves as the rebalancing frequency (step size).\n",
    "# HOLDING_PERIOD_DAYS = 63  # e.g., 63 days is approx. 3 months\n",
    "\n",
    "# # Define the lookback periods (for ranking) in TRADING DAYS.\n",
    "# CALC_PERIODS_DAYS = [126, 252] # e.g., 126 days is approx. 6 months\n",
    "# # ==============================================================================\n",
    "\n",
    "# bot_config = {\n",
    "#     # --- Time Parameters ---\n",
    "#     'search_start_date': '2014-01-01',\n",
    "#     'search_end_date': '2018-12-31',\n",
    "    \n",
    "#     # --- Strategy Parameters (The Search Grid) ---\n",
    "#     # All periods are now defined as integers (number of trading days).\n",
    "#     'calc_periods': CALC_PERIODS_DAYS,\n",
    "#     'fwd_periods': [HOLDING_PERIOD_DAYS], # The holding period is the fwd_period\n",
    "#     'metrics': ['Sharpe', 'Sharpe (ATR)'],\n",
    "#     'rank_slices': [\n",
    "#         (1, 10),\n",
    "#         (11, 30),\n",
    "#     ],\n",
    "\n",
    "#     # --- Data Quality Filter Parameters ---\n",
    "#     'quality_thresholds': {\n",
    "#         'min_median_dollar_volume': 10_000_000,\n",
    "#         'max_stale_pct': 0.05,\n",
    "#         'max_same_vol_count': 1,\n",
    "#     },\n",
    "\n",
    "#     # --- General Parameters ---\n",
    "#     'benchmark_ticker': 'VOO',\n",
    "#     'master_calendar_ticker': 'VOO',\n",
    "#     'results_output_path': './export_csv/dev_strategy_search_results.csv'\n",
    "# }\n",
    "\n",
    "\n",
    "# # --- Let's quickly calculate how many simulations this configuration will run ---\n",
    "# # NOTE: The number of time steps is now an estimate until the master_trading_days\n",
    "# # calendar is created in the next cell.\n",
    "# num_param_sets = len(list(product(\n",
    "#     bot_config['calc_periods'],\n",
    "#     bot_config['fwd_periods'],\n",
    "#     bot_config['metrics'],\n",
    "#     bot_config['rank_slices']\n",
    "# )))\n",
    "\n",
    "# est_days = (pd.to_datetime(bot_config['search_end_date']) - pd.to_datetime(bot_config['search_start_date'])).days\n",
    "# est_trading_days = est_days * (252/365)\n",
    "# est_time_steps = int(est_trading_days / HOLDING_PERIOD_DAYS)\n",
    "\n",
    "\n",
    "# print(\"\\n--- Bot Configuration Initialized (Integer-Based Logic) ---\")\n",
    "# print(f\"Holding Period / Rebalance Frequency: {HOLDING_PERIOD_DAYS} trading days\")\n",
    "# print(f\"Number of unique parameter combinations: {num_param_sets}\")\n",
    "# print(f\"Roughly estimated number of time steps: {est_time_steps}\")\n",
    "# print(f\"Total simulations to run: ~{num_param_sets * est_time_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11e67681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from itertools import product\n",
    "# from tqdm.auto import tqdm\n",
    "# import time\n",
    "# from IPython.display import display\n",
    "\n",
    "# # --- Assume all functions from our project context are already defined ---\n",
    "# # (calculate_rolling_quality_metrics, get_eligible_universe, run_walk_forward_step, etc.)\n",
    "\n",
    "# # --- Assume df_dev and bot_config are already defined from previous steps ---\n",
    "\n",
    "# def run_strategy_search(df_ohlcv, config):\n",
    "#     \"\"\"\n",
    "#     Runs the main backtesting loop based on a provided configuration dictionary.\n",
    "#     This version uses precise integer trading days for all period calculations.\n",
    "#     \"\"\"\n",
    "#     start_time = time.time()\n",
    "    \n",
    "#     # --- 1. PRE-PROCESSING (Run once for efficiency) ---\n",
    "#     print(\"--- Phase 1: Pre-processing Data ---\")\n",
    "    \n",
    "#     quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "\n",
    "#     print(\"Unstacking data for performance...\")\n",
    "#     df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "#     df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "#     df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    \n",
    "#     master_calendar_ticker = config['master_calendar_ticker']\n",
    "#     if master_calendar_ticker not in df_ohlcv.index.get_level_values(0):\n",
    "#         raise ValueError(f\"Master calendar ticker '{master_calendar_ticker}' not found in DataFrame.\")\n",
    "#     master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "#     print(f\"Master trading day calendar created from '{master_calendar_ticker}' ({len(master_trading_days)} days).\")\n",
    "    \n",
    "#     print(\"✅ Pre-processing complete.\\n\")\n",
    "    \n",
    "#     # --- 2. SETUP THE MAIN LOOP ---\n",
    "#     print(\"--- Phase 2: Setting up Simulation Loops ---\")\n",
    "    \n",
    "#     param_combinations = list(product(\n",
    "#         config['calc_periods'],\n",
    "#         config['fwd_periods'],\n",
    "#         config['metrics'],\n",
    "#         config['rank_slices']\n",
    "#     ))\n",
    "    \n",
    "#     # ==============================================================================\n",
    "#     # --- CRITICAL CHANGE: Generate step_dates using integer trading day steps ---\n",
    "#     # ==============================================================================\n",
    "#     # Instead of pd.date_range, we now iterate through our precise trading day calendar.\n",
    "#     search_start_date = pd.to_datetime(config['search_start_date'])\n",
    "#     search_end_date = pd.to_datetime(config['search_end_date'])\n",
    "    \n",
    "#     # Find the index positions in our calendar for the search period.\n",
    "#     start_idx = master_trading_days.searchsorted(search_start_date, side='left')\n",
    "#     end_idx = master_trading_days.searchsorted(search_end_date, side='right')\n",
    "    \n",
    "#     # The step size for rebalancing is the holding period.\n",
    "#     # We only have one fwd_period in our config, so we take the first element.\n",
    "#     step_size = config['fwd_periods'][0] \n",
    "    \n",
    "#     # Generate the list of indices where each new period will start.\n",
    "#     step_indices = range(start_idx, end_idx, step_size)\n",
    "    \n",
    "#     # Get the actual dates corresponding to those indices.\n",
    "#     step_dates = master_trading_days[step_indices]\n",
    "#     # ==============================================================================\n",
    "    \n",
    "#     results_log = []\n",
    "#     total_sims = len(param_combinations) * len(step_dates)\n",
    "#     print(f\"Found {len(param_combinations)} parameter sets and {len(step_dates)} time steps.\")\n",
    "#     print(f\"Total simulations to run: {total_sims}\")\n",
    "#     print(\"✅ Setup complete. Starting main loop...\\n\")\n",
    "\n",
    "#     # --- 3. RUN THE MAIN LOOP ---\n",
    "#     print(\"--- Phase 3: Running Simulations ---\")\n",
    "    \n",
    "#     pbar = tqdm(param_combinations, desc=\"Parameter Sets\")\n",
    "#     for params in pbar:\n",
    "#         # Unpack parameters. They are already integers, so no mapping is needed.\n",
    "#         calc_period, fwd_period, metric, rank_slice = params\n",
    "#         rank_start, rank_end = rank_slice\n",
    "\n",
    "#         for step_date in step_dates:\n",
    "#             eligible_tickers = get_eligible_universe(\n",
    "#                 quality_metrics_df,\n",
    "#                 filter_date=step_date,\n",
    "#                 thresholds=config['quality_thresholds']\n",
    "#             )\n",
    "\n",
    "#             if not eligible_tickers:\n",
    "#                 continue\n",
    "            \n",
    "#             df_close_step = df_close_full[eligible_tickers]\n",
    "#             df_high_step = df_high_full[eligible_tickers]\n",
    "#             df_low_step = df_low_full[eligible_tickers]\n",
    "\n",
    "#             step_result, _ = run_walk_forward_step(\n",
    "#                 df_close_full=df_close_step,\n",
    "#                 df_high_full=df_high_step,\n",
    "#                 df_low_full=df_low_step,\n",
    "#                 master_trading_days=master_trading_days,\n",
    "#                 start_date=step_date,\n",
    "#                 calc_period=calc_period,\n",
    "#                 fwd_period=fwd_period,\n",
    "#                 metric=metric,\n",
    "#                 rank_start=rank_start,\n",
    "#                 rank_end=rank_end,\n",
    "#                 benchmark_ticker=config['benchmark_ticker'],\n",
    "#                 debug=False\n",
    "#             )\n",
    "            \n",
    "#             if step_result['error'] is None:\n",
    "#                 p = step_result['performance_data']\n",
    "#                 log_entry = {\n",
    "#                     'step_date': step_date.date(),\n",
    "#                     'calc_period': calc_period, # Now logging the integer\n",
    "#                     'fwd_period': fwd_period,   # Now logging the integer\n",
    "#                     'metric': metric,\n",
    "#                     'rank_start': rank_start,\n",
    "#                     'rank_end': rank_end,\n",
    "#                     'num_universe': len(eligible_tickers),\n",
    "#                     'num_portfolio': len(step_result['tickers_to_display']),\n",
    "#                     'fwd_p_gain': p['fwd_p_gain'],\n",
    "#                     'fwd_b_gain': p['fwd_b_gain'],\n",
    "#                     'fwd_gain_delta': p['fwd_p_gain'] - p['fwd_b_gain'] if not np.isnan(p['fwd_b_gain']) else np.nan,\n",
    "#                     'fwd_p_sharpe': p['fwd_p_sharpe'],\n",
    "#                 }\n",
    "#                 results_log.append(log_entry)\n",
    "\n",
    "#     print(\"✅ Main loop finished.\\n\")\n",
    "\n",
    "#     # --- 4. SAVE THE RESULTS ---\n",
    "#     print(\"--- Phase 4: Saving Results ---\")\n",
    "#     if not results_log:\n",
    "#         print(\"Warning: No results were generated. The output file will be empty.\")\n",
    "#         return None\n",
    "\n",
    "#     final_df = pd.DataFrame(results_log)\n",
    "#     output_path = config['results_output_path']\n",
    "#     final_df.to_csv(output_path, index=False, float_format='%.4f')\n",
    "\n",
    "#     end_time = time.time()\n",
    "#     print(f\"✅ Results saved to '{output_path}'\")\n",
    "#     print(f\"Total execution time: {end_time - start_time:.2f} seconds.\")\n",
    "    \n",
    "#     return final_df\n",
    "\n",
    "# # --- Execute the Bot ---\n",
    "# dev_results_df = run_strategy_search(df_dev, bot_config)\n",
    "\n",
    "# # --- Display a sample of the results ---\n",
    "# if dev_results_df is not None:\n",
    "#     print(\"\\n--- Sample of Generated Results ---\")\n",
    "#     display(dev_results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fb9e93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Bot Configuration Initialized (Multi-Holding-Period Logic) ---\n",
      "Holding Periods to Test: [3, 5, 10] trading days\n",
      "Number of unique parameter combinations: 36\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# --- 7. BOT CONFIGURATION MANAGER (TESTING MULTIPLE HOLDING PERIODS) ---\n",
    "# ==============================================================================\n",
    "\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "\n",
    "# ==============================================================================\n",
    "# --- PRIMARY USER INPUTS ---\n",
    "# Now we can test a whole list of holding periods in one go.\n",
    "HOLDING_PERIODS_DAYS = [3, 5, 10] # approx. 3d, 1w, 2w\n",
    "\n",
    "CALC_PERIODS_DAYS = [21, 42, 63] # approx. 1m, 2m, 3m\n",
    "# ==============================================================================\n",
    "\n",
    "bot_config = {\n",
    "    # --- Time Parameters ---\n",
    "    'search_start_date': '2014-01-01',\n",
    "    'search_end_date': '2018-12-31',\n",
    "    \n",
    "    # --- Strategy Parameters (The Search Grid) ---\n",
    "    'calc_periods': CALC_PERIODS_DAYS,\n",
    "    'fwd_periods': HOLDING_PERIODS_DAYS, # <-- Pass the full list here\n",
    "    'metrics': ['Sharpe', 'Sharpe (ATR)'],\n",
    "    'rank_slices': [\n",
    "        (1, 5),\n",
    "        (5, 10),\n",
    "    ],\n",
    "\n",
    "    # --- Data Quality Filter Parameters ---\n",
    "    'quality_thresholds': {\n",
    "        'min_median_dollar_volume': 10_000_000,\n",
    "        'max_stale_pct': 0.05,\n",
    "        'max_same_vol_count': 1,\n",
    "    },\n",
    "\n",
    "    # --- General Parameters ---\n",
    "    'benchmark_ticker': 'VOO',\n",
    "    'master_calendar_ticker': 'VOO',\n",
    "    'results_output_path': './export_csv/dev_strategy_search_results.csv'\n",
    "}\n",
    "\n",
    "\n",
    "# --- Let's quickly calculate how many simulations this configuration will run ---\n",
    "num_param_sets = len(list(product(\n",
    "    bot_config['calc_periods'],\n",
    "    bot_config['fwd_periods'],\n",
    "    bot_config['metrics'],\n",
    "    bot_config['rank_slices']\n",
    ")))\n",
    "\n",
    "print(\"\\n--- Bot Configuration Initialized (Multi-Holding-Period Logic) ---\")\n",
    "print(f\"Holding Periods to Test: {HOLDING_PERIODS_DAYS} trading days\")\n",
    "print(f\"Number of unique parameter combinations: {num_param_sets}\")\n",
    "# The total number of steps is now variable, so we don't estimate it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80c38f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Phase 1: Pre-processing Data ---\n",
      "--- Calculating Rolling Quality Metrics (Window: 252 days) ---\n",
      "✅ Rolling metrics calculation complete.\n",
      "Unstacking data for performance...\n",
      "Master trading day calendar created from 'VOO' (1258 days).\n",
      "✅ Pre-processing complete.\n",
      "\n",
      "--- Phase 2: Setting up Simulation Loops ---\n",
      "Pre-calculating rebalancing schedules for each holding period...\n",
      "  - Holding Period 3 days: 420 rebalances\n",
      "  - Holding Period 5 days: 252 rebalances\n",
      "  - Holding Period 10 days: 126 rebalances\n",
      "Found 36 total parameter sets to simulate.\n",
      "✅ Setup complete. Starting main loop...\n",
      "\n",
      "--- Phase 3: Running Simulations ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5169d1ae54e04cd08e52bd68fbed02c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parameter Sets:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic Filter (2014-01-02): Kept 0 of 569 tickers.\n",
      "Dynamic Filter (2014-01-07): Kept 0 of 569 tickers.\n",
      "Dynamic Filter (2014-01-10): Kept 0 of 569 tickers.\n",
      "Dynamic Filter (2014-01-15): Kept 0 of 569 tickers.\n",
      "Dynamic Filter (2014-01-21): Kept 0 of 569 tickers.\n",
      "Dynamic Filter (2014-01-24): Kept 0 of 569 tickers.\n",
      "Dynamic Filter (2014-01-29): Kept 0 of 569 tickers.\n",
      "Dynamic Filter (2014-02-03): Kept 0 of 569 tickers.\n",
      "Dynamic Filter (2014-02-06): Kept 0 of 569 tickers.\n",
      "Dynamic Filter (2014-02-11): Kept 0 of 569 tickers.\n",
      "Dynamic Filter (2014-02-14): Kept 0 of 569 tickers.\n",
      "Dynamic Filter (2014-02-20): Kept 0 of 569 tickers.\n",
      "Dynamic Filter (2014-02-25): Kept 0 of 569 tickers.\n",
      "Dynamic Filter (2014-02-28): Kept 0 of 570 tickers.\n",
      "Dynamic Filter (2014-03-05): Kept 0 of 570 tickers.\n",
      "Dynamic Filter (2014-03-10): Kept 0 of 570 tickers.\n",
      "Dynamic Filter (2014-03-13): Kept 0 of 570 tickers.\n",
      "Dynamic Filter (2014-03-18): Kept 0 of 570 tickers.\n",
      "Dynamic Filter (2014-03-21): Kept 0 of 571 tickers.\n",
      "Dynamic Filter (2014-03-26): Kept 0 of 571 tickers.\n",
      "Dynamic Filter (2014-03-31): Kept 0 of 571 tickers.\n",
      "Dynamic Filter (2014-04-03): Kept 0 of 571 tickers.\n",
      "Dynamic Filter (2014-04-08): Kept 0 of 571 tickers.\n",
      "Dynamic Filter (2014-04-11): Kept 0 of 571 tickers.\n",
      "Dynamic Filter (2014-04-16): Kept 0 of 572 tickers.\n",
      "Dynamic Filter (2014-04-22): Kept 0 of 572 tickers.\n",
      "Dynamic Filter (2014-04-25): Kept 0 of 572 tickers.\n",
      "Dynamic Filter (2014-04-30): Kept 0 of 572 tickers.\n",
      "Dynamic Filter (2014-05-05): Kept 0 of 573 tickers.\n",
      "Dynamic Filter (2014-05-08): Kept 0 of 573 tickers.\n",
      "Dynamic Filter (2014-05-13): Kept 0 of 573 tickers.\n",
      "Dynamic Filter (2014-05-16): Kept 0 of 573 tickers.\n",
      "Dynamic Filter (2014-05-21): Kept 0 of 573 tickers.\n",
      "Dynamic Filter (2014-05-27): Kept 0 of 574 tickers.\n",
      "Dynamic Filter (2014-05-30): Kept 0 of 574 tickers.\n",
      "Dynamic Filter (2014-06-04): Kept 0 of 574 tickers.\n",
      "Dynamic Filter (2014-06-09): Kept 0 of 575 tickers.\n",
      "Dynamic Filter (2014-06-12): Kept 0 of 576 tickers.\n",
      "Dynamic Filter (2014-06-17): Kept 0 of 576 tickers.\n",
      "Dynamic Filter (2014-06-20): Kept 0 of 577 tickers.\n",
      "Dynamic Filter (2014-06-25): Kept 0 of 577 tickers.\n",
      "Dynamic Filter (2014-06-30): Kept 0 of 577 tickers.\n",
      "Dynamic Filter (2014-07-03): Kept 453 of 577 tickers.\n",
      "Dynamic Filter (2014-07-09): Kept 455 of 578 tickers.\n",
      "Dynamic Filter (2014-07-14): Kept 456 of 578 tickers.\n",
      "Dynamic Filter (2014-07-17): Kept 456 of 578 tickers.\n",
      "Dynamic Filter (2014-07-22): Kept 456 of 578 tickers.\n",
      "Dynamic Filter (2014-07-25): Kept 457 of 578 tickers.\n",
      "Dynamic Filter (2014-07-30): Kept 456 of 578 tickers.\n",
      "Dynamic Filter (2014-08-04): Kept 456 of 580 tickers.\n",
      "Dynamic Filter (2014-08-07): Kept 456 of 580 tickers.\n",
      "Dynamic Filter (2014-08-12): Kept 456 of 580 tickers.\n",
      "Dynamic Filter (2014-08-15): Kept 455 of 580 tickers.\n",
      "Dynamic Filter (2014-08-20): Kept 455 of 580 tickers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 121\u001b[39m\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m final_df\n\u001b[32m    120\u001b[39m \u001b[38;5;66;03m# --- Execute the Bot ---\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m dev_results_df = \u001b[43mrun_strategy_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_dev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbot_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# --- Display a sample of the results ---\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dev_results_df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 80\u001b[39m, in \u001b[36mrun_strategy_search\u001b[39m\u001b[34m(df_ohlcv, config)\u001b[39m\n\u001b[32m     77\u001b[39m df_high_step = df_high_full[eligible_tickers]\n\u001b[32m     78\u001b[39m df_low_step = df_low_full[eligible_tickers]\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m step_result, _ = \u001b[43mrun_walk_forward_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf_close_full\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf_close_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_high_full\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf_high_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_low_full\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf_low_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaster_trading_days\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaster_trading_days\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcalc_period\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcalc_period\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfwd_period\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfwd_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank_start\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrank_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank_end\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrank_end\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbenchmark_ticker\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbenchmark_ticker\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m     86\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m step_result[\u001b[33m'\u001b[39m\u001b[33merror\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     89\u001b[39m     p = step_result[\u001b[33m'\u001b[39m\u001b[33mperformance_data\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 78\u001b[39m, in \u001b[36mrun_walk_forward_step\u001b[39m\u001b[34m(df_close_full, df_high_full, df_low_full, master_trading_days, start_date, calc_period, fwd_period, metric, rank_start, rank_end, benchmark_ticker, debug)\u001b[39m\n\u001b[32m     76\u001b[39m first_prices = calc_close.bfill().iloc[\u001b[32m0\u001b[39m]\n\u001b[32m     77\u001b[39m last_prices = calc_close.ffill().iloc[-\u001b[32m1\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m daily_returns = \u001b[43mcalc_close\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbfill\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mffill\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpct_change\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m mean_returns = daily_returns.mean()\n\u001b[32m     80\u001b[39m std_returns = daily_returns.std()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:12137\u001b[39m, in \u001b[36mNDFrame.pct_change\u001b[39m\u001b[34m(self, periods, fill_method, limit, freq, **kwargs)\u001b[39m\n\u001b[32m  12135\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(col) > \u001b[32m0\u001b[39m:\n\u001b[32m  12136\u001b[39m     mask = col.isna().values\n\u001b[32m> \u001b[39m\u001b[32m12137\u001b[39m     mask = mask[\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m~\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m :]\n\u001b[32m  12138\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m  12139\u001b[39m         warnings.warn(\n\u001b[32m  12140\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe default fill_method=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mpad\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m  12141\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.pct_change is deprecated and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m  12146\u001b[39m             stacklevel=find_stack_level(),\n\u001b[32m  12147\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:1229\u001b[39m, in \u001b[36margmax\u001b[39m\u001b[34m(a, axis, out, keepdims)\u001b[39m\n\u001b[32m   1142\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1143\u001b[39m \u001b[33;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[32m   1144\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1226\u001b[39m \u001b[33;03m(2, 1, 4)\u001b[39;00m\n\u001b[32m   1227\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1228\u001b[39m kwds = {\u001b[33m'\u001b[39m\u001b[33mkeepdims\u001b[39m\u001b[33m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np._NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m-> \u001b[39m\u001b[32m1229\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43margmax\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ping\\Files_win10\\python\\py311\\.venv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59\u001b[39m, in \u001b[36m_wrapfunc\u001b[39m\u001b[34m(obj, method, *args, **kwds)\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, *args, **kwds)\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m     61\u001b[39m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[32m     62\u001b[39m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     66\u001b[39m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[32m     67\u001b[39m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, *args, **kwds)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "from IPython.display import display\n",
    "\n",
    "def run_strategy_search(df_ohlcv, config):\n",
    "    \"\"\"\n",
    "    Runs the main backtesting loop. This version can test multiple fwd_periods\n",
    "    by pre-calculating a map of rebalancing dates for each holding period.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # --- 1. PRE-PROCESSING ---\n",
    "    print(\"--- Phase 1: Pre-processing Data ---\")\n",
    "    quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "    print(\"Unstacking data for performance...\")\n",
    "    df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "    df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "    df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "    \n",
    "    master_calendar_ticker = config['master_calendar_ticker']\n",
    "    master_trading_days = df_ohlcv.loc[master_calendar_ticker].index.unique().sort_values()\n",
    "    print(f\"Master trading day calendar created from '{master_calendar_ticker}' ({len(master_trading_days)} days).\")\n",
    "    print(\"✅ Pre-processing complete.\\n\")\n",
    "    \n",
    "    # --- 2. SETUP THE MAIN LOOP ---\n",
    "    print(\"--- Phase 2: Setting up Simulation Loops ---\")\n",
    "    \n",
    "    param_combinations = list(product(\n",
    "        config['calc_periods'],\n",
    "        config['fwd_periods'],\n",
    "        config['metrics'],\n",
    "        config['rank_slices']\n",
    "    ))\n",
    "    \n",
    "    # ==============================================================================\n",
    "    # --- CRITICAL CHANGE: Create a map of step_dates for each fwd_period ---\n",
    "    # ==============================================================================\n",
    "    search_start_date = pd.to_datetime(config['search_start_date'])\n",
    "    search_end_date = pd.to_datetime(config['search_end_date'])\n",
    "    start_idx = master_trading_days.searchsorted(search_start_date, side='left')\n",
    "    end_idx = master_trading_days.searchsorted(search_end_date, side='right')\n",
    "\n",
    "    step_dates_map = {}\n",
    "    print(\"Pre-calculating rebalancing schedules for each holding period...\")\n",
    "    for fwd_period in sorted(config['fwd_periods']):\n",
    "        # The step_size is the fwd_period for this specific backtest\n",
    "        step_indices = range(start_idx, end_idx, fwd_period)\n",
    "        step_dates_map[fwd_period] = master_trading_days[step_indices]\n",
    "        print(f\"  - Holding Period {fwd_period} days: {len(step_dates_map[fwd_period])} rebalances\")\n",
    "    # ==============================================================================\n",
    "    \n",
    "    results_log = []\n",
    "    print(f\"Found {len(param_combinations)} total parameter sets to simulate.\")\n",
    "    print(\"✅ Setup complete. Starting main loop...\\n\")\n",
    "\n",
    "    # --- 3. RUN THE MAIN LOOP ---\n",
    "    print(\"--- Phase 3: Running Simulations ---\")\n",
    "    \n",
    "    pbar = tqdm(param_combinations, desc=\"Parameter Sets\")\n",
    "    for params in pbar:\n",
    "        calc_period, fwd_period, metric, rank_slice = params\n",
    "        rank_start, rank_end = rank_slice\n",
    "\n",
    "        # Look up the correct list of dates for the current fwd_period\n",
    "        current_step_dates = step_dates_map[fwd_period]\n",
    "\n",
    "        for step_date in current_step_dates:\n",
    "            eligible_tickers = get_eligible_universe(\n",
    "                quality_metrics_df, filter_date=step_date, thresholds=config['quality_thresholds']\n",
    "            )\n",
    "            if not eligible_tickers: continue\n",
    "            \n",
    "            df_close_step = df_close_full[eligible_tickers]\n",
    "            df_high_step = df_high_full[eligible_tickers]\n",
    "            df_low_step = df_low_full[eligible_tickers]\n",
    "\n",
    "            step_result, _ = run_walk_forward_step(\n",
    "                df_close_full=df_close_step, df_high_full=df_high_step, df_low_full=df_low_step,\n",
    "                master_trading_days=master_trading_days, start_date=step_date,\n",
    "                calc_period=calc_period, fwd_period=fwd_period,\n",
    "                metric=metric, rank_start=rank_start, rank_end=rank_end,\n",
    "                benchmark_ticker=config['benchmark_ticker'], debug=False\n",
    "            )\n",
    "            \n",
    "            if step_result['error'] is None:\n",
    "                p = step_result['performance_data']\n",
    "                log_entry = {\n",
    "                    'step_date': step_date.date(), 'calc_period': calc_period,\n",
    "                    'fwd_period': fwd_period, 'metric': metric,\n",
    "                    'rank_start': rank_start, 'rank_end': rank_end,\n",
    "                    'num_universe': len(eligible_tickers),\n",
    "                    'num_portfolio': len(step_result['tickers_to_display']),\n",
    "                    'fwd_p_gain': p['fwd_p_gain'], 'fwd_b_gain': p['fwd_b_gain'],\n",
    "                    'fwd_gain_delta': p['fwd_p_gain'] - p['fwd_b_gain'] if not np.isnan(p['fwd_b_gain']) else np.nan,\n",
    "                    'fwd_p_sharpe': p['fwd_p_sharpe'],\n",
    "                }\n",
    "                results_log.append(log_entry)\n",
    "\n",
    "    print(\"✅ Main loop finished.\\n\")\n",
    "\n",
    "    # --- 4. SAVE THE RESULTS ---\n",
    "    print(\"--- Phase 4: Saving Results ---\")\n",
    "    if not results_log:\n",
    "        print(\"Warning: No results were generated. The output file will be empty.\")\n",
    "        return None\n",
    "\n",
    "    final_df = pd.DataFrame(results_log)\n",
    "    output_path = config['results_output_path']\n",
    "    final_df.to_csv(output_path, index=False, float_format='%.4f')\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"✅ Results saved to '{output_path}'\")\n",
    "    print(f\"Total execution time: {end_time - start_time:.2f} seconds.\")\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# --- Execute the Bot ---\n",
    "dev_results_df = run_strategy_search(df_dev, bot_config)\n",
    "\n",
    "# --- Display a sample of the results ---\n",
    "if dev_results_df is not None:\n",
    "    print(\"\\n--- Sample of Generated Results ---\")\n",
    "    display(dev_results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ef2630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbf4d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cfb9528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "step_date           2018-04-30\n",
       "calc_period                 6M\n",
       "fwd_period                  3M\n",
       "metric            Sharpe (ATR)\n",
       "rank_start                   1\n",
       "rank_end                    10\n",
       "num_universe               552\n",
       "num_portfolio               10\n",
       "fwd_p_gain            0.024308\n",
       "fwd_b_gain           -0.052125\n",
       "fwd_gain_delta        0.076433\n",
       "fwd_p_sharpe          0.705695\n",
       "Name: 33, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_results_df.loc[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b75ee90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Walk-Forward Analyzer (using Trading Day Logic)...\n",
      "Master trading day calendar created from 'VOO' (1258 days).\n",
      "Pre-calculating data quality metrics...\n",
      "--- Calculating Rolling Quality Metrics (Window: 252 days) ---\n",
      "✅ Rolling metrics calculation complete.\n",
      "Pre-processing data (unstacking)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea2798186e03496ba855734d3a1ef646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(DatePicker(value=Timestamp('2018-04-30 00:00:00'), description='Start Date:', st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "399717d3fa9e417ab2baecf8db4cd2e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines',\n",
       "              'name': 'placeholder_0',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'acc8e61f-d0d0-4030-aae8-06d440a677c1',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_1',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd7a825c6-854b-46f5-a76d-2881eb1ef0ef',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_2',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b7ad48ec-e5d5-40cb-bdc0-3f4c5ea8d0de',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_3',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '330db243-2b2b-44eb-acda-88a5823ae461',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_4',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '5c117c87-9df7-4d53-a1c1-008c3cae89b3',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_5',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4461a479-d22b-443f-bec6-c743b4c81469',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_6',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '2c2d096e-d213-4674-8fb6-6acfa9a352c4',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_7',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ee488d99-c7dd-4560-8fe0-06367c069e12',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_8',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '92da704c-5b54-43c7-b887-7d9362d7e8c6',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_9',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '8c182195-18ec-470e-8b89-a5a282a5d6ff',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_10',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b214aa95-d094-43c4-9211-8547251b384e',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_11',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'bb580b46-5c5b-4271-b667-9a5fe91d4933',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_12',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f9a7dfe4-0f0f-411e-8f24-3c130de00af0',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_13',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '94026e42-31a7-427c-80fb-c846e1dd0d43',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_14',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e2307414-f8a4-4044-a3c3-eb26c1b89da1',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_15',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b33f1fbb-c8ab-42c9-9c25-05bfef557de8',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_16',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '705a2058-d448-46ae-876c-fb98e71ec833',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_17',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '5db74dd7-0474-4332-8d0d-fe8e85097694',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_18',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '5977a5da-e6a6-40f2-8102-8ea0916e1dc2',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_19',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'be670c99-2d55-4fbd-9b1e-63abc3b4aee4',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_20',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '4c43f2ef-6942-4e0a-957d-ed7109703fb4',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_21',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c34af5ff-e17b-4460-aed3-7947b7c16b33',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_22',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '3d1c7e0e-5317-4c54-8371-034fae7e91d1',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_23',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '0efab64a-273f-470e-918f-94fcd8899fd1',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_24',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '565ffd69-4919-48d6-b3d6-51f4abc3dbe6',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_25',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '0c5323df-3bd9-4a33-96bc-309901ff600c',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_26',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '0fbada6d-2bf7-443d-94d3-1658b4b90260',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_27',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b3b59631-d4d0-4636-aa1e-306e6b66b4ec',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_28',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f11a0f5a-e071-4edb-9c16-d29e34bba940',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_29',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a543956b-c5d8-46c5-9fa3-53bb306c3ebc',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_30',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '9b7f2c26-07af-48e9-aedc-e2b4b77624b6',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_31',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '3de6e0aa-0678-45d0-8a7d-51fe27702c72',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_32',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '3707901e-c535-443c-9a46-beb42eb52051',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_33',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '45364e3f-27ba-447c-862b-f6e1083627e9',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_34',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '2ffb1ecb-c25c-4528-a40c-4ceae9cbbd86',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_35',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '14e9a21a-4a2d-48ad-b10f-1f6bf0c1480a',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_36',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '6abe0014-74a2-45e8-8d48-632920fea73c',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_37',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a945245e-0e52-4ea2-ab9f-1a720667fee6',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_38',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '3d5b1c64-05a1-4736-80a2-2e32715a88d6',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_39',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '49b65029-0fbd-47f1-958d-000428ee8005',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_40',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '1492d1b4-305b-4ecc-ad1f-1a978d2ffe44',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_41',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ba92f920-a0e8-445d-b312-63830135ad10',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_42',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f648ef6f-c5dd-41bd-8b6d-cd332e44e315',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_43',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '32f2cab5-aeb9-4cfd-9ca0-f6ebb67e1750',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_44',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'dcdd0de4-989a-469c-87d6-62d4fdb9f649',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_45',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd857a0ae-0732-48ec-af34-15f043a89cc4',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_46',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '2df63f2b-ba71-4ed1-b0e3-ad12970ae8bb',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_47',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '7b116058-0b07-4611-abe7-72e56e363e60',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_48',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e6b90ab9-664c-4bdc-afa3-f635b12887d5',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'placeholder_49',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '7e6328dc-e88d-4471-8adf-7ac0681f7066',\n",
       "              'visible': False,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': 'black', 'dash': 'dash', 'width': 3},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Benchmark',\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e2bb6a0c-7b5c-49ab-a703-f2f9a19f3f7a',\n",
       "              'visible': True,\n",
       "              'x': [None],\n",
       "              'y': [None]},\n",
       "             {'line': {'color': 'green', 'width': 3},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Group Portfolio',\n",
       "              'showlegend': True,\n",
       "              'type': 'scatter',\n",
       "              'uid': '9a05ca02-dd0c-44a9-9030-98ccf57fa67a',\n",
       "              'visible': True,\n",
       "              'x': [None],\n",
       "              'y': [None]}],\n",
       "    'layout': {'height': 600,\n",
       "               'hovermode': 'x unified',\n",
       "               'legend': {'title': {'text': 'Tickers (Ranked)'}},\n",
       "               'margin': {'t': 50},\n",
       "               'shapes': [{'line': {'color': 'grey', 'dash': 'dash', 'width': 1},\n",
       "                           'type': 'line',\n",
       "                           'x0': 0,\n",
       "                           'x1': 1,\n",
       "                           'xref': 'x domain',\n",
       "                           'y0': 1,\n",
       "                           'y1': 1,\n",
       "                           'yref': 'y'}],\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Walk-Forward Performance Analysis'},\n",
       "               'xaxis': {'title': {'text': 'Date'}},\n",
       "               'yaxis': {'title': {'text': 'Normalized Price (Start = 1)'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic Filter (2018-04-30): Kept 552 of 652 tickers.\n"
     ]
    }
   ],
   "source": [
    "results_container, debug_container = plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_dev,\n",
    "    default_start_date='2018-04-30',\n",
    "    default_calc_period=126,\n",
    "    default_fwd_period=63,\n",
    "    default_metric='Sharpe (ATR)',\n",
    "    default_rank_start=1,\n",
    "    default_rank_end=10,\n",
    "    default_benchmark_ticker='VOO',\n",
    "    quality_thresholds=bot_config['quality_thresholds'],\n",
    "    debug=True  # <-- Activate the new mode!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136212d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_container, debug_container = plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_dev,\n",
    "    default_start_date='2017-04-30',\n",
    "    default_calc_period=20,\n",
    "    default_fwd_period=5,\n",
    "    default_metric='Sharpe (ATR)',\n",
    "    default_rank_start=1,\n",
    "    default_rank_end=5,\n",
    "    default_benchmark_ticker='VOO',\n",
    "    quality_thresholds=bot_config['quality_thresholds'],\n",
    "    debug=True  # <-- Activate the new mode!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1cb63f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1136ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80668dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bacf183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- THE \"BULLETPROOF\" VERIFICATION SCRIPT (DEFINITIVELY CORRECTED) ---\n",
    "\n",
    "# (Run this cell AFTER clicking \"Update Chart\" in the cell above)\n",
    "\n",
    "# 2. Access the debug and results data\n",
    "debug_results = debug_container[0]\n",
    "results_dict = results_container[0] # The container holds the full dictionary\n",
    "\n",
    "if debug_results and results_dict:\n",
    "    print(\"--- Debug Data Successfully Captured ---\")\n",
    "\n",
    "    # Verify the Ranking (\"The Report Card\")\n",
    "    print(\"\\n--- [1] Ranking Metrics for all eligible stocks (Top 15 shown) ---\")\n",
    "    display(debug_results['ranking_metrics'].head(15))\n",
    "\n",
    "    # Verify the Daily Performance (\"The Daily Journal\")\n",
    "    print(\"\\n\\n--- [2] Daily Portfolio Trace for the Forward Period ---\")\n",
    "    \n",
    "    # --- THIS IS THE FINAL FIX ---\n",
    "    \n",
    "    # The correct start date for the forward period is stored in our main results dictionary.\n",
    "    forward_period_start_date = results_dict['actual_calc_end_ts']\n",
    "    \n",
    "    # Now we correctly slice the portfolio_trace DataFrame using a proper date.\n",
    "    fwd_trace = debug_results['portfolio_trace'].loc[forward_period_start_date:]\n",
    "\n",
    "    # --- END OF FIX ---\n",
    "    \n",
    "    print(f\"Showing forward trace starting from: {forward_period_start_date.date()}\")\n",
    "    display(fwd_trace.head())\n",
    "else:\n",
    "    print(\"Debug data not found. Did you click 'Update Chart'?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c86d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_nested_dict(d, prefix=\"\"):\n",
    "    \"\"\"Recursively print every key→value in a (possibly) nested dict.\"\"\"\n",
    "    for k, v in d.items():\n",
    "        full_key = f\"{prefix}.{k}\" if prefix else str(k)\n",
    "        if isinstance(v, dict):\n",
    "            print_nested_dict(v, full_key)          # dive deeper\n",
    "        else:\n",
    "            print(f'{full_key}:\\n{v}\\n')\n",
    "\n",
    "# demo\n",
    "nested = {\n",
    "    'user': {\n",
    "        'name': 'Alice',\n",
    "        'age': 30,\n",
    "        'address': {\n",
    "            'city': 'Paris',\n",
    "            'zip': 75001\n",
    "        }\n",
    "    },\n",
    "    'server': {\n",
    "        'host': 'localhost',\n",
    "        'port': 8080\n",
    "    }\n",
    "}\n",
    "\n",
    "print_nested_dict(nested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b46fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_nested_dict(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7237d87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_nested_dict(debug_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94950cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict['benchmark_price_series'].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513f5003",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_to_verify = results_dict['tickers_to_display']\n",
    "benchmark_ticker = results_dict['benchmark_price_series'].name\n",
    "start_date = results_dict['safe_start_date']\n",
    "\n",
    "print(f'tickers_to_verify: {tickers_to_verify}')\n",
    "print(f'benchmark_ticker: {benchmark_ticker}')\n",
    "print(f'start_date: {start_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c775b207",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_group_tickers_walk_forward_calculation(df_ohlcv=df_dev, \n",
    "                                              tickers_to_verify=tickers_to_verify, \n",
    "                                              benchmark_ticker=benchmark_ticker,\n",
    "                                              start_date=start_date, \n",
    "                                              calc_period=20, \n",
    "                                              fwd_period=5,\n",
    "                                              master_calendar_ticker=benchmark_ticker, \n",
    "                                              export_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9689884",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ticker in tickers_to_verify:\n",
    "    verify_ticker_ranking_metrics(df_ohlcv=df_dev, \n",
    "                              ticker=_ticker, \n",
    "                              start_date=start_date, \n",
    "                              calc_period=20,\n",
    "                              master_calendar_ticker='VOO', \n",
    "                              export_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9f5209",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cba46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*debug_container[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597a7b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug_container[0]['ranking_metrics'].head(50)\n",
    "debug_container[0]['ranking_metrics'].columns\n",
    "\n",
    "# debug_container[0]['portfolio_trace'].head(50)\n",
    "# debug_container[0]['portfolio_trace'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cdce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_results_df.to_csv('./export_csv/dev_results_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584c600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our inspection rules inside the rolling window\n",
    "ticker_thresholds = {\n",
    "    'min_median_dollar_volume': 10_000_000, # $10 million median daily trade volume\n",
    "    'max_stale_pct': 0.1,                   # Allow 10% stale days (i.e. Volume=0 or High=Low)\n",
    "    'max_same_vol_count': 1                 # Allow at most 1 suspicious volume event (i.e. same Volume on consecutive day)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2d172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Verification for the first row of bot results ---\n",
    "\n",
    "print(\"--- Replicating the scenario from the first CSV row ---\")\n",
    "print(\"Start Date: 2014-07-31\")\n",
    "print(\"Calc Period: 6M, Fwd Period: 3M\")\n",
    "print(\"Metric: Sharpe, Ranks: 1 to 10\")\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\"\\nInstructions: The UI will load with the correct defaults. Simply click the 'Update Chart' button.\")\n",
    "\n",
    "# Call the plotter using the parameters from the CSV row as defaults\n",
    "plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_dev,  # CRITICAL: Use the same df_dev as the bot\n",
    "    default_start_date='2017-04-30',\n",
    "    default_calc_period='6M',\n",
    "    default_fwd_period='3M',\n",
    "    default_metric='Sharpe (ATR)',\n",
    "    default_rank_start=1,\n",
    "    default_rank_end=10,\n",
    "    default_benchmark_ticker='VOO',\n",
    "    quality_thresholds=ticker_thresholds,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc9b9ad",
   "metadata": {},
   "source": [
    "### Compare bot results vs verified plot_walk_forward_analyzer_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54317ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the row\n",
    "row_index = 43\n",
    "row = dev_results_df.iloc[row_index]\n",
    "\n",
    "# convert to dict and reformat step_date\n",
    "row_dict = row.to_dict()\n",
    "row_dict['step_date'] = row_dict['step_date'].strftime('%Y-%m-%d')\n",
    "print(f'row no: {row_index}')\n",
    "print(f'row_dict: {row_dict}')\n",
    "\n",
    "_start_date=row_dict['step_date']\n",
    "_calc_period=row_dict['calc_period']\n",
    "_fwd_period=row_dict['fwd_period']\n",
    "_metric=row_dict['metric']\n",
    "_rank_start=row_dict['rank_start']\n",
    "_rank_end=row_dict['rank_end']\n",
    "_benchmark_ticker='VOO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7accff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_walk_forward_analyzer(\n",
    "    df_ohlcv=df_dev,  # CRITICAL: Use the same df_dev as the bot\n",
    "    default_start_date=_start_date,\n",
    "    default_calc_period=_calc_period,\n",
    "    default_fwd_period=_fwd_period,\n",
    "    default_metric=_metric,\n",
    "    default_rank_start=_rank_start,\n",
    "    default_rank_end=_rank_end,\n",
    "    default_benchmark_ticker=_benchmark_ticker,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01521b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_df = calculate_rolling_quality_metrics(\n",
    "    df_ohlcv=df_OHLCV,\n",
    "    window=252,\n",
    "    min_periods=126,\n",
    "    debug=False,  # <-- The key to our new, improved workflow    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4b2b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. make sure the whole frame is sorted\n",
    "df_tmp = quality_df.sort_index()\n",
    "\n",
    "# 2a. pick the exact date if it exists, otherwise the previous one\n",
    "date_needed = pd.Timestamp(_start_date)\n",
    "dates = df_tmp.index.get_level_values('Date').unique().sort_values()   # ← sorted\n",
    "# first date >= date_needed  (later)\n",
    "pos = dates.searchsorted(date_needed, side='left')\n",
    "if pos == len(dates):          # date_needed is after the last date\n",
    "    later_date = pd.NaT\n",
    "else:\n",
    "    later_date = dates[pos]\n",
    "\n",
    "print(f'_start_date: {_start_date}')\n",
    "print(f'real start date: {later_date}')\n",
    "\n",
    "# 3. slice\n",
    "# quality_df = df_tmp.xs(later_date, level='Date')\n",
    "# print(quality_df)\n",
    "print(f\"--- Quality Metrics for {later_date} ---\")\n",
    "# print(quality_df.xs('2025-10-03', level='Date'))\n",
    "print(quality_df.xs(later_date, level='Date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549894d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible_tickers = get_eligible_universe(quality_metrics_df=quality_df, \n",
    "                                        #  filter_date=_start_date, \n",
    "                                         filter_date=later_date,                                         \n",
    "                                         thresholds=ticker_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3898a28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = df_OHLCV.loc[eligible_tickers].copy()\n",
    "_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5645bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_walk_forward_analyzer_original(\n",
    "    df_ohlcv=_df,  # CRITICAL: Use the same df_dev as the bot\n",
    "    default_start_date=_start_date,\n",
    "    default_calc_period=_calc_period,\n",
    "    default_fwd_period=_fwd_period,\n",
    "    default_metric=_metric,\n",
    "    default_rank_start=_rank_start,\n",
    "    default_rank_end=_rank_end,\n",
    "    default_benchmark_ticker=_benchmark_ticker,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ffe810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Load the Bot's Output ---\n",
    "try:\n",
    "    results_df = pd.read_csv(bot_config['results_output_path'])\n",
    "    print(f\"Successfully loaded '{bot_config['results_output_path']}'. Shape: {results_df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: The results file was not found. Please run the bot first.\")\n",
    "    # In a real script, you'd exit here. For a notebook, we'll stop.\n",
    "    results_df = None\n",
    "\n",
    "if results_df is not None:\n",
    "    # --- 2. Define the Strategy Parameters for Grouping ---\n",
    "    # These are the columns that uniquely identify one strategy configuration.\n",
    "    # strategy_params = ['calc_period', 'metric', 'rank_start', 'rank_end']\n",
    "    strategy_params = ['calc_period', 'fwd_period', 'metric', 'rank_start', 'rank_end']    \n",
    "\n",
    "    # --- 3. Group and Aggregate the Results ---\n",
    "    # We group by the strategy parameters and calculate key performance metrics for each group.\n",
    "    summary_df = results_df.groupby(strategy_params).agg(\n",
    "        avg_fwd_p_gain=('fwd_p_gain', 'mean'),\n",
    "        std_fwd_p_gain=('fwd_p_gain', 'std'),\n",
    "        avg_fwd_gain_delta=('fwd_gain_delta', 'mean'),\n",
    "        # Calculate Win Rate: The percentage of periods with positive forward gain.\n",
    "        win_rate=('fwd_p_gain', lambda x: (x > 0).sum() / len(x) if len(x) > 0 else 0),\n",
    "        # Count the number of periods tested for this strategy\n",
    "        num_periods=('step_date', 'count')\n",
    "    ).sort_values(by='avg_fwd_gain_delta', ascending=False) # Sort by outperformance vs benchmark\n",
    "\n",
    "    # --- 4. Format and Display the Summary Table ---\n",
    "    print(\"\\n--- Strategy Performance Summary (2014-2018 Development Run) ---\")\n",
    "    \n",
    "    # Apply formatting for better readability\n",
    "    formatted_summary = summary_df.style.format({\n",
    "        'avg_fwd_p_gain': '{:+.2%}',\n",
    "        'std_fwd_p_gain': '{:.2%}',\n",
    "        'avg_fwd_gain_delta': '{:+.2%}',\n",
    "        'win_rate': '{:.1%}',\n",
    "    }).set_properties(**{'text-align': 'right'})\n",
    "\n",
    "    display(formatted_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b389d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_cumulative_performance(df_ohlcv, strategy_params, quality_thresholds):\n",
    "    \"\"\"\n",
    "    Plots the cumulative performance of a SINGLE strategy over a specified time range.\n",
    "\n",
    "    This function simulates rebalancing a portfolio at a fixed frequency and charts\n",
    "    the resulting equity curve against a benchmark.\n",
    "    \"\"\"\n",
    "    print(\"--- Running Cumulative Performance Simulation for the Winning Strategy ---\")\n",
    "    \n",
    "    # --- 1. Setup and Pre-processing ---\n",
    "    # Unpack strategy parameters from the dictionary\n",
    "    start_date = strategy_params['start_date']\n",
    "    end_date = strategy_params['end_date']\n",
    "    calc_period_str = strategy_params['calc_period']\n",
    "    fwd_period_str = strategy_params['fwd_period']\n",
    "    metric = strategy_params['metric']\n",
    "    rank_start = strategy_params['rank_start']\n",
    "    rank_end = strategy_params['rank_end']\n",
    "    benchmark_ticker = strategy_params['benchmark_ticker']\n",
    "    \n",
    "    # Pre-calculate quality metrics and unstack data once for efficiency\n",
    "    quality_metrics_df = calculate_rolling_quality_metrics(df_ohlcv, window=252)\n",
    "    df_close_full = df_ohlcv['Adj Close'].unstack(level=0)\n",
    "    df_high_full = df_ohlcv['Adj High'].unstack(level=0)\n",
    "    df_low_full = df_ohlcv['Adj Low'].unstack(level=0)\n",
    "\n",
    "    # Map string periods to pandas DateOffset objects\n",
    "    period_options = {'3M': pd.DateOffset(months=3), '6M': pd.DateOffset(months=6), '1Y': pd.DateOffset(years=1)}\n",
    "    calc_period = period_options[calc_period_str]\n",
    "    fwd_period = period_options[fwd_period_str] # This also defines our rebalancing frequency\n",
    "    \n",
    "    # --- 2. Main Simulation Loop ---\n",
    "    # Create the rebalancing dates\n",
    "    step_dates = pd.date_range(start=start_date, end=end_date, freq=f'{fwd_period.months}ME')\n",
    "    \n",
    "    all_fwd_gains = []\n",
    "    \n",
    "    print(f\"Simulating from {step_dates[0].date()} to {step_dates[-1].date()}...\")\n",
    "    \n",
    "    for step_date in step_dates:\n",
    "        # Get the eligible universe for this specific rebalancing date\n",
    "        eligible_tickers = get_eligible_universe(quality_metrics_df, step_date, quality_thresholds)\n",
    "        if not eligible_tickers: continue\n",
    "            \n",
    "        df_close_step = df_close_full[eligible_tickers]\n",
    "        df_high_step = df_high_full[eligible_tickers]\n",
    "        df_low_step = df_low_full[eligible_tickers]\n",
    "        \n",
    "        # Run the core calculation for this single step in time\n",
    "        step_result = run_walk_forward_step(\n",
    "            df_close_step, df_high_step, df_low_step,\n",
    "            step_date, calc_period, fwd_period,\n",
    "            metric, rank_start, rank_end, benchmark_ticker\n",
    "        )\n",
    "        \n",
    "        if step_result['error'] is None:\n",
    "            # Extract the forward portion of the portfolio's performance\n",
    "            fwd_series = step_result['portfolio_series'].loc[step_result['actual_calc_end_ts']:]\n",
    "            all_fwd_gains.append(fwd_series.pct_change().dropna())\n",
    "            \n",
    "    # --- 3. Stitch Together Results & Plot ---\n",
    "    if not all_fwd_gains:\n",
    "        print(\"Error: No valid periods were simulated. Cannot plot.\")\n",
    "        return\n",
    "\n",
    "    # Concatenate all the forward period returns into one long series\n",
    "    strategy_returns = pd.concat(all_fwd_gains)\n",
    "    \n",
    "    # Create the equity curve (cumulative performance)\n",
    "    # (1 + returns).cumprod() is the standard way to calculate this\n",
    "    strategy_equity_curve = (1 + strategy_returns).cumprod()\n",
    "    \n",
    "    # Get the benchmark returns for the same period\n",
    "    benchmark_returns = df_close_full[benchmark_ticker].pct_change()\n",
    "    benchmark_returns_filtered = benchmark_returns.loc[strategy_equity_curve.index]\n",
    "    benchmark_equity_curve = (1 + benchmark_returns_filtered).cumprod()\n",
    "    \n",
    "    # Create the plot\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=strategy_equity_curve.index, y=strategy_equity_curve,\n",
    "                             mode='lines', name='Winning Strategy', line=dict(color='green', width=3)))\n",
    "    fig.add_trace(go.Scatter(x=benchmark_equity_curve.index, y=benchmark_equity_curve,\n",
    "                             mode='lines', name=f'Benchmark ({benchmark_ticker})', line=dict(color='black', dash='dash')))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"Cumulative Performance: '{metric}' Strategy (Top {rank_start}-{rank_end}) vs. Benchmark\",\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=\"Cumulative Growth (Normalized to 1)\",\n",
    "        legend_title=\"Portfolio\",\n",
    "        hovermode='x unified',\n",
    "        height=600\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380f1890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define the parameters for our winning strategy ---\n",
    "winning_strategy_params = {\n",
    "    'start_date': '2014-01-31',\n",
    "    'end_date': '2018-12-31',\n",
    "    'calc_period': '6M',\n",
    "    'fwd_period': '3M',\n",
    "    'metric': 'Sharpe (ATR)',\n",
    "    'rank_start': 1,\n",
    "    'rank_end': 10,\n",
    "    'benchmark_ticker': 'VOO'\n",
    "}\n",
    "\n",
    "# Get the quality thresholds from the bot's configuration\n",
    "quality_thresholds_from_bot = bot_config['quality_thresholds']\n",
    "\n",
    "# --- Run the simulation and generate the plot ---\n",
    "plot_cumulative_performance(\n",
    "    df_ohlcv=df_dev,  # Run on our development dataset\n",
    "    strategy_params=winning_strategy_params,\n",
    "    quality_thresholds=quality_thresholds_from_bot\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
