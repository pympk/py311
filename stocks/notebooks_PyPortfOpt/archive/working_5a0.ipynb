{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff29b931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# --- 1. PANDAS & IPYTHON OPTIONS ---\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 3000*5)\n",
    "pd.set_option('display.float_format', '{:.6f}'.format)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# --- 2. PROJECT PATH CONFIGURATION ---\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "PARENT_DIR = NOTEBOOK_DIR.parent\n",
    "ROOT_DIR = NOTEBOOK_DIR.parent.parent  # Adjust if your notebook is in a 'notebooks' subdirectory\n",
    "DATA_DIR = ROOT_DIR / 'data'\n",
    "SRC_DIR = ROOT_DIR / 'src'\n",
    "\n",
    "# Add 'src' to the Python path to import custom modules\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.append(str(SRC_DIR))\n",
    "\n",
    "# --- 3. IMPORT CUSTOM MODULES ---\n",
    "import utils\n",
    "import plotting_utils\n",
    "\n",
    "# --- 4. INITIAL_CAPITAL ---\n",
    "INITIAL_CAPITAL = 100000\n",
    "\n",
    "# --- 5. RISK FREE ANNUAL RATE ---\n",
    "RISK_FREE_ANNUAL_RATE = 0.04\n",
    "\n",
    "# --- 6. VERIFICATION ---\n",
    "print(\"--- Path Configuration ---\")\n",
    "print(f\"✅ Project Root: {ROOT_DIR}\")\n",
    "print(f\"✅ Parent Dir:   {PARENT_DIR}\")\n",
    "print(f\"✅ Notebook Dir: {NOTEBOOK_DIR}\")\n",
    "print(f\"✅ Data Dir:     {DATA_DIR}\")\n",
    "print(f\"✅ Source Dir:   {SRC_DIR}\")\n",
    "assert all([ROOT_DIR.exists(), DATA_DIR.exists(), SRC_DIR.exists()]), \"A key directory was not found!\"\n",
    "\n",
    "print(\"\\n--- Module Verification ---\")\n",
    "print(f\"✅ Successfully imported 'utils' and 'plotting_utils'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd962df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(DATA_DIR / 'df_adj_close.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83b2486",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'df:\\n{df}')\n",
    "print(\"\\ndf.info():\")\n",
    "df.info()\n",
    "print(f'\\ndf.index.names:\\n{df.index.names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88610c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns is a DataFrame with the same shape and index as df\n",
    "returns = df.pct_change()\n",
    "\n",
    "# Optionally drop the first row (all NaNs) if you don’t need it\n",
    "returns = returns.dropna()\n",
    "\n",
    "# Add a new column 'CASH' with all values set to 0\n",
    "returns['CASH'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5430680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'returns:\\n{returns}')\n",
    "print(\"\\nreturns.info():\")\n",
    "returns.info()\n",
    "print(f'\\nreturns.index.names:\\n{returns.index.names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5646c607",
   "metadata": {},
   "outputs": [],
   "source": [
    "SLIDING_WINDOW_WIDTH = 300\n",
    "SLIDING_WINDOW_STEP = 60\n",
    "SLIDING_WINDOW_STEP = 30\n",
    "\n",
    "n_test_rows = SLIDING_WINDOW_WIDTH - SLIDING_WINDOW_STEP\n",
    "n_train_rows = SLIDING_WINDOW_STEP\n",
    "\n",
    "assert SLIDING_WINDOW_STEP < int(0.3 * SLIDING_WINDOW_WIDTH), \"SLIDING_WINDOW_STEP must be less than 0.3 * SLIDING_WINDOW_WIDTH\"\n",
    "print(\"SLIDING_WINDOW Assertion passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1442dc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the rolling window chunks\n",
    "rolling_chunks = []\n",
    "\n",
    "# Loop through the DataFrame with a step of SLIDING_WINDOW_STEP rows\n",
    "for start in range(0, len(returns) - SLIDING_WINDOW_WIDTH + 1, SLIDING_WINDOW_STEP):\n",
    "    end = start + SLIDING_WINDOW_WIDTH\n",
    "    chunk = returns.iloc[start:end]\n",
    "    rolling_chunks.append(chunk)\n",
    "\n",
    "# Now rolling_chunks is a list of DataFrames, each containing SLIDING_WINDOW_WIDTH rows (or fewer for the last chunk)\n",
    "# Print the number of chunks and the shape of each chunk\n",
    "for i, chunk in enumerate(rolling_chunks):\n",
    "    print(f\"Chunk {i+1:<4} shape: {chunk.shape} | First index: {chunk.index[0].strftime('%Y-%m-%d')} | Last index: {chunk.index[-1].strftime('%Y-%m-%d')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebea670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of dataframes for training\n",
    "n_train_chunks = int(len(rolling_chunks) * 0.75)\n",
    "\n",
    "# Number of dataframes for training\n",
    "train_chunks = rolling_chunks[: n_train_chunks]\n",
    "# Number of dataframes reserved for verification\n",
    "reserve_chunks = rolling_chunks[n_train_chunks :]\n",
    "\n",
    "print(f'Number of training dataframes : {n_train_chunks}')\n",
    "print(f'number of rolling_chunks dataframes in train_chunks: {len(train_chunks)}')\n",
    "print(f'number of rolling_chunks dataframes in reserve_chunks:  {len(reserve_chunks)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963edf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2ca3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import papermill as pm\n",
    "import pandas as pd\n",
    "from pathlib import Path # Use pathlib for cleaner path handling\n",
    "\n",
    "# NOTEBOOK_DIR = Path(\"c:/Users/ping/Files_win10/python/py311/stocks/notebooks_PyPortfOpt/_working\") # Define your directory\n",
    "\n",
    "# Assuming train_chunks is already defined and contains your data\n",
    "\n",
    "for i, train_chunk in enumerate(train_chunks[0:1]): # Using enumerate for clarity if needed\n",
    "    returns_train = train_chunk.iloc[:n_test_rows]\n",
    "    returns_test = train_chunk.iloc[n_test_rows:]\n",
    "\n",
    "    # Define the full file paths with extensions\n",
    "    train_file = NOTEBOOK_DIR / f\"/temp/returns_train_chunk_{i}.parquet\"\n",
    "    test_file = NOTEBOOK_DIR / f\"/temp/returns_test_chunk_{i}.parquet\"\n",
    "\n",
    "    # Save DataFrames to disk with the correct extension\n",
    "    returns_train.to_parquet(train_file)\n",
    "    returns_test.to_parquet(test_file)\n",
    "\n",
    "    # Define the output notebook name\n",
    "    out_notebook = f\"/temp/_pm_out_working_5b2_chunk_{i}.ipynb\"\n",
    "\n",
    "    # Execute the notebook, passing the full paths\n",
    "    pm.execute_notebook(\n",
    "        \"working_5b2.ipynb\",\n",
    "        out_notebook,\n",
    "        parameters={\n",
    "            \"returns_train_path\": str(train_file), # Pass the full path as a string\n",
    "            \"returns_test_path\": str(test_file),   # Pass the full path as a string\n",
    "        },\n",
    "        kernel_name=\"python3\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
