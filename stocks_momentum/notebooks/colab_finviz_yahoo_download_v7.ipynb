{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HplHE-XnwHFz"
      },
      "source": [
        "===== TURN ON POWERTOY AWAKE to KEEP CONNECTION ALIVE =====\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BAeKmVzAEwE",
        "outputId": "5aabec6e-64c5-4fe8-c79e-6f9df538642a"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzjWU0MyA8cT"
      },
      "source": [
        "===== SET download_to_PC and end_index ====="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LnCnXVOGAzi8"
      },
      "outputs": [],
      "source": [
        "# symbols: The string (or sequence) to slice.\n",
        "# start_index: Optional. The starting index of the slice. If None, defaults to 0.\n",
        "# end_index: Optional. The ending index of the slice (exclusive). If None, defaults to the end of the string.\n",
        "# step_value: Optional. The step value for the slice. If None, defaults to 1.\n",
        "\n",
        "# True download to PC, False download to Google Drive\n",
        "download_to_PC = True  # True download to PC\n",
        "# download_to_PC = False  # True download to Google Drive\n",
        "\n",
        "# Download all if end_iddex = None\n",
        "end_index = None\n",
        "end_index = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWX6sLNsmsCr",
        "outputId": "ef9e686f-dcdb-4d3e-c46d-016214af1ab0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "slice of symbols: symbols[slice(None, 3, None)]\n"
          ]
        }
      ],
      "source": [
        "start_index = None\n",
        "\n",
        "step_value = None\n",
        "slice_obj = slice(start_index, end_index, step_value)  # Create a slice object\n",
        "\n",
        "print(f'slice of symbols: symbols[{slice_obj}]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2xUTYT3wHF4",
        "outputId": "ca983a72-46c5-4a6e-8dfa-3d383b6c638f"
      },
      "outputs": [],
      "source": [
        "! pip install fake-useragent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HTCD6Lo1wHF4"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from fake_useragent import UserAgent\n",
        "\n",
        "selector = '.styled-table-new'\n",
        "ua = UserAgent()  # Initialize UserAgent\n",
        "\n",
        "def download_table(url, selector):\n",
        "    \"\"\"\n",
        "    Downloads table data from a Yahoo Finance page with rate limiting.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Add a User-Agent header to mimic a browser\n",
        "        # headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}  # Example User-Agent\n",
        "        new_user_agent = ua.random\n",
        "        headers = {\"User-Agent\": new_user_agent}\n",
        "        response = requests.get(url, headers=headers)\n",
        "        response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        table_body = soup.select_one(selector)\n",
        "\n",
        "        if table_body is None:\n",
        "            print(f\"Error: Table body not found using selector: {selector}\")\n",
        "            return None\n",
        "\n",
        "        rows = table_body.find_all('tr')\n",
        "        if not rows:\n",
        "            print(\"Error: No rows found in the table.\")\n",
        "            return None\n",
        "\n",
        "        # Extract headers from the first row (th elements)\n",
        "        headers_list = [th.text.strip() for th in rows[0].find_all('th')]\n",
        "\n",
        "        data = []\n",
        "        for row in rows:\n",
        "            cells = row.find_all('td')\n",
        "            row_data = [cell.text.strip() for cell in cells]\n",
        "            if row_data:  # Only append if the row has data\n",
        "                data.append(row_data)\n",
        "\n",
        "        if not data:\n",
        "            print(\"Error: No data found in the table rows.\")\n",
        "            return None\n",
        "\n",
        "        df = pd.DataFrame(data, columns=headers_list)\n",
        "        return df\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error during request: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "D6T6kGjzwHF5"
      },
      "outputs": [],
      "source": [
        "columns_common_stock_etfs_metrics_sector_industry_category = 'c=0,1,2,3,4,6,8,10,11,13,14,33,38,40,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,125,126,59,61,63,64,67,65,66,103,100,109'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "url_mktcap ='https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c='\n",
        "# url_columns is 'columns_common_stock_etfs_metrics_sector_industry_category'\n",
        "url_columns = '0,1,2,3,4,6,8,10,11,13,14,33,38,40,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,125,126,59,61,63,64,67,65,66'\n",
        "url_mktcap_rows = ['&r=1', '&r=21', '&r=41', '&r=61', '&r=81', '&r=101', '&r=121', '&r=141', '&r=161', '&r=181', '&r=201', '&r=221', '&r=241', '&r=261', '&r=281', '&r=301', '&r=321', '&r=341', '&r=361', '&r=381', '&r=401', '&r=421', '&r=441', '&r=461', '&r=481', '&r=501', '&r=521', '&r=541', '&r=561', '&r=581', '&r=601', '&r=621', '&r=641', '&r=661', '&r=681', '&r=701', '&r=721', '&r=741', '&r=761', '&r=781', '&r=801', '&r=821', '&r=841', '&r=861', '&r=881', '&r=901', '&r=921', '&r=941', '&r=961', '&r=981', '&r=1001', '&r=1021','&r=1041','&r=1061','&r=1081','&r=1101','&r=1121','&r=1141',]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYhnaEoxwHF6",
        "outputId": "012726ab-0aea-4afb-ebad-6c8624937336"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of urls: 58\n",
            "First 3 urls:\n",
            "['https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,3,4,6,8,10,11,13,14,33,38,40,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,125,126,59,61,63,64,67,65,66&r=1', 'https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,3,4,6,8,10,11,13,14,33,38,40,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,125,126,59,61,63,64,67,65,66&r=21', 'https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,3,4,6,8,10,11,13,14,33,38,40,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,125,126,59,61,63,64,67,65,66&r=41']\n"
          ]
        }
      ],
      "source": [
        "urls_mktcap = []\n",
        "\n",
        "for _rows in url_mktcap_rows:\n",
        "    _url = url_mktcap + url_columns + _rows\n",
        "    urls_mktcap.append(_url)\n",
        "\n",
        "print(f'Total number of urls: {len(urls_mktcap)}')\n",
        "print(f'First 3 urls:\\n{urls_mktcap[0:3]}')  # Print the length of the list of url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWfH7PLrwHF7",
        "outputId": "c604ef57-f8a8-47dd-f83e-4342a393f27d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len(shuffled_urls): 58\n",
            "shuffled_urls[0:10]\n",
            "https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,3,4,6,8,10,11,13,14,33,38,40,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,125,126,59,61,63,64,67,65,66&r=181\n",
            "https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,3,4,6,8,10,11,13,14,33,38,40,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,125,126,59,61,63,64,67,65,66&r=481\n",
            "https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,3,4,6,8,10,11,13,14,33,38,40,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,125,126,59,61,63,64,67,65,66&r=841\n",
            "https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,3,4,6,8,10,11,13,14,33,38,40,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,125,126,59,61,63,64,67,65,66&r=501\n",
            "https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,3,4,6,8,10,11,13,14,33,38,40,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,125,126,59,61,63,64,67,65,66&r=641\n",
            "https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,3,4,6,8,10,11,13,14,33,38,40,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,125,126,59,61,63,64,67,65,66&r=1041\n",
            "https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,3,4,6,8,10,11,13,14,33,38,40,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,125,126,59,61,63,64,67,65,66&r=341\n",
            "https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,3,4,6,8,10,11,13,14,33,38,40,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,125,126,59,61,63,64,67,65,66&r=761\n",
            "https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,3,4,6,8,10,11,13,14,33,38,40,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,125,126,59,61,63,64,67,65,66&r=81\n",
            "https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,3,4,6,8,10,11,13,14,33,38,40,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,125,126,59,61,63,64,67,65,66&r=361\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "urls =  urls_mktcap\n",
        "shuffled_urls = random.sample(urls, len(urls))\n",
        "print(f'len(shuffled_urls): {len(shuffled_urls)}')\n",
        "print(f'shuffled_urls[0:10]')\n",
        "for url in shuffled_urls[0:10]:\n",
        "    print(f'{url}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyA3q6n9wHF7"
      },
      "outputs": [],
      "source": [
        "# test_urls = [\n",
        "#   'https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,3,4,6,14,42,43,44,45,46,47,48,49,50,51,52,53,54,57,58,59,67,65,66,103,100,109,120,121,122&r=1',\n",
        "#   'https://finviz.com/screener.ashx?v=152&ft=4&o=-e.assetsundermanagement&c=0,1,2,3,4,6,14,42,43,44,45,46,47,48,49,50,51,52,53,54,57,58,59,67,65,66,103,100,109,120,121,122&r=101',\n",
        "#   'https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,3,4,6,14,42,43,44,45,46,47,48,49,50,51,52,53,54,57,58,59,67,65,66,103,100,109,120,121,122&r=601',\n",
        "#   ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "No.\tTicker\tCompany\tSector\tIndustry\tMarket Cap\tFwd P/E\tP/S\tP/B\tP/FCF\tDividend\tROE\tDebt/Eq\tOper M\tPerf Week\tPerf Month\tPerf Quart\tPerf Half\tPerf Year\tPerf YTD\tBeta\tATR\tVolatility W\tVolatility M\tSMA20\tSMA50\tSMA200\t50D High\t50D Low\t52W High\t52W Low\tAll-Time High\tAll-Time Low\tRSI\tGap\tAvg Volume\tRel Volume\tVolume\tPrice\tChange\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,3,4,6,8,10,11,13,14,33,38,40,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,125,126,59,61,63,64,67,65,66&r=181. Sleeping for 2.50 seconds.  Processed 1 / 58 urls\n",
            "Downloading https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,3,4,6,8,10,11,13,14,33,38,40,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,125,126,59,61,63,64,67,65,66&r=481. Sleeping for 2.36 seconds.  Processed 2 / 58 urls\n",
            "Downloading https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,3,4,6,8,10,11,13,14,33,38,40,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,125,126,59,61,63,64,67,65,66&r=841. Sleeping for 3.96 seconds.  Processed 3 / 58 urls\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "\n",
        "total_urls_to_download = len(shuffled_urls)\n",
        "\n",
        "df = pd.DataFrame()  # Initialized an empty DataFrame\n",
        "processed_count = 0\n",
        "\n",
        "columns_list = ['No.', 'Ticker', 'Company', 'Sector', 'Industry', 'Market Cap', \n",
        "                'Fwd P/E', 'P/S', 'P/B', 'P/FCF', 'Dividend', 'ROE', 'Debt/Eq', \n",
        "                'Oper M', 'Perf Week', 'Perf Month', 'Perf Quart', 'Perf Half', \n",
        "                'Perf Year', 'Perf YTD', 'Beta', 'ATR', 'Volatility W', 'Volatility M', \n",
        "                'SMA20', 'SMA50', 'SMA200', '50D High', '50D Low', '52W High', '52W Low', \n",
        "                'All-Time High', 'All-Time Low', 'RSI', 'Gap', 'Avg Volume', 'Rel Volume', \n",
        "                'Volume', 'Price', 'Change']\n",
        "\n",
        "# for url in test_urls:\n",
        "# for url in shuffled_urls[3:6]:\n",
        "for url in shuffled_urls[slice_obj]:\n",
        "    # Introduce a delay between requests (adjust as needed)\n",
        "    delay_seconds = random.uniform(2, 4.5)  # Sleep between 2 and 5 seconds\n",
        "    # print(f\"Downloading {symbol}. Sleeping for {delay_seconds:.2f} seconds...\")\n",
        "    processed_count += 1\n",
        "    print(f\"Downloading {url}. Sleeping for {delay_seconds:.2f} seconds.  Processed {processed_count} / {total_urls_to_download} urls\")\n",
        "    time.sleep(delay_seconds)\n",
        "\n",
        "    df_temp = download_table(url, selector)\n",
        "\n",
        "    if df_temp is not None:\n",
        "        df_temp_filtered = df_temp[columns_list]\n",
        "        # Discards the original row indices of both DataFrames.\n",
        "        # Creates a new sequential integer index\n",
        "        df = pd.concat([df, df_temp_filtered], ignore_index=True)\n",
        "    else:\n",
        "        print(f\"Failed to download data for {url}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJt8zyFewHF8",
        "outputId": "b1e7873a-3bfa-470c-876b-2fb8dd442b23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "df_finviz_filename: df_finviz_2025-04-24.parquet\n"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "import pytz\n",
        "\n",
        "pst = pytz.timezone('America/Los_Angeles')  # or 'US/Pacific'\n",
        "current_date_pst = datetime.datetime.now(pst).strftime('%Y-%m-%d')\n",
        "\n",
        "# Save the DataFrame as a Parquet file\n",
        "df_finviz_filename = f\"df_finviz_{current_date_pst}.parquet\"\n",
        "\n",
        "print(f\"df_finviz_filename: {df_finviz_filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "3agEKFzAMX95"
      },
      "outputs": [],
      "source": [
        "import pyarrow\n",
        "\n",
        "df.to_parquet(df_finviz_filename, engine='pyarrow', compression='zstd')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "aw1Sw3G-W419",
        "outputId": "ad4d9c6d-f49d-44f4-b4ba-ac2d5bce3160"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No.</th>\n",
              "      <th>Ticker</th>\n",
              "      <th>Company</th>\n",
              "      <th>Sector</th>\n",
              "      <th>Industry</th>\n",
              "      <th>Market Cap</th>\n",
              "      <th>Fwd P/E</th>\n",
              "      <th>P/S</th>\n",
              "      <th>P/B</th>\n",
              "      <th>P/FCF</th>\n",
              "      <th>...</th>\n",
              "      <th>52W Low</th>\n",
              "      <th>All-Time High</th>\n",
              "      <th>All-Time Low</th>\n",
              "      <th>RSI</th>\n",
              "      <th>Gap</th>\n",
              "      <th>Avg Volume</th>\n",
              "      <th>Rel Volume</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Price</th>\n",
              "      <th>Change</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>181</td>\n",
              "      <td>MMM</td>\n",
              "      <td>3M Co</td>\n",
              "      <td>Industrials</td>\n",
              "      <td>Conglomerates</td>\n",
              "      <td>74.74B</td>\n",
              "      <td>16.62</td>\n",
              "      <td>3.05</td>\n",
              "      <td>16.74</td>\n",
              "      <td>-</td>\n",
              "      <td>...</td>\n",
              "      <td>53.20%</td>\n",
              "      <td>-36.06%</td>\n",
              "      <td>1893.31%</td>\n",
              "      <td>50.27</td>\n",
              "      <td>-0.31%</td>\n",
              "      <td>4.36M</td>\n",
              "      <td>0.67</td>\n",
              "      <td>2,920,302</td>\n",
              "      <td>138.88</td>\n",
              "      <td>2.07%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>182</td>\n",
              "      <td>GD</td>\n",
              "      <td>General Dynamics Corp</td>\n",
              "      <td>Industrials</td>\n",
              "      <td>Aerospace &amp; Defense</td>\n",
              "      <td>72.92B</td>\n",
              "      <td>16.28</td>\n",
              "      <td>1.48</td>\n",
              "      <td>3.28</td>\n",
              "      <td>21.81</td>\n",
              "      <td>...</td>\n",
              "      <td>13.59%</td>\n",
              "      <td>-14.26%</td>\n",
              "      <td>19140.02%</td>\n",
              "      <td>52.78</td>\n",
              "      <td>-0.30%</td>\n",
              "      <td>1.79M</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1,834,919</td>\n",
              "      <td>271.71</td>\n",
              "      <td>2.25%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>183</td>\n",
              "      <td>WMB</td>\n",
              "      <td>Williams Cos Inc</td>\n",
              "      <td>Energy</td>\n",
              "      <td>Oil &amp; Gas Midstream</td>\n",
              "      <td>72.77B</td>\n",
              "      <td>24.85</td>\n",
              "      <td>6.77</td>\n",
              "      <td>5.86</td>\n",
              "      <td>31.69</td>\n",
              "      <td>...</td>\n",
              "      <td>58.16%</td>\n",
              "      <td>-3.33%</td>\n",
              "      <td>9274.76%</td>\n",
              "      <td>56.41</td>\n",
              "      <td>0.65%</td>\n",
              "      <td>8.13M</td>\n",
              "      <td>0.72</td>\n",
              "      <td>5,882,578</td>\n",
              "      <td>59.61</td>\n",
              "      <td>1.93%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>184</td>\n",
              "      <td>INFY</td>\n",
              "      <td>Infosys Ltd ADR</td>\n",
              "      <td>Technology</td>\n",
              "      <td>Information Technology Services</td>\n",
              "      <td>72.10B</td>\n",
              "      <td>20.11</td>\n",
              "      <td>3.74</td>\n",
              "      <td>6.42</td>\n",
              "      <td>17.21</td>\n",
              "      <td>...</td>\n",
              "      <td>9.73%</td>\n",
              "      <td>-33.84%</td>\n",
              "      <td>2935.48%</td>\n",
              "      <td>46.90</td>\n",
              "      <td>0.23%</td>\n",
              "      <td>12.67M</td>\n",
              "      <td>0.80</td>\n",
              "      <td>10,163,611</td>\n",
              "      <td>17.36</td>\n",
              "      <td>0.75%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>185</td>\n",
              "      <td>MSI</td>\n",
              "      <td>Motorola Solutions Inc</td>\n",
              "      <td>Technology</td>\n",
              "      <td>Communication Equipment</td>\n",
              "      <td>71.48B</td>\n",
              "      <td>26.97</td>\n",
              "      <td>6.61</td>\n",
              "      <td>42.01</td>\n",
              "      <td>33.50</td>\n",
              "      <td>...</td>\n",
              "      <td>28.58%</td>\n",
              "      <td>-15.69%</td>\n",
              "      <td>4703.58%</td>\n",
              "      <td>53.04</td>\n",
              "      <td>-0.28%</td>\n",
              "      <td>907.24K</td>\n",
              "      <td>0.47</td>\n",
              "      <td>425,021</td>\n",
              "      <td>428.14</td>\n",
              "      <td>0.94%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 40 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   No. Ticker                 Company       Sector  \\\n",
              "0  181    MMM                   3M Co  Industrials   \n",
              "1  182     GD   General Dynamics Corp  Industrials   \n",
              "2  183    WMB        Williams Cos Inc       Energy   \n",
              "3  184   INFY         Infosys Ltd ADR   Technology   \n",
              "4  185    MSI  Motorola Solutions Inc   Technology   \n",
              "\n",
              "                          Industry Market Cap Fwd P/E   P/S    P/B  P/FCF  \\\n",
              "0                    Conglomerates     74.74B   16.62  3.05  16.74      -   \n",
              "1              Aerospace & Defense     72.92B   16.28  1.48   3.28  21.81   \n",
              "2              Oil & Gas Midstream     72.77B   24.85  6.77   5.86  31.69   \n",
              "3  Information Technology Services     72.10B   20.11  3.74   6.42  17.21   \n",
              "4          Communication Equipment     71.48B   26.97  6.61  42.01  33.50   \n",
              "\n",
              "   ... 52W Low All-Time High All-Time Low    RSI     Gap Avg Volume  \\\n",
              "0  ...  53.20%       -36.06%     1893.31%  50.27  -0.31%      4.36M   \n",
              "1  ...  13.59%       -14.26%    19140.02%  52.78  -0.30%      1.79M   \n",
              "2  ...  58.16%        -3.33%     9274.76%  56.41   0.65%      8.13M   \n",
              "3  ...   9.73%       -33.84%     2935.48%  46.90   0.23%     12.67M   \n",
              "4  ...  28.58%       -15.69%     4703.58%  53.04  -0.28%    907.24K   \n",
              "\n",
              "  Rel Volume      Volume   Price Change  \n",
              "0       0.67   2,920,302  138.88  2.07%  \n",
              "1       1.03   1,834,919  271.71  2.25%  \n",
              "2       0.72   5,882,578   59.61  1.93%  \n",
              "3       0.80  10,163,611   17.36  0.75%  \n",
              "4       0.47     425,021  428.14  0.94%  \n",
              "\n",
              "[5 rows x 40 columns]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQtYfIR5F9y4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6_jh9e9WE_8",
        "outputId": "5b97794f-7f86-447e-84a7-a502ada4c716"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/drive/MyDrive/stocks/df_finviz_tickers.pkl'  # Run in Colab\n",
        "\n",
        "df_tickers = df[['Ticker']]\n",
        "\n",
        "# Save the DataFrame to a pickle file in the specified location\n",
        "df_tickers.to_pickle(file_path)\n",
        "print(f\"{len(df_tickers)} tickers saved to: {file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78db6cfhuLqT"
      },
      "outputs": [],
      "source": [
        "# ======================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VcTdIE3uLqT",
        "outputId": "f0f51798-4130-42c1-8cc7-1ca740c0a6f0"
      },
      "outputs": [],
      "source": [
        "# symbols: The string (or sequence) to slice.\n",
        "# start_index: Optional. The starting index of the slice. If None, defaults to 0.\n",
        "# end_index: Optional. The ending index of the slice (exclusive). If None, defaults to the end of the string.\n",
        "# step_value: Optional. The step value for the slice. If None, defaults to 1.\n",
        "\n",
        "# start_index = None\n",
        "# end_index = None\n",
        "# end_index = 3\n",
        "\n",
        "step_value = None\n",
        "slice_obj = slice(start_index, end_index, step_value)  # Create a slice object\n",
        "\n",
        "print(f'slice of symbols: symbols[{slice_obj}]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZmvZTdHuLqT"
      },
      "outputs": [],
      "source": [
        "from fake_useragent import UserAgent\n",
        "\n",
        "ua = UserAgent()  # Initialize UserAgent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAuxwFy7uLqU"
      },
      "outputs": [],
      "source": [
        "# selector = \"#nimbus-app > section > section > section > article > div.container > div.table-container.yf-1jecxey > table > tbody\"\n",
        "selector = \"#nimbus-app > section > section > section > article > div.container > div.table-container.yf-1jecxey\"\n",
        "col_names = ['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVZTyrX6uLqU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def read_stock_symbols(dir_path, symbols_stocks_file, symbols_ETFs_file):\n",
        "    \"\"\"\n",
        "    Reads stock and ETF symbols from text files in the specified directory and returns them in two separate lists.\n",
        "\n",
        "    Args:\n",
        "        dir_path (str): The directory path where the symbol files are located.\n",
        "        symbols_stocks_file (str): The name of the file containing stock symbols.\n",
        "        symbols_ETFs_file (str): The name of the file containing ETF symbols.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing two lists: (stock_symbols, etf_symbols).  Returns ([], [])\n",
        "               if any error occurs during file reading.\n",
        "    \"\"\"\n",
        "\n",
        "    stock_symbols = []\n",
        "    etf_symbols = []\n",
        "\n",
        "    try:\n",
        "        # Read stock symbols\n",
        "        with open(os.path.join(dir_path, symbols_stocks_file), 'r') as f:\n",
        "            stock_symbols = [line.strip() for line in f]\n",
        "\n",
        "        # Read ETF symbols\n",
        "        with open(os.path.join(dir_path, symbols_ETFs_file), 'r') as f:\n",
        "            etf_symbols = [line.strip() for line in f]\n",
        "\n",
        "        return stock_symbols, etf_symbols\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: One or more files not found in directory: {dir_path}\")\n",
        "        return [], []\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return [], []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I79YQzfFuLqV"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import random  # For a bit of randomness in the sleep time\n",
        "\n",
        "def download_yahoo_finance_table(url, selector):\n",
        "    \"\"\"\n",
        "    Downloads table data from a Yahoo Finance page with rate limiting.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Add a User-Agent header to mimic a browser\n",
        "        # headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}  # Example User-Agent\n",
        "        new_user_agent = ua.random\n",
        "        headers = {\"User-Agent\": new_user_agent}\n",
        "\n",
        "        response = requests.get(url, headers=headers)\n",
        "        response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
        "\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        table_body = soup.select_one(selector)\n",
        "\n",
        "        if table_body is None:\n",
        "            print(f\"Error: Table body not found using selector: {selector}\")\n",
        "            return None\n",
        "\n",
        "        rows = table_body.find_all('tr')\n",
        "        if not rows:\n",
        "            print(\"Error: No rows found in the table.\")\n",
        "            return None\n",
        "\n",
        "        # Extract headers from the first row (th elements)\n",
        "        headers_list = [th.text.strip() for th in rows[0].find_all('th')]\n",
        "\n",
        "        data = []\n",
        "        for row in rows:\n",
        "            cells = row.find_all('td')\n",
        "            row_data = [cell.text.strip() for cell in cells]\n",
        "            if row_data:  # Only append if the row has data\n",
        "                data.append(row_data)\n",
        "\n",
        "        if not data:\n",
        "            print(\"Error: No data found in the table rows.\")\n",
        "            return None\n",
        "\n",
        "        df = pd.DataFrame(data, columns=headers_list)\n",
        "        return df\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error during request: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkcX6TakuLqV"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import pytz\n",
        "\n",
        "def get_current_pst_time():\n",
        "  \"\"\"\n",
        "  Returns the current time in Pacific Standard Time (PST).\n",
        "\n",
        "  Returns:\n",
        "    A string representing the current time in PST, formatted as\n",
        "    \"YYYY-MM-DD HH:MM:SS\".\n",
        "  \"\"\"\n",
        "\n",
        "  pst_timezone = pytz.timezone('America/Los_Angeles')  # Get the PST timezone\n",
        "  pst_now = datetime.datetime.now(pst_timezone)  # Get the current time in PST\n",
        "\n",
        "  return pst_now.strftime(\"%Y-%m-%d %H:%M:%S\")  # Format the time as a string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gInEy7rtuLqV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def convert_df_data_types(df):\n",
        "    \"\"\"\n",
        "    Cleans and converts a Pandas DataFrame with a MultiIndex to the specified data types.\n",
        "\n",
        "    Args:\n",
        "        df: The input Pandas DataFrame.  Assumes a MultiIndex with stock ticker (str) and date (str).\n",
        "            Assumes columns 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume' as objects.\n",
        "\n",
        "    Returns:\n",
        "        A Pandas DataFrame with the correct data types.\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert the second level of the MultiIndex to datetime\n",
        "    try:\n",
        "        df.index = pd.MultiIndex.from_tuples([(i[0], pd.to_datetime(i[1])) for i in df.index], names=df.index.names)\n",
        "    except ValueError as e:\n",
        "        print(f\"Error converting MultiIndex to datetime: {e}\")\n",
        "        return df  # Or handle the error differently, e.g., raise it\n",
        "\n",
        "    # Convert columns to appropriate data types\n",
        "    columns_to_convert = ['Open', 'High', 'Low', 'Close', 'Adj Close']\n",
        "    for col in columns_to_convert:\n",
        "        try:\n",
        "            # Remove commas *before* attempting conversion. CRITICAL.\n",
        "            df[col] = df[col].str.replace(',', '', regex=False)  # Remove commas first\n",
        "            df[col] = df[col].astype(float)\n",
        "        except ValueError as e:\n",
        "            print(f\"Error converting column '{col}' to float: {e}\")\n",
        "            return df #skip this column and return the original df\n",
        "\n",
        "    try:\n",
        "        # Handle '-' values in 'Volume' BEFORE removing commas\n",
        "        df['Volume'] = df['Volume'].replace('-', np.nan)\n",
        "        df['Volume'] = df['Volume'].str.replace(',', '', regex=False).astype(float).astype('Int64') # Use Int64 to store NaN\n",
        "    except ValueError as e:\n",
        "        print(f\"Error converting column 'Volume' to int64: {e}\")\n",
        "        return df\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHvVY-VhuLqV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def adjust_prices(df):\n",
        "    \"\"\"\n",
        "    Adjusts Open, High, Low, and Close prices using Adj Close to account for splits and dividends.\n",
        "\n",
        "    Args:\n",
        "        df: Pandas DataFrame with 'Open', 'High', 'Low', 'Close', and 'Adj Close' columns.\n",
        "            Assumes MultiIndex with stock ticker and datetime.\n",
        "\n",
        "    Returns:\n",
        "        Pandas DataFrame with adjusted 'Open', 'High', and 'Low' prices.\n",
        "    \"\"\"\n",
        "\n",
        "    # Calculate the adjustment ratio\n",
        "    df['adjustment_ratio'] = df['Adj Close'] / df['Close']\n",
        "\n",
        "    # Adjust Open, High, and Low prices\n",
        "    df['Adj Open'] = df['Open'] * df['adjustment_ratio']\n",
        "    df['Adj High'] = df['High'] * df['adjustment_ratio']\n",
        "    df['Adj Low'] = df['Low'] * df['adjustment_ratio']\n",
        "\n",
        "\n",
        "    # Optionally, drop the adjustment_ratio column if you don't need it\n",
        "    df = df.drop('adjustment_ratio', axis=1)  # axis=1 to drop the column\n",
        "\n",
        "    return df\n",
        "\n",
        "# Example Usage (assuming 'df' is your cleaned DataFrame)\n",
        "# df_adjusted = adjust_prices(df.copy())  # Create a copy\n",
        "# print(df_adjusted.head())\n",
        "# print(df_adjusted.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnDeGAN7uLqW",
        "outputId": "417faa34-f632-421e-e8dd-9bb6dbcecc70"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/drive/MyDrive/stocks/df_finviz_tickers.pkl'  # Run in Colab\n",
        "\n",
        "loaded_df = pd.read_pickle(file_path)\n",
        "symbols = loaded_df['Ticker'].tolist()\n",
        "print(f\"symbols (len = {len(symbols)}):\")\n",
        "print(symbols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xZ2jju1uLqW",
        "outputId": "87914ba6-9cd4-44a6-98c2-65b01db9a536"
      },
      "outputs": [],
      "source": [
        "symbols_to_download = symbols[slice_obj]\n",
        "\n",
        "# symbols_to_download = slice_string(symbols, symbol_start, symbol_end, symbol_step)  # Adjust the slice as needed\n",
        "total_symbols_to_download = len(symbols_to_download)\n",
        "processed_count = 0\n",
        "\n",
        "print(f'symbols_to_download: symbols[{slice_obj}]')\n",
        "print(f'total_symbols_to_download: {total_symbols_to_download}')\n",
        "print(f'processed_count: {processed_count}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q52YTHcquLqW",
        "outputId": "46d7f8bb-5db7-4724-ebda-ab19632f5813"
      },
      "outputs": [],
      "source": [
        "current_pst_time = get_current_pst_time()\n",
        "print(f\"Start OHLCV download at PST time: {current_pst_time}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ro6O4nGuLqW",
        "outputId": "f890dc4a-8571-49dd-e616-385dd217aca1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame()  # Initialized an empty DataFrame\n",
        "\n",
        "for symbol in symbols_to_download:\n",
        "    url = f\"https://finance.yahoo.com/quote/{symbol}/history/\"\n",
        "    # Introduce a delay between requests (adjust as needed)\n",
        "    delay_seconds = random.uniform(2, 4.5)  # Sleep between 2 and 5 seconds\n",
        "    # print(f\"Downloading {symbol}. Sleeping for {delay_seconds:.2f} seconds...\")\n",
        "    processed_count += 1\n",
        "    print(f\"Downloading {symbol}. Sleeping for {delay_seconds:.2f} seconds.  Processed {processed_count} / {total_symbols_to_download} symbols.\")\n",
        "    time.sleep(delay_seconds)\n",
        "\n",
        "    df_temp = download_yahoo_finance_table(url, selector)\n",
        "\n",
        "    if df_temp is not None:\n",
        "        df_temp.columns = col_names # Ensure the columns are what is expected\n",
        "\n",
        "        df_temp.set_index('Date', inplace=True) # Set Date as Index\n",
        "        # Create MultiIndex\n",
        "        df_temp.index = pd.MultiIndex.from_product([[symbol], df_temp.index], names=['Symbol', 'Date'])\n",
        "\n",
        "        df = pd.concat([df, df_temp])  # Append to the combined DataFrame\n",
        "\n",
        "    else:\n",
        "        print(f\"Failed to download data for {symbol}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekzZn5ahuLqW",
        "outputId": "3742a90b-7866-46af-f982-8b8719f58ba5"
      },
      "outputs": [],
      "source": [
        "current_pst_time = get_current_pst_time()\n",
        "print(f\"End OHLCV download at PST time: {current_pst_time}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "nW2J6txeuLqX",
        "outputId": "527c8506-5819-4085-efc8-31f21d7cb582"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5elcgkAsuLqX",
        "outputId": "c1ccd4f2-5a5c-42a3-f617-ef05aba9d7d2"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ed0R2tQduLqX",
        "outputId": "f0a9e8ed-8f3e-45ec-ae34-167a567e6ed2"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import pytz\n",
        "\n",
        "pst = pytz.timezone('America/Los_Angeles')  # or 'US/Pacific'\n",
        "current_date_pst = datetime.datetime.now(pst).strftime('%Y-%m-%d')\n",
        "\n",
        "df_OHLCV_filename = f\"df_OHLCV_{current_date_pst}.parquet\"\n",
        "\n",
        "print(f\"df_OHLCV_filename: {df_OHLCV_filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cWwmLvyuLqc",
        "outputId": "474072d0-bf43-46d9-cd54-d02d167c1004"
      },
      "outputs": [],
      "source": [
        "# Drop rows with any NaN values\n",
        "df_dropna = df.dropna()\n",
        "df_dropna.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqENdn0huLqc",
        "outputId": "55cfd90f-aef5-48a3-cc01-105a6767e3a3"
      },
      "outputs": [],
      "source": [
        "df_converted = convert_df_data_types(df_dropna.copy())  # Create a copy to avoid modifying the original\n",
        "df_converted.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEi6efHUuLqd",
        "outputId": "7d3f5f68-4314-40f4-8b6f-919c7375d711"
      },
      "outputs": [],
      "source": [
        "df_adjusted = adjust_prices(df_converted.copy())  # Create a copy\n",
        "df_adjusted.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWQqc08yqnfk"
      },
      "outputs": [],
      "source": [
        "df_adjusted.to_parquet(df_OHLCV_filename, engine='pyarrow', compression='zstd')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "bb6tONh4uLqd",
        "outputId": "16c5ffe6-5f3e-4198-9a4f-0562e0729fc0"
      },
      "outputs": [],
      "source": [
        "df_adjusted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "zvZEbfwqiS0Z",
        "outputId": "c28db9fb-2303-47bf-ca80-93cadd7db8cd"
      },
      "outputs": [],
      "source": [
        "# Create a ZIP file\n",
        "zip_filename = current_date_pst + '_finviz_OHLCV.zip'\n",
        "zip_filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SjosRxFlcwW"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "# from google.colab import files\n",
        "\n",
        "# Example: List of files to download\n",
        "file_list = [df_finviz_filename, df_OHLCV_filename]\n",
        "\n",
        "# Check if files exist before adding to the zip archive\n",
        "with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "    for file in file_list:\n",
        "        if os.path.exists(file):\n",
        "            zipf.write(file)\n",
        "        else:\n",
        "            print(f\"Warning: File not found: {file}. Skipping.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XvKKrhq-7UGk",
        "outputId": "b7d4b569-4234-472c-9033-cb5ddce45f3c"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "if download_to_PC:\n",
        "  # Download the ZIP file (only 1 prompt)\n",
        "  if os.path.exists(zip_filename):\n",
        "      files.download(zip_filename)\n",
        "      print(f\"File '{zip_filename}' dowloaded to PC\")\n",
        "  else:\n",
        "      print(f\"Error: Zip file not created: {zip_filename}\")\n",
        "\n",
        "else:\n",
        "  destination_path = '/content/drive/MyDrive/stocks/'\n",
        "\n",
        "  # Construct the full path to the destination file\n",
        "  destination_file = os.path.join(destination_path, zip_filename)\n",
        "\n",
        "  # Use shutil.copy2 to preserve metadata (like timestamps)\n",
        "  try:\n",
        "      shutil.copy2(zip_filename, destination_file)\n",
        "      print(f\"File '{zip_filename}' downloaded to '{destination_file}'\")\n",
        "  except FileNotFoundError:\n",
        "      print(f\"Error: The file '{zip_filename}' was not found.\")\n",
        "  except Exception as e:\n",
        "      print(f\"An error occurred during the copy operation: {e}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gD4Ira3CdUo"
      },
      "outputs": [],
      "source": [
        "# # prompt: calculate the daily return of each ticker in df_adjusted. note the date index in df_adjusted is in reverse order\n",
        "\n",
        "# # THIS CALCULATAION IS CORRECT --- Calculate daily returns, handling the reversed date index\n",
        "# df_returns = df_adjusted['Adj Close'].pct_change(periods=-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjbtUIlQf9SQ"
      },
      "outputs": [],
      "source": [
        "# # prompt: cp: cannot stat 'zip_filename.zip': No such file or directory\n",
        "\n",
        "# import os\n",
        "# import zipfile\n",
        "# from google.colab import files\n",
        "\n",
        "# # Example: List of files to download\n",
        "# file_list = [df_finviz_filename, df_OHLCV_filename]\n",
        "\n",
        "# # Check if files exist before adding to the zip archive\n",
        "# with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "#     for file in file_list:\n",
        "#         if os.path.exists(file):\n",
        "#             zipf.write(file)\n",
        "#         else:\n",
        "#             print(f\"Warning: File not found: {file}. Skipping.\")\n",
        "\n",
        "# # Download the ZIP file (only 1 prompt)\n",
        "# if os.path.exists(zip_filename):\n",
        "#     files.download(zip_filename)\n",
        "# else:\n",
        "#     print(f\"Error: Zip file not created: {zip_filename}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMk4EaASg5ze"
      },
      "outputs": [],
      "source": [
        "# # prompt: copy zipeFile from above cell to /content/drive/MyDrive/stocks/\n",
        "\n",
        "# import shutil\n",
        "# import os\n",
        "\n",
        "# # Assuming zip_filename is defined in the previous code cell\n",
        "# # and contains the name of the created zip file.\n",
        "# # Example: zip_filename = '2024-07-27_finviz_OHLCV.zip'\n",
        "\n",
        "# destination_path = '/content/drive/MyDrive/stocks/'\n",
        "\n",
        "# # Construct the full path to the destination file\n",
        "# destination_file = os.path.join(destination_path, zip_filename)\n",
        "\n",
        "# # Use shutil.copy2 to preserve metadata (like timestamps)\n",
        "# try:\n",
        "#     shutil.copy2(zip_filename, destination_file)\n",
        "#     print(f\"File '{zip_filename}' copied to '{destination_file}'\")\n",
        "# except FileNotFoundError:\n",
        "#     print(f\"Error: The file '{zip_filename}' was not found.\")\n",
        "# except Exception as e:\n",
        "#     print(f\"An error occurred during the copy operation: {e}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
